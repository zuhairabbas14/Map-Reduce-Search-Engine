{"id": "11369", "url": "https://en.wikipedia.org/wiki?curid=11369", "title": "Frank Capra", "text": "Frank Capra\n\nFrank Russell Capra (born Francesco Rosario Capra; May 18, 1897September 3, 1991) was an Italian-American film director, producer and writer who became the creative force behind some of the major award-winning films of the 1930s and 1940s. Born in Italy and raised in Los Angeles from the age of five, his rags-to-riches story has led film historians such as Ian Freer to consider him the \"American dream personified.\"\n\nCapra became one of America's most influential directors during the 1930s, winning three Oscars from his six nominations as Best Director, along with three other Oscar wins from nine nominations in other categories. Among his leading films were \"It Happened One Night\" (1934), \"You Can't Take It With You\" (1938), and \"Mr. Smith Goes to Washington\" (1939); Capra was nominated as Best Director and as producer for Academy Award for Best Picture on all three films, winning both awards on the first two. During World War II, Capra served in the U.S. Army Signal Corps and produced propaganda films, such as the \"Why We Fight\" series.\n\nAfter World War II, Capra's career declined as his later films such as \"It's a Wonderful Life\" (1946), which flopped when it was first released, were critically derided as being \"simplistic\" or \"overly idealistic\". In succeeding decades, however, these films have been favorably reassessed. Outside of directing, Capra was active in the film industry, engaging in various political and social issues. He served as President of the Academy of Motion Pictures Arts and Sciences, worked alongside the Screenwriters Guild, and was head of the Directors Guild of America. \n\nCapra was born Francesco Rosario Capra in Bisacquino, Sicily, a village near Palermo. He was the youngest of seven children of Salvatore Capra, a fruit grower, and the former Rosaria \"Serah\" Nicolosi. Capra's family was Roman Catholic. The name \"Capra\", notes Capra's biographer Joseph McBride, represents his family's closeness to the land, and means \"goat\". He notes that the English word \"capricious\" derives from it, \"evoking the animal's skittish temperament\", adding that \"the name neatly expresses two aspects of Frank Capra's personality: emotionalism and obstinacy.\"\n\nIn 1903, when he was five, Capra emigrated to the United States with his family, who traveled in one of the steerage compartments of the steamship, \"Germania\", which was the cheapest way to book passage. For Capra, the journey, which took 13 days, remained in his mind for the rest of his life as one of his worst experiences:\n\nCapra remembers the ship's arrival in New York Harbor, where he saw \"a statue of a great lady, taller than a church steeple, holding a torch above the land we were about to enter\". He recalls his father's exclamation at the sight:\n\nThe family settled in Los Angeles's East Side (today Chinatown) which Capra described in his autobiography as an Italian \"ghetto\". Capra's father worked as a fruit picker and young Capra sold newspapers after school for 10 years, until he graduated from high school. Instead of working after graduating, as his parents wanted, he enrolled in college. He worked through college at the California Institute of Technology, playing banjo at nightclubs and taking odd jobs, which included working at the campus laundry facility, waiting tables, and cleaning engines at a local power plant. He studied chemical engineering and graduated in the spring of 1918. Capra later wrote that his college education had \"changed his whole viewpoint on life from the viewpoint of an alley rat to the viewpoint of a cultured person\".\n\nSoon after graduating college, Capra was commissioned in the US Army as a second lieutenant, having completed campus ROTC. In the Army, he taught mathematics to artillerymen at Fort Point, San Francisco. His father died during the war in an accident (1916). In the Army, Capra contracted Spanish flu and was medically discharged to return home to live with his mother. He became a naturalized U.S. citizen in 1920, taking the name Frank Russell Capra. Living at home with his siblings and mother, Capra was the only family member with a college education, yet he was the only one who remained chronically unemployed. After a year without work, seeing how his siblings had steady jobs, he felt he was a failure, which led to bouts of depression and abdominal pains, later discovered to have been an undiagnosed burst appendix.\n\nAfter recovering at home, Capra moved out and spent the next few years living in flophouses in San Francisco and hopping freight trains, wandering the Western United States. To support himself, he took odd jobs on farms, as a movie extra, playing poker, and selling local oil well stocks. In his early twenties, Capra had to undergo a circumcision due to recurring bouts of STIs (the first of which happened after an anonymous encounter with a woman at a party in San Francisco), which caused severe damage to his sex life, an affliction that lasted until his twilight years.\n\nIt was during this time that the 24-year-old Capra directed a 32-minute documentary film entitled \"La Visita Dell'Incrociatore Italiano LIBYA a San Francisco\". Not only did it document the visit of the Italian naval vessel LIBYA to San Francisco, but also the reception given to the crew of the ship by San Francisco's L'Italia Virtus Club, now known as the San Francisco Italian Athletic Club.\n\nAt age 25, Capra took a job selling books written and published by American philosopher, Elbert Hubbard. Capra recalled that he \"hated being a peasant, being a scrounging new kid trapped in the Sicilian ghetto of Los Angeles ... All I had was cockiness – and let me tell you that gets you a long way.\"\n\nDuring his book sales effortsand nearly brokeCapra read a newspaper article about a new movie studio opening in San Francisco. Capra phoned them saying he had moved from Hollywood, and falsely implied that he had experience in the budding film industry. Capra's only prior exposure to films was in 1915 while attending Manual Arts High School. The studio's founder, Walter Montague, was nonetheless impressed by Capra and offered him $75 to direct a one-reel silent film. Capra, with the help of a cameraman, made the film in two days and cast it with amateurs.\n\nAfter that first serious job in films, Capra began efforts to finding similar openings in the film industry. He took a position with another minor San Francisco studio, and subsequently received an offer to work with producer Harry Cohn at his new studio in Los Angeles. During this time, he worked as a property man, film cutter, title writer, and assistant director.\n\nCapra later became a gag writer for Hal Roach's \"Our Gang\" series and then writer for slapstick comedy director, Mack Sennett, where he wrote scripts for comedian Harry Langdon. According to Capra, it was he who invented Langdon's character, the innocent fool living in a \"naughty world.\"\n\nWhen Langdon eventually left Sennett to make longer, feature-length movies with First National Studios, he took Capra along as his personal writer and director. They made three feature films together during 1926 and 1927, all of them successful with critics and the public. The films made Langdon a recognized comedian in the caliber of Charlie Chaplin and Buster Keaton. Capra and Langdon later had a falling out, and Capra was fired. During the following years, Langdon's films went into decline without Capra's assistance. After splitting with Langdon, Capra directed a picture for First National, \"For the Love of Mike\", (1927). This was a silent comedy about three bickering godfathers, a German, a Jew, and an Irishman, starring a budding actress, Claudette Colbert. The movie was considered a failure.\n\nCapra returned to Harry Cohn's studio, now named Columbia Pictures, which was then producing short films and two-reel comedies used as \"fillers\", which played between main features. Columbia was one of many start-up studios on \"Poverty Row\" in Los Angeles. Like the others, Columbia was unable to compete with larger studios which often had their own production facilities, distribution and theaters. Cohn rehired Capra in 1928 to help his studio produce new, full-length feature films, to compete with the major studios. Capra would eventually direct 20 films for Cohn's studio, including all of his classics.\n\nBecause of Capra's engineering education, he adapted more easily to the new sound technology than most directors. He welcomed the transition to sound, recalling, \"I wasn't at home in silent films.\" Most studios were unwilling to invest in the new sound technology, assuming it was a passing fad. Many in Hollywood considered sound a threat to the industry and hoped it would pass quickly; McBride notes that \"Capra was not one of them.\" When he saw Al Jolson singing in \"The Jazz Singer\" in 1927, considered the first talkie, Capra recalled his reaction:\n\nFew of the studio heads or crew were aware of Capra's engineering background until he began directing \"The Younger Generation\" in 1929. The chief cinematographer who worked with Capra on a number of films, was likewise unaware. He describes this early period in sound for film:\n\nDuring his first year with Columbia, Capra directed nine films, some of which were successful. After the first few, Harry Cohn said \"it was the beginning of Columbia making a better quality of pictures.\" According to Barson, \"Capra became ensconced as Harry Cohn's most trusted director.\" His films soon established Capra as a \"bankable\" director known throughout the industry, and Cohn raised Capra's initial salary of $1,000 per film to $25,000 per year. Capra directed a film for MGM during this period, but soon realized he \"had much more freedom under Harry Cohn's benevolent dictatorship\", where Cohn also put Capra's \"name above the title\" of his films, a first for the movie industry. Capra wrote of this period and recalled the confidence that Cohn placed in Capra's vision and directing:\n\nCapra directed his first \"real\" sound picture, \"The Younger Generation\", in 1929. It was a rags-to-riches romantic comedy about a Jewish family's upward mobility in New York City, with their son later trying to deny his Jewish roots in order to keep his rich gentile girlfriend. According to Capra biographer Joseph McBride, Capra \"obviously felt a strong identification with the story of a Jewish immigrant who grows up in the ghetto of New York... and feels he has to deny his ethnic origins to rise to success in America.\" Capra, however, denied any connection of the story with his own life.\n\nNonetheless, McBride insists that \"The Younger Generation\" abounds with parallels to Capra's own life.\" McBride notes the \"devastatingly painful climactic scene\", where the young social-climbing son, embarrassed when his wealthy new friends first meet his parents, passes his mother and father off as house servants. That scene, notes McBride, \"echoes the shame Capra admitted feeling toward his own family as he rose in social status.\"\n\nDuring his years at Columbia, Capra worked often with screenwriter Robert Riskin (husband of Fay Wray), and cameraman Joseph Walker. In many of Capra's films, the wise-cracking and sharp dialogue was often written by Riskin, and he and Capra went on to become Hollywood's \"most admired writer-director team.\"\n\nCapra's films in the 1930s enjoyed immense success at the Academy Awards. \"It Happened One Night\" (1934) became the first film to win all five top Oscars (Best Picture, Best Director, Best Actor, Best Actress, and Best Screenplay). Written by Robert Riskin, it is one of the first of the \"screwball comedies\", and with its release in the Great Depression, critics considered it an escapist story and a variation of the \"American Dream\". The film established the names of Capra, Columbia Pictures, and stars Clark Gable and Claudette Colbert in the movie industry. The film has been called \"picaresque\", and was one of the earliest \"road movies\" which inspired variations on its theme by other filmmakers.\n\nThe film was followed by \"Broadway Bill\" (1934), a screwball comedy about horse racing. The film was a turning point for Capra, however, as he began to conceive of an additional dimension to his movies. He started using his films to convey messages to the public. Capra explains his new thinking:\nThis added goal was inspired after meeting with a Christian Scientist friend who told him to view his talents in a different way:\nCapra began to embody messages in subsequent films, many of which conveyed \"fantasies of goodwill.\" The first of those was \"Mr. Deeds Goes to Town\" (1936), for which Capra won his second Best Director Oscar. Critic Alistair Cooke observed that Capra was \"starting to make movies about themes instead of people.\"\n\nIn 1938, Capra won his third Director Oscar in five years for \"You Can't Take It with You\", which also won Best Picture. In addition to his three directing wins, Capra received directing nominations for three other films (\"Lady for a Day\", \"Mr. Smith Goes to Washington\", and \"It's a Wonderful Life\"). On May 5, 1936, Capra hosted the 8th Academy Awards ceremony.\n\nAlthough \"It's a Wonderful Life\" is his best-known film, Friedman notes that it was \"Mr. Smith Goes to Washington\" (1939) which most represented the \"Capra myth.\" That film expressed Capra's patriotism more than any others, and \"presented the individual working within the democratic system to overcome rampant political corruption.\"\n\nThe film, however, became Capra's most controversial. In his research before filming, he was able to stand close to President Franklin D. Roosevelt during a press conference after the recent acts of war by Germany in Europe. Capra recalls his fears:\nWhen the filming was completed, the studio sent preview copies to Washington. Joseph P. Kennedy, U.S. ambassador to the UK, wrote to Columbia head Harry Cohn, \"Please do not play this picture in Europe.\" Politicians were concerned about the potential negative impact the film might have on the morale of the United States' allies, as World War II had begun. Kennedy wrote to president Roosevelt that \"in foreign countries this film must inevitably strengthen the mistaken impression that the United States is full of graft, corruption and lawlessness.\" Many studio heads agreed nor did they want negative feelings about Hollywood to be instilled in political leaders.\n\nNonetheless, Capra's vision of the film's significance was clear:\nCapra pleaded with Cohn to allow the film to go into distribution and remembers the intensity of their decision making:\nCohn and Capra chose to ignore the negative publicity and demands, and released the film as planned. It was later nominated for 11 Academy Awards, only winning one (for Best Original Story) partly because of the number of major pictures that were nominated that year was 10, including \"The Wizard of Oz\" and \"Gone with the Wind\". Hollywood columnist Louella Parsons called it a \"smash patriotic hit\" and most critics agreed, seeing that audiences left the theaters with \"an enthusiasm for democracy\" and \"in a glow of patriotism.\"\n\nThe significance of the film's message was established further in France, shortly after World War II began. When the French public were asked to select which film they wanted to see most, having been told by the Vichy government that soon no more American films would be allowed in France, the overwhelming majority chose it over all others. To a France soon to be invaded and occupied by Nazi forces, the film most expressed the \"perseverance of democracy and the American way.\"\n\nIn 1941 Capra directed \"Meet John Doe\" (1941), considered by some to be Capra's most controversial movie. The film's hero, played by Gary Cooper, is a former baseball player now bumming around, lacking goals. He is selected by a news reporter to represent the \"common man\", used to capture the imagination of ordinary Americans. The film was released shortly before America became involved in World War II, and citizens were still in an isolationist mood. According to some historians, the film was made to convey a \"deliberate reaffirmation of American values\", although ones which seemed uncertain with respect to the future.\n\nFilm author Richard Glazer speculates that the film may have been autobiographical, \"reflecting Capra's own uncertainties.\" Glazer describes how \"John's accidental transformation from drifter to national figure parallels Capra's own early drifting experience and subsequent involvement in movie making ... \"Meet John Doe\", then, was an attempt to work out his own fears and questions.\"\n\nWithin four days after the Japanese Attack on Pearl Harbor on December 7, 1941, Capra quit his successful directing career in Hollywood and received a commission as a major in the United States Army. He also gave up his presidency of the Screen Directors Guild. Being 44 years of age, he was not asked to enlist, but, notes Friedman, \"Capra had an intense desire to prove his patriotism to his adopted land.\"\n\nCapra recalls some personal reasons for enlisting:\n\nDuring the next four years of World War II, Capra's job was to head a special section on morale to explain to soldiers \"why the hell they're in uniform\", writes Capra, and were not \"propaganda\" films like those created by the Nazis and Japan. Capra directed or co-directed seven documentary war information films.\n\nCapra was assigned to work directly under Chief of Staff George C. Marshall, the most senior officer in command of the Army, who later created the Marshall Plan and was awarded a Nobel Peace Prize. Marshall chose to bypass the usual documentary film-making department, Signal Corps, because he felt they were not capable of producing \"sensitive and objective troop information films.\" One colonel explained the importance of these future films to Capra:\n\nDuring his first meeting with General Marshall, Capra was told his mission:\nThe films included the seven-episode \"Why We Fight\" series – consisting of \"Prelude to War\" (1942), \"The Nazis Strike\" (1942), \"Divide and Conquer\" (1943), \"The Battle of Britain\" (1943), \"The Battle of Russia\" (1943), \"The Battle of China\" (1944), \"War Comes to America\" (1945) – plus \"\" (1945), \"Here Is Germany\" (1945), \"Tunisian Victory\" (1945), and \"Two Down and One to Go\" (1945) that do not bear the \"Why We Fight\" banner; as well as the African-American related film, \"The Negro Soldier\" (1944).\n\nAfter completion of the first few documentaries, government officials and U.S. Army staff found them to be powerful messages and excellent presentations of why it was necessary for the U.S. to fight in the war. All footage came from military and government sources, whereas during earlier years, many newsreels secretly used footage from enemy sources. Animated charts were created by Walt Disney and his animators. A number of Hollywood composers wrote the background music, including Alfred Newman and Russian-born composer Dimitri Tiomkin. After the first complete film was viewed by General Marshall along with U.S. Army staff, Marshall approached Capra: \"Colonel Capra, how did you do it? That is a most wonderful thing.\"\n\nOfficials made efforts to see that the films were seen in theaters throughout the U.S. They were translated into French, Spanish, Portuguese, and Chinese for use by other countries. Winston Churchill ordered that \"all\" of them be shown to the British public in theaters. They are today often broadcast on television and used as a teaching aid.\n\nThe \"Why We Fight\" series is widely considered a masterpiece of war information documentaries, and won an Academy Award. \"Prelude to War\" won the 1942 Academy Award for Documentary Feature. When his career ended, Capra regarded these films as his most important works. As a colonel, he received the Legion of Merit in 1943 and the Distinguished Service Medal in 1945.\n\nAfter the war ended, along with directors William Wyler and George Stevens, Capra founded Liberty Films. Their studio became the first independent company of directors since United Artists in 1919 whose goal was to make films without interference by studio bosses. However, the only picture completed by the studio was \"It's a Wonderful Life\" (1946). It was a box office disappointment, but was nonetheless nominated for five Academy Awards.\n\nWhile the film did not resonate with audiences in 1946, its popularity as a top production has grown through the years. In 1998, the American Film Institute (AFI) named it one of the best films ever made, putting it at 11th on AFI's 100 Years... 100 Movies list of the top American films of all time. In 2006, the AFI put the film at the top of its AFI's 100 Years... 100 Cheers list, ranking what AFI considers to be the most inspirational American movies of all time. It would become Capra's last film to win major acclaim—his successful years were now behind him, although he directed five more films over the next 14 years.\n\nFor \"State of the Union\" (1948), Capra changed studios, working for the only time for MGM Pictures. Although the project had an excellent pedigree with stars Spencer Tracy and Katharine Hepburn, the film was not a success, and Capra's eyebrow-raising statement, \"I think \"State of the Union\" was my most perfect film in handling people and ideas\" has few adherents today.\n\nIn January 1952, Capra was requested by the U.S. Ambassador to India to represent the U.S. film industry at the International Film Festival to be held in India. A State Department friend of Capra asked him and explained why his trip would be important:\nAfter two weeks in India, Capra discovered that Bowles' fears were warranted, as many film sessions were used by Russian and Chinese representatives to give long political speeches. At a lunch with 15 Indian directors and producers, he stressed that \"they must preserve freedom as artists, and that any government control would hinder that freedom. A totalitarian system – and they would become nothing but publicity men for the party in power.\" Capra had a difficult time communicating this, however, as he noted in his diary:\n\nWhen he returned to Washington to give his report, Secretary of State Dean Acheson gave Capra his commendation for \"virtually single-handedly forestalling a possible Communist take-over of Indian films.\" Ambassador Bowles also conveyed gratitude to Capra for \"one helluva job.\"\n\nAlthough \"It's a Wonderful Life\" and \"State of the Union\" were successful soon after the war ended, Capra's themes were becoming out of step with changes in the film industry and the public mood. Friedman finds that while Capra's ideas were popular with depression-era and prewar audiences, they became less relevant to a prospering post-war America. Capra had become \"disconnected from an American culture that had changed\" during the previous decade. Biographer Joseph McBride argues that Capra's disillusionment was more related to the negative effect that the House Un-American Activities Committee (HUAC) had on the film industry in general. The HUAC interrogations in the early 1950s ended many Hollywood careers. Capra himself was not called to testify, although he was a prime target of the committee due to his past associations with many Hollywood blacklisted screenwriters.\n\nCapra blames his early retirement from films on the rising power of stars, which forced him to continually compromise his artistic vision. He also claims that increasing budgetary and scheduling demands were constraining his creative abilities. Film historian Michael Medved agrees with and understands Capra's impressions, noting that he walked away from the movie business because \"he refused to adjust to the cynicism of the new order.\" In his autobiography written in 1971, Capra expressed his feelings about the shifting film industry:\n\nCapra added that in his opinion, \"practically all the Hollywood film-making of today is stooping to cheap salacious pornography in a crazy bastardization of a great art to compete for the 'patronage' of deviates and masturbators.\"\n\nCapra remained employable in Hollywood during and after the HUAC hearings, but chose nonetheless to demonstrate his loyalty by attempting to re-enlist in the Army at the outbreak of the Korean War, in 1950. He was rejected due to his age. He was later invited to join the Defense Department's newly formed Think Tank project, VISTA, but was denied the necessary clearance. According to Friedman, \"these two rejections were devastating to the man who had made a career of demonstrating American ideals in film\", along with his directing award-winning documentary films for the Army. By 1952, at the age of 55, Capra effectively retired from Hollywood filmmaking and spent his later years working with Caltech, his alma mater, to produce educational films on science topics.\n\nCapra directed two films at Paramount Pictures starring Bing Crosby, \"Riding High\" (1950) and \"Here Comes the Groom\" (1951). From 1952 to 1956, Capra produced four science-related television specials in color for The Bell Laboratory Science Series: \"Our Mr. Sun\" (1956), \"Hemo the Magnificent\" (1957), \"The Strange Case of the Cosmic Rays\" (1957), and \"Meteora: The Unchained Goddess\" (1958). These educational science documentaries were popular favorites for school science classrooms. It was eight years before he directed another theatrical film, \"A Hole in the Head\" (1959) with Frank Sinatra and Edward G. Robinson, his first feature film in color. His final theatrical film was with Glenn Ford and Bette Davis, named \"Pocketful of Miracles\" (1961), a remake of his 1933 film \"Lady for a Day\". In the mid-1960s he worked on pre-production for an adaptation of Martin Caidin's novel \"Marooned,\" but budgetary constraints caused him to eventually shelve it.\n\nCapra's final film, \"Rendezvous in Space\" (1964), was an industrial film made for the Martin Marietta Company and shown at the 1964 New York World's Fair. It was exhibited at the New York Hall of Science after the Fair ended.\n\nCapra's directing style relied on improvisation to a great extent. He was noted for going on the set with no more than the master scenes written. He explained his reasoning:\nAccording to some experts, Capra used great, unobtrusive craftsmanship when directing, and felt it was bad directing to distract the audience with fancy technical gimmicks. Film historian and author William S. Pechter described Capra's style as one \"of almost classical purity.\" He adds that his style relied on editing to help his films sustain a \"sequence of rhythmic motion.\" Pechter describes its effect:\nFilm critic John Raeburn discusses an early Capra film, \"American Madness\" (1932), as an example of how he had mastered the movie medium and expressed a unique style:\nAs for Capra's subject matter, film author Richard Griffith tries to summarize Capra's common theme:\n\nCapra's personality when directing gave him a reputation for \"fierce independence\" when dealing with studio bosses. On the set he was said to be gentle and considerate, \"a director who displays absolutely no exhibitionism.\" As Capra's films often carry a message about basic goodness in human nature, and show the value of unselfishness and hard work, his wholesome, feel-good themes have led some cynics to term his style \"Capra-corn.\" However, those who hold his vision in higher regard prefer the term \"Capraesque\".\n\nCapra's basic themes of championing the common man, as well as his use of spontaneous, fast-paced dialogue and goofy, memorable lead and supporting characters, made him one of the most popular and respected filmmakers of the 20th century. His influence can be traced in the works of many directors, including Robert Altman, Ron Howard, Masaki Kobayashi, Akira Kurosawa, John Lasseter, David Lynch, John Milius, Martin Scorsese, Steven Spielberg, Oliver Stone and François Truffaut \n\nCapra married actress Helen Howell in 1923; they divorced in 1928. He married Lucille Warner in 1928, with whom he had a daughter and three sons, one of whom died in infancy.\n\nCapra was four times president of the Academy of Motion Picture Arts and Sciences and three times president of the Directors Guild of America, which he helped found. Under his presidency, he worked to give directors more artistic control of their films. During his career as a director, he retained an early ambition to teach science, and after his career declined in the 1950s, he made educational TV films related to science subjects.\n\nPhysically, Capra was short, stocky, and vigorous, and enjoyed outdoor activities such as hunting, fishing, and mountain climbing. In his much later years, he spent time writing short stories and songs, along with playing his guitar. He collected fine and rare books during the 1930s/40s. His 'Distinguished Library' was sold at auction in New York in 1949, realizing over $68,000 ($ today).\n\nHis son Frank Capra Jr., one of the four children born to Capra and his second wife, Lucille Capra, was the president of EUE Screen Gems Studios in Wilmington, North Carolina, until his death on December 19, 2007. His grandsons, brothers Frank Capra III and Jonathan Capra, have both worked as assistant directors – Frank III worked on the 1995 film \"The American President\", which referred to Frank Capra in the film's dialogue.\n\nIn 1985, at age 88, Capra suffered one of a series of strokes. He died in La Quinta, California, of a heart attack in his sleep in 1991 at the age of 94. He was interred at Coachella Valley Public Cemetery in Coachella, California.\n\nHe left part of his ranch in Fallbrook, California, to Caltech as a retreat center. Capra's personal papers and some film related materials are contained in the Wesleyan University Cinema Archives, which allows scholars and media experts full access.\n\nThe Academy Film Archive preserved \"The Matinee Idol\" and \"Two Down and One to Go!\" by Frank Capra.\n\nCapra’s political beliefs coalesced in his films, which promoted and celebrated the spirit of American individualism. A conservative Republican, Capra railed against Franklin Delano Roosevelt during his tenure as governor of New York, and opposed his presidency during the years of the Depression. Capra stood against government intervention during the national economic crisis.\n\nIn the years following World War II, he became a self-described pacifist, and was very critical of the Vietnam War as it was happening.\n\nDuring the golden age of Hollywood, Capra's \"fantasies of goodwill\" made him one of the two or three most famous and successful directors in the world. Film historian Ian Freer notes that at the time of his death in 1991, his legacy remained intact:\n\nDirector/actor John Cassavetes contemplating Capra’s contribution to the art of film quipped: \"Maybe there really wasn't an America, it was only Frank Capra.\" Capra’s films were his love letters to an idealized America – a cinematic landscape of his own invention. The performances his actors gave were invariable portrayals of personalities developed into recognizable images of popular culture, \"their acting has the bold simplicity of an icon...\" \n\nLike his contemporary, director John Ford, Capra defined and aggrandized the tropes of mythic America where individual courage invariably triumphs over collective evil. Film historian Richard Griffith speaks of Capra's \"...reliance on sentimental conversation and the ultimate benevolence of ordinary America to resolve all deep conflicts.\" \"Average America\" is visualized as \"...a tree lined street, undistinguished frame houses surrounded by modest areas of grass, a few automobiles. For certain purposes it assumed that all \"real \"Americans live in towns like this, and so great is the power of myth, even the born city-dweller is likely to believe vaguely that he too lives on this shady street, or comes from it, or is going to.\" \n\nNYU professor Leonard Quart writes:\"There would be no enduring conflicts – harmony, no matter how contrived and specious, would ultimately triumph in the last frame...In true Hollywood fashion, no Capra film would ever suggest that social change was a complex, painful act. For Capra, there would be pain and loss, but no enduring sense of tragedy would be allowed to intrude on his fabulist world.\" \n\nAlthough Capra's stature as a director had declined in the 1950s, his films underwent a revival in the 1960s:\n\nFrench film historian John Raeburn, editor of \"Cahiers du cinéma\", notes that Capra's films were unknown in France, but there too his films underwent a fresh discovery by the public. He believes the reason for his renewed popularity had to do with his themes, which he made credible \"an ideal conception of an American national character\":\nIn 1982, the American Film Institute honored Capra by giving him their AFI Life Achievement Award. The event was used to create the television film, \"The American Film Institute Salute to Frank Capra\", hosted by James Stewart. In 1986, Capra received the National Medal of Arts. During his acceptance speech for the AFI award, Capra stressed his most important values:\n\nCapra expanded on his visions in his 1971 autobiography, \"The Name Above the Title\":\n1943, Capra awarded Legion of Merit, United States Army (see section \"Why We Fight\" film series, supra).\n\n1945, Distinguished Service Medal, personally presented to Colonel Frank Capra by Army Chief of Staff and five star General George C. Marshall (see section \"Why We Fight\" film series, supra)\n\nIn 1957, Capra was awarded the George Eastman Award, given by George Eastman House for distinguished contribution to the art of film.\n\nLos Angeles Mayor Sam Yorty, by vote of the city council, declared May 12, 1962 as \"Frank Capra Day.\" George Sidney, President of the Directors Guild, stated that \"This is the first time in the history of Hollywood, that the city of Los Angeles has officially recognized a creative talent.\" At the event ceremony, director John Ford announced that Capra had also received an honorary Order of British Empire (OBE) on the recommendation of Winston Churchill. Ford suggested publicly to Capra:\n\nIn 1966, Capra was awarded the Distinguished Alumni Award from his alma mater Caltech. (see section \"Early Life\", supra)\n\nAn annual \"It's a Wonderful Life\" celebration that Capra attended in 1981, during which he said, \"This is one of the proudest moments of my life,\" was recounted in \"The New Yorker\".\n\n Capra won six Academy Awards.\n\nHe was nominated six times for Best Director and seven times for Outstanding Production/Best Picture. Out of six nominations for Best Director, Capra received the award three times. He briefly held the record for winning the most Best Director Oscars when he won for the third time in 1938, until this record was matched by John Ford in 1941, and then later surpassed by Ford in 1952. William Wyler also matched this record upon winning his third Oscar in 1959.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "11370", "url": "https://en.wikipedia.org/wiki?curid=11370", "title": "FIFA World Cup", "text": "FIFA World Cup\n\nThe FIFA World Cup, often simply called the World Cup, is an international association football competition contested by the senior men's national teams of the members of \"\" (FIFA), the sport's global governing body. The championship has been awarded every four years since the inaugural tournament in 1930, except in 1942 and 1946 when it was not held because of the Second World War. The current champion is Germany, which won its fourth title at the 2014 tournament in Brazil.\n\nThe current format of the competition involves a qualification phase, which currently takes place over the preceding three years, to determine which teams qualify for the tournament phase, which is often called the \"World Cup Finals\". 32 teams, including the automatically qualifying host nation(s), compete in the tournament phase for the title at venues within the host nation(s) over a period of about a month.\n\nThe 20 World Cup tournaments have been won by eight different national teams. Brazil have won five times, and they are the only team to have played in every tournament. The other World Cup winners are Germany and Italy, with four titles each; Argentina and inaugural winner Uruguay, with two titles each; and England, France and Spain, with one title each.\n\nThe World Cup is the most prestigious association football tournament in the world as well as the most widely viewed and followed sporting event in the world, exceeding even the Olympic Games; the cumulative audience of all matches of the 2006 FIFA World Cup was estimated to be 26.29 billion with an estimated 715.1 million people watching the final match, a ninth of the entire population of the planet.\n\nThe world's first international football match was a challenge match played in Glasgow in 1872 between Scotland and England, which ended in a 0–0 draw. The first international tournament, the inaugural edition of the British Home Championship, took place in 1884. As football grew in popularity in other parts of the world at the turn of the 20th century, it was held as a demonstration sport with no medals awarded at the 1900 and 1904 Summer Olympics (however, the IOC has retroactively upgraded their status to official events), and at the 1906 Intercalated Games.\n\nAfter FIFA was founded in 1904, it tried to arrange an international football tournament between nations outside the Olympic framework in Switzerland in 1906. These were very early days for international football, and the official history of FIFA describes the competition as having been a failure.\n\nAt the 1908 Summer Olympics in London, football became an official competition. Planned by The Football Association (FA), England's football governing body, the event was for amateur players only and was regarded suspiciously as a show rather than a competition. Great Britain (represented by the England national amateur football team) won the gold medals. They repeated the feat in 1912 in Stockholm.\n\nWith the Olympic event continuing to be contested only between amateur teams, Sir Thomas Lipton organised the Sir Thomas Lipton Trophy tournament in Turin in 1909. The Lipton tournament was a championship between individual clubs (not national teams) from different nations, each one of which represented an entire nation. The competition is sometimes described as \"The First World Cup\", and featured the most prestigious professional club sides from Italy, Germany and Switzerland, but the FA of England refused to be associated with the competition and declined the offer to send a professional team. Lipton invited West Auckland, an amateur side from County Durham, to represent England instead. West Auckland won the tournament and returned in 1911 to successfully defend their title.\n\nIn 1914, FIFA agreed to recognise the Olympic tournament as a \"world football championship for amateurs\", and took responsibility for managing the event. This paved the way for the world's first intercontinental football competition, at the 1920 Summer Olympics, contested by Egypt and 13 European teams, and won by Belgium. Uruguay won the next two Olympic football tournaments in 1924 and 1928. Those were also the first two open world championships, as 1924 was the start of FIFA's professional era.\n\nDue to the success of the Olympic football tournaments, FIFA, with President Jules Rimet as the driving force, again started looking at staging its own international tournament outside of the Olympics. On 28 May 1928, the FIFA Congress in Amsterdam decided to stage a world championship itself. With Uruguay now two-time official football world champions and to celebrate their centenary of independence in 1930, FIFA named Uruguay as the host country of the inaugural World Cup tournament.\n\nThe national associations of selected nations were invited to send a team, but the choice of Uruguay as a venue for the competition meant a long and costly trip across the Atlantic Ocean for European sides. Indeed, no European country pledged to send a team until two months before the start of the competition. Rimet eventually persuaded teams from Belgium, France, Romania, and Yugoslavia to make the trip. In total, 13 nations took part: seven from South America, four from Europe and two from North America.\n\nThe first two World Cup matches took place simultaneously on 13 July 1930, and were won by France and the USA, who defeated Mexico 4–1 and Belgium 3–0 respectively. The first goal in World Cup history was scored by Lucien Laurent of France. In the final, Uruguay defeated Argentina 4–2 in front of a crowd of 93,000 people in Montevideo, and in doing so became the first nation to win the World Cup.\n\nAfter the creation of the World Cup, the 1932 Summer Olympics, held in Los Angeles, did not plan to include football as part of the schedule due to the low popularity of the sport in the United States, as American football had been growing in popularity. FIFA and the IOC also disagreed over the status of amateur players, and so football was dropped from the Games. Olympic football returned at the 1936 Summer Olympics, but was now overshadowed by the more prestigious World Cup.\n\nThe issues facing the early World Cup tournaments were the difficulties of intercontinental travel, and war. Few South American teams were willing to travel to Europe for the 1934 and 1938 tournaments, with Brazil the only South American team to compete in both. The 1942 and 1946 competitions, which Nazi Germany and Brazil sought to host, were cancelled due to World War II and its aftermath.\n\nThe 1950 World Cup, held in Brazil, was the first to include British participants. British teams withdrew from FIFA in 1920, partly out of unwillingness to play against the countries they had been at war with, and partly as a protest against foreign influence on football, but rejoined in 1946 following FIFA's invitation. The tournament also saw the return of 1930 champions Uruguay, who had boycotted the previous two World Cups. Uruguay won the tournament again after defeating the host nation Brazil, in the match called \"Maracanazo\" (Portuguese: \"Maracanaço\").\nIn the tournaments between 1934 and 1978, 16 teams competed in each tournament, except in 1938, when Austria was absorbed into Germany after qualifying, leaving the tournament with 15 teams, and in 1950, when India, Scotland, and Turkey withdrew, leaving the tournament with 13 teams. Most of the participating nations were from Europe and South America, with a small minority from North America, Africa, Asia, and Oceania. These teams were usually defeated easily by the European and South American teams. Until 1982, the only teams from outside Europe and South America to advance out of the first round were: USA, semi-finalists in 1930; Cuba, quarter-finalists in 1938; North Korea, quarter-finalists in 1966; and Mexico, quarter-finalists in 1970.\n\nThe tournament was expanded to 24 teams in 1982, and then to 32 in 1998, also allowing more teams from Africa, Asia and North America to take part. Since then, teams from these regions have enjoyed more success, with several having reached the quarter-finals: Mexico, quarter-finalists in 1986; Cameroon, quarter-finalists in 1990; South Korea, finishing in fourth place in 2002; Senegal, along with USA, both quarter-finalists in 2002; Ghana, quarter-finalists in 2010; and Costa Rica, quarter-finalists in 2014. Nevertheless, European and South American teams continue to dominate, e.g., the quarter-finalists in 1994, 1998, and 2006 were all from Europe or South America and so were the finalists of all tournaments so far.\n\nTwo hundred teams entered the 2002 FIFA World Cup qualification rounds; 198 nations attempted to qualify for the 2006 FIFA World Cup, while a record 204 countries entered qualification for the 2010 FIFA World Cup.\n\nIn October 2013, Sepp Blatter spoke of guaranteeing the Caribbean Football Union's region a position in the World Cup. In the 25 October 2013 edition of the \"FIFA Weekly\" Blatter wrote that: \"From a purely sporting perspective, I would like to see globalisation finally taken seriously, and the African and Asian national associations accorded the status they deserve at the FIFA World Cup. It cannot be that the European and South American confederations lay claim to the majority of the berths at the World Cup.\" Those two remarks suggested to commentators that Blatter could be putting himself forward for re-election to the FIFA Presidency.\n\nFollowing the magazine's publication, Blatter's would-be opponent for the FIFA Presidency, UEFA President Michel Platini responded that he intended to extend the World Cup to 40 national associations, increasing the number of participants by eight. Platini said that he would allocate an additional berth to UEFA, two to Asia Football Confederation and Confederation of African Football, two shared between CONCACAF and CONMEBOL, and a guaranteed place for the Oceania Football Confederation. Platini was clear about why he wanted to expand the World Cup. He said: \"[The World Cup is] not based on the quality of the teams because you don't have the best 32 at the World Cup ... but it's a good compromise. ... It's a political matter so why not have more Africans? The competition is to bring all the people of all the world. If you don't give the possibility to participate, they don't improve.\"\n\nIn October 2016 FIFA president Gianni Infantino stated his support for a 48-team World Cup in 2026. On 10 January 2017, FIFA confirmed the 2026 World Cup will have 48 finalist teams.\n\nBy May 2015, the games were under a particularly dark cloud because of the 2015 FIFA corruption case, allegations and criminal charges of bribery, fraud and money laundering to corrupt the issuing of media and marketing rights (rigged bids) for FIFA games, with FIFA officials accused of taking bribes totaling more than $150 million over 24 years. In late May, the U.S. Justice Department announced a 47-count indictment with charges of racketeering, wire fraud and money laundering conspiracy against 14 people. Arrests of over a dozen FIFA officials were made since that time, particularly on May 29 and December 3.\n\nBy the end of May 2015, a total of nine FIFA officials and five executives of sports and broadcasting markets had already been charged on corruption. At the time, FIFA president Sepp Blatter announced he would relinquish his position in February 2016.\n\nOn 4 June 2015 Chuck Blazer while co-operating with the FBI and the Swiss authorities admitted that he and the other members of FIFA's then-executive committee were bribed in order to promote the 1998 and 2010 World Cups.\n\nOn 10 June 2015 Swiss authorities seized computer data from the offices of Sepp Blatter. The same day, FIFA postponed the bidding process for the 2026 FIFA World Cup in light of the allegations surrounding bribery in the awarding of the 2018 and 2022 tournaments. Then-secretary general Jérôme Valcke stated, \"Due to the situation, I think it's nonsense to start any bidding process for the time being.\"\n\nOn 28 October 2015, Blatter and FIFA VP Michel Platini, a potential candidate for presidency, were suspended for 90 days; both maintained their innocence in statements made to the news media.\n\nOn 3 December 2015 two FIFA vice-presidents were arrested on suspicion of bribery in the same Zurich hotel where seven FIFA officials had been arrested in May. An additional 16 indictments by the U.S. Department of Justice were announced on the same day.\n\nAn equivalent tournament for women's football, the FIFA Women's World Cup, was first held in 1991 in China. The women's tournament is smaller in scale and profile than the men's, but is growing; the number of entrants for the 2007 tournament was 120, more than double that of 1991.\n\nMen's football has been included in every Summer Olympic Games except 1896 and 1932. Unlike many other sports, the men's football tournament at the Olympics is not a top-level tournament, and since 1992, an under-23 tournament with each team allowed three over-age players. Women's football made its Olympic debut in 1996, and is contested between full national sides with no age restrictions.\n\nThe FIFA Confederations Cup is a tournament held one year before the World Cup at the World Cup host nation(s) as a dress rehearsal for the upcoming World Cup. It is contested by the winners of each of the six FIFA confederation championships, along with the FIFA World Cup champion and the host country.\n\nFIFA also organises international tournaments for youth football (FIFA U-20 World Cup, FIFA U-17 World Cup, FIFA U-20 Women's World Cup, FIFA U-17 Women's World Cup), club football (FIFA Club World Cup), and football variants such as futsal (FIFA Futsal World Cup) and beach soccer (FIFA Beach Soccer World Cup). The latter three do not have a women's version, although a FIFA Women's Club World Cup is planned for 2017.\n\nThe FIFA U-20 Women's World Cup is held the year before each Women's World Cup and both tournaments are awarded in a single bidding process. The U-20 tournament serves as a dress rehearsal for the larger competition, the same role as the Confederations Cup plays in the men's game.\n\nFrom 1930 to 1970, the \"Jules Rimet Trophy\" was awarded to the World Cup winning team. It was originally simply known as the \"World Cup\" or \"Coupe du Monde\", but in 1946 it was renamed after the FIFA president Jules Rimet who set up the first tournament. In 1970, Brazil's third victory in the tournament entitled them to keep the trophy permanently. However, the trophy was stolen in 1983 and has never been recovered, apparently melted down by the thieves.\n\nAfter 1970, a new trophy, known as the FIFA World Cup Trophy, was designed. The experts of FIFA, coming from seven countries, evaluated the 53 presented models, finally opting for the work of the Italian designer Silvio Gazzaniga. The new trophy is high, made of solid 18 carat (75%) gold and weighs . The base contains two layers of semi-precious malachite while the bottom side of the trophy bears the engraved year and name of each FIFA World Cup winner since 1974. The description of the trophy by Gazzaniga was: \"The lines spring out from the base, rising in spirals, stretching out to receive the world. From the remarkable dynamic tensions of the compact body of the sculpture rise the figures of two athletes at the stirring moment of victory.\"\n\nThis new trophy is not awarded to the winning nation permanently. World Cup winners retain the trophy only until the post-match celebration is finished. They are awarded a gold-plated replica rather than the solid gold original immediately afterwards.\n\nCurrently, all members (players, coaches, and managers) of the top three teams receive medals with an insignia of the World Cup Trophy; winners' (gold), runners-up' (silver), and third-place (bronze). In the 2002 edition, fourth-place medals were awarded to hosts South Korea. Before the 1978 tournament, medals were only awarded to the eleven players on the pitch at the end of the final and the third-place match. In November 2007, FIFA announced that all members of World Cup-winning squads between 1930 and 1974 were to be retroactively awarded winners' medals.\n\nSince the second World Cup in 1934, qualifying tournaments have been held to thin the field for the final tournament. They are held within the six FIFA continental zones (Africa, Asia, North and Central America and Caribbean, South America, Oceania, and Europe), overseen by their respective confederations. For each tournament, FIFA decides the number of places awarded to each of the continental zones beforehand, generally based on the relative strength of the confederations' teams.\n\nThe qualification process can start as early as almost three years before the final tournament and last over a two-year period. The formats of the qualification tournaments differ between confederations. Usually, one or two places are awarded to winners of intercontinental play-offs. For example, the winner of the Oceanian zone and the fifth-placed team from the Asian zone entered a play-off for a spot in the 2010 World Cup. From the 1938 World Cup onwards, host nations receive automatic qualification to the final tournament. This right was also granted to the defending champions between 1938 and 2002, but was withdrawn from the 2006 FIFA World Cup onward, requiring the champions to qualify. Brazil, winners in 2002, were the first defending champions to play qualifying matches.\n\nThe current final tournament has been used since 1998 and features 32 national teams competing over the course of a month in the host nation(s). There are two stages: the group stage followed by the knockout stage.\n\nIn the group stage, teams compete within eight groups of four teams each. Eight teams are seeded, including the hosts, with the other seeded teams selected using a formula based on the FIFA World Rankings and/or performances in recent World Cups, and drawn to separate groups. The other teams are assigned to different \"pots\", usually based on geographical criteria, and teams in each pot are drawn at random to the eight groups. Since 1998, constraints have been applied to the draw to ensure that no group contains more than two European teams or more than one team from any other confederation.\n\nEach group plays a round-robin tournament, in which each team is scheduled for three matches against other teams in the same group. This means that a total of six matches are played within a group. The last round of matches of each group is scheduled at the same time to preserve fairness among all four teams. The top two teams from each group advance to the knockout stage. Points are used to rank the teams within a group. Since 1994, three points have been awarded for a win, one for a draw and none for a loss (before, winners received two points).\n\nIf one considers all possible outcomes (win, draw, loss) for all six matches in a group, there are 729 (= 3) different outcome combinations possible. However a certain number (207) of these combinations lead to ties between the second and third places. In such case, the ranking among these teams is determined as follows:\n\nThe knockout stage is a single-elimination tournament in which teams play each other in one-off matches, with extra time and penalty shootouts used to decide the winner if necessary. It begins with the round of 16 (or the second round) in which the winner of each group plays against the runner-up of another group. This is followed by the quarter-finals, the semi-finals, the third-place match (contested by the losing semi-finalists), and the final.\n\nOn 10 January 2017, FIFA approved a new format, the 48-team World Cup (to accommodate more teams), which consists of 16 groups of three teams each, with two teams qualifying from each group, to form a round of 32 knockout stage, to be implemented by 2026.\n\nEarly World Cups were given to countries at meetings of FIFA's congress. The locations were controversial because South America and Europe were by far the two centres of strength in football and travel between them required three weeks by boat. The decision to hold the first World Cup in Uruguay, for example, led to only four European nations competing. The next two World Cups were both held in Europe. The decision to hold the second of these in France was disputed, as the South American countries understood that the location would alternate between the two continents. Both Argentina and Uruguay thus boycotted the 1938 FIFA World Cup.\nSince the 1958 FIFA World Cup, to avoid future boycotts or controversy, FIFA began a pattern of alternating the hosts between the Americas and Europe, which continued until the 1998 FIFA World Cup. The 2002 FIFA World Cup, hosted jointly by South Korea and Japan, was the first one held in Asia, and the only tournament with multiple hosts. South Africa became the first African nation to host the World Cup in 2010. The 2014 FIFA World Cup is hosted by Brazil, the first held in South America since Argentina 1978, and is the first occasion where consecutive World Cups are held outside Europe.\n\nThe host country is now chosen in a vote by FIFA's Council. This is done under an exhaustive ballot system. The national football association of a country desiring to host the event receives a \"Hosting Agreement\" from FIFA, which explains the steps and requirements that are expected from a strong bid. The bidding association also receives a form, the submission of which represents the official confirmation of the candidacy. After this, a FIFA designated group of inspectors visit the country to identify that the country meets the requirements needed to host the event and a report on the country is produced. The decision on who will host the World Cup is usually made six or seven years in advance of the tournament. However, there have been occasions where the hosts of multiple future tournaments were announced at the same time, as was the case for the 2018 and 2022 World Cups, which were awarded to Russia and Qatar respectively.\n\nFor the 2010 and 2014 World Cups, the final tournament is rotated between confederations, allowing only countries from the chosen confederation (Africa in 2010, South America in 2014) to bid to host the tournament. The rotation policy was introduced after the controversy surrounding Germany's victory over South Africa in the vote to host the 2006 tournament. However, the policy of continental rotation will not continue beyond 2014, so any country, except those belonging to confederations that hosted the two preceding tournaments, can apply as hosts for World Cups starting from 2018. This is partly to avoid a similar scenario to the bidding process for the 2014 tournament, where Brazil was the only official bidder.\n\nSix of the eight champions have won one of their titles while playing in their own homeland, the exceptions being Brazil, who finished as runners-up after losing the deciding match on home soil in 1950 and lost their semifinal against Germany in 2014, and Spain, which reached the second round on home soil in 1982. England (1966) and France (1998) won their only titles while playing as host nations. Uruguay (1930), Italy (1934) and Argentina (1978) won their first titles as host nations but have gone on to win again, while Germany (1974) won their second title on home soil.\n\nOther nations have also been successful when hosting the tournament. Switzerland (quarter-finals 1954), Sweden (runners-up in 1958), Chile (third place in 1962), South Korea (fourth place in 2002), and Mexico (quarter-finals in 1970 and 1986) all have their best results when serving as hosts. So far, South Africa (2010) has been the only host nation to fail to advance beyond the first round.\n\n\nThe World Cup was first televised in 1954 and is now the most widely viewed and followed sporting event in the world. The cumulative audience of all matches of the 2006 World Cup is estimated to be 26.29 billion. 715.1 million individuals watched the final match of this tournament (a ninth of the entire population of the planet). The 2006 World Cup draw, which decided the distribution of teams into groups, was watched by 300 million viewers. The World Cup attracts many sponsors such as Coca-Cola, McDonald's and Adidas. For these companies and many more, being a sponsor strongly impacts their global brands. Host countries typically experience a multimillion-dollar revenue increase from the month-long event. It was predicted that Brazil will bring in more than $11 billion in revenue for the 2014 World Cup.\n\nEach FIFA World Cup since 1966 has its own mascot or logo. \"World Cup Willie\", the mascot for the 1966 competition, was the first World Cup mascot. Recent World Cups have also featured official match balls specially designed for each World Cup.\n\nThe World Cup even has a statistically significant effect on birth rates, the male/female sex ratio of newborns, and heart attacks in nations whose national teams are competing. Hosting the World Cup or a home team's win tends to increase male births and total birth rate, and heart attacks are more common when home teams are on the field.\n\n\nIn all, 77 nations have played in at least one World Cup. Of these, eight national teams have won the World Cup, and they have added stars to their badges, with each star representing a World Cup victory. (Uruguay, however, choose to display four stars on their badge, representing their two gold medals at the 1924 and 1928 Summer Olympics and their two World Cup titles in 1930 and 1950.)\n\nWith five titles, Brazil are the most successful World Cup team and also the only nation to have played in every World Cup (20) to date. Brazil were also the first team to win the World Cup for the third (1970), fourth (1994) and fifth (2002) time. Italy (1934 and 1938) and Brazil (1958 and 1962) are the only nations to have won consecutive titles. West Germany (1982–1990) and Brazil (1994–2002) are the only nations to appear in three consecutive World Cup finals. Germany has made the most top-four finishes (13), medals (12), as well as the most finals (8).\n\nTo date, the final of the World Cup has only been contested by teams from the UEFA (Europe) and CONMEBOL (South America) confederations. European nations have won eleven titles, while South American have won nine. Only two teams from outside these two continents have ever reached the semi-finals of the competition: USA (North, Central America and Caribbean) in 1930 and South Korea (Asia) in 2002. The best result of an African team is reaching the quarter-finals: Cameroon in 1990, Senegal in 2002 and Ghana in 2010. Only one Oceanian qualifier, Australia in 2006, has advanced to the second round.\n\nBrazil, Argentina, Spain and Germany are the only teams to win a World Cup outside their continental confederation; Brazil came out victorious in Europe (1958), North America (1970 and 1994) and Asia (2002), Argentina won a World Cup in North America in 1986, while Spain won a World Cup in Africa in 2010. Germany was the first European team to win in South America in 2014. Only on four occasions have consecutive World Cups been won by teams from the same continent, and currently it is the first time with three champions in a row from the same continental confederation. Italy and Brazil successfully defended their titles in 1938 and 1962 respectively, while Italy's triumph in 2006 has been followed by Spain's in 2010 and Germany's in 2014. Currently, it is also the first time that one of the currently winning continents (Europe) is ahead of the other (South America) by two championships.\n\nAt the end of each World Cup, awards are presented to the players and teams for accomplishments other than their final team positions in the tournament. There are currently six awards:\nAn \"All-Star Team\" consisting of the best players of the tournament has also been announced for each tournament since 1998.\n\nTwo players share the record for playing in the most World Cups; Mexico's Antonio Carbajal (1950–1966) and Germany's Lothar Matthäus (1982–1998) both played in five tournaments. Matthäus has played the most World Cup matches overall, with 25 appearances. Brazil's Djalma Santos (1954–1962), West Germany's Franz Beckenbauer (1966–1974) and Germany's Philipp Lahm (2006–2014) are the only players to be named to three Finals All-Star Teams.\n\nMiroslav Klose of Germany (2002–2014) is the all-time top scorer at the finals, with 16 goals. He broke Ronaldo of Brazil's record of 15 goals (1998–2006) during 2014 semi-final match against Brazil. West Germany's Gerd Müller (1970–1974) is third, with 14 goals. The fourth placed goalscorer, France's Just Fontaine, holds the record for the most goals scored in a single World Cup; all his 13 goals were scored in the 1958 tournament.\n\nIn November 2007, FIFA announced that all members of World Cup-winning squads between 1930 and 1974 were to be retroactively awarded winners' medals. This made Brazil's Pelé the only player to have won three World Cup winners' medals (1958, 1962, and 1970, although he did not play in the 1962 final due to injury), with 20 other players who have won two winners' medals. Seven players have collected all three types of World Cup medals (winners', runner- ups', and third-place); five players were from West Germany's squad of 1966–1974 including Franz Beckenbauer, Jürgen Grabowski, Horst-Dieter Höttges, Sepp Maier and Wolfgang Overath (1966–1974), Italy's Franco Baresi (1982, 1990, 1994) and the most recent has been Miroslav Klose of Germany (2002–2014) with four consecutive medals.\n\nBrazil's Mário Zagallo and West Germany's Franz Beckenbauer are the only people to date to win the World Cup as both player and head coach. Zagallo won in 1958 and 1962 as a player and in 1970 as head coach. Beckenbauer won in 1974 as captain and in 1990 as head coach. Italy's Vittorio Pozzo is the only head coach to ever win two World Cups (1934 and 1938). All World Cup winning head coaches were natives of the country they coached to victory.\n\nAmong the national teams, Germany has played the most World Cup matches (106) and appeared in the most finals (8), semi-finals (13), quarter-finals (16) as well as scoring the most World Cup goals (224), while Brazil has appeared in the most World Cups (20). The two teams have played each other twice in the World Cup, in the 2002 final and in the 2014 semi-final.\n\n\n"}
{"id": "11371", "url": "https://en.wikipedia.org/wiki?curid=11371", "title": "Quintus Fabius Maximus Verrucosus", "text": "Quintus Fabius Maximus Verrucosus\n\nQuintus Fabius Maximus Verrucosus, surnamed Cunctator ( 280 BC – 203 BC), was a Roman statesman and general of the third century BC. He was consul five times (233, 228, 215, 214, and 209 BC) and was appointed dictator in 221 and 217 BC. He was censor in 230 BC. His agnomen, \"Cunctator\", usually translated as \"the delayer\", refers to the strategy that he employed against Hannibal's forces during the Second Punic War. Facing an outstanding commander with superior numbers, he pursued a then novel strategy of targeting the enemy's supply lines, and accepting only smaller engagements on favourable ground, rather than risking his entire army on direct confrontation with Hannibal himself. As a result, he is regarded as the originator of many tactics used in guerrilla warfare.\n\nBorn at Rome \"circa\" 280 BC, Fabius was a descendant of the ancient patrician Fabia gens. He was the son or grandson of Quintus Fabius Maximus Gurges, three times consul and \"princeps senatus\", and grandson or great-grandson of Quintus Fabius Maximus Rullianus, a hero of the Samnite Wars, who like Verrucosus held five consulships, as well as the offices of dictator and censor. Many earlier ancestors had also been consuls. His cognomen, \"Verrucosus\", or \"warty\", used to distinguish him from other members of his family, derived from a wart on his upper lip.\n\nAccording to Plutarch, Fabius possessed a mild temper and slowness in speaking. As a child, he had difficulties in learning, engaged in sports with other children cautiously and appeared submissive in his interactions with others. All the above were perceived by those who knew him superficially to be signs of inferiority. However, according to Plutarch, these traits proceeded from stability, greatness of mind, and lion-likeness of temper. By the time he reached adulthood and was roused by active life, his virtues exerted themselves; consequently, his lack of energy displayed during his earlier years was revealed as a result of a lack of passion and his slowness was recognised as a sign of prudence and firmness.\n\nWhile still a youth in 265 BC, Fabius was consecrated an augur. It is unknown whether he participated in the First Punic War, fought between the Roman Republic and Carthage from 264 to 241 BC, or what his role might have been. Fabius' political career began in the years following that war. He was probably quaestor in 237 or 236 BC, and curule aedile about 235. During his first consulship, in 233 BC, Fabius was awarded a triumph for his victory over the Ligurians, whom he defeated and drove into the Alps. He was censor in 230, then consul a second time in 228.\n\nAccording to Livy, in 218 BC Fabius took part in an embassy to Carthage, sent to demand redress for the capture of the supposedly neutral town of Saguntum in Spain. After the delegation had received the Carthaginians' reply, it was Fabius himself who, addressing the Carthaginian senate, issued a formal declaration of war between Carthage and the Roman Republic. However, Cassius Dio, followed by Zonaras, calls the ambassador \"Marcus Fabius\", suggesting that it was his cousin, Marcus Fabius Buteo, who issued the declaration of war against the Carthaginians.\n\nWhen the Consul Gaius Flaminius was killed during the disastrous Roman defeat at the Battle of Lake Trasimene, panic swept Rome. With Consular armies destroyed in two major battles, and Hannibal approaching Rome's gates, the Romans feared the imminent destruction of their city. The Roman Senate decided to appoint a dictator, and chose Fabius for the role, in part due to his advanced age and experience. As Dictator, he did not get to appoint his own Master of the Horse; instead, the Romans chose a political enemy, Marcus Minucius. Then Fabius quickly sought to calm the Roman people by asserting himself as a strong Dictator at the moment of what was perceived to be the worst crisis in Roman history. He asked the Senate to allow him to ride on horseback, which Dictators were never allowed to do. He then caused himself to be accompanied by the full complement of twenty-four lictors, and ordered the surviving Consul, Gnaeus Servilius Geminus, to dismiss his lictors (in essence, surrendering his office), and to present himself before Fabius as a private citizen.\n\nPlutarch tells us that Fabius believed that the disaster at Lake Trasimene was due, in part, to the fact that the gods had become neglected. Before that battle, a series of omens had been witnessed, including a series of lightning bolts, which Fabius had believed were warnings from the gods. He had warned Flaminius of this, but Flaminius had ignored the warnings. And so Fabius, as Dictator, next sought to please the gods. He ordered a massive sacrifice of the whole product of the next harvest season throughout Italy, in particular that of cows, goats, swine, and sheep. In addition, he ordered that musical festivities be celebrated, and then told his fellow citizens to each spend a precise sum of 333 sestertii and 333 denarii. Plutarch isn't sure exactly how Fabius came up with this number, although he believes it was to honor the perfection of the number three, as it is the first of the odd numbers, and one of the first of the prime numbers. It is not known if Fabius truly believed that these actions had won the gods over to the Roman side, although the actions probably did (as intended) convince the average Roman that the gods had finally been won over.\n\nFabius was well aware of the Carthaginian military superiority, and so refused to meet Hannibal in a pitched battle. Instead, he kept his troops close to Hannibal, hoping to exhaust him in a long war of attrition. Fabius was able to harass the Carthaginian foraging parties, limiting Hannibal's ability to wreak destruction, while conserving his own military force. The delaying tactics involved not directly engaging Hannibal, while also exercising a \"scorched earth\" practice to prevent Hannibal's forces from obtaining grain and other resources.\n\nThe Romans were unimpressed with this defensive strategy and at first gave Fabius his epithet Cunctator as an insult. The strategy was in part ruined because of a lack of unity in the command of the Roman army, since Fabius' Master of the Horse, Minucius, was a political enemy of Fabius. At one point, Fabius was called by the priests to assist with certain sacrifices, and as such, Fabius left the command of the army in the hands of Minucius during his absence. Fabius had told Minucius not to attack Hannibal in his absence, but Minucius disobeyed and attacked anyway. The attack, though of no strategic value, resulted in the retreat of several enemy units, and so the Roman people, desperate for good news, believed Minucius to be a hero. On hearing of this, Fabius became enraged, and, as Dictator, could have ordered Minucius' execution for his disobedience. One of the Plebeian Tribunes (chief representatives of the people) for the year, Metilius, was a partisan of Minucius, and as such he sought to use his power to help Minucius. The Plebeian Tribunes were the only magistrates independent of the Dictator, and so with his protection, Minucius was relatively safe. Plutarch states that Metilius \"boldly applied himself to the people in the behalf of Minucius\", and had Minucius granted powers equivalent to those of Fabius. By this, Plutarch probably means that as a Plebeian Tribune, Metilius had the Plebeian Council, a popular assembly which only Tribunes could preside over, grant Minucius quasi-dictatorial powers.\n\nFabius did not attempt to fight the promotion of Minucius, but rather decided to wait until Minucius' rashness caused him to run headlong into some disaster. He realized what would happen when Minucius was defeated in battle by Hannibal. Fabius, we are told, reminded Minucius that it was Hannibal, and not he, who was the enemy. Minucius proposed that they share the joint control of the army, with command rotating between the two every other day. Fabius rejected this, and instead let Minucius command half of the army, while he commanded the other half. Minucius openly claimed that Fabius was cowardly because he failed to confront the Carthaginian forces. Near the present-day town of Larino in the Molise (then called Larinum), Hannibal had taken up position in a town called Gerione. In the valley between Larino and Gerione, Minucius decided to make a broad frontal attack on Hannibal's troops. Several thousand men were involved on either side. It appeared that the Roman troops were winning, but Hannibal had set a trap. Soon the Roman troops were being slaughtered. Upon seeing the ambush of Minucius' army, Fabius cried \"O Hercules! how much sooner than I expected, though later than he seemed to desire, hath Minucius destroyed himself!\" On ordering his army to join the battle and rescue their fellow Romans, Fabius exclaimed \"We must make haste to rescue Minucius, who is a valiant man, and a lover of his country.\"\n\nFabius rushed to his co-commander's assistance and Hannibal's forces immediately retreated. After the battle, there was some feeling that there would be conflict between Minucius and Fabius; however, the younger soldier marched his men to Fabius' encampment and is reported to have said, \"My father gave me life. Today you saved my life. You are my second father. I recognize your superior abilities as a commander.\" It was only after Fabius had saved him from an attack by Hannibal that Minucius placed himself under Fabius' command. When Fabius' term as Dictator ended, Consular government was restored, and Gnaeus Servilius Geminus and Marcus Atilius Regulus assumed the Consulship for the remainder of the year.\n\nThe once looked down upon tactics employed by Fabius came then to be respected. It is said, asserts Plutarch, that even Hannibal acknowledged and feared the Fabian strategy and the Roman inexhaustible manpower. As a matter of fact, after Fabius lured him away from Apulia into the Bruttian territory and then proceeded to besiege Tarentum by treachery in 209 B.C., Hannibal commented, \"It seems that the Romans have found another Hannibal, for we have lost Tarentum in the same way that we took it.\"\n\nShortly after Fabius had laid down his dictatorship, Gaius Terentius Varro was elected as a Consul. He rallied the people, through the Roman assemblies, and won their support for his plan to abandon Fabius' strategy, and engage Hannibal directly. Varro's rashness did not surprise Fabius, but when Fabius learned of the size of the army (eighty-eight thousand soldiers) that Varro had raised, he became quite concerned. Unlike the losses that had been suffered by Minucius, a major loss by Varro had the potential to kill so many soldiers that Rome might have had no further resources with which to continue the war. Fabius had warned the other Consul for the year, Aemilius Paullus, to make sure that Varro remained unable to directly engage Hannibal. According to Plutarch, Paullus replied to Fabius that he feared the votes in Rome more than Hannibal's army.\n\nWhen word reached Rome of the disastrous Roman defeat under Varro and Paullus at the Battle of Cannae, the Senate and the People of Rome turned to Fabius for guidance. They had believed his strategy to be flawed before, but now they thought him to be as wise as the gods. He walked the streets of Rome, assured as to eventual Roman victory, in an attempt to comfort his fellow Romans. Without his support, the senate might have remained too frightened to even meet. He placed guards at the gates of the city to stop the frightened Romans from fleeing, and regulated mourning activities. He set times and places for this mourning, and ordered that each family perform such observances within their own private walls, and that the mourning should be complete within a month; following the completion of these mourning rituals, the entire city was purified of its blood-guilt in the deaths. This decree effectively outlawed competitive outdoor mourning, which could have had a devastating psychological impact on the survivors.\n\n\"Cunctator\" became an honorific title, and his delaying tactic was followed for the rest of the war. Fabius' own military success was small, aside from the reconquest of Tarentum in 209 BC. For this victory, Plutarch tells us, he was awarded a second triumph that was even more splendid than the first. When Marcus Livius Macatus, the governor of Tarentum, claimed the merit of recovering the town, Fabius rejoined, \"Certainly, had you not lost it, I would have never retaken it.\" After serving as Dictator, he served as a Consul twice more (in 215 BC and 214 BC), and for a fifth time in 209 BC. He was also Chief Augur (at a very young age) and Pontifex, but never Pontifex Maximus according to Gaius Stern (citing Livy on Fabius). The holding of seats in the two highest colleges was not repeated until either Julius Caesar or possibly Sulla.\n\nIn the senate, he opposed the young and ambitious Scipio Africanus, who wanted to carry the war to Africa. Fabius continued to argue that confronting Hannibal directly was too dangerous. Scipio planned to take Roman forces to Carthage itself and force Hannibal to return to Africa to defend the city. Scipio was eventually given limited approval, despite continuous opposition from Fabius, who blocked levies and restricted Scipio's access to troops. Fabius wished to ensure that sufficient forces remained to defend Roman territory if Scipio was defeated. Fabius became gravely ill and died in 203 BC, shortly after Hannibal's army left Italy, and before the eventual Roman victory over Hannibal at the Battle of Zama won by Scipio.\n\nPart of his eulogy is preserved on a fragment, which praised his delaying strategy in his altercations with Hannibal during the Second Punic War. The inscription reads as follows: \"...[as censor] he conducted the first revision of the senate membership and held committal elections in the consulship of Marcus Junius Pera and Marcus Barbula; he besieged and recaptured Tarentum and the strong-hold of Hannibal, and [obtained enormous booty?]; he won surpassing glory by his military [exploits?].\" \n\nLater, he became a legendary figure and the model of a tough, courageous Roman, and was bestowed the honorific title, \"The Shield of Rome\" (similar to Marcus Claudius Marcellus being named the \"Sword of Rome\"). According to Ennius, \"unus homo nobis cunctando restituit rem\" – \"one man, by delaying, restored the state to us.\" Virgil, in the Aeneid, has Aeneas' father Anchises mention Fabius Maximus while in Hades as the greatest of the many great Fabii, quoting the same line. While Hannibal is mentioned in the company of history's greatest generals, military professionals have bestowed Fabius' name on an entire strategic doctrine known as \"Fabian strategy\", and George Washington has been called \"the American Fabius.\"\n\nAccording to its own ancient legend, the Roman princely family of Massimo descends from Fabius Maximus.\n\n\n\n\n"}
{"id": "11376", "url": "https://en.wikipedia.org/wiki?curid=11376", "title": "Floating-point arithmetic", "text": "Floating-point arithmetic\n\nIn computing, floating-point arithmetic is arithmetic using formulaic representation of real numbers as an approximation so as to support a trade-off between range and precision. For this reason, floating-point computation is often found in systems which include very small and very large real numbers, that of which require fast processing times. A number is, in general, represented approximately to a fixed number of significant digits (the significand) and scaled using an exponent in some fixed base; the base for the scaling is normally two, ten, or sixteen. A number that can be represented exactly is of the following form:\nwhere significand is an integer (i.e., in Z), base is an integer greater than or equal to two, and exponent is also an integer.\nFor example:\n\nThe term \"floating point\" refers to the fact that a number's radix point (\"decimal point\", or, more commonly in computers, \"binary point\") can \"float\"; that is, it can be placed anywhere relative to the significant digits of the number. This position is indicated as the exponent component, and thus the floating-point representation can be thought of as a kind of scientific notation.\n\nA floating-point system can be used to represent, with a fixed number of digits, numbers of different orders of magnitude: e.g. the distance between galaxies or the diameter of an atomic nucleus can be expressed with the same unit of length. The result of this dynamic range is that the numbers that can be represented are not uniformly spaced; the difference between two consecutive representable numbers grows with the chosen scale.\n\nOver the years, a variety of floating-point representations have been used in computers. However, since the 1990s, the most commonly encountered representation is that defined by the IEEE 754 Standard.\n\nThe speed of floating-point operations, commonly measured in terms of FLOPS, is an important characteristic of a computer system, especially for applications that involve intensive mathematical calculations.\n\nA floating-point unit (FPU, colloquially a math coprocessor) is a part of a computer system specially designed to carry out operations on floating-point numbers.\n\nA number representation specifies some way of encoding a number, usually as a string of digits.\n\nThere are several mechanisms by which strings of digits can represent numbers. In common mathematical notation, the digit string can be of any length, and the location of the radix point is indicated by placing an explicit \"point\" character (dot or comma) there. If the radix point is not specified, then the string implicitly represents an integer and the unstated radix point would be off the right-hand end of the string, next to the least significant digit. In fixed-point systems, a position in the string is specified for the radix point. So a fixed-point scheme might be to use a string of 8 decimal digits with the decimal point in the middle, whereby \"00012345\" would represent 0001.2345.\n\nIn scientific notation, the given number is scaled by a power of 10, so that it lies within a certain range—typically between 1 and 10, with the radix point appearing immediately after the first digit. The scaling factor, as a power of ten, is then indicated separately at the end of the number. For example, the orbital period of Jupiter's moon Io is seconds, a value that would be represented in standard-form scientific notation as seconds.\n\nFloating-point representation is similar in concept to scientific notation. Logically, a floating-point number consists of:\n\nTo derive the value of the floating-point number, the \"significand\" is multiplied by the \"base\" raised to the power of the \"exponent\", equivalent to shifting the radix point from its implied position by a number of places equal to the value of the exponent—to the right if the exponent is positive or to the left if the exponent is negative.\n\nUsing base-10 (the familiar decimal notation) as an example, the number , which has ten decimal digits of precision, is represented as the significand 1528535047 together with 5 as the exponent. To determine the actual value, a decimal point is placed after the first digit of the significand and the result is multiplied by to give , or . In storing such a number, the base (10) need not be stored, since it will be the same for the entire range of supported numbers, and can thus be inferred.\n\nSymbolically, this final value is:\nwhere formula_4 is the significand (ignoring any implied decimal point), formula_5 is the precision (the number of digits in the significand), formula_6 is the base (in our example, this is the number \"ten\"), and formula_7 is the exponent.\n\nHistorically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal), and other less common varieties, such as base sixteen (hexadecimal notation), and even base three (see Setun).\n\nA floating-point number is a rational number, because it can be represented as one integer divided by another; for example is (145/100)*1000 or /100. The base determines the fractions that can be represented; for instance, 1/5 cannot be represented exactly as a floating-point number using a binary base, but 1/5 can be represented exactly using a decimal base (, or ). However, 1/3 cannot be represented exactly by either binary (0.010101...) or decimal (0.333...), but in base 3, it is trivial (0.1 or 1×3) . The occasions on which infinite expansions occur depend on the base and its prime factors, as described in the article on Positional Notation.\n\nThe way in which the significand (including its sign) and exponent are stored in a computer is implementation-dependent. The common IEEE formats are described in detail later and elsewhere, but as an example, in the binary single-precision (32-bit) floating-point representation, formula_8, and so the significand is a string of 24 bits. For instance, the number π's first 33 bits are:\nIf the leftmost bit is considered the 1st bit, then the 24th bit is zero and the 25th bit is 1; thus, in rounding to 24 bits, let's attribute to the 24th bit the value of the 25th, yielding:\n\nWhen this is stored using the IEEE 754 encoding, this becomes the significand formula_4 with formula_12 (where formula_4 is assumed to have a binary point to the right of the first bit) after a left-adjustment (or \"normalization\") during which leading or trailing zeros are truncated should there be any, which is unnecessary in this case; as a result of this normalization, the first bit of a non-zero binary significand is always 1, so it need not be stored, saving one bit of storage. In other words, from this representation, π is calculated as follows:\nwhere formula_15 is the normalized significand's \"n\"th bit from the left, where counting starts with 1. Normalization, which is reversed by the addition of the implicit one, can be thought of as a form of compression; it allows a binary significand to be compressed into a field one bit shorter than the maximum precision, at the expense of extra processing.\n\nThe floating-point representation is by far the most common way of representing in computers an approximation to real numbers. However, there are alternatives:\n\nIn 1914, Leonardo Torres y Quevedo designed an electro-mechanical version of Charles Babbage's Analytical Engine, and included floating-point arithmetic.\nIn 1938, Konrad Zuse of Berlin completed the Z1, the first binary, programmable mechanical computer; it uses a 24-bit binary floating-point number representation with a 7-bit signed exponent, a 17-bit significand (including one implicit bit), and a sign bit. The more reliable relay-based Z3, completed in 1941, has representations for both positive and negative infinities; in particular, it implements defined operations with infinity, such as formula_19, and it stops on undefined operations, such as formula_20.\nZuse also proposed, but did not complete, carefully rounded floating-point arithmetic that includes formula_21 and NaN representations, anticipating features of the IEEE Standard by four decades. In contrast, von Neumann recommended against floating-point numbers for the 1951 IAS machine, arguing that fixed-point arithmetic is preferable.\n\nThe first \"commercial\" computer with floating-point hardware was Zuse's Z4 computer, designed in 1942–1945. In 1946, Bell Laboratories introduced the Mark V, which implements decimal floating-point numbers.\n\nThe Pilot ACE has binary floating-point arithmetic, and it became operational in 1950 at National Physical Laboratory, UK. Thirty-three were later sold commercially as the English Electric DEUCE. The arithmetic is actually implemented in software, but with a one megahertz clock rate, the speed of floating-point and fixed-point operations in this machine were initially faster than those of many competing computers.\n\nThe mass-produced IBM 704 followed in 1954; it introduced the use of a biased exponent. For many decades after that, floating-point hardware was typically an optional feature, and computers that had it were said to be \"scientific computers\", or to have \"scientific computation\" (SC) capability (see also Extensions for Scientific Computation (XSC)). It was not until the launch of the Intel i486 in 1989 that \"general-purpose\" personal computers had floating-point capability in hardware as a standard feature.\n\nThe UNIVAC 1100/2200 series, introduced in 1962, supports two floating-point representations:\n\nThe IBM 7094, also introduced in 1962, supports single-precision and double-precision representations, but with no relation to the UNIVAC's representations. Indeed, in 1964, IBM introduced proprietary hexadecimal floating-point representations in its System/360 mainframes; these same representations are still available for use in modern z/Architecture systems. However, in 1998, IBM included IEEE-compatible binary floating-point arithmetic to its mainframes; in 2005, IBM also added IEEE-compatible decimal floating-point arithmetic.\n\nInitially, computers used many different representations for floating-point numbers. The lack of standardization at the mainframe level was an ongoing problem by the early 1970s for those writing and maintaining higher-level source code; these manufacturer floating-point standards differed in the word sizes, the representations, and the rounding behavior and general accuracy of operations. Floating-point compatibility across multiple computing systems was in desperate need of standardization by the early 1980s, leading to the creation of the IEEE-754 standard once the 32-bit (or 64-bit) word had become commonplace. This standard was significantly based on a proposal from Intel, which was designing the i8087 numerical coprocessor; Motorola, which was designing the 68000 around the same time, gave significant input as well.\n\nIn 1989, mathematician and computer scientist William Kahan was honored with the Turing Award for being the primary architect behind this proposal; he was aided by his student (Jerome Coonen) and a visiting professor (Harold Stone).\n\nAmong the x86 innovations are these:\n\nA floating-point number consists of two fixed-point components, whose range depends exclusively on the number of bits or digits in their representation. Whereas components linearly depend on their range, the floating-point range linearly depends on the significant range and exponentially on the range of exponent component, which attaches outstandingly wider range to the number.\n\nOn a typical computer system, a 'double precision' (64-bit) binary floating-point number has a coefficient of 53 bits (one of which is implied), an exponent of 11 bits, and one sign bit. Positive floating-point numbers in this format have an approximate range of 10 to 10, because the range of the exponent is [−1022,1023] and 308 is approximately log(2). The complete range of the format is from about −10 through +10 (see IEEE 754).\n\nThe number of normalized floating-point numbers in a system (\"B\", \"P\", \"L\", \"U\") where\n\n\nis formula_22.\n\nThere is a smallest positive normalized floating-point number,\nUnderflow level = UFL = formula_23\nwhich has a 1 as the leading digit and 0 for the remaining digits of the significand, and the smallest possible value for the exponent.\n\nThere is a largest floating-point number,\nOverflow level = OFL = formula_24 which has \"B\" − 1 as the value for each digit of the significand and the largest possible value for the exponent.\n\nIn addition there are representable values strictly between −UFL and UFL. Namely, positive and negative zeros, as well as denormalized numbers.\n\nThe IEEE has standardized the computer representation for binary floating-point numbers in IEEE 754 (a.k.a. IEC 60559). This standard is followed by almost all modern machines. IBM mainframes support IBM's own hexadecimal floating point format and IEEE 754-2008 decimal floating point in addition to the IEEE 754 binary format. The Cray T90 series had an IEEE version, but the SV1 still uses Cray floating-point format.\n\nThe standard provides for many closely related formats, differing in only a few details. Five of these formats are called \"basic formats\" and others are termed \"extended formats\"; three of these are especially widely used in computer hardware and languages:\n\nIncreasing the precision of the floating point representation generally reduces the amount of accumulated round-off error caused by intermediate calculations.\nLess common IEEE formats include:\nAny integer with absolute value less than 2 can be exactly represented in the single precision format, and any integer with absolute value less than 2 can be exactly represented in the double precision format. Furthermore, a wide range of powers of 2 times such a number can be represented. These properties are sometimes used for purely integer data, to get 53-bit integers on platforms that have double precision floats but only 32-bit integers.\n\nThe standard specifies some special values, and their representation: positive infinity (+∞), negative infinity (−∞), a negative zero (−0) distinct from ordinary (\"positive\") zero, and \"not a number\" values (NaNs).\n\nComparison of floating-point numbers, as defined by the IEEE standard, is a bit different from usual integer comparison. Negative and positive zero compare equal, and every NaN compares unequal to every value, including itself. All values except NaN are strictly smaller than +∞ and strictly greater than −∞. Finite floating-point numbers are ordered in the same way as their values (in the set of real numbers).\n\nA project for revising the IEEE 754 standard was started in 2000 (see IEEE 754 revision); it was completed and approved in June 2008. It includes decimal floating-point formats and a 16-bit floating-point format (\"binary16\"). binary16 has the same structure and rules as the older formats, with 1 sign bit, 5 exponent bits and 10 trailing significand bits. It is being used in the NVIDIA Cg graphics language, and in the openEXR standard.\n\nFloating-point numbers are typically packed into a computer datum as the sign bit, the exponent field, and the significand or mantissa, from left to right. For the IEEE 754 binary formats (basic and extended) which have extant hardware implementations, they are apportioned as follows:\n\nWhile the exponent can be positive or negative, in binary formats it is stored as an unsigned number that has a fixed \"bias\" added to it. Values of all 0s in this field are reserved for the zeros and subnormal numbers; values of all 1s are reserved for the infinities and NaNs. The exponent range for normalized numbers is [−126, 127] for single precision, [−1022, 1023] for double, or [−16382, 16383] for quad. Normalized numbers exclude subnormal values, zeros, infinities, and NaNs.\n\nIn the IEEE binary interchange formats the leading 1 bit of a normalized significand is not actually stored in the computer datum. It is called the \"hidden\" or \"implicit\" bit. Because of this, single precision format actually has a significand with 24 bits of precision, double precision format has 53, and quad has 113.\n\nFor example, it was shown above that π, rounded to 24 bits of precision, has:\nThe sum of the exponent bias (127) and the exponent (1) is 128, so this is represented in single precision format as\n\nIf one graphs the floating-point value of a bit pattern (\"x\"-axis is bit pattern, considered as integers, \"y\"-axis the value of the floating-point number; assume positive), one obtains a piecewise linear approximation of a shifted and scaled exponential function with base 2, formula_25 (hence actually formula_26). Conversely, given a real number, if one takes the floating-point representation and considers it as an integer, one gets a piecewise linear approximation of a shifted and scaled base 2 logarithm, formula_27 (hence actually formula_28), as shown at right.\n\nThis interpretation is useful for visualizing how the values of floating-point numbers vary with the representation, and allow for certain efficient approximations of floating-point operations by integer operations and bit shifts. For example, reinterpreting a float as an integer, taking the negative (or rather subtracting from a fixed number, due to bias and implicit 1), then reinterpreting as a float yields the reciprocal. Explicitly, ignoring significand, taking the reciprocal is just taking the additive inverse of the (unbiased) exponent, since the exponent of the reciprocal is the negative of the original exponent. (Hence actually subtracting the exponent from twice the bias, which corresponds to unbiasing, taking negative, and then biasing.) For the significand, near 1 the reciprocal is approximately linear: formula_29 (since the derivative is formula_30; this is the first term of the Taylor series), and thus for the significand as well, taking the negative (or rather subtracting from a fixed number to handle the implicit 1) is approximately taking the reciprocal.\n\nMore significantly, bit shifting allows one to compute the square (shift left by 1) or take the square root (shift right by 1). This leads to approximate computations of the square root; combined with the previous technique for taking the inverse, this allows the fast inverse square root computation, which was important in graphics processing in the late 1980s and 1990s. This can be exploited in some other applications, such as volume ramping in digital sound processing.\n\nConcretely, each time the exponent increments, the value doubles (hence grows exponentially), while each time the significand increments (for a given exponent), the value increases by formula_31 (hence grows linearly, with slope equal to the actual (unbiased) value of the exponent). This holds even for the last step from a given exponent, where the significand overflows into the exponent: with the implicit 1, the number after 1.11...1 is 2.0 (regardless of the exponent), i.e., an increment of the exponent:\nThus as a graph it is linear pieces (as the significand grows for a given exponent) connecting the evenly spaced powers of two (when the significand is 0), with each linear piece having twice the slope of the previous: it is approximately a scaled and shifted exponential formula_32. Each piece takes the same horizontal space, but twice the vertical space of the last. Because the exponent is convex up, the value is always \"greater\" than or equal to the actual (shifted and scaled) exponential curve through the points with significand 0; by a slightly different shift one can more closely approximate an exponential, sometimes overestimating, sometimes underestimating. Conversely, interpreting a floating-point number as an integer gives an approximate shifted and scaled logarithm, with each piece having half the slope of the last, taking the same vertical space but twice the horizontal space. Since the logarithm is convex down, the approximation is always \"less\" than the corresponding logarithmic curve; again, a different choice of scale and shift (as at above right) yields a closer approximation.\n\nIn the IEEE 754 standard, zero is signed, meaning that there exist both a \"positive zero\" (+0) and a \"negative zero\" (−0). In most run-time environments, positive zero is usually printed as \"0\" and the negative zero as \"-0\". The two values behave as equal in numerical comparisons, but some operations return different results for +0 and −0. For instance, 1/(−0) returns negative infinity, while 1/+0 returns positive infinity (so that the identity 1/(1/±∞) = ±∞ is maintained). Other common functions with a discontinuity at \"x\"=0 which might treat +0 and −0 differently include log(\"x\"), signum(\"x\"), and the principal square root of for any negative number \"y\". As with any approximation scheme, operations involving \"negative zero\" can occasionally cause confusion. For example, in IEEE 754, \"x\" = \"y\" does not always imply 1/\"x\" = 1/\"y\", as 0 = −0 but 1/0 ≠ 1/−0.\n\nSubnormal values fill the underflow gap with values\nwhere the absolute distance between them is the same as for\nadjacent values just outside the underflow gap.\nThis is an improvement over the older practice to just have zero in the underflow gap,\nand where underflowing results were replaced by zero (flush to zero).\n\nModern floating-point hardware usually handles subnormal values (as well as normal values),\nand does not require software emulation for subnormals.\n\nThe infinities of the extended real number line can be represented in IEEE floating-point datatypes,\njust like ordinary floating-point values like 1, 1.5, etc.\nThey are not error values in any way, though they are often (but not always, as it depends on the rounding) used as\nreplacement values when there is an overflow. Upon a divide-by-zero exception,\na positive or negative infinity is returned as an exact result. An infinity can also be introduced as\na numeral (like C's \"INFINITY\" macro, or \"∞\" if the programming language allows that syntax).\n\nIEEE 754 requires infinities to be handled in a reasonable way, such as\n\nIEEE 754 specifies a special value called \"Not a Number\" (NaN) to be returned as the result of certain \"invalid\" operations, such as 0/0, ∞×0, or sqrt(−1). In general, NaNs will be propagated i.e. most operations involving a NaN will result in a NaN, although functions that would give some defined result for any given floating-point value will do so for NaNs as well, e.g. NaN ^ 0 = 1. There are two kinds of NaNs: the default \"quiet\" NaNs and, optionally, \"signaling\" NaNs. A signaling NaN in any arithmetic operation (including numerical comparisons) will cause an \"invalid\" exception to be signaled.\n\nThe representation of NaNs specified by the standard has some unspecified bits that could be used to encode the type or source of error; but there is no standard for that encoding. In theory, signaling NaNs could be used by a runtime system to flag uninitialized variables, or extend the floating-point numbers with other special values without slowing down the computations with ordinary values, although such extensions are not common.\n\nIt is a common misconception that the more esoteric features of the IEEE 754 standard discussed here, such as extended formats, NaN, infinities, subnormals etc., are only of interest to numerical analysts, or for advanced numerical applications; in fact the opposite is true: these features are designed to give safe robust defaults for numerically unsophisticated programmers, in addition to supporting sophisticated numerical libraries by experts. The key designer of IEEE 754, William Kahan notes that it is incorrect to \"... [deem] features of IEEE Standard 754 for Binary Floating-Point Arithmetic that ...[are] not appreciated to be features usable by none but numerical experts. The facts are quite the opposite. In 1977 those features were designed into the Intel 8087 to serve the widest possible market... Error-analysis tells us how to design floating-point arithmetic, like IEEE Standard 754, moderately tolerant of well-meaning ignorance among programmers\".\n\nBy their nature, all numbers expressed in floating-point format are rational numbers with a terminating expansion in the relevant base (for example, a terminating decimal expansion in base-10, or a terminating binary expansion in base-2). Irrational numbers, such as π or √2, or non-terminating rational numbers, must be approximated. The number of digits (or bits) of precision also limits the set of rational numbers that can be represented exactly. For example, the number 123456789 cannot be exactly represented if only eight decimal digits of precision are available.\n\nWhen a number is represented in some format (such as a character string) which is not a native floating-point representation supported in a computer implementation, then it will require a conversion before it can be used in that implementation. If the number can be represented exactly in the floating-point format then the conversion is exact. If there is not an exact representation then the conversion requires a choice of which floating-point number to use to represent the original value. The representation chosen will have a different value from the original, and the value thus adjusted is called the \"rounded value\".\n\nWhether or not a rational number has a terminating expansion depends on the base. For example, in base-10 the number 1/2 has a terminating expansion (0.5) while the number 1/3 does not (0.333...). In base-2 only rationals with denominators that are powers of 2 (such as 1/2 or 3/16) are terminating. Any rational with a denominator that has a prime factor other than 2 will have an infinite binary expansion. This means that numbers which appear to be short and exact when written in decimal format may need to be approximated when converted to binary floating-point. For example, the decimal number 0.1 is not representable in binary floating-point of any finite precision; the exact binary representation would have a \"1100\" sequence continuing endlessly:\nwhere, as previously, \"s\" is the significand and \"e\" is the exponent.\n\nWhen rounded to 24 bits this becomes\nwhich is actually 0.100000001490116119384765625 in decimal.\nAs a further example, the real number π, represented in binary as an infinite sequence of bits is\nbut is\nwhen approximated by rounding to a precision of 24 bits.\n\nIn binary single-precision floating-point, this is represented as \"s\" = 1.10010010000111111011011 with \"e\" = 1.\nThis has a decimal value of\nwhereas a more accurate approximation of the true value of π is\n\nThe result of rounding differs from the true value by about 0.03 parts per million, and matches the decimal representation of π in the first 7 digits. The difference is the discretization error and is limited by the machine epsilon.\n\nThe arithmetical difference between two consecutive representable floating-point numbers which have the same exponent is called a unit in the last place (ULP). For example, if there is no representable number lying between the representable numbers 1.45a70c22 and 1.45a70c24, the ULP is 2×16, or 2. For numbers with a base-2 exponent part of 0, i.e. numbers with an absolute value higher than or equal to 1 but lower than 2, an ULP is exactly 2 or about 10 in single precision, and exactly 2 or about 10 in double precision. The mandated behavior of IEEE-compliant hardware is that the result be within one-half of a ULP.\n\nRounding is used when the exact result of a floating-point operation (or a conversion to floating-point format) would need more digits than there are digits in the significand. IEEE 754 requires \"correct rounding\": that is, the rounded result is as if infinitely precise arithmetic was used to compute the value and then rounded (although in implementation only three extra bits are needed to ensure this). There are several different rounding schemes (or \"rounding modes\"). Historically, truncation was the typical approach. Since the introduction of IEEE 754, the default method (\"round to nearest, ties to even\", sometimes called Banker's Rounding) is more commonly used. This method rounds the ideal (infinitely precise) result of an arithmetic operation to the nearest representable value, and gives that representation as the result. In the case of a tie, the value that would make the significand end in an even digit is chosen. The IEEE 754 standard requires the same rounding to be applied to all fundamental algebraic operations, including square root and conversions, when there is a numeric (non-NaN) result. It means that the results of IEEE 754 operations are completely determined in all bits of the result, except for the representation of NaNs. (\"Library\" functions such as cosine and log are not mandated.)\n\nAlternative rounding options are also available. IEEE 754 specifies the following rounding modes:\n\nAlternative modes are useful when the amount of error being introduced must be bounded. Applications that require a bounded error are multi-precision floating-point, and interval arithmetic.\nThe alternative rounding modes are also useful in diagnosing numerical instability: if the results of a subroutine vary substantially between rounding to + and − infinity then it is likely numerically unstable and affected by round-off error.\n\nFor ease of presentation and understanding, decimal radix with 7 digit precision will be used in the examples, as in the IEEE 754 \"decimal32\" format. The fundamental principles are the same in any radix or precision, except that normalization is optional (it does not affect the numerical value of the result). Here, \"s\" denotes the significand and \"e\" denotes the exponent.\n\nA simple method to add floating-point numbers is to first represent them with the same exponent. In the example below, the second number is shifted right by three digits, and one then proceeds with the usual addition method:\n\nIn detail:\n\nThis is the true result, the exact sum of the operands. It will be rounded to seven digits and then normalized if necessary. The final result is\n\nNote that the lowest three digits of the second operand (654) are essentially lost. This is round-off error. In extreme cases, the sum of two non-zero numbers may be equal to one of them:\n\nIn the above conceptual examples it would appear that a large number of extra digits would need to be provided by the adder to ensure correct rounding; however, for binary addition or subtraction using careful implementation techniques only two extra \"guard\" bits and one extra \"sticky\" bit need to be carried beyond the precision of the operands.\n\nAnother problem of loss of significance occurs when two nearly equal numbers are subtracted. In the following example \"e\" = 5; \"s\" = 1.234571 and \"e\" = 5; \"s\" = 1.234567 are representations of the rationals 123457.1467 and 123456.659.\n\nThe best representation of this difference is \"e\" = −1; \"s\" = 4.877000, which differs more than 20% from \"e\" = −1; \"s\" = 4.000000. In extreme cases, all significant digits of precision can be lost (although gradual underflow ensures that the result will not be zero unless the two operands were equal). This \"cancellation\" illustrates the danger in assuming that all of the digits of a computed result are meaningful. Dealing with the consequences of these errors is a topic in numerical analysis; see also Accuracy problems.\n\nTo multiply, the significands are multiplied while the exponents are added, and the result is rounded and normalized.\n\nSimilarly, division is accomplished by subtracting the divisor's exponent from the dividend's exponent, and dividing the dividend's significand by the divisor's significand.\n\nThere are no cancellation or absorption problems with multiplication or division, though small errors may accumulate as operations are performed in succession. In practice, the way these operations are carried out in digital logic can be quite complex (see Booth's multiplication algorithm and Division algorithm).\nFor a fast, simple method, see the Horner method.\n\nFloating-point computation in a computer can run into three kinds of problems:\n\nPrior to the IEEE standard, such conditions usually caused the program to terminate, or triggered some kind\nof trap that the programmer might be able to catch. How this worked was system-dependent,\nmeaning that floating-point programs were not portable. (Note that the term \"exception\" as used in IEEE-754 is a general term meaning an exceptional condition, which is not necessarily an error, and is a different usage to that typically defined in programming languages such as a C++ or Java, in which an \"exception\" is an alternative flow of control, closer to what is termed a \"trap\" in IEEE-754 terminology).\n\nHere, the required default method of handling exceptions according to IEEE 754 is discussed (the IEEE-754 optional trapping and other \"alternate exception handling\" modes are not discussed). Arithmetic exceptions are (by default) required to be recorded in \"sticky\" status flag bits. That they are \"sticky\" means that they are not reset by the next (arithmetic) operation, but stay set until explicitly reset. The use of \"sticky\" flags thus allows for testing of exceptional conditions to be delayed until after a full floating-point expression or subroutine: without them exceptional conditions that could not be otherwise ignored would require explicit testing immediately after every floating-point operation. By default, an operation always returns a result according to specification without interrupting computation. For instance, 1/0 returns +∞, while also setting the divide-by-zero flag bit (this default of ∞ is designed so as to often return a finite result when used in subsequent operations and so be safely ignored).\n\nThe original IEEE 754 standard, however, failed to recommend operations to handle such sets of arithmetic exception flag bits. So while these were implemented in hardware, initially programming language implementations typically did not provide a means to access them (apart from assembler). Over time some programming language standards (e.g., C99/C11 and Fortran) have been updated to specify methods to access and change status flag bits. The 2008 version of the IEEE 754 standard now specifies a few operations for accessing and handling the arithmetic flag bits. The programming model is based on a single thread of execution and use of them by multiple threads has to be handled by a means outside of the standard (e.g. C11 specifies that the flags have thread-local storage).\n\nIEEE 754 specifies five arithmetic exceptions that are to be recorded in the status flags (\"sticky bits\"):\nThe default return value for each of the exceptions is designed to give the correct result in the majority of cases such that the exceptions can be ignored in the majority of codes. \"inexact\" returns a correctly rounded result, and \"underflow\" returns a denormalized small value and so can almost always be ignored. \"divide-by-zero\" returns infinity exactly, which will typically then divide a finite number and so give zero, or else will give an \"invalid\" exception subsequently if not, and so can also typically be ignored. For example, the effective resistance of n resistors in parallel (see fig. 1) is given by formula_33. If a short-circuit develops with formula_34 set to 0, formula_35 will return +infinity which will give a final formula_36 of 0, as expected (see the continued fraction example of for another example).\n\"Overflow\" and \"invalid\" exceptions can typically not be ignored, but do not necessarily represent errors: for example, a root-finding routine, as part of its normal operation, may evaluate a passed-in function at values outside of its domain, returning NaN and an \"invalid\" exception flag to be ignored until finding a useful start point.\n\nThe fact that floating-point numbers cannot precisely represent all real numbers, and that floating-point operations cannot precisely represent true arithmetic operations, leads to many surprising situations. This is related to the finite precision with which computers generally represent numbers.\n\nFor example, the non-representability of 0.1 and 0.01 (in binary) means that the result of attempting to square 0.1 is neither 0.01 nor the representable number closest to it. In 24-bit (single precision) representation, 0.1 (decimal) was given previously as \"e\" = −4; \"s\" = 110011001100110011001101, which is\nSquaring this number gives\nSquaring it with single-precision floating-point hardware (with rounding) gives\nBut the representable number closest to 0.01 is\n\nAlso, the non-representability of π (and π/2) means that an attempted computation of tan(π/2) will not yield a result of infinity, nor will it even overflow. It is simply not possible for standard floating-point hardware to attempt to compute tan(π/2), because π/2 cannot be represented exactly. This computation in C:\n\n/* Enough digits to be sure we get the correct approximation. */\ndouble pi = 3.1415926535897932384626433832795;\ndouble z = tan(pi/2.0);\n\nwill give a result of 16331239353195370.0. In single precision (using the tanf function), the result will be −22877332.0.\n\nBy the same token, an attempted computation of sin(π) will not yield zero. The result will be (approximately) 0.1225 in double precision, or −0.8742 in single precision.\n\nWhile floating-point addition and multiplication are both commutative (\"a\" + \"b\" = \"b\" + \"a\" and \"a\" × \"b\" = \"b\" × \"a\"), they are not necessarily associative. That is, (\"a\" + \"b\") + \"c\" is not necessarily equal to \"a\" + (\"b\" + \"c\"). Using 7-digit significand decimal arithmetic:\n\nThey are also not necessarily distributive. That is, (\"a\" + \"b\") × \"c\" may not be the same as \"a\" × \"c\" + \"b\" × \"c\":\n\nIn addition to loss of significance, inability to represent numbers such as π and 0.1 exactly, and other slight inaccuracies, the following phenomena may occur:\n\n\n\"Machine precision\" is a quantity that characterizes the accuracy of a floating-point system, and is used in backward error analysis of floating-point algorithms. It is also known as unit roundoff or \"machine epsilon\". Usually denoted Ε, its value depends on the particular rounding being used.\n\nWith rounding to zero,\nwhereas rounding to nearest,\n\nThis is important since it bounds the \"relative error\" in representing any non-zero real number x within the normalized range of a floating-point system:\n\nBackward error analysis, the theory of which was developed and popularized by James H. Wilkinson, can be used to establish that an algorithm implementing a numerical function is numerically stable. The basic approach is to show that although the calculated result, due to roundoff errors, will not be exactly correct, it is the exact solution to a nearby problem with slightly perturbed input data. If the perturbation required is small, on the order of the uncertainty in the input data, then the results are in some sense as accurate as the data \"deserves\". The algorithm is then defined as \"backward stable\". Stability is a measure of the sensitivity to rounding errors of a given numerical procedure; by contrast, the condition number of a function for a given problem indicates the inherent sensitivity of the function to small perturbations in its input and is independent of the implementation used to solve the problem.\n\nAs a trivial example, consider a simple expression giving the inner product of (length two) vectors formula_41 and formula_42, then\nand so\nwhich is the sum of two slightly perturbed (on the order of Ε) input data, and so is backward stable. For more realistic examples in numerical linear algebra see Higham 2002 and other references below.\n\nAlthough, as noted previously, individual arithmetic operations of IEEE 754 are guaranteed accurate to within half a ULP, more complicated formulae can suffer from larger errors due to round-off. The loss of accuracy can be substantial if a problem or its data are ill-conditioned, meaning that the correct result is hypersensitive to tiny perturbations in its data. However, even functions that are well-conditioned can suffer from large loss of accuracy if an algorithm numerically unstable for that data is used: apparently equivalent formulations of expressions in a programming language can differ markedly in their numerical stability. One approach to remove the risk of such loss of accuracy is the design and analysis of numerically stable algorithms, which is an aim of the branch of mathematics known as numerical analysis. Another approach that can protect against the risk of numerical instabilities is the computation of intermediate (scratch) values in an algorithm at a higher precision than the final result requires, which can remove, or reduce by orders of magnitude, such risk: IEEE 754 quadruple precision and extended precision are designed for this purpose when computing at double precision.\n\nFor example, the following algorithm is a direct implementation to compute the function A(x) = (x−1) / (exp(x−1) − 1) which is well-conditioned at 1.0, however it can be shown to be numerically unstable and lose up to half the significant digits carried by the arithmetic when computed near 1.0.\n\ndouble A(double X)\n\nIf, however, intermediate computations are all performed in extended precision (e.g. by setting line [1] to C99 long double), then up to full precision in the final double result can be maintained. Alternatively, a numerical analysis of the algorithm reveals that if the following non-obvious change to line [2] is made:\n\nthen the algorithm becomes numerically stable and can compute to full double precision.\n\nTo maintain the properties of such carefully constructed numerically stable programs, careful handling by the compiler is required. Certain \"optimizations\" that compilers might make (for example, reordering operations) can work against the goals of well-behaved software. There is some controversy about the failings of compilers and language designs in this area: C99 is an example of a language where such optimizations are carefully specified so as to maintain numerical precision. See the external references at the bottom of this article.\n\nA detailed treatment of the techniques for writing high-quality floating-point software is beyond the scope of this article, and the reader is referred to, and the other references at the bottom of this article. Kahan suggests several rules of thumb that can substantially decrease by orders of magnitude the risk of numerical anomalies, in addition to, or in lieu of, a more careful numerical analysis. These include: as noted above, computing all expressions and intermediate results in the highest precision supported in hardware (a common rule of thumb is to carry twice the precision of the desired result i.e. compute in double precision for a final single precision result, or in double extended or quad precision for up to double precision results); and rounding input data and results to only the precision required and supported by the input data (carrying excess precision in the final result beyond that required and supported by the input data can be misleading, increases storage cost and decreases speed, and the excess bits can affect convergence of numerical procedures: notably, the first form of the iterative example given below converges correctly when using this rule of thumb). Brief descriptions of several additional issues and techniques follow.\n\nAs decimal fractions can often not be exactly represented in binary floating-point, such arithmetic is at its best when it is simply being used to measure real-world quantities over a wide range of scales (such as the orbital period of a moon around Saturn or the mass of a proton), and at its worst when it is expected to model the interactions of quantities expressed as decimal strings that are expected to be exact. An example of the latter case is financial calculations. For this reason, financial software tends not to use a binary floating-point number representation. The \"decimal\" data type of the C# and Python programming languages, and the decimal formats of the IEEE 754-2008 standard, are designed to avoid the problems of binary floating-point representations when applied to human-entered exact decimal values, and make the arithmetic always behave as expected when numbers are printed in decimal.\n\nExpectations from mathematics may not be realized in the field of floating-point computation. For example, it is known that formula_55, and that formula_56, however these facts cannot be relied on when the quantities involved are the result of floating-point computation.\n\nThe use of the equality test (codice_1) requires care when dealing with floating-point numbers. Even simple expressions like codice_2 will, on most computers, fail to be true (in IEEE 754 double precision, for example, codice_3 is approximately equal to -4.44089209850063e-16). Consequently, such tests are sometimes replaced with \"fuzzy\" comparisons (codice_4, where epsilon is sufficiently small and tailored to the application, such as 1.0E−13). The wisdom of doing this varies greatly, and can require numerical analysis to bound epsilon. Values derived from the primary data representation and their comparisons should be performed in a wider, extended, precision to minimize the risk of such inconsistencies due to round-off errors. It is often better to organize the code in such a way that such tests are unnecessary. For example, in computational geometry, exact tests of whether a point lies off or on a line or plane defined by other points can be performed using adaptive precision or exact arithmetic methods.\n\nSmall errors in floating-point arithmetic can grow when mathematical algorithms perform operations an enormous number of times. A few examples are matrix inversion, eigenvector computation, and differential equation solving. These algorithms must be very carefully designed, using numerical approaches such as Iterative refinement, if they are to work well.\n\nSummation of a vector of floating-point values is a basic algorithm in scientific computing, and so an awareness of when loss of significance can occur is essential. For example, if one is adding a very large number of numbers, the individual addends are very small compared with the sum. This can lead to loss of significance. A typical addition would then be something like\nThe low 3 digits of the addends are effectively lost. Suppose, for example, that one needs to add many numbers, all approximately equal to 3. After 1000 of them have been added, the running sum is about 3000; the lost digits are not regained. The Kahan summation algorithm may be used to reduce the errors.\n\nRound-off error can affect the convergence and accuracy of iterative numerical procedures. As an example, Archimedes approximated π by calculating the perimeters of polygons inscribing and circumscribing a circle, starting with hexagons, and successively doubling the number of sides. As noted above, computations may be rearranged in a way that is mathematically equivalent but less prone to error (numerical analysis).\nTwo forms of the recurrence formula for the circumscribed polygon are:\n\nHere is a computation using IEEE \"double\" (a significand with 53 bits of precision) arithmetic:\n\nWhile the two forms of the recurrence formula are clearly mathematically equivalent, the first subtracts 1 from a number extremely close to 1, leading to an increasingly problematic loss of significant digits. As the recurrence is applied repeatedly, the accuracy improves at first, but then it deteriorates. It never gets better than about 8 digits, even though 53-bit arithmetic should be capable of about 16 digits of precision. When the second form of the recurrence is used, the value converges to 15 digits of precision.\n\n\n"}
{"id": "11378", "url": "https://en.wikipedia.org/wiki?curid=11378", "title": "First Epistle to the Corinthians", "text": "First Epistle to the Corinthians\n\nThe First Epistle to the Corinthians (), usually referred to simply as First Corinthians and often written 1 Corinthians, is one of the Pauline epistles of the New Testament of the Christian Bible. The epistle says that Paul the Apostle and \"Sosthenes our brother\" wrote it to \"the church of God which is at Corinth\" although the scholarly consensus holds that Sosthenes was the amanuensis who wrote down the text of the letter at Paul's direction.\n\nThis epistle contains some well-known phrases, including: \"all things to all men\" (), \"through a glass, darkly\" (), and \"When I was a child, I spoke as a child, I understood as a child, I thought as a child\" ().\n\nThere is consensus among historians and Christian theologians that Paul is the author of the First Epistle to the Corinthians (c. AD 53–54). The letter is quoted or mentioned by the earliest of sources, and is included in every ancient canon, including that of Marcion. The personal and even embarrassing texts about immorality in the church increase consensus.\n\nHowever, two passages may have been inserted at a later stage. The first passage is 1 Corinthians 11:2–16, dealing with praying and prophesying with head covering. The second passage is 1 Corinthians 14:34–35, whose authenticity has been hotly debated. Part of the reason for doubt is that in some manuscripts, the verses come at the end of the chapter instead of at its present location. Furthermore, Paul is here appealing to the law which is uncharacteristic of him. Lastly, the verses come into conflict with 11:5 where women are described as praying and prophesying.\n\nThe epistle was written from Ephesus (16:8), a city on the west coast of today's Turkey, about 180 miles by sea from Corinth. According to Acts of the Apostles, Paul founded the church in Corinth (Acts 18:1–17), then spent approximately three years in Ephesus (Acts 19:8, 19:10, 20:31). The letter was written during this time in Ephesus, which is usually dated as being in the range of AD 53–57.\n\nThe traditional subscription to the epistle, translated in the King James Bible, states that this epistle was written at Philippi, perhaps arising from a misinterpretation of 16:5, \"For I do pass through Macedonia\", as meaning, \"I am passing through Macedonia\". In 16:8 Paul declares his intention of staying in Ephesus until Pentecost. This statement, in turn, is clearly reminiscent of Paul's Second Missionary Journey, when Paul traveled from Corinth to Ephesus, before going to Jerusalem for Pentecost (cf. Acts 18:22). Thus, it is possible that I Corinthians was written during Paul's first (brief) stay in Ephesus, at the end of his Second Journey, usually dated to early AD 54. However, it is more likely that it was written during his extended stay in Ephesus, where he refers to sending Timothy to them (Acts 19:22, I Cor. 4:17). Also, his references to Apollos (1:12, 3:4, etc.) show that Apollos was known to Paul and the church at the time of writing, which would preclude the first recorded visit to Ephesus (See Acts 18:24–28).\n\nThe epistle may be divided into seven parts:\n\n\n Some time before 2 Corinthians was written, Paul paid them a second visit (2 Cor. 12: 14; 2 Cor. 13: 1) to check some rising disorder (2 Cor. 2: 1; 2 Cor. 13: 2), and wrote them a letter, now lost (1 Cor. 5: 9). They had also been visited by Apollos (Acts 18: 27), perhaps by Peter (1 Cor. 1: 12), and by some Jewish Christians who brought with them letters of commendation from Jerusalem (1 Cor. 1: 12; 2 Cor. 3: 1; 2 Cor. 5: 16; 2 Cor. 11: 23).\n\nPaul wrote this letter to correct what he saw as erroneous views in the Corinthian church. Several sources informed Paul of conflicts within the church at Corinth: Apollos (Acts 19:1), a letter from the Corinthians, the \"household of Chloe\", and finally Stephanas and his two friends who had visited Paul (1:11; 16:17). Paul then wrote this letter to the Corinthians, urging uniformity of belief (\"that ye all speak the same thing and that there be no divisions among you\", 1:10) and expounding Christian doctrine. Titus and a brother whose name is not given were probably the bearers of the letter to the church at Corinth (2 Corinthians 2:13; 8:6, 16–18).\n\nIn general, divisions within the church at Corinth seem to be a problem, and Paul makes it a point to mention these conflicts in the beginning. Specifically, pagan roots still hold sway within their community. Paul wants to bring them back to what he sees as correct doctrine, stating that God has given him the opportunity to be a \"skilled master builder\" to lay the foundation and let others build upon it (1 Cor 3:10).\n\nLater, Paul wrote about immorality in Corinth by discussing an immoral brother, how to resolve personal disputes, and sexual purity. Regarding marriage, Paul states that it is better for Christians to remain unmarried, but that if they lacked self-control, it is better to marry than \"burn\" (πυροῦσθαι) which Christians have traditionally thought meant to burn with sinful desires. The Epistle may include marriage as an apostolic practice in 1 Corinthians 9:5, \"Do we not have the right to be accompanied by a believing wife, as do the other apostles and the brothers of the Lord and Cephas (Peter)?\" (In the last case, the letter concurs with Matthew 8:14, which mentions Peter having a mother-in-law and thus, by interpolation, a wife.) However, the Greek word for \"wife\" is the same word for \"woman\". The Early Church Fathers including Tertullian, Jerome, and Augustine state the Greek word is ambiguous and the women in 1 Corinthians 9:5 were women ministering to the Apostles as women ministered to Christ (cf Matthew 27:55, Luke 8:1–3), and were not wives, and assert they left their \"offices of marriage\" to follow Christ and to preach.\n\nPaul also argues unmarried people must please God, just as married people must please their spouses. The letter is also notable for mentioning the role of women in churches, that for instance they must remain silent (1 Cor. 11:2–16, 14:34–35), and the role of prophecy and speaking tongues in churches. After discussing his views on worshipping idols, Paul finally ends with his views on resurrection. He states that Christ died for our sins, and was buried, and rose on the third day according to the scriptures (1 Cor. 15:3). Paul then asks: \"Now if Christ is preached as raised from the dead, how can some of you say that there is no resurrection of the dead?\" (1 Cor. 15:12) and addresses the question of resurrection.\n\nThroughout the letter, Paul presents issues that are troubling the community in Corinth and offers ways to fix them. Paul states that this letter is not meant to make them feel ashamed but to \"admonish\" them as beloved children. They are expected to become imitators of Jesus and follow the ways in Christ as he, Paul, teaches in all his churches (1 Cor. 4:14–16).\n\n\n\n"}
{"id": "11379", "url": "https://en.wikipedia.org/wiki?curid=11379", "title": "List of Scots", "text": "List of Scots\n\nList of Scots is an incomplete list of notable people from Scotland.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "11380", "url": "https://en.wikipedia.org/wiki?curid=11380", "title": "List of South Africans", "text": "List of South Africans\n\nThis is a list of notable South Africans who are the subjects of Wikipedia articles.\n\n\n\n\nAlso see: Prelates, clerics and evangelists\n\n\n\nSee also: South African poets and Afrikaans language poets\n\n\n\n\n\n\nSee also: South African musicians and South African composers\n\n\n\n\n\n\n\n\n\n\n\n\nSee also: Dutch Cape governors, British Cape governors, Natal governors and Governors-General\n\n\n\n\nSee also: Gcaleka rulers, , Xhosa Chiefs, Zulus\n\n\n\n\n\n\n\n\n\nSee also: South African Test cricketers, South African ODI cricketers, South African Twenty20 International cricketers, South African women Test cricketers\n\n\n\n\nSee also: and \n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "11382", "url": "https://en.wikipedia.org/wiki?curid=11382", "title": "File manager", "text": "File manager\n\nA file manager or file browser is a computer program that provides a user interface to manage files and folders. The most common operations performed on files or groups of files include creating, opening (e.g. viewing, playing, editing or printing), renaming, moving or copying, deleting and searching for files, as well as modifying file attributes, properties and file permissions. Folders and files may be displayed in a hierarchical tree based on their directory structure. Some file managers contain features inspired by web browsers, including forward and back navigational buttons.\n\nSome file managers provide network connectivity via protocols, such as FTP, NFS, SMB or WebDAV. This is achieved by allowing the user to browse for a file server (connecting and accessing the server's file system like a local file system) or by providing its own full client implementations for file server protocols.\n\nA term that predates the usage of \"file manager\" is \"directory editor\". The first directory editor, DIRED, was invented circa 1974 at the Stanford Artificial Intelligence Lab by Stan Kugell\n\nA directory editor was written for EXEC 8 at the University of Maryland, and was available to other users at that time. The term was used by other developers, including Jay Lepreau, who wrote the dired program in 1980,\n\nwhich ran on BSD. This was in turn inspired by an older program with the same name running on TOPS-20. Dired inspired other programs, including dired, the editor script (for emacs and similar editors), and ded.\n\"File-list\" file managers are lesser known and older than orthodox file managers.\n\nOne such file manager is flist, which was first used in 1981 on the Conversational Monitor System.\nThis is a variant of fulist, which originated before late 1978, according to comments by its author, Theo Alkema.\n\nThe flist program provided a list of files in the user's minidisk, and allowed sorting by any file attribute. The file attributes could be passed to scripts or function-key definitions, making it simple to use flist as part of CMS EXEC, EXEC 2 or XEDIT scripts.\n\nThis program ran only on IBM VM/SP CMS, but was the inspiration for other programs, including filelist (a script run via the Xedit editor), and programs running on other operating systems, including a program also called flist, which ran on OpenVMS, and fulist (from the name of the corresponding internal IBM program), which runs on Unix.\n\n\"Orthodox file managers\" (OFM) or \"command-based file managers\" are text-menu based file managers, that commonly have three windows (two panels and one command line window). Orthodox file managers are one of the longest running families of file managers, preceding Graphical User Interface-based types. Developers create applications that duplicate and extend the manager that was introduced by PathMinder and John Socha's famous Norton Commander for DOS. The concept is more than thirty years old—PathMinder was released in 1984, and Norton Commander version 1.0 was released in 1986. Despite the age of this concept, file managers based on Norton Commander are actively developed, and dozens of implementations exist for DOS, Unix, and Microsoft Windows. Nikolai Bezroukov publishes his own set of criteria for an OFM standard (version 1.2 dated June 1997).\n\nAn orthodox file manager typically has three windows. Two of the windows are called panels and are positioned symmetrically at the top of the screen. The third is the command line, which is essentially a minimized command (shell) window that can be expanded to full screen. Only one of the panels is active at a given time. The active panel contains the \"file cursor\". Panels are resizable and can be hidden. Files in the active panel serve as the source of file operations performed by the manager. For example, files can be copied or moved from the active panel to the location represented in the passive panel. This scheme is most effective for systems in which the keyboard is the primary or sole input device. The active panel shows information about the current working directory and the files that it contains. The passive (inactive) panel shows the content of the same or another directory (the default target for file operations). Users may customize the display of columns that show relevant file information. The active panel and passive panel can be switched (often by pressing the tab key).\n\nThe following features describe the class of orthodox file managers.\n\nOther common features include:\n\nThe introduction of tabbed panels in some file managers (for example Total Commander) made it possible to manipulate more than one active and passive directory at a time.\n\nOrthodox file managers are among the most portable file managers. Examples are available on almost any platform, with both command-line and graphical interfaces. This is unusual among command line managers in that something purporting to be a standard for the interface is published. They are also actively supported by developers. This makes it possible to do the same work on different platforms without much relearning of the interface.\n\nSometimes they are called dual-pane managers, a term that is typically used for programs such as the Windows File Explorer (see below). But they have three panes including a command line pane below (or hidden behind) two symmetric panes. Furthermore, most of these programs allow using just one of the two larger panes with the second hidden. Some also add an item to the Context Menu in Windows to \"Open two Explorers, side by side\".\n\nNotable ones include:\n\nA navigational file manager is a newer type of file manager. Since the advent of GUIs, it has become the dominant type of file manager for desktop computers.\n\nTypically, it has two panes, with the filesystem tree in the left pane and the contents of the current directory in the right pane. For macOS, the miller columns view in Finder (originating in NeXTStep) is a variation on the navigational file manager theme.\n\nThe interface in a navigational file manager often resembles a web browser, complete with \"back\" and \"forward\" buttons, and often \"reload\" buttons. Most also contain an address bar into which the file or directory path (or URI) can be typed.\n\nMost navigational file managers have two panes, the left pane being a tree view of the filesystem. This means that unlike orthodox file managers, the two panes are asymmetrical in their content and use.\n\nSelecting a directory in the Navigation pane on the left designates it as the current directory, displaying its contents in the Contents pane on the right. However, expanding (+) or collapsing (-) a portion of the tree without selecting a directory will not alter the contents of the right pane. The exception to this behavior applies when collapsing a parent of the current directory, in which case the selection is refocused on the collapsed parent directory, thus altering the list in the Contents pane.\n\nThe process of moving from one location to another need not open a new window. Several instances of the file manager can be opened simultaneously and communicate with each other via drag-and-drop and clipboard operations, so it is possible to view several directories simultaneously and perform cut-and paste operations between instances.\n\nFile operations are based on drag-and-drop and editor metaphors: users can select and copy files or directories onto the clipboard and then paste them in a different place in the filesystem or even in a different instance of the file manager.\n\nNotable examples of navigational file managers include:\n\nSpatial file managers use a spatial metaphor to represent files and directories as if they were actual physical objects. A spatial file manager imitates the way people interact with physical objects.\n\nSome ideas behind the concept of a spatial file manager are:\n\n\nAs in navigational file managers, when a directory is opened, the icon representing the directory changes—perhaps from an image showing a closed drawer to an opened one, perhaps the directory's icon turns into a silhouette filled with a pattern—and a new window is opened to represent that directory.\n\nExamples of file managers that use a spatial metaphor to some extent include:\n\nDysfunctional spatial file managers:\n\nSome projects have attempted to implement a three-dimensional method of displaying files and directory structures. Three-dimensional file browsing has not yet become popular; the exact implementation tends to differ between projects, and there are no common standards to follow.\n\nExamples of three-dimensional file managers include:\n\nWeb-based file managers are typically scripts written in either PHP, Ajax, Perl, ASP or another server-side language. When installed on a local server or on a remote server, they allow files and directories located there to be managed and edited, using a web browser, without the need for FTP Access.\n\nMore advanced, and usually commercially distributed, web-based file management scripts allow the administrator of the file manager to configure secure, individual user accounts, each with individual account permissions. Authorized users have access to documents stored on the server or in their individual user directories anytime, from anywhere, via a web browser.\n\nA web-based file manager can serve as an organization's digital repository. For example, documents, digital media, publishing layouts, and presentations can be stored, managed, and shared between customers, suppliers, and remote workers, or just internally.\n\nWeb-based file managers are becoming increasingly popular due to the rise in popularity of dynamic web content management systems (CMS) and the need for non-technical website moderators to manage media on their websites powered by these platforms.\n\nAn example is net2ftp, a PHP- and JavaScript-based FTP client.\n\n\n"}
{"id": "11385", "url": "https://en.wikipedia.org/wiki?curid=11385", "title": "File viewer", "text": "File viewer\n\nA file viewer is application software that presents the data stored in a computer file in a human-friendly form. The file contents are generally displayed on the screen, or they may be printed. Also, they may be read aloud using speech synthesis.\n\nFile viewers do not edit files, yet it is common for them to be able to export data in a different file format, or to copy information from the viewed to the system-wide clipboard. A file viewer is limited-functionality software in the sense that it does not have a capability to create a file, or modify the content of an existing one. Instead, it is used only to display or print the content.\n\nFile viewers have to have sufficient knowledge about the file format to be viewed in order to handle different byte orders, code pages or newline styles.\n\nSome file viewer may be classified as filters that translate binary files into plain text (one example antiword). However, depending on the competence of the translating routines, some information may be lost.\n\nImage viewers display graphics files onscreen. Most viewers are capable of reading multiple graphics file formats but some such as JPEGview are dedicated to a single format. Common image viewer features include thumbnail preview and creation, and image zooming.\n\nFor more complex or proprietary file formats, file viewers are usually provided by the same companies that make the editing software using those formats. Viewers are usually distributed free of charge, while editors have to be bought. For example, the full version of Adobe Acrobat can be used to create content for most computer platforms. To ensure that people can access the documents created with Adobe Acrobat, the software publisher created a viewer program, the Acrobat Reader, and made it available for free. Microsoft also makes viewers for Word and PowerPoint documents freely available. These viewer applications allow the file format to be readable on all supported operating-systems, free of charge, making the commercial product a more attractive solution.\n\nA web browser is a type of file viewer, which renders HTML markup into a human-friendly presentation. Although HTML is stored in plain text files, viewing an HTML file in a browser and in a text editor produces significantly different results. Web browsers may also be used to view image and multimedia files.\n\nThere are also types of data that are not intended for static display — these incorporate the time dimension. Viewers for such formats are named players. But the essence is the same — presenting file contents in human-friendly form (i.e. displaying video on the screen as intended, or playing sound through loudspeakers). And the same consideration of different file formats is present.\n\n\n\n\n\n\n"}
{"id": "11387", "url": "https://en.wikipedia.org/wiki?curid=11387", "title": "First Epistle of Peter", "text": "First Epistle of Peter\n\nThe First Epistle of Peter, usually referred to simply as First Peter and often written 1 Peter, is a book of the New Testament. The author presents himself as Peter the Apostle, and the epistle was traditionally held to have been written during his time as bishop of Rome or Bishop of Antioch, though neither title is used in the epistle. The letter is addressed to various churches in Asia Minor suffering religious persecution.\n\nThe authorship of 1 Peter has traditionally been attributed to the Apostle Peter because it bears his name and identifies him as its author (1:1). Although the text identifies Peter as its author, the language, dating, style, and structure of this letter have led many scholars to conclude that this letter is pseudonymous. Many scholars are convinced that Peter was not the author of this letter because the author had to have a formal education in rhetoric/philosophy and an advanced knowledge of the Greek language.\n\nGraham Stanton rejects Petrine authorship because 1 Peter was most likely written during the reign of Domitian in AD 81, which is when he believes widespread Christian persecution began, which is long after the death of Peter. Current scholarship has abandoned the persecution argument because the described persecution within the work does not necessitate a time period outside of the period of Peter. Many scholars also doubt Petrine authorship because they are convinced that 1 Peter is dependent on the Pauline epistles and thus was written after Paul the Apostle’s ministry because it shares many of the same motifs espoused in Ephesians, Colossians, and the Pastoral Epistles. Others argue that it makes little sense to ascribe the work to Peter when it could have been ascribed to Paul. One theory used to support Petrine authorship of 1 Peter is the \"secretarial hypothesis\", which suggests that 1 Peter was dictated by Peter and was written in Greek by his secretary, Silvanus (5:12). John Elliot, however, suggests that the notion of Silvanus as secretary or author or drafter of 1 Peter represents little more than a counsel of despair and introduces more problems than it solves because the Greek rendition of 5:12 suggests that Silvanus was not the secretary, but the courier/bearer of 1 Peter, and some see Mark as a contributive amanuensis in the composition and writing of the work. On the one hand, some scholars such as Bart D. Ehrman are convinced that the language, dating, literary style, and structure of this text makes it implausible to conclude that 1 Peter was written by Peter; according to these scholars, it is more likely that 1 Peter is a pseudonymous letter, written later by one of the disciples of Peter in his honor. On the other hand, some scholars argue that there is not enough evidence to conclude that Peter did not write 1 Peter. For instance, there are similarities between 1 Peter and Peter's speeches in the Biblical book of Acts, and the earliest attestation of Peter's authorship comes from 2 Peter (AD 60–160) and the letters of Clement (AD 70-140). Ultimately, the authorship of 1 Peter remains contested.\n\n1 Peter is addressed to the “elect resident aliens” scattered throughout Pontus, Galatia, Cappadocia, Asia, and Bithynia. The five areas listed in 1:1 as the geographical location of the first readers were Roman provinces in Asia Minor. The order in which the provinces are listed may reflect the route to be taken by the messenger who delivered the circular letter. The recipients of this letter are referred to in 1:1 as “exiles of the Dispersion.” In 1:17, they are urged to “live in reverent fear during the time of your exile\". The social makeup of the addressees of 1 Peter is debatable because some scholars interpret “strangers” (1:1) as Christians longing for their home in heaven, some interpret it as literal “strangers”, or as an Old Testament adaptation applied to Christian believers.\n\nWhile the new Christians have encountered oppression and hostility from locals, Peter advises them to maintain loyalty to both their religion and the Roman Empire (1 Peter 2:17).\n\nThe author counsels (1) to steadfastness and perseverance under persecution (1–2:10); (2) to the practical duties of a holy life (2:11–3:13); (3) he adduces the example of Christ and other motives to patience and holiness (3:14–4:19); and (4) concludes with counsels to pastors and people (chap. 5).\n\nDavid Bartlett lists the following outline to structure the literary divisions of 1 Peter.\n\nThe Petrine author writes of his addressees undergoing “various trials” (1 Peter 1:6), being “tested by fire” (1:7), maligned “as evildoers” (2:12) and suffering “for doing good” (3:17). Based on such internal evidence, biblical scholar John Elliott summarizes the addressees’ situation as one marked by undeserved suffering. Verse (), \"Spirits in prison\", is a continuing theme in Christianity, and one considered by most theologians to be enigmatic and difficult to interpret.\n\nA number of verses in the epistle contain possible clues about the reasons Christians experienced opposition. Exhortations to live blameless lives (2:15; 3:9, 13, 16) may suggest that the Christian addressees were accused of immoral behavior, and exhortations to civil obedience (2:13–17) perhaps imply that they were accused of disloyalty to governing powers.\n\nHowever, scholars differ on the nature of persecution inflicted on the addressees of 1 Peter. Some read the epistle to be describing persecution in the form of social discrimination, while some read them to be official persecution.\n\nSome scholars believe that the sufferings the epistle's addressees were experiencing were social in nature, specifically in the form of verbal derision. Internal evidence for this includes the use of words like “malign” (2:12; 3:16), and “reviled” (4:14). Biblical scholar John Elliott notes that the author explicitly urges the addressees to respect authority (2:13) and even honor the emperor (2:17), strongly suggesting that they were unlikely to be suffering from official Roman persecution. It is significant to him that the author notes that “your brothers and sisters in all the world are undergoing the same kinds of suffering” (5:9), indicating suffering that is worldwide in scope. Elliott sees this as grounds to reject the idea that the epistle refers to official persecution, because the first worldwide persecution of Christians officially meted by Rome did not occur until the persecution initiated by Decius in AD 250.\n\nOn the other hand, scholars who support the official persecution theory take the exhortation to defend one's faith (3:15) as a reference to official court proceedings. They believe that these persecutions involved court trials before Roman authorities, and even executions.\n\nOne common supposition is that 1 Peter was written during the reign of Domitian (AD 81–96). Domitian's aggressive claim to divinity would have been rejected and resisted by Christians. Biblical scholar Paul Achtemeier believes that persecution of Christians by Domitian would have been in character, but points out that there is no evidence of official policy targeted specifically at Christians. If Christians were persecuted, it is likely to have been part of Domitian’s larger policy suppressing all opposition to his self-proclaimed divinity. There are other scholars who explicitly dispute the idea of contextualizing 1 Peter within Domitian’s reign. Duane Warden believes that Domitian’s unpopularity even among Romans renders it highly unlikely that his actions would have great influence in the provinces, especially those under the direct supervision of the senate such as Asia (one of the provinces 1 Peter is addressed to).\n\nAlso often advanced as a possible context for 1 Peter is the trials and executions of Christians in the Roman province of Bithynia-Pontus under Pliny the Younger. Scholars who support this theory believe that a famous letter from Pliny to Emperor Trajan concerning the delation of Christians reflects the situation faced by the addressees of this epistle. In Pliny's letter, written in AD 112, he asks Trajan if the accused Christians brought before him should be punished based on the name ‘Christian’ alone, or for crimes associated with the name. For biblical scholar John Knox, the use of the word “name” in 4:14–16 is the “crucial point of contact” with that in Pliny’s letter. In addition, many scholars in support of this theory believe that there is content within 1 Peter that directly mirrors the situation as portrayed in Pliny’s letter. For instance, they interpret the exhortation to defend one’s faith “with gentleness and reverence” in 3:15–16 as a response to Pliny executing Christians for the obstinate manner in which they professed to be Christians. Generally, this theory is rejected mainly by scholars who read the suffering in 1 Peter to be caused by social, rather than official, discrimination.\n\nThe author refers to Jesus, after his death, proclaiming to spirits in prison (3:18–20). This passage, and a few others (such as Matthew 27:52 and Luke 23:43), are the basis of the traditional Christian belief in the descent of Christ into hell, or the harrowing of hell. Though interpretations vary, some theologians see this passage as referring to Jesus, after his death, going to a place (neither heaven nor hell in the ultimate sense) where the souls of pre-Christian people waited for the Gospel. The first creeds to mention the harrowing of hell were Arian formularies of Sirmium (359), Nike (360), and Constantinople (360). It spread through the west and later appeared in the Apostles' Creed\".\n\n\nOnline translations of the First Epistle of Peter:\n\nRelated articles:\n"}
{"id": "11388", "url": "https://en.wikipedia.org/wiki?curid=11388", "title": "First Epistle of John", "text": "First Epistle of John\n\nThe First Epistle of John, often referred to as First John and written 1 John, is the first of the Johannine epistles of the New Testament, and the fourth of the catholic epistles. It is attributed to John the Evangelist, traditionally thought to be the author of the Gospel of John and the other two Johannine epistles. This epistle was probably written in Ephesus in AD 95–110. The work was written to counter docetism, which is the belief that Jesus did not come \"in the flesh\", but only as a spirit. It also defined how Christians are to discern true teachers: by their ethics, their proclamation of Jesus in the flesh, and by their love.\n\nThe main themes of the epistle are love and fellowship with God. The author describes various tests by which readers may ascertain whether or not their communion with God is genuine, and teaches that the proof of spiritual regeneration is a life of active righteousness. It also distinguishes between the world (which is full of evil and under the dominion of Satan) and the children of God (who are set apart from the world).\n\nThe main themes of the epistle are discernible in the writer's sectional organisation of his contents. There are four sections (arranged in the chiasm ABB'A'): 1:1–2:14; 2:15–3:10; 3:11–4:13; 4:14–5:20. The first, A, speaks of \"the witness\", given and received, to God who is \"light\" and the exhortation is \"to live in his light\". The second, B, is an exhortation \"to love not the world\", with earthly motives, in earthly ways. The third, B', a balance to B, emphasizes (rather) \"love one another\". The fourth, A', again begins with \"the witness\", but this time it is to God who is \"love\"; \"life eternal\" is theirs who live a life of loving God. The key requirements of Ancient Rhetoric, \"Purpose\" and \"Structure\" are clearly evidenced in this letter. So too are the other requirements of \"Style\" and \"Memory\".\n\nAmong the most controversial verses of the Bible is what some consider an explicit reference that supports the doctrine of the trinity, the \"Comma Johanneum\": \"For there are three that bear record in heaven, the Father, the Word, and the Holy Ghost: and these three are one. And there are three that bear witness in earth, the Spirit, and the water, and the blood: and these agree in one.\" (1 John 5:7–8, King James Version). Verse 7 does not appear in any version of the Greek text prior to the ninth century, and first appears in most of the Latin manuscripts, especially in the Vetus Itala (Old Latin predating Jerome) before being translated into Greek and added to later Greek manuscripts. It was included in the King James Bible, something Isaac Newton commented on in An Historical Account of Two Notable Corruptions of Scripture. This is sometimes used as evidence to counter the King-James-Only Movement. Bart Ehrman suggests in his book \"Misquoting Jesus\" that the King James Version would not have included the passage if Desiderius Erasmus had not given in to pressure to include it in the Textus Receptus even though he doubted its authenticity.\n\nThe majority of modern translations (for example English Standard Version and New American Standard Bible) do not include this text, or (for example the New Revised Standard Version) include it as a footnote. Albert Barnes (1798–1870) said regarding its authenticity:On the whole, therefore, the evidence seems to me to be clear that this passage is not a genuine portion of the inspired writings, and should not be appealed to in proof of the doctrine of the Trinity.\n\nThe epistle is not written in the same form as the other biblical epistles, lacking an epistolary opening or conclusion. The epistle is written in a simple style, without syntactical flourishes, and makes frequent use of asyndeton, where related thoughts are placed next to one another without conjunctions. In contrast to the linear style used in the Pauline epistles, John's thought moves in loops or circles forming a slowly advancing sequence of thought. This is similar to the parallel structure of Hebrew poetry, in which the second verse of a couplet often carries the same meaning as the first, though in the epistle the frequent recapitulations of already expressed ideas serve also to add to what has previously been said. In summary, the epistle may be said to exhibit a paraenetic style which is \"marked by personal appeal, contrasts of right and wrong, true and false, and an occasional rhetorical question\".\n\nSome scholars have proposed the idea that the epistle is really John's commentary on a selection of traditional parallel couplets. While this theory, first propounded by Ernst von Dobschütz and Rudolf Bultmann, is not universally accepted, Amos Wilder writes that, \"It is at least clear that there are considerable and sometimes continuous elements in the epistle whose style distinguishes them from that of the author both with respect to poetic structure and syntactic usage.\"\n\nThe epistle is traditionally held to have been composed by John the Evangelist, at Ephesus, when the writer was in advanced age. The epistle's content, language and conceptual style are very similar to the Gospel of John, 2 John, and 3 John, indicating that they were written by the same author. Indeed, at the end of the 19th century scholar Ernest DeWitt Burton wrote that there could be \"no reasonable doubt\" that 1 John and the gospel were written by the same author, and Amos Wilder has said that, \"Early Christian tradition and the great majority of modern scholars have agreed on the common authorship of these writings, even where the author has not been identified with the apostle John.\"\n\nHowever, other modern scholars have challenged this position. Though the common authorship of the three epistles is still almost universally accepted, scholars such as Heinrich Julius Holtzmann and C. H. Dodd have maintained that the epistle and the gospel were written by different authors. There are at least two principal arguments for this view. The first is that the epistle often uses a demonstrative pronoun at the beginning of a sentence, then a particle or conjunction, followed by an explanation or definition of the demonstrative at the end of the sentence, a stylistic technique which is not used in the gospel. The second is that the author of the epistle \"uses the conditional sentence in a variety of rhetorical figures which are unknown to the gospel\".\n\n\"The Fourth Gospel addresses itself to the challenges posed by Judaism and others outside Johannine circles who have rejected the community's vision of Jesus as preexistent Son, sent by the Father. The epistles (First, Second, and Third John) \"describe the fracturing of the Johannine community itself\".\n\nThe author wrote the epistle so that the joy of his audience would \"be full\" (1:4) and that they would \"not practice sin\" (2:1) and that \"you who believe in the name of the Son of God... may know that you have eternal life\" (5:13). We can therefore distinguish in the epistle both a general purpose (to increase mutual joy) and a specific purpose (to provide readers with tests by which they might assure themselves of their salvation). It appears as though the author was concerned about heretical teachers that had been influencing churches under his care. Such teachers were considered Antichrists (2:18–19) who had once been church leaders but whose teaching became heterodox. It appears that these teachers taught a form of docetism in which Jesus came to earth as a spirit without a real body of flesh (4:2) that his death on the cross was not as a true atonement for sins (1:7). It appears that John might have also been rebuking a proto-Gnostic named Cerinthus, who also denied the true humanity of Christ.\n\nThe purpose of the author (1:1–4) is to declare the Word of Life to those to whom he writes, in order that they might be united in fellowship with the Father and his Son Jesus Christ. He shows that the means of union with God are, (1) on the part of Christ, his atoning work (1:7; 2:2; 3:5; 4:10, 14; 5:11, 12) and his advocacy (2:1); and (2), on the part of man, holiness (1:6), obedience (2:3), purity (3:3), faith (3:23; 4:3; 5:5), and love (2:7, 8; 3:14; 4:7; 5:1).\n\nWhereas the Gospel of John was written to unbelievers, this epistle was written to those who were already believers (5:13). It seems likely that its audience was largely gentile rather than Jewish, since it contains few Old Testament quotations or distinctly Jewish forms of expression. The epistle was probably carried by itinerant missionaries to different churches throughout the region and read aloud to the congregations.\n\n\n\n\nOnline translations of the First Epistle of John\n"}
{"id": "11390", "url": "https://en.wikipedia.org/wiki?curid=11390", "title": "First Vatican Council", "text": "First Vatican Council\n\nThe Vatican Council () was convoked by Pope Pius IX on 29 June 1868, after a period of planning and preparation that began on 6 December 1864. This, the twentieth ecumenical council of the Catholic Church, held three centuries after the Council of Trent, opened on 8 December 1869 and adjourned on 20 October 1870. Unlike the five earlier General Councils held in Rome, which met in the Lateran Basilica and are known as Lateran Councils, it met in the Vatican Basilica, hence its name. Its best-known decision is its definition of papal infallibility, strongly promoted by the Archbishop Luigi Natoli.\n\nThe council was convoked to deal with the contemporary problems of the rising influence of rationalism, liberalism, and materialism. Its purpose was, besides this, to define the Catholic doctrine concerning the Church of Christ. There was discussion and approval of only two constitutions: the Dogmatic Constitution on the Catholic Faith and the First Dogmatic Constitution on the Church of Christ, the latter dealing with the primacy and infallibility of the Bishop of Rome. The first matter brought up for debate was the dogmatic draft of Catholic doctrine against the manifold errors due to rationalism.\n\nThis council was summoned by Pope Pius IX by a bull on 29 June 1868. The first session was held in St. Peter's Basilica on 8 December 1869. Preliminary sessions dealt with general administrative matters and committee assignments. Bishop Bernard John McQuaid complained of rainy weather, inadequate heating facilities and boredom. Bishop James Roosevelt Bayley of Newark, New Jersey noted the high prices in Rome.\n\nThe doctrine of papal infallibility was not new and had been used by Pope Pius in defining as dogma, in 1854, the Immaculate Conception of Mary, the mother of Jesus. However, the proposal to define papal infallibility itself as dogma met with resistance, not because of doubts about the substance of the proposed definition, but because some considered it inopportune to take that step at that time. Richard McBrien divides the bishops attending Vatican I into three groups. The first group, which McBrien calls the \"active infallibilists\", was led by Henry Edward Manning and Ignatius von Senestréy. According to McBrien, the majority of the bishops were not so much interested in a formal definition of papal infallibility as they were in strengthening papal authority and, because of this, were willing to accept the agenda of the infallibilists. A minority, some 10 percent of the bishops, McBrien says, opposed the proposed definition of papal infallibility on both ecclesiastical and pragmatic grounds, because, in their opinion, it departed from the ecclesiastical structure of the early Christian church. From a pragmatic perspective, they feared that defining papal infallibility would alienate some Catholics, create new difficulties for union with non-Catholics, and provoke interference by governments in church affairs. Those who held this view included most of the German and Austro-Hungarian bishops, nearly half of the Americans, one third of the French, most of the Chaldaeans and Melkites, and a few Armenians. Only a few bishops appear to have had doubts about the dogma itself.\n\nOn 24 April 1870, the dogmatic constitution on the Catholic faith \"Dei Filius\" was adopted unanimously. The draft presented to the council on 8 March drew no serious criticism, but a group of 35 English-speaking bishops, who feared that the opening phrase of the first chapter, \"\"Sancta romana catholica Ecclesia\"\" (the holy Roman Catholic Church), might be construed as favouring the Anglican branch theory, later succeeded in having an additional adjective inserted, so that the final text read: \"\"Sancta catholica apostolica romana Ecclesia\"\" (the holy Catholic Apostolic Roman Church). The constitution thus set forth the teaching of the \"Holy Catholic Apostolic Roman Church\" on God, revelation and faith.\n\nThere was stronger opposition to the draft constitution on the nature of the Church, which at first did not include the question of papal infallibility, but the majority party in the council, whose position on this matter was much stronger, brought it forward. It was decided to postpone discussion of everything in the draft except infallibility. The decree did not go forward without controversy; Cardinal Filippo Guidi, Archbishop of Bologna, proposed adding that the Pope is assisted by \"the counsel of the bishops manifesting the tradition of the churches.\" The Pope rejected Guidi's view of the bishops as witnesses to the tradition, maintaining that \"I am the tradition.\"\n\nOn 13 July 1870, the section on infallibility was voted on: 451 voted simply in favour (\"placet\"), 88 against (\"non placet\"), and 62 in favour but on condition of some amendment (\"placet iuxta modum\"). This made evident what the final outcome would be, and some 60 members of the opposition left Rome so as not to be associated with approval of the document. The final vote, with a choice only between \"placet\" and \"non placet\", was taken on 18 July 1870, with 433 votes in favour and only 2 against defining as a dogma the infallibility of the pope when speaking \"ex cathedra\". The two votes against were cast by Bishop Aloisio Riccio, and Bishop Edward Fitzgerald.\n\nThe dogmatic constitution states that the Pope has \"full and supreme power of jurisdiction over the whole Church\" (chapter 3:9); and that, when he \"speaks \"ex cathedra\", that is, when, in the exercise of his office as shepherd and teacher of all Christians, in virtue of his supreme apostolic authority, he defines a doctrine concerning faith or morals to be held by the whole Church, he possesses, by the divine assistance promised to him in blessed Peter, that infallibility which the divine Redeemer willed his Church to enjoy in defining doctrine concerning faith or morals\" (chapter 4:9).\n\nNone of the bishops who had argued that proclaiming the definition was inopportune refused to accept it. Some Catholics, mainly of German language and largely inspired by the historian Ignaz von Döllinger, formed the separate Old Catholic Church in protest; von Döllinger did not formally join the new group.\n\nDiscussion of the rest of the document on the nature of the Church was to continue when the bishops returned after a summer break. However, in the meanwhile the Franco-Prussian War broke out. With the swift German advance and the capture of Emperor Napoleon III, France was no longer in a position to protect the Pope's rule in Rome.\n\nConsequently, on 20 September 1870, the Kingdom of Italy captured Rome and annexed it. One month later, on 20 October 1870, Pope Pius IX suspended the council indefinitely. It was never reconvened. The Council was formally closed by Pope John XXIII in 1960.\n\nMoritz Busch recounts that Otto von Bismarck confided that, after the capture of Rome, Pius IX considered leaving Rome and reopening the council elsewhere:\nHe also reports:\n\n\n\n"}
{"id": "11391", "url": "https://en.wikipedia.org/wiki?curid=11391", "title": "First Council of the Lateran", "text": "First Council of the Lateran\n\nThe Council of 1123 is reckoned in the series of Ecumenical councils by the Catholic Church. It was convoked by Pope Calixtus II in December, 1122, immediately after the Concordat of Worms. The Council sought to: (a) bring an end to the practice of the conferring of ecclesiastical benefices by people who were laymen; (b) free the election of bishops and abbots from secular influence; (c) clarify the separation of spiritual and temporal affairs; (d) re-establish the principle that spiritual authority resides solely in the Church; (e) abolish the claim of the emperors to influence papal elections.\n\nThe council convoked by Callistus II was significant in size: three hundred bishops and more than six hundred abbots assembled at Rome in March, 1123; Callistus presided in person. During the Council the decisions of the Concordat of Worms were read and ratified. Various other decisions were promulgated.\n\nThe First Lateran Council was called by Pope Callistus II whose reign began February 1, 1119. It demarcated the end of the Investiture controversy which had begun before the time of Pope Gregory VII. The issues had been contentious and had continued with unabated bitterness for almost a century. Guido, as he was called before his elevation to the papacy, was the son of William I, Count of Burgundy. He was closely connected with nearly all the royal houses of Europe on both sides of his family. He had been named the papal legate to France by Pope Paschal II. During Guido's tenure in this office, Paschal II yielded to the military threats of Henry V, Holy Roman Emperor, and was induced to issue the Privilegium in the year 1111. By this document the Church gave up much of what had been claimed and subsequently attained by Pope Gregory VII and his Gregorian Reforms.\n\nThese concessions did not bring the expected peace but were received with violent reactionary opposition everywhere. Europe had come to expect an end to the Investiture controversy, and was not willing to return to the old days when the Holy Roman Emperor named the pope. The greatest resistance was seen in France and was led by Guido, who still held the office of the papal legate. He had been present in the Lateran Synod of 1112 which had proclaimed the Privilegium of 1111. On his return to France, Guido convoked an assembly of the French and Burgundian bishops at Vienne (1112). There the lay investiture of the clergy (the practice of the king, especially the Holy Roman Emperor naming bishops and the pope) was denounced as heretical. A sentence of excommunication was pronounced against Henry V, who had extorted through violence from the pope the concessions documented in the Privilegium. The agreement was deemed to be opposed to the interests of the Church. The decrees from the assembly of Vienne which denounced the Privilegium were sent to Paschal II with a request for confirmation. Pope Paschal II confirmed these which were received in general terms, on October 20, 1112.\n\nGuido was later created cardinal by Pope Paschal II. The latter did not seem to have been pleased with Guido’s bold and forward attacks upon Henry V, Holy Roman Emperor. On the death of Paschal II, January 21, 1118, Gelasius II was elected pope. He was immediately seized by the Italian allies of Henry V, and on his liberation by the populace fled to Gaeta, where he was crowned. Henry V demanded the confirmation of the \"Privilegium\" and received no satisfactory reply. He then set about naming Burdinus, the archbishop of Braga, as his own pope. This pope assumed the name Gregory VIII, but came to be known as antipope Gregory VIII. Burdinus had already been deposed and excommunicated because he had crowned Henry V and the Holy Roman Emperor in Rome in 1117.\n\nThe excommunication of Bardinus was reiterated in Canon 6 of the document produced by Lateran I. Gelasius II promptly excommunicated the antipope Gregory VIII and Henry V. Gelasius was forced to flee under duress from the army of Henry V, and took refuge in the monastery of Cluny, where he died in January 1119. On the fourth day after the death of Gelasius II, February I, 1119, owing mainly to the exertions of Cardinal Cuno, Guido was elected pope and assumed the title of Callistus II. He was crowned Pope at Vienne on February 9, 1119.\n\nBecause of his close connection with the great royal families of Germany, France, England and Denmark, Callistus' papacy was received with much anticipation and celebration throughout Europe. There was a real hope throughout the Continent that the Investiture controversy might be settled once and for all. In the interest of conciliation, even the papal embassy was received by Henry V, Holy Roman Emperor at Strasburg. However, it soon became clear that Henry was not willing to concede his presumed and ancient right to name the pope and bishops within his kingdom. Perhaps to demonstrate conciliation or because of political necessity, Henry withdrew his support for antipope Gregory VIII.\n\nIt was agreed that Henry and Pope Callistus would meet at Mousson. On June 8, 1119, Callistus held a synod at Toulouse to proclaim the disciplinary reforms he had worked to attain in the French Church. In October, 1119, he opened the council at Reims. Louis VI of France and most of the barons of France attended this council along with more than four hundred bishops and abbots. The Pope was also to meet with Henry V, Holy Roman Emperor at Mousson. However, Henry showed up with an army of thirty thousand men. Callistus left Reims for Mousson, but upon learning of the warlike stance of Henry, quickly retreated back to Reims. Here, the Church dealt with issues of simony, concubinage of the clergy.\n\nIt was clear by now that Henry was in no mood to reconcile and a compromise with him was not to be had. The Conclave at Reims considered the situation and determined, as an entire Church, to formally excommunicate both Henry V and the antipope Gregory VIII. This occurred on October 30, 1119. While at Reims, Callistus tried to effect a settlement with Henry I of England and his brother Robert. This too, met with failure.\n\nCallistus was determined to enter Rome which was occupied by the German forces and the antipope Gregory VIII. There was an uprising by the population which forced Gregory VIII to flee the city. After much political and military intrigue in Rome and the southern Italian states, Gregory VIII was formally deposed and Callistus II was generally recognized as the legitimate Pope in 1121. Having become the established power in Italy, Callistus now returned the conflict with Henry V over the issue of lay investiture. Henry had been the recipient of great pressure from many of his barons in Germany over his conflict with the pope. Some had entered into open rebellion. Henry was forced by circumstances to seek a peace with Callistus. Initial negotiations were conducted in October, 1121, at Wurzburg. Lambert, the Cardinal of Ostia was dispatched to convoke a synod at Worms, which began on September 8, 1122. By September 23, the Concordat of Worms, also called the Pactum Calixtinum was concluded. On his side, the emperor gave up his claim to investiture with ring and crosier and granted freedom of election to the episcopal sees.\n\nThe elections of bishops could be witnessed by the emperor or his representatives. Callistus obtained the right to name bishops throughout Germany, but still did not have this power in much of Burgundy and Italy.\n\nThe First Lateran Council was convoked to confirm the Concordat of Worms. The council was most representative with nearly three hundred bishops and six hundred abbots from every part of Catholic Europe being present. It convened on March 18, 1123. Decrees were also passed directed against simony, concubinage among the clergy, church robbers, and forgers of Church documents; the council also reaffirmed indulgences for Crusaders.\n\nIn the remaining few years of his life, Callistus II attempted to secure the status of the Church as it had existed at the end of the reign of Pope Gregory VII. He reorganized and reformed the churches around Rome, canonized Conrad of Constance, condemned the teaching of Peter de Bruis, confirmed the Bishop Thurston of York against the wishes of Henry I of England, and affirmed the freedom of York from the see of Canterbury. Callistus died December 13, 1124. He was succeeded by Pope Honorius II. Callistus II was a strong figure who brought a relative, if tentative peace between Germany and the Church. The Concordat of Worms and the First Lateran Council changed forever the belief in the divine right of kings to name the pope and bishops, and reshaped the nature of church and state forever.\n\nTexts of the First Lateran Council may vary in both wording and numbering of the canons depending on source. In this translation, the precepts of the Concordat of Worms are codified in Canons 2, 4 and 10.\n\nCANON I\nSummary. Ordinations and promotions made for pecuniary considerations are devoid of every dignity.\n\nText. Following the example of the holy fathers and recognizing the obligation of our office, we absolutely forbid in virtue of the authority of the Apostolic See that anyone be ordained or promoted for money in the Church of God. Has anyone thus secured ordination or promotion in the Church, the rank acquired shall be devoid of every dignity.\n\nCANON 2\n\nSummary. Only a priest may be made provost, archpriest, and dean; only a deacon may be archdeacon.\n\nText. No one except a priest shall be promoted to the dignity of provost, archpriest, or dean;\nand no one shall be made archdeacon unless he is a deacon.\n\nCANON 3\n\nSummary. Priests, deacons, and subdeacons are forbidden to live with women other than such as were permitted by the Nicene Council.\n\nText. We absolutely forbid priests, deacons, and subdeacons to associate with concubines and women, or to live with women other than such as the Nicene Council (canon 3) for reasons of necessity permitted, namely, the mother, sister, or aunt, or any such person concerning whom no suspicion could arise.\n\nCANON 4\n\nSummary. Lay persons, no matter how pious they may be, have no authority to dispose of anything that belongs to the Church.\n\nText. In accordance with the decision of Pope Stephen, we declare that lay persons, no matter how devout they may be, have no \nauthority to dispose of anything belonging to the Church, but according to the Apostolic canon the supervision of all ecclesiastical affairs belongs to the bishop, who shall administer them conformably to the will of God. If therefore any prince or other layman shall arrogate to himself the right of disposition, control, or ownership of ecclesiastical goods or properties, let him be judged guilty of sacrilege.\n\nCANON 5\n\nSummary. Marriages between blood-relatives are forbidden.\n\nText. We forbid marriages between blood-relatives because they are forbidden by the divine and secular laws. Those who contract such alliances, as also their offspring, the divine laws not only ostracize but declare accursed, while the civil laws brand them as infamous and deprive them of hereditary rights. We, therefore, following the example of our fathers, declare and stigmatize them as infamous.\n\nCANON 6\n\nSummary. Ordinations by Burdinus and the bishops consecrated by him are invalid.\n\nText. The ordinations made by the heresiarch Burdinus after his condemnation by the Roman Church, as also those made by the bishops consecrated by him after that point of time, we declare to be invalid.\n\nCANON 7\n\nSummary. No one is permitted to arrogate to himself the episcopal authority in matters pertaining to the cura animarum and the bestowal of benefices.\n\nText. No archdeacon, archpriest, provost, or dean shall bestow on another the care of souls or the prebends of a church without the decision or consent of the bishop; indeed, as the sacred canons point out, the care of souls and the disposition of ecclesiastical property are vested in the authority of the bishop. If anyone shall dare act contrary to this and arrogate to himself the power belonging to the bishop, let him be expelled from the Church.\n\nCANON 8\n\nSummary. Military persons are forbidden under penalty of anathema to invade or forcibly hold the city of Benevento.\n\nText. Desiring with the grace of God to protect the recognized possessions of the Holy Roman Church, we forbid under pain of anathema any military person to invade or forcibly hold Benevento, the city of St. Peter. If anyone act contrary to this, let him be anathematized.\n\nCANON 9\n\nSummary. Those excommunicated by one bishop, may not be restored by others.\n\nText. We absolutely forbid that those who have been excommunicated by their own bishops be received into the communion of the Church by other bishops, abbots, and clerics.\nCANON 10\n\nSummary. A bishop consecrated after an uncanonical election shall be deposed.\n\nText. No one shall be consecrated bishop who has not been canonically elected. If anyone dare do this, both the consecrator and the one consecrated shall be deposed without hope of reinstatement.\n\nCANON 11\n\nSummary. To those who give aid to the Christians in the Orient is granted the remission of sins, and their families and possessions are taken under the protection of the Roman Church.\n\nText. For effectively crushing the tyranny of the infidels, we grant to those who go to Jerusalem and also to those who give aid toward the defense of the Christians, the remission of their sins and we take under the protection of St. Peter and the Roman Church their homes, their families, and all their belongings, as was already ordained by Pope Urban II. Whoever, therefore, shall dare molest or seize these during the absence of their owners, shall incur excommunication. Those, however, who with a view of going to Jerusalem or to Spain (that is, against the Moors) are known to have attached the cross to their garments and afterward removed it, we command in virtue of our Apostolic authority to replace it and begin the journey within a year from the coming Easter. Otherwise we shall excommunicate them and interdict within their territory all divine service except the baptism of infants and the administration of the last rites to the dying.\n\nCANON 12\n\nSummary. The property of the porticani dying without heirs is not to be disposed of in a manner contrary to the wish of the one deceased.\n\nText. With the advice of our brethren and of the entire Curia, as well as with the will and consent of the prefect, we decree the abolition of that evil custom which has hitherto prevailed among the porticani, namely, of disposing, contrary to the wish of the one deceased, of the property of porticani dying without heirs; with this understanding, however, that in future the porticani remain faithful to the Roman Church, to us and to our successors.\n\nCANON 13\n\nSummary. If anyone violates the truce of God and after the third admonition does not make satisfaction, he shall be anathematized.\n\nText. If anyone shall violate the truce of God he shall be admonished three times by the bishop to make satisfaction. If he disregards the third admonition the bishop, either with the advice of the metropolitan or with that of two or one of the neighboring bishops, shall pronounce the sentence of anathema against the violator and in writing denounce him to all the bishops. \nCANON 14\n\nSummary. Laymen are absolutely forbidden to remove offerings from the altars of Roman churches.\n\nText. Following the canons of the holy fathers, we absolutely and under penalty of anathema forbid laymen to remove the offerings from the altars of the churches of St. Peter, of The Savior (Lateran Basilica), of St. Mary Rotund, in a word, from the altars of any of the churches or from the crosses. By our Apostolic authority we forbid also the fortifying of churches and their conversion to profane uses.\n\nCANON 15\n\nSummary. Counterfeiters of money shall be excommunicated.\n\nText. Whoever manufactures or knowingly expends counterfeit money, shall be cut off from the communion of the faithful (excommunicated) as one accursed, as an oppressor of the poor and a disturber of the city.\n\nCANON 16\n\nSummary. Robbers of pilgrims and of merchants shall be excommunicated.\n\nText. If anyone shall dare attack pilgrims going to Rome to visit the shrines of the Apostles and the oratories of other saints and rob them of the things they have with them, or exact from merchants new imposts and tolls, let him be excommunicated till he has made satisfaction.\n\nCANON 17\n\nSummary. Abbots and monks may not have the cura animarum.\n\nText. We forbid abbots and monks to impose public penances, to visit the sick, to administer extreme unction, and to sing public masses. The chrism, holy oil, consecration of altars, and ordination of clerics they shall obtain from the bishops in whose dioceses they reside.\n\nCANON 18\n\nSummary. The appointment of priests to churches belongs to the bishops, and without their consent they may not receive tithes and churches from laymen.\n\nText. Priests shall be appointed to parochial churches by the bishops, to whom they shall be responsible for the care of souls and other matters pertaining to them. They are not permitted to receive tithes and churches from laics without the will and consent of the bishops. If they act otherwise, let them be subject to the canonical penalties.\n\nCANON 19\n\nSummary. Taxes paid to bishops by monks since Gregory VII must be continued. Monks may not by prescription acquire the possessions of churches and of bishops.\n\nText. The tax (servitium) which monasteries and their churches have rendered to the bishops since the time of Gregory VII, shall be continued. We absolutely forbid abbots and monks to acquire by prescription after thirty years the possessions of churches and of shops.\n\nCANON 20\n\nSummary. Churches and their possessions, as well as the person and things connected with them, shall remain safe and unmolested.\n\nText. Having in mind the example of our fathers and discharging the duty of our pastoral office, we decree that churches and their possessions, as well as the persons connected with them, namely, clerics and monks and their servants (conversi), also the laborers and the things they use, shall remain safe and unmolested. If anyone shall dare act contrary to this and, recognizing his crime, does not within the space of thirty days make proper amends, let him be cut off from the Church and anathematized.\n\nCANON 21\n\nSummary. Clerics in major orders may not marry, and marriages already contracted must be dissolved.\n\nText. We absolutely forbid priests, deacons, subdeacons, and monks to have concubines or to contract marriage. We decree in accordance with the definitions of the sacred canons, that marriages already contracted by such persons must be dissolved, and that the persons be condemned to do penance.\n\nCANON 22\n\nSummary. The alienation of possessions of the exarchate of Ravenna is condemned, and the Ordinaries made by the intruders are invalid.\n\nText. The alienation that has been made especially by Otto, Guido, Jerome, and perhaps by Philip of possessions of the exarchate of Ravenna, we condemn. In a general way we declare invalid the alienations in whatever manner made by bishops and abbots whether intruded or canonically elected, and also the ordinations conferred by them whether with the consent of the clergy of the Church or simoniacally. We also absolutely forbid any cleric in any way to alienate his prebend or any ecclesiastical benefice. If he has presumed to do this in the past or shall presume to do so in the future, his action shall be null and he shall be subject to the canonical penalties .\n\nLateran I was the first of four Lateran Councils between the years 1123–1215. The first was not very original in its concept, nor one called to meet a pressing theological question. For the most part, Pope Callistus II summoned the council to ratify the various meetings and concords which had been occurring in and around Rome for several years. The most pressing issue was that of the Investiture controversy which had consumed nearly a century of contention and open warfare. At the heart of the question was the ancient right of the Holy Roman Emperor to name the pope as well as bishops and priests. These would be invested with some secular symbol such as a sword or scepter and the spiritual authority represented by a ring, miter and crosier. To an illiterate population, it appeared the bishop or abbot was now the king’s inferior and owed his position to the king. This issue came to the fore in the first part of the eleventh century when Rome and the pope sought autonomy from the Holy Roman Emperor. It had been a central issue in the reign of Pope Gregory VII and his battles with Henry IV, Holy Roman Emperor. The issue was never settled. Years of teaching by Roman trained priests and bishops in Germany had led to an educated generation which rejected the idea of divine right of kings. \nThe Third Lateran Council and the Fourth Lateran Council are generally considered to be of much greater significance than Lateran I. However, Lateran I marked the first time a general and large Council had been held in the West. All previous Councils had been in the East and dominated by Greek theologians and philosophers.\nIn the struggle between Stephen of England and Matilda, the daughter of Henry I of England, the English Church slipped away from the close control the Normans had exercised. Stephen was forced to make many concessions to the Church to gain some element of political control. Historians have largely considered his rule to be a disaster, calling it The Anarchy.\n\nBecause of political necessity, the Holy Roman Emperors were restrained from directly naming bishops in the kingdom. In practicality, the process continued to a certain extent. The issue of separation of Church and State was simply recast in a different direction. Of all the Gregorian Reforms which were embodied by Lateran I, celibacy of the clergy was the most successful. Simony was curtailed. As time progressed, secular interference into the politics of the Church was seen to continue, albeit in different ways from that of the Investiture controversy.\n\nIt has been argued by some historians that the Concordat of Worms and its reiteration by Lateran I were little more than face saving measures by the Church. Henry V, Holy Roman Emperor continued to name bishops within his kingdom. His control over the papacy was definitely abated. At the time, the Concordat of Worms was proclaimed as a great victory for Henry V inside the Holy Roman Empire. It did serve to constrain much of the most recent warfare in and outside the empire. In the end, Henry V died the monarch of a much diminished kingdom.\n\n\n"}
{"id": "11393", "url": "https://en.wikipedia.org/wiki?curid=11393", "title": "Four Noble Truths", "text": "Four Noble Truths\n\nThe Four Noble Truths refer to and express the basic orientation of Buddhism in a short expression: we crave and cling to impermanent states and things, which are \"dukkha\", \"incapable of satisfying\" and painful. This craving keeps us caught in \"samsara\", the endless cycle of repeated rebirth and dying again, and the \"dukkha\" that comes with it. There is, however, a way to end this cycle, namely by attaining \"nirvana\", cessation of craving, whereafter rebirth and associated \"dukkha\" will no longer arise again. This can be accomplished by following the eightfold path, restraining oneself, cultivating discipline, and practicing mindfulness and meditation.\n\nIn short form, the four truths are \"dukkha\", \"samudaya\" (\"arising,\" \"coming together\"), \"nirodha\" (\"cessation,\" \"confinement\"), and \"magga\", the path leading to cessation. As the \"Four Noble Truths\" (Sanskrit: \"catvāri āryasatyāni\"; Pali: \"cattāri ariyasaccāni\"), they are \"the truths of the Noble Ones,\" the truths or realities which are understood by the \"worthy ones\" who have attained nirvana. \n\nIn the \"sutras\", Buddhist religious texts, the four truths have both a symbolic and a propositional function. They represent the awakening and liberation of the Buddha, but also the possibility of liberation for all sentient beings, describing how release from craving is to be reached. In the Pali canon scriptures, the four truths appear in a \"network of teachings,\" as part of \"the entire \"dhamma\" matrix,\" which have to be taken together. They provide a conceptual framework for introducing and explaining Buddhist thought, which has to be personally understood or \"experienced\". \n\nThe function of the four truths, and their importance, developed over time, when \"prajna\", or \"liberating insight,\" came to be regarded as liberating in itself, instead of or in addition to the practice of \"dhyana\", meditation. This \"liberating insight\" gained a prominent place in the sutras, and the four truths came to represent this liberating insight, as part of the enlightenment story of the Buddha.\n\nThe four truths became of central importance in the Theravada tradition of Buddhism, which holds to the idea that insight into the four truths is liberating in itself. They are less prominent in the Mahayana tradition, which sees the higher aims of insight into \"sunyata\", emptiness, and following the Bodhisattva path as central elements in their teachings and practice. The Mahayana tradition reinterpreted the four truths to explain how a liberated being can still be \"pervasively operative in this world.\" Beginning with the exploration of Buddhism by western colonialists in the 19th century and the development of Buddhist modernism, they came to be often presented in the west as the central teaching of Buddhism.\n\nThe four truths are best known from their presentation in the \"Dhammacakkappavattana Sutta\" text, which contains two sets of the four truths, while various other sets can be found in the Pali Canon, a collection of scriptures in the Theravadan Buddhist tradition. According to the Buddhist tradition, the \"Dhammacakkappavattana Sutta\", \"Setting the Wheel of Dhamma in Motion,\" contains the first teachings that the Buddha gave after attaining enlightenment, and liberation from rebirth. According to L. S. Cousins, many scholars are of the view that \"this discourse was identified as the first sermon of the Buddha only at a later date,\" and according to professor of religion Carol S. Anderson the four truths may originally not have been part of this sutta, but were later added in some versions. Within this discourse, the four noble truths are given as follows (\"bhikkus\" is normally translated as \"Buddhist monk\"):\nAccording to this sutra, with the complete comprehension of these four truths release from \"samsara\", the cycle of rebirth, was attained:\nThe comprehension of these four truths by his audience leads to the opening of the \"Dhamma Eye\", that is, the attainment of right vision:\nAccording to K. R. Norman, the Pali canon contains various shortened forms of the four truths, the \"mnemonic set,\" which were \"intended to remind the hearer of the full form of the NTs.\" The earliest form of the mnemonic set was \"dukkham samudayo nirodho magga,\" without the reference to the Pali terms \"sacca\" or \"arya\", which were later added to the formula. The four mnemonic terms can be translated as follows:\n\nThis full set, which is most commonly used in modern expositions, contains grammatical errors, pointing to multiple sources for this set and translation problems within the ancient Buddhist community. Nevertheless, they were considered correct by the Pali tradition, which didn't correct them. According to K.R. Norman, the basic set is as follows:\n\nAccording to L.S. Cousins, the four truths are not restricted to the well-known form where \"dukkha\" is the subject. Other forms take \"the world, the arising of the world\" or \"the āsavas, the arising of the āsavas\" as their subject. According to Cousins, \"the well-known form is simply shorthand for all of the forms.\" \"The world\" refers to the saṅkhāras, that is, all compounded things, or to the six sense spheres.\n\nThe various terms all point to the same basic idea of Buddhism, as described in five skandhas and twelve nidānas: sense-contact with objects leads to sensation, perception, Saṅkhāra ('inclinations', c.q. craving etc.), and consciousness. The \"Twelve Nidānas\" describe how this also leads to rebirth: from sensation comes craving, from craving comes karma, from karma comes rebirth. The aim of the Buddhist path is to reverse this causal chain: when there is no (response to) sensation, there is no craving, no karma, no rebirth.\n\nThe Pali terms \"ariya sacca\" (Sanskrit: \"arya satya\") are commonly translated as \"noble truths\". This translation is a convention started by the earliest translators of Buddhist texts into English. According to K.R. Norman, this is just one of several possible translations. According to Paul Williams,\nThe term \"arya\" was later added to the four truths. The term \"ariya\" (Sanskrit: \"arya\") can be translated as \"noble\", \"not ordinary\", \"valuable\", \"precious\". \"pure\", Paul Williams:\nThe term \"sacca\" (Sanskrit: \"satya\") is a central term in Indian thought and religion. It is typically translated as \"truth\"; but it also means \"that which is in accord with reality\", or \"reality\". According to Rupert Gethin, the four truths are \"four 'true things' or 'realities' whose nature, we are told, the Buddha finally understood on the night of his awakening.\" They function as \"a convenient conceptual framework for making sense of Buddhist thought.\" According to K.R. Norman, probably the best translation is \"the truth[s] of the noble one (the Buddha).\" It is a statement of how things are seen by a Buddha, how things really are when seen correctly. It is the truthful way of seeing, Through not seeing things this way, and behaving accordingly, we suffer.\n\nAccording to Anderson, the four truths have both a symbolic and a propositional function:\nAs a symbol, they refer to the possibility of awakening, as represented by the Buddha, and are of utmost importance:\nAs a proposition, they are part of the matrix or \"network of teachings,\" in which they are \"not particularly central,\" but have an equal place next to other teachings, describing how release from craving is to be reached. A long recognized feature of the Theravada canon is that it lacks an \"overarching and comprehensive structure of the path to \"nibbana\".\" The sutras form a network or matrix, and the four truths appear within this \"network of teachings,\" which have to be taken together. Within this network, \"the four noble truths are one doctrine among others and are not particularly central,\" but are a part of \"the entire \"dhamma\" matrix.\" The four noble truths are be set and learnt in that network, learning \"how the various teachings intersect with each other,\" and refer to the various Buddhist techniques, which are all explicitly and implicitly part of the passages which refer to the four truths. According to Anderson,\nAs a proposition, the four truths defy an exact definition, but refer to and express the basic orientation of Buddhism: clinging and craving to temporary states and things is ultimately unsatisfactory and painful, \"dukkha\", and leads to repeated rebirth and \"redeath.\"\nBy following the Buddhist path, craving and clinging can be confined, peace of mind and real happiness\ncan be attained, and the resulting cycle of repeated rebirth and \"redeath\" will be stopped.\nThe truth of \"dukkha\", \"incapable of satisfying,\" \"painful,\" is the basic insight that life in this \"mundane world,\"\" with its clinging and craving to impermanent states and things\" is \"dukkha\", unsatisfactory and painful. We expect happiness from states and things which are impermanent, and therefore cannot attain real happiness.\n\nThe truth of \"samudaya\", \"arising,\" \"coming together,\" or \"dukkha-samudaya\", the origination or arising of \"dukkha\", is the truth that repeated life in this world, and its associated \"dukkha\" arises, or continues, with taṇhā, \"thirst,\" craving for and clinging to these impermanent states and things.\n\nThe truth of \"nirodha\", cessation, or \"dukkha-nirodha\", the cessation of \"dukkha\", is the truth that \"dukkha\" ceases, or can be confined, when craving and clinging cease or are confined, and nirvana is attained. \"Nirvana\" refers to the moment of attainment itself, and the resulting peace of mind and happiness (\"khlesa-nirvana\"), but also to the final dissolution of the five skandhas at the time of death (\"skandha-nirvana\" or \"parinirvana\"); in the Theravada-tradition, it also refers to a transcendental reality which is \"known at the moment of awakening.\" According to Gethin, \"modern Buddhist usage tends to restrict 'nirvāṇa' to the awakening experience and reserve 'parinirvāṇa' for the death experience. When \"nirvana\" is attained, no more karma is being produced, and rebirth and dissatisfaction will no longer arise again. Cessation is \"nirvana\", \"blowing out,\" and peace of mind. Joseph Goldstein explains:\nThe truth of \"magga\", refers to the path to the cessation of, or liberation from \"dukkha\". By following the Noble Eightfold Path, to \"moksha\", liberation, restraining oneself, cultivating discipline, and practicing mindfulness and meditation, one starts to disengage from craving and clinging to impermanent states and things, and rebirth and dissatisfaction will be ended. The term \"path\" is usually taken to mean the Noble Eightfold Path, but other versions of \"the path\" can also be found in the Nikayas. The Theravada tradition regards insight into the four truths as liberating in itself.\n\nThe well-known eightfold path consists of the understanding that this world is floating and unsatisfying, and how craving keeps us tied to this floating world; a friendly and compassionate attitude to others; a correct way of behaving; mind-control, which means not feeding on negative thoughts, and nurturing positive thoughts; constant awareness of the feelings and responses which arise; and the practice of \"dhyana\", meditation. The tenfold path adds the right (liberating) insight, and liberation from rebirth.\n\nThe four truths are to be internalised, and understood or \"experienced\" personally, to turn them into a lived reality.\n\nThe four truths describe \"dukkha\" and its ending as a means to reach peace of mind in this life, but also as a means to end rebirth. \n\nAccording to Geoffrey Samuel, \"the Four Noble Truths [...] describe the knowledge needed to set out on the path to liberation from rebirth.\" By understanding the four truths, one can stop this clinging and craving, attain a pacified mind, and be freed from this cycle of rebirth and redeath. Patrick Olivelle explains that moksha is a central concept in Indian religions, and \"literally means freedom from samsara.\" Melvin E. Spiro further explains that \"desire is the cause of suffering because desire is the cause of rebirth.\" When desire ceases, rebirth and its accompanying suffering ceases. Peter Harvey explains:\nThe last sermon, the \"Maha-parinibbana Sutta\" (Last Days of the Buddha, Digha Nikaya 16)\", states it as follows:\nSome contemporary teachers tend to explain the four truths psychologically, by taking \"dukkha\" to mean mental anguish in addition to the physical pain of life, and interpreting the four truths as a means to attain happiness in this life. In the contemporary Vipassana movement that emerged out of the Theravada Buddhism, freedom and the \"pursuit of happiness\" have become the main goals, not the end of rebirth, which is hardly mentioned in their teachings. \n\nYet, though freedom and happiness is a part of the Buddhist teachings, these words refer to something different in traditional Asian Buddhism. According to Fronsdal, \"when Asian teachers do talk about freedom, it is primarily in reference to what one is free from—that is, from greed, hate, delusion, grasping, attachment, wrong view, self, and most significantly, rebirth\". \"Nibbana\" is the final freedom, and it has no purpose beyond itself. In contrast, freedom in the creative modern interpretation of Four Noble Truths and the Eightfold Path means living happily and wisely, \"without drastic changes in lifestyle\". Such freedom and happiness is not the goal of Four Noble Truths and related doctrines within traditional Buddhism, but the vipassana teachings in the West make no reference to traditional Theravada doctrines, instead they present only the pragmatic and experiential goals in the form of therapy for the audience's current lives. The creative interpretations are driven in part because the foundational premises of Buddhism do not make sense to audiences outside of Asia. According to Spiro, \"the Buddhist message is not simply a psychological message,\" but an eschatological message.\n\nAccording to Anderson, \"the four truths are recognized as perhaps the most important teaching of the Buddha.\" Yet, as early as 1935 Caroline Rhys Davids wrote that for a teaching so central to Theravada Buddhism, it was missing from critical passages in the Pali canon. According to Gethin, the four truths and the eightfold path are only two lists of \"literally hundreds of similar lists covering the whole range of the theory and practice of ancient Buddhism.\" The position of the four truths within the canon raises questions, and has been investigated throughout the 19th and 20th century.\n\nAccording to academic scholars, inconsistencies in the oldest texts may reveal developments in the oldest teachings. While the Theravada-tradition holds that the Sutta Pitaka is \"the definitive recension of the Buddha-word,\" and Theravadins argue that it is likely that the sutras date back to the Buddha himself, in an unbroken chain of oral transmission, academic scholars have identified many of such inconsistencies, and tried to explain them. Information of the oldest teachings of Buddhism, such as on the Four Noble Truths, has been obtained by analysis of the oldest texts and these inconsitencies, and are a matter of ongoing discussion and research.\n\nAccording to Bronkhorst, the four truths may already have been formulated in earliest Buddhism, but did not have the central place they acquired in later buddhism. According to Anderson, only by the time of the commentaries, in the fifth century CE, did the four truths come to be identified in the Theravada tradition as the central teaching of the Buddha. According to Anderson,\nAccording to Feer and Anderson, the four truths probably entered the Sutta Pitaka from the Vinaya, the rules for monastic order. They were first added to enlightenment-stories which contain the Four Jhanas, replacing terms for \"liberating insight\". From there they were added to the biographical stories of the Buddha.\n\nScholars have noted inconsistencies in the presentations of the Buddha's enlightenment, and the Buddhist path to liberation, in the oldest sutras. These inconsistencies show that the Buddhist teachings evolved, either during the lifetime of the Buddha, or thereafter. According to the Japanese scholar Ui, the four truths are not the earliest representation of the Buddha's enlightenment. Instead, they are a rather late theory on the content of the Buddha's enlightenment. According to Vetter and Bronkhorst, the earliest Buddhist path consisted of a set of practices which culminate in the practice of \"dhyana\", leading to a calm of mind which according to Vetter \"is\" the liberation which is being sought. Later on, \"liberating insight\" came to be regarded as equally liberating. This \"liberating insight\" came to be exemplified by \"prajna\", or the insight in the \"four truths,\" but also by other elements of the Buddhist teachings. According to Vetter and Bronkhorst, this growing importance of \"liberating insight\" was a response to other religious groups in India, which held that a liberating insight was indispensable for \"moksha\", liberation from rebirth. This change is reflected in the canon, where, according to Bronkhorst,\nThe ideas on what exactly constituted this \"liberating insight\" was not fixed but developed over time. According to Bronkhorst, in earliest Buddhism the four truths did not serve as a description of \"liberating insight\". Initially the term \"prajna\" served to denote this \"liberating insight.\" Later on, \"prajna\" was replaced in the suttas by the \"four truths.\" This happened in those texts where practicing the four jhanas preceded the attainment of \"liberating insight,\" and where this practice of the four jhanas then culminates in \"liberating insight.\" This \"liberating insight\" came to be defined as \"insight into the four truths,\" which is presented as the \"liberating insight\" which constituted the awakening, or \"enlightenment\" of the Buddha. When he understood these truths he was \"enlightened\" and liberated, as reflected in Majjhima Nikaya 26:42: \"his taints are destroyed by his seeing with wisdom.\"\n\nOddly, the four truths refer here to the eightfold path as the means to gain liberation, while the attainment of insight into the four truths is portrayed as liberating in itself. According to Bronkhorst, this is an inconsistency which reveals a changes which took place over time in the composition of the sutras. An example of this substitution, and its consequences, is Majjhima Nikaya 36:42-43, which gives an account of the awakening of the Buddha.\n\nThe four truths were superseded by \"pratityasamutpada\", and still later, in the Hinayana schools, by the doctrine of the non-existence of a substantial self or person. Schmithausen states that still other descriptions of this \"liberating insight\" exist in the Buddhist canon:\nIn their symbolic function, the sutras present the insight into the four truths as the culmination of the Buddh's path to awakening. In the \"Vinayapitaka\" and the \"Sutta-pitaka\" they have the same symbolic function, in a reenactment by his listeners of the Buddha's awakening by attaining the \"dhamma-eye\". In contrast, here this insight serves as the starting point to path-entry for his audience. These sutras present a repeated sequence of events:\n\nYet, in other sutras, where the four truths have a propositional function, the comprehension of the four truths destroys the corruptions. They do so in combination with the practice of the \"jhanas\" and the attainment of the divine eye, with which past lifes and the working of frebirth are being seen.\n\nAccording to Anderson, following Schmithausen and Bronkhorst, these two presentations give two different models of the path to liberation, reflecting their function as a symbol and as a proposition. Most likely, the four truths were first associated with the culmination of the path in the destruction of the \"āsavās\", where they substituted the unspecified \"liberating insight\"; as the canon developed, they became more logically associated with the beginning of the Buddhist path.\n\nAccording to Anderson there is a strong tendency within scholarship to present the four truths as the most essential teaching of Buddhism. According to Anderson, the four truths have been simplified and popularized in western writings, due to \"the colonial project of gaining control over Buddhism.\" According to Crosby, the Buddhist teachings are reduced to a \"simple, single rationalized account,\" which has parallels in the reinterpretation of the Buddha in western literature.\n\nThe presentation of the four truths as one of the most important teachings of the Buddha \"has been [done] to reduce the four noble truths to a teaching that is accessible, pliable, and therefore readily appropriated by non-Buddhists.\" There is a great variety of teachings in the Buddhist literature, which may be bewildering for those who are unaware of this variety. The four truths are easily accessible in this regard, and are \"readily [understood] by those outside the Buddhist traditions.\" For example Walpola Rahula's \"What the Buddha Taught\", a widely used introductory text for non-Buddhists, uses the four truths as a framework to present an overview of the Buddhist teachings.\n\nAccording to Harris, the British in the 19th century crafted new representations of Buddhism and the Buddha. 19th century missionaries studied Buddhism, to be more effective in their missionary efforts. The Buddha was de-mystified, and reduced from a \"superhuman\" to a \"compassionate, heroic human,\" serving \"western historical method and the missionary agenda of situating the Buddha firmly below the divine.\" The four truths were discovered by the British by reading the Buddhist texts, and were not immediately granted the central position they later received.\n\nThe writings of British missionaries show a growing emphasis on the four truths as being central to Buddhism, with somewhat different presentations of them. This colonial project had a strong influence on some strands of Buddhism, culminating in socalled Protestant Buddhism, which incorporated several essentially Protestant attitudes regarding religion, such as the emphasis on written texts. According to Gimello, Rahula's book is an example of this Protestant Budhism, and \"was created in an accommodating response to western expectations, and in nearly diametrical opposition to Buddhism as it had actually been practised in traditional Theravada.\"\n\nHendrick Kern proposed in 1882 that the model of the four truths may be an analogy with classical Indian medicine, in which the four truths function as a medical diagnosis, and the Buddha is presented as a physician. Kern's analogy became rather popular, but \"there is not sufficient historical evidence to conclude that th Buddha deliberately drew upon a clearly defined medical model for his fourfold analysis of human pain.\"\n\nAccording to Anderson, those scholars who did not place the four truths at the center of Buddhism, either \"located the four truths in a fuller reading of the Theravada canon and the larger context of South Asian literature,\" or \"located the teaching within an experience of Buddhism as practiced in a contemporary setting.\" According to Anderson, \"these autors suggest a more complex reading of the four noble truths than those who locate the teaching as the key to or as a crucial element within the grand scheme of Buddhism.\"\n\nThe developing Buddhist tradition inserted the four truths, using various formulations, at various sutras. They are being used both as a symbol of all dhammas and the Buddha's awakening, and as a set of propositions which function within a matrix of teachings. According to Anderson, there is no single way to understand the teachings; one teaching may be used to explain another teaching, and vice versa. The teachings form a network, which should be apprehended as such to understand how the various teachings intersect with each other.\n\nThe \"Mahasaccaka Sutta\" (\"The Greater Discourse to Saccaka\", Majjhima Nikaya 36) gives one of several versions of the Buddha's way to liberation. He attains the three knowledges, namely knowledge of his former lifes, knowledge of death and rebirth, and knowledge of the destruction of the taints, the Four Noble Truths. After going through the four dhyanas, and gaining the first two knowledges, the story proceeds:\nBronkhorst dismisses the first two knowledges as later additions, and proceeds to notice that the recognition of the intoxicants is modelled on the four truths. According to Bronkhorst, those are added the bridge the original sequence of \"I directed my mind to the knowledge of the destruction of the intoxicants. My mind was liberated\", which was interrupted by the addition of the four truths. Bronkhorst points out that those do not fit here, since the four truths culminate in the knowledge of the path to be followed, while the Buddha himself is already liberated at that point.\n\nAccording to the Buddhist tradition, the first talk of Gautama Buddha after he attained enlightenment is recorded in the \"Dhammacakkappavattana Sutta\" (\"Setting in Motion the Wheel of Dhamma\", Samyutta Nikaya 56.11). The \"Dhammacakkappavattana Sutta\" provides details on three stages in the understanding of each truth, for a total of twelve insights. The three stages for understanding each truth are:\n\nThese three stages of understanding are emphasized particularly in the Theravada tradition, but they are also recognized by some contemporary Mahayana teachers.\n\nAccording to Cousins, many scholars are of the view that \"this discourse was identified as the first sermon of the Buddha only at a later date.\" According to Stephen Batchelor, the \"Dhammacakkappavattana Sutta\" contains incongruities, and states that\nAccording to Bronkhorst this \"first sermon\" is recorded in several sutras, with important variations. In the Vinaya texts, and in the \"Dhammacakkappavattana Sutta\" which was influenced by the Vinaya texts, the four truths are included, and Kondañña is enlightened when the \"vision of Dhamma\" arises in him: \"whatever is subject to origination is all subject to cessation.\" Yet, in the \"Ariyapariyesanā Sutta\" (\"The Noble Search\", Majjhima Nikaya 26) the four truths are not included, and the Buddha gives the five ascetics personal instructions in turn, two or three of them, while the others go out begging for food. The versions of the \"first sermon\" which include the four truths, such as the \"Dhammacakkappavattana Sutta\", omit this instruction, showing that\nAccording to Bronkhorst, this indicates that the four truths were later added to earlier descriptions of liberation by practicing the four dhyanas, which originally was thought to be sufficient for the destruction of the arsavas. Anderson, following Norman, also thinks that the four truths originally were not part of this sutta, and were later added in some versions.\n\nAccording to Bronkhorst, the \"twelve insights\" are probably also a later addition, born out of unease with the substitution of the general term \"prajna\" for the more specific \"four truths\".\n\nAccording to the Buddhist tradition, the \"Maha-parinibbana Sutta\" (Last Days of the Buddha, Digha Nikaya 16) was given near the end of the Buddha's life. This sutta \"gives a good general idea of the Buddha's Teaching:\"\n\nThe \"Maha-salayatanika Sutta\", Majjhima Nikaya 149:3 plus 149:9, give an alternative presentation of the four truths:\n\nThe Ekavyāvahārika sect emphasized the transcendence of the Buddha, asserting that he was eternally enlightened and essentially non-physical. According to the Ekavyāvahārika, the words of the Buddha were spoken with one transcendent meaning, and the Four Noble Truths are to be understood simultaneously in one moment of insight. According to the Mahīśāsaka sect, the Four Noble Truths should be meditated upon simultaneously.\n\nAccording to Carol Anderson, the four truths have \"a singular position within the Theravada canon and tradition.\" The Theravada tradition regards insight in the four truths as liberating in itself. As Walpola Rahula states, \"when the Truth is seen, all the forces which feverishly produce the continuity of samsara in illusion become calm and incapable of producing any more karma-formations [...] he is free from [...] the 'thirst' for becoming.\" This liberation can be attained in one single moment, when the four truths are understood together. Within the Theravada tradition, great emphasis is placed upon reading and contemplating \"The Discourse That Sets Turning the Wheel of Truth\", and other suttas, as a means to study the four noble truths and put them into practice. For example, Ajahn Sumedho states: \nWithin the Theravada-tradition, three different stances on \"nirvana\" and the question what happens with the \"Arhat\" after death can be found. \"Nirvana\" refers to the cessation of the defilements and the resulting peace of mind and happiness (\"khlesa-nirvana\"); to the final dissolution of the five skandhas at the time of death (\"skandha-nirvana\" or \"parinirvana\"); and to a transcendental reality which is \"known at the moment of awakening.\" According to Gethin, \"modern Buddhist usage tends to restrict 'nirvāṇa' to the awakening experience and reserve 'parinirvāṇa' for the death experience. According to Geisler and Amano, in the \"minimal Theravada interpretation\", \"nirvana\" is a psychological state, which ends with the dissolution of the body and the total extinction of existence. According to Geisler and Amano, the \"orthodox Theravada interpretation\" is that nirvana is a transcendent reality with which the self unites. According to Bronkhorst, while \"Buddhism preached liberation in this life, i.e. before death,\" there was also a tendency in Buddhism to think of liberation happening after death. According to Bronkhorst, this \nAccording to Walpola Rahula, the cessation of \"dukkha\" is \"nirvana\", the \"summum bonum\" of Buddhism, and is attained in this life, not when one dies. \"Nirvana\" is \"perfect freedom, peace, tranquility and happiness,\" and \"Absolute Truth,\" which simply \"is\". Jayatilleke also speaks of \"the attainment of an ultimate reality.\" According to Bhikkhu Bodhi, the \"elimination of craving culminates not only in the extinction of sorrow, anguish and distress, but in the unconditioned freedom of nibbana, which is won with the ending of reapeated rebirth.\" \n\nAccording to Spiro, most (lay) Theravada Buddhists do not aspire for \"nirvana\" and total extinction, but for a pleasurable rebirth in heaven. According to Spiro, this presents a \"serious conflict\" since the Buddhist texts and teaching \"describe life as suffering and hold up nirvana as the \"summum bonum.\"\" In response to this deviation, \"monks and others emphasize that the hope for nirvana is the only legitimate action for Buddhist action.\" Nevertheless, according to Spiro most Burmese lay Buddhists do not aspire for the extinction of existence which is \"nirvana\".\n\nAccording to B.R. Ambedkar, the Indian Buddhist Dalit leader, the four truths were not part of the original teachings of the Buddha, but a later aggregation, due to Hindu influences. According to Ambedkar, total cessation of suffering is an illusion; yet, the Buddhist Middle Path aims at the reduction of suffering and the maximizing of happiness, balancing both sorrow and happiness.\n\nThe four truths are less prominent in the Mahayana traditions, which emphasize insight into sunyata and the Bodhisattva-path as a central elements in their teachings. If the sutras in general are studied at all, it is through various Mahayana commentaries.\n\nAccording to Makransky the Mahayana Bodhisattva ideal created tensions in the explanation of the four truths. In the Mahayana view, a fully enligtened Buddha does not leave \"samsara\", but remains in the world out of compassion with all sentient beings. The four truths, which aim at ending \"samsara\", do not provide a doctrinal basis for this view, and had to be reinterpreted. In the old view, \"klesas\" and \"karma\" are the cause of prolonged existence. According to Makransky, \"[t]o remove those causes was, at physical death, to extinquish one's conditioned existence, hence to end forever one's participation in the world (Third Truth).\" According to Makransky, the question how a liberated being can stiil be \"pervasively operative in this world\" has been \"a seminal source of ongoing doctrinal tension over Buddhahood throughout the history of the Mahayana in India and Tibet.\"\n\nAtisha, in his \"Bodhipathapradīpa\" (\"A Lamp for the Path to Awakening\"), which forms the basis for the Lamrim tradition, discerns three levels of motivation for Buddhist practitioners. At the beginning level of motivation, one strives toward a better life in \"samsara\". At the intermediate level, one strives to a liberation from existence in samsara and the end of all suffering. At the highest level of motivation, one strives after the liberation of all living beings. In his commentary on the text, Tsenshap Serkong Rinpoche explains that the four truths are to be meditated upon as a means of practice for the intermediate level.\n\nAccording to Geshe Tashi Tsering, within Tibetan Buddhism, the four noble truths are studied as part of the Bodhisattva path. They are explained in Mahayana commentaries such as the \"Abhisamayalamkara\", a summary of and commentary on the Prajna Paramitra sutras, where they form part of the lower Hinayana teachings. The truth of the path (the fourth truth) is traditionally presented according to a progressive formula of five paths, rather than as the eightfold path presented in Theravada. According to Tsering, the study of the four truths is combined with the study of the sixteen characteristics of the four noble truths.\n\nSome contemporary Tibetan Buddhist teachers have provided commentary on the \"Dhammacakkappavattana Sutta\" and the noble eightfold path when presenting the dharma to Western students.\n\nNichiren Buddhism is based on the teaching of the Japanese priest and teacher Nichiren, who believed that the Lotus Sūtra contained the essence of all of Gautama Buddha's teachings. The third chapter of the Lotus Sutra states that the Four Noble Truths was the early teaching of the Buddha, while the Dharma of the Lotus is the \"most wonderful, unsurpassed great Dharma.\" The teachings on the four noble truths are a provisional teaching, which Shakyamuni Buddha taught according to the people’s capacity, while the Lotus Sutra is a direct statement of Shakyamuni’s own enlightenment.\n\nFor many western Buddhists, the rebirth doctrine in the Four Noble Truths teaching is a problematic notion. According to Lamb, \"Certain forms of modern western Buddhism [...] see it as purely mythical and thus a dispensable notion.\" According to Coleman, the focus of most vipassana students in the west \"is mainly on meditation practice and a kind of down-to-earth psychological wisdom.\" According to Damien Keown, westerners find \"the ideas of karma and rebirth puzzling.\" According to Gowans, many Western followers and people interested in exploring Buddhism are skeptical and object to the belief in karma and rebirth foundational to the Four Noble Truths. According to Konik,\nAccording to Keown, it is possible to reinterpret the Buddhist doctrines such as the Four Noble Truths, since the final goal and the answer to the problem of suffering is nirvana, and not rebirth. Some Western interpreters have proposed what is sometimes referred to as \"naturalized Buddhism\". It is devoid of rebirth, karma, nirvana, realms of existence, and other concepts of Buddhism, with doctrines such as the Four Noble Truths reformulated and restated in modernistic terms. This \"deflated secular Buddhism\" stresses compassion, impermanence, causality, selfless persons, no Boddhisattvas, no nirvana, no rebirth, and a naturalists approach to well-being of oneself and others.\n\nAccording to Melford Spiro, this approach undermines the Four Noble Truths, for it does not address the existential question for the Buddhist as to \"why live? why not commit suicide, hasten the end of \"dukkha\" in current life by ending life\". In traditional Buddhism, rebirth continues the \"dukkha\" and the path to cessation of \"dukkha\" isn't suicide, but the fourth reality of the Four Noble Truths. The \"naturalized Buddhism\", according to Gowans, is a radical revision to traditional Buddhist thought and practice, and it attacks the structure behind the hopes, needs and rationalization of the realities of human life to traditional Buddhists in East, Southeast and South Asia. According to Keown, it may not be necessary to believe in some of the core Buddhist doctrines to be a Buddhist, but the rebirth, karma, realms of existence and cyclic universe doctrines underpin the Four Noble Truths in Buddhism.\n\nTraditional Buddhist scholars disagree with these modernist Western interpretations. Bhikkhu Bodhi, for example, states that rebirth is an integral part of the Buddhist teachings as found in the sutras, despite the problems that \"modernist interpreters of Buddhism\" seem to have with it. Thanissaro Bhikkhu, as another example, rejects the \"modern argument\" that \"one can still obtain all the results of the practice without having to accept the possibility of rebirth.\" He states, \"rebirth has always been a central teaching in the Buddhist tradition.\"\n\nAccording to Owen Flanagan, the Dalai Lama states that \"Buddhists believe in rebirth\" and that this belief has been common among his followers. However, the Dalai Lama's belief, adds Flanagan, is more sophisticated than ordinary Buddhists, because it is not same as reincarnation, rebirth in Buddhism is envisioned as happening without an assumption of an \"atman, self, soul\", rather through a \"consciousness conceived along the anatman lines\". The doctrine of rebirth is considered mandatory in Tibetan Buddhism, and across many Buddhist sects.\n\nAccording to Christopher Gowans, for \"most ordinary Buddhists, today as well as in the past, their basic moral orientation is governed by belief in karma and rebirth\". Buddhist morality hinges on the hope of well being in this lifetime or in future rebirth, with nirvana (enlightenment) a project for a future lifetime. A denial of karma and rebirth undermines their history, moral orientation and religious foundations. According to Keown, most Buddhists in Asia do accept these traditional teachings, and seek better rebirth.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "11396", "url": "https://en.wikipedia.org/wiki?curid=11396", "title": "French Republican Calendar", "text": "French Republican Calendar\n\nThe French Republican Calendar (), also commonly called the French Revolutionary Calendar (\"calendrier révolutionnaire français\"), was a calendar created and implemented during the French Revolution, and used by the French government for about 12 years from late 1793 to 1805, and for 18 days by the Paris Commune in 1871. The revolutionary system was designed in part to remove all religious and royalist influences from the calendar, and was part of a larger attempt at decimalisation in France (which also included decimal time of day, decimalisation of currency, and metrication).\n\nSylvain Maréchal, prominent anticlerical atheist, published the first edition of his \"Almanach des Honnêtes-gens\" (Almanac of Honest People) in 1788. On pages 14–15 appears a calendar, consisting of twelve months. The first month is \"Mars, ou Princeps\" (March, or First), the last month is \"Février, ou Duodécembre\" (February, or Twelfth). (The months of September [meaning \"the seventh\"] through December [meaning \"the tenth\"] are already numeric names, although their meanings do not match their positions in either the Julian or the Gregorian calendar since the Romans changed the first month of a year from March to January.) The lengths of the months are the same; however, the 10th, 20th, and 30th are singled out of each month as the end of a \"décade\" (group of ten). Individual days were assigned, instead of to the traditional saints, to people noteworthy for mostly secular achievements; December 25 is assigned to both Jesus and Newton.\n\nLater editions of the almanac would switch to the Republican Calendar.\n\nThe days of the French Revolution and Republic saw many efforts to sweep away various trappings of the \"ancien régime\" (the old feudal monarchy); some of these were more successful than others. The new Republican government sought to institute, among other reforms, a new social and legal system, a new system of weights and measures (which became the metric system), and a new calendar. Amid nostalgia for the ancient Roman Republic, the theories of the Enlightenment were at their peak, and the devisers of the new systems looked to nature for their inspiration. Natural constants, multiples of ten, and Latin as well as Ancient Greek derivations formed the fundamental blocks from which the new systems were built.\n\nThe new calendar was created by a commission under the direction of the politician Charles-Gilbert Romme seconded by Claude Joseph Ferry and Charles-François Dupuis. They associated with their work the chemist Louis-Bernard Guyton de Morveau, the mathematician and astronomer Joseph-Louis Lagrange, the astronomer Joseph Jérôme Lefrançois de Lalande, the mathematician Gaspard Monge, the astronomer and naval geographer Alexandre Guy Pingré, and the poet, actor and playwright Fabre d'Églantine, who invented the names of the months, with the help of André Thouin, gardener at the Jardin des Plantes of the Muséum National d'Histoire Naturelle in Paris. As the rapporteur of the commission, Charles-Gilbert Romme presented the new calendar to the Jacobin-controlled National Convention on 23 September 1793, which adopted it on 24 October 1793 and also extended it proleptically to its epoch of 22 September 1792. It is because of his position as rapporteur of the commission that the creation of the republican calendar is attributed to Romme.\n\nThe calendar is often called the \"French Revolutionary Calendar\" because it was created during the Revolution, but this is somewhat of a misnomer. Indeed, there was initially a debate as to whether the calendar should celebrate the Great Revolution, which began in July 1789, or the Republic, which was established in 1792. Immediately following 14 July 1789, papers and pamphlets started calling 1789 year I of Liberty and the following years II and III. It was in 1792, with the practical problem of dating financial transactions, that the legislative assembly was confronted with the problem of the calendar. Originally, the choice of epoch was either 1 January 1789 or 14 July 1789. After some hesitation the assembly decided on 2 January 1792 that all official documents would use the \"era of Liberty\" and that the year IV of Liberty started on 1 January 1792. This usage was modified on 22 September 1792 when the Republic was proclaimed and the Convention decided that all public documents would be dated Year I of the French Republic. The decree of 2 January 1793 stipulated that the year II of the Republic began on 1 January 1793; this was revoked with the introduction of the new calendar, which set 22 September 1793 as the beginning of year II. The establishment of the Republic was used as the epochal date for the calendar; therefore, the calendar commemorates the Republic, not the Revolution. In France, it is known as the \"calendrier républicain\" as well as the \"calendrier révolutionnaire\".\n\nFrench coins of the period naturally used this calendar. Many show the year () in Arabic numbers, although Roman numerals were used on some issues. Year 11 coins typically have a \"XI\" date to avoid confusion with the Roman \"II\".\n\nThe French Revolution is usually considered to have ended with the coup of 18 Brumaire, Year VIII (9 November 1799), the coup d'etat of Napoléon Bonaparte against the established constitutional regime of the \"Directoire\".\n\nThe Concordat of 1801 re-established the Roman Catholic Church as an official institution in France, although not as the state religion of France. The concordat took effect from Easter Sunday, 28 Germinal, Year XI (8 April 1802); it restored the names of the days of the week to the ones from the Gregorian Calendar, and fixed Sunday as the official day of rest and religious celebration. However, the other attributes of the republican calendar, the months, and years, remained as they were.\n\nThe French Republic ended with the coronation of Napoleon I as \"Empereur des Français\" (Emperor of the French) on 11 Frimaire, Year XIII (2 December 1804), but the republican calendar would remain in place for a other year. Napoléon finally abolished the republican calendar with effect from 1 January 1806 (the day after 10 Nivôse Year XIV), a little over twelve years after its introduction. It was, however, used again briefly during the short period of the Paris Commune, 6–23 May 1871 (16 Floréal–3 Prairial Year LXXIX).\n\nSome legal texts that were adopted when the Republican Calendar was officially in use are still in force in France and other nations or territories which at the time were incorporated into revolutionary France, such as present-day Belgium, Luxembourg and the German territories to the west of the Rhine river. These documents have kept their original dates for legal accuracy and citation purposes.\n\nYears appear in writing as Roman numerals (usually), with epoch 22 September 1792, the beginning of the \"Republican Era\" (the day the French First Republic was proclaimed, one day after the Convention abolished the monarchy). As a result, Roman Numeral I indicates the first year of the republic, that is, the year before the calendar actually came into use. By law, the beginning of each year was set at midnight, beginning on the day the apparent autumnal equinox falls at the Paris Observatory.\n\nThere were twelve months, each divided into three ten-day weeks called \"décades\". The tenth day, \"décadi\", replaced Sunday as the day of rest and festivity. The five or six extra days needed to approximate the solar or tropical year were placed after the months at the end of each year and called complementary days. This arrangement was an almost exact copy of the calendar used by the Ancient Egyptians, though in their case the beginning of the year was marked by summer solstice rather than autumn equinox.\n\nA period of four years ending on a leap day was to be called a \"Franciade\". The name \"Olympique\" was originally proposed but changed to Franciade to commemorate the fact that it had taken the revolution four years to establish a republican government in France.\n\nThe leap year was called \"Sextile\", an allusion to the \"bissextile\" leap years of the Julian and Gregorian calendars, because it contained a sixth complementary day.\n\nEach day in the Republican Calendar was divided into ten hours, each hour into 100 decimal minutes, and each decimal minute into 100 decimal seconds. Thus an hour was 144 conventional minutes (more than twice as long as a conventional hour), a minute was 86.4 conventional seconds (44% longer than a conventional minute), and a second was 0.864 conventional seconds (13.6% shorter than a conventional second).\n\nClocks were manufactured to display this decimal time, but it did not catch on. Mandatory use of decimal time was officially suspended 7 April 1795, although some cities continued to use decimal time as late as 1801.\n\nThe numbering of years in the Republican Calendar by Roman numerals ran counter to this general decimalization tendency.\n\nThe Republican calendar year began the day the autumnal equinox occurred in Paris, and had twelve months of 30 days each, which were given new names based on nature, principally having to do with the prevailing weather in and around Paris.\n\nNote: On many printed calendars of Year II (1793–94), the month of \"Thermidor\" was named \"Fervidor\" (from Latin \"fervens\", \"hot\").\n\nMost of the month names were new words coined from French, Latin, or Greek. The endings of the names are grouped by season. \"Dor\" means \"giving\" in Greek.\n\nIn Britain, a contemporary wit mocked the Republican Calendar by calling the months: Wheezy, Sneezy and Freezy; Slippy, Drippy and Nippy; Showery, Flowery and Bowery; Hoppy, Croppy and Poppy. The Scottish historian Thomas Carlyle suggested somewhat more serious English names in his 1837 work \"\", namely Vintagearious, Fogarious, Frostarious, Snowous, Rainous, Windous, Buddal, Floweral, Meadowal, Reapidor, Heatidor, and Fruitidor. Like the French originals, they are neologisms suggesting a meaning related to the season.\n\nThe month is divided into three \"décades\" or \"weeks\" of ten days each, named simply:\n\nDécades were abandoned in Floréal an X (April 1802).\n\nThe Catholic Church used a calendar of saints, which named each day of the year after an associated saint. To reduce the influence of the Church, Fabre d'Églantine introduced a Rural Calendar in which each day of the year had a unique name associated with the rural economy, stated to correspond to the time of year. Every \"décadi\" (ending in 0) was named after an agricultural tool. Each \"quintidi\" (ending in 5) was named for a common animal. The rest of the days were named for \"grain, pasture, trees, roots, flowers, fruits\" and other plants, except for the first month of winter, Nivôse, during which the rest of the days were named after minerals.\n\nFive extra days – six in leap years – were national holidays at the end of every year. These were originally known as \"les sans-culottides\" (after \"sans-culottes\"), but after year III (1795) as \"les jours complémentaires\":\n\nBelow are the Gregorian dates each Republican year (\"an\" in French) began while the calendar was in effect.\n\n\nThe calendar was abolished in the year XIV (1805). After this date, opinions seem to differ on the method by which the leap years would have been determined if the calendar were still in force. There are at least four hypotheses used to convert dates from the Gregorian calendar:\n\nThe following table shows when several years of the Republican Era begin on the Gregorian calendar, according to each of the four above methods:\n\nFor this calendar, the Romme method of calculating leap years is used. Other methods may differ by one day. Time may be cached and therefore not accurate. Decimal time is according to Paris mean time, which is 9 minutes 21 seconds (6.49 decimal minutes) ahead of Greenwich Mean Time. This is as time of page generated ( -- UTC, TMP (Gregorian calendar, conventional time), .(/86400*10 % 10)(/86400*100 % 10)(/86400*1000 % 10)(/86400*10000 % 10)(/86400*100000 % 10) decimal UT, Unix timestamp ) [ (update)]\n\nLeap years in the calendar are a point of great dispute, due to the contradicting statements in the establishing decree stating:\n\nand:\nThese two specifications are incompatible, as leap years defined by the autumnal equinox in Paris do not recur on a regular four year schedule. Thus, the years III, VII, and XI were observed as leap years, and the years XV and XX were also planned as such, even though they were five years apart.\nA fixed arithmetic rule for determining leap years was proposed in the name of the Committee of Public Education by Gilbert Romme on 19 Floréal An III (8 May 1795). The proposed rule was to determine leap years by applying the rules of the Gregorian calendar to the years of the French Republic (years IV, VIII, XII, etc. were to be leap years) except that year 4000 (the last year of ten 400-year periods) should be a common year instead of a leap year. Because he was shortly after sentenced to the guillotine, this proposal was never adopted and the original astronomical rule continued, which excluded any other fixed arithmetic rule. The proposal was intended to avoid uncertain future leap years caused by the inaccurate astronomical knowledge of the 1790s (even today, this statement is still valid due to the uncertainty in ΔT). In particular, the committee noted that the autumnal equinox of year 144 was predicted to occur at 11:59:40 pm local apparent time in Paris, which was closer to midnight than its inherent 3 to 4 minute uncertainty.\n\nThe calendar was abolished by an act dated 22 Fructidor an XIII (9 September 1805) and signed by Napoleon, which referred to a report by Michel-Louis-Étienne Regnaud de Saint-Jean d'Angély and Jean Joseph Mounier, listing two fundamental flaws.\nThe report also noted that the 10-day décade was unpopular and had already been suppressed three years earlier in favor of the 7-day week, removing what was considered by some as one of the calendar's main benefits. The 10-day décade was unpopular with laborers because they received only one full day of rest out of ten, instead of one in seven, although they also got a half-day off on the fifth day. It also, by design, conflicted with Sunday religious observances.\n\nAnother criticism of the calendar was that despite the poetic names of its months, they are tied to the climate and agriculture of metropolitan France and therefore not applicable to France's overseas territories.\n\nThe \"18 Brumaire\" or \"Brumaire\" was the coup d'état of Napoleon Bonaparte on 18 Brumaire An VIII (9 November 1799), which many historians consider as the end of the French Revolution. Karl Marx's 1852 essay \"The 18th Brumaire of Louis Napoléon\" compares the 1851 coup of Louis Napoléon to his uncle's earlier coup.\n\nAnother famous revolutionary date is 9 Thermidor An II (27 July 1794), the date the Convention turned against Robespierre, who, along with others associated with the Mountain, was guillotined the following day. Based on this event, the term \"Thermidorian\" entered the Marxist vocabulary as referring to revolutionaries who destroy the revolution from the inside and turn against its true aims. For example, Leon Trotsky and his followers used this term about Joseph Stalin.\n\nÉmile Zola's novel \"Germinal\" takes its name from the calendar's month of Germinal.\n\nThe seafood dish lobster thermidor was probably named after the 1891 play \"Thermidor\", set during the Revolution.\n\nThe French frigates of the \"Floréal\" class all bear names of Republican months.\n\nThe Convention of 9 Brumaire An III, 30 October 1794, established the École Normale Supérieure. The date appears prominently on the entrance to the school.\n\nThe French composer Fromental Halévy was named after the feast day of 'Fromental' in the Revolutionary Calendar, which occurred on his birthday in year VIII (27 May 1799).\n\nNeil Gaiman's \"The Sandman\" series, included a story called Thermidor which takes place on that month during the French Revolution.\n\nThe \"Liavek\" shared world series uses a calendar which is a direct translation of the French Republican calendar.\n\nSarah Monette's \"Doctrine of Labyrinths\" series borrows the Republican calendar for one of the two competing calendars (their usage splits between social classes) in the fictional city of Mélusine.\n\nAlain Tanner's 1979 film Messidor presents a haphazard summer road trip of two young women in Switzerland.\n\n"}
{"id": "11397", "url": "https://en.wikipedia.org/wiki?curid=11397", "title": "Freeman Dyson", "text": "Freeman Dyson\n\nFreeman John Dyson (born 15 December 1923) is an English-born American theoretical physicist and mathematician, known for his work in quantum electrodynamics, solid-state physics, astronomy and nuclear engineering. He is professor emeritus at the Institute for Advanced Study, a Visitor of Ralston College, and a member of the Board of Sponsors of the Bulletin of the Atomic Scientists.\n\nBorn on 15 December 1923, at Crowthorne in Berkshire, Dyson is the son of the English composer George Dyson, who was later knighted. His mother had a law degree, and after Dyson was born she worked as a social worker. Although not known to be related to the early 20th-century astronomer Frank Watson Dyson, as a small boy Dyson was aware of him and has credited the popularity of an astronomer sharing his surname with helping to spark his own interest in science. At the age of five he calculated the number of atoms in the sun. As a child, he showed an interest in large numbers and in the solar system, and was strongly influenced by the book \"Men of Mathematics\" by Eric Temple Bell. Politically, Dyson says he was \"brought up as a socialist\".\n\nFrom 1936 to 1941, Dyson was a Scholar at Winchester College, where his father was Director of Music. On 25 July 1943, he entered the Operational Research Section (ORS) of the Royal Air Force’s Bomber Command, where he developed analytical methods to help the Royal Air Force bomb German targets during the Second World War. After the war, Dyson was admitted to Trinity College, Cambridge, where he obtained a BA degree in mathematics. From 1946 to 1949, he was a Fellow of his college, occupying rooms just below those of the philosopher Ludwig Wittgenstein, who resigned his professorship in 1947. In 1947, he published two papers in number theory.\n\nIn 1947, Dyson moved to the United States as a Commonwealth Fellow to earn a physics doctorate with Hans Bethe at Cornell University (1947–48). Within a week, however, he had made the acquaintance of Richard Feynman. The budding English physicist recognized the brilliance of the flamboyant American, and attached himself as quickly as possible. He then moved to the Institute for Advanced Study (1948–49), before returning to England (1949–51), where he was a research fellow at the University of Birmingham. Dyson never got his PhD degree.\n\nIn 1949, Dyson demonstrated the equivalence of two then-current formulations of quantum electrodynamics (QED): Richard Feynman's diagrams and the operator method developed by Julian Schwinger and Shin'ichirō Tomonaga. He was the first person after their creator to appreciate the power of Feynman diagrams, and his paper written in 1948 and published in 1949 was the first to make use of them. He said in that paper that Feynman diagrams were not just a computational tool, but a physical theory, and developed rules for the diagrams that completely solved the renormalization problem. Dyson's paper and also his lectures presented Feynman's theories of QED in a form that other physicists could understand, facilitating the physics community's acceptance of Feynman's work. Robert Oppenheimer, in particular, was persuaded by Dyson that Feynman's new theory was as valid as Schwinger's and Tomonaga's. Oppenheimer rewarded Dyson with a lifetime appointment at the Institute for Advanced Study, \"for proving me wrong\", in Oppenheimer's words.\n\nAlso in 1949, in related work, Dyson invented the Dyson series. It was this paper that inspired John Ward to derive his celebrated Ward identity.\n\nIn 1951, Dyson joined the faculty at Cornell as a physics professor, although still lacking a doctorate, and in 1953, he received a permanent post at the Institute for Advanced Study in Princeton, New Jersey, where he has now lived for more than sixty years. In 1957, he became a naturalized citizen of the United States and renounced his British nationality. One reason he gave decades later is that his children born in the US had not been recognized as British subjects.\n\nFrom 1957 to 1961, he worked on the Orion Project, which proposed the possibility of space-flight using nuclear pulse propulsion. A prototype was demonstrated using conventional explosives, but the 1963 Partial Test Ban Treaty (which Dyson was involved in and supported) permitted only underground nuclear testing, so the project was abandoned.\n\nIn 1958, he led the design team for the TRIGA, a small, inherently safe nuclear reactor used throughout the world in hospitals and universities for the production of medical isotopes.\n\nA seminal paper by Dyson came in 1966, when, together with Andrew Lenard and independently of Elliott H. Lieb and Walter Thirring, he proved rigorously that the exclusion principle plays the main role in the stability of bulk matter. Hence, it is not the electromagnetic repulsion between outer-shell orbital electrons which prevents two wood blocks that are left on top of each other from coalescing into a single piece, but rather it is the exclusion principle applied to electrons and protons that generates the classical macroscopic normal force. In condensed matter physics, Dyson also analysed the phase transition of the Ising model in 1 dimension and spin waves.\n\nDyson also did work in a variety of topics in mathematics, such as topology, analysis, number theory and random matrices. There is an interesting story involving random matrices. In 1973, the number theorist Hugh Montgomery was visiting the Institute for Advanced Study and had just made his pair correlation conjecture concerning the distribution of the zeros of the Riemann zeta function. He showed his formula to the mathematician Atle Selberg who said it looked like something in mathematical physics and he should show it to Dyson, which he did. Dyson recognized the formula as the pair correlation function of the Gaussian unitary ensemble, which has been extensively studied by physicists. This suggested that there might be an unexpected connection between the distribution of primes 2,3,5,7,11, ... and the energy levels in the nuclei of heavy elements such as uranium.\n\nAround 1979, Dyson worked with the Institute for Energy Analysis on climate studies. This group, under the direction of Alvin Weinberg, pioneered multidisciplinary climate studies, including a strong biology group. Also during the 1970s, he worked on climate studies conducted by the JASON defense advisory group.\n\nDyson retired from the Institute for Advanced Study in 1994. In 1998, Dyson joined the board of the Solar Electric Light Fund. he was president of the Space Studies Institute, the space research organization founded by Gerard K. O'Neill; he is on its Board of Trustees. Dyson is a long-time member of the JASON group.\n\nDyson has won numerous scientific awards but never a Nobel Prize. Nobel physics laureate Steven Weinberg has said that the Nobel committee has \"fleeced\" Dyson, but Dyson himself remarked in 2009, \"I think it's almost true without exception if you want to win a Nobel Prize, you should have a long attention span, get hold of some deep and important problem and stay with it for ten years. That wasn't my style.\" Dyson is a regular contributor to \"The New York Review of Books\".\n\nIn 2012, he published (with William H. Press) a fundamental new result about the Prisoner's Dilemma in PNAS.\n\nWith his first wife, the Swiss mathematician Verena Huber-Dyson, Dyson had two children, Esther and George. In 1958, he married Imme Jung, a masters runner, and they eventually had four more children, Dorothy, Mia, Rebecca, and Emily Dyson.\n\nDyson's eldest daughter, Esther, is a digital technology consultant and investor; she has been called \"the most influential woman in all the computer world.\" His son George is a historian of science, one of whose books is \"Project Orion: The Atomic Spaceship 1957–1965\".\n\nFriends and colleagues describe Dyson as shy and self-effacing, with a contrarian streak that his friends find refreshing but his intellectual opponents find exasperating. \"I have the sense that when consensus is forming like ice hardening on a lake, Dyson will do his best to chip at the ice\", Steven Weinberg said of him. His friend, the neurologist and author Oliver Sacks, said: \"A favorite word of Freeman's about doing science and being creative is the word 'subversive'. He feels it's rather important not only to be not orthodox, but to be subversive, and he's done that all his life.\" In \"The God Delusion\" (2006), biologist Richard Dawkins criticized Dyson for accepting the religious Templeton Prize in 2000; \"It would be taken as an endorsement of religion by one of the world's most distinguished physicists.\" However, Dyson declared in 2000 that he is a (non-denominational) Christian, and he has disagreed with Dawkins on several occasions, as when he criticized Dawkins' understanding of evolution.\n\nDyson was elected a Fellow of the Royal Society (FRS) in 1952.\n\nDyson was awarded the Lorentz Medal in 1966, Max Planck Medal in 1969, the J. Robert Oppenheimer Memorial Prize in 1970, and the Harvey Prize in 1977.\n\nIn the 1984–85 academic year, he gave the Gifford lectures at Aberdeen, which resulted in the book \"Infinite In All Directions\".\n\nIn 1989, Dyson taught at Duke University as a Fritz London Memorial Lecturer. In the same year, he was elected as an Honorary Fellow of Trinity College, University of Cambridge.\n\nDyson has published a number of collections of speculations and observations about technology, science, and the future. In 1996, he was awarded the Lewis Thomas Prize for Writing about Science.\n\nIn 1993, Dyson was given the Enrico Fermi Award.\n\nIn 1995, he gave the Jerusalem-Harvard Lectures at the Hebrew University of Jerusalem, sponsored jointly by the Hebrew University and Harvard University Press that grew into the book \"Imagined Worlds\".\n\nIn 2000, Dyson was awarded the Templeton Prize for Progress in Religion.\n\nIn 2003, Dyson was awarded the Telluride Tech Festival Award of Technology in Telluride, Colorado.\n\nIn 2011, Dyson was received as one of twenty distinguished Old Wykehamists at the \"Ad Portas\" celebration, the highest honour that Winchester College bestows.\n\nDyson cheerfully admits his record as a prophet is mixed, but \"it is better to be wrong than to be vague.\"\n\n\"To answer the world's material needs, technology has to be not only beautiful but also cheap.\"\n\nDyson favors the dual origin concept: Life first formed cells, then enzymes, and finally, much later, genes. This was first propounded by the Russian Alexander Oparin. J. B. S. Haldane developed the same theory independently. Dyson has simplified things by saying simply that life evolved in two stages, widely separated in time. He regards it as too unlikely that genes could have developed fully blown in one process, because of the biochemistry. He proposes that in a primitive early cell containing ATP and AMP, DNA was invented accidentally because of the similarity of the two. Current cells contain adenosine triphosphate or ATP and adenosine 5'-monophosphate or AMP, which greatly resemble each other but have completely different functions. ATP transports energy around the cell, and AMP is part of RNA and the genetic apparatus. Dyson proposes that in a primitive early cell containing ATP and AMP, RNA and replication were invented accidentally because of the similarity of the two. He suggests that AMP was produced when ATP molecules lost two of their phosphate radicals, and then one cell somewhere performed Eigen's experiment and produced RNA.\n\nUnfortunately there is no direct evidence for the dual origin concept, because once genes developed, they took over, obliterating all traces of the earlier forms of life. In the first origin, the cells were probably just drops of water held together by surface tension, teeming with enzymes and chemical reactions, and a primitive kind of growth or replication. When the liquid drop became too big, it split into two drops. Many complex molecules formed in these \"little city economies\" and the probability that genes would eventually develop in them was much greater than in the prebiotic environment.\n\nIn 1960, Dyson wrote a short paper for the journal \"Science\", entitled \"Search for Artificial Stellar Sources of Infrared Radiation\". In it, he theorized that a technologically advanced extraterrestrial civilization might completely surround its native star with artificial structures in order to maximize the capture of the star's available energy. Eventually, the civilization would completely enclose the star, intercepting electromagnetic radiation with wavelengths from visible light downwards and radiating waste heat outwards as infrared radiation. Therefore, one method of searching for extraterrestrial civilizations would be to look for large objects radiating in the infrared range of the electromagnetic spectrum.\n\nDyson conceived that such structures would be clouds of asteroid-sized space habitats, though science fiction writers have preferred a solid structure: either way, such an artifact is often referred to as a Dyson sphere, although Dyson himself used the term \"shell\". Dyson says that he used the term \"artificial biosphere\" in the article meaning a habitat, not a shape. The general concept of such an energy-transferring shell had been advanced decades earlier by author Olaf Stapledon in his 1937 novel \"Star Maker\", a source that Dyson has credited publicly.\n\nDyson has also proposed the creation of a \"Dyson tree\", a genetically-engineered plant capable of growing on a comet. He suggested that comets could be engineered to contain hollow spaces filled with a breathable atmosphere, thus providing self-sustaining habitats for humanity in the outer solar system.\n\nDyson has been interested in space travel since he was a child, reading such science fiction classics as Olaf Stapledon's \"Star Maker\". As a young man, he worked for General Atomics on the nuclear-powered Orion spacecraft. He hoped Project Orion would put men on Mars by 1965, Saturn by 1970. He's been unhappy for a quarter-century on how the government conducts space travel:\nHe still hopes for cheap space travel, but is resigned to waiting for private entrepreneurs to develop something new—and cheap.\n\nDyson also proposed the use of bioengineered space colonies to colonize the Kuiper Belt on the outer edge of our Solar System. He proposed that habitats could be grown from space hardened spores. The colonies could then be warmed by large reflector plant leaves that could focus the dim, distant sunlight back on the growing colony. This was illustrated by Pat Rawlings on the cover of the National Space Society's Ad Astra magazine.\n\nDyson also has some credits in pure mathematics. His concept \"Dyson's transform\" led to one of the most important lemmas of Olivier Ramaré's theorem that every even integer can be written as a sum of no more than six primes.\n\nThe Dyson series, the formal solution of an explicitly time-dependent Schrödinger equation by iteration, and the corresponding Dyson time-ordering operator formula_1 an entity of basic importance in the mathematical formulation of quantum mechanics, are also named after Dyson.\n\nDyson and Hugh Montgomery discovered together an intriguing connection between quantum physics and Montgomery's pair correlation conjecture about the zeros of the Zeta function. The primes 2, 3, 5, 7, 11, 13, 17, 19, ... are described by the Riemann Zeta function, and Dyson had previously developed a description of quantum physics based on m by m arrays of totally random numbers. What Montgomery and Dyson discovered is that the \"eigenvalues\" of these matrices are spaced apart in exactly the same manner as Montgomery conjectured for the nontrivial zeros of the Zeta function. Andrew Odlyzko has verified the conjecture on a computer, using his Odlyzko–Schönhage algorithm to calculate many zeros. Dyson recognized this connection because of a number-theory question Montgomery asked him. Dyson had published results in number theory in 1947, while a Fellow at Trinity College, Cambridge and so was able to understand Montgomery's question. If Montgomery had not been visiting the Institute for Advanced Study that week, this connection might not have been discovered. There are in nature one, two, and three dimensional quasicrystals. Mathematicians define a quasicrystal as a set of discrete points whose Fourier transform is also a set of discrete points. Andrew Odlyzko has done extensive computations of the Fourier transform of the nontrivial zeros of the Riemann Zeta function, and they seem to form a one dimensional quasicrystal. This would in fact follow from the Riemann hypothesis.\n\nDyson has suggested a kind of cosmic metaphysics of mind. In his book \"Infinite in All Directions\" he writes about three levels of mind: \"The universe shows evidence of the operations of mind on three levels. The first level is the level of elementary physical processes in quantum mechanics. Matter in quantum mechanics is [...] constantly making choices between alternative possibilities according to probabilistic laws. [...] The second level at which we detect the operations of mind is the level of direct human experience. [...] [I]t is reasonable to believe in the existence of a third level of mind, a mental component of the universe. If we believe in this mental component and call it God, then we can say that we are small pieces of God's mental apparatus\" (p. 297).\n\nDyson agrees that anthropogenic global warming exists, and has written that \"[one] of the main causes of warming is the increase of carbon dioxide in the atmosphere resulting from our burning of fossil fuels such as oil and coal and natural gas.\" However, he believes that existing simulation models of climate fail to account for some important factors, and hence the results will contain too much error to reliably predict future trends:\nand, in 2009:\n\nHe is among signatories of a letter to the UN criticizing the IPCC and\nhas also argued against ostracizing scientists whose views depart from the acknowledged mainstream of scientific opinion on climate change, stating that \"heretics\" have historically been an important force in driving scientific progress. \"[H]eretics who question the dogmas are needed ... I am proud to be a heretic. The world always needs heretics to challenge the prevailing orthodoxies.\"\n\nDyson says his views on global warming have been strongly criticized. In reply, he notes that \"[m]y objections to the global warming propaganda are not so much over the technical facts, about which I do not know much, but it’s rather against the way those people behave and the kind of intolerance to criticism that a lot of them have.\"\n\nIn 2008, he endorsed the now common usage of \"global warming\" as synonymous with global anthropogenic climate change, referring to \"measurements that transformed global warming from a vague theoretical speculation into a precise observational science.\"\n\nHe has, however, argued that political efforts to reduce the causes of climate change distract from other global problems that should take priority:\nIn an opinion piece in the Boston Globe of 3 Dec 2015 he wrote,\n\nSince originally taking interest in climate studies in the 1970s, Dyson has suggested that carbon dioxide levels in the atmosphere could be controlled by planting fast-growing trees. He calculates that it would take a trillion trees to remove all carbon from the atmosphere.\n\nIn a 2014 interview, he said that \"What I'm convinced of is that we don't understand climate ... It will take a lot of very hard work before that question is settled.\"\n\nHe is a member of the academic advisory council of the Global Warming Policy Foundation — the climate sceptic think tank chaired by Nigel Lawson.\n\nFrom his 1988 book \"Infinite in All Directions\", he offered some criticism of then current models predicting a devastating nuclear winter in the event of a large-scale nuclear war:\n\nAt the British Bomber Command, Dyson and colleagues proposed ripping out two gun turrets from the RAF Lancaster bombers, to cut the catastrophic losses due to German fighters in the Battle of Berlin. A Lancaster without turrets could fly faster and be much more maneuverable.\nOn hearing the news of the bombing of Hiroshima:\n\nIn 1967, in his capacity as a military adviser Dyson wrote an influential paper on the issue of possible US use of tactical nuclear weapons in the Vietnam War. When a general said in a meeting, \"I think it might be a good idea to throw in a nuke now and then, just to keep the other side guessing...\" Dyson became alarmed and obtained permission to write an objective report discussing the pros and cons of using such weapons from a purely military point of view. (This report, \"Tactical Nuclear Weapons in Southeast Asia\", published by the Institute for Defense Analyses, was obtained, with some redactions, by the Nautilus Institute for Security and Sustainability under the Freedom of Information act in 2002.) It was sufficiently objective that both sides in the debate based their arguments on it. Dyson says that the report showed that, even from a narrow military point of view, the US was better off not using nuclear weapons. Dyson stated on the Dick Cavett show that the use of nuclear weaponry was a bad idea for the US at the time because \"our targets were large and theirs were small.\" (His unstated assumption was that the Soviets would respond by supplying tactical nukes to the other side.)\n\nDyson opposed the Vietnam War, the Gulf War and the invasion of Iraq. He supported Barack Obama in the 2008 US presidential election and \"The New York Times\" has described him as a political liberal. He was one of 29 leading US scientists who wrote a strongly supportive letter to Obama regarding his administration's 2015 nuclear deal with Iran.\n\nWhile teaching for a few weeks in Zurich, Dyson was visited by two officials from the Swiss civil defense authority. Their experts were telling them that fairly simple shelters on a large scale would enable them to survive a nuclear attack, and they wanted confirmation. They knew that Dyson had a security clearance. Dyson reassured them that their shelters would do the job. The US does not build such shelters because it would be contrary to the doctrine of mutual assured destruction, since the US would be able to launch a first strike but survive retaliation.\n\nHe is a nondenominational Christian and has attended various churches from Presbyterian to Roman Catholic. Regarding doctrinal or Christological issues, he has said, \"I am neither a saint nor a theologian. To me, good works are more important than theology.\"\n\nDyson partially disagrees with the famous remark by his fellow physicist Steven Weinberg that \"With or without religion, good people can behave well and bad people can do evil; but for good people to do evil—that takes religion.\"\n\nWhile Dyson has labeled himself a Christian, he identifies himself as agnostic about some of the specifics of his faith. For example, here is a passage from Dyson's review of \"The God of Hope and the End of the World\" from John Polkinghorne:\n\nFreeman Dyson appears in part three of popular American documentary series The Untold History of the United States, which deals with the atomic bombing of Hiroshima.\n\nThe fictional character Gordon Freeman from the \"Half-Life\" video game series is named after Freeman Dyson.\n\nA Dyson sphere was a significant plot device in the \"\" episode \"\".\n\nA \"Freeman Dyson Planetary Spin Motor\" was used in \"The Long Utopia\", the fourth book in the Long Earth series, to destroy a planet.\n\nLarry Niven's classic 1970 sci-fi novel \"Ringworld\" was inspired by Freeman Dyson and his theory of Dyson spheres (see chapter 8, \"Ringworld\"). In it, Dyson is described as \"one of the ancient natural philosophers\".\n\n\n\n\n\n\n\n\n"}
{"id": "11399", "url": "https://en.wikipedia.org/wiki?curid=11399", "title": "Fourth Council of the Lateran", "text": "Fourth Council of the Lateran\n\nThe Fourth Council of the Lateran was convoked by Pope Innocent III with the papal bull \"Vineam domini Sabaoth\" of 19 April 1213, and the Council gathered at Rome's Lateran Palace beginning 11 November 1215. Due to the great length of time between the Council's convocation and meeting, many bishops had the opportunity to attend. It is considered by the Catholic Church to have been the twelfth ecumenical council and is sometimes called the \"Great Council\" or \"General Council of Lateran\" due to the presence of seventy-one patriarchs and metropolitan bishops, four hundred and twelve bishops, and nine hundred abbots and priors together with representatives of several monarchs. \n\nDuring this council, belief in transubstantiation— a Church doctrine which held that the bread and blood offered in the sacrament of the Eucharist becomes the actual blood and body of Christ— was declared obligatory.\n\nLateran IV stands as the high-water mark of the medieval papacy. Its political and ecclesiastical decisions endured down to the Council of Trent while modern historiography has deemed it the most significant papal assembly of the Later Middle Ages. The Fourth Lateran Council was thus the largest and most representative of the medieval councils to that date.\n\nIn summoning the bishops to a general council, Innocent III emphasized that reforms must be made in the Church and that a new crusade to the Holy Land must be launched. He also reminded them that it was not appropriate that their retinue include birds and hunting dogs.\n\nThe agenda laid out in \"Vineam domini Sabaoth\" included reform of the Church, the stamping out of heresy, establishing peace and liberty, and calling for a new crusade. During this council, belief in transubstantiation— a Church doctrine which held that the bread and blood offered in the sacrament of the Eucharist becomes the actual blood and body of Christ— was declared obligatory. The scholarly consensus is that the constitutions were drafted by Innocent III himself.\n\nIn secular matters, the Council confirmed the elevation of Frederick II as Holy Roman Emperor. \n\nThere were violent scenes between the partisans of Simon de Montfort among the French bishops and those of the Count of Toulouse. Raymond VI of Toulouse, his son (afterwards Raymond VII), and Raymond-Roger of Foix attended the Council to dispute the threatened confiscation of their territories; Bishop Foulques and Guy de Montfort (brother of Simon) argued in favour of the confiscation. All of Raymond VI's lands were confiscated, save Provence, which was kept in trust to be restored to his son, Raymond VII. Pierre-Bermond of Sauve's claim to Toulouse was rejected, and Toulouse was awarded to de Montfort; the lordship of Melgueil was separated from Toulouse and entrusted to the bishops of Maguelonne.\n\nCanons presented to the Council included:\n\n\nIn addition, it threatened excommunication to those who supplied ships, arms, and other war materials to the Saracens.\n\nEffective application of the decrees varied according to local conditions and customs.\n\n"}
{"id": "11401", "url": "https://en.wikipedia.org/wiki?curid=11401", "title": "Franconia", "text": "Franconia\n\nFranconia (, also called \"Frankenland\") is a region in Germany, characterised by its culture and language, and may be roughly associated with the areas in which the East Franconian dialect group, locally referred to as \"fränkisch\", is spoken. It commonly refers to the eastern part of the historical Franconian stem duchy, mainly represented by the modern Bavarian administrative districts of Lower, Middle, and Upper Franconia, the adjacent northeastern parts of Heilbronn-Franken in Baden-Württemberg, parts of Thuringia south of the Rennsteig ridge, and small parts of Hesse. However, there is no fixed area that is officially defined as Franconia.\n\nThe German word \"Franken\" - Franconians - also refers to the people group, which is mainly to be found in this region. They are to be distinguished from the Germanic tribe of the Franks and who historically formed their easternmost settlement area. The origins of Franconia lie in the settlement of the Franks from the 6th century in the area probably populated until then mainly by the Elbe Germanic people in the Main river area. Known from the 9th century as \"Francia Orientalis\" (East Francia). in the Middle Ages the region formed much of the eastern part of the Duchy of Franconia and, from 1500, the Franconian Circle. In the course of the restructuring of the south German states by Napoleon after the demise of the Holy Roman Empire, most of Franconia was awarded to Bavaria.\n\nThe German name for Franconia, \"Franken\", comes from the dative plural form of \"Franke,\" a member of the Germanic tribe known as the Franks. The onomatologists largely follow the reference book compiled by early medieval scholar, Saint Isidore of Seville, (c. 560–636) and state that the name derives from an Indo-Germanic root, \"*(s)p(h)ereg-\" (\"avaricious\" or \"ferocious\"). This syllable occurs in the Middle Dutch \"vrac\", \"avaricious\", and old Norwegian \"frakkr\", \"quick, bold\", and means something like \"brave, daring, courageous\". According to this the Franks were thus the \"brave ones\", \"courageous ones\" or \"audacious ones\". From the 9th century the geographical name no longer referred to the whole of France, but increasingly to the region along the River Main, where the name finally stuck.\n\nThe German word \"frank\" in the sense of \"free\" is, by contrast, not an original description of the Franks, but emerged at the time of the Merovingians in the Romanised principality of the Franks. Not until the 15th century was the German word \"frei\" (\"free\") borrowed from the French.\n\nThe Franconian lands lie principally in Bavaria, north and south of the sinuous River Main which, together with the left (southern) Regnitz tributary, including its Rednitz and Pegnitz headstreams, drains most of Franconia. Other large rivers include the upper Werra in Thuringia and the Tauber, as well as the upper Jagst and Kocher streams in the west, both right tributaries of the Neckar. In southern Middle Franconia, the Altmühl flows towards the Danube; the Rhine–Main–Danube Canal crosses the European Watershed. The man-made Franconian Lake District has become a popular destination for day-trippers and tourists.\n\nThe landscape is characterized by numerous \"Mittelgebirge\" ranges of the German Central Uplands. The Western natural border of Franconia is formed by the Spessart and Rhön Mountains, separating it from the former Rhenish Franconian lands around Aschaffenburg (officially part of Lower Franconia), whose inhabitants speak Hessian dialects. To the north rise the Rennsteig ridge of the Thuringian Forest, the Thuringian Highland and the Franconian Forest, the border with the Upper Saxon lands of Thuringia. The Franconian lands include the present-day South Thuringian districts of Schmalkalden-Meiningen, Hildburghausen and Sonneberg, the historical \"Gau\" of Grabfeld, held by the House of Henneberg from the 11th century and later part of the Wettin duchy of Saxe-Meiningen.\n\nIn the east, the Fichtel Mountains lead to Vogtland, Bohemian Egerland (\"Chebsko\") in the Czech Republic, and the Bavarian Upper Palatinate. The hills of the Franconian Jura in the south mark the border with the Upper Bavarian region (\"Altbayern\"), historical Swabia, and the Danube basin. The northern parts of the Upper Bavarian Eichstätt District, territory of the historical Bishopric of Eichstätt, are also counted as part of Franconia.\n\nIn the west, Franconia proper comprises the Tauber Franconia region along the Tauber river, which is largely part of the Main-Tauber-Kreis in Baden-Württemberg. The state's larger Heilbronn-Franken region also includes the adjacent Hohenlohe and Schwäbisch Hall districts. In the city of Heilbronn, beyond the Haller Ebene plateau, South Franconian dialects are spoken. Furthermore, in those easternmost parts of the Neckar-Odenwald-Kreis which had formerly belonged to the Bishopric of Würzburg, the inhabitants have preserved their Franconian identity. Franconian areas in East Hesse along Spessart and Rhön comprise Gersfeld and Ehrenberg.\n\nThe two largest cities of Franconia are Nuremberg and Würzburg. Though located on the southeastern periphery of the area, the Nuremberg metropolitan area is often identified as the economic and cultural centre of Franconia. Further cities in Bavarian Franconia include Fürth, Erlangen, Bayreuth, Bamberg, Aschaffenburg, Schweinfurt, Hof, Coburg, Ansbach and Schwabach. The major (East) Franconian towns in Baden-Württemberg are Schwäbisch Hall on the Kocher — the imperial city declared itself \"Swabian\" in 1442 — and Crailsheim on the Jagst river. The main towns in Thuringia are Suhl and Meiningen.\n\nFranconia may be distinguished from the regions that surround it by its peculiar historical factors and its cultural and especially linguistic characteristics, but it is not a political entity with a fixed or tightly defined area. As a result, it is debated whether some areas belong to Franconia or not. Pointers to a more precise definition of Franconia's boundaries include: the territories covered by the former Duchy of Franconia and former Franconian Circle, the range of the East Franconian dialect group, the common culture and history of the region and the use of the Franconian Rake on coats of arms, flags and seals. However, a sense of popular consciousness of being Franconian is only detectable from the 19th century onwards, which is why the circumstances of the emergence of a Frankish identity are disputed. Franconia has many cultural peculiarities which have been adopted from other regions and further developed.\n\nThe following regions are counted as part of Franconia today: the Bavarian provinces of Lower Franconia, Upper Franconia and Middle Franconia, the municipality of Pyrbaum in the county of Neumarkt in der Oberpfalz, the northwestern part of the Upper Bavarian county of Eichstätt (covering the same area as the old county of Alt-Eichstätt), the East Franconian counties of South Thuringia, parts of Fulda and the Odenwaldkreis in Hesse, the Baden-Württemberg regions of Tauber Franconia and Hohenlohe as well as the region around the Badenian Buchen.\n\nIn individual cases the membership of some areas is disputed. These include the Bavarian language area of Alt-Eichstätt and the Hessian-speaking region around Aschaffenburg, which was never part of the Franconian Imperial Circle. The affiliation of the city of Heilbronn, whose inhabitants do not call themselves Franks, is also controversial. Moreover, the sense of belonging to Franconia in the Frankish-speaking areas of Upper Palatinate, South Thuringia and Hesse is sometimes less marked.\n\nThe region of Franconia is divided among the states of Hesse, Thuringia, Bavaria and Baden-Württemberg. The largest part of Franconia, both by population and area, belongs to the Free State of Bavaria and is divided into the three provinces (\"Regierungsbezirke\") of Middle Franconia (capital: Ansbach), Upper Franconia (capital: Bayreuth) and Lower Franconia (capital: Würzburg). The name of these provinces, as in the case of Upper and Lower Bavaria, refers to their situation with respect to the River Main. Thuse Upper Franconia lies on the upper reaches of the river, Lower Franconia on its lower reaches and Middle Franconia lies in between, although the Main does not flow through Middle Franconia itself. Where the boundaries of these three provinces meet (the 'tripoint') is the \"Dreifrankenstein\" (\"Three Franconias Rock\"). Small parts of Franconia also belong to the provinces of Upper Palatinate and Upper Bavaria.\n\nThe Franconian territories of Baden-Württemberg are the regions of Tauber Franconia and Hohenlohe, which belong to the Heilbronn-Franconia Region with its office in Heilbronn and are part of the Stuttgart Region, and the area around the Badenian Buchen in the Rhein-Neckar Region. The Franconian parts of Thuringia (Henneberg Franconia) lie within the Southwest Thuringia Planning Region. The Franconian regions in Hesse form the smaller parts of the counties of Fulda (Kassel province) and the Odenwaldkreis (Darmstadt province), or lie on the border with Bavaria or Thuringia.\n\nThe two most important rivers of the region are the Main and its primary tributary, the Regnitz. The tributaries of these two rivers in Franconia are the Tauber, Pegnitz, Rednitz and Franconian Saale. Other major rivers in the region are the Jagst and Kocher in Hohenlohe-Franconia, which empty into the Neckar north of Heilbronn in Baden-Württemberg, the Altmühl and the Wörnitz in Middle Franconia, both tributaries of the Danube, and the upper and middle reaches of the Werra, the right-hand headstream of the Weser. In the northeast of Upper Franconia rise two left-hand tributaries of the Elbe: the Saxon Saale and the Eger.\n\nThe Main-Danube Canal connects the Main and Danube across Franconia, running from Bamberg via Nuremberg to Kelheim. It thus complements the Rhine, Main and Danube, helping to ensure a continuous navigable waterway between the North Sea and the Black Sea. In Franconia, there are only a few, often very small, natural lakes. This is due to fact that most natural lakes in Germany are glacial or volcanic in origin, and Franconia escaped both influences in recent earth history. Among the largest waterbodies are reservoirs, which are mostly used as water reserves for the relatively dry landscapes of Franconia. These includes the waters of the Franconian Lake District, which was established in the 1970s and is also a tourist attraction. The heart of these lakes is the Großer Brombachsee, which has an area of 8.7 km² and is thus the largest waterbody in Franconia by surface area.\n\nSeveral Central Upland ranges dominate the Franconian countryside. In the southeast,Franconia is shielded from the rest of Bavaria by the Franconian Jura. In the east, the Fichtel Mountains form the border; in the north are Franconian Forest, the Thuringian Forest, the Rhön Mountains and the Spessart form a kind of natural barrier. To the west are the Franconian Heights and the Swabian-Franconian Forest. In the Franconian part of South Hesse is the Odenwald. Parts of the southern Thuringian Forest border on Franconia. The most important hill ranges in the interior of the region are the Steigerwald and the Franconian Jura with their sub-ranges of Hahnenkamm and Franconian Switzerland. The highest mountain in Franconia is the Schneeberg in the Fichtel Mountains which is . Other well-known mountains include the Ochsenkopf (1,024m), the Kreuzberg (927.8m) and the Hesselberg (689.4m). The outliers of the region include the Hesselberg and the Gleichberge. The lowest point in Franconia is the water level of the River Main in Kahl which lies at a height of 100 metres above sea level.\n\nIn addition to the hill and mountain ranges, there are also several very level areas, including the Middle Franconian Basin and the Hohenlohe Plain. In the south of Franconia are smaller parts of the flat Nördlinger Ries, one of the best preserved impact craters on earth.\n\nFranconia's flora is dominated by deciduous and coniferous forests. Natural forests in Franconia occur mainly in the ranges of the Spessart, Franconian Forest, Odenwald and Steigerwald. The Nuremberg \"Reichswald\" is another great forest, located within the metropolitan region of Nuremberg. Other large areas of forest in the region are the Mönchswald, the Reichsforst in the Fichtel Mountains and the Selb Forest. In the river valleys along the Main and Tauber, the countryside was developed for viticulture. In Spessart there are great oak forests. Also widespread are calcareous grasslands, extensively used pastures on very oligotrophic, poor sites. In particular, the southern Franconian Jura, with the Altmühl Valley, is characterized by poor grassland of this type. Many of these places have been designated as a protected areas.\n\nFranconia has several regions with sandy habitats that are unique for south Germany and are protected as the so-called Sand Belt of Franconia or \"Sandachse Franken\". When the Altmühlsee reservoir was built, a bird island was created and designated as a nature reserve where a variety of birds nest. Another important reserve is the Black Moor in the Rhön, which is one of the most important bog areas in Central Europe. A well known reserve is the Luisenburg Rock Labyrinth at Wunsiedel, a felsenmeer of granite blocks up to several metres across. The establishment of the first Franconian national park in the Steigerwald caused controversy and its designation was rejected in July 2011 by the Bavarian government. The reason was the negative attitude of local population. Conservationists are now demanding protection for parts of the Steigerwald by nominating it for a World Heritage Site. There are several nature parks in Franconia, including the Altmühl Valley Nature Park, which, since 1969, has been one of the largest in Germany.\n\nOther nature parks are the Swabian-Franconian Forest Nature Park in Baden-Württemberg, and the nature parks of Bavarian Rhön, Fichtel Mountains, Franconian Heights, Franconian Forest, Franconian Switzerland-Veldenstein Forest, Haßberge, Spessart and Steigerwald in Bavaria, as well as the Bergstraße-Odenwald Nature Park which straddles Bavaria, Baden-Württemberg and Hesse. Nature parks cover almost half the area of Franconia.\n\nIn 1991 UNESCO recognised the Rhön as a biosphere reserve. Among the most picturesque geotopes in Bavaria, are the Franconian sites of \"Fossa Carolina\", the Twelve Apostle Rocks (\"Zwölf-Apostel-Felsen\"), the Ehrenbürg, the cave ruins of Riesenburg and the lake of Frickenhäuser See. The European Bird Reserves in Franconia are found mainly in uplands like the Steigerwald, in large forests like Nuremberg's Imperial Forest or along rivers like the Altmühl. There are also numerous Special Areas of Conservation and protected landscapes. In Franconia there are very many tufas, raised stream beds near river sources within the karst landscape that are known as 'stone runnels' (\"Steinerne Rinnen\"). There are protected examples at Heidenheim and Wolfsbronn.\n\nLike large parts of Germany, Franconia only has a few large species of wild animal. Forest dwellers include various species of marten, fallow deer, red deer, roe deer, wild boar and fox. In natural areas such as the Fichtel mountains there are populations of lynx and capercaillie, and beaver and otter have grown in numbers. There are occasional sightings of animals that had long been extinct in Central Europe, for example, the wolf.\n\nOnly in the extreme northeast of Franconia and in the Spessart are there Variscan outcrops of the crystalline basement, which were uplifted from below the surface when the Alps exerted a northwards-oriented pressure. These are rocks of pre-Permian vintage, which were folded during various stages of Variscan orogeny in the Late Palaeozoic - before about 380 to 300 million years ago - and, in places, were metamorphosed under high pressure and temperature or were crystallized by ascending magma in the Earth's crust. Rocks which were unchanged or only lightly metamorphosed, because they had been deformed at shallow crustal depths, include the Lower Carboniferous shale and greywacke of Franconian Forest. The Fichtel mountains, the Münchberg Plateau and the Spessart, by contrast, have more metamorphic rocks (phyllite, schist, amphibolite, gneiss). The Fichtel mountains are also characterized by large granite bodies, called post-kinematic plutons which, in the late phase of Variscan orogeny, intruded into the metamorphic rocks. In most cases these are S-type granites whose melting was caused by heated-up sedimentary rocks sunk deep into the Earth's crust. While the Fichtel and Franconian Forest can be assigned to the Saxo-Thuringian Zone of Central European Variscan orogeny, the Spessart belongs to the Central German Crystalline Zone. The Münchberg mass is variously attributed to the Saxo-Thuringian or Moldanubian Zones.\n\nA substantially larger part of the shallow subsurface in Franconia comprises Mesozoic, unmetamorphosed, unfolded rocks of the South German Scarplands. The regional geological element of the South German Scarplands is the Franconian Platform (\"Süddeutsche Großscholle\"). At the so-called Franconian Line, a significant fault line, the Saxo-Thuringian-Moldanubian basement was uplifted in places up to 2000 m above the Franconian Platform. The western two-thirds of Franconia is dominated by the Triassic with its sandstones, siltstones and claystones (so-called siliciclastics) of the bunter sandstone; the limestones and marls of the Muschelkalk and the mixed, but predominantly siliciclastic, sedimentary rocks of the Keuper. In the Rhön, the Triassic rocks are overlain and intruded by volcanic rock (basalts, basanites, phonolites and trachytes) of the Tertiary. The eastern third of Franconia is dominated by the Jurassic rocks of the Franconian Jura, with the dark shales of the Black Jura, the shales and ferruginous sandstones of the Brown Jura and, the weathering-resistant limestones and dolomitic rocks of the White Jura, which stand out from the landscape and form the actual ridge of the Franconian Jura itself. In the Jura, mostly siliciclastic sedimentary rocks formed in the Cretaceous have survived.\n\nThe Mesozoic sediments have been deposited in largescale basin areas. During the Triassic, the Franconian part of these depressions was often part of the mainland, in the Jurassic it was covered for most of the time by a marginal sea of the western Tethys Ocean. At the time when the limestones and dolomites of the White Jura were being deposited, this sea was divided into sponge reefs and intervening lagoons. The reef bodies and the fine-grained lagoon limestones and marls are the material from which the majority of the Franconian Jura is composed today. Following a drop in the sea level towards the end of the Upper Jurassic, larger areas also became part of the mainland at the beginning of the subsequent Cretaceous period. During the Upper Cretaceous, the sea advanced again up to the area of the Franconian Jura. At the end of the Cretaceous, the sea then retreated again from the region. In addition, large parts of South and Central Germany experienced a general uplift -or in areas where the basement had broken through a substantial uplift - the course of formation of the Alps during the Tertiary. Since then, Franconia has been mainly influenced by erosion and weathering (especially in the Jura in the form of karst), which has ultimately led to formation of today's landscapes.\n\nThe oldest macrofossils in Franconia, which are also the oldest in Bavaria, are archaeocyatha, sponge-like, goblet-shaped marine organisms, which were discovered in 2013 in a limestone block of Late Lower Cambrian age, about 520 million years old. The block comes from the vicinity Schwarzenbach am Wald from the so-called Heinersreuth Block Conglomerate (\"Heinersreuther Blockkonglomerat\"), a Lower Carboniferous wildflysch. However, the aforementioned archaeocyathids are not three-dimensional fossils, but two-dimensional thin sections. These thin sections had already been prepared and investigated in the 1970s but the archaeocyathids among them were apparently overlooked at that time.\n\nBetter known and more highly respected fossil finds in Franconia come from the unfolded sedimentary rocks of the Triassic and Jurassic. The bunter sandstone, however, only has a relatively small number of preserved whole fossils. Much more commonly, it contains trace fossils, especially the tetrapod footprints of \"Chirotherium\". The type locality for these animal tracks is Hildburghausen in the Thuringian part of Franconia, where it occurs in the so-called Thuringian Chirotherium Sandstone (\"Thüringer Chirotheriensandstein\", main Middle Bunter Sandstone). \"Chirotherium\" is also found in the Bavarian and Württemberg parts of Franconia. Sites include Aura near Bad Kissingen, Karbach, Gambach and Külsheim. There the deposits are somewhat younger (Upper Bunter Sandstone), and the corresponding stratigraphic interval is called the Franconian Chirotherium Beds (\"Fränkische Chirotherienschichten\"). Among the less significant body fossil records of vertebrates are the procolophonid \"Anomoiodon liliensterni\" from Reurieth in the Thuringian part of Franconia and \"Koiloskiosaurus coburgiensis\" from Mittelberg near Coburg, both from the Thuringian Chirotherium Sandstone, and the Temnospondyle \"Mastodonsaurus ingens\" (possibly identical with the mastodonsaurus, \"Heptasaurus cappelensis\") from the Upper Bunter at Gambach.\n\nAs early as the first decade of the 19th century George, Count of Münster began systematic fossil gathering and digs and in the Upper Muschelkalk at Bayreuth. For example, the Oschenberg hill near Laineck became the type locality of two relatively well-known marine reptiles of the Triassic period, later found in other parts of Central Europe: the \"flat tooth lizard\", \"Placodus\" and the \"false lizard\", \"Nothosaurus\".\n\nIn Franconia's middle Keuper (the Feuerletten) is one of the best known and most common species of dinosaurs of Central Europe: \"Plateosaurus engelhardti\", an early representative of the sauropodomorpha. Its type locality is located at Heroldsberg south of Nuremberg. When the remains of \"Plateosaurus\" were first discovered there in 1834, it was the first discovery of a dinosaur on German soil, and this occurred even before the name \"dinosauria\" was coined. Another important \"Plateosaurus\" find in Franconia was made at Ellingen.\n\nFar more famous than \"Plateosaurus\", \"Placodus\" and \"Nothosaurus\" is the \"Archaeopteryx\", probably the first bird geologically. It was discovered in the southern Franconian Jura, \"inter alia\" at the famous fossil site of Solnhofen in the Solnhofen Platform Limestone (\"Solnhofener Plattenkalk\", (Solnhofen-Formation, early Tithonian, Upper Jurassic). In addition to \"Archaeopteryx\", in the very fine-grained, laminated lagoon limestones are the pterosaur \"Pterodactylus\" and various bony fishes as well as numerous extremely detailed examples of invertebrates e.g. feather stars and dragonflies. Eichstätt is the other \"big\" and similarly famous fossil locality in the Solnhofen Formation, situated on the southern edge of the Jura in Upper Bavaria. Here, as well as \"Archaeopteryx\", the theropod dinosaurs, \"Compsognathus\" and \"Juravenator,\" were found.\n\nAn inglorious episode in the history of paleontology took place in Franconia: fake fossils, known as Beringer's Lying Stones, were acquired in the 1720s by Würzburg doctor and naturalist, Johann Beringer, for a lot of money and then described in a monograph, along with genuine fossils from the Würzburg area. However, it is not entirely clear whether the Beringer forgeries were actually planted or whether he himself was responsible for the fraud.\n\nFranconia has a humid cool temperate transitional climate, which is neither very continental nor very maritime. The average monthly temperatures vary depending on the area between about -1 to -2 °C in January and 17 to 19 °C in August, but may reach a peak of about 35 °C for a few days in the summer, especially in the large cities. The climate of Franconia is sunny and relatively warm. For part of the summer, for example, Lower Franconia is one the sunniest areas in Germany. Daily temperatures in the Bavarian part of Franconia are an average of 0.1 °C higher than the average for Bavaria as a whole. Relatively less rain falls in Franconia, and likewise in the rest of North Bavaria rain than is usual for its geographic location; even summer storms are often less powerful than in other areas of South Germany. In southern Bavaria about 2,000 mm of precipitation falls annually and almost three times as much as in parts of Franconia (about 500–900 mm) in the rain shadow of the Spessart, Rhön and Odenwald.\n\nFranconia, as part of Germany, has a high quality of life. In the \"Worldwide Quality of Living Survey\" by Mercer in 2010, the city of Nuremberg was one of the top 25 cities in the world in terms of quality of life and came sixth in Germany. In environmental ranking Nuremberg came thirteenth in the world and was the best German city In a survey by the German magazine, \"Focus,\" on quality of life in 2014, the districts of Eichstätt and Fürth were among the top positions in the table. In the \"Glücksatlas\" by Deutsche Post Franconia achieved some of the highest scores, but the region slipped in 2013 to 13th place out of 19.\n\nFranconia is named after the Franks, a Germanic tribe who conquered most of Western Europe by the middle of the 8th century. Despite its name, Franconia is not the homeland of the Franks, but rather owes its name to being partially settled by Franks from the Rhineland during the 7th century AD following the defeat of the Alamanni and Thuringians who had dominated the region earlier.\n\nAt the beginning of the 10th century a \"Duchy of Franconia\" () was established within East Francia, which comprised modern Hesse, Palatinate, parts of Baden-Württemberg and most of today's Franconia. After the dissolution of the so-called Stem duchy of Franconia, the Holy Roman Emperors created the Franconian Circle (German \"Fränkischer Reichskreis\") in 1500 to embrace the principalities that grew out of the eastern half of the former duchy. The territory of the Franconian Circle roughly corresponds with modern Franconia. The title of a \"Duke of Franconia\" was claimed by the Würzburg bishops until 1803 and by the kings of Bavaria until 1918. Examples of Franconian cities founded by Frankish noblemen are Würzburg, first mentioned in the 7th century, Ansbach, first mentioned in 748, and Weissenburg, founded in the 7th century.\n\nFossil finds show that the region was already settled by primitive man, \"Homo erectus\", in the middle Ice Age about 600,000 years ago. Probably the oldest human remains in the Bavarian part of Franconia were found in the cave ruins of Hunas at Pommelsbrunn in the county of Nuremberg Land. In the late Bronze Age, the region was probably only sparsely inhabited, as few noble metals occur here and the soils are only moderately fertile. In the subsequent Iron Age (from about 800 B.C.) the Celts become the first nation to be discernible in the region. In northern Franconia they built a chain of hill forts as a line of defence against the Germanii advancing from the north. On the Staffelberg they built a powerful settlement, to which Ptolemy the name \"oppidum Menosgada\", and on the Gleichberge is the largest surviving \"oppidum\" in Central Germany, the Steinsburg. With the increased expansion of Rome in the first century B.C. and the simultaneous advance of the Elbe Germanic tribes from the north, the Celtic culture begain to fall into decline. The southern parts of present-day Franconia soon fell under Roman control; however, most of the region remained in Free Germania. Initially Rome tried extend its direct influence far to the northeast; in the longer term, however, the Germanic-Roman frontier formed further southwest.\nUnder the emperors, Domitian (81-96), Trajan (98-117) and Hadrian (117-138), the Rhaetian Limes was built as a border facing the Germanic tribes to the north. This defensive line ran through the south of Franconia and described an arc across the region whose northernmost point lay at present-day Gunzenhausen. To protect it, the Romans built several forts like Biriciana at Weißenburg, but by the mid-third century, the border could no longer be maintained and by 250 A.D. the Alemanni occupied the areas up to the Danube. Fortified settlements such as the Gelbe Bürg at Dittenheim controlled the new areas. More such Gau forts have been detected north of the former Limes as well. To which tribe their occupants belonged is unknown in most cases. However, it is likely that it was mainly Alemanni and Juthungi in especially in the south. By contrast, it was the Burgundians who settled on the Lower and Middle Main. Many of these hill forts appear to have been destroyed, however, no later than 500 A.D. The reasons are not entirely clear, but it could have been as a result of invasions by the Huns which thus triggered the Great Migration. In many cases, however, it was probably conquest by the Franks that spelt the end of these hilltop settlements.\n\nWith their victories over the heartlands of the Alamanni and Thuringians in the 6th century, the present region of Franconia also fell to the Franks. After the division of the Frankish Empire, East Francia (\"Francia orientialis\") was formed from the territories of the dioceses of Mainz, Worms, Wurzburg and Speyer. Later, the diocese of Bamberg was added. In the 7th century, the Slavs started to populate the northeastern parts of the region from the east, because the area of today's Upper Franconia was very sparsely populated (Bavaria Slavica). However, in the 10th and 11th centuries, they largely gave up their own language and cultural tradition. The majority of the population of Franconia was pagan well into the Early Middle Ages, The first people to spread the Christian faith strongly were wandering Irish Anglo-Saxon monks in the early 7th century. Saint Kilian, who together with his companions, Saint Colman and Saint Totnan are considered to be the apostles to the Franks, suffering martyrdom in Würzburg in the late 7th century, probably did not encounter any pagans in the ducal court. It was probably Saint Boniface who carried the Christian mission deep into the heart of the ordinary population of Franconia.\nIn the mid-9th century the tribal Duchy of Franconia emerged, one of the five tribal or stem duchies of East Francia. The territory of the stem duchy was far bigger than modern Franconia and covered the whole of present-day Hesse, northern Baden-Württemberg, southern Thuringia, large parts of Rhineland-Palatinate and parts of the Franconian provinces in Bavaria. It extended as far west as Speyer, Mainz, and Worms (west of the Rhine) and even included Frankfurt (\"ford of the Franks\"). In the early 10th century, the Babenbergs and Conradines fought for power in Franconia. Ultimately this discord led to the Babenberg Feud which was fuelled and controlled by the crown. The outcome of this feud meant the loss of power for the Babenbergs, but indirectly resulted in the Conradines winning the crown of East Francia. Sometime around 906, Conrad succeeded in establishing his ducal hegemony over Franconia, but when the direct Carolingian male line failed in 911, Conrad was acclaimed King of the Germans, largely because of his weak position in his own duchy. Franconia, like Alamannia was fairly fragmented and the duke's position was often disputed between the chief families. Conrad had granted Franconia to his brother Eberhard on his succession, but when Eberhard rebelled against Otto I in 938, he was deposed from his duchy, which disintegrated in 939 on Eberhard's death into West or Rhenish Franconia ('), and East Franconia (') and was directly subordinated to the Reich. Only after that was the former \"Francia orientalis\" considered to be under the sphere of the bishops of Würzburg as the true Franconia, its territory gradually shrinking to its present area.\n\nMeanwhile, the inhabitants of parts of present-day Upper and Middle Franconia, who were not under the control of Würzburg, probably also considered themselves to be Franks at that time, and certainly their dialect distinguished them from the inhabitants of Bavaria and Swabia.\n\nUnlike the other stem duchies, Franconia became the homeland and power base of East Frankish and German kings after the Ottonians died out in 1024. As a result, in the High Middle Ages, the region did not become a strong regional force such as those which formed in Saxony, Bavaria and Swabia. In 1007, the later canonized Henry II founded the Bishopric of Bamberg and endowed it with rich estates. Bamberg became a favoured \"Pfalz\" and an important centre of the Empire. Because parts of the Bishopric of Würzburg also fell to Bamberg, Würzburg was enfeoffed several royal estates by King Henry II by way of compensation.\nFrom the 12th century Nuremberg Castle was the seat of the Burgraviate of Nuremberg. The burgraviate was ruled from about 1190 by the Zollerns, the Franconian line of the later House of Hohenzollern, which provided the German emperors of the 19th and 20th century. Under the Hohenstaufen kings, Conrad III and Frederick Barbarossa, Franconia became the centre of power in the Empire. During the time when there was no emperor, the Interregnum (1254-1273), some territorial princes became ever more powerful. After the Interregnum, however, the rulers succeeded in re-establishing a stronger royal lordship in Franconia. Franconia soon played an important role again for the monarchy at the time of Rudolf of Habsburg; the itineraries of his successors showing their preference for the Rhine-Main region. In 1376 the Swabian League of Cities was founded and was joined later by several Franconian imperial cities. During the 13th century the Teutonic Order was formed, taking over its first possession in Franconia in 1209, the Bailiwick of Franconia. The foundation of many schools and hospitals and the construction of numerous churches and castles in this area goes back to the work of this Roman Catholic military order. The residence place of the bailiwick was at Ellingen until 1789 when it was transferred to today's Bad Mergentheim. Other orders such as the Knights Templar could not gain a foothold in Franconia; the Order of St. John worked in the Bishopric of Würzburg and had short term commands.\n\nAs of the 13th century, the following states, among others, had formed in the territory of the former Duchy:\n\nOn 2 July 1500 during the reign of Emperor Maximilian I, as part of the Imperial Reform Movement, the Empire was divided into Imperial Circles. This led in 1512 to the formation of the Franconian Circle. Seen from a modern perspective, the Franconian Circle may be viewed as an important basis for the sense of a common Franconian identity that exists today. The Franconian Circle also shaped the geographical limits of the present-day Franconia. In the late Middle Ages and Early Modern Period, the Imperial Circle was severely affected by \"Kleinstaaterei\", the patchwork of tiny states in this region of Germany. As during the late Middle Ages, the bishops of Würzburg used the nominal title of Duke of Franconia during the time of the Imperial Circle. In 1559, the Franconian Circle was given jurisdiction over coinage (\"Münzaufsicht\") and, in 1572, was the only Circle to issue its own police ordinance.\n\nMembers of the Franconian Circle included the imperial cities, the prince-bishoprics, the Bailiwick of Franconia of the Teutonic Order and several counties. The Imperial Knights with their tiny territories, of which there was a particularly large number in Franconia, were outside the Circle assembly and, until 1806, formed the Franconian Knights Circle (\"Fränkischer Ritterkreis\") consisting of six Knights' Cantons. Because the extent of Franconia, already referred to above, is disputed, there were many areas that might be counted as part of Franconia today, that lay outside the Franconian Circle. For example, the area of Aschaffenburg belonged to Electoral Mainz and was a part of the Electoral Rhenish Circle, the area of Coburg belonged to the Upper Saxon Circle and the Heilbronn area to the Swabian Circle. In the 16th century, the College of Franconian Counts was founded to represent the interests of the counts in Franconia.\n\nFranconia played an important role in the spread of the Reformation initiated by Martin Luther, Nuremberg being one of the places where the Luther Bible was printed. The majority of other Franconian imperial cities and imperial knights embraced the new confession. In the course of the counter-reformation several regions of Franconia returned to Catholicism, however, and there was also an increase in witch trials. In addition to Lutheranism, the radical reformatory baptist movement spread early on across the Franconian area. Important Baptist centres were Königsberg and Nuremberg.\nIn 1525, the burden of heavy taxation and socage combined with new, liberal ideas that chimed with the Reformation movement, unleashed the German Peasants' War. The Würzburg area was particularly hard hit with numerous castles and monasteries being burned down. In the end, however, the uprisings were suppressed and for centuries the lowest strata of society were excluded from all political activity.\n\nFrom 1552, Margrave Albert Alcibiades attempted to break the supremacy of the mighty imperial city of Nuremberg and to secularise the ecclesial estates in the Second Margrave War, to create a duchy over which he would rule. Large areas of Franconia were eventually devastated in the fighting until King Ferdinand I together with several dukes and princes decided to overthrow Albert.\n\nIn 1608, the reformed princes merged into a so-called Union within the Empire. In Franconia, the margraves of Ansbach and Bayreuth as well as the imperial cities were part of this alliance. The Catholic side responded in 1609 with a counter-alliance, the League. The conflicts between the two camps ultimately resulted in the Thirty Years' War, which was the greatest strain on the cohesion of the Franconian Circle Initially, Franconia was not a theatre of war, although marauding armies repeatedly crossed its territory. However, in 1631, Swedish troops under Gustavus Adolphus advanced into Franconia and established a large encampment in summer 1632 around Nuremberg. However, the Swedes lost the Battle of the Alte Veste against Wallenstein's troops and eventually withdrew. Franconia was one of the poorest regions in the Empire and lost its imperial political significance. During the course of the war, about half the local population lost their lives. To compensate for these losses about 150,000 displaced Protestants settled in Protestant areas, including Austrian exiles.\nFranconia never developed into a unified territorial state, because the patchwork quilt of small states (\"Kleinstaaterei\") survived the Middle Ages and lasted until the 18th century. As a result, the Franconian Circle had the important task of preserving peace, preventing abuses and to repairing war damage and had a regulatory role in the region until the end of the Holy Roman Empire. Until the War of the Spanish Succession, the Circle had become an almost independent organization and joined the Grand Alliance against Louis XIV as an almost sovereign state. The Circle also developed early forms of a welfare state. It also played a major role in the control of disease during the 16th and 17th centuries. After Charles Alexander abdicated in 1792, the former margraviates of Ansbach and Bayreuth were annexed by Prussia. Karl August Freiherr von Hardenberg was appointed as governor of these areas by Prussia.\n\nMost of modern-day Franconia became part of Bavaria in 1803 thanks to Bavaria's alliance with Napoleon. Culturally it is in many ways different from Bavaria proper (\"Altbayern\", Old Bavaria), however. The ancient name was resurrected in 1837 by Ludwig I of Bavaria. During the Nazi period, Bavaria was broken up into several different Gaue, including Franconia and Main-Franconia.\n\nIn 1803, what was to become the Kingdom of Bavaria was given large parts of Franconia through the enactment of the \"Reichsdeputationshauptschluss\" under pressure from Napoleon for secularization and mediatisation. In 1806, the Act of Confederation led to stronger ties between Bavaria, Württemberg, Baden and other areas with France, whereupon the Holy Roman Empire including the Franconian Circle fell apart. As a reward Bavaria was promised other estates, including the city of Nuremberg. In the so-called \"Rittersturm\" of 1803, Bavaria, Württemberg and Baden seized the territories of the Imperial Knights and Franconian nobility, whoses estates were often no bigger than a few parishes, even though the \"Reichsdeputationshauptschluss\" had not authorised this. In 1806 and 1810, Prussia had to release the territories of Ansbach and Bayreuth, which it had annexed in 1792, to Bavaria, whereby Prussia lost its supremacy in the region.\n\nIn 1814, as a result of the Congress of Vienna,the territories of the Principality of Aschaffenburg and Grand Duchy of Würzburg went to the Kingdom of Bavaria. In order to merge the patchwork quilt of small states in Franconia and Swabia into a greater Bavaria, Maximilian Joseph Montgelas reformed the political structure. Out of this in January 1838 emerged the Franconian provinces with their present names of Middle, Upper and Lower Franconia. . Considerable resentment arose in parts of the Franconian territories over their new membership of Bavaria. There were liberal demands for republican structures which erupted in the revolts of 1848 and 1849 and the Gaibach Festival in 1832. On the one hand the reconciliation policy of the Wittelsbachs and Montgelas' aforementioned policy of unification, and, on the other hand, the inclusion of Bavaria in the German Empire in 1871, which weakened her power Bavaria slightly, the conflict between Franconia and Bavaria eased considerably.\n\nFrom 1836 to 1846, the Kingdom of Bavaria built the Ludwig Canal from Bamberg to Kelheim, which was only abandoned in 1950. However, the canal lost much of its importance shortly after the arrival of the railways. Between 1843 and 1854, the Ludwig South-North Railway was established within Franconia, which ran from Lindau on Lake Constance via Nuremberg, Bamberg and Kulmbach to Hof. The first locomotive to run on German soil steamed 1835 from Nuremberg to Fürth on 7 December 1835.\n\nAfter the First World War the monarchy in Bavaria was abolished, but the state could not agree on a compromise between a Soviet system and parliamentarianism. This caused fighting between the opposing camps and the then prime minister was shot. As a result, the government fled to Bamberg in 1919, where the Bamberg Constitution was adopted while, in Munich, the Bavarian Soviet Republic reigned briefly. In 1919 the Free State of Coburg voted in a referendum against joining Thuringia and was instead united with Bavaria on 1 July 1920.\n\nDuring the Nazi era Nuremberg played a prominent role in the self-expression of the National Socialists as the permanent seat of the Nazi Party. Gunzenhausen made its mark as one of the first towns in the Reich itself to exercise discrimination against the Jewish population. The first Hitler Monument in the German Empire was established there in April 1933. On 25 March 1934 the first Jewish pogrom in Bavaria took place in Gunzenhausen. The attack brought the town negative press coverage worldwide. On 15 September, a Reichstag was specially convened in Nuremberg for the purpose of passing the Nuremberg Laws, under which the antisemitic ideology of the Nazis became a legal basis for such actions.\n\nLike all parts of the German Reich, Franconia was badly affected by Allied air raids. Nuremberg, as a major industrial centre and transportation hub, was hit particularly hard. Between 1940 and 1945 the city was the target of dozens of air raids. Many other places were also affected by air raids. For example, the air raid on 4 December 1944 on Heilbronn and the bombing of Würzburg on 16 March 1945, in which both old towns were almost completely destroyed, was a disaster for both cities. By contrast, the old town of Bamberg was almost completely spared. In order to protect cultural artefacts, the historic art bunker was built below Nuremberg Castle. In the closing stages of the Second World War, at the end of March and April 1945, Franconian towns and cities were captured by formations of the US Army who advanced from the west after the failure of the Battle of the Bulge and Operation Nordwind. The Battle of Nuremberg lasted five days and resulted in at least 901 deaths. The Battle of Crailsheim lasted 16 days, the Battle of Würzburg seven and the Battle of Merkendorf three days.\n\nFollowing the unconditional surrender on 8 May 1945, Bavarian Franconia became part of the American zone of occupation; whilst South Thuringia, with the exception of smaller enclaves like Ostheim, became part of the Soviet zone and the Franconian parts of today's Baden-Württemberg also went to the American zone The most important part of the Allied prosecution programme against leaders of the Nazi regime were the Nuremberg Trials against leaders of the German Empire during the Nazi era, held from 20 November 1945 to 14 April 1949. The Nuremberg Trials are considered a breakthrough for the principle that, for a core set of crimes, there is no immunity from prosecution. For the first time the representatives of a sovereign state were held accountable for their actions. In autumn 1946, the Free State of Bavaria was reconstituted with the enactment of the Bavarian Constitution.\n\nThe state of Württemberg-Baden was founded on 19 September 1945. On 25 April 1952 this state merged with Baden and Württemberg-Hohenzollern (both from the former French occupation zone) to create the present state of Baden-Württemberg. On 1 December 1945 the state of Hesse was founded. Beginning in 1945, refugees and displaced persons from Eastern Europe were settled particularly in rural areas. After 1945, Bavaria and Baden-Württemberg managed the transition from economies that were predominantly agriculture to become leading industrial states in the so-called \"Wirtschaftswunder\". In Lower and Upper Franconia, there was still the problem, however, of the zone along the Inner German Border which was a long way from the markets for its agricultural produce, and was affected by migration and relatively high unemployment, which is why these areas received special support from federal and state governments.\n\nBy contrast, the state of Thuringia was restored by the Soviets in 1945. On 7 October 1949 the German Democratic Republic, commonly known as East Germany, was founded. In 1952 in the course of the 1952 administrative reform in East Germany,the state of Thuringia was relieved of its function The Soviet occupying forces exacted a high level of reparations (especially the dismantling of industrial facilities) which made the initial economic conditions in East Germany very difficult. Along with the failed economic policies of the GDR, this led to a general frustration that fuelled the uprising of 17 June. There were protests in the Franconian territories too, for example in Schmalkalden. The village of Mödlareuth became famous because, for 41 years, it was divided by the Inner German Border and was nicknamed 'Little Berlin. After \"Die Wende\", the fall of the Berlin Wall on 9 November 1989 and reunification on 3 October 1990, made possible mainly by mass demonstrations in East Germany and local exodus of East Germans, the state of Thuringia was reformed with effect from 14 October 1990.\n\nIn the years from 1971 to 1980 an administrative reform was carried out in Bavaria with the aim of creating more efficient municipalities (\"Gemeinden\") and counties (\"Landkreise\"). Against sometimes great protests by the population the number of municipalities was reduced by a third and the number of counties by about a half. Among the changes was the transfer of the Middle Franconian county of Eichstätt to Upper Bavaria. On 18 May 2006, the Bavarian Landtag approved the introduction of Franconia Day (\"Tag der Franken\") in the Franconian territories of the free state.\n\nSince \"Die Wende\", new markets have opened up for the Franconian region of Bavaria in the new (formerly East German) federal states and the Czech Republic, enabling the economy to recover. Today, Franconia is in the centre of the EU (at Oberwestern near Westerngrund; )\n\nWhile Old Bavaria is overwhelmingly Roman Catholic, Franconia is a mixed area. Lower Franconia and the western half of Upper Franconia (Bamberg, Lichtenfels, Kronach) is predominantly Catholic, while most of Middle and the eastern half of Upper Franconia (Bayreuth, Hof, Kulmbach) are predominantly Protestant (Evangelical Church in Germany). The city of Fürth in Middle Franconia historically (before the Nazi era) had a large Jewish population; Henry Kissinger was born there.\n\nA large part of the population of Franconia, which has a population of five million, consider themselves Franconians (\"Franken\", in German homonymous with the name of the historical Franks), a sub-ethnic group of the German people alongside Alemanni, Swabians, Bavarians, Thuringians and Saxons. \nSuch an ethnic identity is generally not shared by other parts of the Franconian-speaking area (members of which may identify as Rhine Franconians (\"Rheinfranken\") or Moselle Franconians (\"Moselfranken\").\n\nThe Free State of Bavaria counts Franconians as one of the \"four tribes of Bavaria\" (\"vier Stämme Bayerns\"), alongside Bavarians, Swabians and Sudeten Germans.\n\nWith the exception of Heilbronn, all cities in Franconia and all towns with a population of over 50,000 are within the Free State of Bavaria. The five cities of Franconia are Nuremberg, Würzburg, Fürth, Heilbronn and Erlangen. In Middle Franconia, in the metropolitan region of Nuremberg there is a densely populated urban area consisting of Nuremberg, Fürth, Erlangen and Schwabach. Nuremberg is the fourteenth largest city in Germany and the second largest in Bavaria.\n\nThe largest settlements in Baden-Württemberg's Franconian region are Heilbronn (pop: 117,531), Schwäbisch Hall (37,096) and Crailsheim (32,417). The largest places in the Thuringian part are Suhl (35,665), Sonneberg (23,796) and Meiningen (20,966). The largest place in the Hessian part of Franconia is Gersfeld with just 5,512 inhabitants. The largest cities within Bavaria are Nuremberg (495,121), Würzburg (124,577), Fürth (118,358) and Erlangen (105,412).\n\nIn the Middle Ages Franconia, with its numerous towns, was separate and not part of other territories such as the Duchy of Bavaria. In the late medieval period it was dominated by mainly smaller towns with a few hundred to a thousand inhabitants, whose size barely distinguished them from the villages. Many towns grew up along large rivers or were founded by the prince-bishops and nobility. Even the Hohenstaufens operated in many towns, most of which later became Imperial Cities with a strong orientation towards Nuremberg. The smallest town in Franconia is Thuringia's Ummerstadt with 487 inhabitants.\n\nGerman is the official language and also the \"lingua franca\". Numerous other languages are spoken that come from other language regions or the native countries of immigrants.\n\nEast Franconian German, the dialect spoken in Franconia, is very different from the Austro-Bavarian dialect. Most Franconians do not call themselves Bavarians. Even though there is no Franconian state, red and white are regarded as the state colours (\"Landesfarben\") of Franconia.\n\nThe proportion of Roman Catholics and Protestants among the population of Franconia is roughly the same, but varies from region to region. Large areas of Middle and Upper Franconia are mainly Protestant. The denominational orientation today still reflects the territorial structure of Franconia at the time of the Franconian Circle. For example, regions, that used to be under the care of the bishoprics of Bamberg, Würzburg and Eichstätt, are mainly Catholic today. On the other hand, all former territories of the imperial cities and the margraviates of Ansbach and Bayreuth have remained mainly Lutheran. The region around the city of Erlangen, which belonged to the Margraviate of Bayreuth, was a refuge for the Huguenots who fled there after the St. Bartholomew's Day massacre in France. Following the success of the Reformation in Nuremberg under Andreas Osiander, it had been an exclusively Protestant imperial city and belonged to the Protestant league of imperial states, the Corpus Evangelicorum, within the \"Reichstag\". Subsequent historical events such as the stream of refugees after the Second World War and the increasing mobility of the population have since blurred denominational geographical boundaries, however.\n\nThe influx of immigrants from Eastern Europe has also seen the establishment of an Orthodox community in Franconia. The Romanian Orthodox Metropolis of Germany, Central and Northern Europe has its headquarters in Nuremberg.\n\nBefore the Nazi era Franconia was as a region with significant Jewish communities, most of whom were Ashkenazi Jews. The first Jewish communities appeared in Franconia in the 12th and 13th centuries and thus later than, for example, in Regensburg. In the Middle Ages, Franconia was a stronghold of Torah studies. But Franconia also began to exclude the Jewish populations particularly early on. For example, there were two Jewish massacres - the Rintfleisch massacres of 1298 and the Armleder Uprising of 1336-1338 - and in the 15th and 16th centuries many cities exiled their Jewish populations, which is why many Jews settled in rural communities. Franconia also rose to early prominence in the discrimination of Jews during the Nazi era. One of the first casualties of the organized Nazi persecution of Jews took place on 21 March in Künzelsau and on 25/26 March 1933 in Creglingen, where police and SA troops under the leadership of \"Standartenführer\" Fritz Klein so-called led a so-called \"weapons search operations\".\nWhilst, in 1818, about 65 per cent of Bavarian Jews lived in the Bavarian part of Franconia, today there are only Jewish communities in Bamberg, Bayreuth, Erlangen, Fürth, Hof, Nuremberg and Würzburg and in Heilbronn in Baden-Württemberg.\n\nAdherents of Islam continue to grow, especially in the larger cities, due to the influx of \"gastarbeiters\" and other immigrants from Muslim countries. As a result, many 'backyard mosques' (\"Hinterhofmoschees\") have sprung up, which are gradually being replaced by purpose-built mosques.\n\nFranconia has almost 300 small breweries. The northwestern parts, the areas around river Main called Franconian wine region also produce a lot of wine. Food typical for the region includes Bratwurst (especially the famous small Nuremberger Bratwurst), \"Schäuferla\" (stewed pork shoulder), Sauerbraten, dumplings, potato salad (typically made with broth), fried carp, Grupfder (seasoned cheese spread), \"Presssack\" (a type of Head cheese: pressed or jellied pork trimmings, like tongue, cheeks, etc.). Lebkuchen are a traditional type of biscuit, and Küchla is a sort of sweet fried dough.\n\nThe tourism industry stresses the romantic character of Franconia. Arguments for this include the picturesque countryside and the many historic buildings that present the long history and culture of the region. In addition the relatively few industrial towns outside of the main industrial cities is underlined. Franconian wine, the rich tradition of beer brewing and local culinary specialities, such as \"Lebküchnerei\" or gingerbread baking, are also seen as a draw that is worth marketing, and which make Franconia a popular tourist destination in Germany. The Romantic Road, the best known German theme route, links several of the tourist high points in western Franconia. The Castle Road runs through the whole Franconian region with its numerous castles and other medieval structures.\n\nThe Franconian countryside is suitable for many sporting activities. For example, the Franconian Way, Celtic Way and the hiking trail network of the Altmühl Valley and the Central Uplands offer a lot of hiking options.\n\nCycling along the large rivers is very popular, for example along the Main Cycleway, which was the first German long distance cycleway to be awarded five starts by the Allgemeiner Deutscher Fahrrad-Club (ADFC). The Tauber Valley Cycleway, a 101 kilometre-long cycle trail in Tauber Franconia, was the second German long distance cycleway to receive five stars.\n\n\n\n"}
{"id": "11402", "url": "https://en.wikipedia.org/wiki?curid=11402", "title": "FileMan", "text": "FileMan\n\nFileMan is a set of utilities written by George Timson in the late 1970s and early 1980s, using MUMPS, which provide a meta-data function for MUMPS applications. The FileMan utilities allow the definition of data structures, menus and security, reports, and forms, allowing someone to set up applications without tremendous experience in the MUMPS programming language.\n\nFileMan was designed to support the complex information storage and processing needs of hospitals. It was based on an active data dictionary that was able to invoke the full interpretive power of the MUMPS language from within a data reference. For example, a field called \"Length of Stay\" could invoke a MUMPS expression that would process the various dates, transfers, and discharges that would then be returned as if it were stored as a fixed data element.\n\nMUMPS differs from many languages in its handling of the null string. A large percentage of the FileMan internal data structures are null strings, in which the information is located in the name of the \"nothing\" being referenced. This approach does not fit the traditional Relational Data Model.\n\nIts first use was in the development of medical applications for the Veterans Administration, now called the Department of Veterans Affairs, a branch of the United States Government.\nSince it was a work created by the US federal government, a copyright cannot be placed on the source code, making the source code in the public domain. Because of this, it has been used for rapid development of applications across a number of organizations, including commercial products.\n\nFileMan may be used standalone, or may be used with the VA Kernel, which provides an operating system neutral environment for applications.\n\n"}
{"id": "11404", "url": "https://en.wikipedia.org/wiki?curid=11404", "title": "United States Foreign Intelligence Surveillance Court", "text": "United States Foreign Intelligence Surveillance Court\n\nThe United States Foreign Intelligence Surveillance Court (FISC, also called the FISA Court) is a U.S. federal court established and authorized under the Foreign Intelligence Surveillance Act of 1978 (FISA) to oversee requests for surveillance warrants against foreign spies inside the United States by federal law enforcement and intelligence agencies. Such requests are made most often by the National Security Agency (NSA) and the Federal Bureau of Investigation (FBI). Congress created FISA and its court as a result of the recommendations by the U.S. Senate's Church Committee. Its powers have evolved to the point that it has been called \"almost a parallel Supreme Court.\"\n\nSince 2009, the court has been relocated to the E. Barrett Prettyman United States Courthouse in Washington, D.C. For roughly thirty years of its history (prior to 2009), it was housed on the sixth floor of the Robert F. Kennedy Department of Justice Building.\n\nIn 2013, a top-secret order issued by the court, which was later leaked to the media from documents culled by Edward Snowden, required a subsidiary of Verizon to provide a daily, on-going feed of all call detail records including those for domestic calls to the NSA.\n\nEach application for one of these surveillance warrants (called a FISA warrant) is made before an individual judge of the court. The court may allow third parties to submit briefs as \"amici curiae\". When the U.S. Attorney General determines that an emergency exists, the Attorney General may authorize the emergency employment of electronic surveillance before obtaining the necessary authorization from the FISC, if the Attorney General or their designee notifies a judge of the court at the time of authorization and applies for a warrant as soon as practicable but not more than seven days after authorization of such surveillance, as required by .\n\nIf an application is denied by one judge of the court, the federal government is not allowed to make the same application to a different judge of the court, but may appeal to the United States Foreign Intelligence Surveillance Court of Review. Such appeals are rare: the first appeal from the FISC to the Court of Review was made in 2002 (\"In re Sealed Case No. 02-001\"), 24 years after the founding of the court.\n\nAlso rare is for FISA warrant requests to be turned down. During the 25 years from 1979 to 2004, 18,742 warrants were granted, while only four were rejected. Fewer than 200 requests had to be modified before being accepted, almost all of them in 2003 and 2004. The four rejected requests were all from 2003, and all four were partially granted after being submitted for reconsideration by the government. Of the requests that had to be modified, few were before the year 2000. During the next eight years, from 2004 to 2012, there were over 15,100 additional warrants granted, and another seven being rejected. Over the entire 33-year period, the FISA court granted 33,942 warrants, with only 12 denials – a rejection rate of 0.03 percent of the total requests. This does not include the number of warrants that were modified by the FISA court. .\nOn May 17, 2002, the court rebuffed Attorney General John Ashcroft, releasing an opinion that alleged that the FBI and Justice Department officials had \"supplied erroneous information to the court\" in more than 75 applications for search warrants and wiretaps, including one signed by FBI Director Louis J. Freeh. Whether this rejection was related to the court starting to require modification of significantly more requests in 2003 is unknown.\n\nOn December 16, 2005, \"The New York Times\" reported that the Bush administration had been conducting surveillance against U.S. citizens without the knowledge of the court since 2002. On December 20, 2005, Judge James Robertson resigned his position with the court, apparently in protest of the secret surveillance, and later, in the wake of the Snowden leaks of 2013, criticized the court-sanctioned expansion of the scope of government surveillance and its being allowed to craft a secret body of law. The government's apparent circumvention of the court started prior to the increase in court-ordered modifications to warrant requests.\n\nIn 2011, the Obama Administration secretly won permission from the Foreign Intelligence Surveillance Court to reverse restrictions on the National Security Agency's use of intercepted phone calls and e-mails, permitting the agency to search deliberately for Americans' communications in its massive databases. The searches take place under a surveillance program Congress authorized in 2008 under Section 702 of the Foreign Intelligence Surveillance Act. Under that law, the target must be a foreigner \"reasonably believed\" to be outside the United States, and the court must approve the targeting procedures in an order good for one year. But a warrant for each target would thus no longer be required. That means that communications with Americans could be picked up without a court first determining that there is probable cause that the people they were talking to were terrorists, spies or \"foreign powers.\" The FISC also extended the length of time that the NSA is allowed to retain intercepted U.S. communications from five years to six years with an extension possible for foreign intelligence or counterintelligence purposes. Both measures were done without public debate or any specific authority from Congress.\n\nBecause of the sensitive nature of its business, the court is a \"secret court\" – its hearings are closed to the public. While records of the proceedings are kept, they also are unavailable to the public, although copies of some records with classified information redacted have been made public. Due to the classified nature of its proceedings, usually only attorneys licensed to practice in front of the US government are permitted to appear before the court. Because of the nature of the matters heard before it, court hearings may need to take place at any time of day or night, weekdays or weekends; thus, at least one judge must be \"on call\" at all times to hear evidence and decide whether or not to issue a warrant.\n\nA heavily redacted version of a 2008 appeal by Yahoo! of an order issued with respect to NSA's PRISM program had been published for the edification of other potential appellants. The identity of the appellant was declassified in June 2013.\n\nThere has been growing criticism of the court since the September 11, 2001 attacks. This is partly because the court sits \"ex parte\" – in other words, in the absence of anyone but the judge and the government present at the hearings. This, combined with the minimal number of requests that are rejected by the court has led experts to characterize it as a rubber stamp (former National Security Agency analyst Russ Tice called it a \"kangaroo court with a rubber stamp\"). The accusation of being a \"rubber stamp\" was rejected by FISA Court president Reggie B. Walton who wrote in a letter to Senator Patrick J. Leahy: \"The annual statistics provided to Congress by the Attorney General … – frequently cited to in press reports as a suggestion that the Court's approval rate of application is over 99% – reflect only the number of \"final\" applications submitted to and acted on by the Court. These statistics do not reflect the fact that many applications are altered to prior or final submission or even withheld from final submission entirely, often after an indication that a judge would not approve them.\" He added: \"There is a rigorous review process of applications submitted by the executive branch, spearheaded initially by five judicial branch lawyers who are national security experts and then by the judges, to ensure that the court’s authorizations comport with what the applicable statutes authorize.\" In a following letter Walton stated that the government had revamped 24.4% of its requests in the face of court questions and demands in time from July 1, 2013 to September 30, 2013. This figure became available after Walton decided in the summer of 2013 that the FISC would begin keeping its own tally of how Justice Department warrant applications for electronic surveillance fared – and would track for the first time when the government withdrew or resubmitted those applications with changes. Some requests are modified by the court but ultimately granted, while the percentage of denied requests is statistically negligible (11 denied requests out of around 34,000 granted in 35 years – equivalent to 0.03%). The accusation that the FISC is a \"rubber stamp\" court was also rejected by Robert S. Litt (General Counsel of Office of the Director of National Intelligence): \"When [the Government] prepares an application for [a section 215 order, it] first submit[s] to the [FISC] what's called a \"read copy\", which the court staff will review and comment on. [A]nd they will almost invariably come back with questions, concerns, problems that they see. And there is an iterative process back and forth between the Government and the [FISC] to take care of those concerns so that at the end of the day, we're confident that we're presenting something that the [FISC] will approve. That is hardly a rubber stamp. It's rather extensive and serious judicial oversight of this process.\"\n\nA 2003 Senate Judiciary Committee \"Interim Report on FBI Oversight in the 107th Congress by the Senate Judiciary Committee: FISA Implementation Failures\" cited the \"unnecessary secrecy\" of the court among its \"most important conclusions\":\nIn a July 2013 interview, Senator and privacy advocate Ron Wyden described the FISC warrant process as \"the most one-sided legal process in the United States\". \"I don't know of any other legal system or court that really doesn't highlight anything except one point of view\", he said. Later in the interview he said Congress should seek to \"diversify some of the thinking on the court\".\n\nElizabeth Gotein, a co-director of the Liberty and National Security Program of the Brennan Center for Justice at the New York University School of Law, has criticized the court as being too compromised to be an impartial tribunal that oversees the work of the NSA and other U.S. intelligence activities. Since the court meets in secret, hears only the arguments of the government prior to deciding a case, and its rulings cannot be appealed or even reviewed by the public, she has argued that: \"Like any other group that meets in secret behind closed doors with only one constituency appearing before them, they're subject to capture and bias.\"\nA related bias of the court results from what critics such as Julian Sanchez, a scholar at the Cato Institute, have described as the near certainty of the polarization or groupthink of the judges of the court. Since all of the judges are appointed by the same person (the Chief Justice of the United States), as of 2013 nearly all currently serving judges are of the same political party (the Republican Party), hear no opposing testimony and feel no pressure from colleagues or the public to moderate their rulings, group polarization is almost a certainty. \"There's the real possibility that these judges become more extreme over time, even when they had only a mild bias to begin with\", Sanchez said.\n\nThe court's judges are appointed solely by the Chief Justice of the United States without confirmation or oversight by the U.S. Congress. This gives the chief justice the ability to appoint like-minded judges and create a court without diversity. \"The judges are hand-picked by someone who, through his votes on the Supreme Court, we have come to learn has a particular view on civil liberties and law enforcement\", Theodore Ruger, a professor at the University of Pennsylvania Law School, said with respect to Chief Justice John G. Roberts. \"The way the FISA is set up, it gives him unchecked authority to put judges on the court who feel the same way he does.\" And Stephen Vladeck, a law professor at the University of Texas School of Law, added, \"Since FISA was enacted in 1978, we've had three chief justices, and they have all been conservative Republicans, so I think one can worry that there is insufficient diversity.\" Since May 2014, however, four of the five judges appointed by Chief Justice Roberts to the FISA Court were appointed to their prior federal court positions by Presidents Bill Clinton and Barack Obama.\n\nThere are some reform proposals. Senator Richard Blumenthal from Connecticut proposed that each of the chief judges of the 12 major appeals courts select a district judge for the surveillance court; the chief justice would still pick the review panel that hears rare appeals of the court's decisions, but six other Supreme Court justices would have to sign off. Another proposal authored by Representative Adam Schiff of California would give the president the power to nominate judges for the court, subject to Senate approval, while Representative Steve Cohen proposed that Congressional leaders pick eight of the court's members.\n\nStephen Vladeck, a professor at the University of Texas School of Law, has argued that, without having to seek the approval of the court (which he has said merely reviews certifications to ensure that they and not the surveillance itself comply with the various statutory requirements), the U.S. Attorney General and the Director of National Intelligence can engage in sweeping programmatic surveillance for one year at a time. There are procedures used by the NSA to target non-U.S. persons and procedures used by the NSA to minimize data collection from U.S. persons. These court-approved policies allow the NSA to do the following:\n\nJameel Jaffer, the ACLU's deputy legal director, said in light of revelations that the government secured telephone records from Verizon and Internet data from some of the largest providers that safeguards that are supposed to be protecting individual privacy are not working. Elizabeth Goitein, co-director of the Liberty and National Security Program at the Brennan Center for Justice in New York, wrote in the Wall Street Journal that when courts make mistakes, the losing party has the right to appeal and the erroneous decision is reversed. \"That process cannot happen when a secret court considers a case with only one party before it.\"\n\nAccording to \"The Guardian\", \"The broad scope of the court orders, and the nature of the procedures set out in the documents, appear to clash with assurances from President Obama and senior intelligence officials that the NSA could not access Americans' call or email information without warrants\". Glenn Greenwald, who published details of the PRISM surveillance program, explained:\n\nDeputy Attorney General James M. Cole and NSA Deputy Director John C. Inglis cited the court's oversight in defending the constitutionality of the NSA's surveillance activities before during a hearing before the House Judiciary Committee in July 2013. Representative Jerrold Nadler, challenged Cole's defense of the program's constitutionality, and he said the secrecy in which the court functioned negated the validity of its review. \"The fact that a secret court unaccountable to public knowledge of what it's doing … may join you in misusing or abusing the statutes is of no comfort whatsoever\", Nadler said. Orin Kerr, a law professor at George Washington University, said the secrecy that comes along with national security makes it difficult to evaluate how the administration carries out the wide authority Congress has given it. \"FISA court judges hear all of this and they think it’s legal,\" Kerr said. \"What we really don't know, though, are what the FISA court’s opinions say.\"\n\nIn July 2013, \"The New York Times\" published disclosures from anonymous government whistleblowers of secret law written by the court holding that vast collections of data on all Americans (even those not connected in any way to foreign enemies) amassed by the NSA do not violate the warrant requirements of Fourth Amendment to the U.S. Constitution. It reported that anyone suspected of being involved in nuclear proliferation, espionage or cyber-attacks, according to the court, may be considered a legitimate target for warrantless surveillance. Acting like a parallel U.S. Supreme Court, the court greatly broadened the \"special-needs\" exception to do so.\n\nThe newspaper reported that in \"more than a dozen classified rulings, the nation's surveillance court has created a secret body of law giving the National Security Agency the power to amass vast collections of data on Americans\". It also wrote, with respect to the court:\n\nThe \"special-needs\" doctrine is an exemption to the Fourth Amendment's Warrants Clause which commands that \"no Warrants shall issue, but upon probable cause, supported by Oath or affirmation, and particularly describing the place to be searched, and the persons or things to be and seized\". The U.S. Supreme Court has recognized an exemption to the Warrants Clause \"outside the foreign intelligence context, in so-called 'special-needs' cases. In those cases, the Court excused compliance with the Warrant Clause when the purpose behind the governmental action went beyond routine law enforcement and insisting upon a warrant would materially interfere with the accomplishment of that purpose. See, \"Vernonia School District 47J v. Acton\", 515 U.S. 646, 653 (1995) (upholding drug testing of highschool athletes and explaining that the exception to the warrant requirement applied \"when special needs, beyond the normal need for law enforcement, make the warrant and probable-cause requirement[s] impracticable (quoting \"Griffin v. Wisconsin\", 483 U.S. 868, 873 (1987))); \"Skinner v. Ry. Labor Execs. Ass'n\", 489 U.S . 602, 620 (1989) (upholding regulations instituting drug and alcohol testing of railroad workers for safety reasons); cf. \"Terry v. Ohio\", 392 U.S . 1, 23-24 (1968) (upholding pat-frisk for weapons to protect officer safety during investigatory stop)\". The U.S. Foreign Intelligence Surveillance Court of Review concluded on August 22, 2008, in the case \"In re Directives [redacted text] Pursuant to Section 105B of the Foreign Intelligence Surveillance Act\", that the \"special-needs\" doctrine applied by analogy to justify a foreign intelligence exception to the warrant requirement for surveillance undertaken for national security purposes and directed at a foreign power or an agent of a foreign power reasonably believed to be located outside the U.S.\n\nJames Robertson a former judge for the U.S. District Court for the District of Columbia, who, in 2004, ruled against the Bush administration in the \"Hamdan v. Rumsfeld\" case, and also served on the FISC for three years between 2002 and 2005 said he was \"frankly stunned\" by the newspaper's report that court rulings had created a new body of law broadening the ability of the NSA to use its surveillance programs to target not only terrorists but suspects in cases involving espionage, cyberattacks and weapons of mass destruction. Geoffrey R. Stone, a professor of constitutional law at the University of Chicago, said he was troubled by the idea that the court is creating a significant body of law without hearing from anyone outside the government, forgoing the adversarial system that is a staple of the American justice system. He said, \"That whole notion is missing in this process\".\n\nThe court concluded that mass collection of telephone metadata (including the time of phone calls and numbers dialed) does not violate the Fourth Amendment as long as the government establishes a valid reason under national security regulations before taking the next step of actually examining the contents of an American's communications. This concept is rooted partly in the special needs doctrine. \"The basic idea is that it's O.K. to create this huge pond of data\", an unnamed U.S. official said, \"but you have to establish a reason to stick your pole in the water and start fishing\". Under the new procedures passed by the U.S. Congress in the FISA Amendments Act of 2008, even the collection of metadata must be considered \"relevant\" to a terrorism investigation or other intelligence activities. The court has indicated that while individual pieces of data may not appear \"relevant\" to a terrorism investigation, the total picture that the bits of data create may in fact be relevant, according to U.S. officials with knowledge of the decisions.\n\nA secret ruling made by the court that redefined the single word \"relevant\" enabled the NSA to gather phone data on millions of Americans. In classified orders starting in the mid-2000s, the court accepted that \"relevant\" could be broadened to permit an entire database of records on millions of people, in contrast to a more conservative interpretation widely applied in criminal cases, in which only some of those records would likely be allowed. Under the Patriot Act, the Federal Bureau of Investigation can require businesses to hand over \"tangible things\", including \"records\", as long as the FBI shows it is reasonable to believe the things are \"relevant to an authorized investigation\" into international terrorism or foreign intelligence activities. The history of the word \"relevant\" is key to understanding that passage. The Supreme Court in 1991 said things are \"relevant\" if there is a \"reasonable possibility\" that they will produce information related to the subject of the investigation. In criminal cases, courts previously have found that very large sets of information did not meet the relevance standard because significant portions innocent people's information would not be pertinent. But the court has developed separate precedents, centered on the idea that investigations to prevent national-security threats are different from ordinary criminal cases. The court's rulings on such matters are classified and almost impossible to challenge because of the secret nature of the proceedings. According to the court, the special nature of national-security and terrorism-prevention cases means \"relevant\" can have a broader meaning for those investigations, say people familiar with the rulings.\n\nPeople familiar with the system that uses phone records in investigations have said that the court's novel legal theories allow the system to include bulk phone records, as long as there are privacy safeguards to limit searches. NSA analysts may query the database only \"when there is a reasonable suspicion, based on specific facts, that the particular basis for the query is associated with a foreign terrorist organization\", according to Director of National Intelligence James Clapper. The NSA database includes data about people's phone calls numbers dialed, how long a call lasted but not the actual conversations. According to Supreme Court rulings, a phone call's content is covered by the Constitution's Fourth Amendment, which restricts unreasonable searches, but the other types of data are not.\n\n\"Relevant\" has long been a broad standard, but the way the court is interpreting it, to mean, in effect, \"everything\", is new, said Mark Eckenwiler, a lawyer who until December 2012 was the Justice Department's primary authority on federal criminal surveillance law. \"I think it's a stretch\" of previous federal legal interpretations, said Eckenwiler. If a federal attorney \"served a grand-jury subpoena for such a broad class of records in a criminal investigation, he or she would be laughed out of court\". Given the traditional legal definition of relevant, Timothy Edgar, a former top privacy lawyer at the Office of the Director of National Intelligence and the National Security Council in the Bush and Obama administrations, noted it is \"a fair point\" to say that someone reading the law might believe it refers to \"individualized requests\" or \"requests in small batches, rather than in bulk database form\". From that standpoint, Edgar said, the reinterpretation of relevant amounts to \"secret law\".\n\nIn June 2013, a copy of a top-secret warrant, issued by the court on April 25, 2013, was leaked to London's \"The Guardian\" newspaper by NSA contractor Edward Snowden. That warrant orders Verizon Business Network Services to provide a daily feed to the NSA containing \"telephony metadata\" – comprehensive call detail records, including location data – about all calls in its system, including those that occur \"wholly within the United States, including local telephone calls.\" The Obama administration published on July 31, 2013 a FISA Court ruling supporting an earlier order requiring a Verizon subsidiary to turn over all of its customers' phone logs for a three-month period, with rules that must be followed when accessing the data.\n\nThe document leaked to \"The Guardian\" acted as a \"smoking gun\" and sparked a public outcry of criticism and complaints that the court exceeded its authority and violated the Fourth Amendment by issuing general warrants. \"The Washington Post\" then reported that it knew of other orders, and that the court had been issuing such orders, to all telecommunication companies, every three months since May 24, 2006.\n\nSince the telephone metadata program was revealed, the intelligence community, some members of Congress, and the Obama administration have defended its legality and use. Most of these defenses involve the 1979 Supreme Court decision \"Smith v. Maryland\" which established that people do not have a \"reasonable expectation\" of privacy for electronic metadata held by third parties like a cellphone provider. That data is not considered \"content\", theoretically giving law enforcement more flexibility in collecting it.\n\nOn July 19, 2013, the court renewed the permission for the NSA to collect Verizon customer records en masse. The U.S. government was relying on a part of American case law known as the \"third-party doctrine\". This notion said that when a person has voluntarily disclosed information to a third party — in this case, the telephony metadata — the customer no longer has a reasonable expectation of privacy over the numbers dialed nor their duration. Therefore, this doctrine argued, such metadata can be accessed by law enforcement with essentially no problem. The content of communications are, however, subject to the Fourth Amendment. The Foreign Intelligence Surveillance Court held in October 2011, citing multiple Supreme Court precedents, that the Fourth Amendment prohibition against unreasonable searches and seizures applies to the contents of all communications, whatever the means, because \"a person's private communications are akin to personal papers.\"\n\nFormer FISC judge Colleen Kollar-Kotelly, who provided the legal foundation for the NSA amassing a database of all Americans' phone records, told associates in the summer of 2013 that she wanted her legal argument out. Rulings for the plaintiff in cases brought by the ACLU on September 10 and 12, 2013, prompted James Clapper to concede that the government had overreached in its covert surveillance under part 215 of FISA and that the Act would likely be amended to reflect Congressional concern.\n\nThe American Civil Liberties Union, a customer of Verizon, asked on November 22, 2013 a federal district court in Lower Manhattan, New York to end the NSA phone call data collection program. The ACLU argued that the program violated the U.S. Constitution's guarantees of privacy and information as well as exceeding the scope of its authorizing legislation, Section 215 of the Patriot Act. The U.S. government countered that the program is constitutional and that Congress was fully informed when it authorized and reauthorized Section 215. Moreover, a government lawyer said, the ACLU has no standing to bring the case because it cannot prove that its members have been harmed by the NSA's use of the data.\n\nIn November 2016, Louise Mensch reported on the news website, Heat Street, that, after an initial June 2016 FBI request was denied, the FISA court had granted a more narrowly-focused October request from the FBI \"to examine the activities of 'U.S. persons' in Donald Trump’s campaign with ties to Russia\". On 12 January 2017, BBC journalist Paul Wood reported that, in response to an April 2016 tip from a foreign intelligence agency to the CIA about \"money from the Kremlin going into the US presidential campaign\", a joint taskforce had been established including representatives of the FBI, the Department of the Treasury, the Department of Justice, the CIA, the Office of the Director of National Intelligence and the National Security Agency; and in June 2016 lawyers from the Department of Justice had applied to the FISA court for \"permission to intercept the electronic records from two Russian banks.\" According to Wood, this application was rejected, as was a more narrowly focussed request in July, and the order was finally granted by a different FISA judge on 15 October, three weeks before the presidential election. On January 19 the \"New York Times\" reported that one of its sources had claimed \"intelligence reports based on some of the wiretapped communications had been provided to the White House.\"\n\nOn 2 March 2017 broadcaster Mark Levin said on his syndicated evening radio program, \"We have a prior administration - Barack Obama and his surrogates who were supporting Hillary Clinton and her party, the Democratic Party - who were using the instrumentalities of the federal government - intelligence activities - to surveil members of the Trump campaign and to put that information out in the public\" and asked, \"Were the president of the United States - the now-president of the United States, Donald Trump - were his phone calls recorded? ... How many phone calls by Donald Trump - if any - have been intercepted by the Obama administration and recorded by the Obama administration?\" Levin claimed that Obama had been involved in a \"silent coup\" against the Trump campaign using \"police state\" tactics during the election campaign. The next day, Joel Pollak writing in Breitbart, summarized and expanded on Levin's argument. He repeated Levin's claim that the Obama administration had initiated the FISA court requests but did not touch on the question of whether Trump's phone had been tapped.\n\nOn the following morning, March 4, 2017, President Trump sent various Twitter messages claiming Barack Obama had bugged his phones during the \"very sacred election process\". Trump charged that Obama was behind the 2016 FISA court order requests, likened the situation to 1950s McCarthyism and the 1970s Watergate scandal and called his predecessor a \"Bad (or sick) guy!\" Obama spokesperson Kevin Lewis and various Obama surrogates including Valerie Jarrett subsequently denied that President Obama or the Obama White House initiated the FISA court order requests. \n\nOn 13 March, the Senate Intelligence Committee had demanded that the Trump administration provide evidence to support the US president’s claim, and on 16 March the committee reported that they had seen no evidence to support Trump's accusation that the Obama administration tapped his phones during the 2016 presidential campaign.\n\nOn Fox News on 14 March, commentator Andrew Napolitano said, \"Three intelligence sources have informed Fox News that President Obama went outside the chain of command. ... He used GCHQ. What is that? It's the initials for the British intelligence spying agency. Simply by saying to them, 'The president needs transcripts of conversations involving candidate Trump's conversations' he's able to get it and there's no American fingerprints on this.\" Two days later, on 16 March, White House press spokesperson, Sean Spicer, read this claim to the press. A GCHQ spokesman responded: \"Recent allegations made by media commentator Judge Andrew Napolitano about GCHQ being asked to conduct 'wiretapping' against the then president elect are nonsense. They are utterly ridiculous and should be ignored.\" On 17 March, the US made a formal apology to Britain for the accusation.\n\nOn April 11th, the Washington Post reported that the FBI had been granted a FISA warrant in the summer of 2016 to monitor then Trump adviser Carter Page. According to the report, \"The FBI and the Justice Department obtained the warrant targeting Carter Page’s communications after convincing a Foreign Intelligence Surveillance Court judge that there was probable cause to believe Page was acting as an agent of a foreign power, in this case Russia, according to the officials.\" The report also states that the warrant has been renewed multiple times since its first issue.\n\nWhen the court was founded, it was composed of seven federal district judges appointed by the Chief Justice of the United States, each serving a seven-year term, with one judge being appointed each year. In 2001, the USA PATRIOT Act expanded the court from seven to eleven judges, and required that at least three of the Court's judges live within twenty miles (32 km) of the District of Columbia. No judge may be appointed to this court more than once, and no judge may be appointed to both the Court of Review and the FISA court.\n\nAs of 2017, Chief Justice John Roberts has appointed all of the current judges, four of whom were nominated to their District Court judgeships by a Democratic President. \n\n\nNotes\nReferences\n"}
{"id": "11407", "url": "https://en.wikipedia.org/wiki?curid=11407", "title": "FC Den Bosch", "text": "FC Den Bosch\n\nFC Den Bosch () is a football club from 's-Hertogenbosch, Netherlands.\n\nThey were founded August 18, 1965, as FC Den Bosch/BVV. They are the successor of BVV (1906) and Wilhelmina (1890). Their stadium is called 'De Vliert', an 8,500 all-seater. Ruud van Nistelrooy started his professional career at this club. In 2005 they finished bottom of the Eredivisie and were relegated.\n\n1971, 1983, 1992, 1999, 2001, 2004\n\n1963, 1966\n\nBelow is a table with FC Den Bosch's domestic results since the introduction of professional football in 1956.\n\nDuring the 2012–13 KNVB Cup quarter-final match against AZ, American forward Jozy Altidore was the target of racist chants. The club's director, Peter Bijvelds, blamed \"malicious supporters making a scandalous mess of the evening\". He said Den Bosch, AZ and the referee considered abandoning the match, but decided against it.\n\n\"We can't deny that, certainly when we play top matches, we have a structural problem with a group of people who ruin things,\" Bijvelds told Dutch radio.\n\nThis racial incident, however, was a minor one, and gravely offended the vast majority of Den Bosch supporters. Following this incident, the club and fans went on a series of actions to rectify the image of the club and re-instate their strong stance against any forms of racism. Evident to this was a campaign launched by the club to equip a village in Africa with football kits and football equipment.\n\n\n\n\n"}
{"id": "11408", "url": "https://en.wikipedia.org/wiki?curid=11408", "title": "Female genital mutilation", "text": "Female genital mutilation\n\nFemale genital mutilation (FGM), also known as female genital cutting and female circumcision, is the ritual cutting or removal of some or all of the external female genitalia. The practice is found in Africa, Asia and the Middle East, and within communities from countries in which FGM is common. UNICEF estimated in 2016 that 200 million women living today in 30 countries—27 African countries, Indonesia, Iraqi Kurdistan and Yemen—have undergone the procedures.\n\nTypically carried out by a traditional circumciser using a blade, FGM is conducted from days after birth to puberty and beyond. In half the countries for which national figures are available, most girls are cut before the age of five. Procedures differ according to the country or ethnic group. They include removal of the clitoral hood and clitoral glans; removal of the inner labia; and removal of the inner and outer labia and closure of the vulva. In this last procedure, known as infibulation, a small hole is left for the passage of urine and menstrual fluid; the vagina is opened for intercourse and opened further for childbirth.\n\nThe practice is rooted in gender inequality, attempts to control women's sexuality, and ideas about purity, modesty and beauty. It is usually initiated and carried out by women, who see it as a source of honour, and who fear that failing to have their daughters and granddaughters cut will expose the girls to social exclusion. Health effects depend on the procedure. They can include recurrent infections, difficulty urinating and passing menstrual flow, chronic pain, the development of cysts, an inability to get pregnant, complications during childbirth, and fatal bleeding. There are no known health benefits.\n\nThere have been international efforts since the 1970s to persuade practitioners to abandon FGM, and it has been outlawed or restricted in most of the countries in which it occurs, although the laws are poorly enforced. Since 2010 the United Nations has called upon healthcare providers to stop performing all forms of the procedure, including reinfibulation after childbirth and symbolic \"nicking\" of the clitoral hood. The opposition to the practice is not without its critics, particularly among anthropologists, who have raised difficult questions about cultural relativism and the universality of human rights.\n\nUntil the 1980s FGM was widely known in English as female circumcision, implying an equivalence in severity with male circumcision. From 1929 the Kenya Missionary Council referred to it as the sexual mutilation of women, following the lead of Marion Scott Stevenson, a Church of Scotland missionary. References to the practice as mutilation increased throughout the 1970s. In 1975 Rose Oldfield Hayes, an American anthropologist, used the term \"female genital mutilation\" in the title of a paper in \"American Ethnologist\", and four years later Fran Hosken, an Austrian-American feminist writer, called it mutilation in her influential \"The Hosken Report: Genital and Sexual Mutilation of Females\".\n\nThe Inter-African Committee on Traditional Practices Affecting the Health of Women and Children began referring to it as female genital mutilation in 1990, and the World Health Organization (WHO) followed suit in 1991. Other English terms include \"female genital cutting\" (FGC) and \"female genital mutilation/cutting\" (FGM/C), preferred by those who work with practitioners.\n\nIn countries where FGM is common, the practice's many variants are reflected in dozens of terms, often alluding to purification. In the Bambara language, spoken mostly in Mali, it is known as \"bolokoli\" (\"washing your hands\") and in the Igbo language in eastern Nigeria as \"isa aru\" or \"iwu aru\" (\"having your bath\"). A common Arabic term for purification has the root \"t-h-r\", used for male and female circumcision (\"tahur\" and \"tahara\"). It is also known in Arabic as \"khafḍ\" or \"khifaḍ\".\n\nCommunities may refer to FGM as \"pharaonic\" for infibulation and \"sunna\" circumcision for everything else. \"Sunna\" means \"path or way\" in Arabic and refers to the tradition of Muhammad, although none of the procedures are required within Islam. The term \"infibulation\" derives from \"fibula\", Latin for clasp—the Ancient Romans reportedly fastened clasps through the foreskins or labia of slaves to prevent sexual intercourse. The surgical infibulation of women came to be known as pharaonic circumcision in Sudan, but as Sudanese circumcision in Egypt. In Somalia it is known simply as \"qodob\" (\"to sew up\").\n\nThe procedures are generally performed by a traditional circumciser (cutter or \"exciseuse\") in the girls' homes, with or without anaesthesia. The cutter is usually an older woman, but in communities where the male barber has assumed the role of health worker he will perform FGM too.\n\nWhen traditional cutters are involved, non-sterile devices are likely to be used, including knives, razors, scissors, glass, sharpened rocks and fingernails. According to a nurse in Uganda, quoted in 2007 in \"The Lancet\", a cutter would use one knife on up to 30 girls at a time.\n\nHealth professionals are often involved in Egypt, Kenya, Indonesia and Sudan. In Egypt 77 percent of FGM procedures, and in Indonesia over 50 percent, were performed by medical professionals as of 2008 and 2016. Women in Egypt reported in 1995 that a local anaesthetic had been used on their daughters in 60 percent of cases, a general anaesthetic in 13 percent and neither in 25 percent (two percent were missing/don't know).\n\nThe WHO, UNICEF and UNFPA issued a joint statement in 1997 defining FGM as \"all procedures involving partial or total removal of the external female genitalia or other injury to the female genital organs whether for cultural or other non-therapeutic reasons\". The procedures vary considerably according to ethnicity and individual practitioners. During a 1998 survey in Niger, women responded with over 50 different terms when asked what was done to them. Translation problems are compounded by the women's confusion over which type of FGM they experienced, or even whether they experienced it. Several studies have suggested that survey responses are unreliable.\n\nStandard questionnaires from United Nations bodies ask women whether they or their daughters have undergone the following: (1) cut, no flesh removed (pricking or symbolic circumcision); (2) cut, some flesh removed; (3) sewn closed; or (4) type not determined/unsure/doesn't know. The most common procedures fall within the \"cut, some flesh removed\" category and involve complete or partial removal of the clitoral glans.\n\nThe World Health Organization created a more detailed typology. Types I–III vary in how much tissue is removed (Type III is the UNICEF category \"sewn closed\"). Type IV describes miscellaneous procedures, including symbolic circumcision.\n\nType Ia (circumcision) involves removal of the clitoral hood only and is rarely performed alone. The more common procedure is Type Ib (clitoridectomy), the complete or partial removal of the clitoral glans (the visible tip of the clitoris) and clitoral hood. The circumciser pulls the clitoral glans with her thumb and index finger and cuts it off.\n\nType II (excision) is the complete or partial removal of the inner labia, with or without removal of the clitoral glans and outer labia. Type IIa is removal of the inner labia; IIb, removal of the clitoral glans and inner labia; and IIc, removal of the clitoral glans, inner and outer labia. \"Excision\" in French can refer to any form of FGM.\n\nType III (infibulation or pharaonic circumcision), the \"sewn closed\" category, involves the removal of the external genitalia and fusion of the wound. The inner and/or outer labia are cut away, with or without removal of the clitoral glans. Type IIIa is the removal and closure of the inner labia and IIIb the outer labia. The practice is found largely in Djibouti, Eritrea, Ethiopia, Somalia and Sudan (though not South Sudan) in northeast Africa. Estimates of numbers vary: according to one in 2008, over eight million women in Africa have experienced it. According to UNFPA in 2010, 20 percent of women with FGM have been infibulated.\n\nComfort Momoh, a specialist midwife, describes Type III: \"[E]lderly women, relatives and friends secure the girl in the lithotomy position. A deep incision is made rapidly on either side from the root of the clitoris to the fourchette, and a single cut of the razor excises the clitoris and both the labia majora and labia minora.\" Girls \"may be pinned down so firmly that bones may fracture\". In Somalia the clitoral glans is removed and shown to the senior female relatives, who decide whether enough has been amputated. After this the labia are removed. The amputated parts might be placed in a pouch for the girl to wear.\n\nA single hole of 2–3 mm is left for the passage of urine and menstrual fluid by inserting something, such as a twig, into the wound. The vulva is then closed with surgical thread, agave or acacia thorns, or covered with a poultice such as raw egg, herbs and sugar. To help the tissue bond, the girl's legs are tied together, often from hip to ankle; the bindings are usually loosened after a week and removed after two to six weeks. The result is a \"drum of skin extending across the [vaginal] orifice except for a small hole\", Momoh writes.\n\nIf the remaining hole is too large in the view of the girl's family, the procedure is repeated. The vagina is opened for sexual intercourse, for the first time either by a midwife with a knife or by the woman's husband with his penis. In some areas, including Somaliland, female relatives of the bride and groom might watch the opening of the vagina to check that the girl is a virgin. Psychologist Hanny Lightfoot-Klein interviewed hundreds of women and men in Sudan in the 1980s about sexual intercourse with Type III:\n\nThe penetration of the bride's infibulation takes anywhere from 3 or 4 days to several months. Some men are unable to penetrate their wives at all (in my study over 15%), and the task is often accomplished by a midwife under conditions of great secrecy, since this reflects negatively on the man's potency. Some who are unable to penetrate their wives manage to get them pregnant in spite of the infibulation, and the woman's vaginal passage is then cut open to allow birth to take place. ... Those men who do manage to penetrate their wives do so often, or perhaps always, with the help of the \"little knife\". This creates a tear which they gradually rip more and more until the opening is sufficient to admit the penis.\nThe woman is opened further for childbirth and closed afterwards, a process known as defibulation (or deinfibulation) and reinfibulation. Reinfibulation can involve cutting the vagina again to restore the pinhole size of the first infibulation. This might be performed before marriage, and after childbirth, divorce and widowhood.\n\nThe WHO defines Type IV as \"[a]ll other harmful procedures to the female genitalia for non-medical purposes\", including pricking, piercing, incising, scraping and cauterization. It includes nicking of the clitoris (symbolic circumcision), burning or scarring the genitals, and introducing substances into the vagina to tighten it. Labia stretching is also categorized as Type IV. Common in southern and eastern Africa, the practice is supposed to enhance sexual pleasure for the man and add to the sense of a woman as a closed space. From the age of eight, girls are encouraged to stretch their inner labia using sticks and massage. Girls in Uganda are told they may have difficulty giving birth without stretched labia.\n\nA definition of FGM from the WHO in 1995 included gishiri cutting and angurya cutting, found in Nigeria and Niger. These were removed from the WHO's 2008 definition because of insufficient information about prevalence and consequences. Angurya cutting is excision of the hymen, usually performed seven days after birth. Gishiri cutting involves cutting the vagina's front or back wall with a blade or penknife, performed in response to infertility, obstructed labour and other conditions. In a study by Nigerian physician Mairo Usman Mandara, over 30 percent of women with gishiri cuts were found to have vesicovaginal fistulae (holes that allow urine to seep into the vagina).\n\nFGM harms women's physical and emotional health throughout their lives. It has no known health benefits. The short-term and late complications depend on the type of FGM, whether the practitioner has had medical training, and whether they used antibiotics and sterilized or single-use surgical instruments. In the case of Type III, other factors include how small a hole was left for the passage of urine and menstrual blood, whether surgical thread was used instead of agave or acacia thorns, and whether the procedure was performed more than once (for example, to close an opening regarded as too wide or re-open one too small).\n\nCommon short-term complications include swelling, excessive bleeding, pain, urine retention, and healing problems/wound infection. A 2015 systematic review of 56 studies that recorded immediate complications suggested that each of these occurred in more than one in ten girls and women undergoing any form of FGM, including symbolic nicking of the clitoris (Type IV), although the risks increased with Type III. The review also suggested that there was under-reporting. Other short-term complications include fatal bleeding, anaemia, urinary infection, septicaemia, tetanus, gangrene, necrotizing fasciitis (flesh-eating disease), and endometritis. It is not known how many girls and women die as a result of the practice, because complications may not be recognized or reported. The practitioners' use of shared instruments is thought to aid the transmission of hepatitis B, hepatitis C and HIV, although no epidemiological studies have shown this.\n\nLate complications vary depending on the type of FGM. They include the formation of scars and keloids that lead to strictures and obstruction, epidermoid cysts that may become infected, and neuroma formation (growth of nerve tissue) involving nerves that supplied the clitoris.\n\nAn infibulated girl may be left with an opening as small as 2–3 mm, which can cause prolonged, drop-by-drop urination, pain while urinating, and a feeling of needing to urinate all the time. Urine may collect underneath the scar, leaving the area under the skin constantly wet, which can lead to infection and the formation of small stones. The opening is larger in women who are sexually active or have given birth by vaginal delivery, but the urethra opening may still be obstructed by scar tissue. Vesicovaginal or rectovaginal fistulae can develop (holes that allow urine or faeces to seep into the vagina). This and other damage to the urethra and bladder can lead to infections and incontinence, pain during sexual intercourse and infertility.\n\nPainful periods are common because of the obstruction to the menstrual flow, and blood can stagnate in the vagina and uterus. Complete obstruction of the vagina can result in hematocolpos and hematometra (where the vagina and uterus fill with menstrual blood). The swelling of the abdomen that results from the collection of fluid, together with the lack of menstruation, can lead to suspicion of pregnancy. Asma El Dareer, a Sudanese physician, reported in 1979 that a girl in Sudan with this condition was killed by her family.\n\nFGM may place women at higher risk of problems during pregnancy and childbirth, which are more common with the more extensive FGM procedures. Infibulated women may try to make childbirth easier by eating less during pregnancy to reduce the baby's size. In women with vesicovaginal or rectovaginal fistulae, it is difficult to obtain clear urine samples as part of prenatal care, making the diagnosis of conditions such as pre-eclampsia harder. Cervical evaluation during labour may be impeded and labour prolonged or obstructed. Third-degree laceration (tears), anal-sphincter damage and emergency caesarean section are more common in infibulated women.\n\nNeonatal mortality is increased. The WHO estimated in 2006 that an additional 10–20 babies die per 1,000 deliveries as a result of FGM. The estimate was based on a study conducted on 28,393 women attending delivery wards at 28 obstetric centres in Burkina Faso, Ghana, Kenya, Nigeria, Senegal and Sudan. In those settings all types of FGM were found to pose an increased risk of death to the baby: 15 percent higher for Type I, 32 percent for Type II, and 55 percent for Type III. The reasons for this were unclear, but may be connected to genital and urinary tract infections and the presence of scar tissue. The researchers wrote that FGM was associated with an increased risk to the mother of damage to the perineum and excessive blood loss, as well as a need to resuscitate the baby, and stillbirth, perhaps because of a long .\n\nAccording to a 2015 systematic review there is little high-quality information available on the psychological effects of FGM. Several small studies have concluded that women with FGM suffer from anxiety, depression and post-traumatic stress disorder. Feelings of shame and betrayal can develop when women leave the culture that practises FGM and learn that their condition is not the norm, but within the practising culture they may view their FGM with pride, because for them it signifies beauty, respect for tradition, chastity and hygiene.\n\nStudies on sexual function have also been small. A 2013 meta-analysis of 15 studies involving 12,671 women from seven countries concluded that women with FGM were twice as likely to report no sexual desire and 52 percent more likely to report dyspareunia (painful sexual intercourse). One third reported reduced sexual feelings.\n\nAid agencies define the prevalence of FGM as the percentage of the 15–49 age group that has exerienced it. These figures are based on nationally representative household surveys known as Demographic and Health Surveys (DHS), developed by Macro International and funded mainly by the United States Agency for International Development (USAID), and Multiple Indicator Cluster Surveys (MICS) conducted with financial and technical help from UNICEF.\n\nThese surveys have been carried out in Africa, Asia, Latin America and elsewhere roughly every five years, since 1984 and 1995 respectively. The first to ask about FGM was the 1989–1990 DHS in northern Sudan. The first publication to estimate FGM prevalence based on DHS data (in seven countries) was by Dara Carr of Macro International in 1997.\n\nFGM is found mostly in what Gerry Mackie called an \"intriguingly contiguous\" zone in Africa—east to west from Somalia to Senegal, and north to south from Egypt to Tanzania. Nationally representative figures are available for 27 countries in Africa, as well as Indonesia, Iraqi Kurdistan and Yemen. Over 200 million women and girls are thought to be living with FGM in those 30 countries. \n\nThe highest concentrations among the 15–49 age group are in Somalia (98 percent), Guinea (97 percent), Djibouti (93 percent), Egypt (91 percent) and Sierra Leone (90 percent). As of 2013, 27.2 million women had undergone FGM in Egypt, 23.8 million in Ethiopia, and 19.9 million in Nigeria. There is also a high concentration in Indonesia, where Type Ia (removal of the clitoral hood) and symbolic nicking (Type IV) are practised; the prevalence rate for the 0–11 group is 49 percent (13.4 million).\n\nSmaller studies or anecdotal reports suggest that FGM is also practised in Colombia, the Congo, Malaysia, Oman, Peru, Saudi Arabia, Sri Lanka, and the United Arab Emirates, as well as among the Bedouin in Israel; in Rahmah, Jordan; and among the Dawoodi Bohra in India. It is also found within immigrant communities in Australasia, Europe, North America and Scandinavia.\n\nPrevalence figures for the 15–19 age group and younger show a downward trend. For example, Burkina Faso fell from 89 percent (1980) to 58 percent (2010); Egypt from 97 percent (1985) to 70 percent (2015); and Kenya from 41 percent (1984) to 11 percent (2014).\n\nFrom 2010 household surveys asked women about the FGM status of all their living daughters. The highest concentrations among girls aged 0–14 were in Gambia (56 percent), Mauritania (54 percent), Indonesia (49 percent for 0–11) and Guinea (46 percent). The figures suggest that a girl was one third less likely in 2014 to undergo FGM than she was 30 years ago. If the rate of decline continues, the number of girls cut will nevertheless rise from 3.6 million a year in 2013 to 4.1 million in 2050 because of population growth.\n\nSurveys have found FGM to be more common in rural areas, less common in most countries among girls from the wealthiest homes, and (except in Sudan and Somalia) less common in girls whose mothers had access to primary or secondary/higher education. In Somalia and Sudan the situation was reversed: in Somalia the mothers' access to secondary/higher education was accompanied by a rise in prevalence of FGM in their daughters, and in Sudan access to any education was accompanied by a rise.\n\nFGM is not invariably a rite of passage between childhood and adulthood, but is often performed on much younger children. Girls are most commonly cut shortly after birth to age 15. In half the countries for which national figures were available in 2000–2010, most girls had been cut by age five. Over 80 percent (of those cut) are cut before the age of five in Nigeria, Mali, Eritrea, Ghana and Mauritania. The 1997 Demographic and Health Survey in Yemen found that 76 percent of girls had been cut within two weeks of birth. The percentage is reversed in Somalia, Egypt, Chad and the Central African Republic, where over 80 percent (of those cut) are cut between five and 14. Just as the type of FGM is often linked to ethnicity, so is the mean age. In Kenya, for example, the Kisi cut around age 10 and the Kamba at 16.\n\nA country's national prevalence often reflects a high sub-national prevalence among certain ethnicities, rather than a widespread practice. In Iraq, for example, FGM is found mostly among the Kurds in Erbil (58 percent prevalence within age group 15–49, as of 2011), Sulaymaniyah (54 percent) and Kirkuk (20 percent), giving the country a national prevalence of eight percent. The practice is sometimes an ethnic marker, but may differ along national lines. In the northeastern regions of Ethiopia and Kenya, which share a border with Somalia, the Somali people practise FGM at around the same rate as they do in Somalia. But in Guinea all Fulani women responding to a survey in 2012 said they had experienced FGM, against 12 percent of the Fulani in Chad, while in Nigeria the Fulani are the only large ethnic group in the country not to practise it.\n\nWomen are asked during surveys about the type of FGM they experienced:\n\nMost women report \"cut, some flesh removed\" (Types I and II). According to Mackie in 2003, Type II is more common in Egypt, while a 2011 study identified Type I as more common. In Nigeria Type I is usually found in the south and the more severe forms in the north.\n\nType III (infibulation) is concentrated in northeastern Africa, particularly Djibouti, Eritrea, Somalia and Sudan. In surveys in 2002–2006, 30 percent of cut girls in Djibouti, 38 percent in Eritrea, and 63 percent in Somalia had experienced Type III. There is also a high prevalence of infibulation among girls in Niger and Senegal, and in 2013 it was estimated that in Nigeria three percent of the 0–14 age group had been infibulated. The type of procedure is often linked to ethnicity. In Eritrea, for example, a survey in 2002 found that all Hedareb girls had been infibulated, compared with two percent of the Tigrinya, most of whom fell into the \"cut, no flesh removed\" category.\n\nDahabo Musa, a Somali woman, described infibulation in a 1988 poem as the \"three feminine sorrows\": the procedure itself, the wedding night when the woman is cut open, then childbirth when she is cut again. Despite the evident suffering, it is women who organize all forms of FGM. Anthropologist Rose Oldfield Hayes wrote in 1975 that educated Sudanese men who did not want their daughters to be infibulated (preferring clitoridectomy) would find the girls had been sewn up after the grandmothers arranged a visit to relatives.\n\nGerry Mackie has compared FGM to footbinding. Like FGM, footbinding was carried out on young girls, nearly universal where practised, tied to ideas about honour, chastity and appropriate marriage, and supported by women. FGM practitioners see the procedures as marking not only ethnic boundaries but also gender difference. According to this view, FGM demasculinizes women, while male circumcision defeminizes men.\n\nFuambai Ahmadu, an anthropologist and member of the Kono people of Sierra Leone, who in 1992 underwent clitoridectomy as an adult during a Sande society initiation, argued in 2000 that it is a male-centred assumption that the clitoris is important to female sexuality. African female symbolism revolves instead around the concept of the womb. Infibulation draws on that idea of enclosure and fertility. \"[G]enital cutting completes the social definition of a child's sex by eliminating external traces of androgyny,\" Janice Boddy wrote in 2007. \"The female body is then covered, closed, and its productive blood bound within; the male body is unveiled, opened and exposed.\"\n\nIn communities where infibulation is common, there is a preference for women's genitals to be smooth, dry and without odour, and both women and men may find the natural vulva repulsive. Men seem to enjoy the effort of penetrating an infibulation. The local preference for dry sex causes women to introduce substances into the vagina to reduce lubrication, including leaves, tree bark, toothpaste and Vicks menthol rub. The WHO includes this practice within Type IV FGM, because the added friction during intercourse can cause lacerations and increase the risk of infection. Because of the smooth appearance of an infibulated vulva, there is also a belief that infibulation increases hygiene.\n\nCommon reasons for FGM cited by women in surveys are social acceptance, religion, hygiene, preservation of virginity, marriageability and enhancement of male sexual pleasure. In a study in northern Sudan, published in 1983, only 17.4 percent of women opposed FGM (558 out of 3,210), and most preferred excision and infibulation over clitoridectomy. Attitudes are changing slowly. In Sudan in 2010, 42 percent of women who had heard of FGM said the practice should continue. In several surveys since 2006, over 50 percent of women in Mali, Guinea, Sierra Leone, Somalia, Gambia and Egypt supported FGM's continuance, while elsewhere in Africa, Iraq and Yemen most said it should end, although in several countries only by a narrow margin.\n\nAgainst the argument that women willingly choose FGM for their daughters, UNICEF calls the practice a \"self-enforcing social convention\" to which families feel they must conform to avoid uncut daughters facing social exclusion.\n\nEllen Gruenbaum reports that, in Sudan in the 1970s, cut girls from an Arab ethnic group would mock uncut Zabarma girls with \"Ya, Ghalfa!\" (\"Hey, unclean!\"). The Zabarma girls would respond \"Ya, mutmura!\" (A \"mutmara\" was a storage pit for grain that was continually opened and closed, like an infibulated woman.) But despite throwing the insult back, the Zabarma girls would ask their mothers, \"What's the matter? Don't we have razor blades like the Arabs?\"\n\nBecause of poor access to information, and because circumcisers downplay the causal connection, women may not associate the health consequences with the procedure. Lala Baldé, president of a women's association in Medina Cherif, a village in Senegal, told Mackie in 1998 that when girls fell ill or died, it was attributed to evil spirits. When informed of the causal relationship between FGM and ill health, Mackie wrote, the women broke down and wept. Mackie argued that surveys taken before and after this sharing of information would show very different levels of support for FGM.\n\nThe American non-profit group Tostan, founded by Molly Melching in 1991, introduced community-empowerment programmes in several countries that focus on local democracy, literacy, and education about healthcare, giving women the tools to make their own decisions. In 1997, using the Tostan programme, Malicounda Bambara in Senegal became the first village to abandon FGM. By 2016, over 7,300 communities in six countries had pledged to abandon FGM and child marriage.\n\nSurveys have shown a widespread belief, particularly in Mali, Mauritania, Guinea and Egypt, that FGM is a religious requirement. Gruenbaum has argued that practitioners may not distinguish between religion, tradition and chastity, making it difficult to interpret the data.\n\nFGM's origins in northeastern Africa are pre-Islamic, but the practice became associated with Islam because of that religion's focus on female chastity and seclusion. There is no mention of it in the Quran. It is praised in several \"hadith\" (sayings attributed to Muhammad) as noble but not required. In 2007 the Al-Azhar Supreme Council of Islamic Research in Cairo ruled that FGM had \"no basis in core Islamic law or any of its partial provisions\".\n\nThere is no mention of FGM in the Bible. Christian missionaries in Africa were among the first to object to FGM, but Christian communities in Africa do practise it. A 2013 UNICEF report identified 17 African countries in which at least 10 percent of Christian women and girls aged 15 to 49 had undergone FGM; in Niger 55 percent of Christian women and girls had experienced it, compared with two percent of their Muslim counterparts. The only Jewish group known to have practised it are the Beta Israel of Ethiopia. Judaism requires male circumcision, but does not allow FGM. FGM is also practised by animist groups, particularly in Guinea and Mali.\nThe practice's origins are unknown, but its east-west, north-south distribution in Africa meets in Sudan. Gerry Mackie has suggested that infibulation began there with the Meroite civilization (c. 800 BCE – c. 350 CE), before the rise of Islam, to increase confidence in paternity. According to historian Mary Knight, Spell 1117 (c. 1991–1786 BCE) of the Ancient Egyptian Coffin Texts may refer in hieroglyphs to an uncircumcised girl (\"'m't\"):\n\na-m-a:X1-D53-B1\n\nThe spell was found on the sarcophagus of Sit-hedjhotep, now in the Egyptian Museum, and dates to Egypt's Middle Kingdom. (Paul F. O'Rourke argues that \"'m't\" probably refers instead to a menstruating woman.) The proposed circumcision of an Egyptian girl, Tathemis, is also mentioned on a Greek papyrus, from 163 BCE, in the British Museum:\n\nSometime after this, Nephoris [Tathemis's mother] defrauded me, being anxious that it was time for Tathemis to be circumcised, as is the custom among the Egyptians. She asked that I give her 1,300 drachmae ... to clothe her ... and to provide her with a marriage dowry ... if she didn't do each of these or if she did not circumcise Tathemis in the month of Mecheir, year 18 [163 BCE], she would repay me 2,400 drachmae on the spot.\n\nThe examination of mummies has shown no evidence of FGM. Citing the Australian pathologist Grafton Elliot Smith, who examined hundreds of mummies in the early 20th century, Knight writes that the genital area may resemble Type III because during mummification the skin of the outer labia was pulled toward the anus to cover the pudendal cleft, possibly to prevent sexual violation. It was similarly not possible to determine whether Types I or II had been performed, because soft tissues had deteriorated or been removed by the embalmers.\nThe Greek geographer Strabo (c. 64 BCE – c. 23 CE) wrote about FGM after visiting Egypt around 25 BCE. The philosopher Philo of Alexandria (c. 20 BCE – 50 CE) also made reference to it: \"the Egyptians by the custom of their country circumcise the marriageable youth and maid in the fourteenth (year) of their age, when the male begins to get seed, and the female to have a menstrual flow.\" It is mentioned briefly in a work attributed to the Greek physician Galen (129 – c. 200 CE): \"When [the clitoris] sticks out to a great extent in their young women, Egyptians consider it appropriate to cut it out.\"\n\nAnother Greek physician, Aëtius of Amida (mid-5th to mid-6th century CE), offered more detail in book 16 of his \"Sixteen Books on Medicine\", citing the physician Philomenes. The procedure was performed in case the clitoris, or \"nymphê\", grew too large or triggered sexual desire when rubbing against clothing. \"On this account, it seemed proper to the Egyptians to remove it before it became greatly enlarged\", Aëtius wrote, \"especially at that time when the girls were about to be married\":\n\nThe surgery is performed in this way: Have the girl sit on a chair while a muscled young man standing behind her places his arms below the girl's thighs. Have him separate and steady her legs and whole body. Standing in front and taking hold of the clitoris with a broad-mouthed forceps in his left hand, the surgeon stretches it outward, while with the right hand, he cuts it off at the point next to the pincers of the forceps.\n\nIt is proper to let a length remain from that cut off, about the size of the membrane that's between the nostrils, so as to take away the excess material only; as I have said, the part to be removed is at that point just above the pincers of the forceps. Because the clitoris is a skinlike structure and stretches out excessively, do not cut off too much, as a urinary fistula may result from cutting such large growths too deeply.\n\nThe genital area was then cleaned with a sponge, frankincense powder and wine or cold water, and wrapped in linen bandages dipped in vinegar, until the seventh day when calamine, rose petals, date pits or a \"genital powder made from baked clay\" might be applied.\n\nWhatever the practice's origins, infibulation became linked to slavery. Mackie cites the Portuguese missionary João dos Santos, who in 1609 wrote of a group inland from Mogadishu who had a \"custome to sew up their Females, especially their slaves being young to make them unable for conception, which makes these slaves sell dearer, both for their chastitie, and for better confidence which their Masters put in them\". The English explorer William Browne wrote in 1799 that the Egyptians practised excision, and that slaves in that country were infibulated to prevent pregnancy. Thus, Mackie argues, a \"practice associated with shameful female slavery came to stand for honor\".\n\nGynaecologists in 19th-century Europe and the United States removed the clitoris to treat insanity and masturbation. A British doctor, Robert Thomas, suggested clitoridectomy as a cure for nymphomania in 1813.\nThe first reported clitoridectomy in the West, described in \"The Lancet\" in 1825, was performed in 1822 in Berlin by Karl Ferdinand von Graefe on a 15-year-old girl who was masturbating excessively.\n\nIsaac Baker Brown, an English gynaecologist, president of the Medical Society of London, and co-founder in 1845 of St. Mary's Hospital, believed that masturbation, or \"unnatural irritation\" of the clitoris, caused hysteria, spinal irritation, fits, idiocy, mania and death. He therefore \"set to work to remove the clitoris whenever he had the opportunity of doing so\", according to his obituary in the \"Medical Times and Gazette\" in 1873. Brown performed several clitoridectomies between 1859 and 1866. When he published his views in \"On the Curability of Certain Forms of Insanity, Epilepsy, Catalepsy, and Hysteria in Females\" (1866), doctors in London accused him of quackery and expelled him from the Obstetrical Society.\n\nIn the United States, J. Marion Sims followed Brown's work and in 1862 slit the neck of a woman's uterus and amputated her clitoris, \"for the relief of the nervous or hysterical condition as recommended by Baker Brown\", after the patient complained of menstrual pain, convulsions and bladder problems. Later that century A. J. Bloch, a surgeon in New Orleans, removed the clitoris of a two-year-old girl who was reportedly masturbating. According to a 1985 paper in the \"Obstetrical & Gynecological Survey\", clitoridectomy was performed in the US into the 1960s to treat hysteria, erotomania and lesbianism.\n\nProtestant missionaries in British East Africa (present-day Kenya) began campaigning against FGM in the early 20th century, when Dr. John Arthur joined the Church of Scotland Mission (CSM) in Kikuyu. An important ethnic marker, the practice was known by the Kikuyu, the country's main ethnic group, as \"irua\" for both girls and boys. It involved excision (Type II) for girls and removal of the foreskin for boys. Unexcised Kikuyu women (\"irugu\") were outcasts.\n\nJomo Kenyatta, general secretary of the Kikuyu Central Association and later Kenya's first prime minister, wrote in 1938 that, for the Kikuyu, the institution of FGM was the \"\"conditio sine qua non\" of the whole teaching of tribal law, religion and morality\". No proper Kikuyu man or woman would marry or have sexual relations with someone who was not circumcised. A woman's responsibilities toward the tribe began with her initiation. Her age and place within tribal history was traced to that day, and the group of girls with whom she was cut was named according to current events, an oral tradition that allowed the Kikuyu to track people and events going back hundreds of years.\n\nBeginning with the CSM mission in 1925, several missionary churches declared that FGM was prohibited for African Christians. The CSM announced that Africans practising it would be excommunicated, which resulted in hundreds leaving or being expelled. The stand-off turned FGM into a focal point of the Kenyan independence movement; the 1929–1931 period is known in the country's historiography as the female circumcision controversy.\n\nIn 1929 the Kenya Missionary Council began referring to FGM as the \"sexual mutilation of women\", rather than circumcision, and a person's stance toward the practice became a test of loyalty, either to the Christian churches or to the Kikuyu Central Association. Hulda Stumpf, an American missionary with the Africa Inland Mission who opposed FGM in the girls' school she helped to run, was murdered in 1930. Edward Grigg, the governor of Kenya, told the British Colonial Office that the killer, who was never identified, had tried to circumcise her.\n\nIn 1956 the council of male elders (the \"Njuri Nchecke\") in Meru announced a ban on FGM. Over the next three years, thousands of girls cut each other's genitals with razor blades as a symbol of defiance. The movement came to be known as \"Ngaitana\" (\"I will circumcise myself\"), because to avoid naming their friends the girls said they had cut themselves. Historian Lynn Thomas described the episode as significant in the history of FGM because it made clear that its victims were also its perpetrators.\n\nThe first known non-colonial campaign against FGM began in Egypt in the 1920s, when the Egyptian Doctors' Society called for a ban. There was a parallel campaign in Sudan, run by religious leaders and British women. Infibulation was banned there in 1946, but the law was unpopular and barely enforced. The Egyptian government banned infibulation in state-run hospitals in 1959, but allowed partial clitoridectomy if parents requested it. (Egypt banned FGM entirely in 2007.)\n\nIn 1959 the UN asked the WHO to investigate FGM, but the latter responded that it was not a medical matter. Feminists took up the issue throughout the 1970s. The Egyptian physician and feminist Nawal El Saadawi criticized FGM in her book \"Women and Sex\" (1972); the book was banned in Egypt and El Saadawi lost her job as director general of public health. She followed up with a chapter, \"The Circumcision of Girls\", in her book \"The Hidden Face of Eve: Women in the Arab World\" (1980), which described her own clitoridectomy when she was six years old:\n\nI did not know what they had cut off from my body, and I did not try to find out. I just wept, and called out to my mother for help. But the worst shock of all was when I looked around and found her standing by my side. Yes, it was her, I could not be mistaken, in flesh and blood, right in the midst of these strangers, talking to them and smiling at them, as though they had not participated in slaughtering her daughter just a few moments ago.\n\nIn 1975 Rose Oldfield Hayes, an American social scientist, became the first female academic to publish a detailed account of FGM, aided by her ability to discuss it directly with women in Sudan. Her article in \"American Ethnologist\" called it \"female genital mutilation\", rather than female circumcision, and brought it to wider academic attention.\nIn 1977 Edna Adan Ismail, who worked at the time for the Somalia Ministry of Health, raised the health consequences of FGM with the Somali Women's Democratic Organization. Two years later Fran Hosken, an Austria-American feminist, published \"The Hosken Report: Genital and Sexual Mutilation of Females\" (1979), the first to offer global figures. She estimated that 110,529,000 women in 20 African countries had experienced FGM. The figures were speculative but consistent with later surveys. Describing FGM as a \"training ground for male violence\", Hosken accused female practitioners of \"participating in the destruction of their own kind\". The language caused a rift between Western and African feminists; African women boycotted a session featuring Hosken during the UN's Mid-Decade Conference on Women in Copenhagen in July 1980.\n\nIn 1979 the WHO held a seminar, \"Traditional Practices Affecting the Health of Women and Children\", in Khartoum, Sudan, and in 1981, also in Khartoum, 150 academics and activists signed a pledge to fight FGM after a workshop held by the Babiker Badri Scientific Association for Women's Studies (BBSAWS), \"Female Circumcision Mutilates and Endangers Women – Combat it!\" Another BBSAWS workshop in 1984 invited the international community to write a joint statement for the United Nations. It recommended that the \"goal of all African women\" should be the eradication of FGM and that, to sever the link between FGM and religion, clitoridectomy should no longer be referred to as \"sunna\".\n\nThe Inter-African Committee on Traditional Practices Affecting the Health of Women and Children, founded in 1984 in Dakar, Senegal, called for an end to the practice, as did the UN's World Conference on Human Rights in Vienna in 1993. The conference listed FGM as a form of violence against women, marking it as a human-rights violation, rather than a medical issue. Throughout the 1990s and 2000s governments in Africa and the Middle East passed legislation banning or restricting FGM. In 2003 the African Union ratified the Maputo Protocol on the rights of women, which supported the elimination of FGM. By 2015 laws restricting FGM had been passed in at least 23 of the 27 African countries in which it is concentrated, although several fell short of a ban.\n"}
{"id": "11411", "url": "https://en.wikipedia.org/wiki?curid=11411", "title": "Fermentation (disambiguation)", "text": "Fermentation (disambiguation)\n\nFermentation is a metabolic process whereby electrons released from nutrients are ultimately transferred to molecules obtained from the breakdown of those same nutrients.\n\nFermentation may also refer to:\n\n\n"}
{"id": "11415", "url": "https://en.wikipedia.org/wiki?curid=11415", "title": "Forcemeat", "text": "Forcemeat\n\nForcemeat is a mixture of ground, lean meat mixed with fat by either grinding, sieving, or puréeing the ingredients. The result may either be smooth or coarse, depending on the desired consistency of the final product. Forcemeats are used in the production of numerous items found in charcuterie; such items include quenelles, sausages, pâtés, terrines, roulades, and galantines. Forcemeats are usually produced from raw meat, except in the case of a \"gratin\" forcemeat. Meats commonly used in the production of forcemeats include pork, fish (pike, trout, or salmon), seafood, game meats (venison, boar, or rabbit), poultry, game birds, veal, and pork livers. Pork fatback is often used for the fat portion of a forcemeat as it has a somewhat neutral flavor.\n\nForcemeats are an ancient food, and are included in \"Apicius\", a collection of Roman cookery recipes, usually thought to have been compiled in the late 4th or early 5th century CE.\n\n\nOften the only binder in a forcemeat is the physical structure of the protein used. Sometimes a secondary binder is necessary to hold the mixture. These binders are generally needed when preparing the country-style and \"gratin\" forcemeats. The three types of binders include eggs, nonfat dry milk powder, and panades. A panade can be made from starchy ingredients which aid in the binding process; these include well-cooked potatoes which have been puréed, cream-soaked bread, or pâte à choux.\n\n\n"}
{"id": "11417", "url": "https://en.wikipedia.org/wiki?curid=11417", "title": "Forseti", "text": "Forseti\n\nForseti (Old Norse \"the presiding one,\" actually \"president\" in modern Icelandic and Faroese) is an Æsir god of justice and reconciliation in Norse mythology. He is generally identified with Fosite, a god of the Frisians. Jacob Grimm noted that if, as Adam of Bremen states, Fosite's sacred island was Heligoland, that would make him an ideal candidate for a deity known to both Frisians and Scandinavians, but that it is surprising he is never mentioned by Saxo Grammaticus.\n\nGrimm took \"Forseti\", \"\"praeses\"\", to be the older form of the name, first postulating an unattested Old High German equivalent *\"forasizo\" (cf. modern German \"Vorsitzender\" \"one who presides\"). but later preferring a derivation from \"fors\", a \"whirling stream\" or \"cataract\", connected to the spring and the god's veneration by seagoing peoples. It is plausible that \"Fosite\" is the older name and \"Forseti\" a folk etymology. According to the German philologist Hans Kuhn the Germanic form Fosite is linguistically identical to Greek \"Poseidon\", hence the original name must have been introduced before the Proto-Germanic sound change, probably via Greek sailors purchasing amber. The Greek traveller Pytheas of Massalia, who describes the amber trade, is known to have visited the region around 325 BC.\n\nAccording to Snorri Sturluson in the Prose Edda, Forseti is the son of Baldr and Nanna. His home is Glitnir, its name, meaning \"shining,\" refers to its silver ceiling and golden pillars, which radiated light that could be seen from a great distance. His is the best of courts; all those who come before him leave reconciled. This suggests skill in mediation and is in contrast to his fellow god Týr, who \"is not called a reconciler of men.\" However, as de Vries points out, the only basis for associating Forseti with justice seems to have been his name; there is no corroborating evidence in Norse mythology. 'Puts to sleep all suits' or 'stills all strifes' may have been a late addition to the strophe Snorri cites, from which he derives the information.\n\nThe first element in the name \"Forsetlund\" (Old Norse \"Forsetalundr\"), a farm in the parish of Onsøy ('Odin's island'), in eastern Norway, seems to be the genitive case of Forseti, offering evidence he was worshipped there.\n\nAccording to Alcuin's Life of St. Willebrord, the saint visited an island between Frisia and Denmark that was sacred to Fosite and was called Fositesland after the god worshipped there. There was a sacred spring from which water had to be drawn in silence, it was so holy. Willebrord defiled the spring by baptizing people in it and killing a cow there. Altfrid tells the same story of St. Liudger. Adam of Bremen retells the story and adds that the island was \"Heiligland\", i.e., Heligoland.\n\nThere is also a late-medieval legend of the origins of written Frisian laws. Wishing to assemble written lawcodes for all his subject peoples, Charlemagne summoned twelve representatives of the Frisian people, the \"Āsegas\" ('law-speakers'), and demanded they recite their people's laws. When they could not do so after several days, he let them choose between death, slavery, or being set adrift in a rudderless boat. They chose the last and prayed for help, whereupon a thirteenth man appeared, with a golden axe on his shoulder. He steered the boat to land with the axe, then threw it ashore; a spring appeared where it landed. He taught them laws and then disappeared. The stranger and the spring have traditionally been identified with Fosite and the sacred spring of Fositesland.\n\nModern scholarship, however, is extremely critical about this hypotheses, as the attribute of the axe is normally associated with Thor, not with Forseti.\n\nForseti appears in the Dungeons & Dragons role-playing game's pantheon, and is often chosen as a patron god by paladins. The tome Forseti is one of the legendary weapons from the twelve crusaders in .\n\n"}
{"id": "11418", "url": "https://en.wikipedia.org/wiki?curid=11418", "title": "Fiorello H. La Guardia", "text": "Fiorello H. La Guardia\n\nFiorello Henry La Guardia (; born Fiorello Enrico La Guardia, ) (December 11, 1882September 20, 1947) was an American politician. He is best known for being the 99th Mayor of New York City for three terms from 1934 to 1945 as a Republican. Previously he had been elected to Congress in 1916 and 1918, and again from 1922 through 1930. Irascible, energetic, and charismatic, he craved publicity and is acclaimed as one of the greatest mayors in American history. Only five feet, two inches (1.57 m) tall, he was called \"the Little Flower\" (\"\" is Italian for \"little flower\").\n\nLa Guardia, a Republican who appealed across party lines, was very popular in New York during the 1930s. As a New Dealer, he supported President Franklin D. Roosevelt, a Democrat, and in turn Roosevelt heavily funded the city and cut off patronage for La Guardia's enemies. La Guardia revitalized New York City and restored public faith in City Hall. He unified the transit system, directed the building of low-cost public housing, public playgrounds, and parks, constructed airports, reorganized the police force, defeated the powerful Tammany Hall political machine, and reestablished employment on merit in place of patronage jobs.\n\nLa Guardia was a domineering leader who verged on authoritarian but whose reform politics were carefully tailored to address the sentiments of his diverse constituency. He defeated a corrupt Democratic machine, presided during a depression and a world war, made the city the model for New Deal welfare and public works programs, and championed immigrants and ethnic minorities. He succeeded with the support of a sympathetic president. He secured his place in history as a tough-minded reform mayor who helped clean out corruption, brought in gifted experts, and fixed upon the city a broad sense of responsibility for its own citizens. His administration engaged new groups that had been kept out of the political system, gave New York its modern infrastructure, and raised expectations of new levels of urban possibility.\n\nLa Guardia was born in Greenwich Village in New York City. His father, Achille La Guardia, was a lapsed Catholic from Cerignola, Italy, and his mother, Irene Coen, was a Jewish woman from Trieste, then part of the Austro-Hungarian Empire; his maternal grandmother Fiorina Luzzatto Coen was a Luzzatto, a member of the prestigious Italian-Jewish family of scholars, kabbalists, and poets and had among her ancestors the famous rabbi Samuel David Luzzatto. It was in Trieste that Achille La Guardia met and married Irene. Fiorello La Guardia was raised an Episcopalian and practiced that religion all his life. His middle name \"Enrico\" was anglicized to \"Henry\" when he was a child.\n\nHe moved to Arizona with his family, where his father had a bandmaster position at Fort Whipple in the U.S. Army. La Guardia attended public schools and high school in Prescott, Arizona. After his father was discharged from his bandmaster position in 1898, Fiorello lived in Trieste. He graduated from the Dwight School, a private school on the Upper West Side of New York City.\n\nLa Guardia joined the State Department and served in U.S. consulates in Budapest, Trieste (Austria-Hungary, now Italy), and Fiume (Austria-Hungary, now Rijeka, Croatia), (1901–1906). He returned to the United States to continue his education at New York University. From 1907 to 1910, he worked as an interpreter for the U.S. Bureau of Immigration at the Ellis Island immigration station.\n\nHe graduated from New York University School of Law in 1910, was admitted to the bar the same year, and began a law practice in New York City.\n\nLa Guardia married twice. His first wife was Thea Almerigotti, an Istrian immigrant, whom he married on March 8, 1919. In June 1920 they had a daughter, Fioretta Thea, who died May 9, 1921, of spinal meningitis. His first wife died of tuberculosis on November 29, 1921, at the age of 26. In 1929 he married Marie Fisher (1895–1984) who had been his secretary while in Congress; they adopted two children, Eric Henry (born 1930) and Jean Marie (1928–62), the biological daughter of Thea's sister. \n\nLa Guardia became Deputy Attorney General of New York in January 1915. In 1916, he was elected to the U.S. House of Representatives, where he had a reputation as a fiery and devoted reformer. As a Representative, La Guardia represented an ethnically diverse slum district in East Harlem and, although barred from important committee posts because of his political independence, he was a tireless and vocal champion of progressive causes. La Guardia took office on March 4, 1917, but soon was commissioned into the United States Army Air Service; he rose to the rank of major in command of a unit of Ca.44 bombers on the Italian-Austrian front in World War I. He resigned his seat in Congress on December 31, 1919.\n\nIn 1919, La Guardia was chosen to run as the Republican candidate for the office of President of the New York City Board of Aldermen. His Democratic opponent was Robert L. Moran, an alderman from the Bronx who had succeeded to the Board presidency in 1918 when Alfred E. Smith, who had been elected board president in 1917, became governor. Michael \"Dynamite Mike\" Kelly, commander of New York's Third \"Shamrock\" Battalion, also joined the race. Tammany Hall looked with alarm upon Kelly's entrance into the campaign and tried to persuade him to withdraw his candidacy and throw his support behind Moran. When he refused, Tammany went to the New York Supreme Court and successfully sued to keep Kelly's name off the ballot. When Election Day arrived, over 3,500 of Kelly's supporters wrote Kelly's name on the ballot. This number was sufficient to defeat Moran, who lost to La Guardia by 1,363 votes.\n\nAs the son of Italian immigrants and an interpreter on Ellis Island between 1907 and 1910, La Guardia had experienced how immigration policies affected the families that came to the United States. He wanted a change for the immigrants, especially with the immigrant medical examinations that took place on Ellis Island. His passion for justice among immigrants, and his ability to speak Italian, Yiddish, and Croatian helped him in his endeavor for justice amongst immigrant factory workers and set him on his path in public service.\n\nLa Guardia, running as a Republican, won a seat in Congress from the Italian stronghold of East Harlem in 1922 and served in the House until March 3, 1933. A leading liberal reformer, La Guardia sponsored labor legislation and railed against immigration quotas. His major legislation was the Norris–La Guardia Act, cosponsored with Nebraska senator George Norris in 1932. It circumvented Supreme Court limitations on the activities of labor unions, especially as those limitations were imposed between the enactment of the Clayton Antitrust Act in 1914 and the end of the 1920s. Based on the theory that the lower courts are creations not of the Constitution but of Congress, and that Congress therefore has wide power in defining and restricting their jurisdiction, the act forbids issuance of injunctions to sustain anti-union contracts of employment, to prevent ceasing or refusing to perform any work or remain in any relation of employment, or to restrain acts generally constituting component parts of strikes, boycotts, and picketing. It also said courts could no longer enforce yellow-dog contracts, which are labor contracts prohibiting a worker from joining a union.\n\nNever an isolationist, he supported using American influence abroad on behalf of democracy or for national independence or against autocracy. Thus he supported the Irish independence movement and the anti-czarist Russian Revolution of 1917, but did not approve of Vladimir Lenin. Unlike most progressive colleagues, such as Norris, La Guardia consistently backed internationalism, speaking in favor of the League of Nations and the Inter-Parliamentary Union as well as peace and disarmament conferences. In domestic policies he tended toward socialism and wanted to nationalize and regulate; however he was never close to the Socialist Party and never bothered to read Karl Marx.\n\nAs a congressman, La Guardia was a tireless and vocal champion of progressive causes, from allowing more immigration and removing U.S. troops from Nicaragua to speaking up for the rights and livelihoods of striking miners, impoverished farmers, oppressed minorities, and struggling families. A thorn in the side of the era's plutocrats and their enablers in government, he fought for progressive income taxes, greater government oversight of Wall Street, and national employment insurance for workers idled by the Great Depression.\n\nLa Guardia was one of the first Republicans to voice his opinion about prohibition, urging that the Dry cause \"would prove disastrous in the long run\". This was breaking a taboo, given the fact that both parties \"avoided taking a stand on prohibition issues\" at the time.\n\nAs a Republican, La Guardia had to support Harding in 1920; he had to be silent in the 1928 campaign although he favored Al Smith, a Democrat. In 1929, he lost the election for mayor to incumbent Democrat Jimmy Walker by a landslide.\nIn 1932 he was defeated for re-election to the House by James J. Lanzetta, the Democratic candidate; 1932 was not a good year for Republican candidates like La Guardia, and the 20th Congressional district was shifting from a Jewish and Italian-American population to a Puerto Rican population. However, it has also been argued that powerful Tammany Hall boss Jimmy Hines was able to successfully get enough votes forged to get La Guardia unseated in this election as well.\n\nWalker and his Irish-run Tammany Hall were forced out of office by scandal and La Guardia was determined to replace him. First he had to win the nomination of both the Republican party and also the \"Fusion\" group of independents. He was not the first choice of either, for they distrusted Italians. On the other hand, La Guardia had enormous determination, high visibility, the support of reformer Samuel Seabury and the ability to ruin the prospects of any rival by a divisive primary contest. He secured the nominations and expected an easy win against hapless incumbent Mayor John P. O'Brien. However, at the last minute Joseph V. McKee entered the race as the nominee of the new \"Recovery party\". McKee was a formidable opponent because he was sponsored by Bronx Democratic boss Edward J. Flynn and apparently was favored by President Franklin Roosevelt. La Guardia made corruption his main issue. The campaign saw mud slung three ways, with La Guardia denounced as a far-left \"Red\", O'Brien as a pawn of the bosses, and McKee as an anti-Semite. La Guardia's win was based on a complex coalition of regular Republicans (mostly middle class German Americans in the boroughs outside Manhattan), a minority of reform-minded Democrats, some Socialists, a large proportion of middle-class Jews, and the great majority of Italians. The Italians had been loyal to Tammany; their switch proved decisive.\n\nLa Guardia came to office in January 1934 with five main goals:\n\nHe achieved most of the first four goals in his first hundred days, as FDR gave him 20% of the entire national CWA budget for work relief. La Guardia then collaborated closely with Robert Moses, with support from the governor, Democrat Herbert Lehman, to upgrade the decaying infrastructure. The city was favored by the New Deal in terms of funding for public works projects.\n\nLa Guardia governed in an uneasy alliance with New York's Jews and liberal WASPs, together with ethnic Italians and Germans.\n\nLa Guardia was not an orthodox Republican. He also ran as the nominee of the American Labor Party, a union-dominated anti-Tammany left wing group that supported Franklin D. Roosevelt for president beginning in 1936. La Guardia supported Roosevelt, chairing the Committee of Independent Voters for Roosevelt and Wallace with Senator George Norris during the 1940 presidential election.\n\nLa Guardia was the city's first Italian-American mayor, but was not a typical Italian New Yorker. He was a Republican Episcopalian who had grown up in Arizona and had a Triestine Jewish mother and a Catholic-turned-atheist father. He spoke several languages, reportedly including Hebrew, Croatian, German, Italian, and Yiddish. It served him well during a contentious congressional campaign in 1922. When Henry Frank, a Jewish opponent, accused him of anti-Semitism, La Guardia rejected the suggestion that he publicly disclose that his mother was Jewish as \"self-serving\". Instead, La Guardia dictated an open letter in Yiddish that was also printed in Yiddish. In it, he challenged Frank to publicly and openly debate the issues of the campaign \"ENTIRELY IN THE YIDDISH LANGUAGE.” Frank, although he was Jewish, could not speak the language and was forced to decline—and lost the election.\n\nLa Guardia loathed the gangsters who brought a negative stereotype and shame to the Italian community. His first action as mayor was to order the chief of police to arrest mob boss Lucky Luciano on whatever charges could be found. La Guardia then went after the gangsters with a vengeance, stating in a radio address to the people of New York in his high-pitched, squeaky voice, \"Let's drive the bums out of town\". In 1934 he went on a search-and-destroy mission looking for mob boss Frank Costello's slot machines, which La Guardia executed with gusto, rounding up thousands of the \"one armed bandits\", swinging a sledgehammer and dumping them off a barge into the water for the newspapers and media. In 1935 La Guardia appeared at The Bronx Terminal Market to institute a citywide ban on the sale, display, and possession of artichokes, whose prices were inflated by mobs. When prices went down, the ban was lifted. In 1936, La Guardia had special prosecutor Thomas E. Dewey, a future Republican presidential candidate, single out Lucky Luciano for prosecution. Dewey led a successful investigation into Luciano's lucrative prostitution operation, eventually sending Luciano to jail with a 30–50 year sentence. The case was made into the 1937 movie \"Marked Woman\", starring Bette Davis.\n\nLa Guardia proved successful in shutting down the burlesque theaters, whose shows offended his puritanical sensibilities.\n\nLa Guardia's admirers credit him with, among other things, restoring the economic lifeblood of New York City during and after the Great Depression. He is given credit for many massive public works programs administered by his powerful Parks Commissioner Robert Moses and employed thousands of voters. The mayor's relentless lobbying for federal funds allowed New York to develop its economic infrastructure.\n\nTo obtain large-scale federal money the mayor became a close partner of Roosevelt and New Deal agencies such as CWA, PWA and WPA, which poured $1.1 billion into the city from 1934–39. In turn he gave FDR a showcase for New Deal achievement, helped defeat FDR's political enemies in Tammany Hall (the Democratic party machine in Manhattan). He and Moses built highways, bridges and tunnels, transforming the physical landscape of New York City. The West Side Highway, East River Drive, Brooklyn Battery Tunnel, Triborough Bridge, and two airports (LaGuardia Airport, and, later, Idlewild, now JFK Airport) were built during his mayoralty.\n\n1939 was a busy year, as he opened the 1939 New York World's Fair at Flushing Meadows-Corona Park, Queens, opened New York Municipal Airport No. 2 in Queens (later renamed Fiorello H. LaGuardia Field), and had the city buy out the Interborough Rapid Transit Company and Brooklyn–Manhattan Transit Corporation, thus completing the public takeover of the subway system. When the city's newspapers were closed by a strike he famously read the comics on the radio.\n\nResponding to popular disdain for the sometimes corrupt City Council, La Guardia successfully proposed a reformed 1938 City Charter that created a powerful new New York City Board of Estimate, similar to a corporate board of directors.\n\nHe was an outspoken and early critic of Adolf Hitler and the Nazi regime. In a public address in 1934, La Guardia warned that \"part of Hitler's program is the complete annihilation of the Jews in Germany\". In 1937, speaking before the Women's Division of the American Jewish Congress, he called for the creation of a special pavilion at the upcoming New York World's Fair, \"a chamber of horrors\" for \"that brown-shirted fanatic\". He also encouraged the boycotting of German goods, led anti-Nazi rallies, and promoted legislation to facilitate the U.S. rescue of the Jewish refugees.\n\nLa Guardia's sister, Gemma La Guardia Gluck (1881–1962), and brother-in-law, Herman Gluck (a Hungarian Jew whom she met while teaching English in Europe), were living in Hungary and were arrested by the Gestapo on June 7, 1944, when the Nazis took control of Budapest. Adolf Eichmann and Heinrich Himmler knew that Gemma was La Guardia's sister and ordered her to be held as a political prisoner. She and Herman Gluck were deported to Mauthausen concentration camp in Austria, where he died, as Gemma learned from reading a newspaper account a year after her own release. She was transferred from Mauthausen to the notorious women's concentration camp at Ravensbrück, located some fifty miles from Berlin, where unbeknownst to Gemma at the time, her daughter Yolanda (whose husband also died in the camps) and baby grandson were also held for a year in a separate barracks. Gemma Gluck, who was held in Block II of the camp and assigned prisoner #44139, was one of the few survivors of this camp and wrote about her time at Ravensbrück.\n\nIn 1941 during the run-up to American involvement in World War II, President Roosevelt appointed La Guardia first director of the new Office of Civilian Defense (OCD). Roosevelt was an admirer of La Guardia; after meeting Winston Churchill for the first time he described him as \"an English Mayor La Guardia\". The OCD was the national agency responsible for preparing for blackouts, air raid wardens, sirens, and shelters in case of German air raids. The government knew that such air raids were impossible but the goal was to psychologically mobilize many thousands of middle class volunteers to make them feel part of the war effort. La Guardia remained Mayor of New York, shuttling back and forth with three days in Washington and four in the city in an effort to do justice to two herculean jobs. On top of this, he still performed other gestures, such as arranging police protection with his personal assurances for local artists Joe Simon and Jack Kirby, when they were threatened by Nazi supporters for their new patriotic comic book superhero, Captain America. After the attack on Pearl Harbor in December 1941, his role was turned over to full-time director of OCD, James M. Landis. La Guardia's popularity slipped away and he ran so poorly in straw polls in 1945 that he did not run for a fourth term.\n\nUnemployment ended, and the city was a gateway for military supplies and soldiers sent to Europe, with the Brooklyn Navy Yard providing many of the warships and the garment trade providing uniforms. The city's great financiers, however, were less important in decision making than the policy makers in Washington, and very high wartime taxes were not offset by heavy war spending. New York was not a center of heavy industry and did not see a wartime boom, as defense plants were built elsewhere. FDR refused to make La Guardia a general and was unable to provide fresh money for the city. By 1944 the city was short of funds to pay for La Guardia's new programs.\n\nLa Guardia was the director general for the United Nations Relief and Rehabilitation Administration (UNRRA) in 1946.\n\nA man of short stature, La Guardia's height is sometimes given as . According to an article in \"The New York Times\", however, his actual height was .\n\nLa Guardia was a Freemason and was a member of Garibaldi Lodge #542, in New York City.\n\nHe died of pancreatic cancer in his home at 5020 Goodridge Avenue, in the Riverdale section of The Bronx on September 20, 1947, aged 64 and is interred at Woodlawn Cemetery in The Bronx, New York City.\n\nLa Guardia was ranked first among the nation's mayors in a 1993 poll of historians and social scientists. \nAccording to biographer Mason B. Williams, his close collaboration with Roosevelt's New Deal proved a striking success in linking national money and local needs. La Guardia enabled the political recognition new groups that had been largely excluded from the political system, such as Jews and Italians. His administration (in cooperation with Robert Moses) gave New York its modern infrastructure. His far-sighted goals raised ambitions for new levels of urban possibility. According to Thomas Kessner, trends since his tenure mean that \"people would be afraid of allowing anybody to take that kind of power\".\n\nIn 1972 the United States Postal Service honored La Guardia with a 14¢ postage stamp.\n\nNew York's LaGuardia Airport, LaGuardia Community College, and other parks and buildings around New York City are named for him.\n\nA strong supporter of Zionism, LaGuardia Street and LaGuardia interchange both in Tel Aviv, Israel, were named in his honor.\n\nKnown for his love of music, La Guardia was noted for spontaneously conducting professional and student orchestras and was instrumental in the creation of the High School of Music & Art in 1936, now renamed the Fiorello H. LaGuardia High School of Music & Art and Performing Arts.\n\nLa Guardia was a fictionalized character in many films – in \"Ghostbusters II\" La Guardia's ghost talks to New York Mayor Lenny (played by David Margulies). He was also the subject of the hit Broadway musical \"Fiorello!\", portrayed by actor Tom Bosley and in \"The Little Flower\", portrayed by Tony Lo Bianco. \"Fiorello!\" won a Pulitzer Prize, and ran for two years (1959–1961).\n\n\n\n\n \n"}
{"id": "11424", "url": "https://en.wikipedia.org/wiki?curid=11424", "title": "Flag", "text": "Flag\n\nA flag is a piece of fabric (most often rectangular or quadrilateral) with a distinctive design that is used as a symbol, as a signaling device, or as decoration. The term \"flag\" is also used to refer to the graphic design employed, and flags have since evolved into a general tool for rudimentary signalling and identification, especially in environments where communication is similarly challenging (such as the maritime environment where semaphore is used). National flags are patriotic symbols with varied wide-ranging interpretations, often including strong military associations due to their original and ongoing military uses. Flags are also used in messaging, advertising, or for other decorative purposes. The study of flags is known as vexillology, from the Latin word \"vexillum\", meaning flag or banner.\n\nDue to the use of flags by military units, 'flag' is also used as the name of some military units. A flag (Arabic: لواء) is equivalent to a brigade in Arab countries, and in Spain, a flag (Spanish: \"bandera\") is a battalion-equivalent in the Spanish Legion.\n\nIn antiquity, field signs or standards were used in warfare that can be categorized as vexilloid or 'flag-like'. Examples include the Sassanid battle standard Derafsh Kaviani, and the standards of the Roman legions such as the eagle of Augustus Caesar's Xth legion, or the dragon standard of the Sarmatians; the latter was let fly freely in the wind, carried by a horseman, but judging from depictions it was more similar to an elongated dragon kite than to a simple flag.\n\nDuring the High Middle Ages flags came to be used primarily as a heraldic device in battle, allowing more easily to identify a knight than only from the heraldic device painted on the shield. Already during the high medieval period, and increasingly during the Late Middle Ages, city states and communes such as those of the Old Swiss Confederacy also began to use flags as field signs. Regimental flags for individual units became commonplace during the Early Modern period.\n\nDuring the peak of the age of sail, beginning in the early 17th century, it was customary (and later a legal requirement) for ships to carry flags designating their nationality; these flags eventually evolved into the national flags and maritime flags of today. Flags also became the preferred means of communications at sea, resulting in various systems of flag signals; \"see, International maritime signal flags\".\n\nUse of flags outside of military or naval context begins only with the rise of nationalist sentiment by the end of the 18th century; the earliest national flags date to that period, and during the 19th century it became common for every sovereign state to introduce a national flag. \n\nOne of the most popular uses of a flag is to symbolize a nation or country. Some national flags have been particularly inspirational to other nations, countries, or subnational entities in the design of their own flags. Some prominent examples include:\nIt is said that the Dutch Tricolour has inspired many flags but most notably those of Russia, New York City, and South Africa (the 1928–94 flag as well the current flag). As the probable inspiration for the Russian flag, it is the source too for the Pan-Slavic colours red, white and blue, adopted by many Slavic states and peoples as their symbols; examples are Slovakia, Serbia, and Slovenia.\n\nNational flag designs are often used to signify nationality in other forms, such as flag patches.\n\nA \"civil\" flag is a version of the national flag that is flown by civilians on non-government installations or craft. The use of civil flags was more common in the past, in order to denote buildings or ships that were not manned by the military. In some countries the civil flag is the same as the war flag or state flag, but without the coat of arms, such as in the case of Spain, and in others it's an alteration of the war flag.\n\nSeveral countries (including the United Kingdom and the Soviet Union) have had unique flags flown by their armed forces, rather than the national flag.\n\nOther countries' armed forces (such as those of the United States or Switzerland) use their standard national flag. The Philippines' armed forces may use their standard national flag, but during times of war the flag is turned upside down. Bulgaria's flag is also turned upside down during times of war. These are also considered war flags, though the terminology only applies to the flag's military usage.\n\nLarge versions of the war flag flown on the warships of countries' navies are known as battle ensigns. In war waving a white flag is a banner of truce or surrender.\n\nFour distinctive African flags currently in the collection of the National Maritime Museum in Britain were flown in action by Itsekiri ships under the control of Nana Olomu during conflict in the late 19th century. One is the flag generally known as the Benin flag and one is referred to as Nana Olomu's flag.\n\nAmong international flags are the Flag of the United Nations, the Olympic flag, and the Paralympic flag.\n\nFlags are particularly important at sea, where they can mean the difference between life and death, and consequently where the rules and regulations for the flying of flags are strictly enforced. A national flag flown at sea is known as an ensign. A courteous, peaceable merchant ship or yacht customarily flies its ensign (in the usual ensign position), together with the flag of whatever nation it is currently visiting at the mast (known as a courtesy flag). To fly one's ensign alone in foreign waters, a foreign port or in the face of a foreign warship traditionally indicates a willingness to fight, with cannon, for the right to do so. As of 2009, this custom is still taken seriously by many naval and port authorities and is readily enforced in many parts of the world by boarding, confiscation and other civil penalties.\n\nIn some countries yacht ensigns are different from merchant ensigns in order to signal that the yacht is not carrying cargo that requires a customs declaration. Carrying commercial cargo on a boat with a yacht ensign is deemed to be smuggling in many jurisdictions. There is a system of international maritime signal flags for numerals and letters of the alphabet. Each flag or pennant has a specific meaning when flown individually. As well, semaphore flags can be used to communicate on an \"ad hoc\" basis from ship to ship over short distances.\nTraditionally, a vessel flying under the courtesy flag of a specific nation, regardless of the vessel's country of registry, is considered to be operating under the law of her 'host' nation.\n\nAnother category of maritime flag flown by some United States Government ships is the distinguishing mark. Although the United States Coast Guard has its own service ensign, all other U.S. Government ships fly the national ensign their service ensign, following United States Navy practice. To distinguish themselves from ships of the Navy, such ships historically have flown their parent organisation's flag from a forward mast as a distinguishing mark. Today, for example, commissioned ships of the National Oceanic and Atmospheric Administration (NOAA) fly the NOAA flag as a distinguishing mark.\n\nFlags are usually rectangular in shape (often in the ratio 2:3, 1:2, or 3:5), but may be of any shape or size that is practical for flying, including square, triangular, or swallow tailed. A more unusual flag shape is that of the flag of Nepal, which is in the shape of two stacked triangles. Other unusual flag shapes include the flag of Ohio and the flag of Tampa.\n\nMany flags are dyed through and through to be inexpensive to manufacture, such that the reverse side is the mirror image of the obverse (front) side, generally the side displayed when the flag is flying from the observer's point of view from left, the side of the pole, to right. This presents two possibilities:\n\nSome complex flag designs are not intended for through and through implementation, requiring separate obverse and reverse sides if made correctly. In these cases there is a design element (usually text) which is not symmetric and should be read in the same direction, regardless of whether the hoist is to the viewer's left or right. These cases can be divided into two types:\nCommon designs on flags include crosses, stripes, and divisions of the surface, or \"field\", into bands or quarters—patterns and principles mainly derived from heraldry. A heraldic coat of arms may also be flown as a banner of arms, as is done on both the state flag of Maryland and the flag of Kiribati.\n\nThe \"de jure\" flag of Libya under Muammar Gaddafi, which consisted of a rectangular field of green, was for a long period the only national flag using a single colour and no design or insignia. However, other historical states have also used flags without designs or insignia, such as the Soviet Republic of Hungary, whose flag was a plain field of red.\n\nColours are normally described with common names, such as \"red\", but may be further specified using colorimetry.\n\nThe largest flag flown from a flagpole worldwide, according to Guinness World Records, is the flag of Mexico flown in Piedras Negras, Mexico. This flag was about . The largest flag ever made was the flag of Qatar; the flag, which measures at , was completed in December 2013 in Doha.\n\nThe general parts of a flag are: canton—the upper inner section of the flag; field or ground—the entire flag except the canton, and the field and hoist ends; fly end—the furthest edge from the hoist end; and hoist end—the edge used to attach the flag to the hoist.\n\nVertical flags are sometimes used in lieu of the standard horizontal flag in central and eastern Europe, particularly in the German-speaking countries. This practice came about because the relatively brisk wind needed to display horizontal flags is not common in these countries.\n\nThe standard horizontal flag (no. 1 in the preceding illustration) is nonetheless the form most often used even in these countries.\n\nThe vertical flag (German: \"Hochformatflagge\" or \"Knatterflagge\"; no. 2) is a vertical form of the standard flag. The flag's design may remain unchanged (No. 2a) or it may change, e.g. by changing horizontal stripes to vertical ones (no. 2b). If the flag carries an emblem, it may remain centered or may be shifted slightly upwards.\n\nThe vertical flag for hoisting from a beam (German: \"Auslegerflagge\" or \"Galgenflagge\"; no. 3) is additionally attached to a horizontal beam, ensuring that it is fully displayed even if there is no wind.\n\nThe vertical flag for hoisting from a horizontal pole (German: \"Hängeflagge\"; no. 4) is hoisted from a horizontal pole, normally attached to a building. The topmost stripe on the horizontal version of the flag faces away from the building.\n\nThe vertical flag for hoisting from a crossbar or banner (German: \"Bannerflagge\"; no. 5) is firmly attached to a horizontal crossbar from which it is hoisted, either by a vertical pole (no. 5a) or a horizontal one (no. 5b). The topmost stripe on the horizontal version of the flag normally faces to the left.\n\nFlags can play many different roles in religion. In Buddhism, prayer flags are used, usually in sets of five differently coloured flags. Many national flags and other flags include religious symbols such as the cross, the crescent, or a reference to a patron saint. Flags are also adopted by religious groups and flags such as the Jain flag, Sikh flag, sindhi flag and the Christian flag are used to represent a whole religion.\n\nAs languages rarely have a flag designed to represent them, it is a common but unofficial practice to use national flags to identify them. The practice is deprecated because it is often considered insulting and because flags tend to evoke feelings other than the intended meaning. Examples of such use include:\nThough this can be done in an uncontroversial manner in some cases, this can easily lead to some problems for certain languages:\nIn this second case, common solutions include symbolising these languages by:\n\nThus, on the Internet, it is common to see the English language associated with the flag of the United Kingdom, or sometimes the flag of England, the flag of the United States or a U.S.-UK mixed flag, usually divided diagonally.\n\nSince many flags have a simple design, there is bound to be cases of flags with similar designs. From 1948 to 1989, the flag of Romania had an insignia in the middle of the tricolour flag. In 1989 the insignia was removed, reverting Romania's flag back to an earlier version. This version matched the design which had been adopted by Chad in 1959. This has concerned the Chadian government, and in 2004 they requested that the United Nations should consider it an issue. In response, the Romanian President Ion Iliescu stated to the media, \"The tricolour belongs to us. We will not give up the tricolour\".\n\nIn certain cases, flag similarities are not coincidental, but the result of a conscious choice.\n\nThe Pan-Arab colours black, white, green, and red are first known from the flag of the Arab Revolt in 1916. The colours were intended to represent certain Arab dynasties. Countries currently using flags with the Pan-Arab colours include Jordan, Kuwait, Palestine and Sudan.\n\nThe tricolor flag of Russia, inspired by the flag of the Netherlands, was introduced in the late 17th century. Based on this flag, the first Pan-Slav congress defined the Pan-Slavic colours red, blue and white. Among former and current countries beside Russia using flags with these colours, are Yugoslavia and the successor states Croatia, Serbia and Slovenia as well as the Czech Republic and Slovakia.\n\nThe oldest flag of the Nordic countries is the flag of Denmark with a description dating from 1748. The design has a cross symbol in a rectangular field, with the center of the cross shifted towards the hoist. This basic design is called Nordic cross and has been adopted by the other Nordic countries Finland, Iceland, Norway and Sweden as well as the dependent territories of Faroe Islands and Åland. Similar flags are also used as regional flags, most prominently the semi-official flag of Scania. The design has also been used outside the Nordic countries in order to underline a cultural connection. Examples are Shetland and Orkney.\n\nLiberia was founded by freed African-American and ex-Caribbean slaves as settlers from the United States and the Caribbean. When Liberia gained independence in 1847, the flag of the new state was modelled on the national flag of the United States, although the symbolism of the elements were differently interpreted.\n\nThe Red Cross on white background as a protection symbol was declared at the First Geneva Convention in 1864. The emblem was formed by reversing the colours of the Swiss flag out of respect to Switzerland.\n\nBecause of their ease of signalling and identification, flags are often used in sports.\n\n\nSome countries use diplomatic flags, such as the United Kingdom and the Kingdom of Thailand\n\nSocial and political movements have adopted flags, to increase their visibility and as a unifying symbol.\n\nThe socialist movement uses red flags to represent their cause. The anarchist movement has a variety of different flags, but the primary flag associated with them is the black flag. In the Spanish civil war, the anarchists used the red-and-black bisected flag. In the 20th century, the rainbow flag was adopted as a symbol of the LGBT social movements. Its derivatives include the Bisexual pride and transgender pride flags.\n\nSome of these political flags have become national flags, such as the red flag of the Soviet Union and national socialist banners for Nazi Germany. The present Flag of Portugal is based on what had been the political flag of the Portuguese Republican Party previous to the 5 October 1910 revolution which brought this party to power.\n\nSome disability advocacy groups have adopted flags to raise awareness of their causes.\n\nThe Epilepsy Awareness Flag includes a prominent lowercase letter 'e' on a white background.\n\nWhen the World Federation of the Deaf adopted its own flag, this action caused some controversy within the deaf community due to the popularity of another flag which was already being flown by many deaf people and related organisations.\n\nFlags are often representative of an individual's affinity or allegiance to a country, team or business and can be presented in various ways. A popular trend that has surfaced revolves around the idea of the 'mobile' flag in which an individual displays their particular flag of choice on their vehicle. These items are commonly referred to as car flags and are usually manufactured from high strength polyester material and are attached to a vehicle via a polypropylene pole and clip window attachment.\n\nIn Australia, Canada, New Zealand, the Philippines, and the United Kingdom, a pair of red-yellow flags is used to mark the limits of the bathing area on a beach, usually guarded by surf lifesavers. If the beach is closed, the poles of the flags are crossed. The flags are coloured with a red triangle and a yellow triangle making a rectangular flag, or a red rectangle over a yellow rectangle. On many Australian beaches there is a slight variation with beach condition signaling. A red flag signifies a closed beach (in the UK also other dangers), yellow signifies strong current or difficult swimming conditions, and green represents a beach safe for general swimming. In Ireland, a red and yellow flag indicates that it is safe to swim; a red flag that it is unsafe; and no flag indicates that there are no lifeguards on duty. Blue flags may also be used away from the yellow-red lifesaver area to designate a zone for surfboarding and other small, non-motorised watercraft.\n\nReasons for closing the beach include:\n\nA surf flag exists, divided into four quadrants. The top left and bottom right quadrants are black, and the remaining area is white.\n\nSignal flag \"India\" (a black circle on a yellow square) is frequently used to denote a \"blackball\" zone where surfboards cannot be used but other water activities are permitted.\n\nRailways use a number of coloured flags. When used as wayside signals they usually use the following meanings (exact meanings are set by the individual railroad company):\n\nAt night, the flags are replaced with lanterns showing the same colours.\n\nFlags displayed on the front of a moving locomotive are an acceptable replacement for classification lights and usually have the following meanings (exact meanings are set by the individual railroad company):\n\nAdditionally, a railroad brakeman will typically carry a red flag to make his or her hand signals more visible to the engineer. Railway signals are a development of railway flags.\n\nA flagpole, flagmast, flagstaff, or staff can be a simple support made of wood or metal. If it is taller than can be easily reached to raise the flag, a cord is used, looping around a pulley at the top of the pole with the ends tied at the bottom. The flag is fixed to one lower end of the cord, and is then raised by pulling on the other end. The cord is then tightened and tied to the pole at the bottom. The pole is usually topped by a flat plate or ball called a \"truck\" (originally meant to keep a wooden pole from splitting) or a finial in a more complex shape. Very high flagpoles may require more complex support structures than a simple pole, such as a guyed mast.\n\nDwajasthambam are flagpoles commonly found at the entrances of South Indian Hindu temples.\n\nSince 23 September 2014, the tallest free-standing flagpole in the world is the Jeddah Flagpole in Saudi Arabia at a height of , exceeding the former record holder the Dushanbe Flagpole in Tajikistan (height: ), National Flagpole in Azerbaijan (height: ) and the North Korean flagpole at Kijŏng-dong (height: ).\n\nThe tallest flagpole in the United Kingdom from 1959 until 2013 stood in Kew Gardens. It was made from a Canadian Douglas-fir tree and was in height.\n\nThe current tallest flagpole in the United States (and the tallest flying an American flag) is the pole completed before Memorial Day 2014 and custom-made with an base in concrete by wind turbine manufacturer Broadwind Energy. It is situated on the north side of the Acuity Insurance headquarters campus along Interstate 43 in Sheboygan, Wisconsin, and is visible from Cedar Grove. The pole can fly a 220-pound flag for in light wind conditions and a heavier 350-pound flag in higher wind conditions.\n\nFlagpoles can be designed in one piece with a taper (typically a steel taper or a Greek entasis taper), or be made from multiple pieces to make them able to expand. In the United States, ANSI/NAAMM guide specification FP-1001-97 covers the engineering design of metal flagpoles to ensure safety.\n\nHoisting the flag is the act of raising the flag on the flagpole. Raising or lowering flags, especially national flags, usually involves ceremonies and certain sets of rules, depending on the country, and usually involve the performance of a national anthem.\n\nA flag-raising squad is a group of people, usually troops, cadets, or students, that marches in and brings the flags for the flag-hoisting ceremony. Flag-hoisting ceremonies involving flag-raising squads can be simple or elaborate, involving large numbers of squads. Elaborate flag-hoisting ceremonies are usually performed on national holidays.\n\nSemaphore is a form of communication that utilizes flags. The signalling is performed by an individual using two flags (or lighted wands), the positions of the flags indicating a symbol. The person who holds the flags is known as the signalman. This form of communication is primarily used by naval signallers. This technique of signalling was adopted in the early 19th century and is still used in various forms today.\n\nThe colours of the flags can also be used to communicate. For example; a white flag means, among other things, surrender or peace, a red flag can be used as a warning signal, and a black flag can mean war, or determination to defeat enemies.\n\nOrientation of a flag is also used for communication, though the practice is rarely used given modern communication systems. Raising a flag upside-down was indicative that the raising force controlled that particular area, but that it was in severe distress.\n\nWhen blown by the wind, flags are subject to wave-like motions that grow in amplitude along the length of the flag. This is sometimes ascribed to the flag pole giving vortex shedding; however, flags that are held by lanyards also can be seen to flap.\n\n\n\n"}
{"id": "11425", "url": "https://en.wikipedia.org/wiki?curid=11425", "title": "Father Dougal McGuire", "text": "Father Dougal McGuire\n\nFather Dougal McGuire is a character in the Channel 4 sitcom \"Father Ted\". Created by Arthur Mathews and Graham Linehan, Dougal was portrayed by comedian Ardal O'Hanlon for the programme's three series. The character is a childlike, simple-minded Roman Catholic priest exiled to Craggy Island, a small island off the coast of Galway.\n\nDougal originated as an unseen character in a short-lived stand-up routine performed by Mathews in the late 1980s. Portraying an early version of Father Ted Crilly on-stage, Mathews occasionally discussed Dougal as one of Ted's great friends. In 1994, the writers took \"Father Ted\" to television, casting O'Hanlon as the on-screen Dougal.\n\nArthur Mathews created the character of Father Ted while working at \"Hot Press\" in 1987–89. During production weekends, he and Paul Woodfull had the idea for The Joshua Trio, a comedic U2 tribute band. The band performed various warm-up sketches written by Mathews, Woodfull, and Graham Linehan, who joined in a non-musical capacity. These sketches included stand-up performed by Mathews in-character as Father Ted Crilly. As Ted, Mathews sometimes read from a book, \"Notes from Africa\", purportedly written by Father Dougal McGuire, a missionary friend who described his experiences of being attacked and chased by natives. In one sketch, Ted discussed his concern for Dougal, who had been voted Most Unpopular Priest in Africa for two years running and was spending Christmas up a tree in the grounds of The Bob Geldof Centre.\n\nIn 1990, Linehan and Mathews began writing \"Irish Lives\", a six-part comedy television series. The show would have taken the form of a mockumentary, with each episode focusing on interviewing a different character, one of whom was Father Ted Crilly. The story involved Ted returning to his seminary to catch up with old friends. When producer Geoffrey Perkins asked Linehan and Mathews to discard the mockumentary format and expand the Father Ted episode to a traditional sitcom, Father Dougal became one of the main characters. When writing Dougal, Linehan and Mathews drew on Stan Laurel, incorporating some of Linehan's own behaviour during moments of confusion.\n\nLinehan and Mathews saw O'Hanlon in a modernised Shakespeare play broadcast by RTÉ, and were impressed by the \"weird, gormless\" face he could pull. Linehan later said, \"That was Dougal right there. He was just spot-on and he became our secret weapon. The show took off so quickly because Ardal was so instantly funny.\" The writers have said that the only other actor they feel might have worked in the role is Don Wycherley, who plays Dougal's Rugged Island counterpart, Father Cyril McDuff, in the show.\n\nThere have been several attempts to remake the show for American audiences. In 2004, it was reported that Graham Norton (who played Father Noel Furlong in \"Father Ted\") had signed on to play Dougal alongside Steve Martin as Ted. No remake has yet entered production.\n\nReferences to Dougal's family are rare. In \"Grant Unto Him Eternal Rest\", he mentions that his parents are dead, and also refers to an uncle who died after his heart stopped beating for a week. It is unclear how Dougal entered the priesthood, with Ted wondering, \"Dougal, how did you get into the Church? Was it, like, collect twelve crisp packets and become a priest?\"\n\nBy the time the show begins, Dougal has been exiled to Craggy Island as punishment for unknown misdeeds. In an early interview, the writers stated that it involved \"a baptism gone wrong\". In \"The Passion of Saint Tibulus\", Bishop Brennan says that Dougal cannot be allowed back into \"the real world\" after \"the Blackrock incident\", in which hundreds of nuns' lives were \"irreparably damaged\".\n\nOn the Channel 4 website for Father Ted, the profile for Father Dougal states that 'Dougal was relegated to the island after an unfortunate incident on a SeaLink ferry that put the lives of hundreds of nuns in danger.'\n\nIn \"Old Grey Whistle Theft\", Dougal mentions that he is 25 years old.\n\nIn the 2011 documentary \"Unintelligent Design\", Linehan said that Dougal had been conceived as a cross between wide-eyed bartender Woody in \"Cheers\" and roadsweeper Trigger in \"Only Fools and Horses\". In another interview, they mentioned Latka Gravas from \"Taxi\" as an influence and compared the relationship between Ted and Dougal to that between Don Quixote and Sancho Panza: \"Alongside the wily priest who would lie at the drop of a hat we wanted a gormless idiot who was the very model of innocence.\"\n\nFor his portrayal of Dougal, O'Hanlon turned to Laurel and Hardy and \"Fawlty Towers\"s bumbling waiter Manuel. O'Hanlon also drew inspiration from his child sister, as well as dogs, explaining: \"Dougal had to be more than just stupid. He had to be otherworldly and very, very strange. I saw Dougal as very doglike, very puppyish and lovable, and really loyal to Ted.\"\n\nAfter the first episode aired, Ben Thompson of \"The Independent\" singled out O'Hanlon as \"the real star of the show\", and said that Dougal's \"holy-fool innocence\" as \"worthy of James Stewart\". Writing for the \"Irish Examiner\", Ed Power said that while the \"meme-worthy\" Dougal and Jack received the most attention at the time of broadcast, Morgan's straight-man performance was the highlight in retrospect. Morgan attributed the show's success to the appealing double-act formed by Dougal, \"an idiot who knows nothing\", and Ted, \"an idiot who thinks he knows something but actually knows nothing.\"\n\nAs testament to the character's enduring popularity, Irish bookmakers humorously began collecting bets on whether Dougal would succeed Pope John Paul II upon his death. The odds were 1,000-1 (better odds than some genuine candidates), and some small stakes were actually received.\n\nIn 2001, O'Hanlon reprised the role of Dougal for a series of PBS advertisements to coincide with \"Father Ted\"s American broadcast; these segments were included on later DVD releases as \"Fundraising with Father Dougal\".\n"}
{"id": "11426", "url": "https://en.wikipedia.org/wiki?curid=11426", "title": "Flores", "text": "Flores\n\nFlores (Indonesian: Pulau Flores) is one of the Lesser Sunda Islands, a group of islands in the eastern half of Indonesia. The population was 1,831,000 in the 2010 census and the largest town is Maumere. The name \"Flores\" is derived from the Portuguese for \"flowers\".\n\nFlores is located east of Sumbawa and Komodo and west of Lembata and the Alor Archipelago. To the southeast is Timor. To the south, across the Sumba Strait, is Sumba island and to the north, beyond the Flores Sea, is Sulawesi.\n\nAmong all islands containing Indonesian territory, Flores is the 10th most populous after Java, Sumatra, Borneo (Kalimantan), Sulawesi, New Guinea, Bali, Madura, Lombok, and Timor and also the 10th biggest island of Indonesia.\n\nUnlike most islands in the Indonesian archipelago, the name \"Flores\" was given by the Portuguese, from \"Cabo de Flores\" (Cape of Flowers), the Portuguese term for the eastern part of the island. This part of the island, originally called Kopondai, was so named by the Portuguese because of the flowering \"Delonix regia\" trees found there. The original name of Flores was \"Nipa\", referring to the serpent.\n\nPortuguese traders and missionaries came to Flores in the 16th century, mainly to Larantuka and Sikka. Their influence is still discernible in Sikka's language, culture and religion. The first Portuguese visit took place in 1511, through the expedition of António de Abreu and his vice-captain Francisco Serrão, en route through the Sunda islands.\n\nThe Dominican order was extremely important in this island, as well as in the neighbouring islands of Timor and Solor. When in 1613 the Dutch attacked the Fortress of Solor, the population of this fort, led by the Dominicans, moved to the harbor town of Larantuka, on the eastern coast of Flores. This population was mixed, of Portuguese and local islanders descent and Larantuqueiros, Topasses or, as Dutch knew them, the 'Black Portuguese' (Swarte Portugueezen).\n\nThe Larantuqueiros or Topasses became the dominant sandalwood trading people of the region for the next 200 years. This group used Portuguese as the language for worship, Malay as the language of trade and a mixed dialect as mother tongue. This was observed by William Dampier, an English privateer visiting the Island in 1699:\n\nIn 1846, Dutch and Portuguese initiated negotiations towards delimiting the territories but these negotiations led nowhere. In 1851 Lima Lopes, the new governor of Timor, Solor and Flores, agreed to sell eastern Flores and the nearby islands to the Dutch in return for a payment of 200,000 Florins in order to support his impoverished administration. Lima Lopes did so without the consent of Lisbon and was dismissed in disgrace, but his agreement was not rescinded and in 1854 Portugal ceded all its historical claims on Flores. After this, Flores became part of the territory of Dutch East Indies.\n\nDuring World War II a Japanese invasion force landed at Reo on 14 May 1942 and occupied Flores.\n\nAfter the war Flores became part of independent Indonesia.\n\nOn 12 December 1992, an earthquake measuring 7.8 on the Richter scale occurred, killing 2,500 people in and around Maumere, including islands off the North coast.\n\nIn 2017 two men were killed in Flores due to land disputes between warrior clans; the Mbehel, a West Mangarrai mountain tribe, and the Rangko from Sulawesi island who helped build Manggarai and were given land near Labuan Bajo by the Manggarai king.\n\nFlores is part of the East Nusa Tenggara province. The island along with smaller minor islands are split into eight regencies (local government districts); from west to east these are: Manggarai Barat (West Manggarai), Manggarai Tengah (Central Manggarai), Manggarai Timur (East Manggarai), Ngada, Nagekeo, Ende, Sikka and Flores Timur (East Flores). Flores has 39.1% of the East Nusa Tenggara provincial population , and the most Indonesians of all islands in the province.\n\nMain Cities in Flores are Labuan Bajo, Ruteng, Bajawa, Ende, Maumere and Larantuka\n\nThe west coast of Flores is one of the few places, aside from the island of Komodo itself, where the Komodo dragon can be found in the wild, and is part of Komodo National Park, a UNESCO World Heritage Site. Kelimutu National Park is the second national park designated on Flores to protect endangered species. The Flores giant rat is also endemic to the island, and Verhoeven's giant tree rat was formerly present. These giant rodents are considered examples of island gigantism.\n\nFlores was also the habitat of several extinct dwarf forms of the proboscidean \"Stegodon\", the most recent (\"Stegodon florensis insularis\") disappearing approximately 12,000 years ago and the diminutive \"Homo floresiensis\". It is speculated by scientists that limited resources and an absence of advanced predators made the few megafaunal species that reached the island subject to insular dwarfism.\n\nIn September 2003, at Liang Bua Cave in western Flores, paleoanthropologists discovered small skeletons that they described as a previously unknown hominin species, \"Homo floresiensis\". These are informally named \"hobbits\" and appear to have stood about tall.\n\nThis hominin had originally been considered to be remarkable for its survival until relatively recent times, only 12,000 years ago. However, by 2016, more extensive stratigraphic and chronological work has pushed the dating of the most recent evidence of their existence back to 50,000 years ago.\n\nThere are many languages spoken on the island of Flores, all of them belonging to the Austronesian family. In the centre of the island in the districts of Ngada, Nagekeo, and Ende there is what is variously called the Central Flores Dialect Chain or the Central Flores Linkage. Within this area there are slight linguistic differences in almost every village. At least six separate languages are identifiable. These are from west to east: Ngadha, Nage, Keo, Ende, Lio and Palu'e, which is spoken on the island with the same name of the north coast of Flores. Locals would probably also add So'a and Bajawa to this list, which anthropologists have labeled dialects of Ngadha.\n\nThe peoples of Flores are almost entirely Roman Catholic Christians, whereas most other Indonesians are Muslim. As a consequence, Flores may be regarded as surrounded by a religious border. The prominence of Catholicism on the island results from its colonisation by Portugal. In other parts of Indonesia with significant Christian populations, such as the Maluku Islands and Sulawesi, the geographical divide is less rigid and Muslims and Christians sometimes live side by side. Flores thereby also has less religious violence that has sporadically occurred in other parts of Indonesia. There are several churches on the island.\n\nThe most famous tourist attraction in Flores is the Kelimutu volcano which containing three colored lakes, located in the district of Ende close to the town of Moni, although you can also visit Inierie vulcano near Bajawa town. These crater lakes are in the caldera of a volcano, and fed by a volcanic gas source, resulting in highly acidic water. The colored lakes change colors on an irregular basis, depending on the oxidation state of the lake from bright red through green and blue.\n\nThere are snorkelling and diving locations along the north coast of Flores, most notably Maumere and Riung. However, due to the destructive practice of local fishermen using bombs to fish, and locals selling shells to tourists, combined with the after effects of a devastating tsunami in 1992, the reefs have slowly been destroyed.\n\nLabuan Bajo town located on the western tip is often used by tourists as a base to visit Komodo and Rinca islands. Labuan bajo also attracts scuba divers, as whale sharks inhabit the waters around Labuan bajo.\n\nThe Luba and Bena villages include traditional houses in Flores, Bena is also noted for its Stone Age megaliths.\n\nLarantuka, on the isle's eastern end, is known for its Holy Week festivals.\n\nIn recent years, local tourist firms around Kelimutu have begun promoting cycling tours around Flores, some of which take up to five or six days depending on the particular program.\n\nIn addition to tourism, the main economic activities on Flores are agriculture, fishing and seaweed production. The primary food crops being grown on Flores are rice, maize, sweet potato and cassava, while the main cash crops are coffee, coconut, candle nut and cashew. Flores is one of the newest origins for Indonesian coffee. Previously, most Arabica coffee (\"Coffea arabica\") from Flores was blended with other origins. Now, demand is growing for this coffee because of its heavy body and sweet chocolate, floral and woody notes.\n\nThere are at least six airports in Flores distributed along the island, ordered from west to east:\n\n\n"}
{"id": "11427", "url": "https://en.wikipedia.org/wiki?curid=11427", "title": "First Punic War", "text": "First Punic War\n\nThe First Punic War (264 to 241 BC) was the first of three wars fought between Ancient Carthage and the Roman Republic. For more than 20 years, the two powers struggled for supremacy, primarily on the Mediterranean island of Sicily and its surrounding waters, and also in North Africa. The war signalled the beginning of a strategic transformation in the western Mediterranean. Carthage began the war as the great sea-power of the western Mediterranean, while Rome had but a small fleet of fighting ships. Over the course of the war, Rome built up a powerful navy, developed new naval tactics, and strategically used their navy, army, and local political alliances on Sicily in order to achieve a victory that expelled the Carthaginians from Sicily. The First Punic War ended with a treaty between Rome and Carthage, but years of bloodshed were to follow in the Second and Third Punic Wars before the strategic issue of power in the western Mediterranean was resolved in favour of Rome, and in the total destruction of Carthage.\n\nThe series of wars between Rome and Carthage took the name \"Punic\" from the Latin name for the Carthaginians, \"Punici\". This is derived from \"Phoenici\"s (Phoenicians), and it refers to the Carthaginian heritage as Phoenician colonists. A Carthaginian name(s) for the conflicts does not survive in any records.\n\nRome had recently emerged as the leading city-state in the Italian Peninsula, a wealthy, powerful, expansionist republic with a successful citizen army. Over the past one hundred years, Rome had come into conflict, and defeated rivals on the Italian peninsula, then incorporated them into the Roman political world. First the Latin League was forcibly dissolved during the Latin War, then the power of the Samnites was broken during the three prolonged Samnite wars, and then the Greek cities of Magna Graecia (southern Italy) submitted to Roman power at the conclusion of the Pyrrhic War. By the beginning of the First Punic War, the Romans had secured the whole of the Italian peninsula, except Gallia Cisalpina in the Po Valley.\n\nCarthage was a republic that dominated the political, military and economic affairs of the western Mediterranean Sea, especially on the North African coasts and islands, and above all, due to its navy. It originated as a Phoenician colony in Africa, near modern Tunis. Carthage had become a wealthy centre for trade networks extending from Gadir (Cádiz) along the coasts of southern Iberia and North Africa, across the Balearic Islands, Corsica, Sardinia, and the western half of Sicily, to the ports of the eastern Mediterranean, including Tyre, its mother city, on the shores of the Levant. At the height of power, just before the First Punic War, Carthage was hostile to foreign ships (such as Roman and Greek vessels) in the western Mediterranean.\n\nNorth African peoples such as the Berbers in the area around Carthage were loosely associated with Carthage. In the midst of the First Punic War some tribes would rebel against Carthage, opening a second front while the Carthaginians battled the Romans in Sicily.\n\nGreek colonists were also a major presence in the western Mediterranean, following centuries of colonial settlement, trade and conflicts with Rome over Magna Graecia and with Carthage over places such as Sicily. The rich, strategically influential, and well-fortified Greek colony of Syracuse was politically independent of Rome and Carthage. Hostilities of the First Punic War began with developments involving the Romans, Carthaginians, and Greek colonists in Sicily and southern Italy.\n\nIn 288 BC, the Mamertines, a group of Italian (Campanian) mercenaries originally hired by Agathocles of Syracuse, occupied the city of Messana (modern Messina) in the north-eastern tip of Sicily, killing all the men and taking the women as their wives. At the same time, a group of Roman troops made up of Campanian \"citizens without the vote\" also seized control of Rhegium, lying across the Straits of Messina on the mainland of Italy. In 270 BC, the Romans regained control of Rhegium and severely punished the survivors of the revolt. In Sicily, the Mamertines ravaged the countryside and collided with the expanding regional empire of the independent city of Syracuse. Hiero II, tyrant of Syracuse, defeated the Mamertines near Mylae on the Longanus River. Following their defeat, the Mamertines appealed to both Rome and Carthage for assistance. The Carthaginians acted first, approached Hiero to take no further action and convinced the Mamertines to accept a Carthaginian garrison in Messana. Either unhappy with the prospect of a Carthaginian garrison or convinced that the recent alliance between Rome and Carthage against Pyrrhus reflected cordial relations between the two, the Mamertines, hoping for more reliable protection, petitioned Rome for an alliance. However, the rivalry between Rome and Carthage had grown since the war with Pyrrhus and that alliance was simply no longer feasible.\n\nAccording to the historian Polybius, considerable debate took place in Rome on the question as to whether to accept the Mamertines' appeal for help and thus likely enter into a war with Carthage. The Romans did not wish to come to the aid of soldiers who had unjustly stolen a city from its rightful possessors, and they were still recovering from the insurrection of Campanian troops at the Battle of Rhegium in 271 BC. However, many were also unwilling to see Carthaginian power in Sicily expand even further. Leaving them at Messana would give the Carthaginians a free hand to deal with Syracuse. After the Syracusans had been defeated, the Carthaginian takeover of Sicily would essentially be complete. A deadlocked senate put the matter before the popular assembly, where it was decided to accept the Mamertines' request and Appius Claudius Caudex was appointed commander of a military expedition with orders to cross to Messana.\n\nSicily is a hilly volcanic island, with geographical obstacles and rough terrain making lines of communication difficult to maintain. For this reason, land warfare played a secondary role in the First Punic War. Land operations were confined to small scale raids and skirmishes, with few pitched battles. Sieges and land blockades were the most common large-scale operations for the regular army. The main blockade targets were the important ports since neither Carthage nor Rome were based in Sicily, and both needed continuous reinforcements and communication with their mainlands.\n\nThe land war in Sicily began with the Roman landing at Messana in 264 BC. According to Polybius, despite the Carthaginian pre-war naval advantage, the Roman landing was virtually unopposed. Two legions commanded by Appius Claudius Caudex disembarked at Messana, where the Mamertines had expelled the Carthaginian garrison commanded by Hanno (no relation to Hanno the Great). After defeating the Syracusan and Carthaginian forces besieging Messana, the Romans marched south and in turn besieged Syracuse. After a brief siege, with no Carthaginian help in sight, Syracuse made peace with the Romans.\n\nAccording to the terms of the treaty, Syracuse would become a Roman ally, pay a somewhat light indemnity of 100 talents of silver to Rome and, perhaps most importantly, agree to help supply the Roman army in Sicily. That solved the Roman problem of having to keep an overseas army provisioned while facing an enemy with a superior navy. Following the defection of Syracuse from Carthage, several other smaller Carthaginian dependencies in Sicily also switched to the Roman side.\n\nMeanwhile, Carthage had begun to build a mercenary army in Africa, which was to be shipped to Sicily to meet the Romans. According to the historian Philinus, this army was composed of 50,000 infantry, 6,000 cavalry, and 60 elephants and partly composed of Ligurians, Celts and Iberians.\n\nIn past wars on the island of Sicily, Carthage had won by relying on certain fortified strong-points throughout the island, and their plan was to conduct the land war in the same fashion. The mercenary army would operate in the open against the Romans, while the strongly fortified cities would provide a defensive base from which to operate.\n\nIn 262 BC, Rome besieged Agrigentum, an operation that involved both consular armies—a total of four Roman legions—and took several months to resolve. The garrison of Agrigentum (known to the Greeks as Acragas) managed to call for reinforcements and the Carthaginian relief force commanded by Hanno which destroyed the Roman supply base at Erbessus. With supplies from Syracuse cut, the Romans were now besieged and constructed a line of contravallation. After a few skirmishes, disease struck the Roman army while supplies in Agrigentum were running low, and both sides saw an open battle as preferable to the current situation. Although the Romans won a clear victory over the Carthaginian relief force at the Battle of Agrigentum, the Carthaginian army defending the city managed to escape. Agrigentum, now lacking any real defences, fell easily to the Romans, who then sacked the city and enslaved the populace.\n\nAt the beginning of the First Punic War, Rome had virtually no experience in naval warfare, whereas the strong and powerful Carthage had a great deal of experience on the seas thanks to its centuries of sea-based trade. Nevertheless, the growing Roman Republic soon understood the importance of Mediterranean control in the outcome of the conflict.\n\nThe first major Roman fleet was constructed after the victory of Agrigentum in 261 BC. Some historians have speculated that, since Rome lacked advanced naval technology, the design of the warships was probably copied from captured Carthaginian triremes and quinqueremes or from ships that had beached on Roman shores due to storms. According to Polybius, the Romans seized a shipwrecked Carthaginian quinquereme, and used it as a blueprint for their own ships. Other historians have pointed out that Rome did have experience with naval technology, as she patrolled her coasts against piracy. Another possibility is that Rome received technical assistance from its seafaring Sicilian ally, Syracuse. Regardless of the state of their naval technology at the start of the war, Rome quickly adapted.\n\nIn order to compensate for the lack of experience, and to make use of standard land military tactics at sea, the Romans equipped their new ships with a special boarding device, the \"corvus\". The Roman military was a land-based army, while Carthage was primarily a naval power. This boarding-bridge allowed the Roman navy to circumvent some of Carthage's naval skills by using their marines to board Carthaginian ships and fight in hand-to-hand combat. Instead of manoeuvring to ram, which was the standard naval tactic at the time, \"corvus\" equipped ships would manoeuver alongside the enemy vessel, deploy the bridge which would attach to the enemy ship through spikes on the end of the bridge, and send legionaries across as boarding parties.\n\nThe new weapon would prove its worth in the Battle of Mylae, the first Roman naval victory, and would continue to do so in the following years, especially in the huge Battle of Cape Ecnomus. The addition of the \"corvus\" forced Carthage to review its military tactics, and since the city had difficulty in doing so, Rome had the naval advantage.\n\nThe Roman fleet under the command of Gaius Duilius, engaged the Carthaginians under general Hannibal Gisco, off northern Mylae in 260 BC. Polybius states that the Carthaginians had 130 ships, but does not give an exact figure for the Romans. The loss of 17 ships at the Lipari Islands from a starting total of 120 ships suggests that Rome had 103 remaining. However, it is possible that this number was greater, thanks to captured ships and the assistance of Roman allies. The Carthaginians anticipated victory, due to their superior experience at sea.\n\nThe \"corvi\" were very successful, and helped the Romans seize the first 30 Carthaginian ships that were close enough. In order to avoid the \"corvi,\" the Carthaginians were forced to navigate around them and approach the Romans from behind, or from the side. The \"corvus\" was usually still able to pivot and grapple most oncoming ships. After an additional 20 Carthaginian ships had been hooked and lost to the Romans, Hannibal Gisco retreated with his surviving ships, leaving Duilius with a clear victory.\n\nInstead of pursuing the remaining Carthaginians, Duilius sailed to Sicily to relieve the city of Segesta, which had been under siege from the Carthaginian infantry commander Hamilcar. Modern historians have wondered at Duilius’ decision not to immediately follow up with another naval attack, but Hannibal Gisco’s remaining 80 ships were probably still too strong for Rome to conquer.\n\nThe Roman advance now continued westward from Agrigentum to relieve the besieged city of Macella in 260 BC, which had sided with Rome and was attacked by the Carthaginians for doing so. In the north, the Romans, with their northern sea flank secured by their naval victory at the Battle of Mylae, advanced toward Thermae. They were defeated there by the Carthaginians under Hamilcar (a popular Carthaginian name, not to be confused with Hannibal Barca's father, with the same name) in 260 BC. The Carthaginians took advantage of this victory by counter-attacking, in 259 BC, and seizing Enna. Hamilcar continued south to Camarina, in Syracusan territory, presumably with the intent to convince the Syracusans to rejoin the Carthaginian side.\n\nThe next year, 258 BC, the Romans were able to regain the initiative by retaking Enna and Camarina. In central Sicily, they took the town of Mytistraton, which they had attacked twice previously. The Romans also moved in the north by marching across the northern coast toward Panormus, but were not able to take the city.\n\nAfter their conquests in the Agrigentum campaign, and following several naval battles, Rome attempted (256/255 BC) the second large scale land operation of the war. Seeking a swifter end to the war than the long sieges in Sicily would have provided, Rome decided to invade the Carthaginian colonies of Africa and usurp Carthage's supremacy in the Mediterranean Sea, consequently forcing Carthage to accept its terms.\n\nIn order to initiate its invasion of Africa, the Roman Republic constructed a major fleet, comprising transports for the army and its equipment, and warships for protection. Carthage attempted to intervene with a fleet of 350 ships (according to Polybius), but was defeated in the Battle of Cape Ecnomus.\n\nAs a result of the battle, the Roman army, commanded by Marcus Atilius Regulus, landed in Africa and began ravaging the Carthaginian countryside. The Siege of Aspis (or Clupea) was the first fighting on African land during the war. Regulus was next victorious at the Battle of Adys, forcing Carthage to sue for peace. According to Polybius, the terms suggested were so heavy that Carthage decided they would be better off under Roman rule. The negotiations failed but fortunately, for the Carthaginians, Xanthippus, a Spartan mercenary, returned to Carthage to reorganise its army. Xanthippus defeated the Roman army and captured Regulus at the Battle of Tunis, and then managed to cut off what remained of the Roman army from its base by re-establishing Carthaginian naval supremacy.\n\nThe Romans, meanwhile, had sent a new fleet to pick up the survivors of its African expedition. Although the Romans defeated the Carthaginian fleet and were successful in rescuing their army in Africa, a storm destroyed nearly the entire Roman fleet on the return trip; the number of casualties in the disaster may have exceeded 90,000 men. The Carthaginians took advantage of this to attack Agrigentum. They did not believe that they could hold the city, so they burned it and left.\n\nThe Romans were able to rally, however, and quickly resumed the offensive. With a new fleet of 140 ships, Rome returned to the strategy of taking the Carthaginian cities in Sicily one by one.\n\nAttacks began with naval assaults on Lilybaeum, the centre of Carthaginian power on Sicily, and a raid on Africa. Both efforts ended in failure. The Romans retreated from Lilybaeum, and the Roman African force was caught in another storm and destroyed.\n\nThe Romans, however, made great progress in the north. The city of Thermae was captured in 252 BC, enabling another advance on the port city of Panormus. The Romans attacked this city after taking Kephalodon in 251 BC. After fierce fighting, the Carthaginians were defeated and the city fell. With Panormus captured, much of western inland Sicily fell with it. The cities of Ietas, Solous, Petra, and Tyndaris agreed to peace with the Romans that same year.\n\nThe next year, the Romans shifted their attention to the north-west. They sent a naval expedition toward Lilybaeum. En route, the Romans seized and burned the Carthaginian hold-out cities of Selinous and Heraclea Minoa. This expedition to Lilybaeum was not successful, but attacking the Carthaginian headquarters demonstrated Roman resolve to take all of Sicily. The Roman fleet was defeated by the Carthaginians at Drepana, forcing the Romans to continue their attacks from land. Roman forces at Lilybaeum were relieved, and Eryx, near Drepana, was seized thus menacing that important city as well.\n\nFollowing the conclusive naval victory off Drepana in 249 BC, Carthage ruled the seas as Rome was unwilling to finance the construction of yet another expensive fleet. Nevertheless, the Carthaginian faction that opposed the conflict, led by the land-owning aristocrat Hanno the Great, gained power and in 244 BC, considering the war to be over, started the demobilisation of the fleet, giving the Romans a chance to again attain naval superiority.\n\nAt this point (247 BC), Carthage sent general Hamilcar Barca (Hannibal's father) to Sicily. His landing at Heirkte (near Panormus) drew the Romans away to defend that port city and resupply point and gave Drepana some breathing room. Subsequent guerrilla warfare kept the Roman legions pinned down and preserved Carthage's toehold in Sicily, although Roman forces which bypassed Hamilcar forced him to relocate to Eryx, to better defend Drepana.\n\nPerhaps in response to Hamilcar's raids, Rome built another fleet (paid for with donations from wealthy citizens). It was this fleet that rendered the Carthaginian success in Sicily futile, as the stalemate Hamilcar produced in Sicily became irrelevant following the Roman naval victory at the Battle of the Aegates Islands in 241 BC, where the new Roman fleet under consul Gaius Lutatius Catulus was victorious over an undermanned and hastily built Carthaginian fleet. Carthage lost most of its fleet and was economically incapable of funding another, or of finding manpower for the crews.\n\nWithout naval support, Hamilcar Barca was cut off from Carthage and forced to negotiate peace and agree to evacuate Sicily. It should be noted that Hamilcar Barca had a subordinate named Gesco conduct the negotiations with Lutatius, in order to create the impression that he had not really been defeated.\n\nDue to the difficulty of operating in Sicily, most of the First Punic War was fought at sea, including the most decisive battles. But one reason the war bogged down into stalemate on the landward side was because ancient navies were ineffective at maintaining seaward blockades of enemy ports. Consequently, Carthage was able to reinforce and re-supply its besieged strongholds, especially Lilybaeum, on the western end of Sicily. Both sides of the conflict had publicly funded fleets. This fact compromised Carthage and Rome's finances and eventually decided the course of the war.\n\nDespite the Roman victories at sea, the Roman Republic lost countless ships and crews during the war, due to both storms and battles. On at least two occasions (255 and 253 BC) whole fleets were destroyed in bad weather; the disaster off Camarina in 255 BC counted two hundred seventy ships and over one hundred thousand men lost, the greatest single loss in history. One theory is that the weight of the \"corvus\" on the prows of the ships made the ships unstable and caused them to sink in bad weather. Later, as Roman experience in naval warfare grew, the \"corvus\" device was made attachable and detachable due to its impact on the navigability of the war vessels.\n\nRome won the First Punic War after 23 years of conflict and in the end became the dominant naval power of the Mediterranean. In the aftermath of the war, both states were financially and demographically exhausted. Corsica, Sardinia and Africa remained Carthaginian, but they had to pay a high war indemnity. Rome's victory was greatly influenced by its persistence. Moreover, the Roman Republic's ability to attract private investments in the war effort to fund ships and crews was one of the deciding factors of the war, particularly when contrasted with the Carthaginian nobility's apparent unwillingness to risk their fortunes for the common war effort.\n\nThe exact number of casualties on each side is difficult to determine, due to bias in the historical sources.\n\nAccording to sources (excluding land warfare casualties):\n\nAlthough uncertain, the casualties were heavy for both sides. Polybius commented that the war was, at the time, the most destructive in terms of casualties in the history of warfare, including the battles of Alexander the Great. Analysing the data from the Roman census of the 3rd century BC, Adrian Goldsworthy noted that during the conflict Rome lost about 50,000 men. This excludes auxiliary troops and every other man in the army without citizen status, who would be outside the head count.\n\nThe terms of the Treaty of Lutatius designed by the Romans were particularly heavy for Carthage, which had lost bargaining power following its defeat at the Aegates islands. Accordingly, Carthage agreed to:\n\n\nFurther clauses determined that the allies of each side would not be attacked by the other, no attacks were to be made by either side upon the other's allies and both sides were prohibited from recruiting soldiers within the territory of the other. This denied the Carthaginians access to any mercenary manpower from Italy and most of Sicily, although this later clause was temporarily abolished during the Mercenary War.\n\nIn the aftermath of the war, Carthage had insufficient state funds. Hanno the Great tried to induce the disbanded armies to accept diminished payment, but kindled a movement that led to an internal conflict, the Mercenary War. After a hard struggle from the combined efforts of Hamilcar Barca, Hanno the Great and others, the Punic forces were finally able to annihilate the mercenaries and the insurgents. However, during this conflict, Rome took advantage of the opportunity to strip Carthage of Corsica and Sardinia as well.\n\nPerhaps the most immediate political result of the First Punic War was the downfall of Carthage's naval power. Conditions signed in the peace treaty were intended to compromise Carthage's economic situation and prevent the city's recovery. The indemnity demanded by the Romans strained the city's finances and forced Carthage to look to other areas of influence for the money to pay Rome.\n\nCarthage, seeking to make up for the recent territorial losses and a plentiful source of silver to pay the large indemnity owed to Rome, turned its attention to Iberia; and in 237 BC, the Carthaginians, led by Hamilcar Barca, began a series of campaigns to expand their control over the peninsula. Though Hamilcar was killed in 229 BC, the offensive continued with the Carthaginians extending their power towards the Ebro valley and founding \"New Carthage\" in 228 BC. When Carthage besieged the Roman protected town of Saguntum in 218 BC, it ignited the Second Punic War with Rome.\n\nAs for Rome, the end of the First Punic War marked the start of Rome's expansion beyond the Italian Peninsula. Sicily became the first Roman province (Sicilia) governed by a former praetor, instead of an ally. Sicily would become very important to Rome as a source of grain. Importantly, Syracuse was granted nominal independent ally status for the lifetime of Hiero II, and was not incorporated into the Roman province of Sicily until after it was sacked by Marcus Claudius Marcellus during the Second Punic War.\n\n\n\n\n\n"}
{"id": "11429", "url": "https://en.wikipedia.org/wiki?curid=11429", "title": "False document", "text": "False document\n\nA false document is often promoted in conjunction with a criminal enterprise, such as fraud or a confidence game. \n\nHowever, a \"false document\" is also a technique employed to create verisimilitude in a work of fiction. By inventing and inserting documents that appear to be factual, an author tries to create a sense of authenticity beyond the normal and expected suspension of disbelief for a work of art. The goal of a false document is to convince an audience that what is being presented is factual.\n\nForged documents in business are typically for financial gain.\n\nA material's certification, essentially a report of its composition and properties, may be forged. A low-property material, produced for lower cost, may be passed as a higher-property material, which has a higher price. The difference becomes illicit profit. Counterfeit fasteners have low-strength alloys or inferior production processes, but are sold as high-strength fasteners.\n\nSimilarly, parts, systems, and processes for high-valued operations may have their quality-assurance documents forged. Substandard items may be cheaper or simply more readily available. Nuclear power plants in Japan and Korea have found components with forged safety documents.\n\"See also\": Information Assurance\n\nA forged document, the Zinoviev Letter, brought about the downfall of the first Labour Government in Britain. Conspiracies within secret intelligence services have occurred more recently, leading Harold Wilson to put in place rules to prevent in the 1960s phone tapping of members of Parliament, for example.\n\n\"The Protocols of the Elders of Zion\", purporting to describe a Jewish plan for global domination, was first published in Russia in 1903, translated into multiple languages, and disseminated internationally in the early part of the 20th century.\n\nArtist JSG Boggs's life and work have been extensively explored by author and journalist Lawrence Weschler. Boggs draws currency with exceptional care and accuracy, but he only ever draws one side. He then attempts to buy things with the piece of paper upon which he has drawn the currency. His goal is to pass each bill for its face value in common transactions. He buys lunch, clothes, and lodging in this manner, and after the transactions are complete, his bills fetch many times their face value on the art market. Boggs does not make any money from the much larger art market value of his work, only from reselling the goods bought, the change and receipts and other such materials. He has been arrested in many countries, and there is much controversy surrounding his work.\n\nOrson Welles' \"F for Fake\" is a prime example of a film which is both about falsification (art forgery and the journalism surrounding art forgery) as well as having falsified moments within the film. The movie follows the exploits of a famous art forger, his biographer Clifford Irving, and the subsequent fake autobiography of Howard Hughes that Irving tries to publish. The issues of veracity and forgery are explored in the film, while at the same time, Welles tricks the audience by incorporating fake bits of narrative alongside the documentary footage.\n\nThere is a long history of producers creating tie-in material to promote and merchandise movies and television shows. Tie-in materials as far-ranging as toys, games, lunch boxes, clothing and so on have all been created and in some cases generate as much or more revenue as the original programming. One big merchandising arena is publishing. In most cases such material is not considered canon within the show's mythology; however, in some instances the books, magazines, etc. are specifically designed by the creators to be canonical. With the rise of the Internet, in-canon online material has become more prominent.\n\nThe following is a list of \"false document\" in-canon supplemental material:\nAdditionally, a set of trading cards was produced which are also canon.\n\nA number of hoaxes have involved false documents:\n\nFalse documents were recently the topic of a graduate-level seminar in the humanities at the University of Michigan. The seminar was taught by Professor Eileen Pollack. While the form has existed for at least two hundred years, the focused study of it is fairly recent.\n\n\n"}
{"id": "11431", "url": "https://en.wikipedia.org/wiki?curid=11431", "title": "Fernando Pessoa", "text": "Fernando Pessoa\n\nFernando António Nogueira Pessoa (; June 13, 1888 – November 30, 1935), commonly known as Fernando Pessoa, was a Portuguese poet, writer, literary critic, translator, publisher and philosopher, described as one of the most significant literary figures of the 20th century and one of the greatest poets in the Portuguese language. He also wrote in and translated from English and French.\n\nPessoa was a prolific writer, and not only under his own name, for he dreamed up approximately seventy-five others. He did not call them \"pseudonyms\" because he felt that did not capture their true independent intellectual life and instead called them \"heteronyms\". These imaginary figures sometimes held unpopular or extreme views.\n\nPessoa was born in Lisbon. On July 13, 1893, when Pessoa was five, his father, Joaquim de Seabra Pessoa, died of tuberculosis and the following year, on January 2, his younger brother Jorge, aged one, also died.\n\nAfter the second marriage of his mother, Maria Magdalena Pinheiro Nogueira, to João Miguel dos Santos Rosa, on December 31, 1895, little Fernando sailed with his mother for South Africa in the beginning of 1896, to join his stepfather, a military officer appointed Portuguese consul in Durban, capital of the former British Colony of Natal.\nHe declared:\nThe young Pessoa received his early education at St. Joseph Convent School, a Catholic grammar school run by Irish and French nuns. He moved to the Durban High School in April, 1899, becoming fluent in English and developing an appreciation for English literature. During the Matriculation Examination, held at the time by the University of the Cape of Good Hope (forerunner of the University of Cape Town), in November 1903, he was awarded the recently created Queen Victoria Memorial Prize for best paper in English. While preparing to enter university, he also attended the Durban Commercial High School during one year, in the evening shift.\n\nMeanwhile, Pessoa started writing short stories in English, some under the name of David Merrick, many of which he left unfinished. At the age of sixteen, \"The Natal Mercury\" (July 6, 1904 edition) published his poem \"Hillier did first usurp the realms of rhyme...\", under the name of C. R. Anon (anonymous), along with a brief introductory text: \"I read with great amusement...\". In December, \"The Durban High School Magazine\" published his essay \"Macaulay\". From February to June, 1905, in the section \"The Man in the Moon\", \"The Natal Mercury\" also published at least four sonnets by Fernando Pessoa: \"Joseph Chamberlain\", \"To England I\", \"To England II\" and \"Liberty\". His poems often carried humorous versions of Anon as the author's name. Pessoa started using pen names quite young. The first one, still in his childhood, was Chevalier de Pas, supposedly a French noble. In addition to Charles Robert Anon and David Merrick, the young writer also signed up, among other pen names, as Horace James Faber, Alexander Search, and other meaningful names.\n\nIn the preface to \"The Book of Disquiet\", Pessoa wrote about himself:\n\nThe young Pessoa was described by a schoolfellow as follows:\nTen years after his arrival, he sailed for Lisbon via the Suez Canal on board the \"Herzog\", leaving Durban for good at the age of seventeen. This journey inspired the poems \"Opiário\" (dedicated to his friend, the poet and writer Mário de Sá-Carneiro) published in March, 1915, in \"Orpheu\" nr.1 and \"Ode Marítima\" (dedicated to the futurist painter Santa-Rita Pintor) published in June, 1915, in \"Orpheu\" nr.2 by his heteronym Álvaro de Campos.\n\nWhile his family remained in South Africa, Pessoa returned to Lisbon in 1905 to study diplomacy. After a period of illness, and two years of poor results, a student strike against the dictatorship of Prime Minister João Franco put an end to his formal studies. Pessoa became an autodidact, a devoted reader who spent a lot of time at the library. In August, 1907, he started working as a practitioner at R.G. Dun & Company, an American mercantile information agency (currently D&B, Dun & Bradstreet). His grandmother died in September and left him a small inheritance, which he spent on setting up his own publishing house, the \"Empreza Ibis\". The venture was not successful and closed down in 1910, but the name ibis, the sacred bird of Ancient Egypt and inventor of the alphabet in Greek mythology, would remain an important symbolic reference for him.\n\nPessoa returned to his uncompleted formal studies, complementing his British education with self-directed study of Portuguese culture. The pre-revolutionary atmosphere surrounding the assassination of King Charles I and Crown Prince Luís Filipe in 1908, and the patriotic outburst resulting from the successful republican revolution in 1910, influenced the development of the budding writer; as did his step-uncle, Henrique dos Santos Rosa, a poet and retired soldier, who introduced the young Pessoa to Portuguese poetry, notably the romantics and symbolists of the 19th century. In 1912, Fernando Pessoa entered the literary world with a critical essay, published in the cultural journal \"A Águia\", which triggered one of the most important literary debates in the Portuguese intellectual world of the 20th century: the polemic regarding a super-Camões. In 1915 a group of artists and poets, including Fernando Pessoa, Mário de Sá-Carneiro and Almada Negreiros, created the literary magazine \"Orpheu\", which introduced modernist literature to Portugal. Only two issues were published (Jan–Feb–Mar and Apr–May–Jun, 1915), the third failed to appear due to funding difficulties. Lost for many years, this issue was finally recovered and published in 1984. Among other writers and poets, \"Orpheu\" published Pessoa, orthonym, and the modernist heteronym, Álvaro de Campos.\n\nAssociated with the artist Ruy Vaz, Pessoa also founded the \"Art Journal\" \"Athena\" (1924–25), in which he published verses of the heteronyms Alberto Caeiro and Ricardo Reis. Along with his profession, as free-lance commercial translator, Fernando Pessoa undertook intense activity as a writer, literary critic and political analyst, contributing to the journals and newspapers \"A Águia\" (1912–13), \"Teatro\" (1913), \"A Renascença\" (1914), \"O Jornal\" (1915), \"Orpheu\" (1915), \"Exílio\" (1916), \"Centauro\" (1916), \"Terra Nossa\" (1916), \"Portugal Futurista\" (1917), \"Acção\" (1919–20), \"Ressurreição\" (1920), \"Contemporânea\" (1922–26), \"Athena\" (1924–25), \"Diário de Lisboa\" (1924–35), \"Revista de Comércio e Contabilidade\" (1926), \"Sol\" (1926), \"O Imparcial\" (1927), \"Presença\" (1927–34), \"Notícias Ilustrado\" (1928–30), \"Girassol\" (1930), \"Revolução\" (1932), \"Descobrimento\" (1932), \"Fama\" (1932–33), \"Fradique\" (1934) and \"Sudoeste\" (1935).\n\nAfter his return to Portugal, when he was seventeen, Pessoa barely left his beloved city of Lisbon, which inspired the poems \"Lisbon Revisited\" (1923 and 1926), under the heteronym Álvaro de Campos. From 1905 to 1920, when his family returned from Pretoria after the death of his stepfather, he lived in fifteen different locations in the city, moving from one rented room to another depending on his fluctuating finances and personal troubles.\n\nPessoa adopted the detached perspective of the flâneur, Bernardo Soares, another of his heteronyms. This character was supposedly an accountant, working for \"Vasques\", the boss of an office located in Douradores Street. Bernardo Soares also supposedly lived in the same downtown street, a world that Pessoa knew quite well due to his long career as freelance correspondence translator. In fact, from 1907 until his death in 1935, Pessoa worked in twenty-one firms located in Lisbon's downtown, sometimes in two or three of them simultaneously. In \"The Book of Disquiet\", \"Bernardo Soares\" describes some of those typical places and their \"atmosphere\".\n\nA statue of Fernando Pessoa sitting at a table (below) can be seen outside A Brasileira, one of the preferred places of young writers and artists of \"Orpheu\"'s group during the 1910s. This coffeehouse, in the aristocratic district of Chiado, is quite close to Pessoa's birthplace: 4, São Carlos Square (in front of the Opera House, where stands another statue of the writer), one of the most elegant neighborhoods of Lisbon. Later on, Pessoa was a frequent customer at Martinho da Arcada, a centennial coffeehouse in Comercio Square, surrounded by ministries, almost an \"office\" for his private business and literary concerns, where he used to meet friends in the 1920s and 1930s.\n\nIn 1925, Pessoa wrote in English a guidebook to Lisbon but it remained unpublished until 1992.\n\nPessoa translated a number of Portuguese books into English. He also translated into Portuguese \"The Scarlet Letter\" by Nathaniel Hawthorne, the short stories \"The Theory and the Hound\", \"The Roads We Take\" and \"Georgia's Ruling\" by O. Henry, and the poems \"The Raven\", \"Annabel Lee\" and \"Ulalume\" by Edgar Allan Poe who, along with Walt Whitman, strongly influenced him. In addition, Pessoa translated into Portuguese a number of books by leading theosophists such as C. W. Leadbeater and Annie Besant.\n\nIn 1912–14, while living with his aunt \"Anica\" and cousins, Pessoa took part in \"semi-spiritualist sessions\" that were carried out at home, but he was considered a \"delaying element\" by the other members of the session. Pessoa's interest in spiritualism was truly awakened in the second half of 1915, while translating theosophist books. This was further deepened in the end of March 1916, when he suddenly started having experiences where he became a medium, which were revealed through automatic writing. On June 24, Pessoa wrote an impressive letter to his aunt and godmother, then living in Switzerland with her daughter and son in law, in which he describes this \"mystery case\" that surprised him.\n\nBesides automatic writing, Pessoa stated also that he had \"astral\" or \"etherial visions\" and was able to see \"magnetic auras\" similar to radiographic images. He felt \"more curiosity than fear\", but was respectful towards this phenomenon and asked secrecy, because \"there is no advantage, but many disadvantages\" in speaking about this. Mediumship exerted a strong influence in Pessoa writings, who felt \"sometimes suddenly being owned by something else\" or having a \"very curious sensation\" in the right arm, which was \"lifted into the air\" without his will. Looking in the mirror, Pessoa saw several times what appeared to be the heteronyms: his \"face fading out\" and being replaced by the one of \"a bearded man\", or another one, four men in total.\n\nPessoa also developed a strong interest in astrology, becoming a competent astrologist. He elaborated more than 1,500 astrological charts, including well-known people like William Shakespeare, Lord Byron, Oscar Wilde, Chopin, Robespierre, Napoleon I, Benito Mussolini, Wilhelm II, Leopold II of Belgium, Victor Emmanuel III, Alfonso XIII, or the Kings Sebastian and Charles of Portugal, and Salazar. In 1915, Pessoa created the heteronym \"Raphael Baldaya\", an astrologist, and planned to write under his name \"System of Astrology\" and \"Introduction to the Study of Occultism\". Pessoa established the pricing of his astrological services from 500 to 5,000 réis and made horoscopes of customers, friends and also himself and, astonishingly, of the heteronyms and also of journals as \"Orpheu\".\n\nBorn on June 13, Pessoa was native of Gemini and had Scorpio as rising sign. The characters of the main heteronyms were inspired by the four astral elements: air, fire, water and earth. It means that Pessoa and his heteronyms altogether comprised the full principles of ancient knowledge. Those heteronyms were designed according to their horoscopes, all include Mercury, the planet of literature. Astrology was part of his everyday life and Pessoa kept that interest until his death, which he was able to predict with a certain degree of accuracy.\n\nAs a mysticist, Pessoa was an enthusiast of esotericism, occultism, hermetism, numerology and alchemy. Along with spiritualism and astrology, he also paid attention to neopaganism, theosophy, rosicrucianism and freemasonry, which strongly influenced his literary work. His interest in occultism led Pessoa to correspond with Aleister Crowley and later helped him to elaborate a fake suicide, when Crowley visited Portugal in 1930. Pessoa translated Crowley's poem \"Hymn To Pan\" into Portuguese, and the catalogue of Pessoa's library shows that he possessed Crowley's books \"Magick in Theory and Practice\" and \"Confessions\". Pessoa also wrote on Crowley's doctrine of Thelema in several fragments, including \"Moral\".\n\nPessoa's declared about secret societies:\n\nLiterary critic Martin Lüdke described Pessoa's philosophy as a kind of pandeism, especially as to those writings made under the pseudonym of Alberto Caeiro.\n\nIn his early years, Pessoa was influenced by major English classic poets as Shakespeare, Milton and Pope, or romantics like Shelley, Byron, Keats, Wordsworth, Coleridge and Tennyson. After his return to Lisbon in 1905, Pessoa was influenced by French symbolists and decadentists Charles Baudelaire, Maurice Rollinat, Stéphane Mallarmé; mainly by Portuguese poets as Antero de Quental, Gomes Leal, Cesário Verde, António Nobre, Camilo Pessanha or Teixeira de Pascoaes. Later on, he was also influenced by modernists as W. B. Yeats, James Joyce, Ezra Pound and T. S. Eliot, among many other writers.\n\nDuring World War I, Pessoa wrote to a number of British publishers, namely Constable & Co. Ltd. (currently Constable & Robinson), in order to print his collection of English verse \"The Mad Fiddler\" (unpublished during his lifetime), but it was refused. However, in 1920, the prestigious literary journal \"Athenaeum\" included one of those poems. Since the British publication failed, in 1918 Pessoa published in Lisbon two slim volumes of English verse: \"Antinous\" and \"35 Sonnets\", received by the British literary press without enthusiasm. Along with some friends, he founded another publishing house, Olisipo, which published in 1921 a further two English poetry volumes: \"English Poems I–II\" and \"English Poems III\" by Fernando Pessoa. In his publishing house, Olisipo, Pessoa issued also some books by his friends: \"A Invenção do Dia Claro\" (The invention of the clear day) by José de Almada Negreiros, \"Canções\" (Songs) by António Botto, and \"Sodoma Divinizada\" (Divinized Sodome) by Raul Leal (Henoch). Olisipo closed down in 1923, following the scandal known as \"Literatura de Sodoma\" (Literature of Sodome), which Pessoa started with his paper \"António Botto e o Ideal Estético em Portugal\" (António Botto and the aesthetical ideal in Portugal), published in the journal \"Contemporanea\".\n\nPolitically, Pessoa considered himself a \"mystical nationalist\" and, despite his monarchist sympathies, he didn't favour the restoration of the monarchy. Pessoa described himself as conservative within the British tradition. He was an outspoken elitist and aligned himself against communism, socialism, fascism and Catholicism. He supported the military coups of 1917 and 1926, and wrote a pamphlet in 1928 supportive of the Military Dictatorship but after the establishment of the New State, in 1933, Pessoa become disenchanted with the regime and wrote critically of Salazar and fascism in general. In the beginning of 1935, Pessoa was banned by the Salazar regime, after he wrote in defense of Freemasonry.\n\nPessoa died on November 30, 1935, aged 47, having published four books in English and one alone in Portuguese: \"Mensagem\" (Message). However, he left a lifetime of unpublished, unfinished or just sketchy work in a domed, wooden trunk (25,574 pages manuscript and typed that have been housed in the Portuguese National Library since 1988). The heavy burden of editing this huge work is still in progress. In 1985 (fifty years after his death), Pessoa's remains were moved to the Hieronymites Monastery, in Lisbon, where Vasco da Gama, Luís de Camões, and Alexandre Herculano are also buried. Pessoa's portrait was on the 100-escudo banknote.\n\nPessoa's earliest heteronym, at the age of six, was Chevalier de Pas. Other childhood heteronyms included Dr. Pancrácio and David Merrick, followed by Charles Robert Anon, an English young man that became Pessoa's \"alter ego\". In 1905/7, when Pessoa was a student at the University of Lisbon, Alexander Search took the place of Anon. The main reason for this was that, although Search is English, he was born in Lisbon as his author. But Search represents a transition heteronym that Pessoa used while searching to adapt to the Portuguese cultural reality. After the republican revolution, in 1910, and consequent patriotic atmosphera, Pessoa created another \"alter ego\", Álvaro de Campos, supposedly a Portuguese naval engineer, born in Tavira and graduated in Glasgow. Translator Richard Zenith notes that Pessoa eventually established at least seventy-two heteronyms. According to Pessoa himself, there were three main heteronyms: Alberto Caeiro, Álvaro de Campos and Ricardo Reis. The heteronyms possess distinct biographies, temperaments, philosophies, appearances, writing styles and even signatures.\n\nPessoa wrote on the heteronyms:\n\nAlberto Caeiro was Pessoa's first great heteronym; it summarized by Pessoa as follows: \"He sees things with the eyes only, not with the mind. He does not let any thoughts arise when he looks at a flower... the only thing a stone tells him is that it has nothing at all to tell him... this way of looking at a stone may be described as the totally unpoetic way of looking at it. The stupendous fact about Caeiro is that out of this sentiment, or rather, absence of sentiment, he makes poetry.\"\n\nWhat this means, and what makes Caeiro such an original poet is the way he apprehends existence. He does not question anything whatsoever; he calmly accepts the world as it is. The recurrent themes to be found in nearly all of Caeiro's poems are wide-eyed childlike wonder at the infinite variety of nature, as noted by a critic. He is free of metaphysical entanglements. Central to his world-view is the idea that in the world around us, all is surface: things are precisely what they seem, there is no hidden meaning anywhere.\n\nHe manages thus to free himself from the anxieties that batter his peers; for Caeiro, things simply exist and we have no right to credit them with more than that. Caeiro attains happiness by not questioning, and by thus avoiding doubts and uncertainties. He apprehends reality solely through his eyes, through his senses. Octavio Paz called him the innocent poet. Paz made a shrewd remark on the heteronyms: In each are particles of negation or unreality. Reis believes in form, Campos in sensation, Pessoa in symbols. Caeiro doesn't believe in anything. He exists.\n\nPoetry before Caeiro was essentially interpretative; what poets did was to offer an interpretation of their perceived surroundings; Caeiro does not do this. Instead, he attempts to communicate his senses, and his feelings, without any interpretation whatsoever.\n\nCaeiro attempts to approach Nature from a qualitatively different mode of apprehension; that of simply perceiving (an approach akin to phenomenological approaches to philosophy). Poets before him would make use of intricate metaphors to describe what was before them; not so Caeiro: his self-appointed task is to bring these objects to the reader's attention, as directly and simply as possible. Caeiro sought a direct experience of the objects before him.\n\nAs such it is not surprising to find that Caeiro has been called an anti-intellectual, anti-Romantic, anti-subjectivist, anti-metaphysical...an anti-poet, by critics; Caeiro simply—is. He is in this sense very unlike his creator Fernando Pessoa: Pessoa was besieged by metaphysical uncertainties; these were, to a large extent, the cause of his unhappiness; not so Caeiro: his attitude is anti-metaphysical; he avoided uncertainties by adamantly clinging to a certainty: his belief that there is no meaning behind things. Things, for him, simply—are.\n\nCaeiro represents a primal vision of reality, of things. He is the pagan incarnate. Indeed, Caeiro was not simply a pagan but paganism itself.\n\nThe critic Jane M. Sheets sees the insurgence of Caeiro—who was Pessoa's first major heteronym—as essential in founding the later poetic \"personas\": By means of this artless yet affirmative anti-poet, Caeiro, a short-lived but vital member of his coterie, Pessoa acquired the base of an experienced and universal poetic vision. After Caeiro's tenets had been established, the avowedly poetic voices of Campos, Reis and Pessoa himself spoke with greater assurance.\n\nIn a letter to William Bentley, Pessoa wrote that \"a \"knowledge\" of the language would be indispensable, for instance, to appraise the 'Odes' of Ricardo Reis, whose Portuguese would draw upon him the blessing of António Vieira, as his stile and diction that of Horace (he has been called, admirably I believe, 'a Greek Horace who writes in Portuguese')\".\n\nReis, both a character and a heteronym of Fernando Pessoa himself, sums up his philosophy of life in his own words, admonishing: 'See life from a distance. Never question it. There's nothing it can tell you.' Like Caeiro, whom he admires, Reis defers from questioning life. He is a modern pagan who urges one to seize the day and accept fate with tranquility. 'Wise is the one who does not seek', he says; and continues: 'the seeker will find in all things the abyss, and doubt in himself.' In this sense Reis shares essential affinities with Caeiro.\n\nBelieving in the Greek gods, yet living in a Christian Europe, Reis feels that his spiritual life is limited, and true happiness cannot be attained. This, added to his belief in Fate as a driving force for all that exists, as such disregarding freedom, leads to his epicureanist philosophy, which entails the avoidance of pain, defending that man should seek tranquility and calm above all else, avoiding emotional extremes.\n\nWhere Caeiro wrote freely and spontaneously, with joviality, of his basic, meaningless connection to the world, Reis writes in an austere, cerebral manner, with premeditated rhythm and structure and a particular attention to the correct use of the language, when approaching his subjects of, as characterized by Richard Zenith, 'the brevity of life, the vanity of wealth and struggle, the joy of simple pleasures, patience in time of trouble, and avoidance of extremes'.\n\nIn his detached, intellectual approach, he is closer to Fernando Pessoa's constant rationalization, as such representing the orthonym's wish for measure and sobriety and a world free of troubles and respite, in stark contrast to Caeiro's spirit and style. As such, where Caeiro's predominant attitude is that of joviality, his sadness being accepted as natural ('My sadness,' Caeiro says, 'is a comfort for it is natural and right.'), Reis is marked by melancholy, saddened by the impermanence of all things.\n\nRicardo Reis is the main character of José Saramago's 1986 novel \"The Year of the Death of Ricardo Reis\".\n\nÁlvaro de Campos manifests, in a way, as an hyperbolic version of Pessoa himself. Of the three heteronyms he is the one who feels most strongly, his motto being 'to feel everything in every way.' 'The best way to travel,' he wrote, 'is to feel.' As such, his poetry is the most emotionally intense and varied, constantly juggling two fundamental impulses: on the one hand a feverish desire to be and feel everything and everyone, declaring that 'in every corner of my soul stands an altar to a different god' (alluding to Walt Whitman's desire to 'contain multitudes'), on the other, a wish for a state of isolation and a sense of nothingness.\n\nAs a result, his mood and principles varied between violent, dynamic exultation, as he fervently wishes to experience the entirety of the universe in himself, in all manners possible (a particularly distinctive trait in this state being his futuristic leanings, including the expression of great enthusiasm as to the meaning of city life and its components) and a state of nostalgic melancholy, where life is viewed as, essentially, empty.\n\nOne of the poet's constant preoccupations, as part of his dichotomous character, is that of identity: he does not know who he is, or rather, fails at achieving an ideal identity. Wanting to be everything, and inevitably failing, he despairs. Unlike Caeiro, who asks nothing of life, he asks too much. In his poetic meditation 'Tobacco Shop' he asks:\n\n\"Fernando Pessoa-himself\" is not the \"real\" Fernando Pessoa. Like Caeiro, Reis and Campos, Pessoa-\"himself\" embodies only aspects of the poet. Fernando Pessoa's personality is not stamped in any given voice; his personality is diffused through the heteronyms. For this reason \"Fernando Pessoa-himself\" stands apart from the poet proper.\n\n\"Pessoa\" shares many essential affinities with his peers, Caeiro and Campos in particular. Lines crop up in his poems that may as well be ascribed to Campos or Caeiro.\n\nLike Álvaro de Campos, Pessoa-himself was afflicted with an acute identity crisis. Pessoa-himself has been described as indecisive and doubt plagued, as restless. Like Campos he can be melancholic, weary, resigned.\n\nA constant theme in Pessoa's poetry is Tédio, or Tedium. The dictionary defines this word simply as 'a condition of being tedious; tediousness or boredom.' This definition does not sufficiently encompass the peculiar brand of tedium experienced by Pessoa-himself. His is more than simple boredom: it is from a world of weariness and disgust with life; a sense of the finality of failure; of the impossibility of having anything to want.\n\n\"Mensagem\", written in Portuguese, is a symbolist epic made up of 44 short poems organized in three parts or Cycles:\n\nThe first, called \"Brasão\" (Coat-of-Arms), relates Portuguese historical protagonists to each of the fields and charges in the Portuguese coat of arms. The first two poems (\"The castles\" and \"The escutcheons\") draw inspiration from the material and spiritual natures of Portugal. Each of the remaining poems associates to each charge a historical personality. Ultimately they all lead to the Golden Age of Discovery.\n\nThe second Part, called \"Mar Português\" (Portuguese Sea), references the country's Age of Portuguese Exploration and to its seaborne Empire that ended with the death of King Sebastian at El-Ksar el Kebir (\"Alcácer-Quibir\" in Portuguese) in 1578. Pessoa brings the reader to the present as if he had woken up from a dream of the past, to fall in a dream of the future: he sees King Sebastian returning and still bent on accomplishing a Universal Empire.\n\nThe third Cycle, called \"O Encoberto\" (\"The Hidden One\"), refers to Pessoa's vision of a future world of peace and the Fifth Empire (which, according to Pessoa, is spiritual and not material, because if it were material England would already have achieved it). After the Age of Force, (Vis), and Taedium (Otium) will come Science (understanding) through a reawakening of \"The Hidden One\", or \"King Sebastian\". The Hidden One represents the fulfillment of the destiny of mankind, designed by God since before Time, and the accomplishment of Portugal.\n\nKing Sebastian is very important, indeed he appears in all three parts of Mensagem. He represents the capacity of dreaming, and believing that it's possible to achieve dreams.\n\nOne of the most famous quotes from \"Mensagem\" is the first line from \"O Infante\" (belonging to the second Part), which is \"Deus quer, o homem sonha, a obra nasce\" (which translates roughly to \"God wishes, man dreams, the work is born\"). That means 'Only by God's will man does', a full comprehension of man's subjection to God's wealth. Another well-known quote from \"Mensagem\" is the first line from \"Ulysses\", \"O mito é o nada que é tudo\" (a possible translation is \"The myth is the nothing that is all\"). This poem refers to Ulysses, king of Ithaca, as Lisbon's founder (recalling an ancient Greek myth).\n\nIn 1912, Fernando Pessoa wrote a set of essays (later collected as \"The New Portuguese Poetry\") for the cultural journal \"A Águia\" (The Eagle), founded in Oporto, in December 1910, and run by the republican association Renascença Portuguesa. In the first years of the Portuguese Republic, this cultural association was started by republican intellectuals led by the writer and poet Teixeira de Pascoaes, philosopher Leonardo Coimbra and historian Jaime Cortesão, aiming for the renewal of Portuguese culture through the aesthetic movement called Saudosismo. Pessoa contributed to the journal \"A Águia\" with a series of papers: 'The new Portuguese Poetry Sociologically Considered' (nr. 4), 'Relapsing...' (nr. 5) and 'The Psychological Aspect of the new Portuguese Poetry' (nrs. 9,11 and 12). These writings were strongly encomiastic to saudosist literature, namely the poetry of Teixeira de Pascoaes and Mário Beirão. The articles disclose Pessoa as a connoisseur of modern European literature and an expert of recent literary trends. On the other hand, he does not care much for a methodology of analysis or problems in the history of ideas. He states his confidence that Portugal would soon produce a great poet – a super-Camões – pledged to make an important contribution for European culture, and indeed, for humanity.\n\nThe philosophical notes of young Fernando Pessoa, mostly written between 1905 and 1912, illustrate his debt to the history of Philosophy more through commentators than through a first-hand protracted reading of the Classics, ancient or modern. The issues he engages with pertain to every philosophical discipline and concern a large profusion of concepts, creating a vast semantic spectrum in texts whose length oscillates between half a dozen lines and half a dozen pages and whose density of analysis is extremely variable; simple paraphrasis, expression of assumptions and original speculation.\n\nPessoa sorted the philosophical systems thus:\n\nSuch pantheist transcendentalism is used by Pessoa to define the project that \"encompasses and exceeds all systems\"; to characterize the new poetry of Saudosismo where the \"typical contradiction of this system\" occurs; to inquire of the particular social and political results of its adoption as the leading cultural paradigm; and, at last, he hints that metaphysics and religiosity strive \"to find in everything a beyond\".\n\n\n\n\n\n"}
{"id": "11432", "url": "https://en.wikipedia.org/wiki?curid=11432", "title": "Full moon", "text": "Full moon\n\nA full moon is the lunar phase that occurs when the Moon is completely illuminated as seen from Earth. This occurs when Earth is located directly between the Sun and the Moon (more exactly, when the ecliptic longitudes of the Sun and Moon differ by 180 degrees). This means that the hemisphere of the Moon that is facing Earth (the near side) is almost fully illuminated by the Sun and appears round (while the far side is almost completely unlit). When the full moon moves into Earth's shadow, a lunar eclipse occurs, and all or part of the Moon's face may appear reddish due to the Rayleigh scattering of blue light in Earth's atmosphere.\n\nLunar eclipses can occur only at full moon, where the Moon's orbit allows it to pass through Earth's shadow. Lunar eclipses do not occur every month because the Moon usually passes above or below Earth's shadow, which is mostly restricted to the ecliptic plane. Lunar eclipses can occur only when the full moon occurs near the two nodes of the orbit, either the ascending or descending node. This causes eclipses to only occur about every 6 months, and often 2 weeks before or after a solar eclipse at new moon at the opposite node.\n\nThe time interval between similar lunar phases—the synodic month—averages about 29.53 days. Therefore, in those lunar calendars in which each month begins on the new moon, the full moon falls on either the 14th or 15th of the lunar month. Because calendar months have a whole number of days, lunar months may be either 29 or 30 days long.\n\nA full moon is often thought of as an event of a full night's duration. This is somewhat misleading because its phase seen from Earth continuously waxes or wanes (though much too slowly to notice in real time with the naked eye). Its maximum illumination occurs at the moment waxing has stopped. For any given location, about half of these maximum full moons may be visible, while the other half occurs during the day, when the full moon is below the horizon.\n\nMany almanacs list full moons not only by date, but also by their exact time, usually in Coordinated Universal Time (UTC). Typical monthly calendars that include lunar phases may be offset by one day when used in a different time zone.\n\nFull moon is generally a suboptimal time to conduct astronomical observations because the bright sunlight reflected by the Moon then outshines the apparently dimmer stars.\n\nOn 12 December 2008, the full moon occurred closer to the Earth than it had been at any time for the previous 15 years, called a supermoon.\n\nOn 19 March 2011, another full supermoon occurred, closer to the Earth than at any time for the previous 18 years.\n\nOn 14 November 2016, a full supermoon occurred closer to the Earth than at any time for the previous 68 years.\n\nThe date and approximate time of a specific full moon (assuming a circular orbit) can be calculated from the following equation:\nwhere \"d\" is the number of days since 1 January 2000 00:00:00 in the Terrestrial Time scale used in astronomical ephemerides; for Universal Time (UT) add the following approximate correction to \"d\":\nwhere \"N\" is the number of full moons since the first full moon of 2000. The true time of a full moon may differ from this approximation by up to about 14.5 hours as a result of the non-circularity of the moon's orbit. See New moon for an explanation of the formula and its parameters.\n\nThe age and apparent size of the full moon vary in a cycle of just under 14 synodic months, which has been referred to as a full moon cycle.\n\nFull moons are traditionally associated with temporal insomnia (inability to sleep), insanity (hence the terms \"lunacy\" and \"lunatic\") and various \"magical phenomena\" such as lycanthropy. Psychologists, however, have found that there is no strong evidence for effects on human behavior around the time of a full moon. They find that studies are generally not consistent, with some showing a positive effect and others showing a negative effect. In one instance, the 23 December 2000 issue of the \"British Medical Journal\" published two studies on dog bite admission to hospitals in England and Australia. The study of the Bradford Royal Infirmary found that dog bites were twice as common during a full moon, whereas the study conducted by the public hospitals in Australia found that they were less likely. All this is relevant to canine rather than human behavior.\n\nHistorically, month names are names of moons (lunations, not necessarily full moons) in lunisolar calendars. Since the introduction of the solar Julian calendar in the Roman Empire, and later the Gregorian calendar worldwide, month names have ceased to be perceived as \"moon names\". The traditional Old English month names were equated with the names of the Julian calendar from an early time (soon after Christianization, according to the testimony of Bede ca. AD 700).\n\nSome full moons have developed new names in modern times, e.g., the blue moon, and the names \"harvest moon\" and \"hunter's moon\" for the full moons of autumn.\n\nThe \"harvest moon\" and \"hunter's moon\" are traditional terms for the full moons occurring during late summer and in the autumn, in the northern hemisphere usually in September and October respectively.\nThe \"harvest moon\" is the full moon closest to the autumnal equinox (22 or 23 September), coming anywhere from two weeks before to two weeks after that date. The \"hunter's moon\" is the full moon following it.\nThe names are recorded from the early 18th century.\nThe Oxford English Dictionary entry for \"harvest moon\" cites a 1706 reference, and for \"hunter's moon\" a 1710 edition of \"The British Apollo\", where the term is attributed to \"the country people\" (\"The Country People call this the Hunters-Moon.\") The names became traditional in American folklore, where they are now often popularly attributed to the Native Americans.\nThe Feast of the Hunters' Moon is a yearly festival in West Lafayette, Indiana, held in late September or early October each year since 1968.\nIn 2010, the Harvest moon occurred on the night of equinox itself (some 5 hours after the point of equinox) for the first time since 1991.\n\nAll full moons rise around the time of sunset. Because the moon moves eastward among the stars faster than the sun its meridian passage is delayed, causing it to rise later each day – on average by about 50.47 minutes. The harvest moon and hunter's moon are unique because the time difference between moonrises on successive evenings is much shorter than average. The moon rises approximately 30 minutes later from one night to the next, as seen from about 40 degrees N or S latitude. (This is because a full moon in September appears to move not straight east but north-east in the sky.) Thus, there is no long period of darkness between sunset and moonrise for several days following the actual date of the full moon.\n\nThe \"Maine Farmers' Almanac\" from c. the 1930s began to publish Native American \"Indian\" full moon names. The \"Farmers' Almanac\" (since 1955 published in Maine, but not the same publication as the \"Maine Farmers' Almanac\") continues to do so.\n\nAn early list of \"Indian month names\" was published in 1918 by Daniel Carter Beard in his \"The American Boy's Book of Signs, Signals and Symbols\" for use by the boy scouts. Beard's \"Indian\" month names were:\n\nSuch names have gained currency in American folklore. They appear in print more widely outside of the almanac tradition from the 1990s in popular publications about the Moon.\n\"Mysteries of the Moon\" by Patricia Haddock (\"Great Mysteries Series\", Greenhaven Press, 1992) gave an extensive list of such names along with the individual tribal groups they were supposedly associated with. Haddock supposes that certain \"Colonial American\" moon names were adopted from Algonquian languages (which were formerly spoken in the territory of New England), while others are based in European tradition (e.g., the Colonial American names for the May moon, \"Milk Moon\", \"Mother's Moon\", \"Hare Moon\" have no parallels in the supposed native names, while the name of November, \"Beaver Moon\" is supposedly based in the Algonquin).\n\nThe individual names given in \"Farmers' Almanac\" include:\nThe Long Night's Moon is the last of the year and the closest to the winter solstice.\n\nIn June 2016 the so-called \"Strawberry Moon\" coincided with the Summer solstice for the first time since 1967, and will not return for another 46 years.\n\n\"Ice moon\" is also used to refer to the first full moon of February or January.\n\nIn Hinduism, most festivals are celebrated on auspicious days. Many of the Hindu festivals are celebrated on days with a full moon at night.\nDifferent parts of India celebrate the same day with different names, as listed below:\n\nMost pre-modern calendars the world over were lunisolar, combining the solar year with the lunation by means of intercalary months.\nThe Julian calendar abandoned this method in favour of a purely solar reckoning while conversely the 7th-century Islamic calendar opted for a purely lunar one.\n\nA continuing lunisolar calendar is in the Hebrew calendar. Evidence of this is noted in the dates of Passover and Easter in Judaism and Christianity, respectively. The date of the Jewish Rosh Hashana and Sukkot festivals along with all other Jewish holidays are dependent on the dates of the new moons.\n\nIn lunisolar calendars, an intercalary month occurs seven times in the 19 years of the Metonic cycle, or on average every 2.7 years (19/7). In the Hebrew Calendar this is noted with a periodic extra month of Adar in the early spring.\n\nIn the modern system of \"traditional\" full moon names tied to the solstice and equinox points, a supernumerary full moon in such a period is called a blue moon. The term \"blue moon\" used in this sense may date to as early as the 16th century, but it became well known in the United States due to the \"Farmers' Almanac\" (published since 1818).\n\nAccording to the \"Farmers' Almanac\", a \"blue moon\" is the third full moon in any period between either solstice and equinox, or between equinox and solstice, (calculated using the mean tropical year), which contains four full moons. These seasons are equal in length, unlike the astronomical ones, which vary in length depending on the Earth's speed in its elliptical orbit round the sun. To compare, in 1983 the equal length seasons began at 1.48 AM on 23 March, 9.15 AM on 22 June, 4.42 PM on 21 September and 12.10 AM on 22 December, while the astronomical seasons began at 4.39 AM on 21 March, 11.09 PM on 21 June, 2.42 PM on 23 September and 10.30 AM on 22 December (all times GMT). Due to a misinterpretation of this definition in the March 1946 \"Sky & Telescope\" magazine, \"blue moon\" has also been used in the sense of \"the second full moon in any month which contains two full moons (this usage has been noted as \"erroneous\" by \"Sky & Telescope\" in 1999).\nAccording to either definition, \"blue moons\" occur with the average frequency of intercalary months, seven times in 19 years, the \"Farmers' Almanac\" system of \"full moon names\" effectively defining a lunisolar calendar.\n\n\n"}
{"id": "11433", "url": "https://en.wikipedia.org/wiki?curid=11433", "title": "Film format", "text": "Film format\n\nA film format is a technical definition of a set of standard characteristics regarding image capture on photographic film, for either stills or filmmaking. It can also apply to projected film, either slides or movies. The primary characteristic of a film format is its size and shape.\n\nIn the case of motion picture film, the format may also include audio parameters (though often not). Other characteristics usually include the film gauge, pulldown method, lens anamorphosis (or lack thereof), and film gate or projector aperture dimensions, all of which need to be defined for photography as well as projection, as they may differ.\n\n\"For roll holder\" means film for cartridge roll holders, allowing roll film to be used with cameras designed to use glass plates. These were spooled with the emulsion facing outward, rather than inward as in film designed for native roll-film cameras. Types 106 to 114 were for Eastman-Walker rollholders, while types 50 to 54 were for Graflex rollholders.\n\nThe primary reason there were so many different negative formats in the early days was that prints were made by contact, without use of an enlarger. The film format would thus be exactly the same as the size of the print—so if you wanted large prints, you would have to use a large camera and corresponding film format.\n\nBefore World War II, each film manufacturer used its own system of numbering for the various sizes of rollfilms they made. The following sortable table shows the corresponding numbers. A blank space means that manufacturer did not make film in that size. Two numbers in one box refers to films available with different numbers of exposures, usually 6 and either 10 or 12. Spool length is measured between inner faces of the flanges; several films of the same image size were available on different spools to fit different cameras.\n\n\n"}
{"id": "11439", "url": "https://en.wikipedia.org/wiki?curid=11439", "title": "Faster-than-light", "text": "Faster-than-light\n\nFaster-than-light (also superluminal or FTL) communication and travel refer to the propagation of information or matter faster than the speed of light.\nThe special theory of relativity implies that only particles with zero rest mass may travel at the speed of light. Tachyons, particles whose speed exceeds that of light, have been hypothesized but the existence of such particles would violate causality and the consensus of physicists is that such particles cannot exist.\n\nOn the other hand, what some physicists refer to as \"apparent\" or \"effective\" FTL depends on the hypothesis that unusually distorted regions of spacetime might permit matter to reach distant locations in less time than light could in normal or undistorted spacetime. According to the current scientific theories, matter is required to travel at subluminally Slower-than-light (also subluminal or STL) speed with respect to the locally distorted spacetime region. \"Apparent\" FTL is not excluded by general relativity, however, any \"Apparent\" FTL physical plausibility is speculative. Examples of \"Apparent\" FTL proposals are the Alcubierre drive and the traversable wormhole.\n\nIn the context of this article, FTL is the transmission of information or matter faster than \"c\", a constant equal to the speed of light in a vacuum, which is 299,792,458 m/s (by definition of the meter) or about 186,282.397 miles per second. This is not quite the same as traveling faster than light, since:\nNeither of these phenomena violates special relativity or creates problems with causality, and thus neither qualifies as \"FTL\" as described here.\n\nIn the following examples, certain influences may appear to travel faster than light, but they do not convey energy or information faster than light, so they do not violate special relativity.\n\nFor an Earthbound observer, objects in the sky complete one revolution around the Earth in 1 day. Proxima Centauri, which is the nearest star outside the solar system, is about 4 light-years away. On a geostationary view, Proxima Centauri has a speed many times greater than \"c\" as the rim speed of an object moving in a circle is a product of the radius and angular speed. It is also possible on a geostatic view for objects such as comets to vary their speed from subluminal to superluminal and vice versa simply because the distance from the Earth varies. Comets may have orbits which take them out to more than 1000 AU. The circumference of a circle with a radius of 1000 AU is greater than one light day. In other words, a comet at such a distance is superluminal in a geostatic, and therefore non-inertial, frame.\n\nIf a laser beam is swept across a distant object, the spot of laser light can easily be made to move across the object at a speed greater than \"c\". Similarly, a shadow projected onto a distant object can be made to move across the object faster than \"c\". In neither case does the light travel from the source to the object faster than \"c\", nor does any information travel faster than light.\n\nSince there is no \"retardation\" (or aberration) of the apparent position of the source of a gravitational or electric static field when the source moves with constant velocity, the static field \"effect\" may seem at first glance to be \"transmitted\" faster than the speed of light. However, uniform motion of the static source may be removed with a change in reference frame, causing the direction of the static field to change immediately, at all distances. This is not a change of position which \"propagates\", and thus this change cannot be used to transmit information from the source. No information or matter can be FTL-transmitted or propagated from source to receiver/observer by an electromagnetic field.\n\nThe rate at which two objects in motion in a single frame of reference get closer together is called the mutual or closing speed. This may approach twice the speed of light, as in the case of two particles travelling at close to the speed of light in opposite directions with respect to the reference frame.\n\nImagine two fast-moving particles approaching each other from opposite sides of a particle accelerator of the collider type. The closing speed would be the rate at which the distance between the two particles is decreasing. From the point of view of an observer standing at rest relative to the accelerator, this rate will be slightly less than twice the speed of light.\n\nSpecial relativity does not prohibit this. It tells us that it is wrong to use Galilean relativity to compute the velocity of one of the particles, as would be measured by an observer traveling alongside the other particle. That is, special relativity gives the right formula for computing such relative velocity.\n\nIt is instructive to compute the relative velocity of particles moving at \"v\" and −\"v\" in accelerator frame, which corresponds to the closing speed of 2\"v\" > \"c\". Expressing the speeds in units of \"c\", β = \"v\"/\"c\":\n\nIf a spaceship travels to a planet one light-year (as measured in the Earth's rest frame) away from Earth at high speed, the time taken to reach that planet could be less than one year as measured by the traveller's clock (although it will always be more than one year as measured by a clock on Earth). The value obtained by dividing the distance traveled, as determined in the Earth's frame, by the time taken, measured by the traveller's clock, is known as a proper speed or a proper velocity. There is no limit on the value of a proper speed as a proper speed does not represent a speed measured in a single inertial frame. A light signal that left the Earth at the same time as the traveller would always get to the destination before the traveller.\n\nSince one might not travel faster than light, one might conclude that a human can never travel further from the Earth than 40 light-years if the traveler is active between the age of 20 and 60. A traveler would then never be able to reach more than the very few star systems which exist within the limit of 20–40 light-years from the Earth. This is a mistaken conclusion: because of time dilation, the traveler can travel thousands of light-years during their 40 active years. If the spaceship accelerates at a constant 1 g (in its own changing frame of reference), it will, after 354 days, reach speeds a little under the speed of light (for an observer on Earth), and time dilation will increase their lifespan to thousands of Earth years, seen from the reference system of the Solar System, but the traveler's subjective lifespan will not thereby change. If the traveler returns to the Earth, she or he will land thousands of years into the Earth's future. Their speed will not be seen as higher than the speed of light by observers on Earth, and the traveler will not measure their speed as being higher than the speed of light, but will see a length contraction of the universe in their direction of travel. And as the traveler turns around to return, the Earth will seem to experience much more time than the traveler does. So, while their (ordinary) coordinate speed cannot exceed \"c\", their proper speed (distance as seen by Earth divided by their proper time) can be much greater than \"c\". This is seen in statistical studies of muons traveling much further than \"c\" times their half-life (at rest), if traveling close to \"c\".\n\nThe phase velocity of an electromagnetic wave, when traveling through a medium, can routinely exceed \"c\", the vacuum velocity of light. For example, this occurs in most glasses at X-ray frequencies. However, the phase velocity of a wave corresponds to the propagation speed of a theoretical single-frequency (purely monochromatic) component of the wave at that frequency. Such a wave component must be infinite in extent and of constant amplitude (otherwise it is not truly monochromatic), and so cannot convey any information.\nThus a phase velocity above \"c\" does not imply the propagation of signals with a velocity above \"c\".\n\nThe group velocity of a wave (e.g., a light beam) may also exceed \"c\" in some circumstances. In such cases, which typically at the same time involve rapid attenuation of the intensity, the maximum of the envelope of a pulse may travel with a velocity above \"c\". However, even this situation does not imply the propagation of signals with a velocity above \"c\", even though one may be tempted to associate pulse maxima with signals. The latter association has been shown to be misleading, because the information on the arrival of a pulse can be obtained before the pulse maximum arrives. For example, if some mechanism allows the full transmission of the leading part of a pulse while strongly attenuating the pulse maximum and everything behind (distortion), the pulse maximum is effectively shifted forward in time, while the information on the pulse does not come faster than \"c\" without this effect. However, group velocity can exceed \"c\" in some parts of a Gaussian beam in vacuum (without attenuation). The diffraction causes that the peak of pulse propagates faster, while overall power does not.\n\nThe expansion of the universe causes distant galaxies to recede from us faster than the speed of light, if proper distance and cosmological time are used to calculate the speeds of these galaxies. However, in general relativity, velocity is a local notion, so velocity calculated using comoving coordinates does not have any simple relation to velocity calculated locally. (See comoving distance for a discussion of different notions of 'velocity' in cosmology.) Rules that apply to relative velocities in special relativity, such as the rule that relative velocities cannot increase past the speed of light, do not apply to relative velocities in comoving coordinates, which are often described in terms of the \"expansion of space\" between galaxies. This expansion rate is thought to have been at its peak during the inflationary epoch thought to have occurred in a tiny fraction of the second after the Big Bang (models suggest the period would have been from around 10 seconds after the Big Bang to around 10 seconds), when the universe may have rapidly expanded by a factor of around 10 to 10.\n\nThere are many galaxies visible in telescopes with red shift numbers of 1.4 or higher. All of these are currently traveling away from us at speeds greater than the speed of light. Because the Hubble parameter is decreasing with time, there can actually be cases where a galaxy that is receding from us faster than light does manage to emit a signal which reaches us eventually.\n\nAccording to Tamara M. Davis, \"Our effective particle horizon is the cosmic microwave background (CMB), at redshift z ∼ 1100, because we cannot see beyond the surface of last scattering. Although the last scattering surface is not at any fixed comoving coordinate, the current recession velocity of the points from which the CMB was emitted is 3.2c. At the time of emission their speed was 58.1c, assuming (ΩM,ΩΛ) = (0.3,0.7). Thus we routinely observe objects that are receding faster than the speed of light and the Hubble sphere is not a horizon.\"\n\nHowever, because the expansion of the universe is accelerating, it is projected that most galaxies will eventually cross a type of cosmological event horizon where any light they emit past that point will never be able to reach us at any time in the infinite future, because the light never reaches a point where its \"peculiar velocity\" towards us exceeds the expansion velocity away from us (these two notions of velocity are also discussed in Comoving distance#Uses of the proper distance). The current distance to this cosmological event horizon is about 16 billion light-years, meaning that a signal from an event happening at present would eventually be able to reach us in the future if the event was less than 16 billion light-years away, but the signal would never reach us if the event was more than 16 billion light-years away.\n\nApparent superluminal motion is observed in many radio galaxies, blazars, quasars and recently also in microquasars. The effect was predicted before it was observed by Martin Rees and can be explained as an optical illusion caused by the object partly moving in the direction of the observer, when the speed calculations assume it does not. The phenomenon does not contradict the theory of special relativity. Corrected calculations show these objects have velocities close to the speed of light (relative to our reference frame). They are the first examples of large amounts of mass moving at close to the speed of light. Earth-bound laboratories have only been able to accelerate small numbers of elementary particles to such speeds.\n\nCertain phenomena in quantum mechanics, such as quantum entanglement, might give the superficial impression of allowing communication of information faster than light. According to the no-communication theorem these phenomena do not allow true communication; they only let two observers in different locations see the same system simultaneously, without any way of controlling what either sees. Wavefunction collapse can be viewed as an epiphenomenon of quantum decoherence, which in turn is nothing more than an effect of the underlying local time evolution of the wavefunction of a system and \"all\" of its environment. Since the underlying behaviour does not violate local causality or allow FTL it follows that neither does the additional effect of wavefunction collapse, whether real \"or\" apparent.\n\nThe uncertainty principle implies that individual photons may travel for short distances at speeds somewhat faster (or slower) than \"c\", even in a vacuum; this possibility must be taken into account when enumerating Feynman diagrams for a particle interaction. However, it was shown in 2011 that a single photon may not travel faster than \"c\". In quantum mechanics, virtual particles may travel faster than light, and this phenomenon is related to the fact that static field effects (which are mediated by virtual particles in quantum terms) may travel faster than light (see section on static fields above). However, macroscopically these fluctuations average out, so that photons do travel in straight lines over long (i.e., non-quantum) distances, and they do travel at the speed of light on average. Therefore, this does not imply the possibility of superluminal information transmission.\n\nThere have been various reports in the popular press of experiments on faster-than-light transmission in optics — most often in the context of a kind of quantum tunnelling phenomenon. Usually, such reports deal with a phase velocity or group velocity faster than the vacuum velocity of light. However, as stated above, a superluminal phase velocity cannot be used for faster-than-light transmission of information.\n\nThe Hartman effect is the tunneling effect through a barrier where the tunneling time tends to a constant for large barriers. This was first described by Thomas Hartman in 1962. This could, for instance, be the gap between two prisms. When the prisms are in contact, the light passes straight through, but when there is a gap, the light is refracted. There is a non-zero probability that the photon will tunnel across the gap rather than follow the refracted path. For large gaps between the prisms the tunnelling time approaches a constant and thus the photons appear to have crossed with a superluminal speed.\n\nHowever, an analysis by Herbert G. Winful from the University of Michigan suggests that the Hartman effect cannot actually be used to violate relativity by transmitting signals faster than \"c\", because the tunnelling time \"should not be linked to a velocity since evanescent waves do not propagate\". The evanescent waves in the Hartman effect are due to virtual particles and a non-propagating static field, as mentioned in the sections above for gravity and electromagnetism.\n\nIn physics, the Casimir effect or Casimir-Polder force is a physical force exerted between separate objects due to resonance of vacuum energy in the intervening space between the objects. This is sometimes described in terms of virtual particles interacting with the objects, owing to the mathematical form of one possible way of calculating the strength of the effect. Because the strength of the force falls off rapidly with distance, it is only measurable when the distance between the objects is extremely small. Because the effect is due to virtual particles mediating a static field effect, it is subject to the comments about static fields discussed above.\n\nThe EPR paradox refers to a famous thought experiment of Einstein, Podolski and Rosen that was realized experimentally for the first time by Alain Aspect in 1981 and 1982 in the Aspect experiment. In this experiment, the measurement of the state of one of the quantum systems of an entangled pair apparently instantaneously forces the other system (which may be distant) to be measured in the complementary state. However, no information can be transmitted this way; the answer to whether or not the measurement actually affects the other quantum system comes down to which interpretation of quantum mechanics one subscribes to.\n\nAn experiment performed in 1997 by Nicolas Gisin at the University of Geneva has demonstrated non-local quantum correlations between particles separated by over 10 kilometers. But as noted earlier, the non-local correlations seen in entanglement cannot actually be used to transmit classical information faster than light, so that relativistic causality is preserved; see no-communication theorem for further information. A 2008 quantum physics experiment also performed by Nicolas Gisin and his colleagues in Geneva, Switzerland has determined that in any hypothetical non-local hidden-variables theory the speed of the quantum non-local connection (what Einstein called \"spooky action at a distance\") is at least 10,000 times the speed of light.\n\nDelayed choice quantum eraser (an experiment of Marlan Scully) is a version of the EPR paradox in which the observation or not of interference after the passage of a photon through a double slit experiment depends on the conditions of observation of a second photon entangled with the first. The characteristic of this experiment is that the observation of the second photon can take place at a later time than the observation of the first photon, which may give the impression that the measurement of the later photons \"retroactively\" determines whether the earlier photons show interference or not, although the interference pattern can only be seen by correlating the measurements of both members of every pair and so it can't be observed until both photons have been measured, ensuring that an experimenter watching only the photons going through the slit does not obtain information about the other photons in an FTL or backwards-in-time manner.\n\nFaster-than-light communication is, by Einstein's theory of relativity, equivalent to time travel. According to Einstein's theory of special relativity, what we measure as the speed of light in a vacuum (or near vacuum) is actually the fundamental physical constant \"c\". This means that all inertial observers, regardless of their relative velocity, will always measure zero-mass particles such as photons traveling at \"c\" in a vacuum. This result means that measurements of time and velocity in different frames are no longer related simply by constant shifts, but are instead related by Poincaré transformations. These transformations have important implications:\n\nEinstein's equations of special relativity postulate that the speed of light in a (near) vacuum is invariant in inertial frames. That is, it will be the same from any frame of reference moving at a constant speed. The equations do not specify any particular value for the speed of the light, which is an experimentally determined quantity for a fixed unit of length. Since 1983, the SI unit of length (the meter) has been defined using the speed of light.\n\nThe experimental determination has been made in vacuum. However, the vacuum we know is not the only possible vacuum which can exist. The vacuum has energy associated with it, called simply the vacuum energy, which could perhaps be altered in certain cases. When vacuum energy is lowered, light itself has been predicted to go faster than the standard value \"c\". This is known as the Scharnhorst effect. Such a vacuum can be produced by bringing two perfectly smooth metal plates together at near atomic diameter spacing. It is called a Casimir vacuum. Calculations imply that light will go faster in such a vacuum by a minuscule amount: a photon traveling between two plates that are 1 micrometer apart would increase the photon's speed by only about one part in 10. Accordingly, there has as yet been no experimental verification of the prediction. A recent analysis argued that the Scharnhorst effect cannot be used to send information backwards in time with a single set of plates since the plates' rest frame would define a \"preferred frame\" for FTL signalling. However, with multiple pairs of plates in motion relative to one another the authors noted that they had no arguments that could \"guarantee the total absence of causality violations\", and invoked Hawking's speculative chronology protection conjecture which suggests that feedback loops of virtual particles would create \"uncontrollable singularities in the renormalized quantum stress-energy\" on the boundary of any potential time machine, and thus would require a theory of quantum gravity to fully analyze. Other authors argue that Scharnhorst's original analysis, which seemed to show the possibility of faster-than-\"c\" signals, involved approximations which may be incorrect, so that it is not clear whether this effect could actually increase signal speed at all.\n\nThe physicists Günter Nimtz and Alfons Stahlhofen, of the University of Cologne, claim to have violated relativity experimentally by transmitting photons faster than the speed of light. They say they have conducted an experiment in which microwave photons — relatively low-energy packets of light — travelled \"instantaneously\" between a pair of prisms that had been moved up to apart. Their experiment involved an optical phenomenon known as \"evanescent modes\", and they claim that since evanescent modes have an imaginary wave number, they represent a \"mathematical analogy\" to quantum tunnelling. Nimtz has also claimed that \"evanescent modes are not fully describable by the Maxwell equations and quantum mechanics have to be taken into consideration.\" Other scientists such as Herbert G. Winful and Robert Helling have argued that in fact there is nothing quantum-mechanical about Nimtz's experiments, and that the results can be fully predicted by the equations of classical electromagnetism (Maxwell's equations).\n\nNimtz told \"New Scientist\" magazine: \"For the time being, this is the only violation of special relativity that I know of.\" However, other physicists say that this phenomenon does not allow information to be transmitted faster than light. Aephraim Steinberg, a quantum optics expert at the University of Toronto, Canada, uses the analogy of a train traveling from Chicago to New York, but dropping off train cars at each station along the way, so that the center of the ever-shrinking main train moves forward at each stop; in this way, the speed of the center of the train exceeds the speed of any of the individual cars.\n\nHerbert G. Winful argues that the train analogy is a variant of the \"reshaping argument\" for superluminal tunneling velocities, but he goes on to say that this argument is not actually supported by experiment or simulations, which actually show that the transmitted pulse has the same length and shape as the incident pulse. Instead, Winful argues that the group delay in tunneling is not actually the transit time for the pulse (whose spatial length must be greater than the barrier length in order for its spectrum to be narrow enough to allow tunneling), but is instead the lifetime of the energy stored in a standing wave which forms inside the barrier. Since the stored energy in the barrier is less than the energy stored in a barrier-free region of the same length due to destructive interference, the group delay for the energy to escape the barrier region is shorter than it would be in free space, which according to Winful is the explanation for apparently superluminal tunneling.\n\nA number of authors have published papers disputing Nimtz's claim that Einstein causality is violated by his experiments, and there are many other papers in the literature discussing why quantum tunneling is not thought to violate causality.\n\nIt was later claimed by the Keller group in Switzerland that particle tunneling does indeed occur in zero real time. Their tests involved tunneling electrons, where the group argued a relativistic prediction for tunneling time should be 500-600 attoseconds (an attosecond is one quintillionth (10) of a second). All that could be measured was 24 attoseconds, which is the limit of the test accuracy. Again, though, other physicists believe that tunneling experiments in which particles appear to spend anomalously short times inside the barrier are in fact fully compatible with relativity, although there is disagreement about whether the explanation involves reshaping of the wave packet or other effects.\n\nBecause of the strong empirical support for special relativity, any modifications to it must necessarily be quite subtle and difficult to measure. The best-known attempt is doubly special relativity, which posits that the Planck length is also the same in all reference frames, and is associated with the work of Giovanni Amelino-Camelia and João Magueijo.\n\nThere are speculative theories that claim inertia is produced by the combined mass of the universe (e.g., Mach's principle), which implies that the rest frame of the universe might be \"preferred\" by conventional measurements of natural law. If confirmed, this would imply special relativity is an approximation to a more general theory, but since the relevant comparison would (by definition) be outside the observable universe, it is difficult to imagine (much less construct) experiments to test this hypothesis.\n\nAlthough the theory of special relativity forbids objects to have a relative velocity greater than light speed, and general relativity reduces to special relativity in a local sense (in small regions of spacetime where curvature is negligible), general relativity does allow the space between distant objects to expand in such a way that they have a \"recession velocity\" which exceeds the speed of light, and it is thought that galaxies which are at a distance of more than about 14 billion light-years from us today have a recession velocity which is faster than light. Miguel Alcubierre theorized that it would be possible to create an Alcubierre drive, in which a ship would be enclosed in a \"warp bubble\" where the space at the front of the bubble is rapidly contracting and the space at the back is rapidly expanding, with the result that the bubble can reach a distant destination much faster than a light beam moving outside the bubble, but without objects inside the bubble locally traveling faster than light. However, several objections raised against the Alcubierre drive appear to rule out the possibility of actually using it in any practical fashion. Another possibility predicted by general relativity is the traversable wormhole, which could create a shortcut between arbitrarily distant points in space. As with the Alcubierre drive, travelers moving through the wormhole would not \"locally\" move faster than light travelling through the wormhole alongside them, but they would be able to reach their destination (and return to their starting location) faster than light traveling outside the wormhole.\n\nDr. Gerald Cleaver, associate professor of physics at Baylor University, and Richard Obousy, a Baylor graduate student, theorized that manipulating the extra spatial dimensions of string theory around a spaceship with an extremely large amount of energy would create a \"bubble\" that could cause the ship to travel faster than the speed of light. To create this bubble, the physicists believe manipulating the 10th spatial dimension would alter the dark energy in three large spatial dimensions: height, width and length. Cleaver said positive dark energy is currently responsible for speeding up the expansion rate of our universe as time moves on.\n\nIn 1977, a paper on Heim theory theorized that it may be possible to travel faster than light by using magnetic fields to enter a higher-dimensional space.\n\nThe possibility that Lorentz symmetry may be violated has been seriously considered in the last two decades, particularly after the development of a realistic effective field theory that describes this possible violation, the so-called Standard-Model Extension. This general framework has allowed experimental searches by ultra-high energy cosmic-ray experiments and a wide variety of experiments in gravity, electrons, protons, neutrons, neutrinos, mesons, and photons.\nThe breaking of rotation and boost invariance causes direction dependence in the theory as well as unconventional energy dependence that introduces novel effects, including Lorentz-violating neutrino oscillations and modifications to the dispersion relations of different particle species, which naturally could make particles move faster than light.\n\nIn some models of broken Lorentz symmetry, it is postulated that the symmetry is still built into the most fundamental laws of physics, but that spontaneous symmetry breaking of Lorentz invariance shortly after the Big Bang could have left a \"relic field\" throughout the universe which causes particles to behave differently depending on their velocity relative to the field; however, there are also some models where Lorentz symmetry is broken in a more fundamental way. If Lorentz symmetry can cease to be a fundamental symmetry at Planck scale or at some other fundamental scale, it is conceivable that particles with a critical speed different from the speed of light be the ultimate constituents of matter.\n\nIn current models of Lorentz symmetry violation, the phenomenological parameters are expected to be energy-dependent. Therefore, as widely recognized, existing low-energy bounds cannot be applied to high-energy phenomena; however, many searches for Lorentz violation at high energies have been carried out using the Standard-Model Extension.\nLorentz symmetry violation is expected to become stronger as one gets closer to the fundamental scale.\n\nIn this approach the physical vacuum is viewed as the quantum superfluid which is essentially non-relativistic whereas the Lorentz symmetry is not an exact symmetry of nature but rather the approximate description valid only for the small fluctuations of the superfluid background. Within the framework of the approach a theory was proposed in which the physical vacuum is conjectured to be the quantum Bose liquid whose ground-state wavefunction is described by the logarithmic Schrödinger equation. It was shown that the relativistic gravitational interaction arises as the small-amplitude collective excitation mode whereas relativistic elementary particles can be described by the particle-like modes in the limit of low momenta. The important fact is that at very high velocities the behavior of the particle-like modes becomes distinct from the relativistic one - they can reach the speed of light limit at finite energy; also, faster-than-light propagation is possible without requiring moving objects to have imaginary mass.\n\nIn 2007 the MINOS collaboration reported results measuring the flight-time of 3 GeV neutrinos yielding a speed exceeding that of light by 1.8-sigma significance. However, those measurements were considered to be statistically consistent with neutrinos traveling at the speed of light. After the detectors for the project were upgraded in 2012, MINOS corrected their initial result and found agreement with the speed of light. Further measurements are going to be conducted.\n\nOn September 22, 2011, a preprint from the OPERA Collaboration indicated detection of 17 and 28 GeV muon neutrinos, sent 730 kilometers (454 miles) from CERN near Geneva, Switzerland to the Gran Sasso National Laboratory in Italy, traveling faster than light by a relative amount of 2.48×10 (approximately 1 in 40,000), a statistic with 6.0-sigma significance. On 17 November 2011, a second follow-up experiment by OPERA scientists confirmed their initial results. However, scientists were skeptical about the results of these experiments, the significance of which was disputed. In March 2012, the ICARUS collaboration failed to reproduce the OPERA results with their equipment, detecting neutrino travel time from CERN to the Gran Sasso National Laboratory indistinguishable from the speed of light. Later the OPERA team reported two flaws in their equipment set-up that had caused errors far outside their original confidence interval: a fiber optic cable attached improperly, which caused the apparently faster-than-light measurements, and a clock oscillator ticking too fast.\n\nIn special relativity, it is impossible to accelerate an object the speed of light, or for a massive object to move the speed of light. However, it might be possible for an object to exist which moves faster than light. The hypothetical elementary particles with this property are called tachyonic particles. Attempts to quantize them failed to produce faster-than-light particles, and instead illustrated that their presence leads to an instability.\n\nVarious theorists have suggested that the neutrino might have a tachyonic nature, while others have disputed the possibility.\n\nMechanical equations to describe hypothetical exotic matter which possesses a negative mass, negative momentum, negative pressure and negative kinetic energy are \n\nConsidering formula_6 and formula_7, the energy-momentum relation of the particle is corresponding to the following dispersion relation \n\nof a wave that can propagate in the negative index metamaterial. Interestingly, the pressure of radiation pressure in the metamaterial is negative and negative refraction, inverse Doppler effect and reverse Cherenkov effect imply that the momentum is also negative. So the wave in a negative index metamaterial can be applied to test the theory of exotic matter and negative mass. For example, the velocity equals\n\nThat is to say, such a wave can break the light barrier under certain conditions and the correctness of the prediction can be judged by comparison with experiments.\n\nGeneral relativity was developed after special relativity to include concepts like gravity. It maintains the principle that no object can accelerate to the speed of light in the reference frame of any coincident observer. However, it permits distortions in spacetime that allow an object to move faster than light from the point of view of a distant observer. One such distortion is the Alcubierre drive, which can be thought of as producing a ripple in spacetime that carries an object along with it. Another possible system is the wormhole, which connects two distant locations as though by a shortcut. Both distortions would need to create a very strong curvature in a highly localized region of space-time and their gravity fields would be immense. To counteract the unstable nature, and prevent the distortions from collapsing under their own 'weight', one would need to introduce hypothetical exotic matter or negative energy.\n\nGeneral relativity also recognizes that any means of faster-than-light travel could also be used for time travel. This raises problems with causality. Many physicists believe that the above phenomena are impossible and that future theories of gravity will prohibit them. One theory states that stable wormholes are possible, but that any attempt to use a network of wormholes to violate causality would result in their decay. In string theory, Eric G. Gimon and Petr Hořava have argued that in a supersymmetric five-dimensional Gödel universe, quantum corrections to general relativity effectively cut off regions of spacetime with causality-violating closed timelike curves. In particular, in the quantum theory a smeared supertube is present that cuts the spacetime in such a way that, although in the full spacetime a closed timelike curve passed through every point, no complete curves exist on the interior region bounded by the tube.\n\nIn physics, the speed of light in a vacuum is assumed to be a constant. However, hypotheses exist that the speed of light is variable.\n\nThe speed of light is a dimensional quantity and so, as has been emphasized in this context by João Magueijo, it cannot be measured. Measurable quantities in physics are, without exception, dimensionless, although they are often constructed as ratios of dimensional quantities. For example, when the height of a mountain is measured, what is really measured is the ratio of its height to the length of a meter stick. The conventional SI system of units is based on seven basic dimensional quantities, namely distance, mass, time, electric current, thermodynamic temperature, amount of substance, and luminous intensity. These units are defined to be independent and so cannot be described in terms of each other. As an alternative to using a particular system of units, one can reduce all measurements to dimensionless quantities expressed in terms of ratios between the quantities being measured and various fundamental constants such as Newton's constant, the speed of light and Planck's constant; physicists can define at least 26 dimensionless constants which can be expressed in terms of these sorts of ratios and which are currently thought to be independent of one another. By manipulating the basic dimensional constants one can also construct the Planck time, Planck length and Planck energy which make a good system of units for expressing dimensional measurements, known as Planck units.\n\nMagueijo's proposal used a different set of units, a choice which he justifies with the claim that some equations will be simpler in these new units. In the new units he fixes the fine structure constant, a quantity which some people, using units in which the speed of light is fixed, have claimed is time-dependent. Thus in the system of units in which the fine structure constant is fixed, the observational claim is that the speed of light is time-dependent.\n\n\n\n\n\n"}
{"id": "11440", "url": "https://en.wikipedia.org/wiki?curid=11440", "title": "FTL", "text": "FTL\n\nFTL may stand for:\n\n\n\n"}
{"id": "11442", "url": "https://en.wikipedia.org/wiki?curid=11442", "title": "FidoNet", "text": "FidoNet\n\nFidoNet is a worldwide computer network that is used for communication between bulletin board systems (BBSes). It uses a store-and-forward system to exchange private (email) and public (forum) messages between the BBSes in the network, as well as other files and protocols in some cases.\n\nThe FidoNet system was based on a number of small interacting programs. Only one of these interacted with the BBS system directly and was the only portion that had to be ported to support other BBS software. This greatly eased porting, and FidoNet was one of the few networks that was widely supported by almost all BBS software, as well as a number of non-BBS online services. This modular construction also allowed FidoNet to easily upgrade to new data compression systems, which was important in an era using modem-based communications over telephone links with high long-distance calling charges.\n\nThe rapid improvement in modem speeds during the early 1990s, combined with the rapid decrease in price of computer systems and storage, made BBSes increasingly popular. By the mid-1990s there were almost 40,000 FidoNet systems in operation, and it was possible to communicate with millions of users around the world. Only UUCPNET came close in terms of breadth or numbers; FidoNet's user base far surpassed other networks like BITNET.\n\nThe broad availability of low-cost Internet connections starting in the mid-1990s lessened the need for FidoNet's store-and-forward system, as any system in the world could be reached for equal cost. Direct dialing into local BBS systems rapidly declined. The availability of internet connectivity is by no means universal, and although FidoNet has shrunk considerably since the early 1990s, it remains in use around the world.\n\nThere are two major accounts of the development of the FidoNet, differing only in small details.\n\nAround Christmas 1983, Tom Jennings started work on a new MS-DOS–hosted bulletin board system that would emerge as Fido BBS. Jennings set up the system in San Francisco some time in early 1984. Another early user was John Madil, who was trying to set up a similar system in Baltimore on his Rainbow 100. Fido started spreading to new systems, and Jennings eventually started keeping an informal list of their phone numbers, with Jennings becoming #1 and Madil #2.\n\nJennings released the first version of the FidoNet software in June 1984. In early 1985 he wrote a document explaining the operations of the FidoNet, along with a short portion on the history of the system. In this version, FidoNet was developed as a way to exchange mail between the first two Fido BBS systems, Jennings' and Madil's, to \"see if it could be done, merely for the fun of it\". This was first supported in Fido V7, \"sometime in June 84 or so\".\n\nIn early 1984, Ben Baker was planning on starting a BBS for the newly forming computer club at the McDonnell Douglas automotive division in St. Louis. Baker was part of the CP/M special interest group within the club. He intended to use the seminal, CP/M-hosted, CBBS system, and went looking for a machine to run it on. The club's president told Baker that DEC would be giving them a Rainbow 100 computer on indefinite loan, so he made plans to move the CBBS onto this machine. The Rainbow contained two processors, an Intel 8088 and a Zilog Z80, allowing it to run both MS-DOS and CP/M, with the BBS running on the latter. When the machine arrived, they learned that the Z80 side had no access to the I/O ports, so CBBS could not communicate with a modem. While searching for software that would run on the MS-DOS side of the system, Baker learned of Fido through Madil.\n\nThe Fido software required changes to the serial drivers to work properly on the Rainbow. A porting effort started, involving Jennings, Madil and Baker. This caused all involved to rack up considerable long distance charges as they all called each other during development, or called into each other's BBSes to leave email. During one such call \"in May or early June\", Baker and Jennings discussed how great it would be if the BBS systems could call each other automatically, exchanging mail and files between them. This would allow them to compose mail on their local machines, and then deliver it quickly, as opposed to calling in and typing the message in while on a long-distance telephone connection. Jennings responded by calling into Baker's system that night and uploading a new version of the software consisting of three files: FIDO_DECV6 (the new version of the BBS program itself), FIDONET, and NODELIST.BBS. The new version of FIDO BBS had a timer that caused it to exit at a specified time, normally at night, and as it exited it would run the separate FIDONET program. NODELIST was the list of Fido BBS systems, which Jennings had already been compiling.\n\nThe FIDONET program was what later became known as a \"mailer\". FIDO was modified to use a previously unused numeric field in the message headers to store a \"node number\" for the machine the message should be delivered to. When FIDONET ran, it would search through the email database for any messages with a number in this field. FIDONET collected all of the messages for a particular node number into a file known as a \"message packet\". After all the packets were generated, one for each node, the FIDONET program would look up the destination node's phone number in NODELIST.BBS, and call the remote system. Provided that FIDONET was running on that system, the two systems would handshake and, if this succeeded, the calling system would upload its packet, download a return packet if there was one, and disconnect. FIDONET would then unpack the return packet, place the received messages into the local system's storage, and move onto the next packet. When there were no remaining packet, it would exit, and run the FIDO BBS program.\n\nIn order to lower long distance charges, the mail exchanges were timed to run late at night, normally 4 AM. This would later be known as \"national mail hour\", and, later still, as \"Zone Mail Hour\".\n\nBy June 1984 Version 7 of the system was being run in production, and nodes were rapidly being added to the network. By August there were almost 30 systems in the nodelist, 50 by September, and over 160 by January 1985. As the network grew, the maintenance of the nodelist became prohibitive, and errors were common. In these cases people would start receiving phone calls at 4 AM, from a caller that would say nothing and then hang up. In other cases the system would be listed before it was up and running, resulting long distance calls that accomplished nothing.\n\nIn August 1984 Jennings handed off control of the nodelist to the group in St. Louis, mostly Ken Kaplan and Ben Baker. Kaplan had come across Fido as part of finding a BBS solution for his company, which worked with DEC computers and had been given a Rainbow computer and a USRobotics 1200bit/s modem. From then on, joining FidoNet required one to set up their system and use it to deliver a netmail message to a special system, Node 51. The message contained various required contact information. If this message was transmitted successfully, it ensured that at least some of the system was working properly. The nodelist team would then reply with another netmail message back to the system in question, containing the assigned node number. If delivery succeeded, the system was considered to be working properly, and it was added to the nodelist. The first new nodelist was published on 21 September 1984.\n\nGrowth continued to accelerate, and by the spring of 1985 the system was already reaching its limit of 250 nodes. In addition to the limits on growth of what was clearly a popular system, nodelist maintenance continued to grow more and more time consuming.\n\nIt was also realized that Fido systems were generally clustered – of the 15 systems running by the start of June 1984, 5 of them were in St. Louis. A user on Jennings's system in San Francisco that addressed emails to different systems in St. Louis would cause calls to be made to each of those BBSes in turn. Local calls were normally free or charged at a low rate. Additionally, the initial call setup, generally the first minute of the call, was normally billed at a higher rate than continuing an existing connection. Therefore, it would make sense to deliver all the messages from all the users in San Francisco to all of the users in St. Louis in a single call. Packets were generally small enough to be delivered within a minute or two, so delivering all the messages in a single call could greatly reduce costs by avoiding multiple first-minute charges. Once delivered, the packet would be broken out into separate packets for local systems, and delivered using multiple local free calls.\n\nThe team settled on the concept of adding a new \"network number\" patterned on the idea of area codes. A complete network address would now consist of the network and node number pair, which would be written with a slash between them. All mail travelling between networks would first be sent to their local \"network host\", someone who volunteered to pay for any long distance charges. That single site would collect up all the netmail from all of the systems in their network, then re-package it into single packets destined to each network. They would then call any required network admin sites and deliver the packet to them. That site would then process the mail as normal, although all of the messages in the packet would be guaranteed to be local calls.\n\nThe network address was placed in an unused field in the Fido message database, which formerly always held a zero. Systems running existing versions of the software already ignored the fields containing the new addressing, so they would continue to work as before; when noticing a message addressed to another node they would look it up and call that system. Newer systems would recognize the network number and instead deliver that message to the network host. To ensure backward compatibility, existing systems retained their original node numbers through this period.\n\nA huge advantage of the new scheme was that node numbers were now unique only within their network, not globally. This meant the previous 250 node limit was gone, but for a variety of reasons this was initially limited to about 1,200. This change also devolved the maintenance of the nodelists down to the network hosts, who then sent updated lists back to Node 51 to be collected into the master list. The St. Louis group now had to only maintain their own local network, and do basic work to compile the global list.\n\nAt a meeting held in Kaplan's living room in St. Louis on 11 April 1985 the various parties hammered out all of the details of the new concept. As part of this meeting, they also added the concept of a \"region\", a purely administrative level that was not part of the addressing scheme. Regional hosts would handle any stragglers in the network maps, remote systems that had no local network hosts. They then divided up the US into ten regions that they felt would have roughly equal populations.\n\nBy May, Jennings had early versions of the new software running. These early versions specified the routing manually through a new ROUTE.BBS file that listed network hosts for each node. For instance, an operator might want to forward all mail to St. Louis through a single node, node 10. ROUTE.BBS would then include a list of all the known systems in that area, with instructions to forward mail to each of those nodes through node 10. This process was later semi-automated by John Warren's NODELIST program. Over time, this information was folded into updated versions of the nodelist format, and the ROUTES file is no longer used.\n\nA new version of FIDO and FIDONET, 10C, was released containing all of these features. On 12 June 1985 the core group brought up 10C, and most Fido systems had upgraded within a few months. The process went much smoother than anyone imagined, and very few nodes had any problems.\n\nSome time during the evolution of Fido, file attachments were added to the system, allowing a file to be referenced from an email message. During the normal exchange between two instances of FIDONET, any files attached to the messages in the packets were delivered after the packet itself had been up or downloaded. It is not clear when this was added, but it was already a feature of the basic system when the 8 February 1985 version of the FidoNet standards document was released, so this was added very early in Fido's history.\n\nAt a sysop meeting in Dallas, the idea was raised that it would be nice if there was some way for the sysops to post messages that would be shared among the systems. In February 1986 Jeff Rush, one of the group members, introduced a new mailer that extracted messages from public forums that the sysop selected, in a manner similar to the way the original mailer handled private messages. The new program was known as a \"tosser/scanner\". The tosser produced a file that was similar (or identical) to the output from the normal netmail scan, however, these files were then compressed and attached to a normal netmail message as an attachment. This message was then sent to a special address on the remote system. After receiving netmail as normal, the scanner on the remote system looked for these messages, unpacked them, and put them into the same public forum on the original system.\n\nIn this fashion, Rush's system implemented a store and forward public message system similar to Usenet, but based on, and hosted by, the FidoNet system. The first such \"echomail\" forum was one created by the Dallas area sysops to discuss business, known as SYSOP. Another called TECH soon followed. Several public \"echos\" soon followed, including GAYNET and CLANG. These spawned hundreds of new echos, and led to the creation of the Echomail Conference List (Echolist) by Thomas Kenny in January 1987. Echomail produced world-spanning shared forums, and its traffic volume quickly surpassed the original netmail system. By the early 1990s, echo mail was carrying over 8 MB of compressed message traffic a day, many times that when uncompressed.\n\nEchomail did not necessarily use the same distribution pathways as normal netmail, and the distribution routing was stored in a separate setup file not unlike the original ROUTES.BBS. At the originating site a header line was added to the message indicating the origin system's name and address. After that, each system that the message traveled through added itself to a growing PATH header, as well as a SEENBY header. SEENBY prevented the message from looping around the network in the case of mis-configured routing information.\n\nEchomail was not the only system to use the file attachment feature of netmail to implement store-and-forward capabilities. Similar concepts were used by online games and other systems as well.\n\nThe evolution towards the net/node addressing scheme was also useful for reducing communications costs between continents, where timezone differences on either end of the connection might also come into play. For instance, the best time to forward mail in the US was at night, but that might not be the best time for European hosts to exchange. Efforts towards introducing a continental level to the addressing system started in 1986.\n\nAt the same time, it was noted that some power users were interested in using FidoNet protocols as a way of delivering the large quantities of echomail to their local machines where it could be read offline. These users did not want their systems to appear in the nodelist - they did not (necessarily) run a bulletin board system and were not publicly accessible. A mechanism allowing netmail delivery to these systems without the overhead of nodelist maintenance was desirable.\n\nIn October 1986 the last major change to the FidoNet network was released, adding \"zones\" and \"points\". Zones represented major geographical areas roughly corresponding to continents. There were six zones in total, North America, South America, Europe, Oceania, Asia, and Africa. Points represented non-public nodes, which were created privately on a BBS system. Point mail was delivered to a selected host BBS as normal, but then re-packaged into a packet for the point to pick up on-demand. The complete addressing format was now codice_1, so a real example might be codice_2. Points were widely used only for a short time, the introduction of offline reader systems filled this role with systems that were much easier to use. Points remain in use to this day, but are less popular than when they were introduced.\n\nAlthough FidoNet supported file attachments from even the earliest standards, this feature tended to be rarely used and was often turned off. File attachments followed the normal mail routing through multiple systems, and could back up transfers all along the line as the files were copied. A solution was offered in the form of \"file requests\", which made file transfers driven by the \"calling\" system and used one-time point-to-point connections instead of the traditional routing. Two such standards became common, \"WaZOO\" and \"Bark\", which saw varying support among different mailers. Both worked in a similar fashion, with the mailer calling the remote system and sending a new handshake packet to request the files.\n\nAlthough FidoNet was, by far, the best known BBS-based network, it was by no means the only one. From 1988 on, PCBoard systems were able to host similar functionality known as RelayNet, while other popular networks included RBBSNet from the Commodore 64 world, and AlterNet. Late in the evolution of the FidoNet system, there was a proposal to allow mail (but not forum messages) from these systems to switch into the FidoNet structure. This was not adopted, and the rapid rise of the internet made this superfluous as these networks rapidly added internet exchange, which acted as a lingua franca.\n\nFidoNet started in 1984 and listed 100 nodes by the end of that year. Steady growth continued through the 1980s, but a combination of factors led to rapid growth after 1988. These included faster and less expensive modems, and rapidly declining costs of hard drives and computer systems in general. By April 1993 the FidoNet nodelist contained over 20,000 systems. At that time it was estimated that each node had, on average, about 200 active users. Of these 4 million users in total, 2 million users commonly used echomail, the shared public forums, while about 200,000 used the private netmail system. At its peak, FidoNet listed approximately 39,000 systems.\n\nThroughout its lifetime, FidoNet was beset with management problems and infighting. Much of this can be traced to the fact that the inter-net delivery cost real money, and the traffic grew more rapidly than decreases caused by improving modem speeds and downward trending long distance rates. As they increased, various methods of recouping the costs were attempted, all of which caused friction in the groups. The problems were so bad that Jennings came to refer to the system as the \"fight-o-net\".\n\nAs modems reached speeds of 28.8 kbit/s, the overhead of the TCP/IP protocols were no longer so egregious and dial-up Internet became increasingly common. By 1995 the bulletin board market was reeling as users abandoned local BBS systems in favour of larger sites and web pages, which could be accessed worldwide for the same cost as accessing a local BBS system. This also made FidoNet less expensive to implement, because inter-net transfers could be delivered over the Internet as well, at little or no marginal cost. But this seriously diluted the entire purpose of the store-and-forward model, which had been built up specifically to address a long-distance problem that no longer existed.\n\nThe FidoNet nodelist started shrinking, especially in areas with widespread availability of internet connections. This downward trend continues, but has levelled out at approximately 2,500 nodes. FidoNet remains popular in areas where Internet access is difficult to come by, or expensive.\n\nThere is now (~2014) a retro movement which is resulting in a slow increase in internet connected BBS and nodes. Telnet, Rlogin, and SSH are being used between systems. This means you can telnet to many BBS worldwide as cheaply as ones next door. Also Usenet and internet mail has been added, along with long file names to many newer versions of BBS software, some being free-ware, resulting in increasing use. The deaf and blind are also able to access this better than the internet as a whole as interfaces for them deal mostly with ASCII text which exists in most BBS. They find it helps them communicate without the complications of pictures and audio in their internet mail and communication in general. Nodelists are no longer declining in all cases.\n\nFidoNet is governed in a hierarchical structure according to FidoNet policy, with designated coordinators at each level to manage the administration of FidoNet nodes and resolve disputes between members. Network coordinators are responsible for managing the individual nodes within their area, usually a city or similar sized area. Regional coordinators are responsible for managing the administration of the network coordinators within their region, typically the size of a state, or small country. Zone coordinators are responsible for managing the administration of all of the regions within their zone. The world is divided into six zones, the coordinators of which elect one of themselves to be the \"International Coordinator\" of FidoNet.\n\nFidoNet was historically designed to use modem-based dial-up (POTS) access between bulletin board systems, and much of its policy and structure reflected this.\n\nThe FidoNet system officially referred only to transfer of \"Netmail\"—the individual private messages between people using bulletin boards—including the protocols and standards with which to support it. A netmail message would contain the name of the person sending, the name of the intended recipient, and the respective FidoNet addresses of each. The FidoNet system was responsible for routing the message from one system to the other (details below), with the bulletin board software on each end being responsible for ensuring that only the intended recipient could read it. Due to the hobbyist nature of the network, any privacy between sender and recipient was only the result of politeness from the owners of the FidoNet systems involved in the mail's transfer. It was common, however, for system operators to reserve the right to review the content of mail that passed through their system.\n\nNetmail allowed for the \"attachment\" of a single file to every message. This led to a series of \"piggyback\" protocols that built additional features onto FidoNet by passing information back and forth as file attachments. These included the automated distribution of files, and transmission of data for inter-BBS games.\n\nBy far the most commonly used of these piggyback protocols was \"Echomail\", public discussions similar to Usenet newsgroups in nature. Echomail was supported by a variety of software that collected up new messages from the local BBSes' public forums (the \"scanner\"), compressed it using ARC or ZIP, attached the resulting archive to a Netmail message, and sent that message to a selected system. On receiving such a message, identified because it was addressed to a particular \"user\", the reverse process was used to extract the messages, and a \"tosser\" put them back into the new system's forums.\n\nEchomail was so popular that for many users, Echomail \"was\" the FidoNet. Private person-to-person Netmail was relatively rare.\n\nFidoNet is politically organized into a tree structure, with different parts of the tree electing their respective coordinators. The FidoNet hierarchy consists of \"zones\", \"regions\", \"networks\", \"nodes\" and \"points\" broken down more-or-less geographically.\n\nThe highest level is the zone, which is largely continent-based:\n\nEach zone is broken down into regions, which are broken down into nets, which consist of individual nodes. Zones 7-4095 are used for \"othernets\"; groupings of nodes which use Fido-compatible software to carry their own independent message areas without being in any way controlled by FidoNet's political structure. Using un-used zone numbers would ensure that each network would have a unique set of addresses, avoiding potential routing conflicts and ambiguities for systems that belonged to more than one network.\n\nFidoNet addresses explicitly consist of a \"zone\" number, a \"network\" number (or region number), and a \"node\" number. They are written in the form Zone:Network/Node. The FidoNet structure also allows for semantic designation of region, host, and hub status for particular nodes, but this status is not directly indicated by the main address.\n\nFor example, consider a node located in Tulsa, Oklahoma, United States with an assigned node number is 918, located in Zone 1 (North America), Region 19, and Network 170. The full FidoNet address for this system would be 1:170/918. The \"region\" was used for administrative purposes, and was only part of the address if the node was listed directly underneath the Regional Coordinator, rather than one of the networks that were used to divide the region further.\n\nFidoNet policy requires that each FidoNet system maintain a \"nodelist\" of every other member system. Information on each node includes the name of the system or BBS, the name of the node operator, the geographic location, the telephone number, and software capabilities. The nodelist is updated weekly, to avoid unwanted calls to nodes that had shut down, with their phone numbers possibly having been reassigned for voice use by the respective telephone company.\n\nTo accomplish regular updates, coordinators of each network maintain the list of systems in their local areas. The lists are forwarded back to the International Coordinator via automated systems on a regular basis. The International Coordinator would then compile a new nodelist, and generate the list of changes (nodediff) to be distributed for node operators to apply to their existing nodelist.\n\nIn a theoretical situation, a node would normally forward messages to a \"hub\". The hub, acting as a distribution point for mail, might then send the message to the Net Coordinator. From there it may be sent through a Regional Coordinator, or to some other system specifically set up for the function. Mail to other zones might be sent through a Zone Gate.\n\nFor example, a FidoNet message might follow the path:\n\nOriginally there was no specific relationship between network numbers and the regions they reside in. In some areas of FidoNet, most notably in Zone 2, the relationship between region number and network number are entwined. For example, 2:201/329 is in Net 201 which is in Region 20 while 2:2410/330 is in Net 2410 which is in Region 24. Zone 2 also relates the node number to the hub number if the network is large enough to contain any hubs. This effect may be seen in the nodelist by looking at the structure of Net 2410 where node 2:2410/330 is listed under Hub 300. This is not the case in other zones.\n\nIn Zone 1, things are much different. Zone 1 was the starting point and when Zones and Regions were formed, the existing nets were divided up regionally with no set formula. The only consideration taken was where they were located geographically in respect to the region's mapped outline. As net numbers got added, the following formula was used.\nRegion number × 20\n\nThen when some regions started running out of network numbers, the following was also used.\n\nRegion number × 200\n\nRegion 19, for instance, contains nets 380-399 and 3800-3999 in addition to those that were in Region 19 when it was formed.\n\nPart of the objective behind the formation of local nets was to implement cost reduction plans by which all messages would be sent to one or more hubs or hosts in compressed form (ARC was nominally standard, but PKZIP is universally supported); one toll call could then be made during off-peak hours to exchange entire message-filled archives with an out-of-town uplink for further redistribution.\n\nIn practice, the FidoNet structure allows for any node to connect directly to any other, and node operators would sometimes form their own toll-calling arrangements on an ad-hoc basis, allowing for a balance between collective cost saving and timely delivery. For instance, if one node operator in a network offered to make regular toll calls to a particular system elsewhere, other operators might arrange to forward all of their mail destined for the remote system, and those near it, to the local volunteer. Operators within individual networks would sometimes have cost-sharing arrangements, but it was also common for people to volunteer to pay for regular toll calls either out of generosity, or to build their status in the community.\n\nThis ad-hoc system was particularly popular with networks that were built on top of FidoNet. Echomail, for instance, often involved relatively large file transfers due to its popularity. If official FidoNet distributors refused to transfer Echomail due to additional toll charges, other node operators would sometimes volunteer. In such cases, Echomail messages would be routed to the volunteers' systems instead.\n\nThe FidoNet system was best adapted to an environment in which local telephone service was inexpensive and long-distance calls (or intercity data transfer via packet-switched networks) costly. Therefore, it fared somewhat poorly in Japan, where even local lines are expensive, or in France, where tolls on local calls and competition with Minitel or other data networks limited its growth.\n\nAs the number of messages in Echomail grew over time, it became very difficult for users to keep up with the volume while logged into their local BBS. \"Points\" were introduced to address this, allowing technically savvy users to receive the already compressed and batched Echomail (and Netmail) and read it locally on their own machines. \n\nTo do this, the FidoNet addressing scheme was extended with the addition of a final address segment, the point number. For instance, a user on the example system above might be given point number 10, and thus could be sent mail at the address 1:170/918.10.\n\nIn real-world use, points are fairly difficult to set up. The FidoNet software typically consisted of a number of small utility programs run by manually edited scripts that required some level of technical ability. Reading and editing the mail required either a \"sysop editor\" program, or a BBS program to be run locally.\n\nIn North America (Zone 1), where local calls are generally free, the benefits of the system were offset by its complexity. Points were used only briefly, and even then only to a limited degree. Dedicated offline mail reader programs such as Blue Wave, Squiggy and Silver Xpress (OPX) were introduced in the mid-1990s, and quickly rendered the point system obsolete. Many of these packages supported the QWK offline mail standard.\n\nIn other parts of the world, especially Europe, this was different. In Europe, even local calls are generally metered, so there was a strong incentive to keep the duration of the calls as short as possible. Point software employs standard compression (ZIP, ARJ, etc.) and so keeps the calls down to a few minutes a day at most. In contrast to North America, pointing saw rapid and fairly widespread uptake in Europe.\n\nMany regions distribute a pointlist in parallel with the nodelist. The pointlist segments are maintained by Net- and Region Pointlist Keepers and the Zone Point List Keeper assembles them into the Zone pointlist. At the peak of FidoNet there were over 120,000 points listed in the Zone 2 pointlist. Listing points is on a voluntary basis and not every point is listed, so how many points there really were is anybody's guess. As of June 2006, there are still some 50,000 listed points. Most of them are in Russia and Ukraine.\n\nFidoNet contained several technical specifications for compatibility between systems. The most basic of all is \"FTS-0001\", with which all FidoNet systems are required to comply as a minimal requirement. FTS-0001 defined:\n\nOther specifications that were commonly used provided for \"echomail\", different transfer protocols and handshake methods (\"e.g.: Yoohoo/Yoohoo2u2, EMSI\"), file compression, nodelist format, transfer over reliable connections such as the Internet (Binkp), and other aspects.\n\nSince computer bulletin boards historically used the same telephone lines for transferring mail as were used for dial-in human users of the BBS, FidoNet policy dictates that at least one designated line of each FidoNet node must be available for accepting mail from other FidoNet nodes during a particular hour of each day.\n\n\"Zone Mail Hour\", as it was named, varies depending on the geographic location of the node, and was designated to occur during the early morning. The exact hour varies depending on the time zone, and any node with only one telephone line is required to reject human callers. In practice, particularly in later times, most FidoNet systems tend to accept mail at any time of day when the phone line is not busy, usually during night.\n\nMost FidoNet deployments were designed in a modular fashion. A typical deployment would involve several applications that would communicate through shared files and directories, and switch between each other through carefully designed scripts or batch files. However, monolithic software that encompassed all required functions in one package is available, such as D'Bridge. Such software eliminated the need for custom batch files and is tightly integrated in operation. The preference of deployment was that of the operator and there were both pros and cons of running in either fashion.\n\nArguably the most important piece of software on a DOS-based Fido system was the \"FOSSIL driver\", which was a small device driver which provided a standard way for the Fido software to talk to the modem. This driver needed to be loaded before any Fido software would work. An efficient FOSSIL driver meant faster, more reliable connections.\n\n\"Mailer software\" was responsible for transferring files and messages between systems, as well as passing control to other applications, such as the BBS software, at appropriate times. The mailer would initially answer the phone and, if necessary, deal with incoming mail via FidoNet transfer protocols. If the mailer answered the phone and a human caller was detected rather than other mailer software, the mailer would exit, and pass control to the BBS software, which would then initialise for interaction with the user. When outgoing mail was waiting on the local system, the mailer software would attempt to send it from time to time by dialing and connecting to other systems who would accept and route the mail further. Due to the costs of toll calls which often varied between peak and off-peak times, mailer software would usually allow its operator to configure the optimal times in which to attempt to send mail to other systems.\n\n\"BBS software\" was used to interact with human callers to the system. BBS software would allow dial-in users to use the system's message bases and write mail to others, locally or on other BBSes. Mail directed to other BBSes would later be routed and sent by the mailer, usually after the user had finished using the system. Many BBSes also allowed users to exchange files, play games, and interact with other users in a variety of ways (i.e.: node to node chat).\n\nA \"scanner/tosser\" application, such as FastEcho, FMail, TosScan and Squish, would normally be invoked when a BBS user had entered a new FidoNet message that needed to be sent, or when a mailer had received new mail to be imported into the local messages bases. This application would be responsible for handling the packaging of incoming and outgoing mail, moving it between the local system's message bases and the mailer's inbound and outbound directories. The scanner/tosser application would generally be responsible for basic routing information, determining which systems to forward mail to.\n\nIn later times, \"message readers\" or \"editors\" that were independent of BBS software were also developed. Often the System Operator of a particular BBS would use a devoted message reader, rather than the BBS software itself, to read and write FidoNet and related messages. One of the most popular editors in 2008 was GoldED+. In some cases FidoNet nodes, or more often FidoNet points, had no public bulletin board attached, and existed only for the transfer of mail for the benefit of the node's operator. Most nodes in 2009 had no BBS access, but only points, if anything.\n\nThe original \"Fido BBS\" software, and some other FidoNet-supporting software from the 1980s, is no longer functional on modern systems. This is for several reasons, including problems related to the Y2K bug. In some cases, the original authors have left the BBS or shareware community, and the software, much of which was closed source, has been rendered abandonware.\n\nSeveral DOS based legacy FidoNet Mailers such as FrontDoor, Intermail, MainDoor and D'Bridge from the early 1990s can still be run today under Windows without a modem, by using the freeware NetFoss Telnet FOSSIL driver, and by using a Virtual Modem such as NetSerial. This allows the mailer to \"dial\" an IP address or hostname via Telnet, rather than dialing a real POTS phone number. There are similar solutions for Linux such as MODEMU (modem emulator) which has limited success when combined with DOSEMU (DOS emulator).\nMail Tossers such as FastEcho and FMail are still used today under both Windows and Linux/DOSEMU.\nThere are several modern Windows based FidoNet Mailers available today with source code, including Argus, Radius, and Taurus. MainDoor is another Windows based Fidonet mailer, which also can be run using either a modem or directly over TCP/IP. Two popular free and open source software FidoNet mailers for Unix-like systems are the binkd (cross-platform, IP-only, uses the binkp protocol) and qico (supports modem communication as well as the IP protocol of ifcico and binkp).\n\nOn the \"hardware\" side, Fido systems were usually well-equipped machines, for their day, with quick CPUs, high-speed modems and 16550 UARTs, which were at the time an upgrade. As a Fidonet system was usually a BBS, it needed to quickly process any new mail events before returning to its 'waiting for call' state. In addition, the BBS itself usually necessitated lots of storage space. Finally, a FidoNet system usually had at least one dedicated phoneline. Consequently, operating a Fidonet system often required significant financial investment, a cost usually met by the owner of the system.\n\nWhile the use of FidoNet has dropped dramatically compared with its use up to the mid-1990s, it is still used in many countries and especially Russia and former republics of the USSR. Some BBSes, including those that are now available for users with Internet connections via telnet, also retain their FidoNet netmail and echomail feeds.\n\nSome of FidoNet's echomail conferences are available via gateways with the Usenet news hierarchy using software like UFGate. There are also mail gates for exchanging messages between Internet and FidoNet. Widespread net abuse and e-mail spam on the Internet side has caused some gateways (such as the former 1:1/31 IEEE fidonet.org gateway) to become unusable or cease operation entirely.\n\n\"FidoNews\" is the newsletter of the FidoNet community. Affectionately nicknamed \"The Snooze\", it is published weekly. It was first published in 1984. Throughout its history, it has been published by various people and entities, including the short-lived International FidoNet Association.\n\n\n"}
{"id": "11444", "url": "https://en.wikipedia.org/wiki?curid=11444", "title": "Falsification", "text": "Falsification\n\nFalsification may refer to:\n"}
{"id": "11445", "url": "https://en.wikipedia.org/wiki?curid=11445", "title": "Fatherland", "text": "Fatherland\n\nFatherland is the nation of one's \"fathers\", \"forefathers\" or \"ancestors\". It can be viewed as a nationalist concept, insofar as it is evocative of emotions related to family ties and links them to national identity and patriotism, but in the English language it can also simply mean the country of one's birth or origin. It can be compared to motherland and homeland, and some languages will use more than one of these terms. The national anthem of the Netherlands between 1815 and 1932, \"Wien Neêrlands Bloed\", makes extensive use of the parallel Dutch word.\n\nThe Ancient Greek \"patris\", fatherland, led to \"patrios\", \"of our fathers\" and thence to the Latin \"patriota\" and Old French \"patriote\", meaning compatriot; from these the English word patriotism is derived. The related Ancient Roman word \"Patria\" led to similar forms in modern Romance languages.\n\n\"Fatherland\" was first encountered by the vast majority of citizens in countries that did not themselves use it during World War II, when it was featured in news reports associated with Nazi Germany. German government propaganda used its appeal to nationalism when making references to Germany and the state. It was used in \"Mein Kampf\", and on a sign in a German concentration camp, also signed, Adolf Hitler. As such, the word \"Vaterland\" could be connected with National Socialism outside Germany; in Germany, this is not the case.\n\nGroups with languages that refer to their native country as a \"fatherland\" include:\n\n\n\n\n"}
{"id": "11447", "url": "https://en.wikipedia.org/wiki?curid=11447", "title": "Flag of the United States", "text": "Flag of the United States\n\nThe flag of the United States of America, often referred to as the American flag, is the national flag of the United States. It consists of thirteen equal horizontal stripes of red (top and bottom) alternating with white, with a blue rectangle in the canton (referred to specifically as the \"union\") bearing fifty small, white, five-pointed stars arranged in nine offset horizontal rows, where rows of six stars (top and bottom) alternate with rows of five stars. The 50 stars on the flag represent the 50 states of the United States of America, and the 13 stripes represent the thirteen British colonies that declared independence from the Kingdom of Great Britain, and became the first states in the U.S. Nicknames for the flag include The Stars and Stripes, Old Glory, and The Star-Spangled Banner.\n\nThe current design of the U.S. flag is its 27th; the design of the flag has been modified officially 26 times since 1777. The 48-star flag was in effect for 47 years until the 49-star version became official on July 4, 1959. The 50-star flag was ordered by the then president Eisenhower on August 21, 1959, and was adopted in July 1960. It is the longest-used version of the U.S. flag and has been in use for over years.\n\nAt the time of the Declaration of Independence in July 1776, the Continental Congress would not legally adopt flags with \"stars, white in a blue field\" for another year. The flag contemporaneously known as \"the Continental Colors\" has historically been referred to as the first national flag.\n\nThe Continental Navy raised the Colors as the ensign of the fledgling nation in the American War for Independence—likely with the expedient of transforming their previous British red ensigns by adding white stripes—and would use this flag until 1777, when it would form the basis for the subsequent \"de jure\" designs.\n\nThe name \"Grand Union\" was first applied to the Continental Colors by George Preble in his 1872 history of the American flag.\n\nThe flag closely resembles the British East India Company flag of the era, and Sir Charles Fawcett argued in 1937 that the company flag inspired the design. Both flags could have been easily constructed by adding white stripes to a British Red Ensign, one of the three maritime flags used throughout the British Empire at the time. However, an East India Company flag could have from nine to 13 stripes, and was not allowed to be flown outside the Indian Ocean.\n\nIn any case, both the stripes (barry) and the stars (mullets) have precedents in classical heraldry. Mullets were comparatively rare in early modern heraldry, but an example of mullets representing territorial divisions predating the U.S. flag are those in the coat of arms of Valais of 1618, where seven mullets stood for seven districts.\n\nOn June 14, 1777, the Second Continental Congress passed the Flag Resolution which stated: \"\"Resolved\", That the flag of the thirteen United States be thirteen stripes, alternate red and white; that the union be thirteen stars, white in a blue field, representing a new constellation.\" Flag Day is now observed on June 14 of each year. While scholars still argue about this, tradition holds that the new flag was first hoisted in June 1777 by the Continental Army at the Middlebrook encampment.\n\nThe first official U.S. flag flown during battle was on August 3, 1777, at Fort Schuyler (Fort Stanwix) during the Siege of Fort Stanwix. Massachusetts reinforcements brought news of the adoption by Congress of the official flag to Fort Schuyler. Soldiers cut up their shirts to make the white stripes; scarlet material to form the red was secured from red flannel petticoats of officers' wives, while material for the blue union was secured from Capt. Abraham Swartwout's blue cloth coat. A voucher is extant that Capt. Swartwout of Dutchess County was paid by Congress for his coat for the flag.\n\nThe 1777 resolution was most probably meant to define a naval ensign. In the late 18th century, the notion of a national flag did not yet exist, or was only nascent. The flag resolution appears between other resolutions from the Marine Committee. On May 10, 1779, Secretary of the Board of War Richard Peters expressed concern \"it is not yet settled what is the Standard of the United States.\" However, the term, \"Standard,\" referred to a national standard for the Army of the United States. Each regiment was to carry the national standard in addition to its regimental standard. The national standard was not a reference to the national or naval flag.\n\nThe Flag Resolution did not specify any particular arrangement, number of points, nor orientation for the stars and the arrangement or whether the flag had to have seven red stripes and six white ones or vice versa. The appearance was up to the maker of the flag. Some flag makers arranged the stars into one big star, in a circle or in rows and some replaced a state's star with its initial. One arrangement features 13 five-pointed stars arranged in a circle, with the stars arranged pointing outwards from the circle (as opposed to up), the so-called Betsy Ross flag. This flag, however, is more likely a flag used for celebrations of anniversaries of the nation's birthday. Experts have dated the earliest known example of this flag to be 1792 in a painting by John Trumbull.\n\nDespite the 1777 resolution, the early years of American independence featured many different flags. Most were individually crafted rather than mass-produced. While there are many examples of 13-star arrangements, some of those flags included blue stripes as well as red and white. Benjamin Franklin and John Adams, in a letter dated October 3, 1778, to Ferdinand I of the Two Sicilies, described the American flag as consisting of \"13 stripes, alternately red, white, and blue, a small square in the upper angle, next the flag staff, is a blue field, with 13 white stars, denoting a new Constellation.\" John Paul Jones used a variety of 13-star flags on his U.S. Navy ships including the well-documented 1779 flags of the Serapis and the Alliance. The Serapis flag had three rows of eight-pointed stars with stripes that were red, white, and blue. The flag for the \"Alliance\", however, had five rows of eight-pointed stars with 13 red and white stripes, and the white stripes were on the outer edges. Both flags were documented by the Dutch government in October 1779, making them two of the earliest known flags of 13 stars.\n\nFrancis Hopkinson of New Jersey, a naval flag designer, and a signer of the Declaration of Independence, designed the 1777 flag while he was the Chairman of the Continental Navy Board's Middle Department, sometime between his appointment to that position in November 1776 and the time that the flag resolution was adopted in June 1777. The Navy Board was under the Continental Marine Committee. Not only did Hopkinson claim that he designed the U.S. flag, but he also claimed that he designed a flag for the U.S. Navy. Hopkinson was the only person to have made such a claim during his own lifetime, when he sent a letter and several bills to Congress for his work. These claims are documented in the Journals of the Continental Congress and George Hasting's biography of Hopkinson. Hopkinson initially wrote a letter to Congress, via the Continental Board of Admiralty, on May 25, 1780. In this letter, he asked for a \"Quarter Cask of the Public Wine\" as payment for designing the U.S. flag, the seal for the Admiralty Board, the seal for the Treasury Board, Continental currency, the Great Seal of the United States, and other devices. However, in three subsequent bills to Congress, Hopkinson asked to be paid in cash, but he did not list his U.S. flag design. Instead, he asked to be paid for designing the \"great Naval Flag of the United States\" in the first bill; the \"Naval Flag of the United States\" in the second bill; and \"the Naval Flag of the States\" in the third, along with the other items. The flag references were generic terms for the naval ensign that Hopkinson had designed, that is, a flag of seven red stripes and six white ones. The predominance of red stripes made the naval flag more visible against the sky on a ship at sea. By contrast, Hopkinson's flag for the United States had seven white stripes, and six red ones – in reality, six red stripes laid on a white background. Hopkinson's sketches have not been found, but we can make these conclusions because Hopkinson incorporated different stripe arrangements in the Admiralty (naval) Seal that he designed in the Spring of 1780 and the Great Seal of the United States that he proposed at the same time. His Admiralty Seal had seven red stripes; whereas, his second U.S. Seal proposal had seven white ones. Hopkinson's flag for the Navy is the one that the Nation preferred as the national flag. Remnants of Hopkinson's U.S. flag of seven white stripes can be found in the Great Seal of the United States and the President's seal. When Hopkinson was chairman of the Navy Board, his position was like that of today's Secretary of the Navy. The payment was not made, however, because it was determined he had already received a salary as a member of Congress. This contradicts the legend of the Betsy Ross flag, which suggests that she sewed the first Stars and Stripes flag by request of the government in the Spring of 1776. Furthermore, a letter from the War Board to George Washington on May 10, 1779, documents that there was still no design established for a national flag for the Army's use in battle.\n\nThe origin of the stars and stripes design has been muddled by a story disseminated by the descendants of Betsy Ross. The apocryphal story credits Betsy Ross for sewing the first flag from a pencil sketch handed to her by George Washington. No evidence for this exists either in the diaries of George Washington nor in the records of the Continental Congress. Indeed, nearly a century passed before Ross' grandson, William Canby, first publicly suggested the story in 1870. By her family's own admission, Ross ran an upholstery business, and she had never made a flag as of the supposed visit in June 1776. Furthermore, her grandson admitted that his own search through the Journals of Congress and other official records failed to find corroboration of his grandmother's story.\n\nThe family of Rebecca Young claimed that she sewed the first flag. Young's daughter was Mary Pickersgill, who made the Star Spangled Banner Flag. According to rumor, the Washington family coat of arms, shown in a 15th-century window of Selby Abbey, was the origin of the stars and stripes.\n\nIn 1795, the number of stars and stripes was increased from 13 to 15 (to reflect the entry of Vermont and Kentucky as states of the Union). For a time the flag was not changed when subsequent states were admitted, probably because it was thought that this would cause too much clutter. It was the 15-star, 15-stripe flag that inspired Francis Scott Key to write \"Defence of Fort M'Henry\", later known as \"The Star Spangled Banner\", which is now the American national anthem. The flag is currently on display in the exhibition, \"The Star-Spangled Banner: The Flag That Inspired the National Anthem\" at the Smithsonian Institution National Museum of American History in a two-story display chamber that protects the flag while it is on view.\n\nOn April 4, 1818, a plan was passed by Congress at the suggestion of U.S. Naval Captain Samuel C. Reid in which the flag was changed to have 20 stars, with a new star to be added when each new state was admitted, but the number of stripes would be reduced to 13 so as to honor the original colonies. The act specified that new flag designs should become official on the first July 4 (Independence Day) following admission of one or more new states. The most recent change, from 49 stars to 50, occurred in 1960 when the present design was chosen, after Hawaii gained statehood in August 1959. Before that, the admission of Alaska in January 1959 prompted the debut of a short-lived 49-star flag.\n\nPrior to the adoption of the 48-star flag in 1912, there was no official arrangement of the stars in the canton, although the U.S. Army and U.S. Navy used standardized designs. Throughout the 19th century there was an abundance of different star patterns, rectangular and circular.\n\nOn July 4, 2007, the 50-star flag became the version of the flag in longest use, surpassing the 48-star flag that was used from 1912 to 1959.\n\nThe U.S. flag was brought to the city of Canton (Guǎngzhōu) in China in 1784 by the merchant ship \"Empress of China\", which carried a cargo of ginseng. There it gained the designation \"Flower Flag\" (). According to a pseudonymous account first published in the \"Boston Courier\" and later retold by author and U.S. naval officer George H. Preble:\n\nIn the above quote, the Chinese words are written phonetically based on spoken Cantonese. The names given were common usage in the nineteenth and early twentieth centuries. Other Asian nations have equivalent terms for America, for example (\"Flower Flag\"). Chinese now refer to the United States as . \"Měi\" is short for \"Měilìjiān\" (, phono-semantic matching of \"American\") and \"guó\" means \"country\", so this name is unrelated to the flag. However, the \"flower flag\" terminology persists in some places today: for example, American Ginseng is called in Chinese, and Citibank, which opened a branch in China in 1902, is known as .\n\nThe U.S. flag took its first trip around the world in 1787–90 on board the \"Columbia\". William Driver, who coined the phrase \"Old Glory\", took the U.S. flag around the world in 1831–32. The flag attracted the notice of Japanese when an oversized version was carried to Yokohama by the steamer \"Great Republic\" as part of a round-the-world journey in 1871.\n\nIn the following table depicting the 28 various designs of the United States flag, the star patterns for the flags are merely the \"usual\" patterns, often associated with the United States Navy. Canton designs, prior to the proclamation of the 48-star flag, had no official arrangement of the stars. Furthermore, the exact \"colors\" of the flag were not standardized until 1934.\n\nIn the November 2012 U.S. election, Puerto Rico voted to become a U.S. state. However, the legitimacy of the result of this election was disputed. On June 11, 2017, another referendum was held, this time with the result that 97% of voters in Puerto Rico voted for statehood. Similarly in November 2016, a statehood referendum was held in the District of Columbia where 86% of voters approved the proposal. If a new U.S. state were to be admitted, it would require a new design on the flag to accommodate the additional star.\n\nThe modern meaning of the flag was forged in December 1860, when Major Robert Anderson moved the U.S. garrison from Fort Moultrie to Fort Sumter in Charleston Harbor. Author Adam Goodheart argues this was the opening move of the American Civil War, and the flag was used throughout northern states to symbolize American nationalism and rejection of secessionism.\n\nThe flag of the United States is one of the nation's most widely recognized symbols. Within the United States, flags are frequently displayed not only on public buildings but on private residences. The flag is a common motif on decals for car windows, and clothing ornaments such as badges and lapel pins. Throughout the world the flag has been used in public discourse to refer to the United States.\n\nThe flag has become a powerful symbol of Americanism, and is proudly flown on many occasions, with giant outdoor flags used by retail outlets to draw customers. Desecration of the flag is considered a public outrage, but remains protected as freedom of speech. Scholars have noted the irony that \"<nowiki>[t]</nowiki>he flag is so revered because it represents the land of the free, and that freedom includes the ability to use or abuse that flag in protest\". In worldwide comparison, Testi noted in 2010 that the United States was not unique in adoring its banner, for the flags of Scandinavian countries are also \"beloved, domesticated, commercialized and sacralized objects\".\n\nThe man credited with designing the current 50 star American flag was Robert G. Heft. He was 17 years old at the time and created the flag design in 1958 as a high school class project while living with his grandparents in Ohio. He received a B− on the project. According to Heft, his history teacher honored their agreement to change his grade to an A after his design was selected.\n\nThe basic design of the current flag is specified by ; outlines the addition of new stars to represent new states. The gives the following values:\n\n\nThese specifications are contained in an executive order which, strictly speaking, governs only flags made for or by the U.S. federal government. In practice, most U.S. national flags available for sale to the public have a different width-to-height ratio; common sizes are or (flag ratio 1.5), or (1.6), or or (1.667). Even flags flown over the U.S. Capitol for sale to the public through Representatives or Senators are provided in these sizes. Flags that are made to the prescribed 1.9 ratio are often referred to as \"G-spec\" (for \"government specification\") flags.\n\nThe exact red, white, and blue colors to be used in the flag are specified with reference to the CAUS Standard Color Reference of America, 10th edition. Specifically, the colors are \"White\", \"Old Glory Red\", and \"Old Glory Blue\". The CIE coordinates for the colors of the 9th edition of the Standard Color Card were formally specified in \"JOSA\" in 1946. These colors form the standard for cloth, and there is no perfect way to convert them to RGB for display on screen or CMYK for printing. The \"relative\" coordinates in the following table were found by scaling the luminous reflectance relative to the flag's \"white\".\n\nAs with the design, the official colors are only officially required for flags produced for the U.S. federal government, and other colors are often used for mass-market flags, printed reproductions, and other products intended to evoke flag colors. The practice of using more saturated colors than the official cloth is not new. As Taylor, Knoche, and Granville wrote in 1950: \"The color of the official wool bunting [of the blue field] is a very dark blue, but printed reproductions of the flag, as well as merchandise supposed to match the flag, present the color as a deep blue much brighter than the official wool.\"\n\nSometimes, Pantone Matching System (PMS) approximations to the flag colors are used. One set was given on the website of the U.S. embassy in London as early as 1998; the website of the U.S. embassy in Stockholm claimed in 2001 that those had been suggested by Pantone, and that the U.S. Government Printing Office preferred a different set. A third red was suggested by a California Military Department document in 2002. In 2001, the Texas legislature specified that the colors of the Texas flag should be \"(1) the same colors used in the United States flag; and (2) defined as numbers 193 (red) and 281 (dark blue) of the Pantone Matching System.\"\n\nWhen Alaska and Hawaii were being considered for statehood in the 1950s, more than 1,500 designs were submitted to President Dwight D. Eisenhower. Although some of them were 49-star versions, the vast majority were 50-star proposals. At least three of these designs were identical to the present design of the 50-star flag. At the time, credit was given by the executive department to the United States Army Institute of Heraldry for the design.\n\nOf these proposals, one created by 17-year-old Robert G. Heft in 1958 as a school project received the most publicity. His mother was a seamstress, but refused to do any of the work for him. He originally received a B– for the project. After discussing the grade with his teacher, it was agreed (somewhat jokingly) that if the flag was accepted by Congress, the grade would be reconsidered. Heft's flag design was chosen and adopted by presidential proclamation after Alaska and before Hawaii was admitted into the Union in 1959. According to Heft, his teacher did keep to their agreement and changed his grade to an A for the project. The 49- and 50-star flags were each flown for the first time at Fort McHenry on Independence Day, in 1959 and 1960 respectively.\n\nTraditionally, the flag may be decorated with golden fringe surrounding the perimeter of the flag as long as it does not deface the flag proper. Ceremonial displays of the flag, such as those in parades or on indoor posts, often use fringe to enhance the appearance of the flag.\n\nThe first recorded use of fringe on a flag dates from 1835, and the Army used it officially in 1895. No specific law governs the legality of fringe, but a 1925 opinion of the attorney general addresses the use of fringe (and the number of stars) \"... is at the discretion of the Commander in Chief of the Army and Navy ...\" as quoted from footnote in previous volumes of Title 4 of the United States Code law books and is a source for claims that such a flag is a military ensign not civilian. However, according to the Army Institute of Heraldry, which has official custody of the flag designs and makes any change ordered, there are no implications of symbolism in the use of fringe. Several federal courts have upheld this conclusion, most recently and forcefully in \"Colorado v. Drew\", a Colorado Court of Appeals judgment that was released in May 2010. Traditionally, the Army and Air Force use a fringed National Color for parade, color guard and indoor display, while the Sea Services (Navy, Marine Corps and Coast Guard) use a fringeless National Color for all occasions.\n\nThe flag is customarily flown year-round at most public buildings, and it is not unusual to find private houses flying full-size () flags. Some private use is year-round, but becomes widespread on civic holidays like Memorial Day, Veterans Day, Presidents' Day, Flag Day, and on Independence Day. On Memorial Day it is common to place small flags by war memorials and next to the graves of U.S. war veterans. Also on Memorial Day it is common to fly the flag at half staff, until noon, in remembrance of those who lost their lives fighting in U.S. wars.\n\nThe United States Flag Code outlines certain guidelines for the use, display, and disposal of the flag. For example, the flag should never be dipped to any person or thing, unless it is the ensign responding to a salute from a ship of a foreign nation. This tradition may come from the 1908 Summer Olympics in London, where countries were asked to dip their flag to King Edward VII: the American flag bearer did not. Team captain Martin Sheridan is famously quoted as saying \"this flag dips to no earthly king\", though the true provenance of this quotation is unclear.\nThe flag should never be allowed to touch the ground and, if flown at night, must be illuminated. If the edges become tattered through wear, the flag should be repaired or replaced. When a flag is so tattered that it can no longer serve as a symbol of the United States, it should be destroyed in a dignified manner, preferably by burning. The American Legion and other organizations regularly conduct flag retirement ceremonies, often on Flag Day, June 14. (The Boy Scouts of America recommends that modern nylon or polyester flags be recycled instead of burned, due to hazardous gases being produced when such materials are burned.)\n\nThe Flag Code prohibits using the flag \"for any advertising purpose\" and also states that the flag \"should not be embroidered, printed, or otherwise impressed on such articles as cushions, handkerchiefs, napkins, boxes, or anything intended to be discarded after temporary use\". Both of these codes are generally ignored, almost always without comment.\n\nSection 8, entitled Respect For Flag states in part: \"The flag should never be used as wearing apparel, bedding, or drapery\", and \"No part of the flag should ever be used as a costume or athletic uniform\". Section 3 of the Flag Code defines \"the flag\" as anything \"by which the average person seeing the same without deliberation may believe the same to represent the flag of the United States of America\".\n\nAn additional part of Section 8 Respect For Flag, that is frequently violated at sporting events is part (c) \"The flag should never be carried flat or horizontally, but always aloft and free.\"\n\nAlthough the Flag Code is U.S. federal law, there is no penalty for a private citizen or group failing to comply with the Flag Code and it is not widely enforced—indeed, punitive enforcement would conflict with the First Amendment right to freedom of speech. Passage of the proposed Flag Desecration Amendment would overrule legal precedent that has been established.\n\nWhen the flag is affixed to the right side of a vehicle of any kind (e.g.: cars, boats, planes, any physical object that moves), it should be oriented so that the canton is towards the front of the vehicle, as if the flag were streaming backwards from its hoist as the vehicle moves forward. Therefore, U.S. flag decals on the right sides of vehicles may appear to be reversed, with the union to the observer's right instead of left as more commonly seen.\n\nThe flag has been displayed on every U.S. spacecraft designed for manned flight, including Mercury, Gemini, Apollo Command/Service Module, Apollo Lunar Module, and the Space Shuttle. The flag also appeared on the S-IC first stage of the Saturn V launch vehicle used for Apollo. But since Mercury, Gemini, and Apollo were launched and landed vertically and were not capable of horizontal atmospheric flight as the Space Shuttle did on its landing approach, the \"streaming\" convention was not followed and these flags were oriented with the stripes running horizontally, perpendicular to the direction of flight.\n\nOn some U.S. military uniforms, flag patches are worn on the right shoulder, following the vehicle convention with the union toward the front. This rule dates back to the Army's early history, when both mounted cavalry and infantry units would designate a standard bearer, who carried the Colors into battle. As he charged, his forward motion caused the flag to stream back. Since the Stars and Stripes are mounted with the canton closest to the pole, that section stayed to the right, while the stripes flew to the left. Several US military uniforms, such as flight suits worn by members of the United States Air Force and Navy, have the flag patch on the left shoulder.\n\nOther organizations that wear flag patches on their uniforms can have the flag facing in either direction. The congressional charter of the Boy Scouts of America stipulates that the uniforms should not imitate U.S. military uniforms; consequently, the flags are displayed on the right shoulder with the stripes facing front, the reverse of the military style. Law enforcement officers often wear a small flag patch, either on a shoulder, or above a shirt pocket.\n\nEvery U.S. astronaut since the crew of Gemini 4 has worn the flag on the left shoulder of his or her space suit, with the exception of the crew of Apollo 1, whose flags were worn on the right shoulder. In this case, the canton was on the left.\n\nThe flag did not appear on U.S. postal stamp issues until the Battle of White Plains Issue was released in 1926, depicting the flag with a circle of 13 stars. The 48-star flag first appeared on the General Casimir Pulaski issue of 1931, though in a . The first U.S. postage stamp to feature the flag as the sole subject was issued July 4, 1957, Scott catalog number 1094. Since that time the flag has frequently appeared on U.S. stamps.\n\nIn 1907 Eben Appleton, New York stockbroker and grandson of Lieutenant Colonel George Armistead (the commander of Fort McHenry during the 1814 bombardment) loaned the Star Spangled Banner Flag to the Smithsonian Institution, and in 1912 he converted the loan to a gift. Appleton donated the flag with the wish that it would always be on view to the public. In 1994, the National Museum of American History determined that the Star Spangled Banner Flag required further conservation treatment to remain on public display. In 1998 teams of museum conservators, curators, and other specialists helped move the flag from its home in the Museum's Flag Hall into a new conservation laboratory. Following the reopening of the National Museum of American History on November 21, 2008, the flag is now on display in a special exhibition, \"The Star-Spangled Banner: The Flag That Inspired the National Anthem,\" where it rests at a 10 degree angle in dim light for conservation purposes.\n\nBy presidential proclamation, acts of Congress, and custom, U.S. flags are displayed continuously at certain locations.\n\n\n\nThe flag should especially be displayed at full staff on the following days:\n\n\nThe flag is displayed at half-staff (half-mast in naval usage) as a sign of respect or mourning. Nationwide, this action is proclaimed by the president; statewide or territory-wide, the proclamation is made by the governor. In addition, there is no prohibition against municipal governments, private businesses or citizens flying the flag at half-staff as a local sign of respect and mourning. However, many flag enthusiasts feel this type of practice has somewhat diminished the meaning of the original intent of lowering the flag to honor those who held high positions in federal or state offices. President Dwight D. Eisenhower issued the first proclamation on March 1, 1954, standardizing the dates and time periods for flying the flag at half-staff from all federal buildings, grounds, and naval vessels; other congressional resolutions and presidential proclamations ensued. However, they are only guidelines to all other entities: typically followed at state and local government facilities, and encouraged of private businesses and citizens.\n\nTo properly fly the flag at half-staff, one should first briefly hoist it top of the staff, then lower it to the half-staff position, halfway between the top and bottom of the staff. Similarly, when the flag is to be lowered from half-staff, it should be first briefly hoisted to the top of the staff.\n\nFederal statutes provide that the flag should be flown at half-staff on the following dates:\n\n\nNational Korean War Veterans Armistice Day, on July 27, was formerly a day of half-staff observance until the law expired in 2003. In 2009, it became a day of full-staff observance.\n\nThough not part of the official Flag Code, according to military custom, flags should be folded into a triangular shape when not in use. To properly fold the flag:\n\n\nThere is also no specific meaning for each fold of the flag. However, there are scripts read by non-government organizations and also by the Air Force that are used during the flag folding ceremony. These scripts range from historical timelines of the flag to religious themes.\n\nTraditionally, the flag of the United States plays a role in military funerals, and occasionally in funerals of other civil servants (such as law enforcement officers, fire fighters, and U.S. presidents). A burial flag is draped over the deceased's casket as a pall during services. Just prior to the casket being lowered into the ground, the flag is ceremonially folded and presented to the deceased's next of kin as a token of respect.\n\n\n\n\n\n"}
{"id": "11448", "url": "https://en.wikipedia.org/wiki?curid=11448", "title": "Federated States of Micronesia", "text": "Federated States of Micronesia\n\nThe Federated States of Micronesia (; abbreviated FSM and also known simply as Micronesia) is an independent sovereign island nation and a United States associated state consisting of four states from west to east, Yap, Chuuk, Pohnpei and Kosraethat are spread across the Western Pacific Ocean. Together, the states comprise around 607 islands (a combined land area of approximately ) that cover a longitudinal distance of almost just north of the equator. They lie northeast of New Guinea, south of Guam and the Marianas, west of Nauru and the Marshall Islands, east of Palau and the Philippines, about north of eastern Australia and some southwest of the main islands of Hawaii.\n\nWhile the FSM's total land area is quite small, it occupies more than of the Pacific Ocean, giving the country the 14th largest Exclusive Economic Zone in the world. The capital is Palikir, located on Pohnpei Island, while the largest city is Weno, located in the Chuuk Atoll.\n\nEach of its four states is centered on one or more main high islands, and all but Kosrae include numerous outlying atolls. The Federated States of Micronesia is spread across part of the Caroline Islands in the wider region of Micronesia, which consists of thousands of small islands divided among several countries. The term \"Micronesia\" may refer to the Federated States or to the region as a whole.\n\nThe FSM was formerly a part of the Trust Territory of the Pacific Islands (TTPI), a United Nations Trust Territory under U.S. administration, but it formed its own constitutional government on May 10, 1979, becoming a sovereign state after independence was attained on November 3, 1986 under a Compact of Free Association with the United States. Other neighboring island entities, and also former members of the TTPI, formulated their own constitutional governments and became the Republic of the Marshall Islands (RMI) and the Republic of Palau (ROP). The FSM has a seat in the United Nations.\n\nThe ancestors of the Micronesians settled over four thousand years ago. A decentralized chieftain-based system eventually evolved into a more centralized economic and religious culture centered on Yap.\n\nNan Madol, consisting of a series of small artificial islands linked by a network of canals, is often called the Venice of the Pacific. It is located on the eastern periphery of the island of Pohnpei and used to be the ceremonial and political seat of the Saudeleur dynasty that united Pohnpei's estimated 25,000 people from about AD 500 until 1500, when the centralized system collapsed.\n\nEuropean explorers—first the Portuguese in search of the Spice Islands (Indonesia) and then the Spanish—reached the Carolines in the sixteenth century. The Spanish incorporated the archipelago to the Spanish East Indies and in the 19th century established a number of outposts and missions. In 1887, they founded the town of \"Santiago de la Ascension\" in what today is Kolonia on the island of Pohnpei.\n\nFollowing defeat in the Spanish–American War, the Spanish sold the archipelago to Germany in 1899 under the German–Spanish Treaty of 1899. Germany incorporated it into German New Guinea.\n\nDuring World War I, it was captured by Japan. Following the war, the League of Nations awarded a mandate for Japan to administer the islands as part of the South Pacific Mandate.\n\nDuring World War II, a significant portion of the Japanese fleet was based in Truk Lagoon. In February 1944, Operation Hailstone, one of the most important naval battles of the war, took place at Truk, in which many Japanese support vessels and aircraft were destroyed.\n\nFollowing World War II, it was administered by the United States under United Nations auspices in 1947 as part of the Trust Territory of the Pacific Islands pursuant to Security Council Resolution 21.\n\nOn May 10, 1979, four of the Trust Territory districts ratified a new constitution to become the Federated States of Micronesia. Palau, the Marshall Islands, and the Northern Mariana Islands chose not to participate. The FSM signed a Compact of Free Association with the United States, which entered into force on November 3, 1986, marking Micronesia's emergence from trusteeship to independence. Independence was formally concluded under international law in 1990, when the United Nations officially ended the Trusteeship status pursuant to Security Council Resolution 683. The Compact was renewed in 2004.\n\nThe Federated States of Micronesia is governed by the 1979 constitution, which guarantees fundamental human rights and establishes a separation of governmental powers. The unicameral Congress has fourteen members elected by popular vote. Four senators—one from each state—serve four-year terms; the remaining ten senators represent single-member districts based on population, and serve two-year terms. The President and Vice President are elected by Congress from among the four state-based senators to serve four-year terms in the executive branch. Their congressional seats are then filled by special elections.\n\nThe president and vice president are supported by an appointed cabinet. There are no formal political parties.\n\nIn international politics, the Federated States of Micronesia has often voted with the United States with respect to United Nations General Assembly resolutions.\n\nThe FSM is a sovereign, self-governing state in free association with the United States of America, which is wholly responsible for its defense. The Division of Maritime Surveillance operates a paramilitary Maritime Wing and a small Maritime Police Unit. The Compact of Free Association allows FSM citizens to join the U.S. military without having to obtain U.S. permanent residency or citizenship, allows for immigration and employment for Micronesians in the U.S., and establishes economic and technical aid programs.\n\nFSM has foreign relations with 56 countries, including the Holy See. FSM was admitted to the United Nations based on the Security Council's recommendation on August 9, 1991 in Resolution 703 and the General Assembly's approval on September 17, 1991 in Resolution 46/2. The FSM is an active member of the Pacific Islands Forum.\n\nThe four states in the federation are:\nThese states are further divided into municipalities.\n\nThe Federated States of Micronesia consists of 607 islands extending across the archipelago of the Caroline Islands east of the Philippines. The islands have a combined area of .\n\nThe islands are grouped into four states, which are Yap, Chuuk (called Truk until January 1990), Pohnpei (known as \"Ponape\" until November 1984), and Kosrae (formerly Kusaie). These four states are each represented by a white star on the national flag. The capital is Palikir, on Pohnpei.\n\nEconomic activity in the Federated States of Micronesia consists primarily of subsistence farming and fishing. The islands have few mineral deposits worth exploiting, except for high-grade phosphate. Long line fishing of tuna is also viable with foreign vessels from China operated in the 1990s. The potential for a tourist industry exists, but the remoteness of the location and a lack of adequate facilities hinder development. Financial assistance from the U.S. is the primary source of revenue, with the U.S. pledged to spend $1.3 billion in the islands in 1986–2001; the CIA World Factbook lists high dependence on U.S. aid as one of the main concerns of the FSM. Geographical isolation and a poorly developed infrastructure are major impediments to long-term growth.\n\nThe Federated States of Micronesia is served by four international airports.\n\nThe indigenous population of the nation, which is predominantly Micronesian, consists of various ethnolinguistic groups. It has a nearly 100% Pacific Islander and Asian population: Chuukese 48.8%, Pohnpeian 24.2%, Kosraean 6.2%, Yapese 5.2%, Yap outer islands 4.5%, Asian 1.8%, Polynesian 1.5%, other 6.4%, unknown 1.4%. A sizeable minority also have some Japanese ancestry, which is a result of intermarriages between Japanese settlers and Micronesians during the Japanese colonial period.\n\nThere is also a growing expatriate population of Americans, Australians, Europeans, and residents from China and the Philippines since the 1990s. English has become the common language of the government, and for secondary and tertiary education. Outside of the main capital towns of the four FSM states, the local languages are primarily spoken. Population growth remains high at more than 3% annually, offset somewhat by net emigration.\n\nEnglish is the official and common language. Also spoken are Chuukese, Kosraean, Pohnpeian, Yapese, Ulithian, Woleaian, Nukuoro, and Kapingamarangi.\n\nOther languages spoken in the country include Pingelapese, Ngatikese, Satawalese, Puluwatese, Mortlockese, and Mokilese. There are about 3,000 speakers of Kapingamarangi and Ulithian, and under 1,000 speakers of Nukuoro.\n\nMost Micronesians are Christian. Several Protestant denominations, as well as the Roman Catholic Church, are present in every Micronesian state. Most Protestant groups trace their roots to American Congregationalist missionaries. On the island of Kosrae, the population is approximately 7,800; 95 percent are Protestants. On Pohnpei, the population of 35,000 is evenly divided between Protestants and Catholics.\n\nOn Chuuk and Yap, an estimated 60 percent are Catholic and 40 percent are Protestant. Religious groups with small followings include Baptists, Assemblies of God, Salvation Army, Seventh-day Adventists, Jehovah's Witnesses, The Church of Jesus Christ of Latter-day Saints (Mormons), and the Bahá'í Faith. There is a small group of Buddhists on Pohnpei, and a small group of Ahmadiyya Muslims in Kosrae. Attendance at religious services is generally high; churches are well supported by their congregations and play a significant role in civil society.\n\nMost immigrants are Filipino Catholics who have joined local Catholic churches. The Filipino Iglesia ni Cristo also has a church in Pohnpei. In the 1890s, on the island of Pohnpei, intermissionary conflicts and the conversion of clan leaders resulted in religious divisions along clan lines which persist today. More Protestants live on the western side of the island, while more Catholics live on the eastern side. Missionaries of many religious traditions are present and operate freely. The Constitution provides for freedom of religion, and the Government generally respected this right in practice. The US government received no reports of societal abuses or discrimination based on religious belief or practice in 2007.\n\nPohnpei is notable for the prevalence of an extreme form of color blindness called Achromatopsia, and known locally as maskun. Approximately 5% of the atoll's 3000 inhabitants are afflicted.\n\nEach of the four States has its own culture and traditions, but there are also common cultural and economic bonds that are centuries old. Cultural similarities include the importance of the traditional extended family and clan systems and are found on all the islands.\n\nThe island of Yap is notable for its \"stone money\" (Rai stones), large disks usually of calcite, up to in diameter, with a hole in the middle. The islanders, aware of the owner of a piece, do not necessarily move them when ownership changes. There are five major types: \"Mmbul\", \"Gaw\", \"Ray\", \"Yar\", and \"Reng\", the last being only in diameter. Their value is based on both size and history, many of them having been brought from other islands, as far as New Guinea, but most coming in ancient times from Palau. Approximately 6,500 of them are scattered around the island.\n\nThere have been few published literary writers from the Federated States of Micronesia. In 2008, Emelihter Kihleng became the first ever Micronesian to publish a collection of poetry in the English language.\n\n\n\n\n\n\n\n"}
{"id": "11449", "url": "https://en.wikipedia.org/wiki?curid=11449", "title": "Frederick William, Elector of Brandenburg", "text": "Frederick William, Elector of Brandenburg\n\nFrederick William () (16 February 1620 – 29 April 1688) was Elector of Brandenburg and Duke of Prussia – and thus ruler of Brandenburg-Prussia – from 1640 until his death. A member of the House of Hohenzollern, he is popularly known as \"the Great Elector\" (\"\") because of his military and political achievements. Frederick William was a staunch pillar of the Calvinist faith, associated with the rising commercial class. He saw the importance of trade and promoted it vigorously. His shrewd domestic reforms gave Prussia a strong position in the post-Westphalian political order of north-central Europe, setting Prussia up for elevation from duchy to kingdom, achieved under his son and successor.\n\nElector Frederick William was born in Berlin to George William, Elector of Brandenburg, and Elisabeth Charlotte of the Palatinate. His inheritance consisted of the Margraviate of Brandenburg, the Duchy of Cleves, the County of Mark, and the Duchy of Prussia.\n\nDuring the Thirty Years' War, George William strove to maintain, with a minimal army, a delicate balance between the Protestant and Catholic forces fighting throughout the Holy Roman Empire. Out of these unpromising beginnings Frederick William managed to rebuild his war-ravaged territories. In contrast to the religious disputes that disrupted the internal affairs of other European states, Brandenburg-Prussia benefited from the policy of religious tolerance adopted by Frederick William. With the help of French subsidies, he built up an army to defend the country. In the Second Northern War, he was forced to accept Swedish vassalage for the Duchy of Prussia according to the terms of the Treaty of Königsberg (1656), but as the war progressed he succeeded in gaining full sovereignty for the Prussian duchy in the treaties of Labiau, Wehlau, Bromberg and Oliva, leaving the Holy Roman Emperor as his only liege for his imperial holdings.\n\nIn the conflict for Pomerania inheritance, Frederick William had to accept two setbacks, one in the Northern War and one in the Scanian War. Though militarily successful in Swedish Pomerania, he had to bow to France's demands and return his gains to Sweden in the Treaty of Saint-Germain-en-Laye (1679).\n\nFrederick William was a military commander of wide renown, and his standing army would later become the model for the Prussian Army. He is notable for his joint victory with Swedish forces at the Battle of Warsaw (1656), which, according to Hajo Holborn, marked \"the beginning of Prussian military history\", but the Swedes turned on him at the behest of King Louis XIV of France and invaded Brandenburg. After marching 250 kilometres in 15 days back to Brandenburg, he caught the Swedes by surprise and managed to defeat them on the field at the Battle of Fehrbellin, destroying the myth of Swedish military invincibility. He later destroyed another Swedish army that invaded the Duchy of Prussia during the Great Sleigh Drive in 1678. He is noted for his use of broad directives and delegation of decision-making to his commanders, which would later become the basis for the German doctrine of Auftragstaktik, and he is noted for using rapid mobility to defeat his foes.\n\nFrederick William is notable for raising an army of 40,000 soldiers by 1678, through the General War Commissariat presided over by Joachim Friedrich von Blumenthal. He was an advocate of mercantilism, monopolies, subsidies, tariffs, and internal improvements. Following Louis XIV's revocation of the Edict of Nantes, Frederick William encouraged skilled French and Walloon Huguenots to emigrate to Brandenburg-Prussia with the Edict of Potsdam, bolstering the country's technical and industrial base. On Blumenthal's advice he agreed to exempt the nobility from taxes and in return they agreed to dissolve the Estates-General. He also simplified travel in Brandenburg and the Duchy of Prussia by connecting riverways with canals, a system that was expanded by later Prussian architects, such as Georg Steenke; the system is still in use today.\n\nOn 7 December 1646 in The Hague, Frederick William entered into a marriage, proposed by Blumenthal as a partial solution to the Jülich-Berg question, with Luise Henriette of Nassau (1627–1667), daughter of Frederick Henry of Orange-Nassau and Amalia of Solms-Braunfels and his 1st cousin once removed through William the Silent. Their children were as follows:\n\nOn 13 June 1668 in Gröningen, Frederick William married Sophie Dorothea of Holstein-Sonderburg-Glücksburg, daughter of Philip, Duke of Schleswig-Holstein-Sonderburg-Glücksburg and Sophie Hedwig of Saxe-Lauenburg.\nTheir children were the following:\n"}
{"id": "11454", "url": "https://en.wikipedia.org/wiki?curid=11454", "title": "Frederick V", "text": "Frederick V\n\nFrederick V or Friedrich V may refer to: \n\n"}
{"id": "11456", "url": "https://en.wikipedia.org/wiki?curid=11456", "title": "French horn", "text": "French horn\n\nThe French horn (since the 1930s known simply as the \"horn\" in some professional music circles) is a brass instrument made of tubing wrapped into a coil with a flared bell. The double horn in F/B (technically a variety of German horn) is the horn most often used by players in professional orchestras and bands. A musician who plays any kind of horn is generally referred to as a horn player (or less frequently, a hornist).\n\nPitch is controlled through the combination of the following factors: speed of propulsion of air through the instrument (controlled by the player's lungs and thoracic diaphragm); diameter and tension of lip aperture (controlled by the player's lip muscles—the embouchure) in the mouthpiece; plus, in a modern French horn, the operation of valves by the left hand, which route the air into extra sections of tubing. Most horns have lever-operated rotary valves, but some, especially older horns, use piston valves (similar to a trumpet's) and the Vienna horn uses double-piston valves, or pumpenvalves. The backward-facing orientation of the bell relates to the perceived desirability to create a subdued sound, in concert situations, in contrast to the more piercing quality of the trumpet. A horn without valves is known as a natural horn, changing pitch along the natural harmonics of the instrument (similar to a bugle). Pitch may also be controlled by the position of the hand in the bell, in effect reducing the bell's diameter. The pitch of any note can easily be raised or lowered by adjusting the hand position in the bell.\n\nThree valves control the flow of air in the \"single horn\", which is tuned to F or less commonly B. The more common \"double horn\" has a fourth valve, usually operated by the thumb, which routes the air to one set of tubing tuned to F or another tuned to B. Triple horns with five valves are also made, tuned in F, B, and a descant E or F. Also common are \"descant\" doubles, which typically provide B and alto F branches. This configuration provides a high-range horn while avoiding the additional complexity and weight of a triple.\n\nA crucial element in playing the horn deals with the mouthpiece. Most of the time, the mouthpiece is placed in the exact center of the lips, but, because of differences in the formation of the lips and teeth of different players, some tend to play with the mouthpiece slightly off center. Although the exact side-to-side placement of the mouthpiece varies for most horn players, the up-and-down placement of the mouthpiece is generally two-thirds on the upper lip and one-third on the lower lip. When playing higher notes, the majority of players exert a small degree of additional pressure on the lips using the mouthpiece. However, this is undesirable from the perspective of both endurance and tone: excessive mouthpiece pressure makes the horn sound forced and harsh, and decreases player's stamina due to the resulting constricted flow of blood to the lips and lip muscles. It is the goal of all serious brass musicians to develop their technique such that additional mouthpiece pressure is avoided altogether, or at the very least, minimized.\n\nThe name \"French horn\" is found only in English, first coming into use in the late 17th century. At that time, French makers were preeminent in the manufacture of hunting horns, and were credited with creating the now-familiar, circular \"hoop\" shape of the instrument. As a result, these instruments were often called, even in English, by their French names: \"trompe de chasse\" or \"cor de chasse\" (the clear modern distinction between \"trompes\", trumpets, and \"cors\", horns, did not exist at that time). German makers first devised \"crooks\" to make such horns playable in different keys—so musicians came to use \"French\" and \"German\" to distinguish the simple hunting horn from the newer horn with crooks, which in England was also called by the Italian name \"corno cromatico\" (chromatic horn). More recently, \"French horn\" is often used colloquially, though the adjective has normally been avoided when referring to the European orchestral horn, ever since the German horn began replacing the French-style instrument in British orchestras around 1930. The International Horn Society has recommended since 1971 that the instrument be simply called the \"horn\".\n\nThere is also a more specific use of \"French horn\" to describe a particular horn type, differentiated from the German horn and Vienna horn. In this sense, \"French horn\" refers to a narrow-bore instrument () with three Périnet (piston) valves. It retains the narrow bell-throat and mouthpipe crooks of the orchestral hand horn of the late 18th century, and most often has an \"ascending\" third valve. This is a whole-tone valve arranged so that with the valve in the \"up\" position the valve loop is engaged, but when the valve is pressed the loop is cut out, raising the pitch by a whole tone.\n\nThe horn is the third-highest-sounding instrument in the brass family, below the trumpet and the cornet. Horns are mostly tuned in B or F, or a combination of both. In some traditions, novice players use a single horn in F, while others prefer the B horn. The F horn is used more commonly than the B horn, especially in school bands. Compared to the other brass instruments in orchestras and concert bands, it has a very different mouthpiece, but has the widest usable range—approximately four octaves, depending on the ability of the player. Sound is produced by vibrating (\"buzzing\") the player's lips into the mouthpiece of the instrument. Different partials in the harmonic series can be played by adjusting the air pressure and lip tension, while different harmonic series can be accessed by pressing the valves. More lip tension and faster air produces higher notes, less lip tension and slower air produces lower notes. The player can also adjust the pitch of the instrument through the position of their hand in the bell. The right hand, usually cupped at a \"three o-clock\" position in the bell, can lower the pitch, depending on how far into the bell the player puts it, by as much as a semitone in the instrument's midrange. The horn plays in a higher portion of its overtone series compared to most brass instruments. Its conical bore (as opposed to the cylindrical bore of the trumpet or trombone) is largely responsible for its characteristic tone.\n\nToday, music for the horn is typically written in F and sounds a perfect fifth lower than written. The limitations on the range of the instrument are primarily governed by the available valve combinations for the first four octaves of the overtone series and after that by the ability of the player to control the pitch through their air supply and embouchure. The typical written ranges for the horn start at either the F immediately below the bass clef or the C an octave below middle A.\n\nThe standard range starting from a low F is based on the characteristics of the single horn in F. But there is a great deal of music written beyond this range, on the assumption that players are using a double horn in F/B. Its valve combinations allow for the production of every chromatic tone from two octaves on either side of the horn's written middle C (sounding F immediately below the bass clef to F at the top of the treble clef). Although the upper range of the horn repertoire rarely exceeds high C (two octaves above the horn's middle C, sounding F at the top of the treble clef), skilled players can achieve yet higher pitches.\n\nAlso important to note is that many pieces from the Baroque to Romantic periods are written in keys other than F. This practice began in the early days of the horn before valves, when the composer would indicate the key the horn should be in (horn in D, horn in C, etc.) and the part would be notated as if it were in C. For a player with a valveless (i.e. natural) horn that is a help, showing where in the harmonic series a particular note is. A player with a modern instrument must provide the final transposition to the correct pitch. For example, a written C for horn in D must be transposed down a minor third and played as an A on an F horn.\n\nAs the name indicates, humans originally used to blow on the actual horns of animals before starting to emulate them in metal. This original usage survives in the shofar, a ram's horn, which plays an important role in Jewish religious rituals.\n\nEarly metal horns were less complex than modern horns, consisting of brass tubes with a slightly flared opening (the bell) wound around a few times. These early \"hunting\" horns were originally played on a hunt, often while mounted, and the sound they produced was called a recheat. Change of pitch was effected entirely by the lips (the horn not being equipped with valves until the 19th century). Without valves, only the notes within the harmonic series are available.\n\nEarly horns were commonly pitched in B alto, A, A, G, F, E, E, D, C, and B basso. Since the only notes available were those on the harmonic series of one of those pitches, they had no ability to play in different keys. The remedy for this limitation was the use of crooks, i.e., sections of tubing of differing length that, when inserted, altered the length of the instrument, and thus its pitch.\n\nIn the mid-18th century, horn players began to insert the right hand into the bell to change the length of the instrument, adjusting the tuning up to the distance between two adjacent harmonics depending on how much of the opening was covered.\n\nIn 1818 the German makers Heinrich Stölzel and Friedrich Blümel patented the first valved horn, using rotary valves. Piston valves were introduced in France about 1839 by François Périnet. Valves were initially intended to overcome problems associated with changing crooks during a performance. Valves' unreliability, musical taste, and players' distrust, among other reasons, slowed their adoption into mainstream. Many traditional conservatories and players refused to use them at first, claiming that the valveless horn, or \"natural horn\", was a better instrument. Some musicians, specializing in period instruments, still use a natural horn when playing in original performance styles, seeking to recapture the sound and tenor in which an older piece was written.\n\nThe use of valves, however, opened up a great deal more flexibility in playing in different keys; in effect, the horn became an entirely different instrument, fully chromatic for the first time. Valves were originally used primarily as a means to play in different keys without crooks, not for harmonic playing. That is reflected in compositions for horns, which only began to include chromatic passages in the late 19th century. When valves were invented, generally, the French made smaller horns with piston valves and the Germans made larger horns with rotary valves.\n\nIn English, the term \"French horn\" is often used because the word \"horn\" by itself, even in the context of musical instruments, may refer to nearly any wind instrument with a flared exit for the sound. Nevertheless, the International Horn Society has recommended since 1971 that the instrument be simply called the \"horn\", despite the ambiguity of the term.\n\nHorns may be classified in single horn, double horn, compensating double horn, and triple horn as well as the versatility of detachable bells.\nSingle horns use a single set of tubes connected to the valves. This allows for simplicity of use and a much lighter weight. They are usually in the keys of F or B, although many F horns have longer slides to tune them to E, and almost all B horns have a valve to put them in the key of A. The problem with single horns is the inevitable choice between accuracy or tone – while the F horn has the \"typical\" horn sound, above third-space C accuracy is a concern for the majority of players because, by its nature, one plays high in the horn's harmonic series where the overtones are closer together. This led to the development of the B horn, which, although easier to play accurately, has a less desirable sound in the mid and especially the low register where it is not able to play all of the notes. The solution has been the development of the double horn, which combines the two into one horn with a single lead pipe and bell. Both main types of single horns are still used today as student models because they are cheaper and lighter than double horns. In addition, the single B horns are sometimes used in solo and chamber performances and the single F survives orchestrally as the Vienna horn. Additionally, single F alto and B alto descants are used in the performance of some baroque horn concertos and F, B and F alto singles are occasionally used by jazz performers.\n\nDennis Brain's benchmark recordings of the Mozart Horn Concerti were made on a single B instrument by Gebr. Alexander, now on display at the Royal Academy of Music in London.\n\nDespite the introduction of valves, the single F horn proved difficult for use in the highest range, where the partials grew closer and closer, making accuracy a great challenge. An early solution was simply to use a horn of higher pitch—usually B. The use of the F versus the B horn was a hotbed of debate between horn players of the late 19th century, until the German horn maker Ed. Kruspe (namesake of his family's brass instrument firm) produced a prototype of the \"double horn\" in 1897.\n\nThe double horn also combines two instruments into a single frame: the original horn in F, and a second, higher horn keyed in B. By using a fourth valve (usually operated by the thumb), the horn player can quickly switch from the deep, warm tones of the F horn to the higher, brighter tones of the B horn. The two sets of tones are commonly called \"sides\" of the horn. Using the fourth valve not only changes the basic length (and thus the harmonic series and pitch) of the instrument, it also causes the three main valves to use proportionate slide lengths.\n\nIn the USA, the two most common styles (\"wraps\") of double horns are named Kruspe and Geyer/Knopf, after the first instrument makers who developed and standardized them. The Kruspe wrap locates the B change valve above the first valve, near the thumb. The Geyer wrap has the change valve behind the third valve, near the little finger (although the valve's trigger is still played with the thumb). In effect, the air flows in a completely different direction on the other model. Kruspe wrap horns tend to be larger in the bell throat than the Geyer wrap horns. Typically, Kruspe models are constructed from nickel silver (also called German silver, an alloy of copper, nickel and zinc, containing no actual silver) while Geyer horns tend to be of yellow brass. Both models have their own strengths and weaknesses, and while the choice of instrument is very personal, an orchestral horn section is usually found to have either one or the other, owing to the differences in tone color, response, and projection of the two different styles.\n\nIn Europe the most popular horns are arguably those made by Gebr. Alexander, of Mainz (particularly the Alexander 103), and those made by Paxman in London. In Germany and the Benelux countries, the Alex 103 is extremely popular. These horns do not fit strictly into the Kruspe or Knopf camps, but have features of both. Alexander prefers the traditional medium bell size, which they have produced for many years, whereas Paxman do offer their models in a range of bell throat sizes. In the United States, the Conn 8D, a mass-produced instrument based on the Kruspe design, has been extremely popular in many areas (New York, Los Angeles, Cleveland, Philadelphia). Since roughly the early 1990s, however, for reasons ranging from changing tastes to a general dislike of Conn's newer 8Ds, orchestras have been moving away from the popular Conn 8D. Geyer model horns (by Carl Geyer, Karl Hill, Keith Berg, Steve Lewis, Jerry Lechniuk, Dan Rauch, and Ricco-Kuhn) are used in other areas (San Francisco, Chicago, Pittsburgh, Boston, Houston). The CF Schmidt double, with its unique piston change valve, is occasionally found in sections playing Geyer/Knopf model equipment.\n\nThe first design of the double horn did not have a separate set of slides pitched in F. Rather, the main key of the horn was B (the preference of German horn players) and it could be played in F by directing air through the B slides, an F extension, and another set of smaller slides. This \"compensated\" for the longer length of the F slides, producing a horn now called the \"compensating double.\" It was, and still is, widely used by European horn players because of its light weight and ease of playing, especially in the high register.\n\nThis relatively new design was created to afford the player even more security in the high register. It employs not only the F and B horns, but also a third, descant horn. This descant horn is usually pitched an octave above the F horn, though it can be alternatively pitched in E. Some players find the high E to better match the acoustical qualities of the double horn, whereas the high F horn can have a more bugle quality in some cases. However, often players prefer the high F horn because of the more familiar valve fingerings that are identical to the low F side of the triple horn.\n\nThe triple horn is activated through the use of a second thumb valve. The triple horn was met with considerable resistance when it first appeared. Horn players were reluctant to spend far more money for a triple horn than they would for a double horn, and a feeling that using a triple horn to help with the high register was \"cheating\" was rampant among prominent horn players. Also, the horns were much heavier than the average double horn. Players noted that their arms became fatigued much faster. Moreover, the combination of three different horns creates issues with sonority, because the piping shared among all three sides (that is, the lead pipe and bell) are mathematically disproportional to two or all three horn lengths. Horn makers have had to make concessions to \"even out\" the sound between all three, often to the loss of sound quality of each side or entire ranges of the instrument. Advances in horn production are gradually eliminating these drawbacks, and the triple horn is gaining popularity. They are rarely available in anything lower than professional quality. Like double horns, triple horns can come in both full and compensating wraps. Today they are found being played in many professional orchestras, although the substantial cost difference between double and triple horns limits their usage elsewhere.\n\nThe horn, although not large, is awkward in its shape and does not lend itself well to transport where space is shared or limited. To compensate, horn makers can make the bell detachable; this allows for smaller and more manageable horn cases.\n\nThe variety in horn history necessitates consideration of the natural horn, Vienna horn, mellophone, marching horn, and Wagner tuba.\n\nThe natural horn is the ancestor of the modern horn. It is essentially descended from hunting horns, with its pitch controlled by air speed, aperture (opening of the lips through which air passes) and the use of the right hand moving in and out of the bell. Today it is played as a period instrument. The natural horn can only play from a single harmonic series at a time because there is only one length of tubing available to the horn player. A proficient player can indeed alter the pitch by partially muting the bell with the right hand, thus enabling the player to reach some notes that are not part of the instrument's natural harmonic series – of course this technique also affects the quality of the tone. The player has a choice of key by using crooks to change the length of tubing.\n\nThe Vienna horn is a special horn used primarily in Vienna, Austria. Instead of using rotary valves or piston valves, it uses the pumpenvalve (or Vienna valve), which is a double-piston operating inside the valve slides, and usually situated on the opposite side of the corpus from the player's left hand, and operated by a long pushrod. Unlike the modern horn, which has grown considerably larger internally (for a bigger, broader, and louder tone), and considerably heavier (with the addition of valves and tubing in the case of the double horn) the Vienna horn very closely mimics the size and weight of the natural horn, (although the valves do add some weight, they are lighter than rotary valves) even using crooks in the front of the horn, between the mouthpiece and the instrument. Although instead of the full range of keys, Vienna horn players usually use an F crook and it is looked down upon to use others, though switching to an A or B crook for higher pitched music does happen on occasion. Vienna horns are often used with funnel shaped mouthpieces similar to those used on the natural horn, with very little (if any) backbore and a very thin rim. The Viennese horn requires very specialized technique and can be quite challenging to play, even for accomplished players of modern horns. The Vienna horn has a warmer, softer sound than the modern horn. Its pumpenvalves facilitate a continuous transition between notes (glissando); conversely, a more precise operating of the valves is required to avoid notes that sound out of tune.\n\nTwo instruments are called a \"mellophone\". The first is an instrument shaped somewhat like a horn, in that it is formed in a circle. It has piston valves and is played with the right hand on the valves. Manufacturing of this instrument sharply decreased in the middle of the 20th century, and this mellophone (or mellophonium) rarely appears today.\n\nThe second instrument is used in modern brass bands and marching bands, and is more accurately called a \"marching mellophone\" or mellophone. A derivative of the F alto horn, it is keyed in F. It is shaped like a flugelhorn, with piston valves played with the right hand and a forward-pointing bell. These horns are generally considered better marching instruments than regular horns because their position is more stable on the mouth, they project better, and they weigh less. It is primarily used as the middle voice of drum and bugle corps. Though they are usually played with a V-cup cornet-like mouthpiece, their range overlaps the common playing range of the horn. This mouthpiece switch makes the mellophone louder, less mellow, and more brassy and brilliant, making it more appropriate for marching bands. Often now with the use of converters, traditional conical horn mouthpieces are used to achieve the more mellow sound of a horn to make the marching band sound more like a concert band.\n\nAs they are pitched in F or G and their range overlaps that of the horn, mellophones can be used in place of the horn in brass and marching band settings. Mellophones are, however, sometimes unpopular with horn players because the mouthpiece change can be difficult and requires a different embouchure. Mouthpiece adapters are available so that a horn mouthpiece can fit into the mellophone lead pipe, but this does not compensate for the many differences that a horn player must adapt to. The \"feel\" of the mellophone can be foreign to a horn player. Another unfamiliar aspect of the mellophone is that it is designed to be played with the right hand instead of the left (although it can be played with the left). Intonation can also be an issue when playing the mellophone.\n\nWhile horn players may be asked to play the mellophone, it is unlikely that the instrument was ever intended as a substitute for the horn, mainly because of the fundamental differences described. As an instrument it compromises between the ability to sound like a horn, while being used like a trumpet or flugelhorn, a tradeoff that sacrifices acoustic properties for ergonomics.\n\nThe marching horn is quite similar to the mellophone in shape and appearance, but is pitched in the key of B (the same as the B side of a regular double horn). It is also available in F alto (one octave above the F side of a regular double horn). The marching horn is also normally played with a horn mouthpiece (unlike the mellophone, which needs an adapter to fit the horn mouthpiece). These instruments are primarily used in marching bands so that the sound comes from a forward-facing bell, as dissipation of the sound from the backward-facing bell becomes a concern in open-air environments. Many college marching bands and drum corps, however, use mellophones instead, which, with many marching bands, better balance the tone of the other brass instruments; additionally, mellophones require less special training of trumpet players, who considerably outnumber horn players.\n\nThe Wagner tuba is a rare brass instrument that is essentially a horn modified to have a larger bell throat and a vertical bell. Despite its name, it is generally not considered part of the tuba family. Invented for Richard Wagner specifically for his work \"Der Ring des Nibelungen\", it has since been written for by various other composers, including Bruckner, Stravinsky and Richard Strauss. It uses a horn mouthpiece and is available as a single tuba in B or F, or, more recently, as a double tuba similar to the double horn. Its common range is similar to that of the euphonium, but its possible range is the same as that of the horn, extending from low F, below the bass clef staff to high C above the treble staff when read in F. These low pedals are substantially easier to play on the Wagner tuba than on the horn. Wagner viewed the regular horn as a woodwind rather than a brass instrument, evidenced by his placing of the horn parts in his orchestral scores in the woodwind group and not in their usual place above the trumpets in the brass section.\n\nDiscussion of the repertoire of horns must recognize the different needs of orchestras and concert bands in contrast to marching bands, as above, but also the use of horns in a wide variety of music, including chamber music and jazz.\n\nThe horn is most often used as an orchestral and concert band instrument, with its singular tone being employed by composers to achieve specific effects. Leopold Mozart, for example, used horns to signify the hunt, as in his \"Jagdsinfonie\" (hunting symphony). Telemann wrote much for the horn, and it features prominently in the work of Handel and in Bach's \"Brandenburg Concerto no. 1\". Once the technique of hand-stopping had been developed, allowing fully chromatic playing, composers began to write seriously for the horn. Gustav Mahler made great use of the horn's uniquely haunting and distant sound in his symphonies, notably the famous \"Nachtmusik\" (serenade) section of his Symphony No. 7.\n\nMany composers have written works that have become favorites in the horn repertoire. These include Poulenc (\"Elegie\") and Saint-Saëns (\"Morceau de Concert for horn and orchestra\", op. 94 and \"Romance\", op. 36). Others, particularly Wolfgang Amadeus Mozart, whose friend Joseph Leutgeb was a noted horn player, wrote extensively for the instrument, including concerti and other solo works. Mozart's \"A Musical Joke\" satirizes the limitations of contemporary horn playing, including the risk of selecting the wrong crook by mistake.\n\nThe development of the valve horn was exploited by romantic composers such as Bruckner, Mahler, and Richard Strauss, whose father was a well-known professional horn player. Strauss's \"Till Eulenspiegel's Merry Pranks\" contains one of the best known horn solos from this period, relying on the chromatic facility of the valved horn. Schumann's \"Konzertstück\" for four horns and orchestra is a notable three-movement work. Brahms had a lifelong love-affair with the instrument, with many prominently featured parts throughout his four symphonies. However players today typically play Brahms on modern valved instruments.\n\nThere is an abundance of chamber music repertoire for horn. It is a standard member of the wind quintet and brass quintet, and often appears in other configurations, such as Brahms' Horn Trio for violin, horn and piano (for which, however, Brahms specified the natural horn). Also, the horn can be used by itself in a horn ensemble or \"horn choir\". The horn choir is especially practical because the extended range of the horn provides the composer or arranger with more possibilities, registerally, sonically, and contrapuntally.\n\nA classical orchestra usually contained two horns. Typically, the 1st horn played a high part and the 2nd horn played a low part. Composers from Beethoven onwards commonly used four horns. Here, the 1st and 2nd horns played as a pair (1st horn being high, 2nd horn being low), and the 3rd and 4th horns played as another pair (3rd horn being high, 4th horn being low). Music written for the modern horn follows a similar pattern with 1st and 3rd horns being high and 2nd and 4th horns being low.\n\nThis configuration serves multiple purposes. It is easier to play high when the adjacent player is playing low and vice versa. Pairing makes it easier to write for horns, as the 3rd and 4th horns can take over from the 1st and 2nd horns, or play contrasting material. For example, if the piece is in C minor, the 1st and 2nd horns might be in C, the tonic major key, which could get most of the notes, and the 3rd and 4th horns might be in E, the relative major key, to fill in the gaps.\n\nMany orchestral horn sections today also have an assistant who doubles the 1st horn part for selected passages, joining in loud parts, playing instead of the principal if there is a 1st horn solo approaching, or alternating with the principal if the part is tiring to play. Often the assistant is asked to play a passage after resting a long time. Also, he or she may be asked to enter in the middle of a passage, exactly matching the sound, articulation, and overall interpretation of the principal.\n\nThe horn has rarely been used in jazz music; colloquially in jazz, the word \"horn\" refers to any wind instrument. Notable exponents, however, include composer/arranger Gil Evans who included the horn as an ensemble instrument from the 1940s, first in Claude Thornhill's groups, and later with the pioneering cool jazz nonet led by trumpeter Miles Davis, and in many other projects that sometimes also featured Davis, as well as Don Ellis, a trumpet player from Stan Kenton's jazz band. Notable works of Ellis' jazz horn include \"Strawberry Soup\" and other songs on the album Tears of Joy. Notable improvising horn players in jazz include Julius Watkins, Willie Ruff, John Graas, David Amram, John Clark, Vincent Chancey, Mark Taylor, Giovanni Hoffer, Arkady Shilkloper, Adam Unsworth, and Tom Varner.\n\n\nPeople who are more notable for their other achievements, but also play the horn, include actors Ewan McGregor and David Ogden Stiers, comedian and television host Jon Stewart, journalist Chuck Todd, The Who bassist and singer John Entwistle, and rapper and record producer B.o.B.\n\n\n"}
{"id": "11457", "url": "https://en.wikipedia.org/wiki?curid=11457", "title": "Fra Angelico", "text": "Fra Angelico\n\nFra Angelico (born Guido di Pietro; February 18, 1455) was an Early Italian Renaissance painter described by Vasari in his \"Lives of the Artists\" as having \"a rare and perfect talent\".\n\nHe was known to contemporaries as Fra Giovanni da Fiesole (Brother John of Fiesole) and Fra Giovanni Angelico (Angelic Brother John). In modern Italian he is called il Beato Angelico (Blessed Angelic One); the common English name Fra Angelico means the \"Angelic friar\".\n\nIn 1982 Pope John Paul II proclaimed his beatification in recognition of the holiness of his life, thereby making the title of \"Blessed\" official. Fiesole is sometimes misinterpreted as being part of his formal name, but it was merely the name of the town where he took his vows as a Dominican friar, and was used by contemporaries to separate him from others who were also known as Fra Giovanni. He is listed in the Roman Martyrology as \"Beatus Ioannes Faesulanus, cognomento Angelicus\"—\"Blessed Giovanni of Fiesole, surnamed 'the Angelic' \".\n\nVasari wrote of Fra Angelico that \"it is impossible to bestow too much praise on this holy father, who was so humble and modest in all that he did and said and whose pictures were painted with such facility and piety.\"\n\nFra Angelico was born Guido di Pietro at Rupecanina in the Tuscan area of Mugello near Fiesole towards the end of the 14th century. Nothing is known of his parents. He was baptized Guido or Guidolino. The earliest recorded document concerning Fra Angelico dates from October 17, 1417 when he joined a religious confraternity or guild at the Carmine Church, still under the name of Guido di Pietro. This record reveals that he was already a painter, a fact that is subsequently confirmed by two records of payment to Guido di Pietro in January and February 1418 for work done in the church of Santo Stefano del Ponte. The first record of Angelico as a friar dates from 1423, when he is first referred to as Fra Giovanni (Friar John), following the custom of those entering one of the older religious orders of taking a new name. He was a member of the local community at Fiesole, not far from Florence, of the Dominican Order; one of the medieval Orders belonging to a category known as mendicant Orders because they generally lived not from the income of estates but from begging or donations. Fra, a contraction of \"frater\" (Latin for 'brother'), is a conventional title for a mendicant friar.\n\nAccording to Vasari, Fra Angelico initially received training as an illuminator, possibly working with his older brother Benedetto who was also a Dominican and an illuminator. The former Dominican convent of San Marco in Florence, now a state museum, holds several manuscripts that are thought to be entirely or partly by his hand. The painter Lorenzo Monaco may have contributed to his art training, and the influence of the Sienese school is discernible in his work. He had several important charges in the convents he lived in, but this did not limit his art, which very soon became famous. According to Vasari, the first paintings of this artist were an altarpiece and a painted screen for the Charterhouse (Carthusian monastery) of Florence; none such exist there now.\n\nFrom 1408 to 1418, Fra Angelico was at the Dominican friary of Cortona, where he painted frescoes, now mostly destroyed, in the Dominican Church and may have been assistant to Gherardo Starnina or a follower of his. Between 1418 and 1436 he was at the convent of Fiesole, where he also executed a number of frescoes for the church and the Altarpiece, which was deteriorated but has since been restored. A predella of the Altarpiece remains intact and is conserved in the National Gallery, London, and is a great example of Fra Angelico's ability. It shows Christ in Glory surrounded by more than 250 figures, including beatified Dominicans.\n\nIn 1436, Fra Angelico was one of a number of the friars from Fiesole who moved to the newly built convent or friary of San Marco in Florence. This was an important move which put him in the centre of artistic activity of the region and brought about the patronage of one of the wealthiest and most powerful members of the city's governing authority, or \"Signoria\" (namely Cosimo de' Medici), who had a cell reserved for himself at the friary in order that he might retreat from the world. \nIt was, according to Vasari, at Cosimo's urging that Fra Angelico set about the task of decorating the convent, including the magnificent fresco of the Chapter House, the often-reproduced Annunciation at the top of the stairs leading to the cells, the Maesta (or Coronation of the Madonna) with Saints (cell 9) and the many other devotional frescoes, of smaller format but remarkable luminous quality, depicting aspects of the Life of Christ that adorn the walls of each cell.\n\nIn 1439 Fra Angelico completed one of his most famous works, the \"San Marco Altarpiece\" at Florence. The result was unusual for its time. Images of the enthroned Madonna and Child surrounded by saints were common, but they usually depicted a setting that was clearly heaven-like, in which saints and angels hovered about as divine presences rather than people. But in this instance, the saints stand squarely within the space, grouped in a natural way as if they were able to converse about the shared experience of witnessing the Virgin in glory. Paintings such as this, known as Sacred Conversations, were to become the major commissions of Giovanni Bellini, Perugino and Raphael.\n\nIn 1445 Pope Eugene IV summoned him to Rome to paint the frescoes of the Chapel of the Holy Sacrament at St Peter's, later demolished by Pope Paul III. Vasari claims that at this time Fra Angelico was offered the Archbishopric of Florence by Pope Nicholas V, and that he refused it, recommending another friar for the position. The story seems possible and even likely. However, if Vasari's date is correct, then the pope must have been Eugene IV and not Nicholas, who was elected Pope only on 6 March 1447. Moreover, the Archbishop in 1446–1459 was the Dominican Antoninus of Florence (Antonio Pierozzi), canonized by Pope Adrian VI in 1523. In 1447 Fra Angelico was in Orvieto with his pupil, Benozzo Gozzoli, executing works for the Cathedral. Among his other pupils were Zanobi Strozzi.\n\nFrom 1447 to 1449 Fra Angelico was back at the Vatican, designing the frescoes for the Niccoline Chapel for Nicholas V. The scenes from the lives of the two martyred deacons of the Early Christian Church, St. Stephen and St. Lawrence may have been executed wholly or in part by assistants. The small chapel, with its brightly frescoed walls and gold leaf decorations gives the impression of a jewel box. From 1449 until 1452, Fra Angelico returned to his old convent of Fiesole, where he was the Prior.\n\nIn 1455, Fra Angelico died while staying at a Dominican convent in Rome, perhaps on an order to work on Pope Nicholas' chapel. He was buried in the church of Santa Maria sopra Minerva. \nThe English writer and critic William Michael Rossetti wrote of the friar:\nPope John Paul II beatified Fra Angelico on October 3, 1982, and in 1984 declared him patron of Catholic artists.\n\nFra Angelico was working at a time when the style of painting was in a state of change. This process of change had begun a hundred years previous with the works of Giotto and several of his contemporaries, notably Giusto de' Menabuoi, both of whom had created their major works in Padua, although Giotto was trained in Florence by the great Gothic artist, Cimabue, and painted a fresco cycle of St Francis in the Bardi Chapel in the Basilica di Santa Croce. Giotto had many enthusiastic followers, who imitated his style in fresco, some of them, notably the Lorenzetti, achieving great success.\n\nThe patrons of these artists were most often monastic establishments or wealthy families endowing a church. Because the paintings often had devotional purpose, the clients tended to be conservative. Frequently, it would seem, the wealthier the client, the more conservative the painting. There was a very good reason for this. The paintings that were commissioned made a statement about the patron. Thus the more gold leaf it displayed, the more it spoke to the patron's glory. The other valuable commodities in the paint-box were lapis lazuli and vermilion. Paint made from these colours did not lend itself to a tonal treatment. The azure blue made of powdered lapis lazuli went on flat, the depth and brilliance of colour being, like the gold leaf, a sign of the patron's ability to provide well. For these reasons, altarpieces are often much more conservatively painted than frescoes, which were often of almost life-sized figures and relied upon a stage-set quality rather than lavish display in order to achieve effect.\n\nFra Angelico was the contemporary of Gentile da Fabriano. Gentile's altarpiece of the \"Adoration of the Magi\", 1423, in the Uffizi is regarded as one of the greatest works of the style known as International Gothic. At the time it was painted, another young artist, known as Masaccio, was working on the frescoes for the Brancacci Chapel at the church of the Carmine. Masaccio had fully grasped the implications of the art of Giotto. Few painters in Florence saw his sturdy, lifelike and emotional figures and were not affected by them. His work partner was an older painter, Masolino, of the same generation as Fra Angelico. Masaccio died at 27, leaving the work unfinished.\n\nThe works of Fra Angelico reveal elements that are both conservatively Gothic and progressively Renaissance. In the altarpiece of the Coronation of the Virgin, painted for the Florentine church of Santa Maria Novella, are all the elements that a very expensive altarpiece of the 14th century was expected to provide; a precisely tooled gold background, lots of azure, lots of vermilion and an obvious display of arsenic green. The workmanship of the gilded haloes and gold-edged robes is exquisite and all very Gothic. What makes this a Renaissance painting, as against Gentile da Fabriano's masterpiece, is the solidity, the three-dimensionality and naturalism of the figures and the realistic way in which their garments hang or drape around them. Even though it is clouds these figures stand upon, and not the earth, they do so with weight.\n\nThe series of frescoes that Fra Angelico painted for the Dominican friars at San Marcos realise the advancements made by Masaccio and carry them further. Away from the constraints of wealthy clients and the limitations of panel painting, Fra Angelico was able to express his deep reverence for his God and his knowledge and love of humanity. The meditational frescoes in the cells of the convent have a quieting quality about them. They are humble works in simple colours. There is more mauvish-pink than there is red, and the brilliant and expensive blue is almost totally lacking. In its place is dull green and the black and white of Dominican robes. There is nothing lavish, nothing to distract from the spiritual experiences of the humble people who are depicted within the frescoes. Each one has the effect of bringing an incident of the life of Christ into the presence of the viewer. They are like windows into a parallel world. These frescoes remain a powerful witness to the piety of the man who created them.\nVasari relates that Cosimo de' Medici seeing these works, inspired Fra Angelico to create a large Crucifixion scene with many saints for the Chapter House. As with the other frescoes, the wealthy patronage did not influence the Friar's artistic expression with displays of wealth.\n\nMasaccio ventured into perspective with his creation of a realistically painted niche at Santa Maria Novella. Subsequently, Fra Angelico demonstrated an understanding of linear perspective particularly in his Annunciation paintings set inside the sort of arcades that Michelozzo and Brunelleschi created at San’ Marco's and the square in front of it.\n\nWhen Fra Angelico and his assistants went to the Vatican to decorate the chapel of Pope Nicholas, the artist was again confronted with the need to please the very wealthiest of clients. In consequence, walking into the small chapel is like stepping into a jewel box. The walls are decked with the brilliance of colour and gold that one sees in the most lavish creations of the Gothic painter Simone Martini at the Lower Church of St Francis of Assisi, a hundred years earlier. Yet Fra Angelico has succeeded in creating designs which continue to reveal his own preoccupation with humanity, with humility and with piety. The figures, in their lavish gilded robes, have the sweetness and gentleness for which his works are famous. According to Vasari:\nIn their bearing and expression, the saints painted by Fra Angelico come nearer to the truth than the figures done by any other artist.\n\nIt is probable that much of the actual painting was done by his assistants to his design. Both Benozzo Gozzoli and Gentile da Fabriano were highly accomplished painters. Benozzo took his art further towards the fully developed Renaissance style with his expressive and lifelike portraits in his masterpiece of the Journey of the Magi, painted in the Medici's private chapel at their palazzo.\n\nThrough Fra Angelico's pupil Benozzo Gozzoli's careful portraiture and technical expertise in the art of fresco we see a link to Domenico Ghirlandaio, who in turn painted extensive schemes for the wealthy patrons of Florence, and through Ghirlandaio to his pupil Michelangelo and the High Renaissance.\n\nApart from the lineal connection, superficially there may seem little to link the humble priest with his sweetly pretty Madonnas and timeless Crucifixions to the dynamic expressions of Michelangelo's larger-than-life creations. But both these artists received their most important commissions from the wealthiest and most powerful of all patrons, the Vatican.\n\nWhen Michelangelo took up the Sistine Chapel commission, he was working within a space that had already been extensively decorated by other artists. Around the walls the \"Life of Christ\" and \"Life of Moses\" were depicted by a range of artists including his teacher Ghirlandaio, Raphael's teacher Perugino and Botticelli. They were works of large scale and exactly the sort of lavish treatment to be expected in a Vatican commission, vying with each other in complexity of design, number of figures, elaboration of detail and skillful use of gold leaf. Above these works stood a row of painted Popes in brilliant brocades and gold tiaras. None of these splendours have any place in the work which Michelangelo created. Michelangelo, when asked by Pope Julius II to ornament the robes of the Apostles in the usual way, responded that they were very poor men.\n\nWithin the cells of San’Marco, Fra Angelico had demonstrated that painterly skill and the artist's personal interpretation were sufficient to create memorable works of art, without the expensive trappings of blue and gold. In the use of the unadorned fresco technique, the clear bright pastel colours, the careful arrangement of a few significant figures and the skillful use of expression, motion and gesture, Michelangelo showed himself to be the artistic descendant of Fra Angelico. Frederick Hartt describes Fra Angelico as \"prophetic of the mysticism\" of painters such as Rembrandt, El Greco and Zurbarán.\n\nRome\nCortona\nFiesole\nFlorence, Santa Trinita \nFlorence, Santa Maria degli Angeli \nFlorence, Santa Maria Novella \n\n\n\nEach cell is decorated with a fresco which matches in size and shape the single round-headed window beside it. The frescoes are apparently for contemplative purpose. They are have a pale, serene, unearthly beauty. Many of Fra Angelico's finest and most reproduced works are among them. There are, particularly in the inner row of cells, some of less inspiring quality and of more repetitive subject, perhaps completed by assistants. Many pictures include Dominican saints as witnesses, allowing the friar using the cell to place himself in the scene.\n\nOrvieto Cathedral\n\nThree segments of the ceiling in the Cappella Nuova, with the assistance of Benozzo Gozzoli.\n\nNiccoline Chapel\n\nThe Chapel of Pope Nicholas V, at the Vatican, was probably painted with much assistance from Benozzo Gozzoli and Gentile da Fabriano. The entire surface of wall and ceiling is sumptuously painted. There is much gold leaf for borders and decoration, and a great use of brilliant blue made from lapis lazuli.\n\nWorldwide press coverage reported in November 2006 that two missing masterpieces by Fra Angelico had turned up, having hung in the spare room of the late Jean Preston, in her terrace house in Oxford, England. Her father had bought them for £100 each in the 1960s then bequeathed them to her when he died. Preston, an expert medievalist, recognised them as being high quality Florentine renaissance, but did not realize that they were works by Fra Angelico until they were identified in 2005 by Michael Liversidge of Bristol University. There was almost no demand at all for medieval art during the 1960s and no dealers showed any interest, so Preston's father bought them almost as an afterthought along with some manuscripts. Coincidentally the manuscripts turned out to be high quality Victorian forgeries by The Spanish Forger. The paintings are two of eight side panels of a large altarpiece painted in 1439 for Fra Angelico's monastery at San Marco, which was later split up by Napoleon's army. While the centre section is still at the monastery, the other six small panels are in German and US museums. These two panels were presumed lost forever. The Italian Government had hoped to purchase them but they were outbid at auction on 20 April 2007 by a private collector for £1.7M. Both panels are now restored and exhibited in the San Marco Museum in Florence.\n\n\n\n"}
{"id": "11458", "url": "https://en.wikipedia.org/wiki?curid=11458", "title": "Fra Bartolomeo", "text": "Fra Bartolomeo\n\nFra Bartolomeo or Bartolommeo OP (March 28, 1472 – October 31, 1517), also known as Bartolommeo di Pagholo, Bartolommeo di S. Marco, and his original name Baccio della Porta, was an Italian Renaissance painter of religious subjects. He spent all his career in Florence until his mid-forties, when he travelled to work in various cities, as far south as Rome. He trained with Cosimo Roselli and in the 1490s fell under the influence of Savonarola, which led him to become a Dominican friar in 1500, renouncing painting for several years.\n\nHe was instructed to resume painting for the benefit of his order in 1504, and now developed an idealized High Renaissance style, seen in his \"Vision of St Bernard\" of that year, now in poor condition but whose \"figures and drapery move with a seraphic grace that must have struck the young Raphael with the force of revelation\". He remained friends with Raphael, and each influenced the other.\n\nHis portrait of Savonarola remains the most famous image of the reformer. Fra Bartolomeo painted both in oils and fresco, and some of his drawings are pure landscape sketches that are the earliest of this type from Italy.\n\nHe was born in Savignano di Prato, Tuscany. He received the nickname of Baccio della Porta for his house was near the Gate of San Pier Gattolini.\n\nStarting from 1483 or 1484, by recommendation of Benedetto da Maiano, he apprenticed in the workshop of Cosimo Rosselli. He was one of the greatest painters of his time. In 1490 or 1491 he began a collaboration with Mariotto Albertinelli. In the late 1490s Baccio was drawn to the teachings of Fra Girolamo Savonarola, who denounced what he viewed as vain and corrupt contemporary art. Savonarola argued for art serving as a direct visual illustration of the Bible to educate those unable to read the book. From 1498 is his famous portrait of Savonarola, now in the Museo Nazionale di San Marco in Florence. The following year he was commissioned a fresco of the \"Universal Judgement\" for the Ospedale di Santa Maria Nuova, completed by Albertinelli and Giuliano Bugiardini when Baccio became a Dominican friar on July 26, 1500. The following year he entered the convent of San Marco.\n\nHe renounced painting for several years, not resuming until 1504 when he became the head of the monastery workshop in obedience to his superior. In that year he began a \"Vision of St. Bernard\" for Bernardo Bianco's family chapel in the Badia Fiorentina, finished in 1507.\nSoon thereafter, Raphael visited Florence and befriended the friar. Bartolomeo learned perspective from the younger artist, while Raphael added skills in coloring and handling of drapery, which was noticeable in the works he produced after their meeting. With Raphael, he remained on the friendliest terms, and when he departed from Rome, left in his hands two unfinished pictures which Raphael completed.\n\nAt the beginning of 1508 Bartolomeo moved to Venice to paint a \"Holy Father, St. Mary Magdalene and St. Catherine of Siena\" for the Dominicans of San Pietro Martire in Murano, influenced somewhat by Venetian colorism. As the Dominicans did not pay for the work, he took it back to Lucca, where it can be seen now. Also in Lucca, in the October 1509, he painted by Albertinelli an altarpiece with \"Madonna and Child with Saints\" for the local cathedral. On November 26, 1510 Pier Soderini commissioned him an altarpiece for the Sala del Consiglio of Florence, now in the Museum of San Marco. Two years later he finished another altarpiece for the cathedral of Besançon.\n\nIn 1513 he went to Rome, where he painted a \"Peter and Paul\", now in the Pinacoteca Vaticana, while from the following years are the \"St. Mark Evangelist\" of Palazzo Pitti in Florence and the frescoes in the Dominican convent of Pian di Mugnone, a frazione of Fiesole, just outside Florence. After a promised \"Feast of Venus\" for Duke Alfonso I d'Este of Ferrara, of which only drawings remain, his last work is fresco of \"Noli me tangere\" also in Pian di Mugnone.\nHe died in Florence in 1517.\n\nInitially, his works showed the influence of Rosselli's assistant, Piero di Cosimo, and those of Domenico Ghirlandaio and Filippino Lippi. After his hiatus from 1500 to 1503, he seemed to change vision, taking from Raphael the representation of light and its effects over moving shapes.\n\nFra Bartolomeo's figures are generally small and draped. These qualities were alleged against him as defects, and to prove that his style was not the result of want of power, he painted the magnificent figure of the \"St. Mark Evangelist\" (ranked as his masterpiece), and the undraped figure of Saint Sebastian. It is alleged that the latter was felt to be so strongly expressive of suffering and agony, that it was found necessary to remove it from the place where it had been exhibited in the chapel of a convent.\n\nFra Bartolomeo's compositions are remarkable for skill in the massing of light and shade, richness and delicacy of colouring, and for the admirable drapery of the figures, Bartolomeo having been the first to introduce and use the lay-figure with joints.\n\nAmong his pupils were Cecchino del Frate, Benedetto Ciamfanini, Gabriel Rustici, Ridolfo Ghirlandaio (the son of Domenico Ghirlandaio), and Fra Paolo Pistolese.\n\n\n\nAttribution:\n\n"}
{"id": "11459", "url": "https://en.wikipedia.org/wiki?curid=11459", "title": "Frédéric Bazille", "text": "Frédéric Bazille\n\nJean Frédéric Bazille (December 6, 1841 – November 28, 1870) was a French Impressionist painter. Many of Bazille's major works are examples of figure painting in which he placed the subject figure within a landscape painted \"en plein air\".\n\nFrédéric Bazille was born in Montpellier, Hérault, Languedoc-Roussillon, France, into a wealthy Protestant family. He became interested in painting after seeing some works of Eugène Delacroix. His family agreed to let him study painting, but only if he also studied medicine.\n\nBazille began studying medicine in 1859, and moved to Paris in 1862 to continue his studies. There he met Pierre-Auguste Renoir and Alfred Sisley, was drawn to Impressionist painting, and began taking classes in Charles Gleyre's studio. After failing his medical exam in 1864, he began painting full-time. His close friends included Claude Monet, Alfred Sisley, and Édouard Manet. Bazille was generous with his wealth, and helped support his less fortunate associates by giving them space in his studio and materials to use.\n\nBazille was just twenty-three years old when he painted several of his best-known works, including \"The Pink Dress\" (c. 1864, Musée d'Orsay, Paris). This painting combines a portrait-like depiction of Bazille's cousin, Thérèse des Hours, who is seen from behind—and the sunlit landscape at which she gazes. His best-known painting is \"Family Reunion\" of 1867–1868 (Musée d'Orsay, Paris).\n\nFrédéric Bazille joined a Zouave regiment in August 1870, a month after the outbreak of the Franco-Prussian War. On November 28 of that year, he was with his unit at the Battle of Beaune-la-Rolande when, his officer having been injured, he took command and led an assault on the German position. He was hit twice in the failed attack and died on the battlefield at the age of twenty-eight. His father travelled to the battlefield a few days later to take his body back for burial at Montpellier over a week later.\n\n\n\n"}
{"id": "11460", "url": "https://en.wikipedia.org/wiki?curid=11460", "title": "Ford Madox Brown", "text": "Ford Madox Brown\n\nFord Madox Brown (16 April 1821 – 6 October 1893) was an English painter of moral and historical subjects, notable for his distinctively graphic and often Hogarthian version of the Pre-Raphaelite style. Arguably, his most notable painting was \"Work\" (1852–1865). Brown spent the latter years of his life painting the Manchester Murals, depicting Mancunian history, for Manchester Town Hall.\n\nBrown was the grandson of the medical theorist John Brown, founder of the Brunonian system of medicine. His great grandfather was a Scottish labourer. His father Ford Brown served as a purser in the Royal Navy, including a period serving under Sir Isaac Coffin and a period on HMS \"Arethusa\". He left the Navy after the end of the Napoleonic Wars.\n\nIn 1818, Ford Brown married Caroline Madox, of an old Kentish family, from which his middle name was taken. Brown's parents had limited financial resources, and they moved to Calais to seek cheaper lodgings, where their daughter Elizabeth Coffin was born in 1819 and their son Ford Madox Brown in 1821.\n\nBrown's education was limited, as the family frequently moved between lodgings in the Pas-de-Calais and relatives in Kent, but he showed artistic talent in copying of old master prints. His father initially sought a naval career for his son, writing to his former captain Sir Isaac Coffin. The family moved to Bruges in 1835 so Brown could study at the academy under Albert Gregorius. Brown moved to Ghent in 1836 to continue his studies under Pieter van Hanselaere. He moved to Antwerp in 1837 to study under Gustaf Wappers. He continued to study in Antwerp after his mother's death in 1839. His sister died in 1840, and then his father in 1842.\n\nThe Tate Gallery holds an early example of Brown's work, a portrait of his father. He first exhibited at the Royal Academy in 1840, a work inspired by Lord Byron's poem \"The Giaour\" (now lost) and then completed a version of \"The Execution of Mary, Queen of Scots\", with his cousin and future wife Elisabeth Bromley as one of his models. He lived in Montmartre with his new wife and aging father in 1841. He painted \"Manfred on the Jungfrau\", inspired by Lord Byron's poem \"Manfred\" while he was in Paris.\n\nIn 1843 he submitted work to the Westminster Cartoon Competition, for compositions to decorate the new Palace of Westminster. His entry, \"The Body of Harold Brought before William\", was not successful. His early works were, however, greatly admired by the young Dante Gabriel Rossetti, who asked him to become his tutor. Through Rossetti, Brown came into contact with the artists who went on to form the Pre-Raphaelite Brotherhood. Though closely linked to them, he was never actually a member of the brotherhood itself, but adopted the bright colours and realistic style of William Holman Hunt and John Everett Millais. He was also influenced by the works of Holbein that he saw in Basel in 1845, and by Friedrich Overbeck and Peter Cornelius, whom he met in Rome in 1845-46.\n\nBrown struggled to make his mark in the 1850s, with his paintings failing to find buyers, and he considered emigrating to India. In 1852 he started work on two of his most significant works.\n\nOne of his most famous images is \"The Last of England\", painted from 1852 to 1855, which was sold in March 1859 for 325 Guineas (\"2010: £\"). It depicts a pair of stricken emigrants as they sail away on the ship that will take them from England forever. It was inspired by the departure of the Pre-Raphaelite sculptor Thomas Woolner, who had left for Australia. In an unusual tondo format, the painting is structured with Brown's characteristic linear energy, and emphasis on apparently grotesque and banal details, such as the cabbages hanging from the ship's side. The husband and wife are portraits of Brown and his second wife Emma.\nBrown's most important painting was \"Work\" (1852–1865), begun in Hampstead in 1852 and which he showed at his retrospective exhibition in 1865. Thomas Plint advanced funds to enable Brown to complete the work, in anticipation of obtaining the finished painting, but died in 1861 before the painting had been completed. In this painting, Brown attempted to depict the totality of the mid-Victorian social experience in a single image, depicting 'navvies' digging up a road (Heath Street in Hampstead, London) and disrupting the old social hierarchies as they did so. The image erupts into proliferating details from the dynamic centre of the action, as the workers tear a hole in the road – and, symbolically, in the social fabric. Each character represents a particular social class and role in the modern urban environment. Brown wrote a catalogue to accompany the special exhibition of \"Work.\" This publication included an extensive explanation of \"Work\" that nevertheless leaves many questions unanswered. Brown's concern with the social issues addressed in \"Work\" prompted him to open a soup kitchen for Manchester's hungry, and to attempt to aid the city's unemployed to find work by founding a labour exchange.\n\nBrown found patrons in the north of England, including Plint, George Rae from Birkenhead, John Miller from Liverpool, and James Leathart from Newcastle. By the late 1850s he had lost patience with the poor reception he received at the Royal Academy and ceased to show his works there, rejecting an offer from Millais to support his becoming an associate member. He founded the Hogarth Club in 1858, with William Morris, Edward Burne-Jones, and his former pupil Rossetti. After a successful period of a few years, the club reached over 80 members, including several prominent members of the Royal Academy, but Brown resigned in 1860, and the club collapsed in 1861.\n\nFrom the 1860s, Brown also designed furniture and stained glass. He was a founder partner of William Morris's design company, Morris, Marshall, Faulkner & Co., in 1861, which dissolved in 1874 with Morris continuing on his own. He was a close friend of the landscape artist Henry Mark Anthony.\n\nBrown's major achievement after \"Work\" was \"The Manchester Murals\", a cycle of twelve paintings in the Great Hall of Manchester Town Hall depicting the history of the city. Brown would be 72 by the time he finished the murals. In total, he took six years perfecting the murals, which were his last major work.\n\nFord Madox Brown was married twice. His first wife Elizabeth Bromley was his first cousin, the daughter of his mother's sister Mary. They were married in Meopham in Kent in April 1841, shortly before his 20th birthday and less than a year after the sudden death of his sister Elizabeth. They lived in Montmartre in 1841 with Brown's invalid father who died the following summer.\n\nTheir first child died young as an infant in November 1842. Their daughter Emma Lucy was born in 1843 and the family moved back to England in 1844. They travelled to Rome in 1845 to alleviate the illness of his wife, who was suffering from consumption (pulmonary tuberculosis). She died in Paris in June 1846, aged 27, on the journey back to England from Rome.\n\nEmma Hill became a frequent model for Brown from 1848; for example, she is the wife in \"The Last of England\". She became his mistress, and they shared a house in London, but social convention made him unable to marry an illiterate daughter of a bricklayer. Their daughter Catherine Emily was born in 1850, and eventually they were married at St Dunstan-in-the-West in April 1853. Their son, Oliver Madox Brown (1855–1874) (known as Nolly) showed promise both as an artist and poet, but died of blood poisoning before his maturity. The death of Nolly was a crushing blow for Brown, and he kept a room for his son's belongings as a shrine. Another son Arthur was born in September 1856. Brown used Arthur as the model for the baby held by a ragged girl in the foreground of \"Work\", but he died aged only ten months old in July 1857.\n\nHis daughters Lucy and Catherine were also competent artists. Lucy married William Michael Rossetti in 1874. Catherine, married Francis Hueffer; through Catherine, Brown was the grandfather of novelist Ford Madox Ford and great-grandfather of Labour Home Secretary Frank Soskice.\n\nBrown's second wife died in October 1890, and he died in Primrose Hill in 1893. He is buried in the St Pancras and Islington Cemetery in East Finchley, close to Muswell Hill. He was given a secular funeral, and the funeral oration was delivered by the American Moncure D. Conway, the secularist after whom Conway Hall was later named.\n\nThe J D Wetherspoon pub in Oxford Road, Manchester is named after Ford Madox Brown. It states on the Wetherspoon's website that \"This J D Wetherspoon pub is named after the much-travelled artist Ford Madox Brown, a one-time resident of Victoria Park, a suburb south of the pub.\" The pub opened in 2007.\n\n\n\n"}
{"id": "11461", "url": "https://en.wikipedia.org/wiki?curid=11461", "title": "Francis Crick", "text": "Francis Crick\n\nFrancis Harry Compton Crick (8 June 1916 – 28 July 2004) was a British molecular biologist, biophysicist, and neuroscientist, most noted for being a co-discoverer of the structure of the DNA molecule in 1953 with James Watson, work which was based partly on fundamental studies done by Rosalind Franklin, Raymond Gosling and Maurice Wilkins. Together with Watson and Maurice Wilkins, he was jointly awarded the 1962 Nobel Prize in Physiology or Medicine \"for their discoveries concerning the molecular structure of nucleic acids and its significance for information transfer in living material\".\n\nCrick was an important theoretical molecular biologist and played a crucial role in research related to revealing the helical structure of DNA. He is widely known for use of the term \"central dogma\" to summarize the idea that genetic information flow in cells is essentially one-way, from DNA to RNA to protein.\n\nDuring the remainder of his career, he held the post of J.W. Kieckhefer Distinguished Research Professor at the Salk Institute for Biological Studies in La Jolla, California. His later research centered on theoretical neurobiology and attempts to advance the scientific study of human consciousness. He remained in this post until his death; \"he was editing a manuscript on his death bed, a scientist until the bitter end\" according to Christof Koch.\n\nCrick was the first son of Harry Crick (1887–1948) and Annie Elizabeth Crick (née Wilkins; 1879–1955). He was born and raised in Weston Favell, then a small village near the English town of Northampton, in which Crick’s father and uncle ran the family’s boot and shoe factory. His grandfather, Walter Drawbridge Crick (1857–1903), an amateur naturalist, wrote a survey of local foraminifera (single-celled protists with shells), corresponded with Charles Darwin, and had two gastropods (snails or slugs) named after him.\n\nAt an early age, Francis was attracted to science and what he could learn about it from books. As a child, he was taken to church by his parents. But by about age 12, he said he did not want to go anymore, as he preferred a scientific search for answers over religious belief.\n\nWalter Crick, his uncle, lived in a small house on the south side of Abington Avenue; he had a shed at the bottom of his little garden where he taught Crick to blow glass, do chemical experiments and to make photographic prints. When he was eight or nine he transferred to the most junior form of the Northampton Grammar School, on the Billing Road. This was about from his home so he could walk there and back, by Park Avenue South and Abington Park Crescent, but he more often went by bus or, later, by bicycle. The teacher – a Miss Holding – was an inspired teacher and made everything interesting. The teaching in the higher forms was satisfactory, but not as stimulating. After the age of 14, he was educated at Mill Hill School in London (on scholarship), where he studied mathematics, physics, and chemistry with his best friend John Shilston. He shared the Walter Knox Prize for Chemistry on Mill Hill School's Foundation Day, Friday, 7 July 1933. He declared that his success was inspired by the quality of teaching he received whilst a pupil at Mill Hill.\n\nAt the age of 21, Crick earned a Bachelor of Science degree in physics from University College London. Crick had failed to gain a place at a Cambridge college, probably through failing their requirement for Latin. Crick began his PhD at UCL but was interrupted by WWII. He later became a PhD student and Honorary Fellow of Gonville and Caius College, Cambridge and mainly worked at the Cavendish Laboratory and the Medical Research Council (MRC) Laboratory of Molecular Biology in Cambridge. He was also an Honorary Fellow of Churchill College, Cambridge and of University College, London.\n\nCrick began a Ph.D. research project on measuring viscosity of water at high temperatures (which he later described as \"the dullest problem imaginable\") in the laboratory of physicist Edward Neville da Costa Andrade at University College London, but with the outbreak of World War II (in particular, an incident during the Battle of Britain when a bomb fell through the roof of the laboratory and destroyed his experimental apparatus), Crick was deflected from a possible career in physics. During his second year as a PhD student, however, he was awarded the Carey Foster Research Prize, a great honour. He did postdoctoral work at the Polytechnic Institute of Brooklyn.\n\nDuring World War II, he worked for the Admiralty Research Laboratory, from which emerged a group of many notable scientists, including David Bates, Robert Boyd, George Deacon, John Gunn, Harrie Massey, and Nevill Mott; he worked on the design of magnetic and acoustic mines, and was instrumental in designing a new mine that was effective against German minesweepers.\n\nIn 1947, aged 31, Crick began studying biology and became part of an important migration of physical scientists into biology research. This migration was made possible by the newly won influence of physicists such as Sir John Randall, who had helped win the war with inventions such as radar. Crick had to adjust from the \"elegance and deep simplicity\" of physics to the \"elaborate chemical mechanisms that natural selection had evolved over billions of years.\" He described this transition as, \"almost as if one had to be born again.\" According to Crick, the experience of learning physics had taught him something important—hubris—and the conviction that since physics was already a success, great advances should also be possible in other sciences such as biology. Crick felt that this attitude encouraged him to be more daring than typical biologists who tended to concern themselves with the daunting problems of biology and not the past successes of physics.\n\nFor the better part of two years, Crick worked on the physical properties of cytoplasm at Cambridge's Strangeways Research Laboratory, headed by Honor Bridget Fell, with a Medical Research Council studentship, until he joined Max Perutz and John Kendrew at the Cavendish Laboratory. The Cavendish Laboratory at Cambridge was under the general direction of Sir Lawrence Bragg, who had won the Nobel Prize in 1915 at the age of 25. Bragg was influential in the effort to beat a leading American chemist, Linus Pauling, to the discovery of DNA's structure (after having been pipped at the post by Pauling's success in determining the alpha helix structure of proteins). At the same time Bragg's Cavendish Laboratory was also effectively competing with King's College London, whose Biophysics department was under the direction of Randall. (Randall had refused Crick's application to work at King's College.) Francis Crick and Maurice Wilkins of King's College were personal friends, which influenced subsequent scientific events as much as the close friendship between Crick and James Watson. Crick and Wilkins first met at King's College and not, as erroneously recorded by two authors, at the Admiralty during World War II.\n\nHe married twice, fathered three children and was the grandfather of six grandchildren; his brother Anthony (born in 1918) predeceased him in 1966.\n\nSpouses:\n\nChildren:\n\nGrandchildren\n\n\nCrick died of colon cancer on the morning of 28 July 2004 at the University of California, San Diego (UCSD) Thornton Hospital in La Jolla; he was cremated and his ashes were scattered into the Pacific Ocean. A public memorial was held on 27 September 2004 at the Salk Institute, La Jolla, near San Diego, California; guest speakers included James Watson, Sydney Brenner, Alex Rich, Seymour Benzer, Aaron Klug, Christof Koch, Pat Churchland, Vilayanur Ramachandran, Tomaso Poggio, Leslie Orgel, Terry Sejnowski, his son Michael Crick, and his youngest daughter Jacqueline Nichols. A private memorial for family and colleagues was held on 3 August 2004.\n\nCrick was interested in two fundamental unsolved problems of biology: how molecules make the transition from the non-living to the living, and how the brain makes a conscious mind. He realized that his background made him more qualified for research on the first topic and the field of biophysics. It was at this time of Crick’s transition from physics to biology that he was influenced by both Linus Pauling and Erwin Schrödinger. It was clear in theory that covalent bonds in biological molecules could provide the structural stability needed to hold genetic information in cells. It only remained as an exercise of experimental biology to discover exactly which molecule was the genetic molecule. In Crick’s view, Charles Darwin’s theory of evolution by natural selection, Gregor Mendel’s genetics and knowledge of the molecular basis of genetics, when combined, revealed the secret of life. Crick had the very optimistic view that life would very soon be created in a test tube. However, some people (such as fellow researcher and colleague Esther Lederberg) thought that Crick was unduly optimistic \n\nIt was clear that some macromolecule such as a protein was likely to be the genetic molecule. However, it was well known that proteins are structural and functional macromolecules, some of which carry out enzymatic reactions of cells. In the 1940s, some evidence had been found pointing to another macromolecule, DNA, the other major component of chromosomes, as a candidate genetic molecule. In the 1944 Avery-MacLeod-McCarty experiment, Oswald Avery and his collaborators showed that a heritable phenotypic difference could be caused in bacteria by providing them with a particular DNA molecule.\n\nHowever, other evidence was interpreted as suggesting that DNA was structurally uninteresting and possibly just a molecular scaffold for the apparently more interesting protein molecules. Crick was in the right place, in the right frame of mind, at the right time (1949), to join Max Perutz’s project at the University of Cambridge, and he began to work on the X-ray crystallography of proteins. X-ray crystallography theoretically offered the opportunity to reveal the molecular structure of large molecules like proteins and DNA, but there were serious technical problems then preventing X-ray crystallography from being applicable to such large molecules.\n\nCrick taught himself the mathematical theory of X-ray crystallography. During the period of Crick's study of X-ray diffraction, researchers in the Cambridge lab were attempting to determine the most stable helical conformation of amino acid chains in proteins (the alpha helix). Linus Pauling was the first to identify the 3.6 amino acids per helix turn ratio of the alpha helix. Crick was witness to the kinds of errors that his co-workers made in their failed attempts to make a correct molecular model of the alpha helix; these turned out to be important lessons that could be applied, in the future, to the helical structure of DNA. For example, he learned the importance of the structural rigidity that double bonds confer on molecular structures which is relevant both to peptide bonds in proteins and the structure of nucleotides in DNA.\n\nIn 1951 and 1952, together with William Cochran and Vladimir Vand, Crick assisted in the development of a mathematical theory of X-ray diffraction by a helical molecule. This theoretical result matched well with X-ray data for proteins that contain sequences of amino acids in the alpha helix conformation. Helical diffraction theory turned out to also be useful for understanding the structure of DNA.\n\nLate in 1951, Crick started working with James Watson at Cavendish Laboratory at the University of Cambridge, England. Using \"Photo 51\" (the X-ray diffraction results of Rosalind Franklin and her graduate student Raymond Gosling of King's College London, given to them by Gosling and Franklin's colleague Wilkins), Watson and Crick together developed a model for a helical structure of DNA, which they published in 1953. For this and subsequent work they were jointly awarded the Nobel Prize in Physiology or Medicine in 1962 with Wilkins.\n\nWhen Watson came to Cambridge, Crick was a 35-year-old graduate student (due to his work during WWII) and Watson was only 23, but he already had a Ph.D. They shared an interest in the fundamental problem of learning how genetic information might be stored in molecular form. Watson and Crick talked endlessly about DNA and the idea that it might be possible to guess a good molecular model of its structure. A key piece of experimentally-derived information came from X-ray diffraction images that had been obtained by Wilkins, Franklin, and Gosling. In November 1951, Wilkins came to Cambridge and shared his data with Watson and Crick. Alexander Stokes (another expert in helical diffraction theory) and Wilkins (both at King's College) had reached the conclusion that X-ray diffraction data for DNA indicated that the molecule had a helical structure—but Franklin vehemently disputed this conclusion. Stimulated by their discussions with Wilkins and what Watson learned by attending a talk given by Franklin about her work on DNA, Crick and Watson produced and showed off an erroneous first model of DNA. Their hurry to produce a model of DNA structure was driven in part by the knowledge that they were competing against Linus Pauling. Given Pauling's recent success in discovering the Alpha helix, they feared that Pauling might also be the first to determine the structure of DNA.\n\nMany have speculated about what might have happened had Pauling been able to travel to Britain as planned in May 1952. As it was, his political activities caused his travel to be restricted by the United States government and he did not visit the UK until later, at which point he met none of the DNA researchers in England. At any rate he was preoccupied with proteins at the time, not DNA. Watson and Crick were not officially working on DNA. Crick was writing his Ph.D. thesis; Watson also had other work such as trying to obtain crystals of myoglobin for X-ray diffraction experiments. In 1952, Watson performed X-ray diffraction on tobacco mosaic virus and found results indicating that it had helical structure. Having failed once, Watson and Crick were now somewhat reluctant to try again and for a while they were forbidden to make further efforts to find a molecular model of DNA.\nOf great importance to the model building effort of Watson and Crick was Rosalind Franklin's understanding of basic chemistry, which indicated that the hydrophilic phosphate-containing backbones of the nucleotide chains of DNA should be positioned so as to interact with water molecules on the outside of the molecule while the hydrophobic bases should be packed into the core. Franklin shared this chemical knowledge with Watson and Crick when she pointed out to them that their first model (from 1951, with the phosphates inside) was obviously wrong.\n\nCrick described what he saw as the failure of Wilkins and Franklin to cooperate and work towards finding a molecular model of DNA as a major reason why he and Watson eventually made a second attempt to do so. They asked for, and received, permission to do so from both William Lawrence Bragg and Wilkins. In order to construct their model of DNA, Watson and Crick made use of information from unpublished X-ray diffraction images of Franklin's (shown at meetings and freely shared by Wilkins), including preliminary accounts of Franklin's results/photographs of the X-ray images that were included in a written progress report for the King's College laboratory of Sir John Randall from late 1952.\n\nIt is a matter of debate whether Watson and Crick should have had access to Franklin's results without her knowledge or permission, and before she had a chance to formally publish the results of her detailed analysis of her X-ray diffraction data which were included in the progress report. However, Watson and Crick found fault in her steadfast assertion that, according to her data, a helical structure was not the only possible shape for DNA—so they had a dilemma. In an effort to clarify this issue, Max Ferdinand Perutz later published what had been in the progress report, and suggested that nothing was in the report that Franklin herself had not said in her talk (attended by Watson) in late 1951. Further, Perutz explained that the report was to a Medical Research Council (MRC) committee that had been created in order to \"establish contact between the different groups of people working for the Council\". Randall's and Perutz's laboratories were both funded by the MRC.\n\nIt is also not clear how important Franklin's unpublished results from the progress report actually were for the model-building done by Watson and Crick. After the first crude X-ray diffraction images of DNA were collected in the 1930s, William Astbury had talked about stacks of nucleotides spaced at 3.4 angström (0.34 nanometre) intervals in DNA. A citation to Astbury's earlier X-ray diffraction work was one of only eight references in Franklin's first paper on DNA. Analysis of Astbury's published DNA results and the better X-ray diffraction images collected by Wilkins and Franklin revealed the helical nature of DNA. It was possible to predict the number of bases stacked within a single turn of the DNA helix (10 per turn; a full turn of the helix is 27 angströms [2.7 nm] in the compact A form, 34 angströms [3.4 nm] in the wetter B form). Wilkins shared this information about the B form of DNA with Crick and Watson. Crick did not see Franklin's B form X-ray images (Photo 51) until after the DNA double helix model was published.\n\nOne of the few references cited by Watson and Crick when they published their model of DNA was to a published article that included Sven Furberg's DNA model that had the bases on the inside. Thus, the Watson and Crick model was not the first \"bases in\" model to be proposed. Furberg's results had also provided the correct orientation of the DNA sugars with respect to the bases. During their model building, Crick and Watson learned that an antiparallel orientation of the two nucleotide chain backbones worked best to orient the base pairs in the centre of a double helix. Crick's access to Franklin's progress report of late 1952 is what made Crick confident that DNA was a double helix with antiparallel chains, but there were other chains of reasoning and sources of information that also led to these conclusions.\n\nAs a result of leaving King's College for Birkbeck College, Franklin was asked by John Randall to give up her work on DNA. When it became clear to Wilkins and the supervisors of Watson and Crick that Franklin was going to the new job, and that Linus Pauling was working on the structure of DNA, they were willing to share Franklin's data with Watson and Crick, in the hope that they could find a good model of DNA before Pauling was able. Franklin's X-ray diffraction data for DNA and her systematic analysis of DNA's structural features was useful to Watson and Crick in guiding them towards a correct molecular model. The key problem for Watson and Crick, which could not be resolved by the data from King's College, was to guess how the nucleotide bases pack into the core of the DNA double helix.\nAnother key to finding the correct structure of DNA was the so-called Chargaff ratios, experimentally determined ratios of the nucleotide subunits of DNA: the amount of guanine is equal to cytosine and the amount of adenine is equal to thymine. A visit by Erwin Chargaff to England in 1952 reinforced the salience of this important fact for Watson and Crick. The significance of these ratios for the structure of DNA were not recognized until Watson, persisting in building structural models, realized that A:T and C:G pairs are structurally similar. In particular, the length of each base pair is the same. Chargaff had also pointed out to Watson that, in the aqueous, saline environment of the cell, the predominant tautomers of the pyrimidine (C and T) bases would be the amine and keto configurations of cytosine and thymine, rather than the imino and enol forms that Crick and Watson had assumed. They consulted Jerry Donohue who confirmed the most likely structures of the nucleotide bases. The base pairs are held together by hydrogen bonds, the same non-covalent interaction that stabilize the protein α-helix. The correct structures were essential for the positioning of the hydrogen bonds. These insights led Watson to deduce the true biological relationships of the A:T and C:G pairs. After the discovery of the hydrogen bonded A:T and C:G pairs, Watson and Crick soon had their anti-parallel, double helical model of DNA, with the hydrogen bonds at the core of the helix providing a way to \"unzip\" the two complementary strands for easy replication: the last key requirement for a likely model of the genetic molecule. As important as Crick's contributions to the discovery of the double helical DNA model were, he stated that without the chance to collaborate with Watson, he would not have found the structure by himself.\n\nCrick did tentatively attempt to perform some experiments on nucleotide base pairing, but he was more of a theoretical biologist than an experimental biologist. There was another near-discovery of the base pairing rules in early 1952. Crick had started to think about interactions between the bases. He asked John Griffith to try to calculate attractive interactions between the DNA bases from chemical principles and quantum mechanics. Griffith's best guess was that A:T and G:C were attractive pairs. At that time, Crick was not aware of Chargaff's rules and he made little of Griffith's calculations, although it did start him thinking about complementary replication. Identification of the correct base-pairing rules (A-T, G-C) was achieved by Watson \"playing\" with cardboard cut-out models of the nucleotide bases, much in the manner that Linus Pauling had discovered the protein alpha helix a few years earlier. The Watson and Crick discovery of the DNA double helix structure was made possible by their willingness to combine theory, modeling and experimental results (albeit mostly done by others) to achieve their goal.\n\nThe DNA double helix structure proposed by Watson and Crick was based upon \"Watson-Crick\" bonds between the four bases most frequently found in DNA (A, C, T, G) and RNA (A, C, U, G). However, later research showed that triple-stranded, quadruple-stranded and other more complex DNA molecular structures required Hoogsteen base pairing. The entire field of synthetic biology began with work by researchers such as Erik T. Kool, in which bases other than A, C, T and G are used in a synthetic DNA. In addition to synthetic DNA there are also attempts to construct synthetic codons, synthetic endonucleases, synthetic proteins and synthetic zinc fingers. Using synthetic DNA, instead of there being 4 codons, if there are n new bases there could be as many as n codons. Research is currently being done to see if codons can be expanded to more than 3 bases. These new codons can code for new amino acids. These synthetic molecules can be used not only in medicine, but in creation of new materials.\n\nThe discovery was made on 28 February 1953; the first Watson/Crick paper appeared in \"Nature\" on 25 April 1953. Sir Lawrence Bragg, the director of the Cavendish Laboratory, where Watson and Crick worked, gave a talk at Guy's Hospital Medical School in London on Thursday 14 May 1953 which resulted in an article by Ritchie Calder in the \"News Chronicle\" of London, on Friday 15 May 1953, entitled \"Why You Are You. Nearer Secret of Life.\" The news reached readers of \"The New York Times\" the next day; Victor K. McElheny, in researching his biography, \"Watson and DNA: Making a Scientific Revolution\", found a clipping of a six-paragraph New York Times article written from London and dated 16 May 1953 with the headline \"Form of 'Life Unit' in Cell Is Scanned.\" The article ran in an early edition and was then pulled to make space for news deemed more important. (\"The New York Times\" subsequently ran a longer article on 12 June 1953). The university's undergraduate newspaper \"Varsity\" also ran its own short article on the discovery on Saturday 30 May 1953. Bragg's original announcement of the discovery at a Solvay conference on proteins in Belgium on 8 April 1953 went unreported by the British press.\n\nIn a seven-page, handwritten letter to his son at a British boarding school on 19 March 1953 Crick explained his discovery, beginning the letter \"\"My Dear Michael, Jim Watson and I have probably made a most important discovery...\"\". The letter was put up for auction at Christie's New York on 10 April 2013 with an estimate of $1 to $2 million, eventually selling for $6,059,750, the largest amount ever paid for a letter at auction.\n\nSydney Brenner, Jack Dunitz, Dorothy Hodgkin, Leslie Orgel, and Beryl M. Oughton, were some of the first people in April 1953 to see the model of the structure of DNA, constructed by Crick and Watson; at the time they were working at Oxford University's Chemistry Department. All were impressed by the new DNA model, especially Brenner who subsequently worked with Crick at Cambridge in the Cavendish Laboratory and the new Laboratory of Molecular Biology. According to the late Dr. Beryl Oughton, later Rimmer, they all travelled together in two cars once Dorothy Hodgkin announced to them that they were off to Cambridge to see the model of the structure of DNA. Orgel also later worked with Crick at the Salk Institute for Biological Studies.\n\nIn addition, the entire field of synthetic biology began with researchers such as Erik T. Kool, where bases other than A, C, T and G are used in a synthetic DNA. In addition to synthetic DNA there are also attempts to construct synthetic codons, synthetic endonucleases, synthetic proteins and synthetic zinc fingers. Using synthetic DNA, instead of there being 4 codons, if there are n new bases there could be as many as n codons. Research is currently being done to see if codons can be expanded to more than 3 bases. These new codons can code for new amino acids. These synthetic molecules can be used not only in medicine, but in creation of new materials.\n\nSoon after Crick's death, there have been allegations about him having used LSD when he came to the idea of the helix structure of the DNA. While he almost certainly did use LSD, it is unlikely that he was doing that as early as 1953.\n\nIn 1954, at the age of 37, Crick completed his Ph.D. thesis: \"\"X-Ray Diffraction: Polypeptides and Proteins\"\" and received his degree. Crick then worked in the laboratory of David Harker at Brooklyn Polytechnic Institute, where he continued to develop his skills in the analysis of X-ray diffraction data for proteins, working primarily on ribonuclease and the mechanisms of protein synthesis. David Harker, the American X-ray crystallographer, was described as \"the John Wayne of crystallography\" by Vittorio Luzzati, a crystallographer at the Centre for Molecular Genetics in Gif-sur-Yvette near Paris, who had worked with Rosalind Franklin.\n\nAfter the discovery of the double helix model of DNA, Crick's interests quickly turned to the biological implications of the structure. In 1953, Watson and Crick published another article in \"Nature\" which stated: \"it therefore seems likely that the precise sequence of the bases is the code that carries the genetical information\".\n\nIn 1956, Crick and Watson speculated on the structure of small viruses. They suggested that spherical viruses such as Tomato bushy stunt virus had icosahedral symmetry and were made from 60 identical subunits.\n\nAfter his short time in New York, Crick returned to Cambridge where he worked until 1976, at which time he moved to California. Crick engaged in several X-ray diffraction collaborations such as one with Alexander Rich on the structure of collagen. However, Crick was quickly drifting away from continued work related to his expertise in the interpretation of X-ray diffraction patterns of proteins.\n\nGeorge Gamow established a group of scientists interested in the role of RNA as an intermediary between DNA as the genetic storage molecule in the nucleus of cells and the synthesis of proteins in the cytoplasm (the RNA Tie Club). It was clear to Crick that there had to be a code by which a short sequence of nucleotides would specify a particular amino acid in a newly synthesized protein. In 1956, Crick wrote an informal paper about the genetic coding problem for the small group of scientists in Gamow's RNA group. In this article, Crick reviewed the evidence supporting the idea that there was a common set of about 20 amino acids used to synthesize proteins. Crick proposed that there was a corresponding set of small \"adaptor molecules\" that would hydrogen bond to short sequences of a nucleic acid, and also link to one of the amino acids. He also explored the many theoretical possibilities by which short nucleic acid sequences might code for the 20 amino acids.\nDuring the mid-to-late 1950s Crick was very much intellectually engaged in sorting out the mystery of how proteins are synthesized. By 1958, Crick's thinking had matured and he could list in an orderly way all of the key features of the protein synthesis process:\n\nThe adaptor molecules were eventually shown to be tRNAs and the catalytic \"ribonucleic-protein complexes\" became known as ribosomes. An important step was later realization (in 1960) that the messenger RNA was not the same as the ribosomal RNA. None of this, however, answered the fundamental theoretical question of the exact nature of the genetic code. In his 1958 article, Crick speculated, as had others, that a triplet of nucleotides could code for an amino acid. Such a code might be \"degenerate\", with 4×4×4=64 possible triplets of the four nucleotide subunits while there were only 20 amino acids. Some amino acids might have multiple triplet codes. Crick also explored other codes in which, for various reasons, only some of the triplets were used, \"magically\" producing just the 20 needed combinations. Experimental results were needed; theory alone could not decide the nature of the code. Crick also used the term \"central dogma\" to summarize an idea that implies that genetic information flow between macromolecules would be essentially one-way:\n\nSome critics thought that by using the word \"dogma\", Crick was implying that this was a rule that could not be questioned, but all he really meant was that it was a compelling idea without much solid evidence to support it. In his thinking about the biological processes linking DNA genes to proteins, Crick made explicit the distinction between the materials involved, the energy required, and the information flow. Crick was focused on this third component (information) and it became the organizing principle of what became known as molecular biology. Crick had by this time become a highly influential theoretical molecular biologist.\n\nProof that the genetic code is a degenerate triplet code finally came from genetics experiments, some of which were performed by Crick. The details of the code came mostly from work by Marshall Nirenberg and others who synthesized synthetic RNA molecules and used them as templates for \"in vitro\" protein synthesis. Nirenberg first announced his results to a small audience in Moscow at a 1961 conference. Crick's reaction was to invite Nirenberg to deliver his talk to a larger audience.\n\nAn enduring controversy has been generated by Watson and Crick's use of DNA X-ray diffraction data collected by Franklin and Gosling. The controversy arose from the fact that some of Franklin's unpublished data were used without her knowledge or consent by Watson and Crick in their construction of the double helix model of DNA. Of the four DNA researchers, only Franklin had a degree in chemistry; Wilkins and Crick had backgrounds in physics, Watson in biology.\n\nPrior to publication of the double helix structure, Watson and Crick had little direct interaction with Franklin herself. They were, however, aware of her work, more aware than she herself realized. Watson was present at a lecture, given in November 1951, where Franklin presented the two forms of the molecule, type A and type B, and discussed the position of the phosphate units on the external part of the molecule. She also specified the amount of water to be found in the molecule in accordance with other parts of it, data that have considerable importance in terms of the stability of the molecule. She was the first to discover and formulate these facts, which in fact constituted the basis for all later attempts to build a model of the molecule. Before this both Linus Pauling and Watson and Crick had generated erroneous models with the chains inside and the bases pointing outwards. Her identification of the space group for DNA crystals revealed to Crick that the two DNA strands were antiparallel.\n\nIn January 1953, Watson was shown an X-ray photograph of B-DNA (called photograph 51), by Wilkins. Wilkins had been given photograph 51 by Rosalind Franklin's Ph.D. student Raymond Gosling. Wilkins and Gosling had worked together in the Medical Research Council's (MRC) Biophysics Unit before director John Randall appointed Franklin to take over both DNA diffraction work and guidance of Gosling's thesis. It appears that Randall did not communicate effectively with them about Franklin's appointment, contributing to confusion and friction between Wilkins and Franklin.\n\nIn the middle of February 1953, Crick's thesis advisor, Max Perutz, gave Crick a copy of a report written for a Medical Research Council biophysics committee visit to King's in December 1952, containing data from the King's group, including some of Franklin's crystallographic calculations.\n\nFranklin was unaware that photograph 51 and other information had been shared with Crick and Watson. She wrote a series of three draft manuscripts, two of which included a double helical DNA backbone. Her two A form manuscripts reached Acta Crystallographica in Copenhagen on 6 March 1953, one day before Crick and Watson had completed their model.\n\nThe X-ray diffraction images collected by Gosling and Franklin provided the best evidence for the helical nature of DNA. Franklin's experimental work thus proved crucial in Watson and Crick's discovery. Her experimental results provided estimates of the water content of DNA crystals, and these results were most consistent with the three sugar-phosphate backbones being on the outside of the molecule. Franklin's X-Ray photograph showed that the backbones had to be on the outside. Although she at first insisted vehemently that her data did not force one to conclude that DNA has a helical structure, in the drafts she submitted in 1953 she argues for a double helical DNA backbone. Her identification of the space group for DNA crystals revealed to Crick that the DNA strands were antiparallel, which helped Watson and Crick decide to look for DNA models with two antiparallel polynucleotide strands.\n\nIn summary, Watson and Crick had three sources for Franklin's unpublished data: 1) her 1951 seminar, attended by Watson, 2) discussions with Wilkins, who worked in the same laboratory with Franklin, 3) a research progress report that was intended to promote coordination of Medical Research Council-supported laboratories. Watson, Crick, Wilkins and Franklin all worked in MRC laboratories.\n\nCrick and Watson felt that they had benefited from collaborating with Wilkins. They offered him a co-authorship on the article that first described the double helix structure of DNA. Wilkins turned down the offer, a fact that may have led to the terse character of the acknowledgment of experimental work done at King's College in the eventual published paper. Rather than make any of the DNA researchers at King's College co-authors on the Watson and Crick double helix article, the solution that was arrived at was to publish two additional papers from King's College along with the helix paper. Brenda Maddox suggests that because of the importance of her experimental results in Watson and Crick's model building and theoretical analysis, Franklin should have had her name on the original Watson and Crick paper in \"Nature\". Franklin and Gosling submitted their own joint 'second' paper to \"Nature\" at the same time as Wilkins, Stokes, and Wilson submitted theirs (i.e. the 'third' paper on DNA).\n\nWatson's portrayal of Franklin in \"The Double Helix\" (written after Franklin's death when libel laws did not apply anymore) was negative and gave the appearance that she was Wilkins' assistant and was unable to interpret her own DNA data.\n\nThe X-ray diffraction images collected by Franklin provided the best evidence for the helical nature of DNA. While Franklin's experimental work proved important to Crick and Watson's development of a correct model, she herself could not realize it at the time. When she left King's College, Director Sir John Randall insisted that all DNA work belonged exclusively to King's and ordered Franklin to not even think about it. Franklin subsequently did superb work in J. D. Bernal's Lab at Birkbeck College with the tobacco mosaic virus extending ideas on helical construction.\n\nCrick was often described as very talkative, with Watson – in \"The Double Helix\" – implying lack of modesty. His personality combined with his scientific accomplishments produced many opportunities for Crick to stimulate reactions from others, both inside and outside the scientific world, which was the centre of his intellectual and professional life. Crick spoke rapidly, and rather loudly, and had an infectious and reverberating laugh, and a lively sense of humour. One colleague from the Salk Institute described him as \"a brainstorming intellectual powerhouse with a mischievous smile... Francis was never mean-spirited, just incisive. He detected microscopic flaws in logic. In a room full of smart scientists, Francis continually reearned his position as the heavyweight champ.\"\n\nCrick occasionally expressed his views on eugenics, usually in private letters. For example, Crick advocated a form of positive eugenics in which wealthy parents would be encouraged to have more children. He once remarked, \"In the long run, it is unavoidable that society will begin to worry about the character of the next generation... It is not a subject at the moment which we can tackle easily because people have so many religious beliefs and until we have a more uniform view of ourselves I think it would be risky to try and do anything in the way of eugenics... I would be astonished if, in the next 100 or 200 years, society did not come round to the view that they would have to try to improve the next generation in some extent or one way or another.\"\n\nCrick was a firm critic of Young Earth creationism. In the 1987 United States Supreme Court case \"Edwards v. Aguillard\", Crick joined a group of other Nobel laureates who advised, \"'Creation-science' simply has no place in the public-school science classroom.\" Crick was also an advocate for the establishment of Darwin Day as a British national holiday.\n\nCrick referred to himself as a humanist, which he defined as the belief \"that human problems can and must be faced in terms of human moral and intellectual resources without invoking supernatural authority.\" He publicly called for humanism to replace religion as a guiding force for humanity, writing:\n\nCrick was especially critical of Christianity:\n\nCrick once joked, \"Christianity may be OK between consenting adults in private but should not be taught to young children.\"\n\nIn his book \"Of Molecules and Men\", Crick expressed his views on the relationship between science and religion. After suggesting that it would become possible for a computer to be programmed so as to have a soul, he wondered: at what point during biological evolution did the first organism have a soul? At what moment does a baby get a soul? Crick stated his view that the idea of a non-material soul that could enter a body and then persist after death is just that, an imagined idea. For Crick, the mind is a product of physical brain activity and the brain had evolved by natural means over millions of years. He felt that it was important that evolution by natural selection be taught in schools and that it was regrettable that English schools had compulsory religious instruction. He also considered that a new scientific world view was rapidly being established, and predicted that once the detailed workings of the brain were eventually revealed, erroneous Christian concepts about the nature of humans and the world would no longer be tenable; traditional conceptions of the \"soul\" would be replaced by a new understanding of the physical basis of mind. He was sceptical of organized religion, referring to himself as a skeptic and an agnostic with \"a strong inclination towards atheism\".\n\nIn 1960, Crick accepted an honorary fellowship at Churchill College, Cambridge, one factor being that the new college did not have a chapel. Some time later a large donation was made to establish a chapel and the College Council decided to accept it. Crick resigned his fellowship in protest.\n\nIn October 1969 Crick participated in a celebration of the 100th year of the journal \"Nature\" in which he attempted to make some predictions about what the next 30 years would hold for molecular biology. His speculations were later published in \"Nature\". Near the end of the article, Crick briefly mentioned the search for life on other planets, but he held little hope that extraterrestrial life would be found by the year 2000. He also discussed what he described as a possible new direction for research, what he called \"biochemical theology\". Crick wrote \"so many people pray that one finds it hard to believe that they do not get some satisfaction from it\".\n\nCrick suggested that it might be possible to find chemical changes in the brain that were molecular correlates of the act of prayer. He speculated that there might be a detectable change in the level of some neurotransmitter or neurohormone when people pray. He might have been imagining substances such as dopamine that are released by the brain under certain conditions and produce rewarding sensations. Crick's suggestion that there might someday be a new science of \"biochemical theology\" seems to have been realized under an alternative name: there is now the new field of neurotheology. Crick's view of the relationship between science and religion continued to play a role in his work as he made the transition from molecular biology research into theoretical neuroscience.\n\nCrick asked in 1998 \"and if some of the Bible is manifestly wrong, why should any of the rest of it be accepted automatically? ... And what would be more important than to find our true place in the universe by removing one by one these unfortunate vestiges of earlier beliefs?\"\n\nIn 2003 he was one of 22 Nobel laureates who signed the \"Humanist Manifesto\".\n\nDuring the 1960s, Crick became concerned with the origins of the genetic code. In 1966, Crick took the place of Leslie Orgel at a meeting where Orgel was to talk about the origin of life. Crick speculated about possible stages by which an initially simple code with a few amino acid types might have evolved into the more complex code used by existing organisms. At that time, everyone thought of proteins as the only kind of enzymes and ribozymes had not yet been found. Many molecular biologists were puzzled by the problem of the origin of a protein replicating system that is as complex as that which exists in organisms currently inhabiting Earth. In the early 1970s, Crick and Orgel further speculated about the possibility that the production of living systems from molecules may have been a very rare event in the universe, but once it had developed it could be spread by intelligent life forms using space travel technology, a process they called \"directed panspermia\". In a retrospective article, Crick and Orgel noted that they had been overly pessimistic about the chances of abiogenesis on Earth when they had assumed that some kind of self-replicating protein system was the molecular origin of life.\n\nIn 1976 Crick addressed the origin of protein synthesis in a paper with Sydney Brenner, Aaron Klug, and George Pieczenik. In this paper, they speculate that code constraints on nucleotide sequences allow protein synthesis without the need for a ribosome. It, however, requires a five base binding between the mRNA and tRNA with a flip of the anti-codon creating a triplet coding, even though it is a five-base physical interaction. Thomas H. Jukes pointed out that the code constraints on the mRNA sequence required for this translation mechanism is still preserved.\n\nCrick's period at Cambridge was the pinnacle of his long scientific career, but he left Cambridge in 1977 after 30 years, having been offered (and having refused) the Mastership of Gonville and Caius. James Watson claimed at a Cambridge conference marking the 50th anniversary of the discovery of the structure of DNA in 2003: \"Now perhaps it's a pretty well kept secret that one of the most uninspiring acts of the University of Cambridge over this past century was to turn down Francis Crick when he applied to be the Professor of Genetics, in 1958. Now there may have been a series of arguments, which led them to reject Francis. It was really saying, don't push us to the frontier.\" The apparently \"pretty well kept secret\" had already been recorded in Soraya De Chadarevian's \"Designs For Life: Molecular Biology After World War II\", published by Cambridge University Press in 2002. His major contribution to molecular biology in Cambridge is well documented in \"The History of the University of Cambridge: Volume 4 (1870 to 1990)\", which was published by CUP in 1992.\n\nAccording to the University of Cambridge's genetics department official website, the electors of the professorship could not reach consensus, prompting the intervention of then University Vice-Chancellor Lord Adrian. Lord Adrian first offered the professorship to a compromise candidate, Guido Pontecorvo, who refused, and is said to have offered it then to Crick, who also refused.\n\nIn 1976, Crick took a sabbatical year at the Salk Institute for Biological Studies in La Jolla, California. Crick had been a nonresident fellow of the Institute since 1960. Crick wrote, \"I felt at home in Southern California.\" After the sabbatical, Crick left Cambridge in order to continue working at the Salk Institute. He was also a professor at the University of California, San Diego. He taught himself neuroanatomy and studied many other areas of neuroscience research. It took him several years to disengage from molecular biology because exciting discoveries continued to be made, including the discovery of alternative splicing and the discovery of restriction enzymes, which helped make possible genetic engineering. Eventually, in the 1980s, Crick was able to devote his full attention to his other interest, consciousness. His autobiographical book, \"\", includes a description of why he left molecular biology and switched to neuroscience.\n\nUpon taking up work in theoretical neuroscience, Crick was struck by several things:\n\nCrick hoped he might aid progress in neuroscience by promoting constructive interactions between specialists from the many different subdisciplines concerned with consciousness. He even collaborated with neurophilosophers such as Patricia Churchland. In 1983, as a result of their studies of computer models of neural networks, Crick and Mitchison proposed that the function of REM sleep is to remove certain modes of interactions in networks of cells in the mammalian cerebral cortex; they called this hypothetical process 'reverse learning' or 'unlearning'. In the final phase of his career, Crick established a collaboration with Christof Koch that lead to publication of a series of articles on consciousness during the period spanning from 1990 to 2005. Crick made the strategic decision to focus his theoretical investigation of consciousness on how the brain generates visual awareness within a few hundred milliseconds of viewing a scene. Crick and Koch proposed that consciousness seems so mysterious because it involves very short-term memory processes that are as yet poorly understood. Crick also published a book describing how neurobiology had reached a mature enough stage so that consciousness could be the subject of a unified effort to study it at the molecular, cellular and behavioural levels. Crick's book \"The Astonishing Hypothesis\" made the argument that neuroscience now had the tools required to begin a scientific study of how brains produce conscious experiences. Crick was skeptical about the value of computational models of mental function that are not based on details about brain structure and function.\n\nIn addition to his third share of the 1962 Nobel prize for Physiology or Medicine, he received many awards and honours, including the Royal and Copley medals of the Royal Society (1972 and 1975), and also the Order of Merit (on 27 November 1991); he refused an offer of a CBE in 1963, but was often referred to in error as 'Sir Francis Crick' and even on occasions as 'Lord Crick.' He was elected an EMBO Member in 1964.\n\nThe award of Nobel prizes to John Kendrew and Max Perutz, and to Crick, Watson, and Wilkins was satirised in a short sketch in the BBC TV programme \"That Was The Week That Was\" with the Nobel Prizes being referred to as 'The Alfred Nobel Peace Pools.'\n\nThe Francis Crick Medal and Lecture was established in 2003 following an endowment by his former colleague, Sydney Brenner, joint winner of the 2002 Nobel Prize in Physiology and Medicine. The lecture is delivered annually in any field of biological sciences, with preference given to the areas in which Francis Crick himself worked. Importantly, the lectureship is aimed at younger scientists, ideally under 40, or whose career progression corresponds to this age. , Crick lectures have been delivered by Julie Ahringer, Dario Alessi, Ewan Birney, Simon Boulton, Jason Chin, Simon Fisher, Matthew Hurles, Gilean McVean, Duncan Odom, Geraint Rees, Sarah Teichmann and Daniel Wolpert.\n\nThe Francis Crick Institute is a £660 million biomedical research centre located in north London, United Kingdom. The Francis Crick Institute is a partnership between Cancer Research UK, Imperial College London, King's College London, the Medical Research Council, University College London (UCL) and the Wellcome Trust. Completed in 2016, it is the largest centre for biomedical research and innovation in Europe.\n\nThe University of Cambridge Graduate School of Biological, Medical and Veterinary Sciences hosts The Francis Crick Graduate Lectures. The first two lectures were by John Gurdon and Tim Hunt.\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "11463", "url": "https://en.wikipedia.org/wiki?curid=11463", "title": "Francis van Aarssens", "text": "Francis van Aarssens\n\nBaron Francis van Aarssens or Baron François van Aerssen (27 September 1572 - 27 December 1641), from 1611 on lord of Sommelsdijk, was a diplomat and statesman of the United Provinces.\n\nHe was born in Brussels, the son of Cornelis van Aarsens, also a statesman. His talents commended him to the notice of Advocate Johan van Oldenbarnevelt, who sent him, at the age of 26 years, as a diplomatic agent of the states-general to the court of France. He took a considerable part in the negotiations of the Twelve Years' Truce in 1609.\n\nHis conduct of affairs having displeased the French king, he was recalled from his post by Oldenbarneveldt in 1616. Such was the hatred he henceforth conceived against his former benefactor, that he did his very utmost to effect Oldebarneveldt's ruin. He was one of the packed court of judges who in 1619 condemned the aged statesman to death. For his share in this judicial murder a deep stain rests on the memory of Aarssens.\n\nHe afterwards became the confidential counsellor of Maurice, Prince of Orange, and afterwards of Frederick Henry, Prince of Orange, in their conduct of the foreign affairs of the republic. He was sent on special embassies to Venice, Germany and England, and displayed so much diplomatic skill and finesse that Cardinal Richelieu ranked him among the three greatest politicians of his time. He died, aged 69, in The Hague.\n\n"}
{"id": "11464", "url": "https://en.wikipedia.org/wiki?curid=11464", "title": "Frigate", "text": "Frigate\n\nA frigate is any of several types of warship, the term having been used for ships of various sizes and roles over the last few centuries.\n\nIn the 17th century, this term was used for any warship built for speed and maneuverability, the description often used being \"frigate-built\". These could be warships carrying their principal batteries of carriage-mounted guns on a single deck or on two decks (with further smaller carriage-mounted guns usually carried on the forecastle and quarterdeck of the vessel). The term was generally used for ships too small to stand in the line of battle, although early line-of-battle ships were frequently referred to as frigates when they were built for speed.\n\nIn the 18th century, the term referred to ships that were usually as long as a ship of the line and were square-rigged on all three masts (full rigged), but were faster and with lighter armament, used for patrolling and escort. In the definition adopted by the British Admiralty, they were rated ships of at least 28 guns, carrying their principal armaments upon a single continuous deck — the upper deck — while ships of the line possessed two or more continuous decks bearing batteries of guns.\n\nIn the late 19th century (beginning about 1858 with the construction of prototypes by the British and French navies), the armoured frigate was a type of ironclad warship that for a time was the most powerful type of vessel afloat. The term \"frigate\" was used because such ships still mounted their principal armaments on a single continuous upper deck.\n\nIn modern navies, frigates are used to protect other warships and merchant-marine ships, especially as anti-submarine warfare (ASW) combatants for amphibious expeditionary forces, underway replenishment groups, and merchant convoys. Ship classes dubbed \"frigates\" have also more closely resembled corvettes, destroyers, cruisers, and even battleships. The rank \"frigate captain\" derives from the name of this type of ship.\n\nThe term \"frigate\" (Italian: \"fregata\"; Spanish/Catalan/Portuguese/Sicilian: \"fragata\"; Dutch: \"fregat\"; French: \"frégate\") originated in the Mediterranean in the late 15th century, referring to a lighter galleass type ship with oars, sails and a light armament, built for speed and maneuverability. The etymology of the word is unknown, although it may have originated as a corruption of \"\", a Latin word for an open vessel with no lower deck. \"Aphractus\" was, in turn, derived from the Ancient Greek phrase ἄφρακτος ναῦς (\"aphraktos naus\"), or \"undefended ship\".\n\nIn 1583, during the Eighty Years' War, Habsburg Spain recovered the Southern Netherlands from the rebellious Dutch. This soon led to the occupied ports being used as bases for privateers, the Dunkirkers, to attack the shipping of the Dutch and their allies. To achieve this they developed small, maneuverable, sailing vessels that came to be referred to as frigates. The success of these Dunkirker vessels influenced the ship design of other navies contending with them but because most regular navies required ships of greater endurance than the Dunkirker frigates could provide, the term was soon applied less exclusively to any relatively fast and elegant sail-only war ship. In French, the term \"frigate\" became a verb, meaning 'to build long and low', and an adjective, adding further confusion. Even the huge English could be described as \"a delicate frigate\" by a contemporary after her upper decks were reduced in 1651.\n\nThe navy of the Dutch Republic was the first navy to build the larger ocean-going frigates. The Dutch navy had three principal tasks in the struggle against Spain: to protect Dutch merchant ships at sea, to blockade the ports of Spanish-held Flanders to damage trade and halt enemy privateering, and to fight the Spanish fleet and prevent troop landings. The first two tasks required speed, shallowness of draft for the shallow waters around the Netherlands, and the ability to carry sufficient supplies to maintain a blockade. The third task required heavy armament, sufficient to fight against the Spanish fleet. The first of these larger battle-capable frigates were built around 1600 at Hoorn in Holland. By the later stages of the Eighty Years' War the Dutch had switched entirely from the heavier ships still used by the English and Spanish to the lighter frigates, carrying around 40 guns and weighing around 300 tons.\n\nThe effectiveness of the Dutch frigates became most visible in the Battle of the Downs in 1639, encouraging most other navies, especially the English, to adopt similar designs.\n\nThe fleets built by the Commonwealth of England in the 1650s generally consisted of ships described as \"frigates\", the largest of which were two-decker 'great frigates' of the third rate. Carrying 60 guns, these vessels were as big and capable as 'great ships' of the time; however, most other frigates at the time were used as 'cruisers': independent fast ships. The term \"frigate\" implied a long hull design, which relates directly to speed (see hull speed) and also, in turn, helped the development of the broadside tactic in naval warfare.\nAt this time, a further design evolved, reintroducing oars to create the galley frigate such as of 1676 which was rated as a 32-gun fifth rate but also had a bank of 40 oars set below the upper deck which could be used to propel the ship in the absence of a favourable wind.\n\nIn Danish, the word \"fregat\" is often applied to warships carrying as few as 16 guns, such as which the British classified as a sloop.\n\nUnder the rating system of the Royal Navy, by the middle of the 18th century, the term \"frigate\" was technically restricted to single-decked ships of the fifth rate, though small 28-gun frigates were classed as sixth rate.\n\nThe classic sailing frigate, well-known today for its role in the Napoleonic wars, can be traced back to French developments in the second quarter of the 18th century. The French-built Médée of 1740 is often regarded as the first example of this type. These ships were square-rigged and carried all their main guns on a single continuous upper deck. The lower deck, known as the \"gun deck\", now carried no armament, and functioned as a \"berth deck\" where the crew lived, and was in fact placed below the waterline of the new frigates.\n\nA total of fifty-nine French sailing frigates were built between 1777 and 1790, with a standard design averaging a hull length of and an average draught of . The new frigates recorded sailing speeds of up to , significantly faster than their predecessor vessels. They were able to fight with all their guns when the seas were so rough that comparable two-deckers had to close the gun-ports on their lower decks (see the Action of 13 January 1797, for an example when this was decisive). Like the larger 74 which was developed at the same time, the new frigates sailed well and were good fighting vessels due to a combination of long hulls and low upperworks compared to vessels of comparable size and firepower.\n\nThe Royal Navy captured a handful of the new French frigates during the War of the Austrian Succession (1740–1748) and were impressed by them, particularly for their inshore handling capabilities. They soon built copies and started to adapt the type to their own needs, setting the standard for other frigates as the leading naval power. The first British frigates carried 28 guns including an upper deck battery of twenty-four 9-pounder guns (the remaining four smaller guns were carried on the quarter deck) but soon developed into fifth-rate ships of 32 or 36 guns including an upper deck battery of twenty-six 12-pounder guns, with the remaining six or ten smaller guns carried on the quarter deck and forecastle. From around 1778, a larger \"heavy\" frigate was developed with a main battery of twenty-six or twenty-eight 18-pounder guns (again with the remaining ten smaller guns carried on the quarter deck and forecastle).\n\nBoth British and American frigates could (and usually did) additionally carry smaller carriage-mounted guns on their quarter decks and forecastles (the superstructures above the upper deck). Technically, rated ships with fewer than 28 guns could not be classed as frigates but as \"post ships\"; however, in common parlance most post ships were often described as \"frigates\", the same casual misuse of the term being extended to smaller two-decked ships that were too small to stand in the line of battle.\n\nRoyal Navy frigates of the late 18th century included the 1780-vintage \"Perseverance\" class, which measured around 900 tons burthen and carried 36 guns; this successful class was followed by numerous other classes that measured over 1,000 tons burthen and carried 38 guns.\n\nIn 1797, three of the United States Navy's first six major ships were rated as 44-gun frigates (or \"super-frigates\"), which operationally carried fifty-six to sixty 24-pounder long guns and 32-pounder or 42-pounder carronades on two decks; by all regards they were exceptionally powerful and tough. These ships were so well-armed that they were often regarded as equal to ships of the line, and after a series of losses at the outbreak of the War of 1812, Royal Navy fighting instructions ordered British frigates (usually of 38 guns or less) to never engage American frigates at any less than a 2:1 advantage. , preserved as a museum ship by the US Navy, is the oldest commissioned warship afloat, and is a surviving example of a frigate from the Age of Sail. \"Constitution\" and her sister ships and were created in a response to deal with the Barbary Coast pirates and in conjunction with the Naval Act of 1794. The three big frigates, when built, had a distinctive building pattern which minimised \"hogging\" (in which the centre of the keel rises while both ends drop) and improves hydrodynamic efficiency.\n\nThe hull was designed so that all the weight from the guns was upon the keel itself. Joshua Humphreys proposed that only live oak, a tree that grew only in America, should be used to build these ships. The method was to use diagonal riders, eight on each side that sat at a 45 degree angle. These beams of live oak were about two feet wide and around a foot thick and helped to maintain the shape of the hull, serving also to reduce flexibility and to minimize impacts. These ideas were considered revolutionary in the late 18th and early 19th century. A three-layer method was used in which the planks along the sides of the hull were laid horizontally across the frames, making a crossing or checker board pattern. The sides of the ship could be as thick as 25 inches, and were able to absorb substantial damage. The strength of this braced construction earned USS \"Constitution\" the nickname \"Old Ironsides\".\n\nFrigates were perhaps the hardest-worked of warship types during the Age of Sail. While smaller than a ship-of-the-line, they were formidable opponents for the large numbers of sloops and gunboats, not to mention privateers or merchantmen. Able to carry six months' stores, they had very long range; and vessels larger than frigates were considered too valuable to operate independently.\n\nFrigates scouted for the fleet, went on commerce-raiding missions and patrols, and conveyed messages and dignitaries. Usually, frigates would fight in small numbers or singly against other frigates. They would avoid contact with ships-of-the-line; even in the midst of a fleet engagement it was bad etiquette for a ship of the line to fire on an enemy frigate which had not fired first. Frigates were involved in fleet battles, often as \"repeating frigates\". In the smoke and confusion of battle, signals made by the fleet commander, whose flagship might be in the thick of the fighting, might be missed by the other ships of the fleet. Frigates were therefore stationed to windward or leeward of the main line of battle, and had to maintain a clear line of sight to the commander's flagship. Signals from the flagship were then repeated by the frigates, which themselves standing out of the line and clear from the smoke and disorder of battle, could be more easily seen by the other ships of the fleet. If damage or loss of masts prevented the flagship from making clear conventional signals, the repeating frigates could interpret them and hoist their own in the correct manner, passing on the commander's instructions clearly.\n\nFor officers in the Royal Navy, a frigate was a desirable posting. Frigates often saw action, which meant a greater chance of glory, promotion, and prize money.\n\nUnlike larger ships that were placed in ordinary, frigates were kept in service in peacetime as a cost-saving measure and to provide experience to frigate captains and officers which would be useful in wartime. Frigates could also carry marines for boarding enemy ships or for operations on shore; in 1832, the frigate landed a party of 282 sailors and Marines ashore in the US Navy's first Sumatran expedition.\n\nCommon armament was one gundeck with 24–30 long guns, from 8- to 24-pounders (3.6 to 11 kg), with up to a dozen light guns or carronades on the quarterdeck and forecastle above.\n\nFrigates remained a crucial element of navies until the mid-19th century. The first ironclads were classified as \"frigates\" because of the number of guns they carried. However, terminology changed as iron and steam became the norm, and the role of the frigate was assumed first by the protected cruiser and then by the light cruiser.\n\nFrigates are often the vessel of choice in historical naval novels due to their relative freedom compared to ships of the line (kept for fleet actions) and smaller vessels (generally assigned to a home port and less widely ranging). For example, the Patrick O'Brian Aubrey–Maturin series, C. S. Forester's Horatio Hornblower series and Alexander Kent's Richard Bolitho series. The motion picture \"\" features a reconstructed historic frigate, HMS \"Rose\", to depict Aubrey's frigate HMS \"Surprise\".\n\nVessels classed as frigates continued to play a great role in navies with the adoption of steam power in the 19th century. In the 1830s, navies experimented with large paddle steamers equipped with large guns mounted on one deck, which were termed \"paddle frigates\".\n\nFrom the mid-1840s on, frigates which more closely resembled the traditional sailing frigate were built with steam engines and screw propellers. These \"screw frigates\", built first of wood and later of iron, continued to perform the traditional role of the frigate until late in the 19th century.\n\nFrom 1859, armour was added to ships based on existing frigate and ship of the line designs. The additional weight of the armour on these first ironclad warships meant that they could have only one gun deck, and they were technically frigates, even though they were more powerful than existing ships-of-the-line and occupied the same strategic role. The phrase \"armoured frigate\" remained in use for some time to denote a sail-equipped, broadside-firing type of ironclad.\n\nAfter 1875, the term \"frigate\" fell out of use. Vessels with armoured sides were designated as \"battleships\" or \"armoured cruisers\", while \"protected cruisers\" only possessed an armoured deck, and unarmoured vessels, including frigates and sloops, were classified as \"unprotected cruisers\".\n\nModern frigates are related to earlier frigates only by name. The term \"frigate\" was readopted during the Second World War by the British Royal Navy to describe an anti-submarine escort vessel that was larger than a corvette, smaller than a destroyer, and about equal in size and capability to the American destroyer escort. they are usually less expensive to build and maintain. Anti-submarine escorts had previously been classified as sloops by the Royal Navy, and the s of 1939–1945 were as large as the new types of frigate, and more heavily armed. Twenty-two of these were reclassified as frigates after the war, as were the remaining 24 smaller s.\n\nThe frigate was introduced to remedy some of the shortcomings inherent in the corvette design: limited armament, a hull form not suited to open-ocean work, a single shaft which limited speed and maneuverability, and a lack of range. The frigate was designed and built to the same mercantile construction standards (scantlings) as the corvette, allowing manufacture by yards unused to warship construction. The first frigates of the (1941) were essentially two sets of corvette machinery in one larger hull, armed with the latest Hedgehog anti-submarine weapon.\n\nThe frigate possessed less offensive firepower and speed than a destroyer, but such qualities were not required for anti-submarine warfare. Submarines were slow while submerged, and ASDIC sets did not operate effectively at speeds of over . Rather, the frigate was an austere and weatherly vessel suitable for mass-construction and fitted with the latest innovations in anti-submarine warfare. As the frigate was intended purely for convoy duties, and not to deploy with the fleet, it had limited range and speed.\n\nThe contemporary German \"Flottenbegleiter\" (\"fleet escorts\"), also known as \"F-Boats\", were essentially frigates. They were based on a pre-war \"Oberkommando der Marine\" concept of vessels which could fill roles such as fast minesweeper, minelayer, merchant escort and anti-submarine vessel. Because of the Treaty of Versailles their displacement was officially limited to 600 tons, although in reality they exceeded this by about 100 tons. F-boats had two stacks and two 105 mm gun turrets. The design was flawed because of its narrow beam, sharp bow and unreliable high pressure steam turbines. F-boats were succeeded in operational duties by Type 35 and Elbing class torpedo boats. \"Flottenbegleiter\" remained in service as advanced training vessels.\n\nIt was not until the Royal Navy's of 1944 that a British design classified as a \"frigate\" was produced for fleet use, although it still suffered from limited speed. These anti-aircraft frigates, built on incomplete hulls, were similar to the United States Navy's destroyer escorts (DE), although the latter had greater speed and offensive armament to better suit them to fleet deployments. The destroyer escort concept came from design studies by the General Board of the United States Navy in 1940, as modified by requirements established by a British commission in 1941 prior to the American entry into the war, for deep-water escorts. The American-built destroyer escorts serving in the British Royal Navy were rated as Captain-class frigates. The U.S. Navy's two Canadian-built and 96 British-influenced, American-built frigates that followed originally were classified as \"patrol gunboats\" (PG) in the U.S. Navy but on 15 April 1943 were all reclassified as patrol frigates (PF).\n\nThe introduction of the surface-to-air missile after World War II made relatively small ships effective for anti-aircraft warfare: the \"guided missile frigate.\" In the USN, these vessels were called \"ocean escorts\" and designated \"DE\" or \"DEG\" until 1975 – a holdover from the World War II destroyer escort or \"DE\". The Royal Canadian Navy and British Royal Navy maintained the use of the term \"frigate\"; likewise, the French Navy refers to missile-equipped ship, up to cruiser-sized ships (, , and es), by the name of \"frégate\", while smaller units are named \"aviso\". The Soviet Navy used the term \"guard-ship\" (\"сторожевой корабль\").\n\nFrom the 1950s to the 1970s, the United States Navy commissioned ships classed as guided missile frigates (hull classification symbol DLG or DLGN, literally meaning guided missile destroyer leaders), which were actually anti-aircraft warfare cruisers built on destroyer-style hulls. These had one or two twin launchers per ship for the RIM-2 Terrier missile, upgraded to the RIM-67 Standard ER missile in the 1980s. This type of ship was intended primarily to defend aircraft carriers against anti-ship cruise missiles, augmenting and eventually replacing converted World War II cruisers (CAG/CLG/CG) in this role. The guided missile frigates also had an anti-submarine capability that most of the World War II cruiser conversions lacked. Some of these ships — and along with the and es — were nuclear-powered (DLGN). These \"frigates\" were roughly mid-way in size between cruisers and destroyers. This was similar to the use of the term \"frigate\" during the age of sail during which it referred to a medium-sized warship, but it was inconsistent with conventions used by other contemporary navies which regarded frigates as being smaller than destroyers. During the 1975 ship reclassification, the large American frigates were redesignated as guided missile cruisers or destroyers (CG/CGN/DDG), while ocean escorts (the American classification for ships smaller than destroyers, with hull symbol DE/DEG (destroyer escort)) were reclassified as frigates (FF/FFG), sometimes incorrectly called \"fast frigates\". In the late 1970s the US Navy introduced the 51-ship \"Oliver Hazard Perry\"-class guided missile frigates (FFG), the last of which was decommissioned in 2015, although some serve in other navies. By 1995 the older guided missile cruisers and destroyers were replaced by the s and s.\n\nOne of the most successful post-1945 designs was the British , which was used by several navies. Laid down in 1959, the \"Leander\"s were based on the previous Type 12 anti-submarine frigate but equipped for anti-aircraft use as well. They were used by the UK into the 1990s, at which point some were sold onto other navies. The \"Leander\" design, or improved versions of it, were licence-built for other navies as well.\n\nNearly all modern frigates are equipped with some form of offensive or defensive missiles, and as such are rated as guided-missile frigates (FFG). Improvements in surface-to-air missiles (e.g., the Eurosam Aster 15) allow modern guided-missile frigates to form the core of many modern navies and to be used as a fleet defence platform, without the need for specialised anti-air warfare frigates.\n\nThe Royal Navy Type 61 \"Salisbury\" class were \"air direction\" frigates equipped to track aircraft. To this end they had reduced armament compared to the Type 41 \"Leopard\"-class air-defence frigates built on the same hull.\n\nMulti-role frigates like the MEKO 200, and es are designed for navies needing warships deployed in a variety of situations that a general frigate class would not be able to fulfill and not requiring the need for deploying destroyers.\n\nAt the opposite end of the spectrum, some frigates are specialised for anti-submarine warfare. Increasing submarine speeds towards the end of World War II (see German Type XXI submarine) greatly reduced the margin of speed superiority of frigate over submarine. The frigate could no longer be slow and powered by mercantile machinery and consequently postwar frigates, such as the \"Whitby\" class, were faster.\n\nSuch ships carry improved sonar equipment, such as the variable depth sonar or towed array, and specialised weapons such as torpedoes, forward-throwing weapons such as Limbo and missile-carried anti-submarine torpedoes such as ASROC or Ikara. Surface-to-air missiles such as Sea Sparrow and surface-to-surface missiles such as Exocet give them defensive and offensive capabilities. The Royal Navy's original Type 22 frigate is an example of a specialised anti-submarine warfare frigate.\n\nEspecially for anti-submarine warfare, most modern frigates have a landing deck and hangar aft to operate helicopters, eliminating the need for the frigate to close with unknown sub-surface threats, and using fast helicopters to attack nuclear submarines which may be faster than surface warships. For this task the helicopter is equipped with sensors such as sonobuoys, wire-mounted dipping sonar and magnetic anomaly detectors to identify possible threats, and torpedoes or depth-charges to attack them.\n\nWith their onboard radar helicopters can also be used to reconnoitre over-the-horizon targets and, if equipped with anti-ship missiles such as Penguin or Sea Skua, to attack them. The helicopter is also invaluable for search and rescue operation and has largely replaced the use of small boats or the jackstay rig for such duties as transferring personnel, mail and cargo between ships or to shore. With helicopters these tasks can be accomplished faster and less dangerously, and without the need for the frigate to slow down or change course.\n\nStealth technology has been introduced in modern frigate design. Frigate shapes are designed to offer a minimal radar cross section, which also lends them good air penetration; the maneuverability of these frigates has been compared to that of sailing ships. Examples are the French with the Aster 15 missile for anti-missile capabilities, the German and s, the Turkish type frigates with the MK-41 VLS, and the Indian and es with the Brahmos missile system.\n\nThe modern French Navy applies the term first-class frigate and second-class frigate to both destroyers and frigates in service. Pennant numbers remain divided between F-series numbers for those ships internationally recognised as frigates and D-series pennant numbers for those more traditionally recognised as destroyers. This can result in some confusion as certain classes are referred to as frigates in French service while similar ships in other navies are referred to as destroyers. This also results in some recent classes of French ships being among the largest in the world to carry the rating of frigate.\n\nIn the German Navy, frigates were used to replace aging destroyers; however in size and role the new German frigates exceed the former class of destroyers. The future German F125-class frigate will be the largest class of frigates worldwide with a displacement of more than 7,200 tons. The same was done in the Spanish Navy, which went ahead with the deployment of the first Aegis frigates, the s.\n\nSome new classes of ships similar to corvettes are optimized for high-speed deployment and combat with small craft rather than combat between equal opponents; an example is the U.S. Littoral Combat Ship (LCS). As of 2015, all s in the United States Navy have been decommissioned, and their role partially being assumed by the new LCS. While the LCS class ships are smaller than the frigate class they will replace, they offer a similar degree of weaponry while requiring less than half the crew complement and offering a top speed of over . A major advantage for the LCS ships is that they are designed around specific mission modules allowing them to fulfill a variety of roles. The modular system also allows for most upgrades to be performed ashore and installed later into the ship, keeping the ships available for deployment for the maximum time.\n\nThe latest U.S. deactivation plans means that this is the first time that the U.S. Navy has been without a frigate class of ships since 1943 (technically is rated as a frigate and is still in commission, but does not count towards Navy force levels).\n\nThe remaining 20 LCSs to be acquired from 2019 and onwards that will be enhanced will be designated as frigates, and existing ships given modifications may also have their classification changed to \"FF\" as well.\n\nA few nations have frigates on display as museum ships. They are:\n\n\n\n\n\n\n\n\nNote that Algerian, Tripolitan and Tunisian sail frigates are listed under Turkey. All Italian city-state frigates are listed under Italy.\n\n\n\n"}
{"id": "11466", "url": "https://en.wikipedia.org/wiki?curid=11466", "title": "Francisco Franco", "text": "Francisco Franco\n\nFrancisco Franco Bahamonde (; 4 December 1892 – 20 November 1975) was a Spanish general who ruled over Spain as a military dictator for 36 years from 1939 until his death.\n\nAs a conservative and a monarchist, he opposed the abolition of the monarchy and the establishment of a republic in 1931. With the 1936 elections, the conservative Spanish Confederation of Autonomous Right-wing Groups lost by a narrow margin and the leftist Popular Front came to power. Intending to overthrow the republic, Franco followed other generals in attempting a failed coup that precipitated the Spanish Civil War. With the death of the other generals, Franco quickly became his faction's only leader.\n\nFranco gained military support from various regimes and groups, especially Nazi Germany and Fascist Italy, while the Republican side was supported by Spanish communists and anarchists as well as the Soviet Union, Mexico and the International Brigades. Franco personally requested the Bombing of Guernica in 1937. Franco won the war, which claimed half a million lives, in 1939. He established a military dictatorship, which he defined as a totalitarian state. Franco proclaimed himself Head of State and Government under the title \"El caudillo\", a term similar to \"Il duce\" (Italian) for Benito Mussolini and \"Der Führer\" (German) for Adolf Hitler. In April 1937, Franco merged the fascist and traditionalist political parties in the rebel zone, as well as other conservative and monarchist elements, into FET y de las JONS, outlawing the rest of political parties, thus Spain became a one-party state.\n\nUpon his rise to power, Franco implemented policies that were responsible for the repression and deaths of as many as 400,000 political opponents and dissenters, through the use of forced labor and executions in the concentration camps his regime operated. Despite maintaining an official policy of neutrality during World War II, he provided military support to the Axis in numerous ways; he allowed German and Italian ships to use Spanish harbors and ports, the Abwehr gained intelligence in Spain on Allied activities, and the Blue Division fought alongside the European Axis against the Soviet Union until 1944. Communists at the time and popular critics on the left called his regime \"fascist\", but academics typically categorize it as conservative and authoritarian. Spain was isolated by the international community for nearly a decade after World War II. By the 1950s, the nature of his regime changed from being openly totalitarian and using severe repression to a more authoritarian system with limited pluralism. During the Cold War, Franco appeared as one of the world's foremost anti-Communist figures; his regime was assisted by the West and it was asked to join NATO. By the 1960s, Spain saw incremental reforms and progressive economic development.\n\nFranco died in 1975 at the age of 82. He restored the monarchy before his death, which made King Juan Carlos I his successor, who led the Spanish transition to democracy. After a referendum, a new constitution was adopted, which transformed Spain into a parliamentary democracy under a constitutional monarchy.\n\nA highly controversial figure within Europe and abroad, Franco is seen as a divisive leader. Supporters credit his strong anti-communist views, preservation of traditional Spanish practices and support of the Monarchy of Spain as positive influences over the nation. Critics disparage him as an autocratic dictator who violently suppressed opposition and dissent, banned culture seen as non-Spanish, and provided much support to the Axis Powers during World War II.\n\nFranco was born at half past noon on December 4, 1892, at 108 Calle Frutos Saavedra in Ferrol, Galicia. He was baptised thirteen days later at the military church of San Francisco, with the baptismal name Francisco Paulino Hermenegildo Teódulo; Francisco for his paternal grandfather, Paulino for his godfather, Hermenegildo for his maternal grandmother and godmother, and Teódulo for the saint day of his birth.\n\nHis father was of Andalusian ancestry. After relocating to Galicia, the family was strongly involved in the Spanish Navy, and over the span of two centuries produced naval officers for six uninterrupted generations, down to Franco's father Nicolás Franco y Salgado Araújo (November 22, 1855 – February 22, 1942).\n\nHis mother was María del Pilar Bahamonde y Pardo de Andrade (1865 – February 28, 1934) and she was an upper middle-class Roman Catholic. His parents married in 1890. The young Franco spent much of his childhood with his two brothers, Nicolás (Ferrol, 1891–1977) and Ramón, and his two sisters, María del Pilar (Ferrol, 1894 – Madrid, 1989), and María de la Paz (Ferrol, 1899 – Ferrol, 1903). The latter died in infancy. Nicolás was later a naval officer and diplomat who in time married María Isabel Pascual del Pobil y Ravello. Ramón was a pioneer aviator, a Freemason with originally leftist political leanings who was killed in an air accident on a military mission in 1938. María del Pilar married Alonso Jaráiz y Jeréz.\n\nFrancisco was to follow his father into the Navy, but as a result of the Spanish–American War the country lost much of its navy as well as most of its colonies. Not needing any more officers, the Naval Academy admitted no new entrants from 1906 to 1913. To his father's chagrin, Francisco decided to try the Spanish Army. In 1907, he entered the Infantry Academy in Toledo, graduating in 1910 as a lieutenant. Two years later, he obtained a commission to Morocco. Spanish efforts to occupy their new African protectorate provoked the protracted Rif War (from 1909 to 1927) with native Moroccans. Their tactics resulted in heavy losses among Spanish military officers, and also provided an opportunity to earn promotion through merit. It was said that officers would receive either \"la caja o la faja\" (a coffin or a general's sash). Franco quickly gained a reputation as a good officer. In 1913, Franco transferred into the newly formed regulares: Moroccan colonial troops with Spanish officers, who acted as shock troops. This transfer into a perilous role may have been decided because Franco failed to win the hand of his first love, Sofía Subirán. (The letters between the two were found and she was questioned by journalists.)\n\nIn 1916, aged 23 and already a captain, he was shot by enemy machine gun fire. He was badly wounded in the abdomen, specifically the liver, in a skirmish at \"El Biutz\" and possibly lost a testicle. The physicians of the battle later concluded that his intestines were spared because he inhaled the moment he was shot. His survival marked him permanently in the eyes of the native troops as a man of \"baraka\" (good luck). He was recommended for Spain's highest honour for gallantry, the coveted \"Cruz Laureada de San Fernando\", but instead received the \"Cross of Maria Cristina, First Class\". With that he was promoted to major at the end of February 1917. This made him the youngest major in the Spanish army. From 1917 to 1920, he served in Spain. In 1920, Lieutenant Colonel José Millán Astray, a histrionic but charismatic officer, founded the Spanish Foreign Legion, on similar lines to the French Foreign Legion. Franco became the Legion's second-in-command and returned to Africa. On July 24, 1921, the poorly commanded and overextended Spanish Army suffered a crushing defeat at Annual from Rif tribesmen led by the Abd el-Krim brothers. The Legion and supporting units relieved the Spanish enclave of Melilla after a three-day forced march led by Franco. In 1923, by now a lieutenant colonel, he was made commander of the Legion.\n\nThat year, he married María del Carmen Polo y Martínez-Valdès. Three years later the couple had a daughter, María del Carmen. Following his honeymoon Franco was summoned to Madrid to be presented to King Alfonso XIII. This and other occasions of royal attention would mark him during the Republic as a monarchical officer. Promoted to colonel, Franco led the first wave of troops ashore at Al Hoceima in 1925. This landing in the heartland of Abd el-Krim's tribe, combined with the French invasion from the south, spelled the beginning of the end for the short-lived Republic of the Rif. Franco's recognition eventually caught up with him and he was promoted to brigadier general on February 3, 1926. This made him the youngest general in Spain, and perhaps the youngest general of Europe. In 1928 Franco was appointed director of the newly created General Military Academy of Zaragoza, a new college for all army cadets, replacing the former separate institutions for young men seeking to become officers in infantry, cavalry, artillery, and other branches of the army. Franco was removed as Director of the Zaragoza Military Academy in 1931; about 95% of his former Zaragoza cadets later came to side with him in the Civil War.\n\nWith the fall of the monarchy in 1931, Franco did not take any notable stand. But the closing of the Academy in June by War Minister Manuel Azaña provoked his first clash with the Spanish Republic. Azaña found Franco's farewell speech to the cadets insulting. Franco stressed in his speech the Republic's need for discipline and respect. For six months Franco was without a post and under surveillance.\n\nFranco was a subscriber to the journal of Acción Española, a monarchist organisation, and a firm believer in the Jewish-Masonic-Bolshevik conspiracy or \"contubernio\" (filthy cohabitation)—'one of Franco's favourite words'; a conspiracy in which Jews, Freemasons, Communists, and other leftists alike allegedly sought the destruction of Christian Europe, with Spain the principal target.\n\nOn February 5, 1932, he was given a command in A Coruña. Franco avoided involvement in José Sanjurjo's attempted coup that year, and even wrote a hostile letter to Sanjurjo expressing his anger over the attempt. As a side result of Azaña's military reform, in January 1933, Franco was relegated from the first to the 24th in the list of brigadiers; the same year, on February 17, he was given the military command of the Balearic Islands: a post above his rank, but Franco was still angered that he was purposely stuck in the positions he didn't want to be. Yet it was quite common for the Conservative Officers to be moved or demoted.\n\nNew elections held in October 1933 resulted in a centre-right majority. In opposition to this government, a revolutionary communist/anarchist movement broke out on October 5, 1934. This uprising was rapidly quelled in most of the country, but gained a stronghold in Asturias, with the support of the miners' unions. Franco, already General of Division and aide to the war minister, Diego Hidalgo, was put in command of the operations directed to suppress the insurgency. Troops of the Spanish Army of Africa carried this out, with General Eduardo López Ochoa as commander in the field. After two weeks of heavy fighting (and a death toll estimated between 1,200 and 2,000), the rebellion was suppressed.\n\nThe insurgency in Asturias (see Asturian miners' strike of 1934) sharpened the antagonism between Left and Right. Franco and López Ochoa (who, prior to the campaign in Asturias, had been seen as a left-leaning officer) emerged as officers prepared to use 'troops against Spanish civilians as if they were a foreign enemy'. Franco described the rebellion to a journalist in Oviedo as, 'a frontier war and its fronts are socialism, communism and whatever attacks civilisation in order to replace it with barbarism.' Though the colonial units sent to the north by the government at Franco's recommendation consisted of the Spanish Foreign Legion and the Moroccan Regulares Indigenas, the right wing press portrayed the Asturian rebels as lackeys of a foreign Jewish-Bolshevik conspiracy. At the start of the Civil War, López Ochoa was assassinated. Some time after these events, Franco was briefly commander-in-chief of the Army of Africa (from February 15 onwards), and from May 19, 1935, on, Chief of the General Staff.\n\nAfter the ruling centre-right coalition collapsed amid the Straperlo corruption scandal, new elections were scheduled. Two wide coalitions formed: the Popular Front on the left, ranging from Republican Union to Communists, and the Frente Nacional on the right, ranging from the centre radicals to the conservative Carlists. On February 16, 1936, the left won by a narrow margin. Growing political bitterness surfaced again. The government and its supporters, the Popular Front, had launched a campaign against the Opposition whom they accused of plotting against the Republic. According to the right-wing opposition, the real enemies of the Republic were not on the Right but on the Left; Spain was in imminent danger of falling under a \"Communist dictatorship\", and therefore by fighting the democratically elected Popular Front, they were merely doing their duty in defense of law and order and of the freedom and the fundamental rights of the Spanish people.\n\nOn February 23 Franco was sent to the Canary Islands to serve as the islands' military commander, an appointment perceived by him as a \"destierro\" (banishment). Meanwhile, a conspiracy led by Emilio Mola was taking shape. In June, Franco was contacted and a secret meeting was held within the forest of La Esperanza on Tenerife to discuss starting a military coup. An obelisk commemorating this historic meeting was erected at the site in a clearing at Las Raíces.\n\nOutwardly Franco maintained an ambiguous attitude almost until July. On June 23, 1936, he wrote to the head of the government, Casares Quiroga, offering to quell the discontent in the Spanish Republican Army, but received no reply. The other rebels were determined to go ahead \"con Paquito o sin Paquito\" (with \"Paquito\" or without \"Paquito\"; \"Paquito\" being a diminutive of \"Paco\", which in turn is short for \"Francisco\"), as it was put by José Sanjurjo, the honorary leader of the military uprising. After various postponements, July 18 was fixed as the date of the uprising. The situation reached a point of no return and, as presented to Franco by Mola, the coup was unavoidable and he had to choose a side. He decided to join the rebels and was given the task of commanding the Army of Africa. A privately owned DH 89 De Havilland Dragon Rapide, flown by two British pilots, Cecil Bebb and Hugh Pollard, was chartered in England on July 11 to take Franco to Africa.\n\nThe assassination of the right-wing opposition leader José Calvo Sotelo by government police troops, possibly in retaliation for the murder of José Castillo, precipitated the uprising. On July 17, one day earlier than planned, the African Army rebelled, detaining their commanders. On July 18, Franco published a manifesto and left for Africa, where he arrived the next day to take command.\n\nA week later the rebels, who soon called themselves the \"Nationalists\", controlled a third of Spain; however most naval units remained under control of the Republican loyalist forces, which left Franco isolated. The coup had failed in the attempt to bring a swift victory, but the Spanish Civil War had begun.\n\nThe Spanish Civil War began in July 1936 and officially ended with Franco's victory in April 1939, leaving 190,000 to 500,000 dead. Despite the Non-Intervention Agreement of August 1936, the war was marked by foreign intervention on behalf of both sides, leading to international repercussions. The nationalist side was supported by Fascist Italy, which sent the \"Corpo Truppe Volontarie\", and later by Nazi Germany, which assisted with the Condor Legion. They were opposed by the Soviet Union and communist, socialists and anarchists within Spain. The United Kingdom and France strictly adhered to the arms embargo, provoking dissensions within the French Popular Front coalition led by Léon Blum, but the Republican side was nonetheless supported by the Soviet Union and volunteers fighting in the International Brigades (see for example Ken Loach's \"Land and Freedom\").\n\nBecause Adolf Hitler and Joseph Stalin used the war as a testing ground for modern warfare, some historians, such as Ernst Nolte, have considered the Spanish Civil War, along with World War II, part of a European Civil War lasting from 1936 to 1945 and characterised mainly as a left/right ideological conflict. This interpretation has not found acceptance among most historians, who consider the Spanish Civil War and Second World War to be two distinct conflicts. Among other things, they point to the political heterogeneity on both sides (\"See Spanish Civil War: other factions\") and criticise a monolithic interpretation which overlooks the local nuances of Spanish history.\n\nFollowing July 18, 1936 \"pronunciamiento\", Franco assumed the leadership of the 30,000 soldiers of the Spanish Army of Africa. The first days of the insurgency were marked with a serious need to secure control over the Spanish Moroccan Protectorate. On one side, Franco had to win the support of the natives and their (nominal) authorities, and, on the other, had to ensure his control over the army. His method was the summary execution of some 200 senior officers loyal to the Republic (one of them his own cousin). His loyal bodyguard was shot by Manuel Blanco. Franco's first problem was how to move his troops to the Iberian Peninsula, since most units of the Navy had remained in control of the Republic and were blocking the Strait of Gibraltar. He requested help from Benito Mussolini, who responded with an unconditional offer of arms and planes; in Germany Wilhelm Canaris, the head of the \"Abwehr\" military intelligence, persuaded Hitler to support the Nationalists. From July 20 onward Franco was able, with a small group of 22 mainly German Junkers Ju 52 aircraft, to initiate an air bridge to Seville, where his troops helped to ensure the rebel control of the city. Through representatives, he started to negotiate with the United Kingdom, Germany, and Italy for more military support, and above all for more aircraft. Negotiations were successful with the last two on July 25 and aircraft began to arrive in Tetouan on August 2. On August 5 Franco was able to break the blockade with the newly arrived air support, successfully deploying a ship convoy with some 2,000 soldiers.\n\nIn early August, the situation in western Andalusia was stable enough to allow him to organise a column (some 15,000 men at its height), under the command of then Lieutenant-Colonel Juan Yagüe, which would march through Extremadura towards Madrid. On August 11 Mérida was taken, and on August 15 Badajoz, thus joining both nationalist-controlled areas. Additionally, Mussolini ordered a voluntary army, the \"Corpo Truppe Volontarie\" (CTV) of some 12,000 Italians of fully motorised units to Seville and Hitler added to them a professional squadron from the Luftwaffe (2JG/88) with about 24 planes. All these planes had the Nationalist Spanish insignia painted on them, but were flown by Italian and German nationals. The backbone of Franco's aviation in those days were the Italian SM.79 and SM.81 bombers, the biplane Fiat CR.32 fighter and the German Junkers Ju 52 cargo-bomber and the Heinkel He 51 biplane fighter.\n\nOn September 21, with the head of the column at the town of Maqueda (some 80 km away from Madrid), Franco ordered a detour to free the besieged garrison at the Alcázar of Toledo, which was achieved on September 27. This controversial decision gave the Popular Front time to strengthen its defenses in Madrid and hold the city that year, but the holding of Alcázar was an important morale and propaganda success for the Nationalists.\n\nThe designated leader of the uprising, General José Sanjurjo, died on July 20, 1936, in a plane crash. Therefore, in the nationalist zone, \"Political life ceased.\" Initially, only military command mattered; this was divided into regional commands (Emilio Mola in the North, Gonzalo Queipo de Llano in Seville commanding Andalusia, Franco with an independent command and Miguel Cabanellas in Zaragoza commanding Aragon). The Spanish Army of Morocco itself was split into two columns, one commanded by General Juan Yagüe and the other commanded by Colonel José Varela.\n\nFrom July 24 a coordinating \"junta\" was established, based at Burgos. Nominally led by Cabanellas, as the most senior general, it initially included Mola, three other generals, and two colonels; Franco was later added in early August. On September 21 it was decided that Franco was to be commander-in-chief (this unified command was opposed only by Cabanellas), and, after some discussion, with no more than a lukewarm agreement from Queipo de Llano and from Mola, also head of government. He was, doubtlessly, helped to this primacy by the fact that, in late July, Hitler had decided that all of Germany's aid to the nationalists would go to Franco.\n\nMola had been somewhat discredited as the main planner of the attempted coup that had now degenerated into a civil war, and was strongly identified with the Carlist monarchists and not at all with the Falange, a party with Fascist leanings and connections (\"phalanx\", a far-right Spanish political party founded by The 3rd Marqués de Estella), nor did he have good relations with Germany; Queipo de Llano and Cabanellas had both previously rebelled against the dictatorship of General The 2nd Marqués de Estella and were therefore discredited in some nationalist circles; and Falangist leader The 3rd Marqués de Estella was in prison in Alicante (he would be executed a few months later) and the desire to keep a place open for him prevented any other Falangist leader from emerging as a possible head of state. Franco's previous aloofness from politics meant that he had few active enemies in any of the factions that needed to be placated, and also he had cooperated in recent months with both Germany and Italy.\n\nOn October 1, 1936, in Burgos, Franco was publicly proclaimed as \"Generalísimo\" of the National army and \"Jefe del Estado\" (Head of State). When Mola was killed in another air accident a year later (which some believe was an assassination) (June 2, 1937), no military leader was left from those who organised the conspiracy against the Republic between 1933 and 1935.\n\nFranco personally guided military operations from this time until the end of the war. After the failed assault on Madrid in November 1936, Franco settled on a piecemeal approach to winning the war, rather than bold maneuvering. As with his decision to relieve the garrison at Toledo, this approach has been subject of some debate; some of his decisions, such as in June 1938 when he preferred to head for Valencia instead of Catalonia, remain particularly controversial from a military viewpoint. However, Valencia, Castellon and Alicante saw the last Republican troops defeated by Franco.\n\nAlthough both Germany and Italy provided military support to Franco, the degree of influence of both powers on his direction of the war seems to have been very limited. Nevertheless, the Italian troops, despite not being always effective, were present in most of the large operations in large numbers, while the German aircraft helped the Nationalist air force dominate the skies for most of the war. The Portuguese dictator Salazar also openly assisted the Nationalists from the start, contributing with 20,000 troops.\n\nFranco's direction of the German and Italian forces was limited, particularly in the direction of the Condor Legion, but he was by default their supreme commander, and they rarely made decisions on their own. For reasons of prestige it was decided to continue assisting Franco until the end of the war, and Italian and German troops paraded on the day of the final victory in Madrid.\n\nFrom 1937 to 1948 the Franco regime was a hybrid as Franco fused the ideologically incompatible national-syndicalist Falange (\"Phalanx\", a fascist Spanish political party founded by The 3rd Marqués de Estella) and the Carlist monarchist parties into one party under his rule, dubbed \"Falange Española Tradicionalista y de las Juntas de Ofensiva Nacional-Sindicalista\" (FET y de las JONS), which became the only legal party in 1939. Unlike some other fascist movements, the Falangists had developed an official program in 1934, the \"Twenty-Seven Points\". In 1937, Franco assumed as the tentative doctrine of his regime 26 out of the original 27 points. Franco made himself \"jefe nacional\" (National Chief) of the new FET (\"Falange Española Tradicionalista\"; Traditionalist Spanish Phalanx) with a secretary, Junta Political and National Council to be named subsequently by himself. Five days later (April 24) the raised-arm salute of the Falange was made the official salute of the Nationalist regime. In 1939 the personalist style heavily predominated, with ritualistic invocations of \"Franco, Franco, Franco.\" The Falangists' hymn, \"Cara al Sol\", became the semi-national anthem of Franco's not-yet-established regime.\n\nThis new political formation appeased the pro-German Falangists while tempering them with the anti-German Carlists. Franco's brother-in-law Ramón Serrano Súñer, who was his main political advisor, was able to turn the various parties under Franco against each other to absorb a series of political confrontations against Franco himself. Franco expelled the original leading members of both the Carlists (Manuel Fal Condé) and the Falangists (Manuel Hedilla) to secure his political future. Franco also appeased the Carlists by exploiting the Republicans' anti-clericalism in his propaganda, in particular concerning the \"Martyrs of the war\". While the loyalist forces presented the war as a struggle to defend the Republic against Fascism, Franco depicted himself as the defender of \"Catholic Spain\" against \"atheist Communism.\"\n\nBy early 1939 only Madrid (see History of Madrid) and a few other areas remained under control of the government forces. On February 27 Chamberlain's Britain and Daladier's France officially recognised the Franco regime. On March 28, 1939, with the help of pro-Franco forces inside the city (the \"fifth column\" General Mola had mentioned in propaganda broadcasts in 1936), Madrid fell to the Nationalists. The next day, Valencia, which had held out under the guns of the Nationalists for close to two years, also surrendered. Victory was proclaimed on April 1, 1939, when the last of the Republican forces surrendered. On the same day, Franco placed his sword upon the altar of a church and in a vow, promised that he would never again take up his sword unless Spain itself was threatened with invasion.\n\nAt least 70,000 people were executed during the civil war. Franco's victory was followed by thousands of summary executions (from 15,000 to 25,000 people) and imprisonments, while many were put to forced labour, building railways, drying out swamps, digging canals (\"La Corchuela\", the Canal of the Bajo Guadalquivir), construction of the Valle de los Caídos monument, etc. The 1940 shooting of the president of the Catalan government, Lluís Companys, was one of the most notable cases of this early suppression of opponents and dissenters. According to Gabriel Jackson, the number of victims of the \"White Terror\" (executions and hunger or illness in prisons) only between 1939 and 1943 was 200,000.\n\nLeftists suffered a high death toll. The Spanish intelligentsia and atheists were also targeted for liquidation, as well as military and government figures who had remained loyal to the Madrid government during the civil war.\n\nIn his history of the Spanish Civil War, Antony Beevor \"reckons Franco's ensuing 'white terror' claimed 200,000 lives. The 'red terror' had already killed 38,000.\" Julius Ruiz concludes that \"although the figures remain disputed, a minimum of 37,843 executions were carried out in the Republican zone with a maximum of 150,000 executions (including 50,000 after the war) in Nationalist Spain.\"\n\nDespite the official end of the war, guerrilla resistance to Franco (known as \"the \"maquis\"\") was widespread in many mountainous regions, and continued well into the 1950s. In 1944, a group of republican veterans, which also fought in the French resistance against the Nazis, invaded the Val d'Aran in northwest Catalonia, but they were quickly defeated.\n\nThe end of the war led to hundreds of thousands of exiles, mostly to France (but also Mexico, Chile, Cuba, the USA and so on.). On the other side of the Pyrenees, refugees were confined in internment camps of the French Third Republic, such as Camp Gurs or Camp Vernet, where 12,000 Republicans were housed in squalid conditions (mostly soldiers from the Durruti Division). The 17,000 refugees housed in Gurs were divided into four categories (Brigadists, pilots, \"Gudaris\" and ordinary 'Spaniards'). The \"Gudaris\" (Basques) and the pilots easily found local backers and jobs, and were allowed to quit the camp, but the farmers and ordinary people, who could not find relations in France, were encouraged by the Third Republic, in agreement with the Francoist government, to return to Spain. The great majority did so and were turned over to the Francoist authorities in Irún. From there they were transferred to the Miranda de Ebro camp for \"purification\" according to the Law of Political Responsibilities.\n\nAfter the proclamation by Marshal Philippe Pétain of the Vichy France regime, the refugees became political prisoners, and the French police attempted to round up those who had been liberated from the camp. Along with other \"undesirables\", they were sent to the Drancy internment camp before being deported to Nazi Germany. 5,000 Spaniards thus died in Mauthausen concentration camp. The Chilean poet Pablo Neruda, who had been named by the Chilean President Pedro Aguirre Cerda special consul for immigration in Paris, was given responsibility for what he called \"the noblest mission I have ever undertaken\": shipping more than 2,000 Spanish refugees, who had been housed by the French in squalid camps, to Chile on an old cargo ship, the \"Winnipeg\".\n\nIn September 1939 World War II began. On October 23, 1940, Hitler and Franco met in Hendaye in France to discuss the possibility of Spain's entry on the side of the Axis. However, Franco's demands, including supplies of food and fuel, as well as Spanish control of Gibraltar and French North Africa, proved too much for Hitler. At the time Hitler did not want to risk damaging his relations with the new Vichy French government. (An oft-cited remark attributed to Hitler is that the German leader said that he would rather have some of his own teeth extracted than to have to personally deal further with Franco.) Franco had received important support from Adolf Hitler and Benito Mussolini during the Spanish Civil War, and he had signed the Anti-Comintern Pact. He described Spain as part of the Axis in official documents, while offering various kinds of support to Italy and Germany. He allowed Spanish soldiers to volunteer to fight in the German Army against the USSR (the Blue Division), but forbade Spaniards to fight in the West against the democracies. Franco's common ground with Hitler was particularly weakened by Hitler's propagation of Nazi mysticism and his attempts to manipulate Christianity, which went against Franco's fervent commitment to defending Catholicism. Contributing to the disagreement was an ongoing dispute over German mining rights in Spain. Some historians argue that Franco made demands he knew Hitler would not accede to in order to stay out of the war. Other historians argue that Franco, as the leader of a destroyed and bankrupt country in chaos following a brutal three-year civil war, simply had little to offer the Axis and that the Spanish armed forces were not ready for a major war.\n\nYet, after the Fall of France in June 1940, Spain did adopt a pro-Axis stance (for example, German and Italian ships and U-boats were allowed to use Spanish naval facilities) before returning to a more neutral position in the autumn of 1943 when the tide of the war had turned decisively against the Axis Powers, and Italy had switched sides. Franco was initially keen to join the war before the UK was defeated. In the winter of 1940–41 Franco toyed with the idea of a \"Latin Bloc\" formed by Spain, Portugal, Vichy France, the Vatican and Italy, without much consequence. Franco seriously considered blocking allied access to the Mediterranean Sea by invading British-controlled Gibraltar, but he abandoned the idea after learning that the plan would have likely failed due to Gibraltar being too heavily defended, and it would have given the British the grounds to declare war on Spain and thus give the UK and its allies an excellent opportunity to take both the Canary Islands and Spanish Morocco, as well as possibly invade mainland Spain itself. Franco was aware that his air force would not be able to protect Spanish cities from attacks by the British Royal Air Force, and the British Royal Navy would be able to blockade Spain to prevent imports of crucial materials such as oil. Spain depended on oil imports from the United States, which were almost certain to be cut off if Spain formally joined the Axis. Franco and Serrano Suñer held a meeting with Mussolini and Ciano in Bordighera, Italy on February 12, 1941. Mussolini affected not to be interested in Franco's help due to the defeats his forces had suffered in North Africa and the Balkans, and he even told Franco that he wished he could find any way to leave the war. When the invasion of the Soviet Union began on June 22, 1941, Franco's foreign minister Ramón Serrano Suñer immediately suggested the formation of a unit of military volunteers to join the invasion. Volunteer Spanish troops (the \"División Azul\", or \"Blue Division\") fought on the Eastern Front under German command from 1941 to 1944. Some historians have argued that not all of the Blue Division were true volunteers and that Franco expended relatively small but significant resources to aid the Axis powers' battle against the Soviet Union.\n\nFranco was initially disliked by Cuban President Fulgencio Batista, who, during World War II, suggested a joint U.S.-Latin American declaration of war on Spain in order to overthrow Franco's regime. Hitler may not have really wanted Spain to join the war, as he needed neutral harbors to import materials from countries in Latin America and elsewhere. In addition Hitler felt Spain would be a burden as it would be dependent on Germany for help. By 1941 Vichy French forces were proving their effectiveness in North Africa, reducing the need for Spanish help, and Hitler was wary about opening up a new front on the western coast of Europe as he struggled to reinforce the Italians in Greece and Yugoslavia. Franco signed a revised Anti-Comintern Pact on November 25, 1941.\n\nAfter the war, the Spanish government tried to destroy all evidence of its cooperation with the Axis. However, in 2010 documents were discovered showing that on May 13, 1941, Franco ordered his provincial governors to compile a list of Jews while he sided and made an alliance with the Axis powers. Franco supplied Reichsführer-SS Heinrich Himmler, architect of the Nazis' Final Solution, with a list of 6,000 Jews in Spain. Despite the creation of the list, there is no evidence of any Jew seeking refuge from Germany being sent back to Germany. Although Franco made occasional negative references to Jews, he had Jewish friends in Morocco and even publicly stopped an outbreak of discrimination against Jews there. When Franco became dictator, no official attacks on Jews were ever countenanced by his government, nor did he ever hand Jews over to Germany. Spanish Jews in the army served Franco with the same conditions as anyone else. Furthermore, Spanish diplomats extended their diplomatic protection over Jews in Hungary, Czechoslovakia and the Balkans.\n\nOn June 14, 1940, Spanish forces in Morocco occupied Tangier (a city under the rule of the League of Nations) and did not leave it until the war's end in 1945.\n\nFranco was recognised as the Spanish head of state by Great Britain and France in February 1939. Already proclaimed \"Generalísimo\" of the Nationalists and \"Jefe del Estado\" (Head of State) in October 1936, he thereafter assumed the official title of \"\"Su Excelencia el Jefe de Estado\"\" (\"His Excellency the Head of State\"). However, he was also referred to in state and official documents as \"\"Caudillo de España\"\" (\"the Leader of Spain\"), and sometimes called \"\"el Caudillo de la Última Cruzada y de la Hispanidad\"\" (\"the Leader of the Last Crusade and of the Hispanic heritage\") and \"\"el Caudillo de la Guerra de Liberación contra el Comunismo y sus Cómplices\"\" (\"the Leader of the War of Liberation Against Communism and Its Accomplices\").\n\nIn 1947 Franco proclaimed Spain a monarchy, but did not designate a monarch. This gesture was largely done to appease the monarchists in the \"Movimiento Nacional\" (Carlists and Alfonsists). Franco left the throne vacant until 1969, proclaiming himself as a \"de facto\" regent for life. At the same time, Franco appropriated many of the privileges of a king. He wore the uniform of a Captain General (a rank traditionally reserved for the King) and resided in El Pardo Palace. In addition he began walking under a canopy, and his portrait appeared on most Spanish coins and postage stamps. He also added \"by the grace of God\", a phrase usually part of the styles of monarchs, to his style.\n\nFranco initially sought support from various groups. His administration marginalised fascist ideologues in favor of technocrats, many of whom were linked with Opus Dei, who promoted economic modernisation.\n\nAlthough Franco and Spain under his rule adopted some trappings of fascism, he, and Spain under his rule, are generally not considered to be fascist; among the distinctions, fascism entails a revolutionary aim to transform society, where Franco did not seek to do so, and, to the contrary, although authoritarian, he was by nature conservative and traditional. Stanley Payne notes: \"scarcely any of the serious historians and analysts of Franco consider the generalissimo to be a core fascist\". The few consistent points in Franco's long rule were above all authoritarianism, nationalism, Catholicism, anti-Freemasonry, and anti-Communism.\n\nThe aftermath of the Civil War was socially bleak: many of those who had supported the Republic fled into exile. Spain lost thousands of doctors, nurses, teachers, lawyers, judges, professors, businessmen, artists, etc. Many of those who had to stay lost their jobs or lost their rank. Sometimes those jobs were given to unskilled and even untrained personnel. This deprived the country of many of its brightest minds, and also of a very capable workforce. However, this was done to keep Spain's citizens consistent with the ideals sought by the Nationalists and Franco.\n\nWith the end of World War II, Spain suffered from the economic consequences of its isolation from the international community. Spain was excluded from the Marshall Plan, unlike other neutral countries in Europe.This situation ended in part when, in the light of Cold War tensions and of Spain's strategic location, the United States of America entered into a trade and military alliance with Franco. This historic alliance commenced with the United States of America President Eisenhower's visit in 1953 which resulted in the Pact of Madrid. Spain was then admitted to the United Nations in 1955.\n\nIn 1952 a syndicate from Dallas, Texas, including Jack Crichton, Everette Lee DeGolyer, and Clint Murchison sought drilling rights to petroleum in Spain. The operation was handled by Delta Drilling Company.\n\nThe first decade of Franco's rule following the end of the Civil War in 1939 saw continued oppression and the killing of an undetermined number of political opponents. Estimation is difficult and controversial, but the number of people killed probably lies somewhere between 15,000 and 50,000.\n\nBy the start of the 1950s Franco's state had become less violent, but during his entire rule, non-government trade unions and all political opponents across the political spectrum, from communist and anarchist organisations to liberal democrats and Catalan or Basque separatists, were either suppressed or tightly controlled by all means, up to and including violent police repression. The \"Confederación Nacional del Trabajo\" (CNT) and the \"Unión General de Trabajadores\" (UGT) trade unions were outlawed, and replaced in 1940 by the corporatist \"Sindicato Vertical\". The Spanish Socialist Workers' Party and the \"Esquerra Republicana de Catalunya\" (ERC) were banned in 1939, while the Communist Party of Spain (PCE) went underground. The Basque Nationalist Party (PNV) went into exile, and in 1959 the ETA armed group was created to wage a low-intensity war against Franco.\n\nFranco's Spanish nationalism promoted a unitary national identity by repressing Spain's cultural diversity. Bullfighting and flamenco were promoted as national traditions while those traditions not considered \"Spanish\" were suppressed. Franco's view of Spanish tradition was somewhat artificial and arbitrary: while some regional traditions were suppressed, Flamenco, an Andalusian tradition, was considered part of a larger, national identity. All cultural activities were subject to censorship, and many, such as the Sardana, the national dance of Catalunya, were plainly forbidden (often in an erratic manner). This cultural policy was relaxed over time, most notably during the late 1960s and early 1970s.\n\nFranco also used language politics in an attempt to establish national homogeneity. He promoted the use of Castilian Spanish and suppressed other languages such as Catalan, Galician, and Basque. The legal usage of languages other than Castilian was forbidden. All government, notarial, legal and commercial documents were to be drawn up exclusively in Castilian and any documents written in other languages were deemed null and void. The usage of any other language was forbidden in schools, in advertising, and on road and shop signs. For unofficial use, citizens continued to speak these languages. This was the situation throughout the 1940s and to a lesser extent during the 1950s, but after 1960 the non-Castilian Spanish languages were freely spoken and written, and they reached bookshops and stages, although they never received official status.\n\nOn the other hand, the Catholic Church was upheld as the established church of the Spanish State, and it regained many of the traditional privileges it had lost under the Republic. Civil servants had to be Catholic, and some official jobs even required a \"good behavior\" statement by a priest. Civil marriages which had taken place in Republican Spain were declared null and void unless they had been confirmed by the Catholic Church. Divorce was forbidden, along with contraceptives and abortion.\n\nMost country towns and rural areas were patrolled by pairs of \"Guardia Civil\", a military police for civilians, which functioned as Franco's chief means of social control. Larger cities and capitals were mostly under the Policia Armada, or the \"grises\" (\"greys\", due to the colour of their uniforms) as they were called.\n\nStudent revolts at universities in the late 1960s and early 1970s were violently repressed by the heavily armed \"Policía Armada\" (Armed Police). Plainclothes secret police worked inside Spanish universities.\n\nThe enforcement by public authorities of traditional Catholic values was a stated intent of the regime, mainly by using a law (the \"Ley de Vagos y Maleantes\", Vagrancy Act) enacted by Azaña. The remaining nomads of Spain (Gitanos and Mercheros like El Lute) were especially affected. Through this law, homosexuality, pedophilia and prostitution were made criminal offenses in 1954, although its application was seldom consistent.\n\nFrancoism professed a devotion to the traditional role of a woman in society, that is being a loving child to her parents and brothers, being faithful to her husband, and residing with her family. Official propaganda confined the role of women to family care and motherhood. Immediately after the war most progressive laws passed by the Republic aimed at equality between the sexes were nullified. Women could not become judges, or testify in a trial. They could not become university professors. Their affairs and economic lives had to be managed by their fathers and husbands. Even in the 1970s a woman fleeing from an abusive husband could be arrested and imprisoned for \"abandoning the home\" (\"abandono del hogar\"). Until the 1970s a woman could not have a bank account without a co-sign by her father or husband. In the 1960s and 1970s these restrictions were somewhat relaxed, but it was not until after Franco's death that a more egalitarian view of the sexes was adopted.\n\nSpain attempted to retain control of its colonial empire throughout Franco's rule. During the Algerian War (1954–62), Madrid became the base of the \"Organisation armée secrète\" (OAS) right-wing French Army group which sought to preserve French Algeria. Despite this, Franco was forced to make some concessions. When French Morocco became independent in 1956, he surrendered Spanish Morocco to Mohammed V, retaining only a few enclaves (the \"Plazas de soberanía\"). The year after, Mohammed V invaded Spanish Sahara during the Ifni War (known as the \"Forgotten War\" in Spain). Only in 1975, with the Green March, did Morocco take control of all of the former Spanish territories in the Sahara.\n\nIn 1968, under the United Nations pressure, Franco granted Spain's colony of Equatorial Guinea its independence, and the next year it ceded the exclave of Ifni to Morocco. Under Franco, Spain also pursued a campaign to force a negotiation on the British overseas territory of Gibraltar, and closed its border with that territory in 1969. The border would not be fully reopened until 1985.\n\nThe Civil War ravaged the Spanish economy. Infrastructure had been damaged, workers killed, and daily business severely hampered. For more than a decade after Franco's victory, the devastated economy recovered very slowly. Franco initially pursued a policy of autarky, cutting off almost all international trade. The policy had devastating effects, and the economy stagnated. Only black marketeers could enjoy an evident affluence.\n\nOn the brink of bankruptcy, a combination of pressure from the United States, the IMF and, most importantly, the technocrats from Opus Dei, managed to convince the regime to adopt a free market economy. Many of the old guard in charge of the economy were replaced by \"technocrata\", despite some initial opposition from Franco. From the mid-1950s there was modest acceleration in economic activity after some minor reforms and a relaxation of controls. But the growth proved too much for the economy, with shortages and inflation breaking out towards the end of the 1950s.\n\nWhen Franco replaced his ideological ministers with the apolitical technocrats, the regime implemented several development policies that included deep economic reforms. After a recession, growth took off from 1959, creating an economic boom that lasted until 1974, and became known as the \"Spanish Miracle\".\n\nConcurrent with the absence of social reforms, and the economic power shift, a tide of mass emigration commenced to other European countries, and to a lesser extent, to South America. Emigration helped the regime in two ways. The country got rid of populations it would not have been able to keep in employment, and the emigrants supplied the country with much needed monetary remittances.\n\nDuring the 1960s, the wealthy classes of Francoist Spain experienced further increases in wealth, particularly those who remained politically faithful, while a burgeoning middle class became visible as the \"economic miracle\" progressed. International firms established factories in Spain where salaries were low, company taxes very low, strikes forbidden and workers' health or state protections almost unheard of. State-owned firms like the car manufacturer SEAT, truck builder Pegaso and oil refiner INH, massively expanded production. Furthermore, Spain was virtually a new mass market. Spain became the second-fastest growing economy in the world between 1959 and 1973, just behind Japan. By the time of Franco's death in 1975, Spain still lagged behind most of Western Europe but the gap between its per capita GDP and that of the leading Western European countries had narrowed greatly, and the country had developed a large industrialised economy.\n\nFranco was reluctant to enact any form of administrative and legislative decentralisation and kept a fully centralised government with a similar administrative structure to that established by the House of Bourbon and General Miguel Primo de Rivera y Orbaneja. Such structures were both based on the model of the French centralised State. The main drawback of this kind of management is that government attention and initiatives were irregular, and often depended more on the goodwill of regional Government representatives than on regional needs. Thus, inequalities in schooling, health care or transport facilities among regions were patent: classically affluent regions like Madrid, Catalonia, or the Basque Country fared much better than Extremadura, Galicia or Andalusia. Some regions, like Extremadura or La Mancha did not have a university.\n\nThe Basque Country and Catalonia were among the regions that offered the strongest resistance to Franco in the Civil War. Franco dissolved the autonomy granted by the Second Spanish Republic to these two regions and to Galicia. Franco abolished the centuries-old fiscal privileges and autonomy (the \"fueros\") in two of the three Basque provinces: Guipuzcoa and Biscay, but kept them for Álava which had sided with the nationalists in the civil war.\n\nAmong Franco's greatest area of support during the civil war was Navarre, the northern half of which was Basque-speaking. Navarre remained a separate region from the Basque Country and Franco also decided to preserve its centuries-old fiscal privileges and autonomy, the so-called Fueros of Navarre. The regional privileges for Álava and Navarre were kept because Álava and Navarre had participated in the initial \"coup d'état\" against the Republican government on July 18, 1936.\n\nFranco abolished the official statute and recognition of the Basque, Galician, and Catalan languages that the Second Spanish Republic had granted for the first time in the history of Spain. He returned to Castilian as the only official language of the State and education. The Franco era corresponded with the popularisation of the compulsory national educational system and the development of modern mass media, both controlled by the State and in the Castilian language, and heavily reduced the number of speakers of Basque, Catalan and Galician, as happened during the second half of the 20th century with other European minority languages which were not officially protected, such as Scottish Gaelic or French Breton. By the 1970s the majority of the population in urban areas could not speak the minority language or, as in some Catalan towns, their social use had been abandoned, leaving them limited to family use. Because of the already fragile situation of the Basque language before the Civil War, it became the most endangered language in Spain. By the 1970s Basque lacked a sufficient number of new speakers to assure its future, and moved closer to extinction. It is now recognised that the Basque language would have disappeared in a few more decades if the same linguistic policies had been preserved. This was the main reason that drove the Francoist provincial government of Álava to create a network of Basque medium schools (Ikastola) in 1973 which were State-financed.\n\nAt the end of World War II, Spain's fascist dealings made it an international pariah and the country was kept out of the United Nations, the Marshall Plan and NATO. In the 1950s, however, Spain's strategic location and Franco's anti-communist hostility towards the Soviet Union led the United States of America to reconsider its position towards Spain and it entered into a trade and military alliance as part of its policy of containment.\n\nThis historic alliance began with the signing of the Pact of Madrid in 1953, which guaranteed American support for Franco's regime. Spain was admitted to the United Nations in 1955 and President Eisenhower later visited Spain in 1959 and met with Franco.\n\nPresident Richard Nixon was in favor of Franco, and, after Franco's death, he stated: \"General Franco was a loyal friend and ally of the United States.\" American military facilities in Spain built during this era included Naval Station Rota, Morón Air Base, and Torrejón Air Base.\n\nIn 1969 Franco designated Prince Juan Carlos de Borbón, who had been educated by him in Spain, with the new title of Prince of Spain, as his heir-apparent. This designation came as a surprise to the Carlist pretender to the throne, as well as to Juan Carlos' father, Don Juan, the Count of Barcelona, who had a superior claim to the throne, but was feared by Franco to be too liberal. By 1973 Franco had surrendered the function of prime minister (\"Presidente del Gobierno\"), remaining only as head of state and commander in chief of the military.\n\nAs his final years progressed, tensions within the various factions of the \"Movimiento\" would consume Spanish political life, as varying groups jockeyed for positions in order to gain control of the country's future. The death of prime minister Luis Carrero Blanco on December 20, 1973 in a bombing by ETA eventually gave an edge to the liberalizing faction. On July 19, 1974, the aged Franco fell ill from various health problems, and Juan Carlos took over as Acting Head of State. Franco soon recovered, and on September 2 he resumed his duties as Head of State. One year later he fell ill once again from more health problems including a long battle with Parkinson's disease. On October 30, 1975, he fell into a coma and was put on life support. Franco's family agreed to disconnect the life-support machines. Officially, he died on November 20, 1975 from heart failure, at the age of 82 — the same date as the death of The 3rd Marqués de Estella, the founder of the Falange. However the historian Ricardo de la Cierva claimed that he had been told, around 6 pm on November 19, that Franco had already died. After Franco's death, he was buried at Valle de los Caídos, a colossal memorial built by the forced labour of political prisoners in order to honour the casualties of the Spanish Civil War. Franco's funeral was attended by Prince Rainier III of Monaco, Chilean leader General Augusto Pinochet, who revered Franco and modelled his leadership style on the Spanish leader, Bolivia's dictator General Hugo Banzer, Jordan's King Hussein and the United States of America Vice President Nelson Rockefeller.\n\nIn Spain and abroad, the legacy of Franco remains controversial. The Oxford Dictionary uses Franco's regime as an example of fascism. Franco served as a role model for several anti-communist dictators in South America. Augusto Pinochet is known to have admired Franco. Similarly, as late as in 2006 Franco supporters in Spain have made homages to Pinochet.\n\nThe length of his rule, the suppression of opposition, and the effective propaganda sustained through the years have made a detached evaluation almost impossible. Franco had won the hearts of many and was then able to win the Civil War; Churchill said that if he was a Spaniard living in Spain he would have supported Franco. For 40 years, Spaniards, and particularly children at school were told that Divine Providence had sent him to save Spain from chaos and poverty.\n\nIn 2006 the BBC reported that Maciej Giertych, an MEP of the clerical-nationalist League of Polish Families, had expressed admiration for Franco, stating that he \"guaranteed the maintenance of traditional values in Europe\".\nMany Spaniards, particularly those who suffered under Franco's rule, have sought to remove official recognition of his regime. Most government buildings and streets that were named after him during his long rule reverted to their original names. Owing to Franco's human rights record, the Spanish government in 2007 banned all official public references to the Franco regime and removed any statues, street names and memorials associated with the regime, with reportedly the last statue in Santander being removed in 2008. Churches that retain plaques commemorating Franco and the victims of his Republican opponents may lose state aid. Since 1978 the national anthem of Spain, the \"Marcha Real\", has not been accompanied by the lyrics introduced by Franco. Recent attempts to give the national anthem new lyrics have failed due to lack of consensus.\n\nIn March 2006, the Permanent Commission of the Parliamentary Assembly of the Council of Europe unanimously adopted a resolution \"firmly\" condemning the \"multiple and serious violations\" of human rights committed in Spain under the Francoist regime from 1939 to 1975. The resolution was at the initiative of Leo Brincat and of the historian Luis María de Puig, and was the first international official condemnation of the repression enacted by Franco's regime. The resolution also urged public access to be given to historians (professional and amateurs) to the various archives of the Francoist regime, including those of the private \"Fundación Francisco Franco\" which, as well as other Francoist archives, remain as of 2006 inaccessible to the public. The \"Fundación Francisco Franco\" received various archives from the El Pardo Palace, and is alleged to have sold some of them to private individuals. Furthermore, it urged the Spanish authorities to set up an underground exhibition in the Valle de los Caidos monument to explain the \"terrible\" conditions in which it was built. Finally, it proposed the construction of monuments to commemorate Franco's victims in Madrid and other important cities.\n\nIn Spain, a commission to repair the dignity and restore the memory of the victims of Francoism (\"Comisión para reparar la dignidad y restituir la memoria de las víctimas del franquismo\") was approved in the summer of 2004, and is directed by the socialist deputy Prime Minister María Teresa Fernández de la Vega.\nRecently the Association for the Recovery of Historical Memory (ARHM) initiated a systematic search for mass graves of people executed during Franco's regime, which has been supported since the Spanish Socialist Workers' Party's (PSOE) victory during the 2004 elections by José Luis Rodríguez Zapatero's government. A \"Ley de la memoria histórica de España\" (Law on the Historical Memory of Spain) was approved on July 28, 2006, by the Council of Ministers, but it took until October 31, 2007, for the Congress of Deputies to approve an amended version as \"The Bill to recognise and extend rights and to establish measures in favour of those who suffered persecution or violence during the Civil War and the Dictatorship\" (in common parlance still known as Law of Historical Memory). The Senate approved the bill on December 10, 2007. Among other things, the law is supposed to enforce an official recognition of the crimes committed against civilians during the Francoist rule and organise under state supervision the search for mass graves.\n\nOfficial endeavors to preserve the historical memory of the Franco regime include exhibitions like the one the Museu d'Història de Catalunya (Catalan Museum of History) organised around the prison experience.\n\nThe accumulated wealth of Franco's family (including much real estate inherited from Franco, such as the \"Pazo de Meirás\", the \"Canto del Pico\" in Torrelodones and the Cornide Palace in A Coruña), and its murky provenance, have also become matters of public discussion. Estimates of the family's wealth have ranged from 350 million to 600 million euros, well above what could possibly be accumulated from investing his official income. When Franco was ill, the francoist Cortes voted a large public pension for his wife Carmen Polo, which the later democratic governments kept paying. At the time of her death in 1988, Carmen Polo was receiving more than 12.5 million pesetas (four million more than Felipe González, then head of the government).\n\n\n\n\n\n\n"}
{"id": "11467", "url": "https://en.wikipedia.org/wiki?curid=11467", "title": "Flash Crowd", "text": "Flash Crowd\n\n\"Flash Crowd\" is a 1973 English language novella by science fiction author Larry Niven, one of a series about the social consequence of inventing an instant, practically free transfer booth.\n\nOne consequence not foreseen by the builders of the system was that with the almost immediate reporting of newsworthy events, tens of thousands of people worldwide — along with criminals — would teleport to the scene of anything interesting, thus creating disorder and confusion. The plot centers around a television journalist who, after being fired for his inadvertent role in inciting a post-robbery riot in Los Angeles, seeks to independently investigate the teleportation system for the flaws in its design allowing for such spontaneous riots to occur. His investigation takes him to destinations and people around the world within the matter of less than 12 hours before he gets his chance to plead his case on television, and he encounters the wide-ranging effects of displacements upon aspects of human behavior such as settlement, crime, natural resources, agriculture, waste management and tourism.\n\n\n\nIn various other books, for example \"Ringworld\", Niven suggests that easy transportation might be disruptive to traditional behavior and open the way for new forms of parties, spontaneous congregations, or shopping trips around the world. The central character in \"Ringworld\", celebrating his birthday, teleports across time-zones to \"lengthen\" his birthday multiple times (particularly notable since the first edition had the error of the character heading the wrong direction, increasing that edition's value).\n\nNiven's essay \"Exercise in Speculation: The Theory and Practice of Teleportation\" was published in the collection \"All the Myriad Ways\" In it he discusses the ideas that underlie his teleportation stories.\n\n\nOn the World Wide Web, a similar phenomenon can occur, when a web site catches the attention of a large number of people, and gets an unexpected and overloading surge of traffic. This usage was first coined by John Pettitt of Beyond.com in 1996. Multiple other terms for the phenomenon exist, often coming from the name of a particular prominent, high-traffic site whose normal base of viewers can constitute a flash crowd when directed to a less famous website. Notorious examples include the \"Slashdot effect\", the \"Instalanche\" (when a smaller site gets links by the popular blog Instapundit), or a website being \"Farked\" or Drudged (where the target site is crashed due to the large number of hits in a short time).\n"}
{"id": "11469", "url": "https://en.wikipedia.org/wiki?curid=11469", "title": "August Kekulé", "text": "August Kekulé\n\nFriedrich August Kekulé, later Friedrich August Kekule von Stradonitz (; 7 September 1829 – 13 July 1896), was a German organic chemist. From the 1850s until his death, Kekulé was one of the most prominent chemists in Europe, especially in theoretical chemistry. He was the principal founder of the theory of chemical structure.\n\nKekulé never used his first given name; he was known throughout his life as August Kekulé. After he was ennobled by the Kaiser in 1895, he adopted the name August Kekule von Stradonitz, without the French acute accent over the second \"e\". The French accent had apparently been added to the name by Kekulé's father during the Napoleonic occupation of Hesse by France, to ensure that French-speaking people pronounced the third syllable.\n\nThe son of a civil servant, Kekulé was born in Darmstadt, the capital of the Grand Duchy of Hesse. After graduating from secondary school (the Grand Ducal Gymnasium in Darmstadt), in the fall of 1847 he entered the University of Giessen, with the intention of studying architecture. After hearing the lectures of Justus von Liebig in his first semester, he decided to study chemistry. Following four years of study in Giessen and a brief compulsory military service, he took temporary assistantships in Paris (1851–52), in Chur, Switzerland (1852–53), and in London (1853–55), where he was decisively influenced by Alexander Williamson. His Giessen doctoral degree was awarded in the summer of 1852.\n\nIn 1856 Kekulé became Privatdozent at the University of Heidelberg. In 1858 he was hired as full professor at the University of Ghent, then in 1867 he was called to Bonn, where he remained for the rest of his career. Basing his ideas on those of predecessors such as Williamson, Edward Frankland, William Odling, Auguste Laurent, Charles-Adolphe Wurtz and others, Kekulé was the principal formulator of the theory of chemical structure (1857–58). This theory proceeds from the idea of atomic valence, especially the tetravalence of carbon (which Kekulé announced late in 1857) and the ability of carbon atoms to link to each other (announced in a paper published in May 1858), to the determination of the bonding order of all of the atoms in a molecule. Archibald Scott Couper independently arrived at the idea of self-linking of carbon atoms (his paper appeared in June 1858), and provided the first molecular formulas where lines symbolize bonds connecting the atoms. For organic chemists, the theory of structure provided dramatic new clarity of understanding, and a reliable guide to both analytic and especially synthetic work. As a consequence, the field of organic chemistry developed explosively from this point. Among those who were most active in pursuing early structural investigations were, in addition to Kekulé and Couper, Frankland, Wurtz, Alexander Crum Brown, Emil Erlenmeyer, and Alexander Butlerov.\n\nKekulé's idea of assigning certain atoms to certain positions within the molecule, and schematically connecting them using what he called their \"Verwandtschaftseinheiten\" (\"affinity units\", now called \"valences\" or \"bonds\"), was based largely on evidence from chemical reactions, rather than on instrumental methods that could peer directly into the molecule, such as X-ray crystallography. Such physical methods of structural determination had not yet been developed, so chemists of Kekulé's day had to rely almost entirely on so-called \"wet\" chemistry. Some chemists, notably Hermann Kolbe, heavily criticized the use of structural formulas that were offered, as he thought, without proof. However, most chemists followed Kekulé's lead in pursuing and developing what some have called \"classical\" structure theory, which was modified after the discovery of electrons (1897) and the development of quantum mechanics (in the 1920s).\n\nThe idea that the number of valences of a given element was invariant was a key component of Kekulé's version of structural chemistry. This generalization suffered from many exceptions, and was subsequently replaced by the suggestion that valences were fixed at certain oxidation states. For example, periodic acid according to Kekuléan structure theory could be represented by the chain structure I-O-O-O-O-H. By contrast, the modern structure of (meta) periodic acid has all four oxygen atoms surrounding the iodine in a tetrahedral geometry.\n\nKekulé's most famous work was on the structure of benzene. In 1865 Kekulé published a paper in French (for he was then still in Francophone Belgium) suggesting that the structure contained a six-membered ring of carbon atoms with alternating single and double bonds. The following year he published a much longer paper in German on the same subject.\n\nThe empirical formula for benzene had been long known, but its highly unsaturated structure was a challenge to determine. Archibald Scott Couper in 1858 and Joseph Loschmidt in 1861 suggested possible structures that contained multiple double bonds or multiple rings, but the study of aromatic compounds was in its earliest years, and too little evidence was then available to help chemists decide on any particular structure.\n\nMore evidence was available by 1865, especially regarding the relationships of aromatic isomers. Kekulé argued for his proposed structure by considering the number of isomers observed for derivatives of benzene. For every monoderivative of benzene (CHX, where X = Cl, OH, CH, NH, etc.) only one isomer was ever found, implying that all six carbons are equivalent, so that substitution on any carbon gives only a single possible product. For diderivatives such as the toluidines, CH(NH)(CH), three isomers were observed, for which Kekulé proposed structures with the two substituted carbon atoms separated by one, two and three carbon-carbon bonds, later named ortho, meta, and para isomers respectively.\n\nThe counting of possible isomers for diderivatives was however criticized by Albert Ladenburg, a former student of Kekulé, who argued that Kekulé's 1865 structure implied two distinct \"ortho\" structures, depending on whether the substituted carbons are separated by a single or a double bond. Since ortho derivatives of benzene were never actually found in more than one isomeric form, Kekulé modified his proposal in 1872 and suggested that the benzene molecule oscillates between two equivalent structures, in such a way that the single and double bonds continually interchange positions. This implies that all six carbon-carbon bonds are equivalent, as each is single half the time and double half the time. A firmer theoretical basis for a similar idea was later proposed in 1928 by Linus Pauling, who replaced Kekulé's oscillation by the concept of resonance between quantum-mechanical structures.\n\nThe new understanding of benzene, and hence of all aromatic compounds, proved to be so important for both pure and applied chemistry after 1865 that in 1890 the German Chemical Society organized an elaborate appreciation in Kekulé's honor, celebrating the twenty-fifth anniversary of his first benzene paper. Here Kekulé spoke of the creation of the theory. He said that he had discovered the ring shape of the benzene molecule after having a reverie or day-dream of a snake seizing its own tail (this is an ancient symbol known as the ouroboros). This vision, he said, came to him after years of studying the nature of carbon-carbon bonds.\n\nA similar humorous depiction of benzene had appeared in 1886 in the \"Berichte der Durstigen Chemischen Gesellschaft\" (Journal of the Thirsty Chemical Society), a parody of the \"Berichte der Deutschen Chemischen Gesellschaft\", only the parody had monkeys seizing each other in a circle, rather than snakes as in Kekulé's anecdote. Some historians have suggested that the parody was a lampoon of the snake anecdote, possibly already well-known through oral transmission even if it had not yet appeared in print. Others have speculated that Kekulé's story in 1890 was a re-parody of the monkey spoof, and was a mere invention rather than a recollection of an event in his life. \nKekulé's 1890 speech, in which these anecdotes appeared, has been translated into English. If one takes the anecdote as the memory of a real event, circumstances mentioned in the story suggest that it must have happened early in 1862.\n\nHe told yet another anecdote in 1890, of a vision of dancing atoms and molecules that led to his theory of structure. This happened, he claimed, while he was riding on the upper deck of a horse-drawn omnibus in London. This probably occurred in the late summer of 1855.\n\nIn 1895 Kekulé was ennobled by Kaiser Wilhelm II of Germany, giving him the right to add \"von Stradonitz\" to his name, referring to a possession of his patrilineal ancestors in Stradonice, Bohemia. This title was used by his son, genealogist Stephan Kekulé von Stradonitz. Of the first five Nobel Prizes in Chemistry, Kekulé's students won three: van 't Hoff in 1901, Fischer in 1902 and Baeyer in 1905.\n\nA larger-than-life size monument of Kekulé is situated in front of the former Chemical Institute at the University of Bonn. His monument is often decorated by students, e.g. for Valentine's Day.\n\n\n\n"}
{"id": "11472", "url": "https://en.wikipedia.org/wiki?curid=11472", "title": "Frederick III, Holy Roman Emperor", "text": "Frederick III, Holy Roman Emperor\n\nFrederick III (21 September 1415 – 19 August 1493), called the Peaceful or the Fat, was Holy Roman Emperor from 1452 until his death, the first emperor of the House of Habsburg. He was the penultimate emperor to be crowned by the Pope, and the last to be crowned in Rome.\n\nPrior to his imperial coronation, he was duke of the Inner Austrian lands of Styria, Carinthia and Carniola from 1424, and also acted as regent over the Duchy of Austria (as Frederick V) from 1439. He was elected and crowned King of Germany (as Frederick IV) in 1440. He was the longest-reigning German monarch when in 1493, after ruling his domains for more than 53 years, he was succeeded by his son Maximilian I.\n\nDuring his reign, Frederick concentrated on re-uniting the Habsburg \"hereditary lands\" of Austria and took a lesser interest in Imperial affairs. Nevertheless, by his dynastic entitlement to Hungary as well as by the Burgundian inheritance, he laid the foundations for the later Habsburg Empire. Mocked as \"Arch-Sleepyhead of the Holy Roman Empire\" () during his lifetime, he is today increasingly seen as an efficient ruler.\n\nBorn at the Tyrolean residence of Innsbruck in 1415, Frederick was the eldest son of the Inner Austrian duke Ernest the Iron, a member of the Leopoldian line of the Habsburg dynasty, and his second wife Cymburgis of Masovia. According to the 1379 Treaty of Neuberg, the Leopoldinian branch ruled over the duchies of Styria, Carinthia and Carniola, or what was referred to as Inner Austria. Only three of Frederick's eight siblings survived childhood: his younger brother Albert (later to be Albert VI, archduke of Austria), and his sisters Margaret (later the electress of Saxony) and Catherine. In 1424, nine-year-old Frederick's father died, making Frederick the duke of Inner Austria, as Frederick V, with his uncle, Duke Frederick IV of Tyrol, acting as regent.\n\nFrom 1431, Frederick tried to obtain majority (to be declared \"of age\", and thus allowed to rule) but for several years was denied by his relatives. Finally, in 1435, Albert V, duke of Austria (later Albert II, the king of Germany), awarded him the rule over his Inner Austrian heritage. Almost from the beginning, Frederick's younger brother Albert asserted his rights as a co-ruler, as the beginning of a long rivalry. Already in these years, Frederick had begun to use the symbolic A.E.I.O.U. signature as a kind of motto with various meanings. In 1436 he made a pilgrimage to the Holy Land, accompanied by numerous nobles knighted by the Order of the Holy Sepulchre, which earned him great reputation.\n\nUpon the death of his uncle Duke Frederick IV in 1439, Frederick took over the regency of Tyrol and Further Austria for the duke's heir Sigismund. Again he had to ward off the claims raised by his brother Albert VI; he prevailed by the support of the Tyrolean aristocracy. Likewise he acted as regent for his nephew Ladislaus the Posthumous, son of late King Albert II and his consort Elizabeth of Luxembourg, in the duchy of Austria (Further Austria). (Ladislaus would unfortunately die before coming of age). Frederick was now the undisputed head of the Habsburg dynasty, though his regency in the lands of the Albertinian Line (Further Austria) was still viewed with suspicion.\n\nAs a cousin of late King Albert II, Frederick became a candidate for the imperial election. On 2 February 1440, the prince-electors convened at Frankfurt and unanimously elected him King of the Romans as Frederick IV; his rule was still based on his hereditary lands of Styria, Carinthia and Carniola, or Inner Austria.\n\nIn 1442, Frederick allied himself with Rudolf Stüssi, burgomaster of Zurich, against the Old Swiss Confederacy in the Old Zurich War (Alter Zürichkrieg) but lost. In 1448, he entered into the Concordat of Vienna with the Holy See, which remained in force until 1806 and regulated the relationship between the Habsburgs and the Holy See.\n\nIn 1452, at the age of 37, Frederick III travelled to Italy to receive his bride and to be crowned Holy Roman Emperor. His fiancée, the 18-year-old \"infanta\" Eleanor, daughter of King Edward of Portugal, landed at Livorno after a 104-day trip. Her dowry would help Frederick alleviate his debts and cement his power. The couple met at Siena on 24 February and proceeded together to Rome. As per tradition, they spent a night outside the walls of Rome before entering the city on 9 March, where Frederick and Pope Nicholas V exchanged friendly greetings. Because the emperor had been unable to retrieve the Iron Crown of Lombardy from the cathedral of Monza where it was kept, nor be crowned King of Italy by the archbishop of Milan (on account of Frederick's dispute with Francesco Sforza, lord of Milan), he convinced the pope to crown him as such with the German crown, which had been brought for the purpose. This coronation took place on the morning of 16 March, in spite of the protests of the Milanese ambassadors, and in the afternoon Frederick and Eleanor were married by the pope. Finally, on 19 March, Frederick and Eleanor were anointed in St Peter's Basilica by the Vice-Chancellor of the Holy Roman Church, Cardinal Francesco Condulmer, and Frederick was then crowned with the Imperial Crown by the pope. Frederick was the last Emperor to be crowned in Rome; his great-grandson Charles V was the last emperor to be crowned, but this was done in Bologna.\n\nFrederick's style of rulership was marked by hesitation and a sluggish pace of decision making. The Italian humanist Enea Silvio Piccolomini, later Pope Pius II, who at one time worked at Frederick's court, described the Emperor as a person who wanted to conquer the world while remaining seated. Although this was regarded as a character flaw in older academic research, his delaying tactics are now viewed as a means of coping with political challenges in far-flung territorial possessions. Frederick is credited with having the ability to sit out difficult political situations patiently.\n\nAccording to contemporary accounts, Frederick had difficulties developing emotional closeness to other persons, including his children and wife Eleanor. In general, Frederick kept himself away from women, the reasons for which are not known. As Frederick was rather distant to his family, Eleanor had a great influence on the raising and education of Frederick's children, and she therefore played an important role in the House of Habsburg's rise to prominence. Despite the fact that their marriage had been unhappy, when Eleanor died the Emperor was affected by her loss and remained widowed for the rest of his long life.\n\nFrederick's political initiatives were hardly bold, but they were still successful. His first major opponent was his brother Albert VI, who challenged his rule. He did not manage to win a single conflict on the battlefield against him, and thus resorted to more subtle means. He held his second cousin once removed Ladislaus the Posthumous, the ruler of the Archduchy of Austria, Hungary and Bohemia, (born in 1440) as a prisoner and attempted to extend his guardianship over him in perpetuity to maintain his control over Lower Austria. Ladislaus was freed in 1452 by the Lower Austrian estates. He acted similarly towards his first cousin Sigismund of the Tyrolian line of the Habsburg family. Despite those efforts, he failed to gain control over Hungary and Bohemia in the Bohemian–Hungarian War (1468–78) and was even defeated in the Austrian–Hungarian War (1477–88) by the Hungarian King Matthias Corvinus in 1485, who managed to maintain residence in Vienna until his death five years later in the Siege of Vienna.\n\nUltimately, Frederick prevailed in all those conflicts by outliving his opponents and sometimes inheriting their lands, as was the case with Ladislaus, from whom he gained Lower Austria in 1457, and with his brother Albert VI, whom he succeeded in Upper Austria. These conflicts forced him into an anachronistic itinerant existence, as he had to move his court between various places through the years, residing in Graz, Linz and . owes him its castle and the \"New Monastery\".\n\nStill, in some ways his policies were astonishingly successful. In the Siege of Neuss (1474–75), he forced Charles the Bold of Burgundy to give up his daughter Mary of Burgundy as wife to Frederick's son Maximilian. With the inheritance of Burgundy, the House of Habsburg began to rise to predominance in Europe. This gave rise to the saying \"Let others wage wars, but you, happy Austria, shall marry\", which became a motto of the dynasty.\n\nThe marriage of his daughter Kunigunde to Albert IV, Duke of Bavaria, was another result of intrigues and deception, but must be counted as a defeat for Frederick. Albert illegally took control of some imperial fiefs and then asked to marry Kunigunde (who lived in Innsbruck, far from her father), offering to give her the fiefs as a dower. Frederick agreed at first, but after Albert took over yet another fief, Regensburg, Frederick withdrew his consent. On 2 January 1487, however, before Frederick's change of heart could be communicated to his daughter, Kunigunde married Albert. A war was prevented only through the mediation of the Emperor's son, Maximilian.\n\nIn some smaller matters, Frederick was quite successful: in 1469 he managed to establish bishoprics in Vienna and , a step that no previous Duke of Austria had been able to achieve.\n\nFrederick's personal motto was the mysterious string A.E.I.O.U., which he imprinted on all his belongings. He never explained its meaning, leading to many different interpretations being presented, although it has been claimed that shortly before his death he said it stands for ' or ' (\"All the world is subject to Austria\"). It may well symbolise his own understanding of the historical importance and meaning of his rule and of the early gaining of the Imperial title.\n\nFrederick had five children from his marriage with Eleanor of Portugal:\nFor the last 10 years of Frederick's life, he and Maximilian ruled jointly.\n\nFrederick III died in 1493, aged 77, at Linz. His left foot had become gangrenous, and was amputated. He survived this procedure, but continued infection prompted amputation of his left leg, after which he was said to have bled to death.\n\nHis grave, built by Nikolaus Gerhaert von Leyden, in St. Stephen's Cathedral, Vienna, is one of the most important works of sculptural art of the late Middle Ages. (His amputated leg was buried with him.) The heavily adorned tomb was not completed until 1513, two decades after Frederick's death, and has survived in its original condition.\n\n\n"}
{"id": "11475", "url": "https://en.wikipedia.org/wiki?curid=11475", "title": "Fuerteventura", "text": "Fuerteventura\n\nFuerteventura (; literally meaning \"strong fortune\" but translated by some as \"Strong Winds\" or a corruption of the French term for \"Great Adventure\") is one of the Canary Islands, in the Atlantic Ocean off the coast of Africa, politically part of Spain. At , it is the second largest of the Canary Islands, after Tenerife. It was declared a biosphere reserve by UNESCO in May 2009. Its capital is Puerto del Rosario.\n\nThe first settlers of Fuerteventura are believed to have come from North Africa. The word \"Mahorero\" (\"Majorero\") or \"Maho\" is still used today to describe the people of Fuerteventura and is derived from the ancient word 'mahos', a type of goatskin shoe worn by these original inhabitants. They lived in caves and semi-subterranean dwellings, some of which have been excavated, revealing remnants of early tools and pottery. In antiquity, the island was known o.a. as \"Planaria\", in reference to the flatness of most of its terrain.\n\nIn the 11th century BC, Phoenician settlers landed in Fuerteventura and Lanzarote.\n\nSeveral Spanish and Portuguese expeditions to the islands were organized around 1340, followed by Moors and European slave traders. At the end of the Iberian conquest, the island was divided into two Guanches kingdoms, one adhering to King Guize and the other to King Ayoze. The territories of these kingdoms were called Maxorata (in the North) and Jandía (in the South) respectively. They were separated by a wall, which traversed the La Pared isthmus. Some remains have been preserved. The ancient name for the island, Erbania, is derived from this wall's name.\n\nThe island's conquest began in earnest in 1402, commanded by Jean de Béthencourt and Gadifer de la Salle. They arrived with only 63 sailors out of the original 283, as many had deserted along the way. After arriving and settling in Lanzarote, the invaders made some first excursions to the neighboring islands. In 1404, Bethencourt and Gadifer founded Betancuria, on the West coast, the first settlement on the island. After numerous difficulties, Gadifer took charge of the invasion, while Bethencourt returned to Spain to seek the recognition and support of the Castilian king.\nIn 1405, de Béthencourt completed his conquest of the island, establishing its capital in Betancuria (Puerto Rosario took over the mantle as island capital in 1835). It is generally accepted that the island took its name from \"fuerte\" (strong) and \"ventura\" (wind), as mentioned by mallorcan navigator Angelino Dulcert in 1339.\n\nIn 1424 Pope Martin V, through the Betancuria Brief, edicted the establishment of the Bishopric of Fuerteventura, which encompassed all the Canary Islands safe for the island of Lanzarote. The origin of this bishopric is directly related to the events that occurred after the Great Schism (1378-1417), in that the bishop of San Marcial del Rubicón of Lanzarote (at the time, the only diocese in the Canary Islands) did not recognize the papacy of Martin V, and instead adhered to anti-Pope Benedict XIII. The \"Bishopric of Fuerteventura\" was based in the \"Parish of Santa María de Betancuria\", bestowing upon the latter the status of Grant Cathedral. After the reabsorbtion of the \"Diocese of San Marcial del Rubicón\" by the papacy of Pope of Martin V, the Bishopric of Fuerteventura was abolished in 1431, only seven years after it was created.\n\nThe first census recorded a population of some 1,200 inhabitants. The population increased gradually thereafter. In 1476 the territory became the \"Señorío Territorial de Fuerteventura\", subjected to the Catholic Monarchs. In later years, the island was invaded by the Spanish, French and the English.\n\nOver time, the island endured numerous pirate raids. A Berber lead expedition invaded in 1593, sweeping as far inland as the capital. Various castles were built along the coastline, to protect against these type of attacks. The population was moved inland as a second protective measure. Because of the raids, a first \"Captain General\" was dispatched to Fuerteventura, accompanied by a number of \"Sergeant Majors\", to defend the island in the name of the Crown. At that time Betancuria became the religious capital of the island.\n\nTwo major pirate attacks took place in 1740, within a month of each other. Two separate bands of English privateers attempted to loot the town of Tuineje. These attacks were however successfully averted by the local population and the island's militia. This successful repelling of the invaders is celebrated at a re-enactment that takes place in Gran Tarajal every year in October.\n\nThe island's garrison was officially instated in 1708. Its colonel assumed the title of \"Governor at Arms\", a hereditary, lifelong appointment which has remained in the Sánchez-Dumpiérrez family. In time, this family increasingly garnered power over the other islands through alliances with the family of Arias de Saavedra and the Lady of Fuerteventura. During the same year the \"Assistant Parish of La Oliva and Pájara\" was created, to become operational in 1711. On December 17, 1790 the \"Assistant Parish of Tuineje\" was created, which became a new parish division on June 23, 1792 under the bishop Tavira, with lands including part of the Jandía peninsular, and with a population of 1,670 inhabitants. 1780 saw the start of a barrilla plantation industry.\n\nIn 1852, a free trade zone was extended by Isabella II to the Canary Islands. Military island rule, which began in 1708, was finally dissolved in 1859, and Puerto de Cabras (now Puerto del Rosario) became the new capital.\nThe Canary Islands obtained self-governance in 1912. In 1927, Fuerteventura and Lanzarote became part of the province of Gran Canaria. The seat of the island's government (\"cabildo insular\") is located in Puerto del Rosario. A total of 74,983 people lived on the island in 2003.\n\nBy the 1940s the island had an airport (just west of Puerto del Rosario on the road to Tindaya, still visible today). Mass tourism began to arrive in the mid-1960s, facilitated by the construction of Fuerteventura Airport at El Matorral and the first tourist hotels.\n\nThe island's proximity (a mere 100 km) to the West African coast and the fact that it is part of the Schengen territory make it a prime target destination for undocumented immigrants. However, many have perished while attempting the crossing.\n\nThe elongated island has an area of . The island is long and wide. It is part of the province of Las Palmas. It is divided into six municipalities:\n100 individual settlements are distributed through these municipalities. A nearby islet, Islote de Lobos, is part of the municipality of La Oliva.\n\nLocated just off the coast of north Africa, it is the second biggest of the islands, after Tenerife, and has the longest white sand beaches in the archipelago. The island is a destination for sun, beach and watersports enthusiasts. It lies at the same latitude as Florida and Mexico and temperatures rarely fall below or rise above . It counts 152 separate beaches along its seaboard — of white sand and of black volcanic shingle.\n\nFuerteventura is the oldest island in the Canary Islands dating back 20 million years to a volcanic eruption from the Canary hotspot. The majority of the island was created about 5 million years ago and since then has been eroded by wind and precipitation. On the seabed off the West coast of the island rests an enormous slab of bedrock long and wide, which appears to have slid off the island largely intact at some point in prehistory, similar to the predicted future collapse of Cumbre Vieja, a geological fault on another Canary Island, La Palma. The last volcanic activity in Fuerteventura occurred between 4,000 and 5,000 years ago.\n\nThe highest point in Fuerteventura is Pico de la Zarza (807 m) in the Southwestern part of the island. Geographical features include Istmo de la Pared which is wide and is the narrowest part of Fuerteventura. The island is divided into two parts, the northern portion which is Maxorata and the southwestern part called the Jandía peninsula.\nFuerteventura was chosen among 500 European destinations by the Quality Coast International Certification Program of the European Coastal and Marine Union as one of the most attractive tourist destinations for visitors interested in cultural heritage, environment and sustainability.\n\nThe climate on Fuerteventura is pleasant throughout the year. The island is hence referred to as \"the island of eternal spring\". The sea regulates air temperature, diverting hot Sahara winds away from the island. The island's name in English translates as \"strong fortune\" or \"strong wind\", the Spanish word for wind being \"viento\". During the winter months, temperatures average a high of and a low of around , whereas during the summer a mean high of and a low of can be expected. Precipitation is about per year, most of which falls in autumn and winter. December is the month with highest rainfall.\n\nA sandstorm known as the Calima (similar to the Sirocco wind, which blows to the North of the Sahara, to Europe) may blow from the Sahara Desert to the Northwest, and can cause high temperatures, low visibility and drying air. Temperatures during this phenomenon rise temporarily by approximately 10 degrees Celsius. The wind brings in fine red dust, The fine white sand is not blown in from Sahara, It is made up of dead coral reef and local seabed upheaval. visibility can drop to between or even lower and can even bring African locusts to the island.\n\nThe island is home to one of the two surviving populations of the threatened Canarian Egyptian vulture. It is also inhabited by many wild dogs and cats. On the barren, rocky land there are Barbary ground squirrels and geckos. Fuerteventura also hosts several migratory and nesting birds. The island has significant populations of the collared dove, common swifts and several finch species especially in the vicinity of holiday developments.\nDespite its arid climate, the island is also home to a surprisingly large insect fauna. Butterflies which commonly occur on the island include the clouded yellow (Colias hyale) and the bath white (\"Pontia daplidice\") which feeds on xerophytic cruciferae. The island is also home to the monarch butterfly (\"Danaus plexippus\") and its close African relative \"Danaus chrysippus\". Around holiday developments such as Caleta de Fuste, water is relatively abundant, and dragonfly species including the blue emperor, \"Anax imperator\" and the scarlet darter, \"Crocothemis erythraea\" can be found. The islands sand dunes and shoreline are home to a number of bee and wasp species including the large Eumenid caterpillar hunting wasp, \"Delta dimidiatipenne\" and the striking blue banded bee, (\"Amegilla canifrons\").\nHawkmoths also occur on the island. One of the more notable species is \"Hyles tithymali\" which feeds on endemic spurges such as \"Euphorbia regis-jubae\". \"Acherontia atropos\", the deaths-head hawkmoth also occurs on the island presumably feeding on members of the Solanaceae, for example, \"Datura innoxia\" and \"Nicotiana glauca\" which are common weeds in the vicinity of human habitation.\n\nThe official symbols from nature associated with Fuerteventura are \"Chlamydotis undulata fuertaventurae\" (hubara or houbara) and \"Euphorbia handiensis\" (Cardón de Jandía).\n\nThe island has a population of 74,983. Throughout its long history, Fuerteventura has suffered from a population decline due to the economic situation and the climate, which have made it into a desert island. However, the development of tourism during the 1980s has caused the population to grow year on year since then, doubling it in a little less than a decade.\n\nIn 2005, with 86,642 registered inhabitants, the Fuerteventura population was formed by the following:\n\nComparing this data with the 2001 census shows that the number of permanent residents born on the island has increased by just 3,000. The number who have moved in from abroad has increased by 22,910, making this the biggest contributor to population growth in recent years.\n\nThe island has 116 schools, with a total of 14,337 pupils. Of these, 45 are primary schools, ten are secondary schools, six are for Baccalaureate students and four are vocational colleges.\n\nFuerteventura also has a centre linked with the National University of Distance Education, offering courses in many subjects including economics, business studies, law, history and tourism.\n\nFuerteventura is governed by the Island Department of the Government of Spain, which holds the rank of a Government Subdepartment. The government building is located in the centre of the capital city, in front of the parish church of the Virgin of Rosario, the patron saint of Puerto del Rosario municipality.\n\nThis institution is charged with representing the Government of Spain on the island, and managing all the functions that are not under control of the Canarian Government. This includes the following public services:\n\nSince 30 June 2007, the island's governor has been Eustaquio Juan Santana Gil. 4\n\nThe councils, formed as part of the Councils Act of 1912, administer the Canary Islands and have two principal functions. On one hand, they perform services for the Autonomous Community, and on the other, they are the local government centre for the island. In the 2003 elections, Mario Cabrera González was elected as president representing the Canarian Coalition, with 31.02% of the votes, followed by the Spanish Socialist Workers' Party with 27.53%, represented by the Vice President Domingo Fuentes Curbelo.\n\nThe island is divided into six municipalities with their respective city councils which form part of the FECAM (Federation of Canarian Municipalities). They are governed by the basic legislation of the local regime and their respective organic rules. The populations of the municipalities are as follows:\nIn turn, these municipalities are organised into two associations: the \"Mancomunidad de Municipios del Centro-Norte de Fuerteventura\" formed from La Oliva and Puerto del Rosario, and the remaining municipalities make up the \"Mancomunidad de Municipios del Centro-Sur de Fuerteventura\".\n\nThe economy of Fuerteventura is mainly based on tourism. Primary tourist areas are located around the existing towns of Corralejo in the north and Morro Jable in Jandia, plus the purely tourist development of Caleta de Fuste, south of Puerto del Rosario. Other main industries are fishing and agriculture (cereals and vegetables). The famous Majorero cheese is locally made from the milk of the indigenous majorera goat.\n\nIn 2009, Fuerteventura recorded the highest EU regional unemployment rate at a NUTS3 level, at 29.2 percent.\n\nThe first tourist hotel was built in 1965 followed by the construction of Fuerteventura Airport at El Matorral, heralding the dawn of a new era for the island. Fuerteventura, with its 3,000 sunshine hours a year, was placed firmly on the world stage as a major European holiday destination.\nWhile having fully developed tourist facilities, the island has not experienced the overdevelopment found on some other islands and consequently caters for visitors attracted by its rugged natural beauty.\n\nThe summer Trade Winds and winter swells of the Atlantic make this a year-round surfers' paradise, with more exposed areas on the north and west shores such as Corralejo and El Cotillo proving most popular. Wind surfing takes places at locations around the island. Sailors, scuba divers and big-game fishermen are all drawn to these clear blue Atlantic waters where whales, dolphins, marlin and turtles are all common sights. With many hills present throughout the Island, hikers are also attracted to this Island.\n\nExcellent sandy beaches are found in many locations. Western beaches, such as those around El Cotillo, can experience strong surf. The beaches adjoining the extensive sand dunes east of Corralejo are popular, as are the more protected extensive sandy shores of the Playa de Sotavento de Jandia on the southeastern coast between Costa Calma and the Morro Jable. Naked sun bathing and swimming are the norm almost on all beaches.\n\nMuch of the interior, with its large plains, lavascapes and volcanic mountains, consists of protected areas, although there are organised tours and vehicular access across them.\n\nLike the rest of the Canaries, Carnival is traditionally one of the biggest festivals celebrated on the island. It is celebrated in different ways in all the towns during February and March. These festivities have a different theme each year. They include activities such as parades and galas to choose the carnival king.\n\nThere are many concerts and festivals held in the auditoriums, such as the Festival of Canarian Music. They are also held in smaller venues across the island, featuring bands such as Estopa, Van Gogh's Ear, and King Afrhica.\n\n\nFestival Internacional de Cometas/International Kite Festival is held on the second week of November each year centering on the Corralejo Beaches. It attracts kitefliers and kite surfers from all over Europe. It is popular because the winds are warm and constant and the beaches become filled with hundreds of colourful kites of all shapes and sizes.\n\nFuerteventura has three auditoriums. These are used for all types of performing art. They are also used for non-artistic purposes, such as conferences, charity galas and political meetings.\n\n\nThe Central Library of the Island is located in Antigua's city centre, in the public university. In addition to providing the traditional library services, it has an 180-seat multipurpose room, air conditioning, a wifi zone, and a multimedia room used for seminars, presentations, film festivals etc.\n\nThe island has several museums with different themes and plenty of exhibition spaces, both public and private. These include:\n\n\nIn addition to the museums, the capital Puerto del Rosario has an open-air sculpture park consisting of around 100 sculptures by different artists scattered across the city. Most of them were created for the International Symposium of Sculpture celebrated annually since 2001. During the festival, artists come from all over the world to erect their sculptures in the open air, in full view of passers by.\n\nSites of interest include Corralejo and El Jable to the north which are made up of fine sand dunes whilst the south is filled with long beaches and remote bays. The constant winds blowing onto the beaches provide a paradise for windsurfing. Surfing is common on the west and north coasts where there are large waves. Windsurfing is common around Corralejo and Playas de Sotavento and wave sailing (windsurfing on the waves) on the coast along the northern half of the island. El Cotillo is a small fishing village in the north-west of the Island famous for a very long beach to the south of the village and few very calm beaches to the north. The northern beaches frequented by snorkeling enthusiasts and sun worshippers alike are referred to as lakes by the locals. \n\nAt Cofete on the western side of Jandía a remote and imposing house - Villa Winter - looks out to sea across wide and generally empty beaches. It was reputedly built by a Mr Winter on land given by Generalisimo Franco. Despite being one of the most beautiful parts of Fuerteventura Cofete has very little touristic facilities.\n\nFor a time, the beaches were home to a popular accidental attraction. On 18 January 1994 the once-beautiful and proud United States Lines ocean liner SS \"American Star\" (former \"America\", USS \"West Point\", \"Australis\") was beached in Playa de Garcey during a severe storm. Within a year, she broke in two and later lost her stern. By 2007 the rest of the severely deteriorated ship had collapsed onto her port side, gradually keeling over further and almost completely submerged. By 2008-2012, most of the remains finally slipped below the surface.\n\nThe cuisine is fairly basic due to the customs and climate conditions. They share this simplicity with the other Canary islands, and similarly to them, they use a large quantity of fish. They also use whatever they can grow in the near-barren land. This includes papas arrugadas, a dish of wrinkled potatoes usually served with mojo, which is a hot pepper sauce or with puchero canario, a meat stew.\n\nSeafood is prepared in many ways traditionally, such as pejines (salted fish), jareas, or sancocho (a type of stew) made from fish, generally the grouper, corvina or sama, boiled after salting, and served with mojo, potatoes, or gofio (a type of grain). People are also very keen on the mussels and limpets collected on the island's coasts.\n\nThey also use meat such as beef and pork to make different dishes or simply to for braising, but their main meat is goat, both from the kids and from the older animals. They eat the goat roasted or stewed. Goats are not only useful for their meat - the Fuerteventurans also use the milk to make the cheese majorero, which has won many prizes. The majorero is mostly made of goats milk, and occasionally it is up to 15% ewes milk. It is cured in pimento oil or gofio meal. Majorero and palmero cheese are the only two Canarian cheeses with protected denomination of origin.\n\nMany sports are commonly played in Fuerteventura, both in the open air and in sports centres across the island.\n\nThese are the Canarian sports found on the island:\n\nThe wrestling takes place in a ring of sand called the \"terrero\". Inside it, the two contestants try to knock each other over. Fuerteventura has 14 terreros distributed through all the towns except Betancuria.\n\n\nThe island also has a school wrestling league organized by the council and a programme to promote this sport in clubs. Twelve wrestling schools participate in this, based in Antigua, Costa Calma, El Matorral, La Lajita, Lajares, Las Playitas, Morro Jable, Puerto del Rosario, Tefía, Tetir, Unión Sur and Villaverde.\n\nJuego del Palo is a Canarian martial art which literally translates as \"game of the stick\". It is played by two players both armed with sticks. They aim to defeat each other without making contact with their opponent's body. The origin of this game is unclear. All we know is that it is based on a method of combat used by the precolonial Canarian people.\n\nFuerteventura has the following Palo clubs:\n\nThis is a similar game to the French Pétanque which is actually played very little on the island, although there are a few teams and courts. Basically the game consists of scoring points by throwing a ball to get it as near as possible to an object called a \"mingue\" or \"boliche\". It is played on a rectangular sand or earth pitch which is long and wide.\n\nhttp://www.playaboule.com/Simple_petanque_rules.aspx\n\nThe sea and climate conditions make the island the perfect place for a huge variety of watersports.\n\nMany types of surfing are popular on the island, including traditional surfing, windsurfing (where the board is propelled by a sail) and most recently kitesurfing. The island has many schools and courses dedicated to teaching these sports.\n\nThe sports where Fuerteventura has the most impact internationally are windsurfing and kitesurfing, mainly due to the International Windsurfing and Kiteboarding Championship. This has run since 1985 and is held at Playas de Sotavento in Pájara municipality. Many important wind and kitesurfing figures compete in this championship, such as the several-times world windsurfing champion Björn Dunkerbeck and Gisela Pulido, the very young kiteboarding champion from Tarifa.\n\nMany Canarian windsurfers are on the Canarian Waveriders circuit, which has been based in Corralejo since 2005.\n\nDiving schools are just as frequent as surfing ones, all around the coast of Fuerteventura. Unlike the other islands of the archipelago, Fuerteventura has a shelf which at some points goes up to , making it an ideal place to practice this sport.\n\nTwo of the most useful points for diving are the coast off Playa del Matorral in the South, and the zone between Lobos Island and Corralejo in the north. It is here in Corralejo that the International Sea and Submarine Photography Festival takes places, known as Fimarsub Corralejo - Lobos. During the festival there are beginners' lessons, professional dives, lessons in underwater photography, screenings and other events related to the sport.\n\nThere are many swimming pools on the island but the most obvious place to swim is in the open sea. There is an annual swim from Lobos Island to Fuerteventura, held every year since 1999. The event attracts amateur swimmers from all over the Canaries and Spain, and also swimming professionals such as David Meca and Maarten Van der Weijden, the paralympist Jesús Collado Alarcón who won gold medals for 100m backstroke and butterfly in Athens 2004, and Xavi Torres Ramis, the paralympic champion in Barcelona '92, Sydney and Atlanta.\n\nThe island holds competitions involving different types of boat, such as the lateen and the Optimist. An interesting event is the Tour of Fuerteventura by Kayak, which is organised as a series of stages rather than a competition, and is an easy way to explore the island.\n\nThe most notable competition here is the Gran Tarajal Fishing Open.\n\nSince 2004 the Marcha Ciclotourista has been held in La Oliva and the Criterium Ciclista has been held in Corralejo (also part of the La Oliva municipality) since 2005. Participants include Euskaltel-Euskadi, T-Mobile and a team from Orbea. These competitions have contributed to local interest in the sport and the first professional local team, the Fuerteventura-Canarias, was formed, initially run by Óscar Guerrero, director of Kaiku, although they have not competed for the past few seasons.\n\nThere are various motocross circuits on the island, including \"Los Alares\" in Antigua and \"Isla de Fuerteventura\" in Puerto del Rosario municipality. They hold regular trials, some of which form part of the Canarian Regional Motocross Championship. Throughout the year there are gravel rally races. Two are part of the Canarian Dirt Rally Championship. These are the Antiguan Rally and the La Oliva Rally.\n\nThe island's main football clubs are CD Union Puerto and CD Cotillo, who play in Group XII of the Spanish Tercera División.\n\nThe resort Playitas on the south coast is since around 2008 equipped with a swimming pool and has become a destination for triathlon training camps for Europeans. An annual race called Challenge Fuerteventura is held there on the half ironman distance.\n\n\n\n"}
{"id": "11476", "url": "https://en.wikipedia.org/wiki?curid=11476", "title": "Fairmount, Indiana", "text": "Fairmount, Indiana\n\nFairmount is a town in Fairmount Township, Grant County in the east central part of the U.S. state of Indiana. The population was 2,954 at the 2010 census. It is ninety kilometers (fifty-five miles) northeast of Indianapolis. Largely a bedroom community to its three thousand citizens, Fairmount is best known as the boyhood home of actor James Dean, who is buried there.\n\nFairmount is located at (40.417702, −85.648942).\n\nAccording to the 2010 census, Fairmount has a total area of , all land.\n\nAs of the census of 2010, there were 2,954 people, 1,241 households, and 837 families residing in the town. The population density was . There were 1,350 housing units at an average density of . The racial makeup of the town was 98.6% White, 0.1% African American, 0.2% Native American, 0.2% Asian, 0.2% from other races, and 0.7% from two or more races. Hispanic or Latino of any race were 0.9% of the population.\n\nThere were 1,241 households of which 31.2% had children under the age of 18 living with them, 48.6% were married couples living together, 14.1% had a female householder with no husband present, 4.8% had a male householder with no wife present, and 32.6% were non-families. 28.0% of all households were made up of individuals and 12% had someone living alone who was 65 years of age or older. The average household size was 2.38 and the average family size was 2.85.\n\nThe median age in the town was 40.3 years. 23.9% of residents were under the age of 18; 8.4% were between the ages of 18 and 24; 23.2% were from 25 to 44; 28% were from 45 to 64; and 16.5% were 65 years of age or older. The gender makeup of the town was 48.5% male and 51.5% female.\n\nAs of the census of 2000, there were 2,992 people, 1,226 households, and 859 families residing in the town. The population density was 2,033.0 people per square mile (785.9/km²). There were 1,325 housing units at an average density of 900.3 per square mile (348.0/km²). The racial makeup of the town was 98.30% White, 0.17% Black or African American, 0.70% Native American, 0.20% Asian, 0.07% from other races, and 0.57% from two or more races. Hispanic or Latino of any race were 0.43% of the population.\n\nThere were 1,226 households out of which 31.2% had children under the age of 18 living with them, 55.5% were married couples living together, 11.0% had a female householder with no husband present, and 29.9% were non-families. 26.5% of all households were made up of individuals and 12.5% had someone living alone who was 65 years of age or older. The average household size was 2.44 and the average family size was 2.91.\n\nIn the town, the population was spread out with 25.2% under the age of 18, 8.2% from 18 to 24, 28.2% from 25 to 44, 24.3% from 45 to 64, and 14.1% who were 65 years of age or older. The median age was 38 years. For every 100 females there were 90.5 males. For every 100 females age 18 and over, there were 90.0 males.\n\nThe median income for a household in the town was $33,843, and the median income for a family was $44,033. Males had a median income of $31,136 versus $23,041 for females. The per capita income for the town was $18,029. About 7.4% of families and 9.1% of the population were below the poverty line, including 11.8% of those under age 18 and 7.8% of those age 65 or over.\n\nThe Fairmount area was settled in the 1830s mostly by Quakers from North Carolina. The town was laid out in 1850 and named for Fairmount Park in Philadelphia; it was formally incorporated in 1870.\n\nAfter a large deposit of natural gas was found in 1887, Fairmount became part of the Indiana Gas Boom and a center of the glass industry for the rest of the 19th century. Shortly after the depletion of the gas in 1900 the automobile industry set up factories in the nearby large cities, and Fairmount became a bedroom community, restoring some of its lost prosperity.\nIn the 1940s, James Dean lived with an aunt and uncle, Ortense and Marcus Winslow on a farm north of Fairmount. He attended Fairmount High School, graduating in 1949. After his death in 1955, Dean was buried in Park Cemetery. In 1996, a small Memorial Park north of the town's business district was dedicated in his memory with a bronze bust by Hollywood artist Kenneth Kendall.\n\nDuring the prosperity of the 1960s, Fairmount enjoyed a time of building with a new town hall, water works, post office and elementary school. At the end of the decade the local school district merged with a neighboring one, forming the Madison-Grant united school district. A new high school was built for this district, and Fairmount High School became a middle school. When a new junior high school was opened in 1986, the Fairmount High School building was permanently closed.\n\nFairmount was hit hard by the recession of 1980–1982, which brought the permanent loss of factory jobs and the failure of many farms, but rebounded later in the decade. Fairmount is still relatively prosperous despite the ill fortunes of nearby industrial cities and a steady loss of population.\n\nIn September 1988, The James Dean Gallery opened in a restored Victorian House on North Main Street. Over the years the Museum Exhibit has been toured by nearly 200,000 visitors who come from around the world to visit the hometown of James Dean. Also in 1988, English musician Morrissey filmed the music video for his single Suedehead; a song inspired by his lifelong admiration of Dean, in the town.\n\nThe annual James Dean Festival takes place during the last full weekend in September and includes a Custom & Hot Rod Car Show, The Grand Parade, Street Fair, Carnival Rides, Live Entertainment, a 1950s Dance Contest and the James Dean lookalike Contest.\n\nOn September 30 of each year there is a Memorial Service for James Dean at The Back Creek Friends Church, south of The Winslow Farm.\n\nThe Baldwin Addition Historic District, Fairmount Commercial Historic District, and J.W. Patterson House are listed on the National Register of Historic Places.\n\nMadison-Grant United School Corporation operates public schools.\n\nSchools serving Fairmount:\n\n\n"}
{"id": "11477", "url": "https://en.wikipedia.org/wiki?curid=11477", "title": "Epistles to the Thessalonians", "text": "Epistles to the Thessalonians\n\nThere are two Epistles to the Thessalonians in the Bible:\n"}
{"id": "11478", "url": "https://en.wikipedia.org/wiki?curid=11478", "title": "Free verse", "text": "Free verse\n\nFree verse is an open form of poetry. It does not use consistent meter patterns, rhyme, or any other musical pattern. Many poems composed in free verse thus tend to follow the rhythm of natural speech.\n\nPoets have explained that free verse is not totally free; 'its only freedom is from the tyrant demands of the metered line'. Free verse displays some elements of form. Most free verse, for example, self-evidently continues to observe a convention of the poetic line in some sense, at least in written representations, though retaining a potential degree of linkage. Donald Hall goes as far as to say that \"the \"form\" of free verse is as binding and as liberating as the \"form\" of a rondeau\", and T. S. Eliot wrote, \"No verse is free for the man who wants to do a good job\". \n\nKenneth Allott the poet/critic said the adoption by some poets of vers libre arose from 'mere desire for novelty, the imitation of Whitman, the study of Jacobean dramatic blank verse, and the awareness of what French poets had already done to the alexandrine in France'. The American critic John Livingston Lowes in 1916 observed 'Free verse may be written as very beautiful prose; prose may be written as very beautiful free verse. Which is which?'\n\nSome poets have considered free verse restrictive in its own way. In 1922 Robert Bridges voiced his reservations in the essay 'Humdrum and Harum-Scarum.' Robert Frost later remarked that writing free verse was like \"playing tennis without a net.\" William Carlos Williams said \"being an art form, verse cannot be free in the sense of having no limitations or guiding principles\". Yvor Winters, the poet/critic said \"the free verse that is really verse, the best that is, of W.C. Williams, H. D., Marianne Moore, Wallace Stevens, and Ezra Pound is the antithesis of free\"\n\nAs the name \"vers libre\" suggests, this technique of using more irregular cadences is often said to be derived from the practices of 19th-century French poets such as Gustave Kahn and Jules Laforgue in his \"Derniers vers\" of 1890. Taupin, the USA based French poet/critic concluded that free verse and vers libre are not synonymous, since 'The French language tends to give equal weight to each spoken syllable, whereas English syllables vary in quantity according to whether stressed or unstressed'.\n\nThe sort of cadencing that we now recognize in free verse can be traced back at least as far as the Hebrew psalmist poetry of the Bible. By referring to it is possible to argue that free verse in English first appeared in the 1380s in the John Wycliffe translation of the Psalms and was repeated in different form in most biblical translations ever since. Walt Whitman, who based his long lines in \"Leaves of Grass\" on the phrasing of the King James Bible, influenced later American free verse practitioners, notably Allen Ginsberg. One form of free verse was employed by Christopher Smart in a long poem called Jubilate Agno, written some time between 1759 and 1763 but not published until 1939.\n\nMany poets of the Victorian era experimented with free verse. Christina Rossetti, Coventry Patmore, and T. E. Brown all wrote examples of rhymed but unmetered verse. Poems such as W. E. Henley's 'Discharged' (from his \"In Hospital\" sequence). Free verse in English was persuasively advocated by critic T. E. Hulme in his \"A Lecture on Modern Poetry\" (1908). Later in the preface to \"Some Imagist Poets\" 1916, he comments, \"Only the name is new, you will find something much like vers libre in Dryden's \"Threnodia Augustalis\"; a great deal of Milton's \"Samson Agonistes\", and the oldest in Chaucer's \"House of Fame\".\"\n\nIn France, a few pieces in Arthur Rimbaud's prose poem collection Illuminations were arranged in manuscript in lines, rather than prose and in the Netherlands, tachtiger (i.e. member of 1880s generation of innovative poets) Frederik van Eeden employed the form at least once (in his poem \"Waterlelie\" [\"water lily\"]).\n\nGoethe (particularly in some early poems, such as \"Prometheus\") and Hölderlin used free verse occasionally, due in part to a misinterpretation of the meter used in Pindar's poetry; in Hölderlin's case, he also continued to write unmetered poems after discovering this error. The German poet Heinrich Heine made an important contribution to the development of free verse with 22 poems, written in two-poem cycles called 'Die Nordsee' (The North Sea) (written 1825-1826). These were first published in \"Buch der Lieder\" (Book of Songs) in 1827.\n\nAlthough free verse requires no meter, rhyme, or other traditional poetic techniques, a poet can still use them to create some sense of structure. A clear example of this can be found in Walt Whitman's poems, where he repeats certain phrases and uses commas to create both a rhythm and structure. \n\nPattern and discipline is to be found in free verse: the internal pattern of sounds, the choice of exact words, and the effect of associations give free verse its beauty. With the Imagists free verse became a discipline and acquired status as a legitimate poetic form. Herbert Read however, noting that 'the Imagist Ezra Pound gave free verse its musical structure to an extent that parodoxically it was no longer free'.\n\nDue to a lack of predetermined form, free verse poems have the potential to take truly unique shapes. Unrestrained by traditional boundaries, Yvor Winters described this as \"attempts to widen experience by establishing 'abnormal' conventions\", the poet possesses more license to express, and has more control over the development of the poem. This can allow for a more spontaneous and individualized poetic art product.\n\nTechnically, free verse has been described as 'spaced prose', a mosaic of verse and prose experience.\n\n\n\n"}
{"id": "11479", "url": "https://en.wikipedia.org/wiki?curid=11479", "title": "F. W. de Klerk", "text": "F. W. de Klerk\n\nFrederik Willem de Klerk, DMS (; born 18 March 1936) is a South African politician who served as the country's State President from August 1989 to May 1994. He was the seventh and last head of state of South Africa under the apartheid era. De Klerk was also leader of the National Party (which later became the New National Party) from February 1989 to September 1997.\n\nDe Klerk helped to broker the end of apartheid, South Africa's policies of racial segregation and discrimination, and supported the transformation of South Africa into a non-racial democracy by entering into the negotiations that resulted in all citizens having equal voting and other rights. He won the Félix Houphouët-Boigny Peace Prize in 1991, the Prince of Asturias Award in 1992 and the Nobel Peace Prize in 1993 along with Nelson Mandela for his role in the ending of apartheid.\n\nHe was one of the deputy presidents of South Africa during the presidency of Nelson Mandela until 1996, and is the most recent white South African and Afrikaner to have held the position. In 1997 he retired from active politics. He continues to remain active as a lecturer internationally. After the deaths of Botha in 2006 and Marais Viljoen in 2007, de Klerk is the last surviving State President of South Africa.\n\nThe name \"De Klerk\" is derived from Le Clerc, Le Clercq and De Clercq, and is of French Huguenot origin (meaning \"clergyman\" or \"literate\" in old French). De Klerk noted that he is also of Dutch descent, with an Indian ancestor from the late 1600s or early 1700s. He is also said to be descended from the Khoi interpreter known as Krotoa or Eva.\n\nDe Klerk was born in Johannesburg, in the then Transvaal Province of the Union of South Africa, to Johannes \"Jan\" de Klerk and Hendrina Cornelia Coetzer – \"her forefather was a Kutzer who stems from Austria\". De Klerk graduated from Monument High School in Krugersdorp. De Klerk graduated in 1958 from the Potchefstroom University with BA and LL.B degrees (the latter \"cum laude\"). Following graduation, de Klerk practised law in Vereeniging in the Transvaal. In 1959 he married Marike Willemse, with whom he had two sons and a daughter.\n\nHe came from a family environment in which the conservatism of traditional white South African politics was deeply ingrained. His paternal great-grandfather was Senator Johannes Cornelis \"Jan\" van Rooy. His aunt was married to NP Prime Minister J. G. Strijdom. In 1948, the year when the NP swept to power in whites-only elections on an apartheid platform, F. W. de Klerk's father, Johannes \"Jan\" de Klerk, became secretary of the NP in the Transvaal province and later rose to the positions of cabinet minister and President of the Senate, becoming interim State President in 1975. His brother Willem is a liberal newspaperman and one of the founders of the Democratic Party.\n\n\"F. W.\", pronounced \"eff-veer\", as he became popularly known, was first elected to the House of Assembly in 1969 as the member for Vereeniging, and entered the cabinet in 1978. De Klerk had been offered a professorship of administrative law at Potchefstroom in 1972 but he declined the post because he was serving in Parliament. In 1978, he was appointed Minister of Posts and Telecommunications and Social Welfare and Pensions by Prime Minister Vorster.\n\nUnder Prime Minister and later State President P. W. Botha, he held a succession of ministerial posts, including:\n\n\nHe became Transvaal provincial National Party leader in 1982 and chairman of the Minister's Council in the House of Assembly in 1985.\n\nFor most of his career, de Klerk had a very conservative reputation. The NP's Transvaal branch was historically the most staunchly conservative wing of the party, and he supported continued segregation of universities while Minister of National Education. It thus came as a surprise when in 1989 he placed himself at the head of \"verligte\" (\"enlightened\") forces within the governing party which had come to believe that apartheid could not be maintained forever. This wing favoured beginning negotiations while there was still time to get reasonable terms.\n\nP. W. Botha resigned as leader of the National Party after an apparent stroke, and de Klerk defeated Botha's preferred successor, finance minister Barend du Plessis, in the race to succeed him. A month later, the NP caucus nominated de Klerk as state president. Botha initially refused to resign, saying that he intended to serve out his full five-year term, which expired in 1990. He even hinted that he might run for re-election. However, after protracted negotiations, Botha agreed to resign after the September 1989 parliamentary elections and hand power to de Klerk. However, Botha abruptly resigned on 14 August, and de Klerk was named acting state president until 20 September, when he was elected to a full five-year term as state president.\n\nIn some of his first speeches after assuming the party leadership, he called for a non-racist South Africa and for negotiations about the country's future. A couple of months later, in February 1990, he suddenly lifted the bans on the African National Congress (ANC) and the Communist Party of South Africa, released Nelson Mandela and other political prisoners. In legislative terms, he enabled the gradual end of apartheid. De Klerk also opened the way for the negotiations of the government with the anti-apartheid-opposition about a new constitution for the country. Nevertheless, he was accused by Anthony Sampson of complicity in the violence among the ANC, the Inkatha Freedom Party and elements of the security forces. In \"\", Sampson accuses de Klerk of permitting his ministers to build their own criminal empires.\n\nHis presidency was dominated by the negotiation process, mainly between his NP government and the ANC, which led to the democratization of South Africa. In 1992, de Klerk held a whites-only referendum on ending apartheid, with the result being an overwhelming \"yes\" vote to continue negotiations to end apartheid. Nelson Mandela was distrustful of the role played by de Klerk in the negotiations, particularly as he believed that de Klerk was knowledgeable about 'third force' attempts to foment violence in the country and destabilize the negotiations.\n\nIn 1990, de Klerk gave orders to end South Africa's nuclear weapons programme; the process of nuclear disarmament was essentially completed in 1991. The existence of the programme was not officially acknowledged before 1993.\n\nIn 1993, De Klerk and Mandela were jointly awarded the Nobel Peace Prize for their work in ending apartheid. The awarding of the prize to de Klerk was controversial, especially in the light of de Klerk's reported admission that he ordered a massacre of supposed Azanian Peoples' Liberation Army fighters, including teenagers, shortly before going to Oslo in 1993. It appears that this massacre may form part of the basis for criminal charges that the Anti-Racism Action Forum laid against de Klerk in early 2016. Further, de Klerk's role in the destabilization of the country during the negotiation process through the operation of a 'third force' came to the attention of the Truth and Reconciliation Commission, and was never ultimately clarified.\n\nAfter the first universal elections in 1994, de Klerk became deputy president in the government of national unity under Nelson Mandela, a post he kept until 1996. In 1997 he resigned the leadership of the National Party and retired from politics.\n\nIn 1996, de Klerk was offered the Harper Fellowship at Yale Law School. He declined, citing protests at the university. De Klerk did, however, speak at Central Connecticut State University the day before his fellowship would have begun.\nIn 1998, de Klerk and his wife of 38 years, Marike de Klerk, were divorced following the discovery of his affair with Elita Georgiades, then the wife of Tony Georgiades, a Greek shipping tycoon who had allegedly given de Klerk and the NP financial support. Soon after his divorce, de Klerk and Georgiades were married. His divorce and remarriage scandalised conservative South African opinion, especially among the Calvinist Afrikaners. In 1999, his autobiography, \"The Last Trek – A New Beginning\", was published. In 2001, following the murder of his former wife, the manuscript of her own autobiography, \"A Place Where the Sun Shines Again\", was submitted to de Klerk, who urged the publishers to suppress a chapter dealing with his infidelity.\n\nIn 1999, de Klerk established the pro-peace FW de Klerk Foundation of which he is the chairman. De Klerk is also chairman of the Global Leadership Foundation, headquartered in London, which he set up in 2004, an organisation which works to support democratic leadership, prevent and resolve conflict through mediation and promote good governance in the form of democratic institutions, open markets, human rights and the rule of law. It does so by making available, discreetly and in confidence, the experience of former leaders to today's national leaders. It is a not-for-profit organisation composed of former heads of government and senior governmental and international organisation officials who work closely with heads of government on governance-related issues of concern to them.\n\nOn 4 December 2001, Marike de Klerk was found stabbed and strangled to death in her Cape Town flat. De Klerk, who was on a brief visit to Stockholm, Sweden, to celebrate the 100-year anniversary of the Nobel Prize foundation, announced he would immediately return to mourn his dead ex-wife. The atrocity was reportedly condemned strongly by South African president Thabo Mbeki and Winnie Mandela, among others, who openly spoke in favour of Marike de Klerk. On 6 December 21-year-old security guard Luyanda Mboniswa was arrested for the murder. On 15 May 2003, he received two life sentences for murder, as well as three years for breaking into Marike de Klerk's apartment.\n\nIn 2004, de Klerk announced that he was quitting the New National Party and seeking a new political home after it was announced that the NNP would merge with the ruling ANC. That same year, while giving an interview to US journalist Richard Stengel, de Klerk was asked whether South Africa had turned out the way he envisioned it back in 1990. His response was:\n\nThere are a number of imperfections in the new South Africa where I would have hoped that things would be better, but on balance I think we have basically achieved what we set out to achieve. And if I were to draw balance sheets on where South Africa stands now, I would say that the positive outweighs the negative by far. There is a tendency by commentators across the world to focus on the few negatives which are quite negative, like how are we handling AIDS, like our role vis-à-vis Zimbabwe. But the positives – the stability in South Africa, the adherence to well-balanced economic policies, fighting inflation, doing all the right things in order to lay the basis and the foundation for sustained economic growth – are in place.\n\nIn 2008, he repeated in a speech that \"despite all the negatives facing South Africa, he is very positive about the country\".\n\nIn 2006, he underwent surgery for a malignant tumour in his colon, discovered after an examination on 3 June. His condition deteriorated sharply, and he underwent a second operation after developing respiratory problems. On 13 June, it was announced that he was to undergo a tracheotomy. He recovered and on 11 September 2006 gave a speech at Kent State University Stark Campus.\n\nIn January 2007, de Klerk was a speaker promoting peace and democracy in the world at the \"Towards a Global Forum on New Democracies\" event in Taipei, Taiwan, along with other dignitaries including Poland's Lech Wałęsa and Taiwan's then president Chen Shui-Bian.\n\nDe Klerk is an Honorary Patron of the University Philosophical Society and Honorary Chairman of the Prague Society for International Cooperation. He has also received the Gold Medal for Outstanding Contribution to Public Discourse from the College Historical Society for his contribution to ending apartheid.\n\nDe Klerk is also a Member of the Advisory Board of the Global Panel Foundation based in Berlin, Copenhagen, New York, Prague, Sydney and Toronto – founded by the Dutch entrepreneur Bas Spuybroek in 1988, with the support of Dutch billionaire Frans Lurvink and former Dutch Foreign Minister Hans van den Broek. The Global Panel Foundation is known for its behind-the-scenes work in public policy and the annual presentation of the Hanno R. Ellenbogen Citizenship Award with the Prague Society for International Cooperation.\n\nAfter the inauguration of Jacob Zuma as South Africa's president in May 2009, de Klerk said he is optimistic that Zuma and his government can \"confound the prophets of doom\".\n\nIn a BBC interview broadcast in April 2012, he said he lived in an all-white neighbourhood. He had five servants, three coloured and two black: \"We are one great big family together; we have the best of relationships.\" About Nelson Mandela, he said, \"When Mandela goes it will be a moment when all South Africans put away their political differences, will take hands, and will together honour maybe the biggest known South African that has ever lived.\"\n\nUpon hearing of the death of Mandela, de Klerk said: \"He was a great unifier and a very, very special man in this regard beyond everything else he did. This emphasis on reconciliation was his biggest legacy.\"\n\nIn 2015, de Klerk wrote to \"The Times\" newspaper in the UK criticising moves to remove a statue to Cecil Rhodes at Oriel College, Oxford. He was subsequently criticized by some activists who described it as 'ironic' that the last apartheid President should be defending a statue of a man labelled by critics as the \"architect of apartheid\". There have also been calls for him to be stripped of his Nobel Peace Prize.\n\n"}
{"id": "11488", "url": "https://en.wikipedia.org/wiki?curid=11488", "title": "Furlong", "text": "Furlong\n\nA furlong is a measure of distance in imperial units and U.S. customary units equal to one-eighth of a mile, equivalent to 660 feet, 220 yards, 40 rods, or 10 chains.\n\nUsing the international definition of the inch as exactly 25.4 millimetres, one furlong is 201.168 metres. However, the United States does not uniformly use this conversion ratio. Older ratios are in use for surveying purposes in some states, leading to variations in the length of the furlong of about two parts per million, or 0.4 millimetres ( inch). This variation is too small to have many practical consequences. Five furlongs are about 1.0 kilometre (1.00584 km is the exact value, according to the international conversion).\n\nThe name \"furlong\" derives from the Old English words ' (furrow) and ' (long). Dating back at least to early Anglo-Saxon times, it originally referred to the length of the furrow in one acre of a ploughed open field (a medieval communal field which was divided into strips). The system of long furrows arose because turning a team of oxen pulling a heavy plough was difficult. This offset the drainage advantages of short furrows and meant furrows were made as long as possible. An acre is an area that is one furlong long and one chain (66 feet or 22 yards) wide. For this reason, the furlong was once also called an acre's length, though in modern usage an area of one acre can be of any shape. The term furlong, or shot, was also used to describe a grouping of adjacent strips within an open field.\n\nAmong the early Anglo-Saxons, the rod was the fundamental unit of land measurement. A furlong was forty rods, an acre four by 40 rods, or four rods by one furlong, and thus 160 square rods. At the time, the Saxons used the North German foot, which was 10 percent longer than the foot of today. When England changed to the shorter foot in the late 13th century, rods and furlongs remained unchanged, since property boundaries were already defined in rods and furlongs. The only thing that changed was the number of feet and yards in a rod or a furlong, and the number of square feet and square yards in an acre. The definition of the rod went from 15 old feet to new feet, or from 5 old yards to new yards. The furlong went from 600 old feet to 660 new feet, or from 200 old yards to 220 new yards. The acre went from 36,000 old square feet to 43,560 new square feet, or from 4,000 old square yards to 4,840 new square yards.\n\nThe furlong was historically viewed as being equivalent to the Roman stade (\"stadium\"), which in turn derived from the Greek system. For example, the King James Bible uses the term \"furlong\" in place of the Greek \"stadion\", although more recent translations often use miles or kilometres in the main text and give the original numbers in footnotes.\n\nIn the Roman system, there were 625 feet to the \"stadium\", eight \"stadia\" to the mile, and three miles to the league. A league was considered to be the distance a man could walk in one hour, and the mile (from \"mille\", \"meaning thousand\") consisted of 1,000 \"passus\" (paces, five feet, or double-step).\n\nAfter the fall of the Roman Empire, medieval Europe continued with the Roman system, which the people proceeded to diversify, leading to serious complications in trade, taxation, etc. Around the year 1300, by royal decree England standardized a long list of measures. Among the important units of distance and length at the time were the foot, yard, rod (or pole), furlong, and the mile. The rod was defined as yards or feet, and the mile was eight furlongs, so the definition of the furlong became 40 rods and that of the mile became 5,280 feet (eight furlongs/mile times 40 rods/furlong times feet/rod).\n\nA description from 1675 states, \"Dimensurator or Measuring Instrument whereof the mosts usual has been the Chain, and the common length for English Measures four Poles, as answering indifferently to the Englishs Mile and Acre, 10 such Chains in length making a Furlong, and 10 single square Chains an Acre, so that a square Mile contains 640 square Acres.\" —John Ogilby, Britannia, 1675\n\nThe official use of the furlong was abolished in the United Kingdom under the Weights and Measures Act 1985, an act that also abolished the official use of many other traditional units of measurement.\n\nIn Myanmar, furlongs are currently used in conjunction with miles to indicate distances on highway signs. Mileposts on the Yangon-Mandalay Expressway use miles and furlongs.\nIn the rest of the world, the furlong has very limited use, with the notable exception of horse racing in most English-speaking countries, including Canada and the United States. The distances for horse-racing in Australia were converted to metric in 1972; but, in the United Kingdom, Ireland, Canada, and the United States, races are still given in miles and furlongs.\n\nThe city of Chicago's street numbering system allots a measure of 800 address units to each mile, in keeping with the city's system of eight blocks per mile. This means that every block in a typical Chicago neighborhood (in either North/South or East/West direction but rarely both) is approximately one furlong in length. Salt Lake City's blocks are also each a square furlong in the downtown area. The blocks become less regular in shape further from the center, but the numbering system (800 units to each mile) remains the same everywhere in Salt Lake County. Blocks in central Logan, Utah, and in large sections of Phoenix, Arizona, are similarly a square furlong in extent (eight to a mile, which explains the series of freeway exits: 19th Ave, 27th, 35th, 43rd, 51st, 59th ...). City blocks in the Hoddle Grid of Melbourne are also one furlong in length.\n\nMuch of Ontario, Canada, was originally surveyed on a ten-furlong grid, with major roads being laid out along the grid lines. Now that distances are shown on road signs in kilometres, it is obvious that these major roads are almost exactly two kilometres apart. The exits on highways running through Toronto, for example, are generally at intervals of two kilometres.\n\nThe furlong is also a base unit of the humorous FFF system of units.\n\nThe exact conversion of the furlong to SI units varies slightly among English-speaking countries. In Canada and the United Kingdom,\nwhich define the furlong in terms of the international yard of exactly 0.9144 metres, a furlong is 201.168 m.\nAustralia does not formally define the furlong, but it does define the chain and link in terms of the international yard.\n\nIn the United States, which defines the furlong, chain, rod, and link in terms of the U.S. survey foot of exactly metre, a furlong is approximately 201.1684 m long. The United States does not formally define a \"survey yard\". The difference of approximately two parts per million between the U.S. value and the \"international\" value is insignificant for most practical measurements.\n\n"}
{"id": "11489", "url": "https://en.wikipedia.org/wiki?curid=11489", "title": "File", "text": "File\n\nFile or filing may refer to:\n\n\n\n\n"}
{"id": "11490", "url": "https://en.wikipedia.org/wiki?curid=11490", "title": "Fundamental frequency", "text": "Fundamental frequency\n\nThe fundamental frequency, often referred to simply as the fundamental, is defined as the lowest frequency of a periodic waveform. In music, the fundamental is the musical pitch of a note that is perceived as the lowest partial present. In terms of a superposition of sinusoids (e.g. Fourier series), the fundamental frequency is the lowest frequency sinusoidal in the sum. In some contexts, the fundamental is usually abbreviated as f\" (or FF), indicating the lowest frequency counting from zero. In other contexts, it is more common to abbreviate it as f\", the first harmonic. (The second harmonic is then f = 2⋅f, etc. In this context, the zeroth harmonic would be 0 Hz.)\n\nAll sinusoidal and many non-sinusoidal waveforms are periodic, which is to say they repeat exactly over time. The period of a waveform is the formula_1 for which the following equation is true:\n\nWhere formula_3 is the value of the waveform at formula_4. This means that this equation and a definition of the waveforms values over any interval of length formula_1 is all that is required to describe the waveform completely.\n\nEvery waveform may be described using any multiple of this period. There exists a smallest period over which the function may be described completely and this period is the fundamental period. The fundamental frequency is defined as its reciprocal:\n\nSince the period is measured in units of time, then the units for frequency are 1/time. When the time units are seconds, the frequency is in formula_7, also known as Hertz.\n\nFor a tube of length formula_8 with one end closed and the other end open the wavelength of the fundamental harmonic is formula_9, as indicated by the first two animations. Hence,\n\nTherefore, using the relation\nwhere formula_12 is the speed of the wave, we can find the fundamental frequency in terms of the speed of the wave and the length of the tube:\n\nIf the ends of the same tube are now both closed or both opened as in the last two animations, the wavelength of the fundamental harmonic becomes formula_14. By the same method as above, the fundamental frequency is found to be\n\nAt 20 °C (68 °F) the speed of sound in air is 343 m/s (1129 ft/s). This speed is temperature dependent and increases at a rate of 0.6 m/s for each degree Celsius increase in temperature (1.1 ft/s for every increase of 1 °F).\n\nThe velocity of a sound wave at different temperatures:-\n\nIn music, the fundamental is the musical pitch of a note that is perceived as the lowest partial present. The fundamental may be created by vibration over the full length of a string or air column, or a higher harmonic chosen by the player. The fundamental is one of the harmonics. A harmonic is any member of the harmonic series, an ideal set of frequencies that are positive integer multiples of a common fundamental frequency. The reason a fundamental is also considered a harmonic is because it is 1 times itself.\nThe fundamental is the frequency at which the entire wave vibrates. Overtones are other sinusoidal components present at frequencies above the fundamental. All of the frequency components that make up the total waveform, including the fundamental and the overtones, are called partials. Together they form the harmonic series. Overtones which are perfect integer multiples of the fundamental are called harmonics. When an overtone is near to being harmonic, but not exact, it is sometimes called a harmonic partial, although they are often referred to simply as harmonics. Sometimes overtones are created that are not anywhere near a harmonic, and are just called partials or inharmonic overtones.\n\nThe fundamental frequency is considered the \"first harmonic\" and the \"first partial.\" The numbering of the partials and harmonics is then usually the same; the second partial is the second harmonic, etc. But if there are inharmonic partials, the numbering no longer coincides. Overtones are numbered as they appear \"above\" the fundamental. So strictly speaking, the \"first\" overtone is the \"second\" partial (and usually the \"second\" harmonic). As this can result in confusion, only harmonics are usually referred to by their numbers, and overtones and partials are described by their relationships to those harmonics.\n\nConsider a spring, fixed at one end and having a mass attached to the other; this would be a single degree of freedom (SDoF) oscillator. Once set into motion it will oscillate at its natural frequency. For a single degree of freedom oscillator, a system in which the motion can be described by a single coordinate, the natural frequency depends on two system properties: mass and stiffness; (providing the system is undamped). The radian frequency, \"ω\", can be found using the following equation:\n\nWhere:\n\"k\" = stiffness of the spring\n\"m\" = mass \n\"ω\" = radian frequency (radians per second)\n\nFrom the radian frequency, the natural frequency, \"f\", can be found by simply dividing \"ω\" by 2\"π\". Without first finding the radian frequency, the natural frequency can be found directly using:\n\nWhere:\n\"f\" = natural frequency in hertz (cycles/second)\n\"k\" = stiffness of the spring (Newtons/meter or N/m)\n\"m\" = mass(kg) \nwhile doing the modal analysis of structures and mechanical equipment, the frequency of 1st mode is called fundamental frequency.\n\n"}
{"id": "11491", "url": "https://en.wikipedia.org/wiki?curid=11491", "title": "Fable", "text": "Fable\n\nFable is a literary genre: a succinct fictional story, in prose or verse, that features animals, legendary creatures, plants, inanimate objects, or forces of nature that are anthropomorphized (given human qualities, such as the ability to speak human language) and that illustrates or leads to a particular moral lesson (a \"moral\"), which may at the end be added explicitly as a pithy maxim.\n\nA fable differs from a parable in that the latter \"excludes\" animals, plants, inanimate objects, and forces of nature as actors that assume speech or other powers of humankind.\n\nUsage has not always been so clearly distinguished. In the King James Version of the New Testament, \"\" (\"\"mythos\"\") was rendered by the translators as \"fable\" in the First Epistle to Timothy, the Second Epistle to Timothy, the Epistle to Titus and the First Epistle of Peter.\n\nA person who writes fables is a fabulist.\n\nThe fable is one of the most enduring forms of folk literature, spread abroad, modern researchers agree, less by literary anthologies than by oral transmission. Fables can be found in the literature of almost every country.\n\nThe varying corpus denoted \"Aesopica\" or \"Aesop's Fables\" includes most of the best-known western fables, which are attributed to the legendary Aesop, supposed to have been a slave in ancient Greece around 550 BC. When Babrius set down fables from the \"Aesopica\" in verse for a Hellenistic Prince \"Alexander,\" he expressly stated at the head of Book II that this type of \"myth\" that Aesop had introduced to the \"sons of the Hellenes\" had been an invention of \"Syrians\" from the time of \"Ninos\" (personifying Nineveh to Greeks) and Belos (\"ruler\"). Epicharmus of Kos and Phormis are reported as having been among the first to invent comic fables. Many familiar fables of Aesop include \"The Crow and the Pitcher\", \"The Tortoise and the Hare\" and \"The Lion and the Mouse\". In ancient Greek and Roman education, the fable was the first of the \"progymnasmata\"—training exercises in prose composition and public speaking—wherein students would be asked to learn fables, expand upon them, invent their own, and finally use them as persuasive examples in longer forensic or deliberative speeches. The need of instructors to teach, and students to learn, a wide range of fables as material for their declamations resulted in their being gathered together in collections, like those of Aesop.\n\nAfrican oral culture has a rich story-telling tradition. As they have for thousands of years, people of all ages in Africa continue to interact with nature, including plants, animals and earthly structures such as rivers, plains and mountains. Grandparents enjoy enormous respect in African societies and fill the new role of story-telling during retirement years. Children and, to some extent, adults are mesmerized by good story-tellers when they become animated in their quest to tell a good fable.\n\nIndia has a rich tradition of fabulous novels, mostly explainable by the fact that the culture derives traditions and learns qualities from natural elements. Most of the gods are some form of animals with ideal qualities. Also hundreds of fables were composed in ancient India during the first millennium BC, often as stories within frame stories. Indian fables have a mixed cast of humans and animals. The dialogues are often longer than in fables of Aesop and often witty as the animals try to outwit one another by trickery and deceit. In Indian fables, man is not superior to the animals. The tales are often comical. The Indian fable adhered to the universally known traditions of the fable. The best examples of the fable in India are the Panchatantra and the Jataka tales. These included Vishnu Sarma's \"Panchatantra\", the \"Hitopadesha\", \"Vikram and The Vampire\", and Syntipas' \"Seven Wise Masters\", which were collections of fables that were later influential throughout the Old World. Ben E. Perry (compiler of the \"Perry Index\" of Aesop's fables) has argued controversially that some of the Buddhist \"Jataka tales\" and some of the fables in the \"Panchatantra\" may have been influenced by similar Greek and Near Eastern ones. Earlier Indian epics such as Vyasa's \"Mahabharata\" and Valmiki's \"Ramayana\" also contained fables within the main story, often as side stories or back-story. The most famous fables from the Middle East were the \"One Thousand and One Nights\", also known as the \"Arabian Nights\".\n\nFables had a further long tradition through the Middle Ages, and became part of European high literature. During the 17th century, the French fabulist Jean de La Fontaine (1621–1695) saw the soul of the fable in the moral — a rule of behavior. Starting with the Aesopian pattern, La Fontaine set out to satirize the court, the church, the rising bourgeoisie, indeed the entire human scene of his time. La Fontaine's model was subsequently emulated by England's John Gay (1685–1732); Poland's Ignacy Krasicki (1735–1801); Italy's (1739–1812) and (1754–1827); Serbia's Dositej Obradović (1739–1811); Spain's Félix María de Samaniego (1745–1801) and Tomás de Iriarte y Oropesa (1750–1791); France's Jean-Pierre Claris de Florian (1755–94); and Russia's Ivan Krylov (1769–1844).\n\nIn modern times, while the fable has been trivialized in children's books, it has also been fully adapted to modern adult literature. Felix Salten's \"Bambi\" (1923) is a \"Bildungsroman\" — a story of a protagonist's coming-of-age — cast in the form of a fable. James Thurber used the ancient fable style in his books \"Fables for Our Time\" (1940) and \"Further Fables for Our Time\" (1956), and in his stories \"The Princess and the Tin Box\" in \"The Beast in Me and Other Animals\" (1948) and \"The Last Clock: A Fable for the Time, Such As It Is, of Man\" in \"Lanterns and Lances\" (1961). Władysław Reymont's \"The Revolt\" (1922), a metaphor for the Bolshevik Revolution of 1917, described a revolt by animals that take over their farm in order to introduce \"equality.\" George Orwell's \"Animal Farm\" (1945) similarly satirized Stalinist Communism in particular, and totalitarianism in general, in the guise of animal fable.\n\nIn the 21st century the Neapolitan writer Sabatino Scia is the author of more than two hundred fables that he describes as “western protest fables.” The characters are not only animals, but also things, beings and elements from nature. Scia’s aim is the same as in the traditional fable, playing the role of revealer of human society. In Latin America, the brothers Juan and Victor Ataucuri Garcia have contributed to the resurgence of the fable. But they do so with a novel idea: use the fable as a means of dissemination of traditional literature of that place. In the book \"\"Fábulas Peruanas\" published in 2003, they have collected myths, legends, beliefs of Andean and Amazonian Peru, to write as fables. The result has been an extraordinary work rich in regional nuances. Here we discover the relationship between man and his origin, with nature, with its history, its customs and beliefs then become norms and values.\n\n\n\n\n\n"}
{"id": "11492", "url": "https://en.wikipedia.org/wiki?curid=11492", "title": "Foot", "text": "Foot\n\nThe foot (plural feet) is an anatomical structure found in many vertebrates. It is the terminal portion of a limb which bears weight and allows locomotion. In many animals with feet, the foot is a separate organ at the terminal part of the leg made up of one or more segments or bones, generally including claws or nails.\n\nThe word \"foot\", in the sense of meaning the \"terminal part of the leg of a vertebrate animal\" comes from \"Old English fot \"foot,\" from Proto-Germanic *fot (source also of Old Frisian fot, Old Saxon fot, Old Norse fotr, Danish fod, Swedish fot, Dutch voet, Old High German fuoz, German Fuß, Gothic fotus \"foot\"), from PIE root *ped- \"foot.\" \nThe \"[p]lural form feet is an instance of i-mutation.\" \n\nThe human foot is a strong and complex mechanical structure containing 26 bones, 33 joints (20 of which are actively articulated), and more than a hundred muscles, tendons, and ligaments. The joints of the foot are the ankle and subtalar joint and the interphalangeal articulations of the foot. An anthropometric study of 1197 North American adult Caucasian males (mean age 35.5 years) found that a man's foot length was 26.3 cm with a standard deviation of 1.2 cm.\n\nThe foot can be subdivided into the hindfoot, the midfoot, and the forefoot:\n\nThe \"hindfoot\" is composed of the talus (or ankle bone) and the calcaneus (or heel bone). The two long bones of the lower leg, the tibia and fibula, are connected to the top of the talus to form the ankle. Connected to the talus at the subtalar joint, the calcaneus, the largest bone of the foot, is cushioned underneath by a layer of fat.\n\nThe five irregular bones of the \"midfoot\", the cuboid, navicular, and three cuneiform bones, form the arches of the foot which serves as a shock absorber. The midfoot is connected to the hind- and fore-foot by muscles and the plantar fascia.\n\nThe \"forefoot\" is composed of five toes and the corresponding five proximal long bones forming the metatarsus. Similar to the fingers of the hand, the bones of the toes are called phalanges and the big toe has two phalanges while the other four toes have three phalanges each. The joints between the phalanges are called interphalangeal and those between the metatarsus and phalanges are called metatarsophalangeal (MTP).\nBoth the midfoot and forefoot constitute the \"dorsum\" (the area facing upwards while standing) and the \"planum\" (the area facing downwards while standing).\n\nThe \"instep\" is the arched part of the foot between the toes and the ankle.\n\n\nThere can be many sesamoid bones near the metatarsophalangeal joints, although they are only regularly present in the distal portion of the first metatarsal bone.\n\nThe human foot has two longitudinal arches and a transverse arch maintained by the interlocking shapes of the foot bones, strong ligaments, and pulling muscles during activity. The slight mobility of these arches when weight is applied to and removed from the foot makes walking and running more economical in terms of energy. As can be examined in a footprint, the medial longitudinal arch curves above the ground. This arch stretches from the heel bone over the \"keystone\" ankle bone to the three medial metatarsals. In contrast, the lateral longitudinal arch is very low. With the cuboid serving as its keystone, it redistributes part of the weight to the calcaneus and the distal end of the fifth metatarsal. The two longitudinal arches serve as pillars for the transverse arch which run obliquely across the tarsometatarsal joints. Excessive strain on the tendons and ligaments of the feet can result in fallen arches or flat feet.\n\nThe muscles acting on the foot can be classified into extrinsic muscles, those originating on the anterior or posterior aspect of the lower leg, and intrinsic muscles, originating on the dorsal (top) or plantar (base) aspects of the foot.\n\nAll muscles originating on the lower leg except the popliteus muscle are attached to the bones of the foot. The tibia and fibula and the interosseous membrane separate these muscles into anterior and posterior groups, in their turn subdivided into subgroups and layers.\n\"Anterior group\"\n\n\"Extensor group\": tibialis anterior originates on the proximal half of the tibia and the interosseous membrane and is inserted near the tarsometatarsal joint of the first digit. In the non-weight-bearing leg tibialis anterior flexes the foot dorsally and lift its medial edge (supination). In the weight-bearing leg it brings the leg towards the back of the foot, like in rapid walking. Extensor digitorum longus arises on the lateral tibial condyle and along the fibula to be inserted on the second to fifth digits and proximally on the fifth metatarsal. The extensor digitorum longus acts similar to the tibialis anterior except that it also dorsiflexes the digits. Extensor hallucis longus originates medially on the fibula and is inserted on the first digit. As the name implies it dorsiflexes the big toe and also acts on the ankle in the unstressed leg. In the weight-bearing leg it acts similar to the tibialis anterior.\n\"Peroneal group\": peroneus longus arises on the proximal aspect of the fibula and peroneus brevis below it on the same bone. Together, their tendons pass behind the lateral malleolus. Distally, peroneus longus crosses the plantar side of the foot to reach its insertion on the first tarsometatarsal joint, while peroneus brevis reaches the proximal part of the fifth metatarsal. These two muscles are the strongest pronators and aid in plantar flexion. Longus also acts like a bowstring that braces the transverse arch of the foot.\n\n\"Posterior group\"\n\nThe \"superficial layer\" of posterior leg muscles is formed by the triceps surae and the plantaris. The triceps surae consists of the soleus and the two heads of the gastrocnemius. The heads of gastrocnemius arise on the femur, proximal to the condyles, and soleus arises on the proximal dorsal parts of the tibia and fibula. The tendons of these muscles merge to be inserted onto the calcaneus as the Achilles tendon. Plantaris originates on the femur proximal to the lateral head of the gastrocnemius and its long tendon is embedded medially into the Achilles tendon. The triceps surae is the primary plantar flexor and its strength becomes most obvious during ballet dancing. It is fully activated only with the knee extended because the gastrocnemius is shortened during knee flexion. During walking it not only lifts the heel, but also flexes the knee, assisted by the plantaris.\n\nIn the \"deep layer\" of posterior muscles tibialis posterior arises proximally on the back of the interosseous membrane and adjoining bones and divides into two parts in the sole of the foot to attach to the tarsus. In the non-weight-bearing leg, it produces plantar flexion and supination, and, in the weight-bearing leg, it proximates the heel to the calf. flexor hallucis longus arises on the back of the fibula (i.e. on the lateral side), and its relatively thick muscle belly extends distally down to the flexor retinaculum where it passes over to the medial side to stretch across the sole to the distal phalanx of the first digit. The popliteus is also part of this group, but, with its oblique course across the back of the knee, does not act on the foot.\nOn the \"back\" (top) \"of the foot\", the tendons of extensor digitorum brevis and extensor hallucis brevis lie deep to the system of long extrinsic extensor tendons. They both arise on the calcaneus and extend into the dorsal aponeurosis of digits one to four, just beyond the penultimate joints. They act to dorsiflex the digits.\n\nSimilar to the intrinsic muscles of the hand, there are three groups of muscles in the \"sole of foot\", those of the first and last digits, and a central group:\n\n\"Muscles of the big toe\": abductor hallucis stretches medially along the border of the sole, from the calcaneus to the first digit. Below its tendon, the tendons of the long flexors pass through the tarsal canal. It is an abductor and a weak flexor, and also helps maintain the arch of the foot. flexor hallucis brevis arises on the medial cuneiform bone and related ligaments and tendons. An important plantar flexor, it is crucial for ballet dancing. Both these muscles are inserted with two heads proximally and distally to the first metatarsophalangeal joint. Adductor hallucis is part of this group, though it originally formed a separate system (see contrahens.) It has two heads, the oblique head originating obliquely across the central part of the midfoot, and the transverse head originating near the metatarsophalangeal joints of digits five to three. Both heads are inserted into the lateral sesamoid bone of the first digit. Adductor hallucis acts as a tensor of the plantar arches and also adducts the big toe and then might plantar flex the proximal phalanx.\n\"Muscles of the little toe\": Stretching laterally from the calcaneus to the proximal phalanx of the fifth digit, abductor digiti minimi form the lateral margin of the foot and is the largest of the muscles of the fifth digit. Arising from the base of the fifth metatarsal, flexor digiti minimi is inserted together with abductor on the first phalanx. Often absent, opponens digiti minimi originates near the cuboid bone and is inserted on the fifth metatarsal bone. These three muscles act to support the arch of the foot and to plantar flex the fifth digit.\n\n\"Central muscle group\": The four lumbricals arise on the medial side of the tendons of flexor digitorum longus and are inserted on the medial margins of the proximal phalanges. Quadratus plantae originates with two slips from the lateral and medial margins of the calcaneus and inserts into the lateral margin of the flexor digitorum tendon. It is also known as flexor accessorius. Flexor digitorum brevis arise inferiorly on the calcaneus and its three tendons are inserted into the middle phalanges of digits two to four (sometimes also the fifth digit). These tendons divide before their insertions and the tendons of flexor digitorum longus pass through these divisions. Flexor digitorum brevis flexes the middle phalanges. It is occasionally absent. Between the toes, the dorsal and plantar interossei stretch from the metatarsals to the proximal phalanges of digits two to five. The plantar interossei adducts and the dorsal interossei abducts these digits and are also plantar flexors at the metatarsophalangeal joints.\n\nDue to their position and function, feet are exposed to a variety of potential infections and injuries, including athlete's foot, bunions, ingrown toenails, Morton's neuroma, plantar fasciitis, plantar warts and stress fractures. In addition, there are several genetic disorders that can affect the shape and function of the feet, including a club foot or flat feet.\n\nThis leaves humans more vulnerable to medical problems that are caused by poor leg and foot alignments. Also, the wearing of shoes, sneakers and boots can impede proper alignment and movement within the ankle and foot. For example, High-heeled footwear are known to throw off the natural weight balance (this can also affect the lower back). For the sake of posture, flat soles with no heels are advised.\n\nA doctor who specializes in the treatment of the feet practices podiatry and is called a podiatrist. A pedorthist specializes in the use and modification of footwear to treat problems related to the lower limbs.\nFractures of the foot include:\nFoot sweat is the major cause of foot odor. Sweat itself is odorless, but it creates a beneficial environment for certain bacteria to grow and produce bad-smelling substances.\n\nIn anatomy, pronation is a rotational movement of the forearm (at the radioulnar joint) or foot (at the subtalar and talocalcaneonavicular joints). Pronation of the foot refers to how the body distributes weight as it cycles through the gait. During the gait cycle the foot can pronate in many different ways based on rearfoot and forefoot function. Types of pronation include neutral pronation, underpronation (supination), and overpronation.\n\nAn individual who neutrally pronates initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, the foot will roll in a medial direction, such that the weight is distributed evenly across the metatarsus. In this stage of the gait, the knee will generally, but not always, track directly over the hallux.\n\nThis rolling inwards motion as the foot progresses from heel to toe is the way that the body naturally absorbs shock. Neutral pronation is the most ideal, efficient type of gait when using a heel strike gait; in a forefoot strike, the body absorbs shock instead via flexation of the foot.\n\nAs with a neutral pronator, an individual who overpronates initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, however, the foot will roll too far in a medial direction, such that the weight is distributed unevenly across the metatarsus, with excessive weight borne on the hallux. In this stage of the gait, the knee will generally, but not always, track inwards.\n\nAn overpronator does not absorb shock efficiently. Imagine someone jumping onto a diving board, but the board is so flimsy that when it is struck, it bends and allows the person to plunge straight down into the water instead of back into the air. Similarly, an overpronator's arches will collapse, or the ankles will roll inwards (or a combination of the two) as they cycle through the gait. An individual whose bone structure involves external rotation at the hip, knee, or ankle will be more likely to overpronate than one whose bone structure has internal rotation or central alignment. An individual who overpronates tends to wear down their running shoes on the medial (inside) side of the shoe towards the toe area.\n\nWhen choosing a running or walking shoe, a person with overpronation can choose shoes that have good inside support—usually by strong material at the inside sole and arch of the shoe. It is usually visible. The inside support area is marked by strong greyish material to support the weight when a person lands on the outside foot and then roll onto the inside foot.\n\nAn individual who underpronates also initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, the foot will not roll far enough in a medial direction. The weight is distributed unevenly across the metatarsus, with excessive weight borne on the fifth metatarsal, towards the lateral side of the foot. In this stage of the gait, the knee will generally, but not always, track laterally of the hallux.\n\nLike an overpronator, an underpronator does not absorb shock efficiently – but for the opposite reason. The underpronated foot is like a diving board that, instead of failing to spring someone in the air because it is too flimsy, fails to do so because it is too rigid. There is virtually no give. An underpronator's arches or ankles don't experience much motion as they cycle through the gait. An individual whose bone structure involves internal rotation at the hip, knee, or ankle will be more likely to underpronate than one whose bone structure has external rotation or central alignment. Usually – but not always – those who are bow-legged tend to underpronate. An individual who underpronates tends to wear down their running shoes on the lateral (outside) side of the shoe towards the rear of the shoe in the heel area.\n\nHumans usually wear shoes or similar footwear for protection from hazards when walking outside. There are a number of contexts where it is considered inappropriate to wear shoes. Some people consider it rude to wear shoes into a house and a Māori Marae should only be entered with bare feet.\n\nFoot fetishism is the most common form of sexual fetish.\n\nA paw is the soft foot of a mammal, generally a quadruped, that has claws or nails (e.g., a cat or dog's paw). A hard foot is called a hoof. Depending on style of locomotion, animals can be classified as plantigrade (sole walking), digitigrade (toe walking), or unguligrade (nail walking).\n\nThe metatarsals are the bones that make up the main part of the foot in humans, and part of the leg in large animals or paw in smaller animals. The number of metatarsals are directly related to the mode of locomotion with many larger animals having their digits reduced to two (elk, cow, sheep) or one (horse). The metatarsal bones of feet and paws are tightly grouped compared to, most notably, the human hand where the thumb metacarpal diverges from the rest of the metacarpus.\n\nThe word \"foot\" is used to refer to a \"...linear measure was in Old English (the exact length has varied over time), this being considered the length of a man's foot; a unit of measure used widely and anciently. In this sense the plural is often foot. The current inch and foot are implied from measurements in 12c.\" \nThe word \"foot\" also has a musical meaning; a \"...metrical foot (late Old English, translating Latin pes, Greek pous in the same sense) is commonly taken to represent one rise and one fall of a foot: keeping time according to some, dancing according to others.\"\n\nThe word \"foot\" was used in Middle English to mean \"a person\" (c. 1200).\nThe expression \"...to put one's best foot foremost first recorded 1849 (Shakespeare has the better foot before, 1596)\". The expression to \"...put one's foot in (one's) mouth \"say something stupid\" was first used in 1942. The expression \"put (one's) foot in something\" meaning to \"make a mess of it\" is from was used in 1823.\n\nThe word \"footloose\" was first used in the 1690s, meaning \"free to move the feet, unshackled\"; the more \"figurative sense of \"free to act as one pleases\" was first used in 1873. Like \"footloose\", \"flat-footed\" at first had its obvious literal meaning (in 1600, it meant \"with flat feet\") but by 1912 it meant \"unprepared\" (U.S. baseball slang).\n\n"}
{"id": "11493", "url": "https://en.wikipedia.org/wiki?curid=11493", "title": "Fallout shelter", "text": "Fallout shelter\n\nA fallout shelter is an enclosed space specially designed to protect occupants from radioactive debris or fallout resulting from a nuclear explosion. Many such shelters were constructed as civil defense measures during the Cold War.\n\nDuring a nuclear explosion, matter vaporized in the resulting fireball is exposed to neutrons from the explosion, absorbs them, and becomes radioactive. When this material condenses in the rain, it forms dust and light sandy materials that resemble ground pumice. The fallout emits alpha and beta particles, as well as gamma rays.\n\nMuch of this highly radioactive material falls to earth, subjecting anything within the line of sight to radiation, becoming a significant hazard. A fallout shelter is designed to allow its occupants to minimize exposure to harmful fallout until radioactivity has decayed to a safer level.\n\nDuring the Cold War, many countries built fallout shelters for high-ranking government officials and crucial military facilities, such as Project Greek Island and Cheyenne Mountain nuclear bunker in the United States and Canada's Emergency Government Headquarters. Plans were made, however, to use existing buildings with sturdy below-ground-level basements as makeshift fallout shelters. These buildings were usually placarded with the yellow and black trefoil sign.\n\nThe National Emergency Alarm Repeater (NEAR) program was developed in the United States 1956 during the Cold War to supplement the existing siren warning systems and radio broadcasts in the event of a nuclear attack. The N.E.A.R. civilian alarm device was engineered and tested but the program was not viable and was terminated in 1967. In the U.S. in September 1961, under the direction of Steuart L. Pittman, the federal government started the Community Fallout Shelter Program. A letter from President Kennedy advising the use of fallout shelters appeared in the September 1961 issue of \"Life\" magazine.\n\nIn November 1961, in \"Fortune\" magazine, an article by Gilbert Burck appeared that outlined the plans of Nelson Rockefeller, Edward Teller, Herman Kahn, and Chet Holifield for an enormous network of concrete lined underground fallout shelters throughout the United States sufficient to shelter millions of people to serve as a refuge in case of nuclear war.\n\nSimilar projects have been undertaken in Finland, which requires all buildings with area over 600 m² to have an NBC shelter, and Norway, which requires all buildings with an area over 1000 m² to have a shelter.\n\nThe former Soviet Union and other Eastern Bloc countries often designed their underground mass-transit and subway tunnels to serve as bomb and fallout shelters in the event of an attack.\n\nGermany has protected shelters for 3% of its population, Austria for 30%, Finland for 70%, Sweden for 81% and Switzerland for 114%.\n\nSwitzerland built an extensive network of fallout shelters, not only through extra hardening of government buildings such as schools, but also through a building regulation requiring nuclear shelters in residential buildings since the 1960s (the first legal basis in this sense dates from 4 October 1963). Later, the law ensured that all residential buildings built after 1978 contained a nuclear shelter able to withstand a blast from a 12 megaton explosion at a distance of 700 metres. The \"Federal Law on the Protection of the Population and Civil Protection\" still requires nowadays that every inhabitant should have a place in a shelter close to where they live. \n\nThe Swiss authorities also maintain large communal shelters (such as the Sonnenberg Tunnel) stocked with over four months of food and fuel. The reference \"Nuclear War Survival Skills\" declared that, as of 1986, \"Switzerland has the best civil defense system, one that already includes blast shelters for over 85 percent of all its citizens.\" As of 2006, there were about 300,000 shelters built in private homes, institutions and hospitals, as well as 5,100 public shelters for a total of 8.6 million places, a level of coverage equal to 114% of the population. \n\nIn Switzerland, most residential shelters are no longer stocked with the food and water required for prolonged habitation and a large number have been converted by the owners to other uses (e.g., wine cellars, ski rooms, gyms). But the owner still has the obligation to ensure the maintenance of the shelter.\n\nA basic fallout shelter consists of shields that reduce gamma ray exposure by a factor of 1000. The required shielding can be accomplished with 10 times the thickness of any quantity of material capable of cutting gamma ray exposure in half. Shields that reduce gamma ray intensity by 50% (1/2) include 1 cm (0.4 inch) of lead, 6 cm (2.4 inches) of concrete, 9 cm (3.6 inches) of packed earth or 150 m (500 ft) of air. When multiple thicknesses are built, the shielding multiplies. Thus, a practical fallout shield is ten halving-thicknesses of packed earth, reducing gamma rays by approximately 1024 times (2).\n\nUsually, an expedient purpose-built fallout shelter is a trench; with a strong roof buried by c. 1 m (3 ft) of earth. The two ends of the trench have ramps or entrances at right angles to the trench, so that gamma rays cannot enter (they can travel only in straight lines). To make the overburden waterproof (in case of rain), a plastic sheet may be buried a few inches below the surface and held down with rocks or bricks.\n\nBlast doors are designed to absorb the shock wave of a nuclear blast, bending and then returning to their original shape.\n\nDry earth is a reasonably good thermal insulator, and over several weeks of habitation, a shelter will become dangerously hot. The simplest form of effective fan to cool a shelter is a wide, heavy frame with flaps that swing in the shelter's doorway and can be swung from hinges on the ceiling. The flaps open in one direction and close in the other, pumping air. (This is a Kearny Air Pump, or KAP, named after the inventor, Cresson Kearny)\n\nUnfiltered air is safe, since the most dangerous fallout has the consistency of sand or finely ground pumice. Such large particles are not easily ingested into the soft tissues of the body, so extensive filters are not required. Any exposure to fine dust is far less hazardous than exposure to the fallout outside the shelter. Dust fine enough to pass the entrance will probably pass through the shelter. Some shelters, however, incorporate NBC-filters for additional protection.\n\nEffective public shelters can be the middle floors of some tall buildings or parking structures, or below ground level in most buildings with more than 10 floors. The thickness of the upper floors must form an effective shield, and the windows of the sheltered area must not view fallout-covered ground that is closer than 1.5 km (1 mi). One of Switzerland's solutions is to utilise road tunnels passing through the mountains, with some of these shelters being able to protect tens of thousands.\n\nFallout shelters are not always underground. Above ground buildings with walls and roofs dense enough to afford a meaningful protection factor can be used as a fallout shelter.\n\nA battery-powered radio may be helpful to get reports of fallout patterns and clearance. However, radio and other electronic equipment may be disabled by electromagnetic pulse. For example, even at the height of the cold war, EMP protection had been completed for only 125 of the approximately 2,771 radio stations in the United States Emergency Broadcast System. Also, only 110 of 3,000 existing Emergency Operating Centers had been protected against EMP effects. The Emergency Broadcast System has since been supplanted in the United States by the Emergency Alert System.\n\nThe reference \"Nuclear War Survival Skills\" includes the following supplies in a list of \"Minimum Pre-Crisis Preparations\": one or more shovels, a pick, a bow-saw with an extra blade, a hammer, and 4-mil polyethylene film (also any necessary nails, wire, etc.); a homemade shelter-ventilating pump (a KAP); large containers for water; a plastic bottle of sodium hypochlorite bleach; one or two KFMs and the knowledge to operate them; at least a 2-week supply of compact, nonperishable food; an efficient portable stove; wooden matches in a waterproof container; essential containers and utensils for storing, transporting, and cooking food; a hose-vented 5-gallon can, with heavy plastic bags for liners, for use as a toilet; tampons; insect screen and fly bait; any special medications needed by family members; pure potassium iodide, a 2-oz bottle, and a medicine dropper; a first-aid kit and a tube of antibiotic ointment; long-burning candles (with small wicks) sufficient for at least 14 nights; an oil lamp; a flashlight and extra batteries; and a transistor radio with extra batteries and a metal box to protect it from electromagnetic pulse.\n\nInhabitants should have water on hand, 1-2 gallons per person per day. Water stored in bulk containers requires less space than water stored in smaller bottles.\n\nCommercially made Geiger counters are expensive and require frequent calibration. It is possible to construct an electrometer-type radiation meter called the Kearny fallout meter, which does not require batteries or professional calibration, from properly-scaled plans with just a coffee can or pail, gypsum board, monofilament fishing line, and aluminum foil. Plans are freely available in the public domain in the reference \"Nuclear War Survival Skills\" by Cresson Kearny.\n\nInhabitants should plan to remain sheltered for at least two weeks (with an hour out at the end of the first week – see Swiss Civil Defense guidelines (which was once part of Swiss Zivilschutz)), then work outside for gradually increasing amounts of time, to four hours a day at three weeks. The normal work is to sweep or wash fallout into shallow trenches to decontaminate the area. They should sleep in a shelter for several months. Evacuation at three weeks is recommended by official authorities.\n\nIf available, inhabitants may take potassium iodide at the rate of 130 mg/day per adult (65 mg/day per child) as an additional measure to protect the thyroid gland from the uptake of dangerous radioactive iodine, a component of most fallout and reactor waste.\n\nIn the vast majority of accidents, and in all atomic bomb blasts, the threat due to beta and gamma emitters is greater than that posed by the alpha emitters in the fallout. Alpha particles are identical to a helium-4 nucleus (two protons and two neutrons), and travel at speeds in excess of 5% of the speed of light. Alpha particles have little penetrating power; most cannot penetrate through human skin. Avoiding direct exposure with fallout particles will prevent injury from alpha radiation.\n\nBeta radiation consists of particles (high-speed electrons) given off by some fallout. Most beta particles cannot penetrate more than about 10 feet (3 metres) of air or about inch (3 millimetres) of water, wood, or human body tissue; or a sheet of aluminum foil. Avoiding direct exposure with fallout particles will prevent most injuries from beta radiation.\n\nThe primary dangers associated with beta radiation are internal exposure from ingested fallout particles and beta burns from fallout particles no more than a few days old. Beta burns can result from contact with highly radioactive particles on bare skin; ordinary clothing separating fresh fallout particles from the skin can provide significant shielding.\n\nGamma radiation penetrates further through matter than alpha or beta radiation. Most of the design of a typical fallout shelter is intended to protect against gamma rays. Gamma rays are better absorbed by materials with high atomic numbers and high density, although neither effect is important compared to the total mass per area in the path of the gamma ray. Thus, lead is only modestly better as a gamma shield than an equal mass of another shielding material such as aluminum, concrete, water or soil.\n\nSome gamma radiation from fallout will penetrate into even the best shelters. However, the radiation dose received while inside a shelter can be significantly reduced with proper shielding. Ten halving thicknesses of a given material can reduce gamma exposure to less than of unshielded exposure.\n\nThe bulk of the radioactivity in nuclear accident fallout is more long-lived than that in weapons fallout. A good table of the nuclides, such as that provided by the Korean Atomic Energy Research Institute, includes the fission yields of the different nuclides. From this data it is possible to calculate the isotopic mixture in the fallout (due to fission products in bomb fallout).\n\nWhile a person's home may not be a purpose-made shelter, it could be thought of as one if measures are taken to improve the degree of fallout protection.\n\nThe main threat of beta radiation exposure comes from \"hot particles\" in contact with or close to the skin of a person. Also, swallowed or inhaled hot particles could cause beta burns. As it is important to avoid bringing hot particles into the shelter, one option is to remove one's outer clothing, or follow other decontamination procedures, on entry. Fallout particles will cease to be radioactive enough to cause beta burns within a few days following a nuclear explosion. The danger of gamma radiation will persist for far longer than the threat of beta burns in areas with heavy fallout exposure.\n\nThe gamma dose rate due to the contamination brought into the shelter on the clothing of a person is likely to be small (by wartime standards) compared to gamma radiation that penetrates through the walls of the shelter. The following measures can be taken to reduce the amount of gamma radiation entering the shelter:\n\nFallout shelters feature prominently in the Robert A. Heinlein novel \"Farnham's Freehold\" (Heinlein built a fairly extensive shelter near his home in Colorado Springs in 1963), \"Pulling Through\" by Dean Ing, \"A Canticle for Leibowitz\" by Walter M. Miller and \"Earth\" by David Brin.\n\nThe \"Twilight Zone\" episode \"The Shelter\", from a Rod Serling script, deals with the consequences of actually using a shelter. Another episode of the series called \"One More Pallbearer\" featured a fallout shelter owned by millionaire. The 1985 adaption of the series had the episode \"Shelter Skelter\" that featured a fallout shelter.\n\nIn the \"Only Fools and Horses\" episode \"The Russians are Coming\", Derek Trotter buys a lead fallout shelter, then decides to construct it in fear of an impending nuclear war caused by the Soviet Union (who were still active during the episode's creation).\n\nIn 1999 the film \"Blast from the Past\" was released. It is a romantic comedy film about a nuclear physicist, his wife, and son that enter a well-equipped, spacious fallout shelter during the 1962 Cuban Missile Crisis. They do not emerge until 35 years later, in 1997. The film shows their reaction to contemporary society.\n\nThe \"Fallout\" series of computer games depicts the remains of human civilization after an immensely destructive global nuclear war; the United States of America had built underground vaults that were advertised to protect the population against a nuclear attack, but almost all of them were in fact meant to lure subjects for long-term human experimentation. \n\nFallout Shelter is a free-to-play mobile simulation video game developed by Bethesda Game Studios and published by Bethesda Softworks. Part of the Fallout series, it was released for iOS devices on June 14, 2015, and was released for Android devices on August, 13 2015.\n\n\"Paranoia\", a role-playing game, takes place in a form of fallout shelter, which has become ruled by an insane computer.\n\nThe \"Metro 2033\" book series by Russian author Dmitry Glukhovsky depicts survivors' life in the subway systems below Moscow and Saint-Petersburg after a nuclear exchange between the Russian Federation and the United States of America.\n\nFallout shelters are often featured on the reality television show \"Doomsday Preppers\".\n\nThe Silo series of novellas by Hugh Howey feature extensive fallout-style shelters that protect the inhabitants from an initially unknown disaster.\n\n\nNation specific:\n\nGeneral:\n\n\nPublications:\n\n"}
{"id": "11494", "url": "https://en.wikipedia.org/wiki?curid=11494", "title": "History of the Federated States of Micronesia", "text": "History of the Federated States of Micronesia\n\nThe Federated States of Micronesia are located on the Caroline Islands in the western Pacific Ocean. The history of the modern Federated States of Micronesia is one of settlement by Micronesians; colonization by Spain, Germany, and Japan; United Nations trusteeship under United States-administered Trust Territory of the Pacific Islands; and gradual independence beginning with the ratification of a sovereign constitution in 1979.\n\nThe ancestors of the Micronesians settled there over 4,000 years ago. A decentralized chieftain-based system eventually evolved into a more centralized economic and religious culture centered on Yap and Pohnpei.\n\nOn Pohnpei, pre-colonial history is divided into three eras: \"Mwehin Kawa\" or \"Mwehin Aramas\" (Period of Building, or Period of Peopling, before ca. 1100); \"Mwehin Sau Deleur\" (Period of the Lord of Deleur, ca. 1100 to ca. 1628); and \"Mwehin Nahnmwarki\" (Period of the Nahnmwarki, ca. 1628 to ca. 1885). Pohnpeian legend recounts that the Saudeleur rulers, the first to bring government to Pohnpei, were of foreign origin. The Saudeleur centralized form of absolute rule is characterized in Pohnpeian legend as becoming increasingly oppressive over several generations. Arbitrary and onerous demands, as well as a reputation for offending Pohnpeian deities, sowed resentment among Pohnpeians. The Saudeleur Dynasty ended with the invasion of Isokelekel, another semi-mythical foreigner, who replaced the Saudeleur rule with the more decentralized \"nahnmwarki\" system in existence today. Isokelekel is regarded as the creator of the modern Pohnpeian \"nahnmwarki\" social system and the father of the Pompeian people.\n\nNan Madol offshore of Temwen Island near Pohnpei, consists of a series of small artificial islands linked by a network of canals, and is often called the \"Venice of the Pacific\". It is located near the island of Pohnpei and was the ceremonial and political seat of the Saudeleur Dynasty that united Pohnpei's estimated 25,000 people until its centralized system collapsed amid the invasion of Isokelekel. Isokelekel and his descendants initially occupied the stone city, but later abandoned it.\n\nEuropean explorers - first the Portuguese in search of the Spice Islands (Indonesia) and then the Spanish - reached the Carolines in the 16th century, with the Spanish establishing sovereignty.\n\nSpain sold the islands to Germany in 1899 under the terms of the German–Spanish Treaty of that year.\n\nYap was a major German naval communications center before the First World War and an important international hub for cable telegraphy. It was occupied by Japanese troops in September, 1914, and passed to the Japanese Empire under the Versailles Treaty in 1919 as a mandated territory under League of Nations supervision. US commercial rights on the island were secured by a special US-Japanese treaty to that effect, concluded on February 11, 1922.\n\nDuring World War I, many of the Germany possessions in the Pacific were conquered by Japan, who fought on the side of the Allies of World War I and was active in the Asian and Pacific theatre of World War I.\n\nThe Empire of Japan administrated the islands from 1920 under the South Pacific Mandate granted by the League of Nations. During this period, the Japanese population grew to over 100,000 throughout Micronesia, while the indigenous population was about 40,000. Sugar cane, mining, fishing and tropical agriculture became the major industries.\n\nIn World War II, Japanese-held Yap was one of the islands bypassed in the U.S. \"island-hopping\" strategy, although it was regularly bombed by U.S. ships and aircraft, and Yap-based Japanese bombers did some damage in return. The Japanese garrison comprised 4,423 Imperial Japanese Army men under the command of Colonel Daihachi Itoh and 1,494 Imperial Japanese Navy men. A significant portion of the Japanese fleet was based in Truk Lagoon. In February 1944, Operation Hailstone, one of the most important naval battles of the war, took place at Truk, in which many Japanese support vessels and aircraft were destroyed.\n\nWorld War II brought an abrupt end to the relative prosperity experienced during Japanese civil administration.\n\nThe United Nations created the Trust Territory of the Pacific Islands (TTPI) in 1947. Pohnpei (then including Kusaie), Truk, Yap, Palau, the Marshall Islands and the Northern Mariana Islands, together constituted the TTPI. The United States accepted the role of Trustee of this, the only United Nations Trusteeship to be designated as a \"Security Trusteeship\", whose ultimate disposition was to be determined by the UN Security Council. As Trustee the US was to \"promote the economic advancement and self-sufficiency of the inhabitants.\"\n\nOn May 10, 1979, four of the Trust Territory districts ratified the Constitution of the Federated States of Micronesia. The neighboring trust districts of Palau, the Marshall Islands, and the Northern Mariana Islands chose not to participate. The Honorable Tosiwo Nakayama, the former President of the Congress of Micronesia, became the first President of the FSM and formed his Cabinet. The FSM signed a Compact of Free Association with the U.S., which entered into force on November 3, 1986, marking Micronesia's emergence from trusteeship to independence. Under the Compact, the U.S. has full authority and responsibility for the defense of the FSM. This security relationship can be changed or terminated by mutual agreement. The Compact provides U.S. grant funds and federal program assistance to the FSM. Amended financial assistance provisions came on-line in FY 2004. The basic relationship of free association continues indefinitely.\n\nTrusteeship of the islands ended under United Nations Security Council Resolution 683, passed on December 22, 1990. The Compact was renewed in 2004.\n\n\n"}
{"id": "11495", "url": "https://en.wikipedia.org/wiki?curid=11495", "title": "Politics of the Federated States of Micronesia", "text": "Politics of the Federated States of Micronesia\n\nThe politics of the Federated States of Micronesia (FSM) takes place in a framework of a federal representative democratic republic. The President of the Federated States of Micronesia is both head of state and head of government. Executive power is exercised by the president and his cabinet, while legislative power is vested in both the president and the Congress. The judiciary is independent of the executive and the legislature.\n\nThe internal workings of the Micronesia are governed by the 1979 constitution, which guarantees fundamental human rights and establishes a separation of governmental powers. The Federation is in free association with the United States; the Compact of Free Association entered into force 3 November 1986.\n\nThe president and the vice president are elected by Congress from among the four senators-at-large for four-year terms. The president is both the chief of state and head of government. Their congressional seats are then filled by special elections. The president and vice president are supported by an appointed cabinet.\n\nThe Congress has fourteen non-partisan members, ten members elected for a two-year term in single-seat constituencies and four members elected for a four-year term, one from every state 'at large'.\n\nA head of state (the President) and a legislature are elected on a national level. As far as available, at the last elections, 8 March 2005, only non-partisans have been elected. The president is elected for a four-year term by Congress. There are no political parties in Micronesia, though they are not banned. Political allegiances depend mainly on family and island-related factors.\nThe judiciary is headed by the Supreme Court, which is divided into trial and appellate divisions. The president appoints judges with the advice and consent of the Congress. Andon Amaraich was Chief Justice of the Supreme Court until his death in January 2010. He was succeeded by Martin G. Yinug, who served until his death on August 31, 2014. He was succeeded by Dennis K. Yamase, who continues to serve as Chief Justice of the Supreme Court since his investiture on October 2, 2015.\n\nThe FSM is divided in four states: Chuuk (Truk), Kosrae, Pohnpei, and Yap. Each has its own constitution, elected legislature, and governor. The state governments maintain considerable power, particularly regarding the implementation of budgetary policies.\n\nAsDB, ESCAP, G-77, IBRD, ICAO, IDA, IFC, IMF, Intelsat, IOC, ITU, OPCW, PIF, Sparteca, SPC, UN, UNCTAD, WHO, WMO\n\n\nGovernment\n"}
{"id": "11496", "url": "https://en.wikipedia.org/wiki?curid=11496", "title": "Geography of the Federated States of Micronesia", "text": "Geography of the Federated States of Micronesia\n\nGeography of the Federated States of Micronesia (FSM), a country located in the western Pacific Ocean, and in the Micronesia cultural and ecological sub-region of Oceania.\n\nThe country consists of 607 islands extending across the Caroline Islands Archipelago. They are east of the Philippine Islands, and north of the island of New Guinea. The federal capital is Palikir, on Pohnpei island.\n\nThe 607 islands are grouped into four states, and east to west are: \n\nSeparated from the main islands in southern Pohnpei State are the two islands of Nukuoro and Kapingamarangi. They are geographically part of the Micronesia region, but are linguistically and culturally part of the Polynesia region. The indigenous languages spoken on these two islands are in the Samoic family of Polynesian languages.\n\nThe Federated States of Micronesia are an island group in the Caroline Islands Archipelago of the western Pacific Ocean, in the Micronesia sub-region of Oceania.\n\nLocated about three-quarters of the way from Hawaii to Indonesia at Geographic coordinates: \nMap references are Oceania and Micronesia.\n\nArea:\n\nThe country's total area is four times the size of Washington, D.C. in the U.S.\n\nCoastline:\nThe combined coastlines of the country's 607 islands equal .\n\nMaritime claims:\n\nThe country's 607 islands vary from high mountainous ones to low coral atolls. Geologically, there are volcanic rock outcroppings on the islands of Pohnpei, Kosrae, and Truk.\n\n\nThe extreme points of the Federated States of Micronesia, the landforms that are farther north, south, east or west — than any other location in the country.\n\nEnvironment—current issues:\nOverfishing, climate change, land and water pollution.\n\nEnvironment—international agreements:\n\n\nProducts:\nTropical woods and lumber, marine products, deep-seabed minerals, surface mined phosphate.\n\nThe Federated States of Micronesia enjoys a tropical climate, with quite even, warm temperatures throughout the year.\n\nPrecipitation is generally plentiful, with heavy year-round rainfall. Pohnpei reputedly is one of the wettest places on earth, with up to 330 inches (8.4 m) of rain per year. Nevertheless, drought conditions do occur periodically throughout FSM, especially when the El Niño condition moves into the Western Pacific, when groundwater supplies can dwindle to emergency proportions.\n\nTropical typhoons are an annual threat, from June to December. The country is located on southern edge of the typhoon belt, with occasionally severe damage, particularly to the low-lying atolls.\n\nTsunamis and rising sea levels are other natural threats.\n\n"}
{"id": "11497", "url": "https://en.wikipedia.org/wiki?curid=11497", "title": "Demographics of the Federated States of Micronesia", "text": "Demographics of the Federated States of Micronesia\n\nThis article is about the demographic features of the population of the Federated States of Micronesia, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.\n\nThe Demographics of the Federated States of Micronesia refers to the population characteristics of people who inhabit the Federated States of Micronesia. The indigenous population of the Federated States of Micronesia, which is predominantly Micronesian, consists of various ethnolinguistic groups. English has become the common language. Population growth remains high at more than 3%, but is ameliorated somewhat by net emigration.\n\nThe island of Pohnpei is genetically notable for the prevalence of the extreme form of color blindness known as maskun.\n\nThe following demographic statistics are from the CIA World Factbook, unless otherwise indicated.\n\nPopulation\n\n??? (July 2015 est.)\n\nAge structure\n\n0–14 years: 35.68% (male 114,349/female 107,750)<BR>15–24 years: 20.01% (male 64,036/female 60,512)<BR>25–54 years: 35.73% (male 113,306/female 109,133)<BR>55–64 years: 4.45% (male 13,863/female 13,820)<BR>65 years and over: 4.13% (male 12,315/female 13,385) (2015 est.)\n\nPopulation growth rate\n\n2.02% (2015 est.)\n\nBirth rate\n\n25.77 births/1,000 population (2015 est.)\n\nDeath rate\n\n3.85 deaths/1,000 population (2015 est.)\n\nNet migration rate\n\n1.75 migrant(s)/1,000 population (2015 est.)\n\nInfant mortality rate\n\nTotal: 15.65 deaths/1,000 live births\n\nMale: 17.84 deaths/1,000 live births\n\nFemale: 13.35 deaths/1,000 live births (2015 est.)\n\nLife expectancy at birth\n\nTotal population: 75.12 years<BR>Male: 72.49 years<BR>Female: 77.88 years (2015 est.)\n\nTotal fertility rate\n\n3.28 children born/woman (2015 est.)\n\nNationality<br>\"noun:\" \nMicronesian(s)\n<br>\"adjective:\"\nMicronesian; Kosrae(s), Pohnpeian(s), Trukese, Yapese\n\nEthnic groups\n\nMelanesian 95.3%, Polynesian 3.1%, Micronesian 1.2%, other 0.3% (2009 est.)\n\nReligions\n\nProtestant 73.4% (Church of Melanesia 31.9%, South Sea Evangelical 17.1%, Seventh Day Adventist 11.7%, United Church 10.1%, Christian Fellowship Church 2.5%), Roman Catholic 19.6%, other Christian 2.9%, other 4%, none 0.03%, unspecified 0.1% (2009 est.)\n\nLanguages\n\nMelanesian pidgin (lingua franca), English (official but spoken by only 1%-2% of the population), 120 indigenous languages\n\nLiteracy\n\nDefinition: age 15 and over can read and write<BR>Total Population: 84.1%<BR>Male: 88.9%<BR>Female: 79.2% (2009 est.)\n"}

{"id": "6859", "url": "https://en.wikipedia.org/wiki?curid=6859", "title": "Chiang Kai-shek", "text": "Chiang Kai-shek\n\nChiang Kai-shek (October 31, 1887 – April 5, 1975), also romanized as Chiang Chieh-shih and known as Chiang Chungcheng, was a Chinese political and military leader who served as the leader of the Republic of China between 1928 and 1975. Chiang was an influential member of the Kuomintang (KMT), the Chinese Nationalist Party, and was a close ally of Sun Yat-sen's. He became the Commandant of the Kuomintang's Whampoa Military Academy and took Sun's place as leader of the KMT, following the Canton Coup in early 1926. Having neutralized the party's left wing, Chiang then led Sun's long-postponed Northern Expedition, conquering or reaching accommodations with China's many warlords.\n\nFrom 1928 to 1948, he served as chairman of the National Military Council of the Nationalist Government of the Republic of China (ROC). Chiang Kai-shek was socially conservative, promoting traditional Chinese culture in the New Life Movement, and rejecting both western democracy and Sun's nationalist democratic socialism in favour of an authoritarian government. Unable to maintain Sun's good relations with the Communists, he purged them in a massacre at Shanghai and repression of uprisings at Guangzhou and elsewhere.\n\nAt the onset of the Second Sino-Japanese War, which later became the Chinese theater of World War II, Zhang Xueliang kidnapped Chiang and obliged him to establish a Second United Front with the Communists. After the defeat of the Japanese, the American-sponsored Marshall Mission, an attempt to negotiate a coalition government, failed in 1946. The Chinese Civil War resumed, with the Chinese Communist Party (CCP) led by Mao Zedong defeating the Nationalists and declaring the People's Republic of China in 1949. Chiang's government and army retreated to Taiwan, where Chiang imposed martial law and persecuted critics in a period known as the \"White Terror\".\n\nAfter evacuating to Taiwan, Chiang's government continued to declare its intention to retake mainland China. Chiang ruled Taiwan securely as President of the Republic of China and General of the Kuomintang until his death in 1975, just one year short of Mao's death.\n\nSimilarly to that of Mao, Chiang is regarded as a controversial figure; supporters credit him with playing a major part in the Allied victory of the Second World War; detractors and critics denounce him as a dictator at the front of an authoritarian autocracy who suppressed and purged opponents and critics and arbitrarily incarcerated those he deemed as opposing to the Kuomintang among others.\n\nLike many other Chinese historical figures, Chiang used several names throughout his life. That inscribed in the genealogical records of his family is Jiang Zhoutai (). This so-called \"register name\" (譜名) is the one under which his extended relatives knew him, and the one he used in formal occasions, such as when he got married. In deference to tradition, family members did not use the register name in conversation with people outside of the family. In fact, the concept of real or original name is not as clear-cut in China as it is in the Western world.\n\nIn honor of tradition, Chinese families waited a number of years before officially naming their offspring. In the meantime, they used a \"milk name\" (乳名), given to the infant shortly after his birth and known only to the close family. Thus, the actual name that Chiang received at birth was Jiang Ruiyuan ().\n\nIn 1903, the 16-year-old Chiang went to Ningbo to be a student, and he chose a \"school name\" (學名). This was actually the formal name of a person, used by older people to address him, and the one he would use the most in the first decades of his life (as the person grew older, younger generations would have to use one of the courtesy names instead). (Colloquially, the school name is called \"big name\" (大名), whereas the \"milk name\" is known as the \"small name\" (小名).) The school name that Chiang chose for himself was Zhiqing (; means \"purity of intentions\"). For the next fifteen years or so, Chiang was known as Jiang Zhiqing (Wade-Giles: Chiang Chi-ch‘ing). This is the name under which Sun Yat-sen knew him when Chiang joined the republicans in Guangzhou in the 1910s.\n\nIn 1912, when Jiang Zhiqing was in Japan, he started to use the name Chiang Kai-shek (Chinese: 蔣介石; Pinyin: ; Wade-Giles: Chiang Chieh-shih) as a pen name for the articles that he published in a Chinese magazine he founded: \"Voice of the Army\" (Chinese: 軍聲). \"Jieshi\" is the Pinyin romanization of this name, based on Mandarin, but the most recognized romanized rendering is \"Kai-shek\" which is in Cantonese romanization. As the republicans were based in Canton (a Cantonese speaking area, now commonly known as Guangdong province), Chiang became known by Westerners under the Cantonese romanization of his courtesy name, while the family name as known in English seems to be the Mandarin pronunciation of his Chinese family name, transliterated in Wade-Giles.\n\n\"Kai-shek\"/\"Jieshi\" soon became Chiang's courtesy name (字). Some think the name was chosen from the classic Chinese book the \"I Ching\"; \"介于石\", \"\"[he who is] firm as a rock\"\", is the beginning of line 2 of Hexagram 16, \"豫\". Others note that the first character of his courtesy name is also the first character of the courtesy name of his brother and other male relatives on the same generation line, while the second character of his courtesy name \"shi\" (石—meaning \"stone\") suggests the second character of his \"register name\" \"tai\" (泰—the famous Mount Tai of China). Courtesy names in China often bore a connection with the personal name of the person. As the courtesy name is the name used by people of the same generation to address the person, Chiang soon became known under this new name.\n\nSometime in 1917 or 1918, as Chiang became close to Sun Yat-sen, he changed his name from Jiang Zhiqing to Jiang Zhongzheng (). By adopting the name Chung-cheng (\"central uprightness\"), he was choosing a name very similar to the name of Sun Yat-sen, who was (and still is) known among Chinese as Zhongshan (中山—meaning \"central mountain\"), thus establishing a link between the two. The meaning of uprightness, rectitude, or orthodoxy, implied by his name, also positioned him as the legitimate heir of Sun Yat-sen and his ideas. Not surprisingly, the Chinese Communists always rejected the use of this name and it is not well known in mainland China. However, it was readily accepted by members of the Chinese Nationalist Party and is the name under which Chiang Kai-shek is still commonly known in Taiwan. Often the name is shortened to \"Chung-cheng\" only (\"Zhongzheng\" in Pinyin). Many public places in Taiwan are named Chungcheng after Chiang. For many years passengers arriving at the Chiang Kai-shek International Airport were greeted by signs in Chinese welcoming them to the \"Chung Cheng International Airport\". Similarly, the monument erected to Chiang's memory in Taipei, known in English as Chiang Kai-shek Memorial Hall, was literally named \"Chung Cheng Memorial Hall\" in Chinese. In Singapore, Chung Cheng High School was named after him.\n\nHis name is also written in Taiwan as \"The Late President Lord Chiang\" (先總統　蔣公), where the one-character-wide space known as nuo tai shows respect; this practice has lost some popularity. However, he is still known as \"Lord Chiang\" (蔣公) (without the title or space), along with the name \"Chiang Chung-cheng\", in Taiwan.\n\nChiang was born in Xikou, a town in Fenghua, Zhejiang, about of central Ningbo. His family's ancestral home—a concept important in Chinese society—was Heqiao (), a town in Yixing, Jiangsu, about southwest of central Wuxi and from the shores of Lake Tai. His father Jiang Zhaocong () and mother Wang Caiyu () were members of a prosperous family of salt merchants. Chiang lost his father when he was eight, and he wrote of his mother as the \"embodiment of Confucian virtues\".The young Chiang was inspired throughout his youth by the realisation that the reputation of an honored family rested upon his shoulders. He was a mischievous child, at only three years old he thrust a pair of chopsticks down his throat to see how far they would reach. They became stuck and were removed with great difficulty. Even at a young age he was interested in war, and directed mimic campaigns with a wooden sword and spear. As he grew older he became more aware of the issues that surrounded him, and in his speech to the Kuomintang in 1945, he said:\n\n\"As you all know I was an orphan boy in a poor family. Deprived of any protection after the death of her husband, my mother was exposed to the most ruthless exploitation by neighbouring ruffians and the local gentry. The efforts she made in fighting against the intrigues of these family intruders certainly endowed her with child, brought up in such environment, with an indomitable spirit to fight for justice. I felt throughout my childhood that mother and I were fighting a helpless lone war. We were alone in a desert, no available or possible assistance could we look forward to. But our determination was never shaken, nor hope abandoned.\"\n\nChiang grew up at a time in which military defeats, natural disasters, revolts, and the machinations of the empress dowager Cixi had left the Manchu-dominated Qing Empire destabilized and in debt. Successive demands of the Western powers and Japan since the Opium War had left China owing millions of taels of silver. He decided to pursue a military career. He began his military training at the Baoding Military Academy in 1906, the same year Japan left its bimetallic currency standard, devaluing its yen. He left for Tokyo Shinbu Gakko, a preparatory school for the Imperial Japanese Army Academy intended for Chinese students, in 1907. There, he came under the influence of compatriots to support the revolutionary movement to overthrow the Qing and to set up a Han-dominated Chinese republic. He befriended fellow Zhejiangese Chen Qimei, and in 1908 Chen brought Chiang into the Tongmenghui, an important revolutionary brotherhood of the era. Finishing his schooling, Chiang served in the Imperial Japanese Army from 1909 to 1911.\n\nChiang returned to China in 1911 after learning of the outbreak of the Wuchang Uprising, intending to fight as an artillery officer. He served in the revolutionary forces, where he led a regiment in Shanghai under his friend and mentor Chen Qimei, as one of Chen's chief lieutenants. In early 1912, a dispute arose between Chen and Tao Chen-chang, who was an influential member of the Revolutionary Alliance and who opposed both Sun Yat-sen and Chen. Tao sought to avoid escalating the quarrel by hiding in a hospital but was discovered there by Chiang. Chen dispatched assassins. Chiang may not have taken part in the act but would later assume responsibility to help Chen avoid trouble. Chen valued Chiang despite Chiang's already legendary temper, believing that such bellicosity was useful in a military leader. Alternatively, Professor Pichon Loh reports that Chiang may have killed Tao in the hospital with a pistol.\n\nChiang's friendship with Chen Qimei signaled an association with Shanghai's criminal syndicate (the Green Gang headed by Du Yuesheng and Huang Jinrong). During Chiang's time in Shanghai, he was watched by British-administered Shanghai International Settlement police, who charged him with various felonies. These charges never resulted in a trial and Chiang was never jailed.\n\nChiang became a founding member of the KMT after the success of the 1911 Revolution. After the takeover of the Republican government by Yuan Shikai and the failed Second Revolution in 1913, Chiang, like his KMT comrades, divided his time between exile in Japan and the havens of the Shanghai International Settlement. In Shanghai, Chiang cultivated ties with the city's underworld gangs, which were dominated by the notorious Green Gang and its leader Du Yuesheng. On May 18, 1916, agents of Yuan Shikai assassinated Chen Qimei. Chiang then succeeded Chen as leader of the Chinese Revolutionary Party in Shanghai. Sun Yat-sen's political career was at its lowest point during this time when most of his old Revolutionary Alliance comrades refused to join him in the exiled Chinese Revolutionary Party.\n\nIn 1917, Sun Yat-sen moved his base of operations to Guangzhou, and Chiang joined him in 1918. At this time Sun remained largely sidelined; and, without arms or money, was soon expelled from Guangzhou and exiled again to Shanghai. He was restored to Guangzhou with mercenary help in 1920. After returning to Guangzhou, a rift developed between Sun, who sought to militarily unify China under the KMT, and Guangdong Governor Chen Jiongming, who wanted to implement a federalist system with Guangdong as a model province. On June 16, 1922, Ye Ju, a general of Chen's whom Sun had attempted to exile, led an assault of Guangzhou's Presidential Palace. Sun had already fled to the naval yard and boarded the SS \"Haiqi\", but his wife narrowly evaded shelling and rifle fire as she fled. They met on the SS \"Yongfeng\", where they were joined—as swiftly as he could return from Shanghai, where he was ritually mourning his mother's death—by Chiang. For about 50 days, Chiang stayed with Sun, protecting and caring for him and earning his lasting trust. They abandoned their attacks on Chen on August 9, taking a British ship to Hong Kong and traveling to Shanghai by steamer.\n\nSun regained control of Guangzhou in early 1923, again with the help of mercenaries from Yunnan and from the Comintern. Undertaking a reform of the KMT, he established a revolutionary government aimed at unifying China under the KMT. That same year, Sun sent Chiang to spend three months in Moscow studying the Soviet political and military system. During his trip in Russia, Chiang met Leon Trotsky and other Soviet leaders, but quickly came to the conclusion that the Russian model of government was not suitable for China. Chiang later sent his eldest son, Ching-kuo, to study in Russia. After his father's split from the First United Front in 1927, Ching-kuo was forced to stay there, as a hostage, until 1937. Chiang wrote in his diary, \"It is not worth it to sacrifice the interest of the country for the sake of my son.\" Chiang even refused to negotiate a prisoner swap for his son in exchange for the Chinese Communist Party leader. His attitude remained consistent, and he continued to maintain, by 1937, that \"I would rather have no offspring than sacrifice our nation's interests.\" Chiang had absolutely no intention of ceasing the war against the Communists.\n\nChiang Kai-shek returned to Guangzhou and in 1924 was appointed Commandant of the Whampoa Military Academy by Sun. Chiang resigned from the office for one month in disagreement with Sun's extremely close cooperation with the Comintern, but returned at Sun's demand. The early years at Whampoa allowed Chiang to cultivate a cadre of young officers loyal to both the KMT and himself.\n\nThroughout his rise to power, Chiang also benefited from membership within the nationalist Tiandihui fraternity, to which Sun Yat-sen also belonged, and which remained a source of support during his leadership of the Kuomintang.\n\nSun Yat-sen died on March 12, 1925, creating a power vacuum in the Kuomintang. A contest ensued among Wang Jingwei, Liao Zhongkai, and Hu Hanmin. In August, Liao was assassinated and Hu arrested for his connections to the murderers. Wang Jingwei, who had succeeded Sun as chairman of the Guangzhou regime, seemed ascendant but was forced into exile by Chiang following the Canton Coup. The , renamed the \"Zhongshan\" in Sun's honor, had appeared off Changzhou—the location of the Whampoa Academy—on apparently falsified orders and amid a series of unusual phone calls trying to ascertain Chiang's location. He initially considered fleeing Guangzhou and even booked passage on a Japanese steamer, but then decided to use his military connections to declare martial law on March 20, 1926, and crack down on Communist and Soviet influence over the NRA, the military academy, and the party. The right wing of the party supported him and Stalin—anxious to maintain Soviet influence in the area—had his lieutenants agree to Chiang's demands regarding a reduced Communist presence in the KMT leadership in exchange for certain other concessions. The rapid replacement of leadership enabled Chiang to effectively end civilian oversight of the military after May 15, though his authority was somewhat limited by the army's own regional composition and divided loyalties. On June 5, 1926, he was named commander-in-chief of the National Revolutionary Army and, on July 27, he finally launched Sun's long-delayed Northern Expedition, aimed at conquering the northern warlords and bringing China together under the KMT.\n\nThe NRA branched into three divisions: to the west was the returned Wang Jingwei, who led a column to take Wuhan; Bai Chongxi's column went east to take Shanghai; Chiang himself led in the middle route, planning to take Nanjing before pressing ahead to capture Beijing. However, in January 1927, Wang Jingwei and his KMT leftist allies took the city of Wuhan amid much popular mobilization and fanfare. Allied with a number of Chinese Communists and advised by Soviet agent Mikhail Borodin, Wang declared the National Government as having moved to Wuhan. Having taken Nanjing in March (and briefly visited Shanghai, now under the control of his close ally Bai Chongxi), Chiang halted his campaign and prepared a violent break with Wang's leftist elements, which he believed threatened his control of the KMT.\n\nNow with an established national government in Nanjing, and supported by conservative allies including Hu Hanmin, Chiang's expulsion of the Communists and their Soviet advisers led to the beginning of the Chinese Civil War. Wang Jingwei's National Government was weak militarily, and was soon ended by Chiang with the support of a local warlord (Li Zongren of Guangxi). Eventually, Wang and his leftist party surrendered to Chiang and joined him in Nanjing. In the Central Plains War, Beijing was taken on June, 1928, from an alliance of the warlords Feng Yuxiang and Yan Xishan. In December, the Manchurian warlord Zhang Xueliang pledged allegiance to Chiang's government, completing Chiang's nominal unification of China and ending the Warlord Era.\n\nIn 1927, when he was setting up the Nationalist government in Nanjing, he was preoccupied with \"the elevation of our leader Dr. Sun Yat-sen to the rank of 'Father of our Chinese Republic'. Dr. Sun worked for 40 years to lead our people in the Nationalist cause, and we cannot allow any other personality to usurp this honored position\". He asked Chen Guofu to purchase a photograph that had been taken in Japan around 1895 or 1898. It showed members of the Revive China Society with Yeung Kui-wan ( or , pinyin Yáng Qúyún) as President, in the place of honor, and Sun, as secretary, on the back row, along with members of the Japanese Chapter of the Revive China Society. When told that it was not for sale, Chiang offered a million dollars to recover the photo and its negative. \"The party must have this picture and the negative at any price. They must be destroyed as soon as possible. It would be embarrassing to have our Father of the Chinese Republic shown in a subordinate position\". Chiang never obtained either the photo or its negative.\n\nChiang made great efforts to gain recognition as the official successor of Sun Yat-sen. In a pairing of great political significance, Chiang was Sun's brother-in-law: he had married Soong Mei-ling, the younger sister of Soong Ching-ling, Sun's widow, on December 1, 1927. Originally rebuffed in the early 1920s, Chiang managed to ingratiate himself to some degree with Soong Mei-ling's mother by first divorcing his wife and concubines and promising to sincerely study the precepts of Christianity. He read the copy of the Bible that May-ling had given him twice before making up his mind to become a Christian, and three years after his marriage he was baptized in the Soong's Methodist church. Although some observers felt that he adopted Christianity as a political move, studies of his recently opened diaries suggest that his faith was strong and sincere and that he felt that Christianity reinforced Confucian moral teachings.\n\nUpon reaching Beijing, Chiang paid homage to Sun Yat-sen and had his body moved to the new capital of Nanjing to be enshrined in a grand mausoleum.\n\nIn the West and in the Soviet Union, Chiang Kai-shek was known as the \"Red General\". Movie theaters in the Soviet Union showed newsreels and clips of Chiang. At Moscow, Sun Yat-sen University portraits of Chiang were hung on the walls; and, in the Soviet May Day Parades that year, Chiang's portrait was to be carried along with the portraits of Karl Marx, Vladimir Lenin, Joseph Stalin, and other Communist leaders. The United States consulate and other Westerners in Shanghai were concerned about the approach of \"Red General\" Chiang as his army was seizing control of large areas of the country in the Northern Expedition.\n\nOn April 12, Chiang carried out a purge of thousands of suspected Communists and dissidents in Shanghai, and began large-scale massacres across the country collectively known as the \"White Terror\". Throughout April 1927, more than people were killed in Shanghai. The killings drove most Communists from urban cities and into the rural countryside, where the KMT was less powerful. In the year after April 1927, over 300,000 people died across China in anti-Communist suppression campaigns, executed by the KMT. One of the most famous quotes from Chiang (during that time) was that he would rather mistakenly kill 1,000 innocent people rather than allow one Communist to escape. Some estimates claim the White Terror in China took millions of lives, most of them in the rural areas. No concrete number can be verified. Chiang allowed Soviet agent and advisor Mikhail Borodin and Soviet general Vasily Blücher (Galens) \"escape\" to safety after the purge.\n\nHaving gained control of China, Chiang's party remained surrounded by \"surrendered\" warlords who remained relatively autonomous within their own regions. On October 10, 1928, Chiang was named director of the State Council, the equivalent to President of the country, in addition to his other titles. As with his predecessor Sun Yat-sen, the Western media dubbed him \"Generalissimo\".\n\nAccording to Sun Yat-sen's plans, the Kuomintang (KMT) was to rebuild China in three steps: military rule, political tutelage, and constitutional rule. The ultimate goal of the KMT revolution was democracy, which was not considered to be feasible in China's fragmented state. Since the KMT had completed the first step of revolution through seizure of power in 1928, Chiang's rule thus began a period of what his party considered to be \"political tutelage\" in Sun Yat-sen's name. During this so-called Republican Era, many features of a modern, functional Chinese state emerged and developed.\n\nThe decade of 1928 to 1937 saw some aspects of foreign imperialism, concessions and privileges in China, moderated through diplomacy. The government acted to modernize the legal and penal systems, attempted to stabilize prices, amortize debts, reform the banking and currency systems, build railroads and highways, improve public health facilities, legislate against traffic in narcotics, and augment industrial and agricultural production. Not all of these projects were successfully completed. Efforts were made towards improving education standards; and, in an effort to unify Chinese society, the New Life Movement was launched to encourage Confucian moral values and personal discipline. \"Guoyu\" (\"national language\") was promoted as a standard tongue, and the establishment of communications facilities (including radio) were used to encourage a sense of Chinese nationalism in a way that was not possible when the nation lacked an effective central government.\n\nAny successes that the Nationalists did make, however, were met with constant political and military upheavals. While much of the urban areas were now under the control of the KMT, much of the countryside remained under the influence of weakened yet undefeated warlords and Communists. Chiang often resolved issues of warlord obstinacy through military action, but such action was costly in terms of men and material. The 1930 Central Plains War alone nearly bankrupted the Nationalist government and caused almost casualties on both sides. In 1931, Hu Hanmin, Chiang's old supporter, publicly voiced a popular concern that Chiang's position as both premier and president flew in the face of the democratic ideals of the Nationalist government. Chiang had Hu put under house arrest, but he was released after national condemnation after which he left Nanjing and supported a rival government in Guangzhou. The split resulted in a military conflict between Hu's Guangzhou government and Chiang's Nationalist government. Chiang only won the campaign against Hu after a shift in allegiance by the warlord Zhang Xueliang, who had previously supported Hu Hanmin.\n\nThroughout his rule, complete eradication of the Communists remained Chiang's dream. After assembling his forces in Jiangxi, Chiang led his armies against the newly established Chinese Soviet Republic. With help from foreign military advisers, Chiang's Fifth Campaign finally surrounded the Chinese Red Army in 1934. The Communists, tipped off that a Nationalist offensive was imminent, retreated in the Long March, during which Mao Zedong rose from a mere military official to the most influential leader of the Communist Party of China.\n\nChiang, as a nationalist and a Confucianist, was against the iconoclasm of the May Fourth Movement. Motivated by his sense of nationalism, he viewed some Western ideas as foreign, and he believed that the great introduction of Western ideas and literature that the May Fourth Movement promoted was not beneficial to China. He and Dr. Sun criticized the May Fourth intellectuals as corrupting the morals of China's youth.\n\nContrary to Communist propaganda that Chiang was pro-capitalism, Chiang Kai-shek antagonized the capitalists of Shanghai, often attacking them and confiscating their capital and assets for the use of the government. Chiang confiscated the wealth of capitalists even while he denounced and fought against communists. Chiang crushed pro-communist worker and peasant organizations and rich Shanghai capitalists at the same time. Chiang continued Dr. Sun Yat-sen's anti capitalist ideology, directing Kuomintang media to openly attack capitalists and capitalism, demanding government controlled industry instead.\n\nChiang has often been interpreted as being pro-capitalist, but this conclusion may be problematic. Shanghai capitalists did briefly support him out of fear of communism in 1927, but this support eroded in 1928 when Chiang turned his tactics of intimidation on them. The relationship between Chiang Kai-shek and Chinese capitalists remained poor throughout the period of his administration. Chiang blocked Chinese capitalists from gaining any political power or voice within his regime. Once Chiang Kai-shek was done with his White Terror on pro-communist laborers, he proceeded to turn on the capitalists. Gangster connections allowed Chiang to attack them in the International Settlement, successfully forcing capitalists to back him up with their assets for his military expeditions.\n\nChiang viewed Japan, America, the Soviet Union, France and Britain as all being imperialists with nobody else's interests in mind but their own, seeing them as hypocritical to condemn each other for imperialism which they all practiced. He manipulated America, Nazi Germany, and the Soviet Union to regain lost territories for China as he viewed all the powers as imperialists trying to curtail and suppress China's power and national resurrection.\n\nSome sources attribute Chiang Kai-shek with millions of deaths for the scattered events of mass deaths caused by the Nationalist Government of China. He is certainly partially responsible for the 1938 Yellow River flood which killed hundreds of thousands of Chinese civilians in order to fend off a Japanese Advance. This accusation is usually sourced from Rudolph Rummel who was referring to the Nationalist regime as whole rather than Chiang Kai-Shek in particular. Regardless the Nationalist government of China has been accused of mass killings by Rudolph Rummel estimating the Nationalist government of China is responsible for between 6 and 18.5 million deaths\nHe attributes this death toll to a few major causes for example:\n\nIn Nanjing, on April 1931, Chiang Kai-shek attended a national leadership conference with Zhang Xueliang and Muslim General Ma Fuxiang, in which Chiang and Zhang dauntlessly upheld that Manchuria was part of China in the face of the Japanese invasion. After the Japanese invasion of Manchuria in 1931, Chiang resigned as Chairman of the National Government. He returned shortly afterwards, adopting the slogan \"first internal pacification, then external resistance\". However, this policy of avoiding a frontal war against the Japanese was widely unpopular. In 1932, while Chiang was seeking first to defeat the Communists, Japan launched an advance on Shanghai and bombarded Nanjing. This disrupted Chiang's offensives against the Communists for a time, although it was the northern factions of Hu Hanmin's Guangzhou (Canton) government (notably the 19th Route Army) that primarily led the offensive against the Japanese during this skirmish. Brought into the Nationalist army immediately after the battle, the 19th Route Army's career under Chiang would be cut short after it was disbanded for demonstrating socialist tendencies.\n\nIn December 1936, Chiang flew to Xi'an to coordinate a major assault on the Red Army and the Communist Republic that had retreated into Yan'an. However, Chiang's allied commander Zhang Xueliang, whose forces were used in his attack and whose homeland of Manchuria had been recently invaded by the Japanese, did not support the attack on the Communists. On December 12, Zhang and several other Nationalist generals headed by Yang Hucheng of Shaanxi kidnapped Chiang for two weeks in what is known as the Xi'an Incident. They forced Chiang into making a \"Second United Front\" with the Communists against Japan. After releasing Chiang and returning to Nanjing with him, Zhang was placed under house arrest and the generals who had assisted him were executed. Chiang's commitment to the Second United Front was nominal at best, and it was all but broken up in 1941.\nThe Second Sino-Japanese War broke out in July 1937, and in August of that year Chiang sent of his best-trained and equipped soldiers to defend Shanghai. With over 200,000 Chinese casualties, Chiang lost the political cream of his Whampoa-trained officers. Though Chiang lost militarily, the battle dispelled Japanese claims that it could conquer China in three months and demonstrated to the Western powers that the Chinese would continue the fight. By December, the capital city of Nanjing had fallen to the Japanese resulting in the Nanking Massacre. Chiang moved the government inland, first to Wuhan and later to Chongqing.\n\nHaving lost most of China's economic and industrial centers, Chiang withdrew into the hinterlands, stretching the Japanese supply lines and bogging down Japanese soldiers in the vast Chinese interior. As part of a policy of protracted resistance, Chiang authorized the use of scorched earth tactics, resulting in many civilian deaths. During the Nationalists' retreat from Zhengzhou, the dams around the city were deliberately destroyed by the Nationalist army in order to delay the Japanese advance, killing 500,000 people in the subsequent 1938 Yellow River flood.\n\nAfter heavy fighting, the Japanese occupied Wuhan in the fall of 1938 and the Nationalists retreated farther inland, to Chongqing. While en route to Chongqing, the Nationalist army intentionally started the \"fire of Changsha\", as a part of the scorched earth policy. The fire destroyed much of the city, killed twenty thousand civilians, and left hundreds of thousands of people homeless. Due to an organizational error (it was claimed), the fire was begun without any warning to the residents of the city. The Nationalists eventually blamed three local commanders for the fire and executed them. Newspapers across China blamed the fire on (non-KMT) arsonists, but the blaze contributed to a nationwide loss of support for the KMT.\n\nIn 1939 Muslim leaders Isa Yusuf Alptekin and Ma Fuliang were sent by Chiang to several Middle eastern countries, including Egypt, Turkey, and Syria, to gain support for the Chinese War against Japan, and to express his support for Muslims.\n\nThe Japanese, controlling the puppet-state of Manchukuo and much of China's eastern seaboard, appointed Wang Jingwei as a Quisling-ruler of the occupied Chinese territories around Nanjing. Wang named himself President of the Executive Yuan and Chairman of the National Government (not the same 'National Government' as Chiang's), and led a surprisingly large minority of anti-Chiang/anti-Communist Chinese against his old comrades. He died in 1944, within a year of the end of World War II.\n\nThe Hui Muslim Xidaotang sect pledged allegiance to the Kuomintang after their rise to power and Hui Muslim General Bai Chongxi acquainted Chiang Kaishek with the Xidaotang jiaozhu Ma Mingren in 1941 in Chongqing.\n\nIn 1942 Generalissimo Chiang Kai-shek went on tour in northwestern China in Xinjiang, Gansu, Ningxia, Shaanxi, and Qinghai, where he met both Muslim Generals Ma Buqing and Ma Bufang. He also met the Muslim Generals Ma Hongbin and Ma Hongkui separately.\n\nA border crisis erupted with Tibet in 1942. Under orders from Chiang Kai-shek, Ma Bufang repaired Yushu airport to prevent Tibetan separatists from seeking independence. Chiang also ordered Ma Bufang to put his Muslim soldiers on alert for an invasion of Tibet in 1942. Ma Bufang complied and moved several thousand troops to the border with Tibet. Chiang also threatened the Tibetans with aerial bombardment if they worked with the Japanese. Ma Bufang attacked the Tibetan Buddhist Tsang monastery in 1941. He also constantly attacked the Labrang monastery.\n\nWith the attack on Pearl Harbor and the opening of the Pacific War, China became one of the Allied Powers. During and after World War II, Chiang and his American-educated wife Soong Mei-ling, known in the United States as \"Madame Chiang\", held the support of the United States' China Lobby, which saw in them the hope of a Christian and democratic China. Chiang was even named the Supreme Commander of Allied forces in the China war zone. He was created a Knight Grand Cross of the Order of the Bath by King George VI of the United Kingdom in 1942.\n\nGeneral Joseph Stilwell, an American military adviser to Chiang during World War II, strongly criticized Chiang and his generals for what he saw as their incompetence and corruption. In 1944, the United States Army Air Corps commenced Operation Matterhorn in order to bomb Japan's steel industry from bases to be constructed in mainland China. This was meant to fulfill President Roosevelt's promise to Chiang Kai-shek to begin bombing operations against Japan by November 1944. However, Chiang Kai-shek's subordinates refused to take airbase construction seriously until enough capital had been delivered to permit embezzlement on a massive scale. Stilwell estimated that at least half of the $100 million spent on construction of airbases was embezzled by Nationalist party officials.\n\nChiang played the Soviets and Americans against each other during the war. He first told the Americans that they would be welcome in talks between the Soviet Union and China then secretly told the Soviets that the Americans were unimportant and that their opinions would not be considered. Chiang also used American support and military power in China against the ambitions of the Soviet Union to dominate the talks, stopping the Soviets from taking full advantage of the situation in China with the threat of American military action against the Soviets.\n\nU.S. President Franklin D. Roosevelt, through General Stilwell, privately made it clear that they preferred that the French not reacquire French Indochina (modern day Vietnam, Cambodia and Laos) after the war was over. Roosevelt offered Chiang control of all of Indochina. It was said that Chiang replied: \"Under no circumstances!\"\n\nAfter the war, 200,000 Chinese troops under General Lu Han were sent by Chiang Kai-shek to northern Indochina (north of the 16th parallel) to accept the surrender of Japanese occupying forces there, and remained in Indochina until 1946, when the French returned. The Chinese used the VNQDD, the Vietnamese branch of the Chinese Kuomintang, to increase their influence in Indochina and to put pressure on their opponents. Chiang Kai-shek threatened the French with war in response to maneuvering by the French and Ho Chi Minh's forces against each other, forcing them to come to a peace agreement. In February 1946 he also forced the French to surrender all of their concessions in China and to renounce their extraterritorial privileges in exchange for the Chinese withdrawing from northern Indochina and allowing French troops to reoccupy the region. Following France's agreement to these demands, the withdrawal of Chinese troops began in March 1946. Despite the withdrawal, many Vietnamese who considered themselves as Chinese continued to fight against the French government. Some of Chiang's army stayed to assist the struggle. Many even went to study in China then return to fight for the cause. Ho Chi Minh would be one example. Although denied by the Vietnamese government, Ho Chi Minh married a Chinese wife during his study in China.\n\nDuring the Cairo Conference in 1943, Chiang said that Roosevelt asked him whether China would like to claim the Ryukyu Islands from Japan in addition to retaking Taiwan, the Pescadores, and Manchuria. Chiang claims that he said he was in favor of an international presence on the islands. However, the U.S. became the sole protector of the Ryukyus in 1945 and reverted it to the Japanese in 1972 while securing US military presence there.\n\nIn 1945, when Japan surrendered, Chiang's Chongqing government was ill-equipped and ill-prepared to reassert its authority in formerly Japanese-occupied China, and it asked the Japanese to postpone their surrender until Kuomintang (KMT) authority could arrive to take over. American troops and weapons soon bolstered KMT forces, allowing them to reclaim cities. The countryside, however, remained largely under Communist control.\n\nFor over a year after the Japanese surrender, rumors circulated throughout China that the Japanese had entered into a secret agreement with Chiang, in which the Japanese would assist the Nationalists in fighting the Communists in exchange for the protection of Japanese persons and property there. Many top nationalist generals, including Chiang, had studied and trained in Japan before the Nationalists had returned to the mainland in the 1920s, and maintained close personal friendships with top Japanese officers. The Japanese general in charge of all forces in China, General Yasuji Okamura, had personally trained officers who later became generals in Chiang's staff. Reportedly, General Okamura, before surrendering command of all Japanese military forces in Nanjing, offered Chiang control of all 1.5 million Japanese military and civilian support staff then present in China. Reportedly, Chiang seriously considered accepting this offer, but declined only in the knowledge that the United States would certainly be outraged by the gesture. Even so, armed Japanese troops remained in China well into 1947, with some noncommissioned officers finding their way into the Nationalist officer corps. That the Japanese in China came to regard Chiang as a magnanimous figure to whom many Japanese owed their lives and livelihoods was a fact attested by both Nationalist and Communist sources.\n\nWestad says the Communists won the Civil War because they made fewer military mistakes than Chiang Kai-Shek, and because in his search for a powerful centralized government, Chiang antagonized too many interest groups in China. Furthermore, his party was weakened in the war against Japan. Meanwhile, the Communists told different groups, such as peasants, exactly what they wanted to hear, and cloaked themselves in the cover of Chinese Nationalism.\n\nFollowing the war, the United States encouraged peace talks between Chiang and Communist leader Mao Zedong in Chongqing. Due to concerns about widespread and well-documented corruption in Chiang's government throughout his rule, the U.S. government limited aid to Chiang for much of the period of 1946 to 1948, in the midst of fighting against the People's Liberation Army led by Mao Zedong. Alleged infiltration of the U.S. government by Chinese Communist agents may have also played a role in the suspension of American aid.\n\nChiang's right-hand man, the secret police Chief Dai Li, was both anti-American and anti-Communist. Dai ordered Kuomintang agents to spy on American officers. Earlier, Dai had been involved with the Blue Shirts Society, a fascist-inspired paramilitary group within the Kuomintang, which wanted to expel Western and Japanese imperialists, crush the Communists, and eliminate feudalism. Dai Li died in a plane crash, which was suspected to be an assassination orchestrated by Chiang.\n\nThough Chiang had achieved status abroad as a world leader, his government deteriorated as the result of corruption and inflation. In his diary on June 1948, Chiang wrote that the KMT had failed, not because of external enemies but because of rot from within. The war had severely weakened the Nationalists, while the Communists were strengthened by their popular land-reform policies, and by a rural population that supported and trusted them. The Nationalists initially had superiority in arms and men, but their lack of popularity, infiltration by Communist agents, low morale, and disorganization soon allowed the Communists to gain the upper hand in the civil war.\n\nA new Constitution was promulgated in 1947, and Chiang was elected by the National Assembly as the first term President of the Republic of China on May 20, 1948. This marked the beginning of what was termed the \"democratic constitutional government\" period by the KMT political orthodoxy, but the Communists refused to recognize the new Constitution, and its government, as legitimate. Chiang resigned as President on January 21, 1949, as KMT forces suffered terrible losses and defections to the Communists. After Chiang's resignation the vice-president of the ROC, Li Zongren, became China's acting president.\n\nShortly after Chiang's resignation the Communists halted their advances and attempted to negotiate the virtual surrender of the ROC. Li attempted to negotiate milder terms that would have ended the civil war, but without success. When it became clear that Li was unlikely to accept Mao's terms, the Communists issued an ultimatum in April 1949, warning that they would resume their attacks if Li did not agree within five days. Li refused.\n\nLi's attempts to carry out his policies faced varying degrees of opposition from Chiang's supporters, and were generally unsuccessful. Chiang especially antagonized Li by taking possession of (and moving to Taiwan) US$200 million of gold and US dollars belonging to the central government that Li desperately needed to cover the government's soaring expenses. When the Communists captured the Nationalist capital of Nanjing in April 1949, Li refused to accompany the central government as it fled to Guangdong, instead expressing his dissatisfaction with Chiang by retiring to Guangxi.\n\nThe former warlord Yan Xishan, who had fled to Nanjing only one month before, quickly insinuated himself within the Li-Chiang rivalry, attempting to have Li and Chiang reconcile their differences in the effort to resist the Communists. At Chiang's request Yan visited Li in order to convince Li not to withdraw from public life. Yan broke down in tears while talking of the loss of his home province of Shanxi to the Communists, and warned Li that the Nationalist cause was doomed unless Li went to Guangzhou. Li agreed to return under the condition that Chiang surrender most of the gold and US dollars in his possession that belonged to the central government, and that Chiang stop overriding Li's authority. After Yan communicated these demands and Chiang agreed to comply with them, Li departed for Guangdong.\n\nIn Guangdong, Li attempted to create a new government composed of both Chiang supporters and those opposed to Chiang. Li's first choice of premier was Chu Cheng, a veteran member of the Kuomintang who had been virtually driven into exile due to his strong opposition to Chiang. After the Legislative Yuan rejected Chu, Li was obliged to choose Yan Xishan instead. By this time Yan was well known for his adaptability and Chiang welcomed his appointment.\n\nConflict between Chiang and Li persisted. Although he had agreed to do so as a prerequisite of Li's return, Chiang refused to surrender more than a fraction of the wealth that he had sent to Taiwan. Without being backed by gold or foreign currency, the money issued by Li and Yan quickly declined in value until it became virtually worthless.\n\nAlthough he did not hold a formal executive position in the government, Chiang continued to issue orders to the army, and many officers continued to obey Chiang rather than Li. The inability of Li to coordinate KMT military forces led him to put into effect a plan of defense that he had contemplated in 1948. Instead of attempting to defend all of southern China, Li ordered what remained of the Nationalist armies to withdraw to Guangxi and Guangdong, hoping that he could concentrate all available defenses on this smaller, and more easily defensible, area. The object of Li's strategy was to maintain a foothold on the Chinese mainland in the hope that the United States would eventually be compelled to enter the war in China on the Nationalist side.\n\nChiang opposed Li's plan of defense because it would have placed most of the troops still loyal to Chiang under the control of Li and Chiang's other opponents in the central government. To overcome Chiang's intransigence Li began ousting Chiang's supporters within the central government. Yan Xishan continued in his attempts to work with both sides, creating the impression among Li's supporters that he was a \"stooge\" of Chiang, while those who supported Chiang began to bitterly resent Yan for his willingness to work with Li. Because of the rivalry between Chiang and Li, Chiang refused to allow Nationalist troops loyal to him to aid in the defense of Guangxi and Guangdong, with the result that Communist forces occupied Guangdong in October 1949.\n\nAfter Guangdong fell to the Communists, Chiang relocated the government to Chongqing, while Li effectively surrendered his powers and flew to New York for treatment of his chronic duodenum illness at the Hospital of Columbia University. Li visited the President of the United States, Harry S. Truman, and denounced Chiang as a dictator and an usurper. Li vowed that he would \"return to crush\" Chiang once he returned to China. Li remained in exile, and did not return to Taiwan.\n\nIn the early morning of December 10, 1949, Communist troops laid siege to Chengdu, the last KMT-controlled city in mainland China, where Chiang Kai-shek and his son Chiang Ching-kuo directed the defense at the Chengdu Central Military Academy. Chiang Kai-shek, father and son, sang the Republic of China National Anthem while leaving the Academy all the way to the airfield. The aircraft \"May-ling\" evacuated them to Taiwan on the same day. Chiang Kai-shek would never return to the mainland.\n\nChiang did not re-assume the presidency until March 1, 1950. On January 1952, Chiang commanded the Control Yuan, now in Taiwan, to impeach Li in the \"Case of Li Zongren's Failure to carry out Duties due to Illegal Conduct\" (李宗仁違法失職案). Chiang relieved Li of the position as vice-president in the National Assembly on March 1954.\n\nChiang moved the government to Taipei, Taiwan, where he resumed his duties as President of the Republic of China on March 1, 1950. Chiang was reelected by the National Assembly to be the President of the Republic of China (ROC) on May 20, 1954, and again in 1960, 1966, and 1972. He continued to claim sovereignty over all of China, including the territories held by his government and the People's Republic, as well as territory the latter ceded to foreign governments, such as Tuva and Outer Mongolia. In the context of the Cold War, most of the Western world recognized this position and the ROC represented China in the United Nations and other international organizations until the 1970s.\n\nDuring his presidency on Taiwan, Chiang continued making preparations in order to take back mainland China. He developed the ROC army in order to prepare for an invasion of the mainland, and to defend Taiwan in case of an attack by the Communist forces. He also financed armed groups in mainland China, such as Muslim soldiers of the ROC Army left in Yunnan under Li Mi, who continued to fight. It was not until the 1980s that these troops were finally airlifted to Taiwan. He promoted the Uyghur Yulbars Khan to Governor during the Kuomintang Islamic Insurgency in China (1950–1958) for resisting the Communists, even though the government had already evacuated to Taiwan. He planned an invasion of the mainland in 1962. In the 1950s Chiang's airplanes dropped supplies to Kuomintang Muslim insurgents in Amdo.\n\nDespite the democratic constitution, the government under Chiang was a one-party state, consisting almost completely of mainlanders; the \"Temporary Provisions Effective During the Period of Communist Rebellion\" greatly enhanced executive powers, and the goal of retaking mainland China allowed the KMT to maintain a monopoly on power and the prohibition of opposition parties. The government's official line for these martial law provisions stemmed from the claim that emergency provisions were necessary, since the Communists and KMT were still in a state of war. Seeking to promote Chinese nationalism, Chiang's government actively ignored and suppressed local cultural expression, even forbidding the use of local languages in mass media broadcasts or during class sessions.\n\nThe first decades after the Nationalists moved the seat of government to the province of Taiwan are associated with the organized effort to resist Communism known as the \"White Terror\", during which about 140,000 Taiwanese were imprisoned for their real or perceived opposition to the Kuomintang. Most of those prosecuted were labeled by the Kuomintang as \"bandit spies\" (匪諜), meaning spies for Chinese Communists, and punished as such.\n\nUnder Chiang, the government recognized limited civil and economic freedoms, property rights (personal and intellectual) and other liberties. Despite these restrictions, free debate within the confines of the legislature was permitted. Under the pretext that new elections could not be held in Communist-occupied constituencies, the National Assembly, Legislative Yuan, and Control Yuan members held their posts indefinitely. The Temporary Provisions also allowed Chiang to remain as president beyond the two-term limit in the Constitution. He was reelected by the National Assembly as president four times—doing so in 1954, 1960, 1966, and 1972.\n\nBelieving that corruption and a lack of morals were key reasons that the KMT lost mainland China to the Communists, Chiang attempted to purge corruption by dismissing members of the KMT accused of graft. Some major figures in the previous mainland Chinese government, such as H. H. Kung and T. V. Soong, exiled themselves to the United States. Though politically authoritarian and, to some extent, dominated by government-owned industries, Chiang's new Taiwanese state also encouraged economic development, especially in the export sector. A popular sweeping Land Reform Act, as well as American foreign aid during the 1950s, laid the foundation for Taiwan's economic success, becoming one of the Four Asian Tigers.\n\nAfter Chiang's death, the next president, Chiang's son, Chiang Ching-kuo, and Chiang Ching-kuo's successor, Lee Teng-hui a native Taiwanese, would, in the 1980s and 1990s, increase native Taiwanese representation in the government and loosen the many authoritarian controls of the early era of ROC control in Taiwan.\n\nIn 1971, the Australian Opposition Leader Gough Whitlam, who became Prime Minister in 1972 and swiftly relocated the Australian mission from Taipei to Beijing, visited Japan. After meeting with the Japanese Prime Minister, Eisaku Sato, Whitlam observed that the reason Japan at that time was hesitant to withdraw recognition from the Nationalist government was \"the presence of a treaty between the Japanese government and that of Chiang Kai-shek\". Sato explained that the continued recognition of Japan towards the Nationalist government was due largely to the personal relationship that various members of the Japanese government felt towards Chiang. This relationship was rooted largely in the generous and lenient treatment of Japanese prisoners-of-war by the Nationalist government in the years immediately following the Japanese surrender in 1945, and was felt especially strongly as a bond of personal obligation by the most senior members then in power.\n\nAlthough Japan recognized the People's Republic in 1972, shortly after Kakuei Tanaka succeeded Sato as Prime Minister of Japan, the memory of this relationship was strong enough to be reported by \"The New York Times\" (April 15, 1978) as a significant factor inhibiting trade between Japan and the mainland. There is speculation that a clash between Communist forces and a Japanese warship in 1978 was caused by Chinese anger after Prime Minister Takeo Fukuda attended Chiang's funeral. Historically, Japanese attempts to normalize their relationship with the People's Republic were met with accusations of ingratitude in Taiwan.\n\nChiang was suspicious that covert operatives of the United States plotted a coup against him. In 1950, Chiang Ching-kuo became director of the secret police (Bureau of Investigation and Statistics), which he remained until 1965. Chiang was suspicious of politicians who were overly friendly to the United States, and considered them his enemies. In 1953, seven days after surviving an assassination attempt, Wu Kuo-chen lost his position as governor of Taiwan Province to Chiang Ching-kuo. After fleeing to United States the same year, he became a vocal critic of Chiang's family and government.\n\nChiang Ching-kuo, educated in the Soviet Union, initiated Soviet-style military organization in the Republic of China Military. He reorganized and Sovietized the political officer corps, and propagated Kuomintang ideology throughout the military. Sun Li-jen, who was educated at the American Virginia Military Institute, was opposed to this.\n\nChiang Ching-kuo orchestrated the controversial court-martial and arrest of General Sun Li-jen in August 1955, for plotting a coup d'état with the American Central Intelligence Agency (CIA) against his father Chiang Kai-shek and the Kuomintang. The CIA allegedly wanted to help Sun take control of Taiwan and declare its independence.\n\nIn 1975, 26 years after Chiang came to Taiwan, he died in Taipei at the age of 87. He had suffered a heart attack and pneumonia in the foregoing months and died from renal failure aggravated with advanced cardiac malfunction on April 5.\n\nA month of mourning was declared. Chinese music composer Hwang Yau-tai wrote the Chiang Kai-shek Memorial Song. In mainland China, however, Chiang's death was met with little apparent mourning and Communist state-run newspapers gave the brief headline \"Chiang Kai-shek Has Died.\" Chiang's body was put in a copper coffin and temporarily interred at his favorite residence in Cihu, Daxi, Taoyuan. When his son Chiang Ching-kuo died in 1988, he was entombed in a separate mausoleum in nearby Touliao (頭寮). The hope was to have both buried at their birthplace in Fenghua if and when it was possible. In 2004, Chiang Fang-liang, the widow of Chiang Ching-kuo, asked that both father and son be buried at Wuzhi Mountain Military Cemetery in Xizhi, Taipei County (now New Taipei City). Chiang's ultimate funeral ceremony became a political battle between the wishes of the state and the wishes of his family.\n\nChiang was succeeded as President by Vice President Yen Chia-kan and as Kuomintang party ruler by his son Chiang Ching-kuo, who retired Chiang Kai-shek's title of Director-General and instead assumed the position of Chairman. Yen's presidency was interim; Chiang Ching-kuo, who was the Premier, became President after Yen's term ended three years later.\n\nChiang's portrait hung over the Tiananmen before Mao's portrait was set up in its place. People also put portraits of Chiang in their homes and in public on the streets.\n\nChiang was popular among many people and dressed in plain, simple clothes, unlike contemporary Chinese warlords who dressed extravagantly.\n\nQuotes from the Quran and Hadith were used by Muslims in the Kuomintang-controlled Muslim publication, the \"Yuehua\", to justify Chiang Kai-shek's rule over China.\n\nWhen the Muslim General and Warlord Ma Lin was interviewed, Ma Lin was described as having \"high admiration for and unwavering loyalty to Chiang Kai-shek\".\n\nIn the Philippines, a school was named in his honor in 1939. Today, Chiang Kai Shek College is the largest educational institution for the Chinoy community in the country.\n\nThe Kuomintang used traditional Chinese religious ceremonies, and promoted Martyrdom in Chinese culture. Kuomintang ideology promoted the view that the souls of Party martyrs who died fighting for the Kuomintang, the revolution, and the party founder Dr. Sun Yat-sen were sent to heaven. Chiang Kai-shek believed that these martyrs witnessed events on earth from heaven.\n\nWhen the Northern Expedition was complete, Kuomintang Generals led by Chiang Kai-shek paid tribute to Dr. Sun's soul in heaven with a sacrificial ceremony at the Xiangshan Temple in Beijing in July 1928. Among the Kuomintang Generals present were the Muslim Generals Bai Chongxi and Ma Fuxiang.\n\nChiang Kai-shek considered both the Han Chinese and all the minority peoples of China, the Five Races Under One Union, as descendants of Yellow Emperor, the Yellow Emperor and semi mythical founder of the Chinese nation, and belonging to the Chinese Nation Zhonghua Minzu and he introduced this into Kuomintang ideology, which was propagated into the educational system of the Republic of China.\n\nChiang's legacy has been the target of heated debates because of the different views held about him. For some, Chiang was a national hero who led the victorious Northern Expedition against the Beiyang Warlords in 1927, achieving Chinese unification, and who subsequently led China to ultimate victory against Japan in 1945. Some blamed him for not doing enough against the Japanese forces in the lead-up to, and during, the Second Sino-Japanese War, preferring to withhold his armies for the fight against the Communists, or merely waiting and hoping that the United States would get involved. Some also see him as a champion of anti-Communism, being a key figure during the formative years of the World Anti-Communist League. During the Cold War, he was also seen as the leader who led Free China and the bulwark against a possible Communist invasion. However, Chiang presided over purges, political authoritarianism, and graft during his tenure in mainland China, and ruled throughout a period of imposed martial law. His governments were accused of being corrupt even before he even took power in 1928. He also allied with known criminals like Du Yuesheng for political and financial gains. Some opponents charge that Chiang's efforts in developing Taiwan were mostly to make the island a strong base from which to one day return to mainland China, and that Chiang had little regard for the long-term prosperity and well-being of the Taiwanese people.\n\nToday, Chiang's popularity in Taiwan is divided along political lines, enjoying greater support among Kuomintang (KMT) supporters. He is generally unpopular among Democratic Progressive Party (DPP) voters and supporters. In sharp contrast to his son, Chiang Ching-kuo, and to Sun Yat-sen, his memory is rarely invoked by current political parties, including the Kuomintang. In contrast, his image has been rehabilitated in contemporary Mainland China. Until recently portrayed as a villain who fought against the \"liberation\" of China by the Communists, since the 2000s, he has been portrayed by the media in a neutral or slightly positive light as a Chinese nationalist who tried to bring about national unification and resisted the Japanese invasion during World War II. This shift is largely in response to current political landscape of Taiwan, in relation to Chiang's commitment to a unified China and his stance against Taiwanese separatism during his rule of the island, along with the recent detente between the Communist Party of China (CPC) and Chiang's KMT. In contrast to efforts to remove his public monuments in Taiwan, his ancestral home in Fenghua, Zhejiang on the Mainland has become a commemorative museum and major tourist attraction.\n\nIn the United States and Europe, Chiang was often perceived negatively as the one who lost China to the Communists. His constant demands for Western support and funding also earned him the nickname of \"General Cash-My-Check\". In the West he has been criticized for his poor military skills. He had a record of issuing unrealistic orders and persistently attempting to fight unwinnable battles, leading to the loss of his best troops.\n\nIn recent years, there has been an attempt to find a more moderate interpretation of Chiang. Chiang is now increasingly perceived as a man simply overwhelmed by the events in China, having to fight simultaneously Communists, Japanese, and provincial warlords while having to reconstruct and unify the country. His sincere, albeit often unsuccessful attempts to build a more powerful nation have been noted by scholars such as Jonathan Fenby and Rana Mitter. Mitter has observed that, ironically, today's China is closer to Chiang's vision than to Mao Zedong's. He argues that the Communists, since the 1980s, have essentially created the state envisioned by Chiang in the 1930s. Mitter concludes by writing that \"one can imagine Chiang Kai-shek's ghost wandering round China today nodding in approval, while Mao's ghost follows behind him, moaning at the destruction of his vision\". Liang Shuming opined that Chiang Kai-shek's \"greatest contribution was to make the CCP successful. If he had been a bit more trustworthy, if his character was somewhat better, the CCP would have been unable to beat him\".\n\n\"Formosa Betrayed\", one of the few American movies concerning the process of democratization in Taiwan, depicts Chiang Kai-shek as a brutal dictator, responsible for the execution of thousands of native Taiwanese during the days following the February 28 Incident.\n\nIn an arranged marriage, Chiang was married to a fellow villager named Mao Fumei. While married to Mao, Chiang adopted two concubines (concubinage was still a common practice for well-to-do, non-Christian males in China): he married Yao Yecheng (姚冶誠, 1889–1972) in 1912 and Chen Jieru (陳潔如, 1906–1971) in December 1921. While he was still living in Shanghai, Chiang and Yao adopted a son, Wei-kuo. Chen adopted a daughter in 1924, named Yaoguang (瑤光), who later adopted her mother's surname. Chen's autobiography refuted the idea that she was a concubine. Chen claiming that, by the time she married Chiang, he had already divorced Yao, and that Chen was therefore his wife. Chiang and Mao had a son, Ching-kuo.\n\nAccording to the memoirs of Chen Jieru, Chiang's second wife, she contracted gonorrhea from Chiang soon after their marriage. He told her that he acquired this disease after separating from his first wife and living with his concubine Yao Yecheng, as well as with many other women he consorted with. His doctor explained to her that Chiang had sex with her before completing his treatment for the disease. As a result, both Chiang and Ch'en Chieh-ju believed they had become sterile, which would explain why he had only one child, by his first wife; however, a purported miscarriage by Soong Mei-ling in August 1928 would, if it actually occurred, cast serious doubt on whether this was true.\n\nThe Xikou (Chikow) Chiangs were descended from Chiang Shih-chieh who during the 1600s (17th century) moved there from Fenghua district, whose ancestors in turn came to southeastern China's Zhejiang (Chekiang) province after moving out of Northern China in the 13th century AD. The 12th century BC Duke of Zhou's (Duke of Chou) third son was the ancestors of the Chiangs.\n\nHis great grandfather was Chiang Qi-zeng (Jiang Qizeng) 蒋祈增, his grandfather was Chiang Si-qian 蒋斯千, his uncle was Chiang Zhao-hai 蔣肇海, and his father was Chiang Zhao-cong (Jiang Zhaocong) 蔣肇聰.\n\nChiang personally dealt extensively with religions and power figures in China during his regime.\n\nChiang Kai-shek developed relationships with other Generals. Chiang became a sworn brother of the Muslim General Ma Fuxiang and appointed him to high ranking positions. Chiang addressed Ma Fuxiang's son Ma Hongkui as Shao Yun Shixiong Ma Fuxiang attended national leadership conferences with Chiang during Battles against Japan. Ma Hongkui was eventually scapegoated for the failure of the Ningxia Campaign against the Communists, so he moved to the US instead of remaining in Taiwan with Chiang.\n\nWhen Chiang became President of China after the Northern Expedition, he carved out Ningxia and Qinghai out of Gansu province, and appointed Muslim Generals as Military Governors of all three provinces: Ma Hongkui, Ma Hongbin, and Ma Qi. The three Muslim governors, known as Xibei San Ma (lit. \"the three Mas of the Northwest\"), controlled armies composed entirely of Muslims. Chiang called on the three and their suboordinates to wage war against the Soviet peoples, Tibetans, Communists, and the Japanese. Chiang continued to appoint Muslims as Governors of the three provinces, including Ma Lin and Ma Fushou. Chiang's appointments, the first time that Muslims had been appointed as governors of Gansu, increased the prestige of Muslim officials in northwestern China. The armies raised by this \"Ma Clique\", most notably their Muslim cavalry, were incorporated into the KMT army. Chiang appointed a Muslim General, Bai Chongxi, as the Minister of National Defence of the Republic of China, which controlled the ROC military.\n\nChiang also supported the Muslim General Ma Zhongying, whom he had trained at Whampoa Military Academy during the Kumul Rebellion, in a Jihad against Jin Shuren, Sheng Shicai, and the Soviet Union during the Soviet Invasion of Xinjiang. Chiang designated Ma's Muslim army as the 36th Division (National Revolutionary Army) and gave his troops Kuomintang flags and uniforms. Chiang then supported Muslim General Ma Hushan against Sheng Shicai and the Soviet Union in the Xinjiang War (1937). All Muslim Generals commissioned by Chiang in the National Revolutionary Army swore allegiance to him. Several, like Ma Shaowu and Ma Hushan were loyal to Chiang and Kuomintang hardliners.\n\nThe Ili Rebellion and Pei-ta-shan Incident plagued relations with the Soviet Union during Chiang's rule and caused trouble with the Uyghurs. During the Ili Rebellion and Peitashan incident, Chiang deployed Hui troops against Uyghur mobs in Turfan, and against Soviet Russian and Mongols at Peitashan.\n\nDuring Chiang's rule, attacks on foreigners by Kuomintang forces flared up in several incidents. One of these was the Battle of Kashgar (1934) where a Muslim army loyal to the Kuomintang massacred 4,500 Uyghurs, and killed several British at the British consulate in Kashgar. The British were unable to retaliate.\n\nHu Songshan, a Muslim Imam, backed Chiang Kai-shek's regime and gave prayers for his government. ROC flags were saluted by Muslims in Ningxia during prayer along with exhortations to nationalism during Chiang's rule. Chiang sent Muslim students abroad to study at places like Al Azhar and Muslim schools throughout China taught loyalty to his regime.\n\nThe Yuehua, a Chinese Muslim publication, quoted the Quran and Hadith to justify submitting to Chiang Kai-shek as the leader of China, and as justification for Jihad in the war against Japan.\n\nThe Yihewani (Ikhwan al Muslimun a.k.a. Muslim brotherhood) was the predominant Muslim sect backed by the Chiang government during Chiang's regime. Other Muslim sects, like the Xidaotang and Sufi brotherhoods like Jahriyya and Khuffiya were also supported by his regime. The Chinese Muslim Association, a pro-Kuomintang and anti-Communist organization, was set up by Muslims working in his regime. Salafism attempted to gain a foothold in China during his regime, but the Yihewani and Hanafi Sunni Gedimu denounced the Salafis as radicals, engaged in fights against them, and declared them heretics, forcing the Salafis to form a separate sect. Ma Ching-chiang, a Muslim General, served as an advisor to Chiang Kai-shek. Ma Buqing was another Muslim General who fled to Taiwan along with Chiang. His government donated money to build the Taipei Grand Mosque on Taiwan.\n\nChiang had uneasy relations with the Tibetans. He fought against them in the Sino-Tibetan War, and he supported the Muslim General Ma Bufang in his war against Tibetan rebels in Qinghai. Chiang ordered Ma Bufang to prepare his Islamic army to invade Tibet several times, to deter Tibetan independence, and threatened them with aerial bombardment. After the war, Chiang appointed Ma Bufang as ambassador to Saudi Arabia.\n\nChiang incorporated Methodist values into the New Life Movement under the influence of his wife. Dancing and Western music were discouraged. In one incident, several youths splashed acid on people wearing Western clothing, although Chiang was not directly responsible for these incidents. Despite being a Methodist, he made reference to the Buddha in his diary, and encouraged the establishment of a Buddhist political party under Master Taixu.\n\n\n\n\n"}
{"id": "6863", "url": "https://en.wikipedia.org/wiki?curid=6863", "title": "Compression ratio", "text": "Compression ratio\n\nThe static compression ratio of an internal combustion engine or external combustion engine is a value that represents the ratio of the volume of its combustion chamber from its largest capacity to its smallest capacity. It is a fundamental specification for many common combustion engines.\n\nIn a piston engine, it is the ratio between the volume of the cylinder and combustion chamber when the piston is at the bottom of its stroke, and the volume of the combustion chamber when the piston is at the top of its stroke.\n\nFor example, a cylinder and its combustion chamber with the piston at the bottom of its stroke may contain 1000 cc of air (900 cc in the cylinder plus 100 cc in the combustion chamber). When the piston has moved up to the top of its stroke inside the cylinder, and the remaining volume inside the head or combustion chamber has been reduced to 100 cc, then the compression ratio would be proportionally described as 1000:100, or with fractional reduction, a 10:1 compression ratio.\n\nA high compression ratio is desirable because it allows an engine to extract more mechanical energy from a given mass of air-fuel mixture due to its higher thermal efficiency. This occurs because internal combustion engines are heat engines, and higher efficiency is created because higher compression ratios permit the same combustion temperature to be reached with less fuel, while giving a longer expansion cycle, creating more mechanical power output and lowering the exhaust temperature. It may be more helpful to think of it as an \"expansion ratio\", since more expansion reduces the temperature of the exhaust gases, and therefore the energy wasted to the atmosphere. Diesel engines actually have a higher peak combustion temperature than petrol engines, but the greater expansion means they reject less heat in their cooler exhaust.\n\nHigher compression ratios will however make gasoline engines subject to engine knocking (also known as detonation) if lower octane-rated fuel is used. This can reduce efficiency or damage the engine if knock sensors are not present to modify the ignition timing. However, knock sensors have been a requirement of the OBD-II specification used in 1996 model year vehicles and newer.\n\nOn the other hand, Diesel engines operate on the principle of compression ignition, so that a fuel which resists autoignition will cause late ignition, which will also lead to engine knock.\n\nThe static compression ratio is calculated by the following formula for 4-cycle OVERHEAD VALVE DESIGNS:\n\nCOMPRESSION RATIO (CR) = SUM OF THE SWEPT VOLUME BY THE PISTON IN THE CYLINDER/HEAD COMBUSTION CHAMBER PLUS THE CLEARANCE VOLUME DIVIDED BY THE CLEARANCE VOLUME\n\nWhere:\n\nThe compression ratio in a gasoline (petrol)-powered engine will usually not be much higher than 10:1 due to potential engine knocking (detonation) and not lower than 6:1. Some production automotive engines built for high performance from 1955–1972, used high-octane leaded gasoline or '5 star' to allow compression ratios as high as 13.0:1.\n\nA technique used to prevent the onset of knock is the high \"swirl\" engine that forces the intake charge to adopt a fast circular rotation in the cylinder during compression that provides quicker and more complete combustion. It is possible to manufacture gasoline engines with compression ratios of over 11:1 that can use 87 (MON + RON)/2 (octane rating) fuel with the addition of variable valve timing and knock sensors to delay ignition timing. Such engines may not produce their full rated power using 87 octane gasoline under all circumstances, due to the delayed ignition timing. Direct fuel injection, which can inject fuel only at the time of fuel ignition (similar to a diesel engine), is another recent development which also allows for higher compression ratios on gasoline engines.\n\nThe compression ratio can be as high as 14:1 (2014 Ferrari 458 Speciale) in engines with a 'ping' or 'knock' sensor and an electronic control unit. In 1981, Jaguar released a cylinder head that allowed up to 14:1 compression; but settled for 12.5:1 in production cars. The cylinder head design was known as the \"May Fireball\" head; it was developed by a Swiss engineer Michael May.\n\nIn 2012, Mazda released new petrol engines under the brand name SkyActiv with a 14:1 compression ratio (U.S. models have a 13:1 compression ratio to allow for 87 AKI octane), to be used in all Mazda vehicles by 2015.\n\nIn a turbocharged or supercharged gasoline engine, the CR is customarily built at 10.5:1 or lower. This is due to the turbocharger/supercharger already having compressed the air before it enters the cylinders. Port fuel injected engines typically run lower boost than direct fuel injected engines because port fuel injection allows the air/fuel mixture to be heated together which leads to detonation. Conversely, directly injected engines can run higher boost because heated air will not detonate without a fuel being present. In this instance fuel is injected as late as 60 degrees before top dead center to avoid heating the mixture to the point of compression ignition.\n\nMotorcycle racing engines can use compression ratios as high as 14.7:1, and it is common to find motorcycles with compression ratios above 12.0:1 designed for 86 or 87 octane fuel. F1 engines come closer to 17:1, which is critical for maximizing volumetric/fuel efficiency at around 18,000 RPM.\n\nEthanol and methanol can take significantly higher compression ratios than gasoline. Racing engines burning methanol and ethanol fuel often incorporate a CR of 14.5-16:1.\n\nThe CR may be higher in engines running exclusively on LPG or CNG, due to the higher octane rating of these fuels.\n\nThere is no electrical sparking plug in an auto-ignition diesel engine; the heat of compression raises the temperature of the air in the cylinder sufficiently to ignite the diesel when this is injected into the cylinder; after the compression stroke. The CR will customarily exceed 14:1 and ratios over 22:1 are common. The appropriate compression ratio depends on the design of the cylinder head. The figure is usually between 14:1 and 23:1 for direct injection engines, and between 18:1 and 23:1 for indirect injection.\n\nA compression ratio of 6.5 or lower is desired for operation on kerosene. The petrol-paraffin engine version of the Ferguson TE20 tractor had a compression ratio of 4.5:1 for operation on tractor vaporising oil with an octane rating between 55 and 70.\n\nMeasuring the compression pressure of an engine, with a pressure gauge connected to the spark plug opening, gives an indication of the engine's state and quality. There is, however, no formula to calculate compression ratio based on cylinder pressure.\n\nIf the nominal compression ratio of an engine is given, the pre-ignition cylinder pressure can be estimated using the following relationship:\n\nwhere formula_7 is the cylinder pressure at bottom dead center which is usually at 1 atm, formula_8 is the compression ratio, and formula_9 is the specific heat ratio for the working fluid, which is about 1.4 for air, and 1.3 for methane-air mixture.\n\nFor example, if an engine running on gasoline has a compression ratio of 10:1, the cylinder pressure at top dead center is\n\nThis figure, however, will also depend on cam (i.e. valve) timing. Generally, cylinder pressure for common automotive designs should at least equal 10 bar, or, roughly estimated in pounds per square inch (psi) as between 15 and 20 times the compression ratio, or in this case between 150 psi and 200 psi, depending on cam timing. Purpose-built racing engines, stationary engines etc. will return figures outside this range.\n\nFactors including late intake valve closure (relatively speaking for camshaft profiles outside of typical production-car range, but not necessarily into the realm of competition engines) can produce a misleadingly low figure from this test. Excessive connecting rod clearance, combined with extremely high oil pump output (rare but not impossible) can sling enough oil to coat the cylinder walls with sufficient oil to facilitate reasonable piston ring sealing. In engines with compromised ring seals, this can artificially give a misleadingly high compression figure.\n\nThis phenomenon can actually be used to some slight advantage. If a compression test does give a low figure, and it has been determined it is not due to intake valve closure/camshaft characteristics, then one can differentiate between the cause being valve/seat seal issues and ring seal by squirting engine oil into the spark plug orifice, in a quantity sufficient to disperse across the piston crown and the circumference of the top ring land, and thereby affect the mentioned seal. If a second compression test is performed shortly thereafter, and the new reading is much higher, it would be the ring seal that is problematic, whereas if the compression test pressure observed remains low, it is a valve sealing (or more rarely head gasket, or breakthrough piston or, rarer still, cylinder-wall damage) issue.\n\nIf there is a significant (greater than 10%) difference between cylinders, that may be an indication that valves or cylinder head gaskets are leaking, piston rings are worn, or that the block is cracked.\n\nIf a problem is suspected, then a more comprehensive test using a leak-down tester can locate the leak.\n\nBecause cylinder-bore diameter, piston-stroke length and combustion-chamber volume are almost always constant, the compression ratio for a given engine is almost always constant, until engine wear takes its toll.\n\nOne exception is the experimental Saab Variable Compression engine (SVC). This engine, designed by Saab Automobile, uses a technique that dynamically alters the volume of the combustion chamber (V), which, via the above equation, changes the compression ratio (CR).\n\nThe Atkinson cycle engine was one of the first attempts at variable compression. Since the compression ratio is the ratio between dynamic and static volumes of the combustion chamber, the Atkinson cycle's method of increasing the length of the power stroke compared to the intake stroke ultimately altered the compression ratio at different stages of the cycle.\n\nOn August 15, 2016 Nissan Motor Company announced a new variable compression engine that can choose an optimal compression ratio variably between 8:1 and 14:1. That lets the engine adjust moment by moment to torque demands, always maintaining top efficiency. Nissan says that the turbo-charged, 2-liter, four-cylinder VC-T engine averages 27 percent better fuel economy than the 3.5-liter V6 engine it replaces, with comparable power and torque.\n\nThe calculated compression ratio, as given above, presumes that the cylinder is sealed at the bottom of the stroke, and that the volume compressed is the actual volume.\n\nHowever: intake valve closure (sealing the cylinder) always takes place after BDC, which may cause some of the intake charge to be compressed backwards out of the cylinder by the rising piston at very low speeds; only the percentage of the stroke after intake valve closure is compressed. Intake port tuning and scavenging may allow a greater mass of charge (at a higher than atmospheric pressure) to be trapped in the cylinder than the static volume would suggest ( This \"corrected\" compression ratio is commonly called the \"\"dynamic compression ratio\"\".\n\nThis ratio is higher with more conservative (i.e., earlier, soon after BDC) intake cam timing, and lower with more radical (i.e., later, long after BDC) intake cam timing, but always lower than the static or \"nominal\" compression ratio.\n\nThe actual position of the piston can be determined by trigonometry, using the stroke length and the connecting rod length (measured between centers). The absolute cylinder pressure is the result of an exponent of the dynamic compression ratio. This exponent is a polytropic value for the ratio of variable heats for air and similar gases at the temperatures present. This compensates for the temperature rise caused by compression, as well as heat lost to the cylinder. Under ideal (adiabatic) conditions, the exponent would be 1.4, but a lower value, generally between 1.2 and 1.3 is used, since the amount of heat lost will vary among engines based on design, size and materials used, but provides useful results for purposes of comparison. For example, if the static compression ratio is 10:1, and the dynamic compression ratio is 7.5:1, a useful value for cylinder pressure would be (7.5)^1.3 × atmospheric pressure, or 13.7 bar. (× 14.7 psi at sea level = 201.8 psi. The pressure shown on a gauge would be the absolute pressure less atmospheric pressure, or 187.1 psi.)\n\nThe two corrections for dynamic compression ratio affect cylinder pressure in opposite directions, but not in equal strength. An engine with high static compression ratio and late intake valve closure will have a DCR similar to an engine with lower compression but earlier intake valve closure.\n\nAdditionally, the cylinder pressure developed when an engine is running will be higher than that shown in a compression test for several reasons.\n\n\nCompression ratio and overall pressure ratio are interrelated as follows:\nThe reason for this difference is that compression ratio is defined via the volume reduction:\nwhile pressure ratio is defined as the pressure increase:\nIn calculating the pressure ratio, we assume that an adiabatic compression is carried out (i.e. that no heat energy is supplied to the gas being compressed, and that any temperature rise is solely due to the compression). We also assume that air is a perfect gas. With these two assumptions, we can define the relationship between change of volume and change of pressure as follows:\nwhere formula_14 is the ratio of specific heats (air: approximately 1.4).\nThe values in the table above are derived using this formula. Note that in reality the ratio of specific heats changes with temperature and that significant deviations from adiabatic behavior will occur.\n\n\n"}
{"id": "6865", "url": "https://en.wikipedia.org/wiki?curid=6865", "title": "Concordat of Worms", "text": "Concordat of Worms\n\nThe Concordat of Worms (), sometimes called the Pactum Calixtinum by papal historians, was an agreement between Pope Calixtus II and Holy Roman Emperor Henry V on September 23, 1122, near the city of Worms. It brought to an end the first phase of the power struggle between the Papacy and the Holy Roman Emperors and has been interpreted as containing within itself the germ of nation-based sovereignty that would one day be confirmed in the Treaty of Westphalia (1648); in part this was an unforeseen result of strategic maneuvering between the Church and the European sovereigns over political control within their domains. The King was recognised as having the right to invest bishops with secular authority (\"by the lance\") in the territories they governed, but not with sacred authority (\"by ring and staff\"); the result was that bishops owed allegiance in worldly matters both to the pope and to the king, for they were obliged to affirm the right of the sovereign to call upon them for military support, under his oath of fealty. Previous Holy Roman Emperors had thought it their right, granted by God, to name Church officials within their territories (such as bishops) and to confirm the Papal election (and, at times of extraordinary urgency, actually name popes). In fact, the Emperors had been heavily relying on bishops for their secular administration, as they were not hereditary or quasi-hereditary nobility with family interests, thus adding further suspense to the struggle. A more immediate result of the Investiture struggle identified a proprietary right that adhered to sovereign territory, recognising the right of kings to income from the territory of a vacant diocese and a basis for justifiable taxation. These rights lay outside feudalism, which defined authority in a hierarchy of personal relations, with only a loose relation to territory. The pope emerged as a figure above and out of the direct control of the Holy Roman Emperor.\n\nFollowing efforts by Lamberto Scannabecchi (later Pope Honorius II) and the Diet of Würzburg (1121) in 1122, Pope Calistus II and Holy Roman Emperor Henry V entered into an agreement that effectively ended the Investiture Controversy. By the terms of the agreement, the election of bishops and abbots in Germany was to take place in the emperor's presence as judge between potentially disputing parties, free of bribes, thus retaining to the emperor a crucial role in choosing these great territorial magnates of the Empire. Beyond the borders of Germany, in Burgundy and Italy, the Emperor was to forward the symbols of authority within six months. Calixtus' reference to the feudal homage due the emperor on appointment is guarded: \"shall do unto thee for these what he rightfully should\" was the wording of the \"privilegium\" granted by Calixtus. The Emperor's right to a substantial imbursement on the election of a bishop or abbot was specifically denied.\n\nThe Emperor renounced the right to invest ecclesiastics with ring and crosier, the symbols of their spiritual power, and guaranteed election by the canons of cathedral or abbey and free consecration. The two ended by granting one another peace.\n\nThe Concordat was confirmed by the First Council of the Lateran in 1123.\n\nThe Concordat of Worms was a part of the larger reforms put forth by many popes, most notably Pope Gregory VII. These included celibacy of the clergy, end of simony and autonomy of the Church from secular leaders (lack of autonomy was known as lay investiture).\n\nThe most prized and contested rights that attached to benefices were inheritance and security against confiscation. Benefices were lands granted by the Church to faithful lords. In exchange, the Church expected rent or other services, such as military protection. These lands would then be further divided between lesser lords and commoners. This was the nature of European feudalism. Inheritance was an important issue, since land could fall into the hands of those who did not have loyalty to the Church or the great lords. The usual grant was \"in precaria\", the granting of a life tenure, whereby the tenant stayed on the land only at the pleasure of the lord. The tenant could be expelled from the land at any time. His tenancy was \"precarious\". Counts’ benefices came to be inherited as counties were broken up and as counts assimilated their offices and ex-officio lands to their family property. In central Europe, kings and counts probably were willing to allow the inheritance of small parcels of land to the heirs of those who had offered military or other services in exchange for tenancy. This was contingent on the heirs being reasonably loyal and capable. Churches in Germany, as elsewhere, were willing to allow peasants to inherit their land. This was a source of profit to both churches and lords when the inheritors were charged a fee to inherit the land. Most bishops had a different attitude toward freemen and nobles. To these peasants, grants were made \"in precario\" or \"in beneficio\", usually for a specified and limited number of \"life tenures\". It was not impossible to recover land left to noble families for generations. But the longer the family held church land, the more difficult it was to oust them from the land. Some church officials came to view granting land to noble families amounted to outright alienation. By the twelfth century great churches in Germany, like those elsewhere were finding it difficult to hold out against the accumulation of lay custom and lay objections to temporary inheritance. The Bishop of Worms issued a statement in 1120 indicating the poor and unfree should be allowed to inherit tenancy without payment of fees. It appears to have been something novel. The growing masses of unfree and the marginal were needed for labour, and to bolster the military of both nobility and the church. By the time of Henry IV, bargaining by the peasants for the benefit of the group was the norm.\n\nThe Holy Roman Emperors of Ottonian Dynasty, when they came to the throne, believed they should have the power to appoint the pope. They also believed they should appoint minor church officials. The result was that, more often than not, bishops, abbots of monasteries, and even the pope were not independent, but resembled lackeys or sycophants of the crown of the Holy Roman Empire. This attitude was bolstered by the general conception that the Holy Roman Emperor and all other European Kings were chosen by God to be leaders.\n\nFor temporal secular reasons, the kings did nothing to dispel this attitude. It meant more power for them. A series of popes began to directly challenge this condition. The most vocal and strident was Pope Gregory VII. Reform took a century, but brought greater autonomy for the papacy and the Church in general.\n\nIn the period immediately after 1000, two figures appeared to lead Western Christendom, the pope and the Holy Roman Emperor. Antagonism between the two dominated the next century. After the death of Pope Silvester II in 1003, the papacy fell under the influence of the nobility in Latium, and then after 1046, under the influence of the German emperors. The reality for the west in the Middle Ages was not only the fact that government was split up into small particles but also the fact that vertical and horizontal powers were entangled. People in the Middle Ages did not always know to which of the many lords, the Church and the individual churches, the towns, princes, and kings, they were subordinate. This can be observed in the complexity even at the administrative and judicial level in the jurisdictional conflicts that fill mediaeval history.\n\nThe Church endeavoured to become disengaged from the German control. An example of this secular politicisation is seen when Conrad II, Holy Roman Emperor supported Pope Benedict IX, the most corrupt of any of the popes of the era. It took more than a century to end this manipulation, and was never complete. In the process, the whole Church emerged freed from the grip of all lay lords. This was known as the Gregorian Reform, which takes its name from Pope Gregory VII, (1073–85) . It was merely the latest and most visible of reforms that tended to move the Church back to its roots. It was a question of restoring the autonomy and power of the priestly class in the face of increasing control by the warrior class. The clergy was forced to renew and define itself. There was a battle against simony. The roadmap to celibacy was drawn, if not immediately enacted. Monarchs were excluded from selecting popes. This had been decreed by Pope Nicholas II in 1059. Afterwards, only cardinals could elect the pope. Gregorian Reform reiterated this notion. There was to be no more lay interference in the selection of clergy. The aim was to deprive emperors and their under-lords the right to nominate and invest bishops. The effect was to deprive lay kings power over the Church and increase both spiritual and temporal power in the Vatican and the bishops.\n\nGregory VII appeared to have succeeded when the emperor Henry IV, Holy Roman Emperor was humiliated at Canossa in 1077. There, Henry begged in the snow to be let back into the good graces of the Church, having been excommunicated the year before by Gregory. The penitent and humbled emperor did not remain in that state. Soon Henry IV took his revenge. He named his own pope Antipope Clement III in the old manner of the Holy Roman Emperors. Pope Urban II, more prudent than Gregory sidestepped the issue using a Crusade to gather Christian Europe together under his authority. A compromise was reached in Worms in 1122, by which the emperor abandoned investiture “by ring and staff” to the pope, and promised to respect the freedom of elections and consecrations, but kept for himself the right to invest bishops with the temporalities of their sees “by scepter”. Though the Emperor retained some power over imperial churches, his power was damaged irreparably because he lost the religious authority that previously belonged to the office of the king. In France, England, and the Christian state in Spain, the king could overcome rebellions of his magnates and establish the power of his royal demesne because he could rely on the Church, which, for several centuries, had given him a mystical authority. From time to time, rebellious and recalcitrant monarchs might run afoul of the Church. These could be excommunicated, and after an appropriate time and public penance, be received back into the communion and good graces of the Church.\n\nIn 1075, Gregory VII condemned lay investiture in a document called Dictatus papae. The new doctrine was called libertas ecclesiae (\"freedom of the Church\"). Henry IV insisted on involvement in clerical appointment. The dispute revolved around the issue of investiture—i.e., whether the Holy Roman Emperor had the right to name bishops as well as popes. Gregory VII excommunicated Henry IV in 1076, releasing all Henry's subjects from obedience to him. It led to a great political struggle with many barons rising against Henry in open rebellion. Henry made his way to the Canossa where the Pope was staying in the castle of Countess Matilda. Henry claimed a wish to repent. The pope was suspicious of Henry’s motives, and did not believe he was truly repentant. Henry did penance in the snow outside the castle for three days. Finally, Gregory gave him absolution. The rebellious nobles in Germany who were interested in deposing Henry IV never forgave Pope Gregory VII for what they viewed as treachery.\n\nHenry IV was excommunicated again in 1080, and would not show any indication of repentance. In turn, Henry called a council of bishops who proclaimed Gregory illegitimate. He remained excommunicate for twenty-six years until his death in 1106. It was the consequence of this lengthy episode that a whole generation grew up in Germany and Northern Italy in an atmosphere of war, doubt and scepticism. The papal backers had been busy propounding arguments to show that royal power was not of divine origin. They had been so successful that the moral authority of the Emperor had been undermined in the minds of many of his subjects. Serious divisions existed from this battle over the Investiture controversy, which fractured large portions of the Holy Roman Empire in Germany and Italy. Davis argues these rifts were so deep and lasting that neither Germany nor Italy were able to form a cohesive nation state until the 19th century. A similar situation arose from the French revolution, which caused fractures in France that still exist. The effect of Henry’s excommunication, and his subsequent refusal to repent left a turbulence in central Europe that lasted throughout the Middle Ages. It may have been emblematic of certain German attitudes toward religion in general, and the perceived relevance of the German Emperor in the universal scheme of things.\n\nHenry IV became so filled with hubris over his position, that he renounced Gregory VII and named the bishop of Ravenna pope. Perhaps he was only following what had been thought to be the right of kings: to name the pope. Henry had invested the Ravenna bishop, and now he referred to the new pope, Clement III, Antipope Clement III as \"our pope\". Henry attacked Rome, and on the outskirts of the city gained thirteen cardinals who became loyal to his cause. On Palm Sunday, 1084, Henry IV solemnly enthroned Clement at St. Peter's Basilica and on Easter Day, Clement returned the favour and crowned Henry IV as Emperor of the Holy Roman Empire. Gregory VII was meanwhile still resisting a few hundred yards away from the basilica in the Castel San Angelo, then known as the house of Cencius. Gregory appealed to the Normans for help, and Robert Guiscard responded, entering Rome on May 27, 1084 and rescuing him. In the process, Rome was pillaged and partially burned. Gregory VII died the next year on May 25, 1085 in exile. He felt all was lost. The last words he uttered were, \"I have loved justice and hated iniquity, and therefore I die in exile.\" Gregory VII must have felt he died in utter failure, and to many of his contemporaries it appeared Henry IV and Antipope Clement III had won. But the underlying current was that Henry had overreached, and his appointment of the antipope was beyond the pale. Upon the death of Gregory, the cardinals elected a new pope, Victor III. He owed his elevation to the influence of the Normans. Antipope Clement III still occupied St. Peter’s. When Victor III died, the cardinals elected Urban II (1088–99). He was one of three men Gregory VII suggested as his successor. Urban II preached the First Crusade, which united Western Europe, and more importantly, reconciled the majority of bishops who had abandoned Gregory VII. In the end, Gregorian Reform won out over Henry IV. Preaching the Crusade had one important consequence. The pope was now viewed as the head of the Church. No longer would kings and emperors think themselves equals of the pope, or the head of the Church in their kingdom. This was the situation from 1122 until the Reformation.\n\nSeveral years later, Henry IV died in a deep gloom as had Gregory. It remained for his successor, Henry V to agree with Pope Calixtus II in 1122 to a compromise of the conflict over lay investitures known as the Concordat of Worms.\n\nThe reign of Henry IV showed the weakness of the German monarchy. The ruler was dependent upon the good will of the great men, the nobility of his land. These were technically royal officials and hereditary princes. He was also dependent on the resources of the churches. Henry IV alienated the Church of Rome and many of the magnates in his own kingdom. Many of these spent years in open or subversive rebellion. Henry failed to create a proper bureaucracy to replace his disobedient vassals. The magnates became increasingly independent, and the Church withdrew support. Henry IV spent the last years of his life desperately grasping to keep his throne. It was a greatly diminished kingdom.\n\nThe reign of Henry IV ended with a diminished kingdom and waning power. Many of his underlords had been in constant or desultory revolt for years. Henry IV’s insistence that Antipope Clement III was the real pope had initially been popular with some of the nobles, and even many of the bishops of Germany. But as years passed, this support was slowly withdrawn. The idea that the German king could and should name the pope was increasingly discredited and viewed as an anachronism from a by-gone era. The Empire of the Ottos was virtually lost because of Henry IV.\n\nHenry IV's son, Henry V, rebelled and became emperor after his father's abdication. Henry V realised swift action and a change in his father's policy was necessary. Pope Paschal II rebuked Henry V for appointing bishops in Germany. The king crossed the Alps with an army in 1111. The pope, who was weak and had few supporters was forced to suggest a compromise, the abortive Concordat of 1111. Its simple and radical solution of the Investiture Controversy between the prerogatives of \"regnum\" and \"sacredoium\" proposed that German churchmen would surrender their lands and secular offices to the emperor and constitute a purely spiritual church. Henry gained greater control over the lands of his kingdom, especially those that had been in the hands of the church, but of contested title. He would not interfere with ecclesiastical affairs and churchmen would avoid secular services. The church would be given autonomy and to Henry V would be restored large parts of his empire that his father had lost. Henry V was crowned by Pope Paschal II as the legitimate Holy Roman Emperor. When the concessions of land were read in St. Peters, the crowd revolted in anger. Henry took the pope and cardinals hostage until the pope granted Henry V the right of investiture. Then he returned to Germany – crowned emperor and apparent victor over the papacy.\n\nThe victory was as short-lived as that of his father, Henry IV over Gregory VII. The clergy urged Paschal to rescind his agreement, which he did in 1112. The quarrel followed the predictable course: Henry V rebelled and was excommunicated. Riots broke out in Germany, a new Antipope Gregory VIII was appointed by the German king, nobles loyal to Rome seceded from Henry. The civil war continued, just as under Henry IV. It dragged on for another ten years. Like his father before him, Henry V was faced with waning power. He had no choice but to give up investiture and the old right of naming the pope. The Concordat of Worms was the result. After the Concordat, the German kings never had the same control over the Church as had existed in the time of the Ottonian Dynasty.\n\nHenry V died without heirs in 1125, three years after the Concordat. He had designated his nephew, Frederick von Staufen duke of Swabia, also known as Frederick II, Duke of Swabia as his successor. Instead, churchmen elected Lothar III. A long civil war erupted between the Staufen also known as Hohenstaufen supporters and the heirs of Lothar III. The result was the Hohenstaufen Frederick I (Barbarossa) 1152–1190 who came to power.\n\nThe Concordat of Worms was foreshadowed the Charter of Liberties of Henry I of England. He was the youngest son of William the Conqueror. Through a series of political intrigues, Henry I gained the English throne in 1100. Henry had three problems: (1) Conflict with the Church and Anselm of Canterbury in particular. (2) The earls and barons of England did not accept Henry as their king. (3) The Anglo-Saxon populace did not accept him. Henry reconciled with the Church and Anselm. He married Edith, the daughter of the Scots King Malcolm III. The Anglo-Saxon population was placated because they viewed Edith as one of their own. Henry signed and issued the Charter of Liberties in 1100 from the Norman Chapel in the Tower of London. This gave concessions to the earls and barons, as well as the Church. The investiture issue was still contentious, but a compromise at Bec Abbey in 1107 was essentially identical to the Concordat of Worms.\n\nThe Concordat of London in 1107 was a forerunner of the compromise that was taken up in the Concordat of Worms. In England, as in Germany, the conflict between Church and State was rife. A distinction was being made in the king's chancery between the secular and ecclesiastical powers of the prelates. Bowing to political reality, Henry I of England ceded his right to invest his bishops and abbots and reserved the custom of requiring them to come and do homage. The system of vassalage was not divided among great local lords in England as it was in France, for by right of the Conquest the king was in control.\n\nHenry I of England perceived a danger in placing monastic scholars in his chancery and turned increasingly to secular clerks, some of whom held minor positions in the Church. He often rewarded these men with the titles of bishop and abbot. Henry I expanded the system of scutage to reduce the monarchy's dependence on knights supplied from church lands. Unlike the situation in Germany, Henry I of England used the investiture controversy to strengthen the secular power of the king. It would continue to boil under the surface. The controversy would surface in the Thomas Becket affair under Henry II of England, the , the Statutes of Mortmain and the battles over Cestui que use of Henry VII of England, and finally come to a head under Henry VIII of England.\n\nOf the three reforms Gregory VII and his predecessors and successor popes had attempted, they had been most successful in regard to celibacy of the clergy. Simony had been partially checked. Against lay investiture they won only a limited success, and one that seemed less impressive as the years passed. During the time following the Concordat of Worms, the Church gained in both stature and power.\n\nAccording to the terms of the compromise, the election of bishops and abbots was to follow proper procedure, that is, the canons of the cathedral were to elect the bishop. The monks were to choose the abbot, and only ecclesiastical superiors were to invest the candidate with ring and staff (the traditional insignia of the episcopal office). This was a minimum that the church had demanded (who had far fewer problems with a mere nomination by a layman if the layman did not actually hand over ring and staff). To make up for this and symbolise the \"worldly\" authority of the bishop which the pope had always recognised to derive from the Emperor, another symbol, the scepter, was invented, which would be handed over by the king (or his legate). The rest is an actual compromise: In \"Germany\", the Emperor (or his legate) would have the right to be present at elections to resolve any disputes between candidates (\"yet without violence\"). What this meant, in effect, was that the king would have the bishop he wanted (though over time, the territorial princes would get some \"representation\" within the chapters, making it less easy to ignore them). The bishop-elect would then by invested by the Emperor (or representative) with the scepter and, sometime afterwards, by his ecclesial superior with ring and staff. As William of Champeaux assured Henry V, he had nothing to lose by surrendering the right of investiture. The king retained substantially what he already possessed—the power to fill bishoprics with men of his choice. Nevertheless, Gregory VII’s dramatisation of the issue produced a significant improvement in the character of men raised to the episcopacy. Kings no longer interfered so frequently in their election, and when they did, they generally nominated more worthy candidates for the office.\n\nThis takes only Germany into account, though. As for Burgundy and Italy, elections were to be held without interference by the Emperor, and consecration and investiture by the ecclesial superior would, here, precede the investiture with the scepter which was to follow some time afterwards. Thus, by the Pope accepting the German bishops to be nominated with a large amount of secular influence, his right was recognized to freely choose the bishops in the other parts of the Empire, especially in Imperial Italy at the very doors of the Papal States. To see in the Concordat of Worms mere face-saving of the Church is thus not correct.\n\nThe writing in the document was ambiguous, skirted some issues and avoided others all together. This has caused some scholars to conclude that the settlement turned its back on Gregory VII and Urban II's genuine hopes for reform. The emperor's influence in episcopal was preserved, and he could decide disputed elections. If the compromise was a rebuke to the most radical vision of the liberty of the Church, on at least one point its implication was firm and unmistakable: The king, even an emperor, was a layman, and his power at least morally limited (hence, totalitarianism was unacceptable). According to the opinion of W. Jordan, the divine right of kings was dealt a blow from which it never completely recovered, yet it should be noted that unfettered authority and Caesaropapism was not something the later Mediaevals and Early Moderns understood by the phrase \"by the grace of God\" (which many of them ardently defended). If anything, a blow was dealt to subconsciously remaining pre-Christian Germanic feelings of \"royal hail\".\n\nThere exists a misconception concerning the power of the pope in the Middle Ages. Tradition affords him more power and authority than he actually possessed. It is likely the pope in modern ages is much more powerful than those in mediaeval times. The most powerful of all mediaeval popes was Innocent III. His pronouncements on doctrinal matters and the judgments of his court were considered definitive and final. Opposing the mediaeval pope was the primary and unyielding authority of the state. The struggle over investiture between Pope Gregory VII and Henry IV, Holy Roman Emperor had dramatised the clash between church and state. The Concordat of Worms had eased the situation for a generation. But in the end, it solved nothing. Practically speaking, the king retained a decisive voice in the selection of the hierarchy. All kings supported King John of England’s defiance of Pope Innocent III ninety years after the Concordat of Worms in the matter concerning Stephen Langton. In theory, the pope named his bishops and cardinals. In reality, more often than not, Rome consecrated the clergy once it was notified by the kings who the incumbent would be. Recalcitrance by Rome would lead to problems in the kingdom. For the most part it was a no-win situation for Rome. In this, the Concordat of Worms changed little. The growth of canon law in the Ecclesiastical Courts was based on the underlying Roman law and increased the strength of the Roman Pontiff.\n\nThe English Church was left more or less in the power of the English monarchy. This was the result of the Charter of Liberties, 1100, and the agreement at Bec in 1107. The effect of the Concordat of Worms was different. It ended a civil war that had been going on for more than fifty years. There was no going back to the situation that had preceded it. The political and social structure of Germany had forever been altered. The new generation of cardinals regarded German investiture with contempt and as an embarrassing vestige of the past. They were willing to make concessions with Henry V and his successors in order to get along. The belief after the Concordat was that investiture and the era of theocratic kingship was a discredited doctrine. The German kings had a different view of the matter. Henry V and his successors still believed they had the right and ability to name bishops. In practice, this was true, but only in the territories held by their families. Their domain in the religious sphere had been greatly diminished.\n\nThe catastrophic political consequences of the struggle between pope and emperor also led to a cultural disaster. Germany lost intellectual leadership in western Europe. In 1050, German monasteries were great centres of learning and art and German schools of theology and canon law were unsurpassed and probably unmatched anywhere in Europe. The long civil war over investiture sapped the energy of both German churchmen and intellectuals. They fell behind advances in philosophy, law, literature and art taking place in France and Italy. In many ways, Germany never caught up during the rest of the Middle Ages. Universities were established in France, Italy and England by the early 13th century. Notable are University of Bologna, 1088, University of Paris, 1150, Oxford University, 1167 and Cambridge University, 1207. The first German university, the University of Heidelberg was not established until 1386. It was immediately steeped in mediaeval nominalism and early Protestantism.\n\nKings continued to attempt to control either the direct leadership of the church, or indirectly through political means for centuries. This is seen most clearly in the Avignon Papacy when the popes moved from Rome to Avignon. The conflict in Germany and northern Italy arguably left the culture ripe for various Protestant sects, such as the Cathars, the Waldensians and ultimately Hus and Luther.\n\n\n\n"}
{"id": "6867", "url": "https://en.wikipedia.org/wiki?curid=6867", "title": "Context-free language", "text": "Context-free language\n\nIn formal language theory, a context-free language (CFL) is a language generated by a context-free grammar (CFG).\n\nContext-free languages have many applications in programming languages, in particular, most arithmetic expressions are generated by context-free grammars.\n\nDifferent CF grammars can generate the same CF language. Intrinsic properties of the language can be distinguished from extrinsic properties of a particular grammar by comparing multiple grammars that describe the language.\n\nThe set of all context-free languages is identical to the set of languages accepted by pushdown automata, which makes these languages amenable to parsing. Further, for a given CFG, there is a direct way to produce a pushdown automaton for the grammar (and thereby the corresponding language), though going the other way (producing a grammar given an automaton) is not as direct.\n\nA model context-free language is formula_1, the language of all non-empty even-length strings, the entire first halves of which are formula_2's, and the entire second halves of which are formula_3's. formula_4 is generated by the grammar formula_5.\nThis language is not regular.\nIt is accepted by the pushdown automaton formula_6 where formula_7 is defined as follows:\nformula_8<br>\nformula_9<br>\nformula_10<br>\nformula_11\nUnambiguous CFLs are a proper subset of all CFLs: there are inherently ambiguous CFLs. An example of an inherently ambiguous CFL is the union of formula_12 with formula_13. This set is context-free, since the union of two context-free languages is always context-free. But there is no way to unambiguously parse strings in the (non-context-free) subset formula_14 which is the intersection of these two languages.\n\nThe language of all properly matched parentheses is generated by the grammar formula_15.\n\nThe context-free nature of the language makes it simple to parse with a pushdown automaton.\n\nDetermining an instance of the membership problem; i.e. given a string formula_16, determine whether formula_17 where formula_4 is the language generated by a given grammar formula_19; is also known as \"recognition\". Context-free recognition for Chomsky normal form grammars was shown by Leslie G. Valiant to be reducible to boolean matrix multiplication, thus inheriting its complexity upper bound of \"O\"(\"n\").\nConversely, Lillian Lee has shown \"O\"(\"n\") boolean matrix multiplication to be reducible to \"O\"(\"n\") CFG parsing, thus establishing some kind of lower bound for the latter.\n\nPractical uses of context-free languages require also to produce a derivation tree that exhibits the structure that the grammar associates with the given string. The process of producing this tree is called \"parsing\". Known parsers have a time complexity that is cubic in the size of the string that is parsed.\n\nFormally, the set of all context-free languages is identical to the set of languages accepted by pushdown automata (PDA). Parser algorithms for context-free languages include the CYK algorithm and Earley's Algorithm.\n\nA special subclass of context-free languages are the deterministic context-free languages which are defined as the set of languages accepted by a deterministic pushdown automaton and can be parsed by a LR(k) parser.\n\nSee also parsing expression grammar as an alternative approach to grammar and parser.\n\nContext-free languages are closed under the following operations. That is, if \"L\" and \"P\" are context-free languages, the following languages are context-free as well:\n\nContext-free languages are not closed under complement, intersection, or difference. This was proved by Scheinberg in 1960. However, if \"L\" is a context-free language and \"D\" is a regular language then both their intersection formula_28 and their difference formula_29 are context-free languages.\n\nThe context-free languages are not closed under intersection. This can be seen by taking the languages formula_30 and formula_31, which are both context-free. Their intersection is formula_32, which can be shown to be non-context-free by the pumping lemma for context-free languages.\n\nContext-free languages are also not closed under complementation, as for any languages A and B: formula_33.\n\nContext-free language are also not closed under difference: L = Σ \\ L.\n\nThe following problems are undecidable for arbitrarily given context-free grammars A and B:\n\nThe following problems are \"decidable\" for arbitrary context-free languages:\n\nAccording to Hopcroft, Motwani, Ullman (2003), \nmany of the fundamental closure and (un)decidability properties of context-free languages were shown in the 1961 paper of Bar-Hillel, Perles, and Shamir\n\nThe set formula_14 is a context-sensitive language, but there does not exist a context-free grammar generating this language. So there exist context-sensitive languages which are not context-free. To prove that a given language is not context-free, one may employ the pumping lemma for context-free languages or a number of other methods, such as Ogden's lemma or Parikh's theorem.\n\n"}
{"id": "6868", "url": "https://en.wikipedia.org/wiki?curid=6868", "title": "Caffeine", "text": "Caffeine\n\nCaffeine is a central nervous system (CNS) stimulant of the methylxanthine class. It is the world's most widely consumed psychoactive drug. Unlike many other psychoactive substances, it is legal and unregulated in nearly all parts of the world. There are several known mechanisms of action to explain the effects of caffeine. The most prominent is that it reversibly blocks the action of adenosine on its receptor and consequently prevents the onset of drowsiness induced by adenosine. Caffeine also stimulates certain portions of the autonomic nervous system.\nCaffeine is a bitter, white crystalline purine, a methylxanthine alkaloid, and is chemically related to the adenine and guanine bases of deoxyribonucleic acid (DNA) and ribonucleic acid (RNA). It is found in the seeds, nuts, or leaves of a number of plants native to South America and East Asia and helps to protect them against predator insects and to prevent germination of nearby seeds. The most well known source of caffeine is the coffee bean, a misnomer for the seed of \"Coffea\" plants. Beverages containing caffeine are ingested to relieve or prevent drowsiness and to improve performance. To make these drinks, caffeine is extracted by steeping the plant product in water, a process called infusion. Caffeine-containing drinks, such as coffee, tea, and cola, are very popular; in 2005, 90% of North American adults consumed caffeine daily.\nCaffeine can have both positive and negative health effects. It can treat and prevent the premature infant breathing disorders bronchopulmonary dysplasia of prematurity and apnea of prematurity. Caffeine citrate is on the WHO Model List of Essential Medicines. It may confer a modest protective effect against some diseases, including Parkinson's disease. Some people experience insomnia or sleep disruption if they consume caffeine, especially during the evening hours, but others show little disturbance. Evidence of a risk during pregnancy is equivocal; some authorities recommend that pregnant women limit consumption to the equivalent of two cups of coffee per day or less. Caffeine can produce a mild form of drug dependence – associated with withdrawal symptoms such as sleepiness, headache, and irritability – when an individual stops using caffeine after repeated daily intake. Tolerance to the autonomic effects of increased blood pressure and heart rate, and increased urine output, develops with chronic use (i.e., these symptoms become less pronounced or do not occur following consistent use).\nCaffeine is classified by the US Food and Drug Administration as \"generally recognized as safe\" (GRAS). Toxic doses, over 10 grams per day for an adult, are much higher than typical doses of under 500 milligrams per day. A cup of coffee contains 80–175 mg of caffeine, depending on what \"bean\" (seed) is used and how it is prepared (e.g. drip, percolation, or espresso). Thus it requires roughly 50–100 ordinary cups of coffee to reach a lethal dose. However pure powdered caffeine, which is available as a dietary supplement, can be lethal in tablespoon-sized amounts.\n\nCaffeine is used in:\n\nCaffeine is a central nervous system stimulant that reduces fatigue and drowsiness. At normal doses, caffeine has variable effects on learning and memory, but it generally improves reaction time, wakefulness, concentration, and motor coordination. The amount of caffeine needed to produce these effects varies from person to person, depending on body size and degree of tolerance. The desired effects arise approximately one hour after consumption, and the desired effects of a moderate dose usually subside after about three or four hours.\n\nCaffeine can delay or prevent sleep, and improves task performance during sleep deprivation. Shift workers who use caffeine make fewer mistakes due to drowsiness.\n\nA systematic review and meta-analysis from 2014 found that concurrent caffeine and -theanine use has synergistic psychoactive effects that promote alertness, attention, and task switching; these effects are most pronounced during the first hour post-dose.\n\nCaffeine is a proven ergogenic aid in humans. Caffeine improves athletic performance in aerobic (especially endurance sports) and anaerobic conditions. Moderate doses of caffeine (around 5 mg/kg) can improve sprint performance, cycling and running time trial performance, endurance (i.e., it delays the onset of muscle fatigue and central fatigue), and cycling power output.\n\nFor the general population of healthy adults, Health Canada advises a daily intake of no more than 400 mg.\n\nIn healthy children, caffeine intake produces effects that are \"modest and typically innocuous\". There is no evidence that coffee stunts a child's growth. For children age 12 and under, Health Canada recommends a maximum daily caffeine intake of no more than 2.5 milligrams per kilogram of body weight. Based on average body weights of children, this translates to the following age-based intake limits:\nHealth Canada has not developed advice for adolescents because of insufficient data. However, they suggest that daily caffeine intake for this age group be no more than 2.5 mg/kg body weight. This is because the maximum adult caffeine dose may not be appropriate for light weight adolescents or for younger adolescents who are still growing. The daily dose of 2.5 mg/kg body weight would not cause adverse health effects in the majority of adolescent caffeine consumers. This is a conservative suggestion since older and heavier weight adolescents may be able to consume adult doses of caffeine without suffering adverse effects.\n\nThe UK Food Standards Agency has recommended that pregnant women should limit their caffeine intake, out of prudence, to less than 200 mg of caffeine a day – the equivalent of two cups of instant coffee, or one and a half to two cups of fresh coffee. The American Congress of Obstetricians and Gynecologists (ACOG) concluded in 2010 that caffeine consumption is safe up to 200 mg per day in pregnant women. For women who breastfeed, are pregnant, or may become pregnant, Health Canada recommends a maximum daily caffeine intake of no more than 300 mg, or a little over two 8 oz (237 mL) cups of coffee.\n\nThe evidence for or against the importance of limiting caffeine intake during pregnancy is insufficient and of low quality. There are conflicting reports in the scientific literature about caffeine consumption during pregnancy. A 2011 risk analysis review found that caffeine consumption during pregnancy does not appear to increase the risk of congenital malformations, miscarriage or growth retardation even when consumed in moderate to high amounts. There is some evidence that the hormonal changes during pregnancy slow the metabolic clearance of caffeine from the system, causing a given dose to have longer-lasting effects (as long as 15 hours in the third trimester). There is some evidence that higher caffeine intake by pregnant women may be associated with a higher risk of giving birth to a low birth weight baby, and may be associated with a higher risk of pregnancy loss. A systematic review, analyzing the results of observational studies, suggests that women who consume large amounts of caffeine (greater than 300 mg/day) prior to becoming pregnant may have a higher risk of experiencing pregnancy loss.\n\nCaffeine can increase blood pressure and cause vasoconstriction. Long-term consumption at sufficiently high doses has been associated with chronic arterial stiffness. Coffee and caffeine can affect gastrointestinal motility and gastric acid secretion. Caffeine in low doses may cause weak bronchodilation for up to four hours in asthmatics. Caffeine increases basal metabolic rate in adults. In postmenopausal women, high caffeine consumption can accelerate bone loss.\n\nDoses of caffeine equivalent to the amount normally found in standard servings of tea, coffee and carbonated soft drinks appear to have no diuretic action. However, acute ingestion of caffeine in large doses (at least 250–300 mg, equivalent to the amount found in 2–3 cups of coffee or 5–8 cups of tea) results in a short-term stimulation of urine output in individuals who have been deprived of caffeine for a period of days or weeks. This increase is due to both a diuresis (increase in water excretion) and a natriuresis (increase in saline excretion); it is mediated via proximal tubular adenosine receptor blockade. The acute increase in urinary output may increase the risk of dehydration. However, chronic users of caffeine develop a tolerance to this effect, and experience no increase in urinary output.\n\nMinor undesired symptoms from caffeine ingestion not sufficiently severe to warrant a psychiatric diagnosis are common, and include mild anxiety, jitteriness, insomnia, increased sleep latency, and reduced coordination. Caffeine can have negative effects on anxiety disorders. According to a 2011 literature review, caffeine use is positively associated with anxiety and panic disorders. At high doses, typically greater than 300 mg, caffeine can both cause and worsen anxiety. For some people, discontinuing caffeine use can significantly reduce anxiety.\n\nIn moderate doses, caffeine may reduce symptoms of depression and lower suicide risk.\n\nSome textbooks state that caffeine is a mild euphoriant, others state that it is not a euphoriant, and one states that it is and is not a euphoriant.\n\nWhether or not caffeine can result in an addictive disorder depends on how addiction is defined. Some diagnostic models, such as the and ICD-10, include a classification of caffeine addiction under a broader diagnostic model. Some state that certain users can become addicted and therefore unable to decrease use even though they know there are negative health effects.\n\nCaffeine does not appear to be a reinforcing stimulus, and some degree of aversion may actually occur, with people preferring placebo over caffeine in a study on drug abuse liability published in an NIDA research monograph. Some state that research does not provide support for an underlying biochemical mechanism for caffeine addiction. Other research states it can affect the reward system.\n\n\"Caffeine addiction\" was added to the ICDM-9 and ICD-10. However, its addition was contested with claims that this diagnostic model of caffeine addiction is not supported by evidence. The American Psychiatric Association's does not include the diagnosis of a \"caffeine addiction\" but proposes criteria for the disorder for more study.\n\nWithdrawal can cause mild to clinically significant distress or impairment in daily functioning. The frequency at which this occurs is self reported at 11%, but in lab tests only half of the people who report withdrawal actually experience it, casting doubt on many claims of dependence. Mild to increasingly severe physical dependence and withdrawal symptoms may occur upon abstinence, with greater than 100 mg caffeine per day; some symptoms associated with psychological dependence may also occur during withdrawal. Caffeine dependence can involve withdrawal symptoms such as fatigue, headache, irritability, depressed mood, reduced contentedness, inability to concentrate, sleepiness or drowsiness, stomach pain, and joint pain. Withdrawal headaches are experienced by roughly half of those who stop consuming caffeine for two days following an average daily intake of 235 mg.\n\nThe ICD-10 includes a diagnostic model for caffeine dependence, but the DSM-5 does not. The APA, which published the DSM-5, acknowledged that there was sufficient evidence in order to create a diagnostic model of caffeine dependence for the DSM-5, but they noted that the clinical significance of this disorder is unclear. The DSM-5 instead lists \"caffeine use disorder\" in the section of the manual.\n\nTolerance varies for daily, regular caffeine users and high caffeine users. High doses of caffeine (750 to 1200 mg/day spread throughout the day) have been shown to produce complete tolerance to some, but not all of the effects of caffeine. Doses as low as 100 mg/day, such as a 6 oz cup of coffee or two to three 12 oz servings of caffeinated soft-drink, may continue to cause sleep disruption, among other intolerances. Non-regular caffeine users have the least caffeine tolerance for sleep disruption. Some coffee drinkers develop tolerance to its undesired sleep-disrupting effects, but others apparently do not.\n\nA protective effect of caffeine against Alzheimer's disease is possible, but the evidence is inconclusive. Caffeine increases intraocular pressure in those with glaucoma but does not appear to affect normal individuals. It may protect people from liver cirrhosis. Caffeine may lessen the severity of acute mountain sickness if taken a few hours prior to attaining a high altitude.\n\nConsumption of 1–1.5 grams per day is associated with a condition known as \"caffeinism.\" Caffeinism usually combines caffeine dependency with a wide range of unpleasant symptoms including nervousness, irritability, restlessness, insomnia, headaches, and palpitations after caffeine use.\n\nCaffeine overdose can result in a state of central nervous system over-stimulation called \"caffeine intoxication\" (DSM-IV 305.90). This syndrome typically occurs only after ingestion of large amounts of caffeine, well over the amounts found in typical caffeinated beverages and caffeine tablets (e.g., more than 400–500 mg at a time). The symptoms of caffeine intoxication are comparable to the symptoms of overdoses of other stimulants: they may include restlessness, fidgeting, anxiety, excitement, insomnia, flushing of the face, increased urination, gastrointestinal disturbance, muscle twitching, a rambling flow of thought and speech, irritability, irregular or rapid heart beat, and psychomotor agitation. In cases of much larger overdoses, mania, depression, lapses in judgment, disorientation, disinhibition, delusions, hallucinations, or psychosis may occur, and rhabdomyolysis (breakdown of skeletal muscle tissue) can be provoked.\n\nMassive overdose can result in death. The LD of caffeine in humans is dependent on individual sensitivity, but is estimated to be 150 to 200 milligrams per kilogram of body mass (75–100 cups of coffee for a 70 kilogram adult). A number of fatalities have been caused by overdoses of readily available powdered caffeine supplements, for which the estimated lethal amount is less than a tablespoon. The lethal dose is lower in individuals whose ability to metabolize caffeine is impaired due to genetics or chronic liver disease A death was reported in a man with liver cirrhosis who overdosed on caffeinated mints.\n\nTreatment of mild caffeine intoxication is directed toward symptom relief; severe intoxication may require peritoneal dialysis, hemodialysis, or hemofiltration.\n\nAccording to DSST, alcohol provides a reduction in performance and caffeine has a significant improvement in performance. When alcohol and caffeine are consumed jointly, the effects produced by caffeine are affected, but the alcohol effects remain the same. For example, when additional caffeine is added, the drug effect produced by alcohol is not reduced. However, the jitteriness and alertness given by caffeine is decreased when additional alcohol is consumed. Alcohol consumption alone reduces both inhibitory and activational aspects of behavioral control. Caffeine antagonizes the activational aspect of behavioral control, but has no effect on the inhibitory behavioral control.\n\nSmoking tobacco increases caffeine clearance by 56%.\n\nConsumption of caffeine while orally administering birth control can extend the half-life of caffeine; therefore, greater attention should be taken during caffeine consumption.\n\nCaffeine may increase the effectiveness of some medications including ones used to treat headaches.\n\nIn the absence of caffeine and when a person is awake and alert, little adenosine is present in (CNS) neurons. With a continued wakeful state, over time it accumulates in the neuronal synapse, in turn binding to and activating adenosine receptors found on certain CNS neurons; when activated, these receptors produce a cellular response that ultimately increases drowsiness. When caffeine is consumed, it antagonizes adenosine receptors; in other words, caffeine prevents adenosine from activating the receptor by blocking the location on the receptor where adenosine binds to it. As a result, caffeine temporarily prevents or relieves drowsiness, and thus maintains or restores alertness.\n\nCaffeine is a receptor antagonist at all adenosine receptor subtypes (A, A, A, and A receptors). Antagonism at these receptors stimulates the medullary vagal, vasomotor, and respiratory centers, which increases respiratory rate, reduces heartrate, and constricts blood vessels. Adenosine receptor antagonism also promotes neurotransmitter release (e.g., monoamines and acetylcholine), which endows caffeine with its stimulant effects; adenosine acts as an inhibitory neurotransmitter that suppresses activity in the central nervous system. Heart palpitations are caused by blockade of the adenosine A1 receptor.\n\nBecause caffeine is both water- and lipid-soluble, it readily crosses the blood–brain barrier that separates the bloodstream from the interior of the brain. Once in the brain, the principal mode of action is as a nonselective antagonist of adenosine receptors (in other words, an agent that reduces the effects of adenosine). The caffeine molecule is structurally similar to adenosine, and is capable of binding to adenosine receptors on the surface of cells without activating them, thereby acting as a competitive antagonist.\n\nIn addition to its activity at adenosine receptors, caffeine is an inositol trisphosphate receptor 1 antagonist and a voltage-independent activator of the ryanodine receptors (RYR1, RYR2, and RYR3). It is also a competitive antagonist of the ionotropic glycine receptor.\n\nWhile caffeine does not directly bind to any dopamine receptors, it influences the binding activity of dopamine at its receptors in the striatum by binding to adenosine receptors that have formed GPCR heteromers with dopamine receptors, specifically the A–D receptor heterodimer (this is a receptor complex with 1 adenosine A receptor and 1 dopamine D receptor) and the A–D receptor heterotetramer (this is a receptor complex with 2 adenosine A receptors and 2 dopamine D receptors). The A–D receptor heterotetramer has been identified as a primary pharmacological target of caffeine, primarily because it mediates some of its psychostimulant effects and its pharmacodynamic interactions with dopaminergic psychostimulants.\n\nCaffeine also causes the release of dopamine in the dorsal striatum and nucleus accumbens core (a substructure within the ventral striatum), but not the nucleus accumbens shell, by antagonizing A receptors in the axon terminal of dopamine neurons and A–A heterodimers (a receptor complex composed of 1 adenosine A receptor and 1 adenosine A receptor) in the axon terminal of glutamate neurons. During chronic caffeine use, caffeine-induced dopamine release within the nucleus accumbens core is markedly reduced due to drug tolerance.\n\nCaffeine, like other xanthines, also acts as a phosphodiesterase inhibitor. As a competitive nonselective phosphodiesterase inhibitor, caffeine raises intracellular cAMP, activates protein kinase A, inhibits TNF-alpha and leukotriene synthesis, and reduces inflammation and innate immunity. Caffeine also affects the cholinergic system where it inhibits the enzyme acetylcholinesterase.\n\nCaffeine antagonizes adenosine A2A receptors in the ventrolateral preoptic area (VLPO), thereby reducing inhibitory GABA neurotransmission to the tuberomammillary nucleus, a histaminergic projection nucleus that activation-dependently promotes arousal. Disinhibition of the tuberomammillary nucleus is the chief mechanism by which caffeine produces wakefulness-promoting effects.\n\nCaffeine from coffee or other beverages is absorbed by the small intestine within 45 minutes of ingestion and distributed throughout all bodily tissues. Peak blood concentration is reached within 1–2 hours. It is eliminated by first-order kinetics. Caffeine can also be absorbed rectally, evidenced by suppositories of ergotamine tartrate and caffeine (for the relief of migraine) and chlorobutanol and caffeine (for the treatment of hyperemesis). However, rectal absorption is less efficient than oral: the maximum concentration (C) and total amount absorbed (AUC) are both about 30% (i.e. 1/3.5) of the oral amounts.\n\nCaffeine's biological half-life – the time required for the body to eliminate one-half of a dose – varies widely among individuals according to factors such as pregnancy, other drugs, liver enzyme function level (needed for caffeine metabolism) and age. In healthy adults, caffeine's half-life is between 3–7 hours. Smoking decreases the half-life by 30–50%, while oral contraceptives can double it and pregnancy can raise it to as much as 15 hours during the last trimester. In newborns the half-life can be 80 hours or more, dropping very rapidly with age, possibly to less than the adult value by age 6 months. The antidepressant fluvoxamine (Luvox) reduces the clearance of caffeine by more than 90%, and increases its elimination half-life more than tenfold; from 4.9 hours to 56 hours.\n\nCaffeine is metabolized in the liver by the cytochrome P450 oxidase enzyme system, in particular, by the CYP1A2 isozyme, into three dimethylxanthines, each of which has its own effects on the body:\n\n1,3,7-Trimethyluric acid is a minor caffeine metabolite. Each of these metabolites is further metabolized and then excreted in the urine. Caffeine can accumulate in individuals with severe liver disease, increasing its half-life.\n\nA 2011 review found that increased caffeine intake was associated with a variation in two genes that increase the rate of caffeine catabolism. Subjects who had this mutation on both chromosomes consumed 40 mg more caffeine per day than others. This is presumably due to the need for a higher intake to achieve a comparable desired effect, not that the gene led to a disposition for greater incentive of habituation.\n\nPure anhydrous caffeine is a bitter-tasting white odorless powder with a melting point of 235–238 °C. Caffeine is moderately soluble in water at room temperature (2 g/100 mL), but very soluble in boiling water (66 g/100 mL). It is also moderately soluble in ethanol (1.5 g/100 mL). It is weakly basic (pK of conjugate base = ~0.6) requiring strong acid to protonate it. Caffeine does not contain any stereogenic centers and hence is classified as an achiral molecule.\n\nThe xanthine core of caffeine contains two fused rings, a pyrimidinedione and imidazole. The pyrimidinedione in turn contains two amide functional groups that exist predominately in a zwitterionic resonance the location from which the nitrogen atoms are double bonded to their adjacent amide carbons atoms. Hence all six of the atoms within the pyrimidinedione ring system are sp hybridized and planar. Therefore, the fused 5,6 ring core of caffeine contains a total of ten pi electrons and hence according to Hückel's rule is aromatic.\n\nThe biosynthesis of caffeine is an example of convergent evolution among different species.\n\nCaffeine may be synthesized in the lab starting with dimethylurea and malonic acid.\n\nCommercial supplies of caffeine are not usually manufactured synthetically because the chemical it is readily available as a byproduct of decaffeination.\n\nExtraction of caffeine from coffee, to produce caffeine and decaffeinated coffee, can be performed using a number of solvents. Benzene, chloroform, trichloroethylene, and dichloromethane have all been used over the years but for reasons of safety, environmental impact, cost, and flavor, they have been superseded by the following main methods:\n\n\"Decaffeinated\" coffees do in fact contain caffeine in many cases – some commercially available decaffeinated coffee products contain considerable levels. One study found that decaffeinated coffee contained 10 mg of caffeine per cup, compared to approximately 85 mg of caffeine per cup for regular coffee.\n\nCaffeine can be quantified in blood, plasma, or serum to monitor therapy in neonates, confirm a diagnosis of poisoning, or facilitate a medicolegal death investigation. Plasma caffeine levels are usually in the range of 2–10 mg/L in coffee drinkers, 12–36 mg/L in neonates receiving treatment for apnea, and 40–400 mg/L in victims of acute overdosage. Urinary caffeine concentration is frequently measured in competitive sports programs, for which a level in excess of 15 mg/L is usually considered to represent abuse.\n\nSome analog substances have been created which mimic caffeine's properties with either function or structure or both. Of the latter group are the xanthines DMPX and 8-chlorotheophylline, which is an ingredient in dramamine. Members of a class of nitrogen substituted xanthines are often proposed as potential alternatives to caffeine. Many other xanthine analogues constituting the adenosine receptor antagonist class have also been elucidated.\n\nSome other caffeine analogs:\n\nAround sixty plant species are known to contain caffeine. Common sources are the \"beans\" (seeds) of the two cultivated coffee plants, \"Coffea arabica\" and \"C. canephora\" (the quantity varies, but 1.3% is a typical value); in the leaves of the tea bush; and in kola nuts. Other sources include yaupon holly leaves, South American holly yerba mate leaves, seeds from Amazonian maple guarana berries, and Amazonian holly guayusa leaves. Temperate climates around the world have produced unrelated caffeine containing plants.\n\nCaffeine in plants acts as a natural pesticide: it can paralyze and kill predator insects feeding on the plant. High caffeine levels are found in coffee seedlings when they are developing foliage and lack mechanical protection. In addition, high caffeine levels are found in the surrounding soil of coffee seedlings, which inhibits seed germination of nearby coffee seedlings, thus giving seedlings with the highest caffeine levels fewer competitors for existing resources for survival. Caffeine is stored in tea leaves in two places. Firstly, in the cell vacuoles where it is complexed with polyphenols. This caffeine probably is released into the mouth parts of insects, to discourage herbivory. Secondly, around the vascular bundles, where it probably inhibits pathogenic fungi from entering and colonizing the vascular bundles. Caffeine in nectar may improve the reproductive success of the pollen producing plants by enhancing the reward memory of pollinators such as honeybees.\n\nThe differing perceptions in the effects of ingesting beverages made from various plants containing caffeine could be explained by the fact that these beverages also contain varying mixtures of other methylxanthine alkaloids, including the cardiac stimulants theophylline and theobromine, and polyphenols that can form insoluble complexes with caffeine.\n\nProducts containing caffeine are coffee, tea, soft drinks (\"colas\"), energy drinks, other beverages, chocolate, caffeine tablets, other oral products, and inhalation.\n\nThe world's primary source of caffeine is the coffee \"bean\" (the seed of the coffee plant), from which coffee is brewed. Caffeine content in coffee varies widely depending on the type of coffee bean and the method of preparation used; even beans within a given bush can show variations in concentration. In general, one serving of coffee ranges from 80 to 100 milligrams, for a single shot (30 milliliters) of arabica-variety espresso, to approximately 100–125 milligrams for a cup (120 milliliters) of drip coffee. \"Arabica\" coffee typically contains half the caffeine of the \"robusta\" variety.\nIn general, dark-roast coffee has very slightly less caffeine than lighter roasts because the roasting process reduces caffeine content of the bean by a small amount.\n\nTea contains more caffeine than coffee by dry weight. A typical serving, however, contains much less, since tea is normally brewed more weakly than coffee. Also contributing to caffeine content are growing conditions, processing techniques, and other variables. Thus, teas contain varying amounts of caffeine.\n\nTea contains small amounts of theobromine and slightly higher levels of theophylline than coffee. Preparation and many other factors have a significant impact on tea, and color is a very poor indicator of caffeine content. Teas like the pale Japanese green tea, \"gyokuro\", for example, contain far more caffeine than much darker teas like \"lapsang souchong\", which has very little.\n\nCaffeine is also a common ingredient of soft drinks, such as cola, originally prepared from kola nuts. Soft drinks typically contain 0 to 55 milligrams of caffeine per 12 ounce serving. By contrast, energy drinks, such as Red Bull, can start at 80 milligrams of caffeine per serving. The caffeine in these drinks either originates from the ingredients used or is an additive derived from the product of decaffeination or from chemical synthesis. Guarana, a prime ingredient of energy drinks, contains large amounts of caffeine with small amounts of theobromine and theophylline in a naturally occurring slow-release excipient.\n\n\nChocolate derived from cocoa beans contains a small amount of caffeine. The weak stimulant effect of chocolate may be due to a combination of theobromine and theophylline, as well as caffeine. A typical 28-gram serving of a milk chocolate bar has about as much caffeine as a cup of decaffeinated coffee. By weight, dark chocolate has one to two times the amount of caffeine as coffee: 80–160 mg per 100 g.\n\nTablets offer the advantages over coffee and tea of convenience, known dosage, and avoiding concomitant sugar, acid and fluid intake. Manufacturers of caffeine tablets claim that using caffeine of pharmaceutical quality improves mental alertness. These tablets are commonly used by students studying for their exams and by people who work or drive for long hours.\n\nOne U.S. company is marketing oral dissolvable caffeine strips. Another intake route is SpazzStick, a caffeinated lip balm. Alert Energy Caffeine Gum was introduced in the United States in 2013, but was voluntarily withdrawn after an announcement of an investigation by the FDA of the health effects of added caffeine in foods.\n\nThere are several products being marketed that offer inhalers that deliver proprietary blends of supplements, with caffeine being a key ingredient. In 2012, the FDA sent a warning letter to one of the companies marketing these inhalers, expressing concerns for the lack of safety information available about inhaled caffeine.\n\n\nAccording to Chinese legend, the Chinese emperor Shennong, reputed to have reigned in about 3000 BCE, accidentally discovered tea when he noted that when certain leaves fell into boiling water, a fragrant and restorative drink resulted. Shennong is also mentioned in Lu Yu's \"Cha Jing\", a famous early work on the subject of tea.\n\nThe earliest credible evidence of either coffee drinking or knowledge of the coffee tree appears in the middle of the fifteenth century, in the Sufi monasteries of the Yemenin southern Arabia. From Mocha, coffee spread to Egypt and North Africa, and by the 16th century, it had reached the rest of the Middle East, Persia and Turkey. From the Middle East, coffee drinking spread to Italy, then to the rest of Europe, and coffee plants were transported by the Dutch to the East Indies and to the Americas.\n\nKola nut use appears to have ancient origins. It is chewed in many West African cultures, individually or in a social setting, to restore vitality and ease hunger pangs.\n\nThe earliest evidence of cocoa bean use comes from residue found in an ancient Mayan pot dated to 600 BCE. Also, chocolate was consumed in a bitter and spicy drink called \"xocolatl\", often seasoned with vanilla, chile pepper, and achiote. \"Xocolatl\" was believed to fight fatigue, a belief probably attributable to the theobromine and caffeine content. Chocolate was an important luxury good throughout pre-Columbian Mesoamerica, and cocoa beans were often used as currency.\n\n\"Xocolatl\" was introduced to Europe by the Spaniards, and became a popular beverage by 1700. The Spaniards also introduced the cacao tree into the West Indies and the Philippines. It was used in alchemical processes, where it was known as \"black bean\".\n\nThe leaves and stems of the yaupon holly (\"Ilex vomitoria\") were used by Native Americans to brew a tea called \"asi\" or the \"black drink\". Archaeologists have found evidence of this use far into antiquity, possibly dating to Late Archaic times.\n\nIn 1819, the German chemist Friedlieb Ferdinand Runge isolated relatively pure caffeine for the first time; he called it \"\"Kaffebase\"\" (i.e. a base that exists in coffee). According to Runge, he did this at the behest of Johann Wolfgang von Goethe. In 1821, caffeine was isolated both by the French chemist Pierre Jean Robiquet and by another pair of French chemists, Pierre-Joseph Pelletier and Joseph Bienaimé Caventou, according to Swedish chemist Jöns Jacob Berzelius in his yearly journal. Furthermore, Berzelius stated that the French chemists had made their discoveries independently of any knowledge of Runge's or each other's work. However, Berzelius later acknowledged Runge's priority in the extraction of caffeine, stating: \"However, at this point, it should not remain unmentioned that Runge (in his \"Phytochemical Discoveries\", 1820, pages 146–147) specified the same method and described caffeine under the name \"Caffeebase\" a year earlier than Robiquet, to whom the discovery of this substance is usually attributed, having made the first oral announcement about it at a meeting of the Pharmacy Society in Paris.\"\n\nPelletier's article on caffeine was the first to use the term in print (in the French form \"Caféine\" from the French word for coffee: \"café\"). It corroborates Berzelius's account:\n\nRobiquet was one of the first to isolate and describe the properties of pure caffeine, whereas Pelletier was the first to perform an elemental analysis.\n\nIn 1827, M. Oudry isolated \"théine\" from tea, but it was later proved by Mulder and by Carl Jobst that theine was actually caffeine.\n\nIn 1895, German chemist Hermann Emil Fischer (1852–1919) first synthesized caffeine from its chemical components (i.e. a \"total synthesis\"), and two years later, he also derived the structural formula of the compound. This was part of the work for which Fischer was awarded the Nobel Prize in 1902.\n\nBecause it was recognized that coffee contained some compound that acted as a stimulant, first coffee and later also caffeine has sometimes been subject to regulation. For example, in the 16th century Islamists in Mecca and in the Ottoman Empire made coffee illegal for some classes. Charles II of England tried to ban it in 1676, Frederick II of Prussia banned it in 1777, and coffee was banned in Sweden at various times between 1756 and 1823.\n\nIn 1911, caffeine became the focus of one of the earliest documented health scares, when the US government seized 40 barrels and 20 kegs of Coca-Cola syrup in Chattanooga, Tennessee, alleging the caffeine in its drink was \"injurious to health\". Although the judge ruled in favor of Coca-Cola, two bills were introduced to the U.S. House of Representatives in 1912 to amend the Pure Food and Drug Act, adding caffeine to the list of \"habit-forming\" and \"deleterious\" substances, which must be listed on a product's label.\n\nThe Food and Drug Administration (FDA) in the United States currently allows only beverages containing less than 0.02% caffeine; but caffeine powder, which is sold as a dietary supplement, is unregulated. It is a regulatory requirement that the label of most prepackaged foods must declare a list of ingredients, including food additives such as caffeine, in descending order of proportion. However, there is no regulatory provision for mandatory quantitative labeling of caffeine, (e.g., milligrams caffeine per stated serving size). There are a number of food ingredients that naturally contain caffeine. These ingredients must appear in food ingredient lists. However, as is the case for \"food additive caffeine\", there is no requirement to identify the quantitative amount of caffeine in composite foods containing ingredients that are natural sources of caffeine. While coffee or chocolate are broadly recognized as caffeine sources, some ingredients (e.g. guarana, yerba maté) are likely less recognized as caffeine sources. For these natural sources of caffeine, there is no regulatory provision requiring that a food label identify the presence of caffeine nor state the amount of caffeine present in the food.\n\nGlobal consumption of caffeine has been estimated at 120,000 tonnes per year, making it the world's most popular psychoactive substance. This amounts to one serving of a caffeinated beverage for every person every day.\n\nSome Seventh-day Adventists, Church of God (Restoration) adherents, and Christian Scientists do not consume caffeine. Some from these religions believe that one is not supposed to consume a non-medical, psychoactive substance, or believe that one is not supposed to consume a substance that is addictive. The Church of Jesus Christ of Latter-day Saints has said the following with regard to caffeinated beverages: \" . . . the Church revelation spelling out health practices (Doctrine and Covenants 89) does not mention the use of caffeine. The Church's health guidelines prohibit alcoholic drinks, smoking or chewing of tobacco, and 'hot drinks' – taught by Church leaders to refer specifically to tea and coffee.\"\n\nGaudiya Vaishnavas generally also abstain from caffeine, because they believe it clouds the mind and over-stimulates the senses. To be initiated under a guru, one must have had no caffeine, alcohol, nicotine or other drugs, for at least a year.\n\nCaffeinated beverages are widely consumed by Muslims today. In the 16th century, some Muslim authorities made unsuccessful attempts to ban them as forbidden \"intoxicating beverages\" under Islamic dietary laws.\n\nRecently discovered bacteria \"Pseudomonas putida\" CBB5 can live on pure caffeine, and can cleave caffeine into carbon dioxide and ammonia.\n\nCaffeine is toxic to birds and to dogs and cats, and has a pronounced adverse effect on mollusks, various insects, and spiders. This is at least partly due to a poor ability to metabolize the compound, causing higher levels for a given dose per unit weight. Caffeine has also been found to enhance the reward memory of honeybees.\n\nCaffeine has been used to double chromosomes in haploid wheat.\n\n\n\n"}
{"id": "6874", "url": "https://en.wikipedia.org/wiki?curid=6874", "title": "Cyc", "text": "Cyc\n\nCyc () is an artificial intelligence project that attempts to assemble a comprehensive ontology and knowledge base of everyday common sense knowledge, with the goal of enabling AI applications to perform human-like reasoning.\n\nThe project was started in 1984 by Douglas Lenat at MCC and is developed by the Cycorp company.\nParts of the project are released as OpenCyc, which provides an API, RDF endpoint, and data dump under an open source license.\n\nThe project was started in 1984 as part of (former Central Intelligence Agency deputy director) Bobby Ray Inman's US Government sponsored Microelectronics and Computer Technology Corporation in order \"to counter a then ominous Japanese effort in AI, the \"fifth-generation\" project.\"\n\nThe objective was to codify, in machine-usable form, millions of pieces of knowledge that compose human common sense. CycL presented a proprietary knowledge representation schema that utilized first-order relationships. In 1986, Doug Lenat estimated the effort to complete Cyc would be 250,000 rules and 350 man-years of effort. \nThe Cyc Project was spun off into Cycorp, Inc. in Austin, Texas in 1994.\n\nThe name \"Cyc\" (from \"encyclopedia\", pronounced like \"syke\") is a registered trademark owned by Cycorp. The original knowledge base is proprietary, but a smaller version of the knowledge base, intended to establish a common vocabulary for automatic reasoning, was released as OpenCyc under an open source (Apache) license. More recently, Cyc has been made available to AI researchers under a research-purposes license as ResearchCyc.\n\nTypical pieces of knowledge represented in the database are \"Every tree is a plant\" and \"Plants die eventually\". When asked whether trees die, the inference engine can draw the obvious conclusion and answer the question correctly. The Knowledge Base (KB) contains over one million human-defined assertions, rules or common sense ideas. These are formulated in the language CycL, which is based on predicate calculus and has a syntax similar to that of the Lisp programming language.\n\nMuch of the current work on the Cyc project continues to be knowledge engineering, representing facts about the world by hand, and implementing efficient inference mechanisms on that knowledge. Increasingly, however, work at Cycorp involves giving the Cyc system the ability to communicate with end users in natural language, and to assist with the knowledge formation process via machine learning.\n\nLike many companies, Cycorp has ambitions to use Cyc's natural language processing to parse the entire internet to extract structured data.\n\nIn 2008, Cyc resources were mapped to many Wikipedia articles, potentially easing connecting with other open datasets like DBpedia and Freebase.\n\nThe concept names in Cyc are known as \"constants\". Constants start with an optional \"#$\" and are case-sensitive. There are constants for:\n\nThe most important predicates are #$isa and #$genls. The first one describes that one item is an instance of some collection, the second one that one collection is a subcollection of another one. Facts about concepts are asserted using certain CycL \"sentences\". Predicates are written before their arguments, in parentheses:\n\"Bill Clinton belongs to the collection of U.S. presidents\" and\n\"All trees are plants\".\n\"Paris is the capital of France.\"\n\nSentences can also contain variables, strings starting with \"?\". These sentences are called \"rules\". One important rule asserted about the #$isa predicate reads\nwith the interpretation \"if OBJ is an instance of the collection SUBSET and SUBSET is a subcollection of SUPERSET, then OBJ is an instance of the collection SUPERSET\". Another typical example is\nwhich means that for every instance of the collection #$ChordataPhylum (i.e. for every chordate), there exists a female animal (instance of #$FemaleAnimal) which is its mother (described by the predicate #$biologicalMother).\n\nThe knowledge base is divided into \"microtheories\" (Mt), collections of concepts and facts typically pertaining to one particular realm of knowledge. Unlike the knowledge base as a whole, each microtheory is required to be free from contradictions. Each microtheory has a name which is a regular constant; microtheory constants contain the string \"Mt\" by convention. An example is #$MathMt, the microtheory containing mathematical knowledge. The microtheories can inherit from each other and are organized in a hierarchy:\none specialization of #$MathMt is #$GeometryGMt, the microtheory about geometry.\n\nAn inference engine is a computer program that tries to derive answers from a knowledge base.\nThe Cyc inference engine performs general logical deduction (including modus ponens, modus tollens, universal quantification and existential quantification).\n\nThe latest version of OpenCyc, 4.0, was released in June 2012. OpenCyc 4.0 includes the entire Cyc ontology containing hundreds of thousands of terms, along with millions of assertions relating the terms to each other; however, these are mainly taxonomic assertions, not the complex rules available in Cyc. The knowledge base contains 239,000 concepts and 2,093,000 facts and can be browsed on the OpenCyc website.\n\nAs of 2017, OpenCyc is no longer available.\n\nThe first version of OpenCyc was released in spring 2002 and contained only 6,000 concepts and 60,000 facts. The knowledge base is released under the Apache License. Cycorp has stated its intention to release OpenCyc under parallel, unrestricted licences to meet the needs of its users. The CycL and SubL interpreter (the program that allows you to browse and edit the database as well as to draw inferences) is released free of charge, but only as a binary, without source code. It is available for Linux and Microsoft Windows. The open source Texai project has released the RDF-compatible content extracted from OpenCyc.\n\nIn July 2006, Cycorp released the executable of ResearchCyc 1.0, a version of Cyc aimed at the research community, at no charge. (ResearchCyc was in beta stage of development during all of 2004; a beta version was released in February 2005.) In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes significantly more semantic knowledge (i.e., additional facts) about the concepts in its knowledge base, and includes a large lexicon, English parsing and generation tools, and Java based interfaces for knowledge editing and querying. In addition it contains a system for Ontology-based data integration.\n\nThe comprehensive Terrorism Knowledge Base is an application of Cyc in development that will try to ultimately contain all relevant knowledge about \"terrorist\" groups, their members, leaders, ideology, founders, sponsors, affiliations, facilities, locations, finances, capabilities, intentions, behaviors, tactics, and full descriptions of specific terrorist events. The knowledge is stored as statements in mathematical logic, suitable for computer understanding and reasoning.\n\nCyclopedia is being developed; it superimposes Cyc keywords on pages taken from Wikipedia pages.\n\nThe Cleveland Clinic has used Cyc to develop a natural language query interface of biomedical information.\nThe query is parsed into a set of CycL (higher-order logic) fragments with open variables, then after applying various constraints (medical domain knowledge, common sense, discourse pragmatics, syntax), there is a way to fit those fragments together, one semantically meaningful formal query.\n\nThe Cyc project has been described as \"one of the most controversial endeavors of the artificial intelligence history\". Criticism includes:\n\nMachine-learning scientist Pedro Domingos refers to the project as a \"catastrophic failure\" for several reasons, including the unending amount of data required to produce any viable results and the inability for Cyc to evolve on its own.\n\nThis is a list of notable people who work or have worked on Cyc either as employees of MCC (where Cyc was first started) or Cycorp.\n\n\n"}
{"id": "6876", "url": "https://en.wikipedia.org/wiki?curid=6876", "title": "CE", "text": "CE\n\nCE, Ce or ce may refer to:\n\n\n\n\n\n\n\n\n\n"}
{"id": "6878", "url": "https://en.wikipedia.org/wiki?curid=6878", "title": "Carlos Valderrama", "text": "Carlos Valderrama\n\nCarlos Alberto Valderrama Palacio (; born 2 September 1961 in Santa Marta, Colombia), also known as \"El Pibe\" (\"The Kid\"), is a Colombian former footballer who played as a midfielder. A creative playmaker, known for his precise passing, technical skills, and elegance on the ball, he is regarded as one of the best Colombian and South American footballers of all time, and by some as Colombia's greatest player ever; his distinctive hairstyle, as well as talent and skilful playing style made him one of South America's elite and most recognisable footballers in the late 1980s and early 1990s. He won the South American Footballer of the Year award in 1987 and 1993, and in 1999, he was also named one of the top 100 players of the 20th century by World Soccer. In 2004, he was included in the FIFA 100, a list of the 125 \"greatest living footballers\" chosen by Pelé to celebrate the 100th anniversary of FIFA.\n\nValderrama was a member of the Colombia national football team from 1985 until 1998. He represented Colombia in 111 full internationals and scored 11 times, making him the most capped player in the country's history. He played a major role during the golden era of Colombian football in the 1990s, representing his national side in three FIFA World Cups and five Copa América tournaments.\n\nAfter spending most of his career playing club football in South America and Europe, towards the end of his career Valderrama played in Major League Soccer, joining the league in its first season. One of the most recognisable players in the league at the time of its inception, he helped popularise the league during the second half of the 1990s. To this day, he is an icon and is considered one of the most decorated players to ever play in MLS; in 2005, he was named to the MLS All-Time Best XI.\n\nValderrama began his career at Unión Magdalena of the Colombian First Division in 1981. He also later played for Millonarios in 1984, and joined Deportivo Cali in 1985, before moving to the French First Division side Montpellier, in 1988; despite initially struggling to adapt to the less technical and the faster, more physical, and tactical brand of football being played in Europe, which initially saw him lose his place in the squad, his passing ability later saw him become the club's main creative force, and he played a decisive role as his side won the French Cup in 1990. In 1991, he remained in Europe and joined Spanish side Real Valladolid for a season. He then returned to Colombia in 1992 and went on to play for Independiente Medellín, and subsequently Atlético Junior in 1993, with whom he won the Colombian championship in 1993 and 1995.\n\nValderrama began his Major League Soccer career with the US side Tampa Bay Mutiny in the league's inaugural year of 1996, and won its ever first Supporters' Shield and Most Valuable Player award, finishing the season with 4 goals and 17 assists. He remained with the club for the 1997 season, and also spent a spell on loan back at Deportivo Cali in Colombia, before moving to another MLS side, Miami Fusion, in 1998, where he also remained for two seasons. He returned to Tampa Bay in 2000, spending two more seasons with the club; while a member of the Mutiny, the team would sell Carlos Valderrama wigs at Tampa Stadium. In the 2000 MLS season, Valderrama recorded the only 20+ assist season in MLS history—ending the season with 26 — a single season assist record that remains intact to this day, and which MLS itself suggested was an \"unbreakable\" record in a 2012 article. In 2001, Valderrama joined the Colorado Rapids, and remained with the team until 2002, when he retired; his American soccer league career spanned a total of eight years, during which he made 175 appearances. In the MLS, Valderrama scored relatively few goals (16) for a midfielder, but is the league's second all-time leader in assists (114) after Steve Ralston (121), a former teammate. In 2005, he was named to the MLS All-Time Best XI.\n\nValderrama was a member of the Colombia national football team from 1985 until 1998; he made 111 international appearances, scoring 11 goals, making him the most capped player in the country's history. He represented and captained his national side in the 1990, 1994, and \n1998 FIFA World Cups, and also took part in the 1987, 1989, 1991, 1993, and 1995 Copa América tournaments.\n\nValderrama made his international debut on 27 October 1985, in a 3–0 defeat to Paraguay in a 1986 World Cup qualifying match, at the age of 24. In his first major international tournament, he helped Colombia to a third-place finish at the 1987 Copa América in Argentina, as his team's captain, where he was named the tournament's best player; during the tournament he scored the opening goal in Colombia's 2–0 over Bolivia on 1 July, their first match of the group stage.\n\nSome of Valderrama's most impressive international performances came during the 1990 FIFA World Cup in Italy, during which he served as Colombia's captain. He helped his team to a 2–0 win against the UAE in Colombia's opening match of the group stage, scoring the second goal of the match with a strike from 20 yards. Colombia lost their second match against Yugoslavia, however,\nneeding at least a draw against the eventual champions West Germany in their final group match in order to advance to the next round of the competition. In the decisive game, German striker Pierre Littbarski scored what appeared to be the winning goal in the 88th minute of the game; however, within the last minute of injury time, Valderrama beat several opposing players and made a crucial left-footed pass to Freddy Rincon, who subsequently equalised, sealing a place for Colombia in the second round of the tournament with a 1–1 draw. Colombia were eliminated in the round of 16, following a 2–1 extra time loss to Cameroon.\n\nOn 5 September 1993, Valderrama contributed to Colombia's historic 5–0 victory over South American rivals Argentina at the \"Monumental\" in Buenos Aires, which allowed them to qualify for the 1994 World Cup. Although much was expected of Valderrama at the World Cup, an injury during a pre-tournament warm-up game put his place in the squad in jeopardy; although he was able to regain match fitness in time for the tournament, Colombia disappointed and suffered a first round elimination following defeats to Romania and the hosts USA.\n\nFour years later, Valderrama led his nation to qualify for the 1998 World Cup in France, scoring three goals during the qualifying stages. His impact in the final tournament at the advancing age of 37, however, was less decisive, and, despite defeating Tunisia, Colombia once again suffered a first round exit, following a 2–0 defeat against England, which was Valderrama's final international appearance.\n\nAlthough Valderrama is often defined as a 'classic number 10 playmaker', due to his creativity and offensive contribution, in reality he was not a classic playmaker in the traditional sense; although he often wore the number 10 shirt throughout his career and was deployed as an attacking midfielder at times, he played mostly in deeper positions in the centre of the pitch, often operating as a deep-lying playmaker, rather than in more advanced midfield positions behind the forwards, in order to have a greater influence on the game. A team-player, Valderrama was also known to be an extremely selfless midfielder, who preferred assisting his teammates over going for goal himself; his tactical intelligence, positioning, efficient movement and versatile range of passing enabled him to both set the tempo of his team in midfield with short, first time exchanges, or create chances with long lobbed passes or through balls.\n\nValderrama's most instantly recognisable physical features were his big afro-blonde hairstyle, jewelry, and moustache, but he was best known for his grace and elegance on the ball, as well as his agility, and quick feet as a footballer. His control, dribbling ability and footwork were similar to those of smaller players, which for a player of Valderrama's size and physical build was fairly uncommon, and he frequently stood out throughout his career for his ability to use his strength, balance, composure, and flamboyant technique to shield the ball from opponents when put under pressure, and retain possession in difficult situations, which made him extremely popular with the fans. Valderrama's mix of physical strength, two-footed ability, unpredictability and flair enabled him to produce key and incisive performances against top tier teams, while his world class vision and exceptional passing and crossing ability with his right foot made him one of the best assist providers of his time; his height, physique and elevation also made him effective in the air, and he was also an accurate free kick taker and striker of the ball, despite not being a particularly prolific goalscorer.\n\nDespite his natural talent and ability as a footballer, Valderrama earned a reputation for having a \"languid\" playing style, as well as lacking notable pace, being unfit, and for having a poor defensive work-rate on the pitch, in particular after succumbing to the physical effects of ageing in his later career in the MLS. In his first season in France, he also initially struggled to adapt to the faster-paced, more physical and tactically rigorous European brand of football, which saw him play in an unfamiliar position, and gave him less space and time on the ball to dictate attacking passing moves; he was criticised at times for his lack of match fitness and his low defensive contribution, which initially limited his appearances with the club, although he later successfully became a key creative player in his team's starting line-up due to his discipline, skill, and his precise and efficient passing. Despite these claims, earlier in his career, however, Valderrama demonstrated substantial pace, stamina, and defensive competence.\n\nFormer French defender Laurent Blanc, who played with Valderrama in Montpellier, voiced one of the most accurate descriptions for Valderrama, \"In the fast and furious European game he wasn't always at his ease. He was a natural exponent of 'toque', keeping the ball moving. But he was so gifted that we could give him the ball when we didn't know what else to do with it knowing he wouldn’t lose it... and often he would do things that most of us only dream about.\"\n\nIn February 2004, Valderrama ended his 22-year career in a tribute match at the Metropolitan stadium of Barranquilla, with some of the most important football players of South America, such as Diego Maradona, Enzo Francescoli and José Luis Chilavert.\n\nSince retiring from professional football, Valderrama has become assistant manager of Atlético Junior. On November 1, 2007, Valderrama accused a referee of corruption by waving cash in the face of Oscar Julian Ruiz when the official awarded a penalty to América de Cali. Junior lost the match 4–1, which ended the club's hopes of playoff qualification.\n\nIn 2006, a 22-foot bronze statue of Valderrama, created by Colombian artist Amilkar Ariza, was erected outside Estadio Eduardo Santos in Valderrama's birthplace of Santa Marta.\n\nValderrama is married and has five children. Valderrama was the only Colombian to feature in FIFA's 125 Top Living Football Players list in March 2004. He is currently a coach for a football academy called Clearwater Galactics sometimes in Clearwater, Florida.\n\nValderrama appeared on the cover of Konami's \"International Superstar Soccer Pro 98\". In the Nintendo 64 version of the game, he is referred to by his nickname, \"El Pibe\".\n\nValderrama has also appeared in EA Sports' FIFA football video game series; he was named one of the Ultimate Team Legend cards in \"FIFA 15\".\n\n\"Scores and results lists Colombia's goal tally first.\"\n\n\n\n\n\n"}
{"id": "6879", "url": "https://en.wikipedia.org/wiki?curid=6879", "title": "Cyborgs in fiction", "text": "Cyborgs in fiction\n\nCyborgs are a prominent staple in the science fiction genre. This article summarizes notable instances of cyborgs in fiction.\n\n\"Night of the Steel Assassin\" is a January 1966 episode of \"The Wild Wild West\" TV series. \"Iron Man\" Torres, played by John Dehner- the world's first cyborg, plans to assassinate President Grant in New Mexico.\n\nIn 1966, Kit Pedler, a medical scientist, created the Cybermen for the TV program \"Doctor Who\", based on his concerns about science changing and threatening humanity. The Cybermen had replaced much of their bodies with mechanical prostheses and were now supposedly emotionless creatures driven only by logic.\n\nIsaac Asimov's short story \"The Bicentennial Man\" explored cybernetic concepts. The central character is NDR, a robot who begins to modify himself with organic components. His explorations lead to breakthroughs in human medicine \"via\" artificial organs and prosthetics. By the end of the story, there is little physical difference between the body of the hero, now called Andrew, and humans equipped with advanced prosthetics, save for the presence of Andrew's artificial positronic brain. Asimov also explored the idea of the cyborg in relation to robots in his short story \"Segregationist\", collected in \"The Complete Robot\".\n\nThe 1972 science fiction novel \"Cyborg\", by Martin Caidin, told the story of a man whose damaged body parts are replaced by mechanical devices (\"bionics\"). This novel was adapted into a TV series, \"The Six Million Dollar Man\", in 1973, and a spin-off, \"The Bionic Woman\" in 1976. Caidin also addressed bionics in his 1968 novel, \"The God Machine\".\n\nIn 1974, Marvel Comics writer Rich Buckler introduced the cyborg Deathlok the Demolisher, and a dystopian post-apocalyptic future, in \"Astonishing Tales\" No. 25. Buckler's character dealt with rebellion and loyalty, with allusion to Frankenstein's monster, in a twelve-issue run. Deathlok was later resurrected in \"Captain America\", followed by two others in 1990 and 1999.\n\nIn the novel Man Plus by Frederick Pohl, an able-bodied astronaut, Roger Torraway, is surgically altered in order to augment his fragile human body and allow him to function in the harsh climate of Mars. The result is both \"monstrous\" (he has bat-like wings, infrared sight, an enhanced brain capable of processing all the new sensory inputs) and \"freeing\" (his cyborg body is more \"naturally\" made for Mars, as opposed to his all-human colleagues on the Mars mission). Torraway's cyborg character is reprised in a 1995 sequel, Mars Plus.\n\nThe 1982 film \"Blade Runner\" featured creatures called replicants, bio-engineered or bio-robotic beings. The Nexus series—genetically designed by the Tyrell Corporation—are virtually identical to an adult human, but have superior strength, agility, and variable intelligence depending on the model. Because of their physical similarity to humans a replicant must be detected by its lack of emotional responses and empathy to questions posed in a Voight-Kampff test. A derogatory term for a replicant is \"skin-job,\" a term heard again extensively in \"Battlestar Galactica\". In the opening crawl of the film, they are first said to be the next generation in robotics. The crawl also states genetics play some role in the creation of replicants. The original novel makes mention of the biological components of the androids, but also alludes to the mechanical aspects commonly found in other material relating to robots.\n\nThe 1987 science fiction action film \"RoboCop\" features a cyborg protagonist. After being killed by a criminal gang, police officer Alex Murphy is transformed by a private company into a cyborg cop. The transformation is used to explore the theme of resurrection and identity. There are cyborg \"kaiju\" in the Godzilla films such as Gigan and Mechagodzilla.\n\nAlthough frequently referred to onscreen as a cyborg, Terminators might be more properly an android. While it has skin and blood (cellular organic systems), these serve mainly as a disguise and are not symbiotic with the machine components, a trait of true cyborgs. The endoskeletons beneath are fully functional robots and have been seen operating independently, especially during the future segments of the \"Terminator\" movies. The T-1000 (which is said to be made completely of a liquid metal) of \"\" is definitely an android. The Terminator Cameron Phillips seen in the TV series \"\" is of a previously unseen model, and is once again referred to on screen (including once by another Terminator) as a cyborg. \"Terminator Salvation\" introduces Marcus Wright, a death-row convict who donated his body to Cyberdyne Systems, who was later revived as a T-H \"Hybrid Human\" with his original brain and heart placed into an endoskeleton which was then covered by a copy of his original organic tissue.\n\nCyborgs have also been present in real-time strategy video games. The \"Command & Conquer\" video game series had cyborgs as a part of its plot – specifically Cyborgs created by the \"Brotherhood of Nod\" via Tiberium Infusion experimentation. They were frequently used for anti-personnel, though the Cyborg Commando proved to be useful in most situations. Cyborgs were brought back by the AI named LEGION, (a successor to CABAL) under direct orders from Kane. The 'Marked of Kane' units also contain Cyborgs.\n\nThe \"Metal Gear Solid\" series of video games has a recurring character known as Grey Fox or the \"Cyborg Ninja\" who is a person wearing a cybernetic exoskeleton (either worn as a suit or grafted directly to the character's body) and wielding a high-frequency blade.\n\nThe cyborg ninja suit has been donned by multiple characters, most recently by the character Raiden in \"\". He became the newest incarnation of the Cyborg Ninja after he was captured by The Patriots after he stole the body of Big Boss for the Paradise Lost Army. His body was heavily experimented on for the purpose of creating the ultimate soldier and the only remaining organic parts of his original body are his head and spinal cord. His cyborg body is composed of artificial muscle, organs, bones, and blood( a \"white\" artificial blood that the PLA substituted for his old, nanomachine primed blood). His cyborg body was optimized for war and enabled him to fight on a superhuman level and withstand what would normally be considered fatal injuries.\n\nOne of the most famous cyborgs is Darth Vader from the \"Star Wars\" films. Vader was once Anakin Skywalker, a famous Jedi turned to the Dark Side. After a ferocious battle with his former master, Obi-Wan Kenobi, Anakin is left for dead beside a lava flow on Mustafar, and is outfitted with an artificial life support system as well as robotic arms and legs. General Grievous, Lobot, and Luke Skywalker are the three other most prominent cyborgs in the Star Wars universe.\n\nIn Akira Toriyama's \"manga\" and \"anime\" series \"Dragon Ball\", a scientist named Dr. Gero created several cyborgs, including villain Cell, sibling cyborgs Android 17 and Android 18, as well as Android 20, who was built from Gero himself.\n\nA direct brain-to-computer interface is a valuable, but expensive, luxury in Larry Niven and Jerry Pournelle's novel \"Oath of Fealty\".\n\nIn the manga and anime series \"Ghost in the Shell\", the protagonist Motoko Kusanagi is the fully prosthetic leader of an anti-terrorist force, who lives in a future Japan where the majority of adults are cyborgs and can connect wirelessly to the Internet for real-time communication and data research. The most common augmentations in the series are partly artificial brains called cyberbrains.\n\nBruce Sterling in his universe of Shaper/Mechanist suggested an idea of alternative cyborg called Lobster, which is made not by using internal implants, but by using an external shell (\"e.g.\" a Powered Exoskeleton). Unlike human cyborgs that appear human externally while being synthetic internally, a Lobster looks inhuman externally but contains a human internally. The computer game \"\" prominently featured the Omar, where \"Omar\" is a Russian translation of the word \"Lobster\" (since the Omar are of Russian origin in the game).\n\nIn the \"Brain and Brawn\" series of novels series by Anne McCaffrey and others, beginning with \"The Ship Who Sang\", a \"brainship\" is a human body, usually one that could not develop normally, encased in the strongest materials available in that universe, and mentally connected to the controls of a spacecraft. Later novels link the brainship to fully functional humanoid androids.\n\n\n\n\n\n\n\n\n"}
{"id": "6880", "url": "https://en.wikipedia.org/wiki?curid=6880", "title": "Caesar salad", "text": "Caesar salad\n\nA Caesar salad is a salad of romaine lettuce and croutons dressed with parmesan cheese, lemon juice, olive oil, egg, Worcestershire sauce, garlic, and black pepper. It is traditionally prepared tableside.\n\nThe salad's creation is generally attributed to restaurateur Caesar Cardini, an Italian immigrant who operated restaurants in Mexico and the United States. Cardini was living in San Diego but he was also working in Tijuana where he avoided the restrictions of Prohibition. His daughter Rosa (1928–2003) recounted that her father invented the dish when a Fourth of July 1924 rush depleted the kitchen's supplies. Cardini made do with what he had, adding the dramatic flair of the table-side tossing \"by the chef.\" A number of Cardini's staff have said that they invented the dish.\n\nJulia Child said that she had eaten a Caesar salad at Cardini's restaurant when she was a child in the 1920s. In 1946, newspaper columnist Dorothy Kilgallen wrote of a Caesar containing anchovies, differing from Cardini's version:\nThe big food rage in Hollywood—the Caesar salad—will be introduced to New Yorkers by Gilmore's Steak House. It's an intricate concoction that takes ages to prepare and contains (zowie!) lots of garlic, raw or slightly coddled eggs, croutons, romaine, anchovies, parmeasan [\"sic\"] cheese, olive oil, vinegar and plenty of black pepper.\nAccording to Rosa Cardini, the original Caesar salad (unlike his brother Alex's \"Aviator's salad\") did not contain pieces of anchovy; the slight anchovy flavor comes from the Worcestershire sauce. Cardini was opposed to using anchovies in his salad.\n\nIn the 1970s, Cardini's daughter said that the original recipe included whole lettuce leaves, which were meant to be lifted by the stem and eaten with the fingers; coddled eggs; and Italian olive oil.\n\nBottled Caesar dressings are now produced and marketed by many companies.\n\nThe trademark brands, \"Cardini's\", \"Caesar Cardini's\" and \"The Original Caesar Dressing\" are all claimed to date to February 1950, though they were only registered decades later, and more than a dozen varieties of bottled \"Cardini's\" dressing are available today, with various ingredients.\n\nMany variations of the salad exist; for example, by topping a Caesar salad with grilled chicken, steak, or seafood. Certain Mexican restaurants may improvise on items such as substituting tortilla strips for croutons or Cotija cheese for the Parmesan.\n\nCommon ingredients in many recipes:\n\nThere are limitless variations. However, some of the more common are:\n\nThere is inherent risk of infection by salmonella bacteria occasionally found in raw egg from cracked or improperly washed eggshells. This is a concern with many similar dressings that are emulsified with eggs, though generally the pH level is thought to be acidic enough to kill those bacteria. Nevertheless, later versions of the recipe call at least for briefly cooked coddled eggs or pasteurized eggs. Recipes may omit the egg and produce a \"Caesar vinaigrette\". Many variations of this salad exist; yogurt is sometimes substituted for the eggs to maintain a creamy texture and others call for using mayonnaise, oil and vinegar.\n\n\n\n"}
{"id": "6881", "url": "https://en.wikipedia.org/wiki?curid=6881", "title": "Cecilia Beaux", "text": "Cecilia Beaux\n\nCecilia Beaux (May 1, 1855 – September 7, 1942) was an American society portraitist, in the manner of John Singer Sargent. She was a near-contemporary of American artist Mary Cassatt and also received her training in Philadelphia and France. Her sympathetic renderings of the American ruling class made her one of the most successful portrait painters of her era.\n\nEliza Cecilia Beaux was born on May 1, 1855 in Philadelphia, Pennsylvania. She was the youngest daughter of French silk manufacturer Jean Adolphe Beaux and teacher Cecilia Kent Leavitt. Her mother was the daughter of prominent businessman John Wheeler Leavitt of New York City and his wife Cecilia Kent of Suffield, Connecticut. Cecilia Kent Leavitt died from puerperal fever 12 days after giving birth at age 33. Cecilia \"Leilie\" Beaux and her sister Etta were subsequently raised by their maternal grandmother and aunts, primarily in Philadelphia. Her father, unable to bear the grief of his loss, and feeling adrift in a foreign country, returned to his native France for 16 years, with only one visit back to Philadelphia. He returned when Cecilia was two, but left four years later after his business failed. As she confessed later, \"We didn’t love Papa very much, he was so foreign. We thought him \"peculiar\".\" Her father did have a natural aptitude for drawing and the sisters were charmed by his whimsical sketches of animals. Later, Beaux would discover that her French heritage would serve her well during her pilgrimage and training in France.\n\nIn Philadelphia, Beaux's aunt Emily married mining engineer William Foster Biddle, whom Beaux would later describe as \"after my grandmother, the strongest and most beneficent influence in my life.\" For fifty years, he cared for his nieces-in-law with consistent attention and occasional financial support. Her grandmother, on the other hand, provided day-to-day supervision and kindly discipline. Whether with housework, handiwork, or academics, Grandma Leavitt offered a pragmatic framework, stressing that \"everything undertaken must be completed, conquered.\" The Civil War years were particularly challenging, but the extended family survived despite little emotional or financial support from Beaux's father.\n\nAfter the war, Beaux began to spend some time in the household of \"Willie\" and Emily, both proficient musicians. Beaux learned to play the piano but preferred singing. The musical atmosphere later proved an advantage for her artistic ambitions. Beaux recalled, \"They understood perfectly the spirit and necessities of an artist's life.\" In her early teens, she had her first major exposure to art during visits with Willie to the nearby Pennsylvania Academy of the Fine Arts, one of America's foremost art schools and museums. Though fascinated by the narrative elements of some of the pictures, particularly the Biblical themes of the massive paintings of Benjamin West, at this point Beaux had no aspirations of becoming an artist.\n\nHer childhood was a sheltered though generally happy one. As a teen she already manifested the traits, as she described, of \"both a realist and a perfectionist, pursued by an uncompromising passion for carrying through.\" She attended the Misses Lyman School and was just an average student, though she did well in French and Natural History. However, she was unable to afford the extra fee for art lessons. At age 16, Beaux began art lessons with a relative, Catherine Ann Drinker, an accomplished artist who had her own studio and a growing clientele. Drinker became Beaux's role model, and she continued lessons with Drinker for a year. She then studied for two years with the painter Francis Adolf Van der Wielen, who offered lessons in perspective and drawing from casts during the time that the new Pennsylvania Academy of the Fine Arts was under construction. Given the bias of the Victorian age, female students were denied direct study in anatomy and could not attend drawing classes with live models (who were often prostitutes) until a decade later.\n\nAt 18, Beaux was appointed as a drawing teacher at Miss Sanford's School, taking over Drinker's post. She also gave private art lessons and produced decorative art and small portraits. Her own studies were mostly self-directed. Beaux received her first introduction to lithography doing copy work for Philadelphia printer Thomas Sinclair and she published her first work in \"St. Nicholas\" magazine in December 1873. Beaux demonstrated accuracy and patience as a scientific illustrator, creating drawings of fossils for Edward Drinker Cope, for a multi-volume report sponsored by the U.S. Geological Survey. However, she did not find technical illustration suitable for a career (the extreme exactitude required gave her pains in the \"solar plexus\"). At this stage, she did not yet consider herself an artist.\n\nBeaux began attending the Pennsylvania Academy of the Fine Arts in 1876, then under the dynamic influence of Thomas Eakins, whose great work \"The Gross Clinic\" had \"horrified Philadelphia Exhibition-goers as a gory spectacle\" at the Centennial Exhibition of 1876. She steered clear of the controversial Eakins, though she much admired his work. His progressive teaching philosophy, focused on anatomy and live study (and allowed the female students to partake in segregated studios), eventually led to his firing as director of the Academy. She did not ally herself with Eakins' ardent student supporters, and later wrote, \"A curious instinct of self-preservation kept me outside the magic circle.\" Instead, she attended costume and portrait painting classes for three years taught by the ailing director Christian Schussele. Beaux won the Mary Smith Prize at the Pennsylvania Academy of the Fine Arts exhibitions in 1885, 1887, 1891, and 1892.\n\nAfter leaving the Academy, the 24-year-old Beaux decided to try her hand at porcelain painting and she enrolled in a course at the National Art Training School. She was well suited to the precise work but later wrote, \"this was the lowest depth I ever reached in commercial art, and although it was a period when youth and romance were in their first attendance on me, I remember it with gloom and record it with shame.\" She studied privately with William Sartain, a friend of Eakins and a New York artist invited to Philadelphia to teach a group of art students, starting in 1881. Though Beaux admired Eakins more and thought his painting skill superior to Sartain's, she preferred the latter's gentle teaching style which promoted no particular aesthetic approach. Unlike Eakins, however, Sartain believed in phrenology and Beaux adopted a lifelong belief that physical characteristics correlated with behaviors and traits.\n\nBeaux attended Sartain's classes for two years, then rented her own studio and shared it with a group of women artists who hired a live model and continued without an instructor. After the group disbanded, Beaux set in earnest to prove her artistic abilities. She painted a large canvas in 1884, \"Les Derniers Jours d'Enfance\", a portrait of her sister and nephew whose composition and style revealed a debt to James McNeill Whistler and whose subject matter was akin to Mary Cassatt's mother-and-child paintings. It was awarded a prize for the best painting by a female artist at the Academy, and further exhibited in Philadelphia and New York. Following that seminal painting, she painted over 50 portraits in the next three years with the zeal of a committed professional artist. Her invitation to serve as a juror on the hanging committee of the Academy confirmed her acceptance amongst her peers. In the mid-1880s, she was receiving commissions from notable Philadelphians and earning $500 per portrait, comparable to what Eakins commanded. When her friend Margaret Bush-Brown insisted that \"Les Derniers\" was good enough to be exhibited at the famed Paris Salon, Beaux relented and sent the painting abroad in the care of her friend, who managed to get the painting into the exhibition.\n\nAt 32, despite her clear success in Philadelphia, Beaux decided that she still needed to advance her skills. She left for Paris with cousin May Whitlock, forsaking several suitors and overcoming the objections of her family. There she trained at the Académie Julian, the largest art school in Paris, and at the Académie Colarossi, receiving weekly critiques from established masters like Tony Robert-Fleury and William-Adolphe Bouguereau. She wrote, \"Fleury is much less benign than Bouguereau and don't temper his severities…he hinted of possibilities before me and as he rose said the nicest thing of all, 'we will do all we can to help you'…I want these men…to know me and recognize that I can do something.\" Though advised regularly of Beaux's progress abroad and to \"not be worried about any indiscretions of ours\", her Aunt Eliza repeatedly reminded her niece to avoid the temptations of Paris, \"Remember you are first of all a Christian – then a woman and last of all an Artist.\"\n\nWhen Beaux arrived in Paris, the Impressionists, a group of artists who had begun their own series of independent exhibitions from the official Salon in 1874, were beginning to lose their solidarity. Also known as the \"Independents\" or \"Intransigents\", the group which at times included Degas, Monet, Sisley, Caillebotte, Pissarro, Renoir, and Berthe Morisot, had been receiving the wrath of the critics for several years. Their art, though varying in style and technique, was the antithesis of the type of Academic art in which Beaux was trained and of which her teacher William-Adolphe Bouguereau was a leading master. In the summer of 1888, with classes in summer recess, Beaux worked in the fishing village of Concarneau with the American painters Alexander Harrison and Charles Lazar. She tried applying the plein-air painting techniques used by the Impressionists to her own landscapes and portraiture, with little success. Unlike her predecessor Mary Cassatt, who had arrived near the beginning of the Impressionist movement 15 years earlier and who had absorbed it, Beaux's artistic temperament, precise and true to observation, would not align with Impressionism and she remained a realist painter for the rest of her career, even as Cézanne, Matisse, Gauguin, and Picasso were beginning to take art into new directions. Beaux mostly admired classic artists like Titian and Rembrandt. Her European training did influence her palette, however, and she adopted more white and paler coloration in her oil painting, particularly in depicting female subjects, an approach favored by Sargent as well.\n\nBack in America in 1889, Beaux proceeded to paint portraits in the grand manner, taking as her subjects members of her sister's family as well as the elite of Philadelphia. In making her decision to devote herself to art, she also thought it was best not to marry, and in choosing male company she selected men who would not threaten to sidetrack her career. She resumed life with her family, and they supported her fully, acknowledging her chosen path and demanding of her little in the way of household responsibilities, \"I was never once asked to do an errand in town, some bit of shopping…so well did they understand.\" She developed a structured, professional routine, arriving promptly at her studio, and expected the same from her models.\n\nThe five years that followed were highly productive, resulting in over forty portraits. In 1890 she exhibited at the Paris Exposition, obtained in 1893 the gold medal of the Philadelphia Art Club, and also the Dodge prize at the New York National Academy of Design. Her portrait of \"The Reverend Matthew Blackburne Grier\" was particularly well-received, as was \"Sita and Sarita\", a portrait of her cousin Charles W. Leavitt's wife Sarah (Allibone) Leavitt in white, with a small black cat perched on her shoulder, both gazing out mysteriously. The mesmerizing effect prompted one critic to point out \"the witch-like weirdness of the black kitten\" and for many years, the painting solicited questions by the press. But the result was not pre-planned, as Beaux's sister later explained, \"Please make no mystery about it—it was only an idea to put the black kitten on her cousin's shoulder. Nothing deeper.\" \"Sita and Sarita\" eventually was donated by the artist to the collection of the Musée d'Orsay. Another highly regarded portrait from that period is \"New England Woman\" (1895), a nearly all-white oil painting which was purchased by the Pennsylvania Academy of the Fine Arts.\n\nIn 1895 Beaux became the first woman to have a regular teaching position at the Pennsylvania Academy of the Fine Arts, where she instructed in portrait drawing and painting for the next twenty years. That rare type of achievement by a woman prompted one local newspaper to state, \"It is a legitimate source of pride to Philadelphia that one of its most cherished institutions has made this innovation.\" She was a popular instructor. In 1896, Beaux returned to France to see a group of her paintings presented at the Salon. Influential French critic M. Henri Rochefort commented, \"I am compelled to admit, not without some chagrin, that not one of our female artists…is strong enough to compete with the lady who has given us this year the portrait of Dr. Grier. Composition, flesh, texture, sound drawing—everything is there without affectation, and without seeking for effect.\"\n\nCecelia Beaux considered herself a \"New Woman\", a 19th-century women who explored educational and career opportunities that had generally been denied to women. In the late 19th century Charles Dana Gibson depicted the \"New Woman\" in his painting, \"The Reason Dinner was Late\", which is \"a sympathetic portrayal of artistic aspiration on the part of young women\" as she paints a visiting policeman. She was one of the \"New Woman\" of the 19th century successful, highly trained women artists who never married, like Ellen Day Hale, Mary Cassatt, Elizabeth Nourse and Elizabeth Coffin.\n\nBeaux was a member of Philadelphia's The Plastic Club. Other members included Elenore Abbott, Jessie Willcox Smith, Violet Oakley, Emily Sartain, and Elizabeth Shippen Green. Many of the women who founded the organization had been students of Howard Pyle. It was founded to provide a means to encourage one another professionally and create opportunities to sell their works of art.\n\nBy 1900 the demand for Beaux's work brought clients from Washington, D.C., to Boston, prompting the artist to move to New York City; it was there she spent the winters, while summering at Green Alley, the home and studio she had built in Gloucester, Massachusetts. Beaux's friendship with Richard Gilder, editor-in-chief of the literary magazine \"The Century\", helped promote her career and he introduced her to the elite of society. Among her portraits which followed from that association are those of Georges Clemenceau; First Lady Edith Roosevelt and her daughter; and Admiral Sir David Beatty. She also sketched President Teddy Roosevelt during her White House visits in 1902, during which \"He sat for two hours, talking most of the time, reciting Kipling, and reading scraps of Browning.\" Her portraits \"Fanny Travis Cochran\", \"Dorothea and Francesca\", and \"Ernesta and her Little Brother\", are fine examples of her skill in painting children; \"Ernesta with Nurse\", one of a series of essays in luminous white, was a highly original composition, seemingly without precedent. She became a member of the National Academy of Design in 1902. and won the Logan Medal of the arts at the Art Institute of Chicago in 1921.\n\nBy 1906, Beaux began to live year-round at Green Alley, in a comfortable colony of \"cottages\" belonging to her wealthy friends and neighbors. All three aunts had died and she needed an emotional break from Philadelphia and New York. She managed to find new subjects for portraiture, working in the mornings and enjoying a leisurely life the rest of the time. She carefully regulated her energy and her activities to maintain a productive output, and considered that a key to her success. On why so few women succeeded in art as she did, she stated, \"Strength is the stumbling block. They (women) are sometimes unable to stand the hard work of it day in and day out. They become tired and cannot reenergize themselves.\"\n\nWhile Beaux stuck to her portraits of the elite, American art was advancing into urban and social subject matter, led by artists such as Robert Henri who espoused a totally different aesthetic, \"Work with great speed..Have your energies alert, up and active. Do it all in one sitting if you can. In one minute if you can. There is no use delaying…Stop studying water pitchers and bananas and paint everyday life.\" He advised his students, among them Edward Hopper and Rockwell Kent, to live with the common man and paint the common man, in total opposition to Cecilia Beaux's artistic methods and subjects. The clash of Henri and William Merritt Chase (representing Beaux and the traditional art establishment) resulted in 1907 in the independent exhibition by the urban realists known as \"The Eight\" or the Ashcan School. Beaux and her art friends defended the old order, and many thought (and hoped) the new movement to be a passing fad, but it turned out to be a revolutionary turn in American art.\n\nIn 1910, her beloved Uncle Willie died. Though devastated by the loss, at fifty-five years of age, Beaux remained highly productive. In the next five years she painted almost 25 percent of her lifetime output and received a steady stream of honors. She had a major exhibition of 35 paintings at the Corcoran Gallery of Art in Washington, D.C., in 1912. Despite her continuing production and accolades, however, Beaux was working against the current of tastes and trends in art. The famed \"Armory Show\" of 1913 in New York City was a landmark presentation of 1,200 paintings showcasing Modernism. Beaux believed that the public, initially of mixed opinion about the \"new\" art, would ultimately reject it and return its favor to the Pre-Impressionists.\n\nBeaux was crippled after breaking her hip while walking in Paris in 1924. With her health impaired, her work output dwindled for the remainder of her life. That same year Beaux was asked to produce a self-portrait for the Medici collection in the Uffizi Gallery in Florence. In 1930 she published an autobiography, \"Background with Figures\". Her later life was filled with honors. In 1930 she was elected a member of the National Institute of Arts and Letters; in 1933 came membership in the American Academy of Arts and Letters, which two years later organized the first major retrospective of her work. Also in 1933 Eleanor Roosevelt honored Beaux as \"the American woman who had made the greatest contribution to the culture of the world\". In 1942 The National Institute of Arts and Letters awarded her a gold medal for lifetime achievement.\n\nCecilia Beaux died at the age of 87 on September 17, 1942, in Gloucester, Massachusetts. She was buried in Bala Cynwyd, Pennsylvania. In her will she devised that a Duncan Phyfe rosewood secretaire made for her father go to her cherished nephew Cecil Kent Drinker, a Harvard physician, whom she had painted as a young boy.\n\nThough Beaux was an individualist, comparisons to Sargent would prove inevitable, and often favorable. Her strong technique, her perceptive reading of her subjects, and her ability to flatter without falsifying, were traits similar to his.\n\n\"The critics are very enthusiastic. (Bernard) Berenson, Mrs. Coates tells me, stood in front of the portraits – Miss Beaux's three – and wagged his head. 'Ah, yes, I see!' Some Sargents. The ordinary ones are signed John Sargent, the best are signed Cecilia Beaux, which is, of course, nonsense in more ways than one, but it is part of the generous chorus of praise.\" Though overshadowed by Mary Cassatt and relatively unknown to museum-goers today, Beaux's craftsmanship and extraordinary output were highly regarded in her time. While presenting the Carnegie Institute's Gold Medal to Beaux in 1899, William Merritt Chase stated \"Miss Beaux is not only the greatest living woman painter, but the best that has ever lived. Miss Beaux has done away entirely with sex [gender] in art.\"\n\nDuring her long productive life as an artist, she maintained her personal aesthetic and high standards against all distractions and countervailing forces. She constantly struggled for perfection, \"A perfect technique in anything,\" she stated in an interview, \"means that there has been no break in continuity between the conception and the act of performance.\" She summed up her driving work ethic, \"I can say this: When I attempt anything, I have a passionate determination to overcome every obstacle…And I do my own work with a refusal to accept defeat that might almost be called painful.\"\n\n\n"}
{"id": "6882", "url": "https://en.wikipedia.org/wiki?curid=6882", "title": "Chrysler", "text": "Chrysler\n\nFCA US LLC (also called Fiat Chrysler or Chrysler) () is the American subsidiary of Fiat Chrysler Automobiles N.V., an Italian controlled automobile manufacturer registered in the Netherlands with headquarters in London, U.K., for tax purposes. FCA US is one of the \"Big Three\" American automobile manufacturers. FCA US has its headquarters in Auburn Hills, Michigan and sells vehicles worldwide under its flagship Chrysler brand, as well as the Dodge, Jeep, and Ram Trucks. Other major divisions include Mopar, its automotive parts and accessories division, and SRT, its performance automobile division.\n\nWalter Chrysler founded Chrysler Corporation in 1925 from the remains of the Maxwell Motor Company. He expanded the company in 1928 with the acquisition of Fargo Trucks and Dodge Brothers, and the creation of the Plymouth and DeSoto brands. Chrysler used the General Motors brand diversification and hierarchy strategy he had seen working for Buick.\nFacing postwar declines in market share, productivity, and profitability, as GM and Ford were growing, Chrysler borrowed $250 million in 1954 from Prudential to pay for expansion and updated car designs.\n\nIn the 1960s the company expanded into Europe, by taking control of French, British and Spanish auto companies; Chrysler Europe was sold in 1978 to PSA Peugeot Citroën for $1.\n\nChrysler struggled through the 1970s to adapt to changing markets, increased US import competition, and safety and environmental regulation. The company began an engineering partnership with Mitsubishi Motors, and began selling Mitsubishi vehicles branded as Dodge and Plymouth in North America. By the late 1970s, Chrysler was on the verge of bankruptcy. It was saved by $1.5 billion in loan guarantees from the US government. New CEO Lee Iacocca was credited with returning the company to profitability in the 1980s. In 1985, Diamond-Star Motors was created, further expanding the Chrysler-Mitsubishi relationship.\n\nIn 1987, Chrysler acquired American Motors Corporation (AMC), which brought the profitable Jeep brand under the Chrysler umbrella.\n\nIn 1998, Chrysler merged with German automaker Daimler-Benz AG to form DaimlerChrysler; the merger proved contentious with investors. As a result, Chrysler was sold to Cerberus Capital Management and renamed Chrysler LLC in 2007.\n\nLike the other Big Three automobile manufacturers, Chrysler was hit hard by the automotive industry crisis of 2008–2010. The company remained in business through a combination of negotiations with creditors, filing for Chapter 11 bankruptcy reorganization on April 30, 2009, and participating in a bailout from the U.S. government through the Troubled Asset Relief Program. On June 10, 2009, Chrysler emerged from the bankruptcy proceedings with the United Auto Workers pension fund, Fiat S.p.A., and the U.S. and Canadian governments as principal owners. The bankruptcy resulted in Chrysler defaulting on over $4 billion in debts. By May 24, 2011, Chrysler finished repaying its obligations to the U.S. government five years early, although the cost to the American taxpayer was $1.3 billion. Over the next few years, Fiat gradually acquired the other parties' shares while removing much of the weight of the loans (which carried a 21% interest rate) in a short period. On January 1, 2014, Fiat S.p.A announced a deal to purchase the rest of Chrysler from the United Auto Workers retiree health trust. The deal was completed on January 21, 2014, making Chrysler Group a subsidiary of Fiat S.p.A. In May 2014, Fiat Chrysler Automobiles, NV was established by merging Fiat S.p.A. into the company. This was completed in August 2014. Chrysler Group LLC remained a subsidiary until December 15, 2014, when it was renamed FCA US LLC, to reflect the Fiat-Chrysler merger.\n\nThe Chrysler company was founded by Walter Chrysler (1875–1940) on June 6, 1925, when the Maxwell Motor Company (est. 1904) was re-organized into the Chrysler Corporation.\n\nWalter Chrysler had arrived at the ailing Maxwell-Chalmers company in the early 1920s. He was hired to overhaul the company's troubled operations (after a similar rescue job at the Willys-Overland car company). In late 1923 production of the Chalmers automobile was ended.\n\nIn January 1924, Walter Chrysler launched the well-received Chrysler automobile. The Chrysler was a 6-cylinder automobile, designed to provide customers with an advanced, well-engineered car, but at a more affordable price than they might expect. (Elements of this car are traceable to a prototype which had been under development at Willys during Chrysler's tenure The original 1924 Chrysler included a carburetor air filter, high compression engine, full pressure lubrication, and an oil filter, features absent from most autos at the time. Among the innovations in its early years were the first practical mass-produced four-wheel hydraulic brakes, a system nearly completely engineered by Chrysler with patents assigned to Lockheed, and rubber engine mounts to reduce vibration.\nChrysler also developed a wheel with a ridged rim, designed to keep a deflated tire from flying off the wheel. This wheel was eventually adopted by the auto industry worldwide.\n\nFollowing the introduction of the Chrysler, the Maxwell brand was dropped after the 1925 model year. The new, lower-priced four-cylinder Chryslers introduced for the 1926 year were badge-engineered Maxwells. The advanced engineering and testing that went into Chrysler Corporation cars helped to push the company to the second-place position in U.S. sales by 1936, a position it would last hold in 1949.\n\nIn 1928, the Chrysler Corporation began dividing its vehicle offerings by price class and function. The Plymouth brand was introduced at the low-priced end of the market (created essentially by once again reworking and rebadging Chrysler's four-cylinder model). At the same time, the DeSoto brand was introduced in the medium-price field. Also in 1928, Chrysler bought the Dodge Brothers automobile and truck company and continued the successful Dodge line of automobiles and Fargo range of trucks. By the mid-1930s, the DeSoto and Dodge divisions would trade places in the corporate hierarchy.\nThe Imperial name had been used since 1926, but was never a separate make, just the top-of-the-line Chrysler. In 1955, the company decided to spin it off as its own make and division to better compete with its rivals, Lincoln and Cadillac.\n\nOn April 28, 1955, Chrysler and Philco had announced the development and production of the World's First All-Transistor car radio. The all-transistor car radio Mopar model 914HR, was developed and produced by Chrysler and Philco, and was an $150.00 \"option\" on the 1956 Imperial car models. Philco was the company who had manufactured the all-transistor car radio Mopar model 914HR, starting in the fall of 1955 at its Sandusky Ohio plant, for the Chrysler corporation.\n\nOn September 28, 1957, Chrysler had announced the first production electronic fuel injection (EFI), as an option on some of its new 1958 car models (Chrysler 300D, Dodge D500, DeSoto Adventurer, Plymouth Fury). The first attempt to use this system was by American Motors on the 1957 Rambler Rebel. Bendix Corporation's Electrojector used a transistor computer brain modulator box, but teething problems on pre-production cars meant very few cars were made. The EFI system in the Rambler ran fine in warm weather, but suffered hard starting in cooler temperatures and AMC decided not to use this EFI system, on its 1957 Rambler Rebel production cars that were sold to the public. Chrysler also used the Bendix \"Electrojector\" fuel injection system and only around 35 vehicles were built with this option, on its 1958 production built car models. Owners of EFI Chryslers were so dissatisfied that all but one were retrofitted with carburetors (while that one has been completely restored, with original EFI electronic problems resolved).\n\nImperial would see new body styles introduced every two to three years, all with V8 engines and automatic transmissions, as well as technologies that would filter down to Chrysler corporation's other models. Imperial was folded back into the Chrysler brand in 1971.\n\nThe Valiant was also introduced for 1960 as a distinct brand. In the U.S. market, Valiant was made a model in the Plymouth line for 1961 and the DeSoto make was discontinued during 1961. With those exceptions per applicable year and market, Chrysler's range from lowest to highest price from the 1940s through the 1970s was Valiant, Plymouth, Dodge, DeSoto, Chrysler, and Imperial.\n\nFrom 1963 through 1969, Chrysler increased its existing stakes to take full control of the French Simca, British Rootes and Spanish Barreiros companies, merging them into Chrysler Europe in 1967. In the 1970s, an engineering partnership was established with Mitsubishi Motors, and began selling Mitsubishi vehicles branded as Dodge and Plymouth in North America.\n\nChrysler struggled to adapt to the changing environment of the 1970s. When consumer tastes shifted to smaller cars in the early 1970s, particularly after the 1973 oil crisis, Chrysler could not meet the demand. Additional burdens came from increased US import competition, and tougher government regulation of car safety, fuel economy, and emissions. As the smallest of the Big 3 US automakers, Chrysler lacked the financial resources to meet all of these challenges. In 1978, Lee Iacocca was brought in to turn the company around, and in 1979 Iacocca sought US government help. Congress later passed the \"Loan Guarantee Act\" providing $1.5 billion in loan guarantees. The \"Loan Guarantee Act\" required that Chrysler also obtain $2 billion in concessions or aid from sources outside the federal government, which included interest rate reductions for $650 million of the savings, asset sales of $300 million, local and state tax concessions of $250 million, and wage reductions of about $590 million along with a $50 million stock offering. $180 million was to come from concessions from dealers and suppliers.\n\nAfter a period of plant closures and salary cuts agreed to by both management and the auto unions, the loans were repaid with interest in 1983. In November 1983 the Dodge Caravan/Plymouth Voyager was introduced, leading the establishment of the minivan as a major category, and initiating Chrysler's return to stability.\n\nIn 1985, Diamond-Star Motors was created, further expanding the Chrysler-Mitsubishi relationship. In 1987, Chrysler acquired American Motors Corporation (AMC), which brought the profitable Jeep brand under the Chrysler umbrella.\nIn 1985, Chrysler entered an agreement with American Motors Corporation (AMC) to produce Chrysler M platform rear-drive, as well as Dodge Omnis front wheel drive cars, in AMC's Kenosha, Wisconsin plant. In 1987, Chrysler acquired the 47% ownership of AMC that was held by Renault. The remaining outstanding shares of AMC were purchased on the NYSE by August 5, 1987, making the deal valued somewhere between US$1.7 billion and US$2 billion, depending on how costs were counted. Chrysler CEO Lee Iacocca wanted the Jeep brand, particularly the Jeep Grand Cherokee (ZJ) that was under development, the world-class, brand-new manufacturing plant in Bramalea, Ontario, as well as AMC's engineering and management talent that became critical for Chrysler's future success. Chrysler established the Jeep/Eagle division as a \"specialty\" arm to market products distinctly different from the K-car-based products with the Eagle cars targeting import buyers. Former AMC dealers sold Jeep vehicles and various new Eagle models, as well as Chrysler products, strengthening the automaker's retail distribution system.\n\nEurostar, a joint venture between Chrysler and Steyr-Daimler-Puch, began producing the Chrysler Voyager in Austria for European markets in 1992.\n\nIn 1998, Chrysler and its subsidiaries entered into a partnership dubbed a \"merger of equals\" with German-based Daimler-Benz AG, creating the combined entity DaimlerChrysler AG. To the surprise of many stockholders, Daimler subsequently acquired Chrysler in a stock swap, before the retirement of Chrysler CEO Bob Eaton. His lack of planning for Chrysler in the 1990s, to become their own global automotive company, is widely accepted as the reason why the merger was needed. Under DaimlerChrysler, the company was named DaimlerChrysler Motors Company LLC, with its U.S. operations generally called \"DCX\". The Eagle brand was retired shortly after Chrysler's merger with Daimler-Benz in 1998 Jeep became a stand-alone division, and efforts were made to merge the Chrysler and Jeep brands as one sales unit. In 2001, the Plymouth brand was also discontinued.\n\nEurostar also built the Chrysler PT Cruiser in 2001 and 2002. The Austrian venture was sold to Magna International in 2002 and became Magna Steyr. The Voyager continued in production until 2007, whereas the Chrysler 300C, Jeep Grand Cherokee and Jeep Commander were also built at the plant from 2005 to 2010.\n\nOn May 14, 2007, DaimlerChrysler announced the sale of 80.1% of Chrysler Group to American private equity firm Cerberus Capital Management, L.P., thereafter known as Chrysler LLC, although Daimler (renamed as Daimler AG) continued to hold a 19.9% stake. The economic collapse of 2007 - 2009 pushed an already fragile company to the brink. On April 30, 2009, the automaker filed for Chapter 11 bankruptcy protection to be able to operate as a going concern, while renegotiating its debt structure and other obligations, which resulted in the corporation defaulting on over $4 billion in secured debts. The U.S. government described the company's action as a \"prepackaged surgical bankruptcy.\"\n\nThe sale of substantially all of Chrysler's assets to \"New Chrysler\", organized as Chrysler Group LLC was completed on June 10, 2009. The federal government provided support for the deal with US$8 billion in financing at near 21%. Under Sergio Marchionne, \"World Class Manufacturing\" or WCM, a system of complete and thorough manufacturing quality, was introduced and several products re-launched with quality and luxury. The 2010 Jeep Grand Cherokee very soon became the most awarded SUV - Ever. The Ram, Jeep, Dodge, SRT and Chrysler divisions were separated to focus on their own identity and brand and 11 major model refreshes occurred in 21 months. The PT Cruiser, Nitro, Liberty and Caliber models (created during DCX) were discontinued. On May 24, 2011, Chrysler repaid its $7.6 billion loans to the United States and Canadian governments. The US Treasury, through the Troubled Asset Relief Program (TARP), invested $12.5 billion in Chrysler and recovered $11.2 billion when the company shares were sold in May 2011, resulting in a $1.3 billion loss. On July 21, 2011, Fiat bought the Chrysler shares held by the United States Treasury. With the purchase, Chrysler once again became foreign owned; however, this time Chrysler was the luxury division. The Chrysler 300 was badged Lancia Thema in some European markets (with additional engine options), giving Lancia a much needed replacement for its flagship.\n\nOn January 1, 2014, Fiat announced it would be acquiring the remaining shares of Chrysler owned by the VEBA worth $3.65 billion. The deal was completed on January 21, 2014. Several days later, the intended reorganization of Fiat and Chrysler under a new holding company, Fiat Chrysler Automobiles, together with a new FCA logo were announced. The most challenging launch for this new company came immediately in January 2014 with a completely redesigned Chrysler 200. The vehicle's creation is from the completely integrated company, FCA, executing from a global compact-wide platform.\n\nOn 16 December 2014, Chrysler Group LLC announced a name change to FCA US LLC.\n\nOn Thursday, 12 January 2017, FCA US LLC shares plunged after the EPA accused it of using emissions cheating software to evade diesel-emissions tests, however the company countered the accusations, with the chairman and CEO, Sergio Marchionne, sternly rejecting the allegations. The following day, shares rose as investors played down the effect of the accusations. Analysts gave estimates of potential fines from several hundred million dollars to $4 billion, although the likelihood of a hefty fine was low. Senior United States Senator Bill Nelson urged the FTC to look into possible deceptive marketing of the company's diesel-powered SUVs. Shares dropped 2.2 percent after the announcement.\n\n\n\nChrysler is the smallest of the \"Big Three\" U.S. automakers (Chrysler Group LLC, Ford Motor Company, and General Motors). In 2013 Chrysler sold 1,800,368 vehicles, 9% up from 2012, and fourth largest in sales behind GM, Ford and Toyota.\n\nChrysler's sales have fluctuated dramatically over the last decade. In 2007 sales reached 2,076,650, falling to 931,402 units in 2009, the company's worst result in decades.\n\nIt is reported that Chrysler was heavy on fleet sales in 2010, hitting as high as 56 percent of total sales in February of that year. For the whole year, 38 percent of sales of Chrysler were to fleet customers. The industry average was 19 percent. However, the company hopes to reduce its fleet sales to the industry average in 2011 with a renewed product lineup.\n\nChrysler is the world's 11th largest vehicle manufacturer as ranked by OICA in 2012. Total Chrysler vehicle production was about 2.37 million that year, up from 1.58 million in 2010.\n\nIn 2007, Chrysler began to offer vehicle lifetime powertrain warranty for the first registered owner or retail lessee. The deal covered owner or lessee in U.S., Puerto Rico and the Virgin Islands, for 2009 model year vehicles, and 2006, 2007 and 2008 model year vehicles purchased on or after July 26, 2007. Covered vehicles excluded SRT models, Diesel vehicles, Sprinter models, Ram Chassis Cab, Hybrid System components (including transmission), and certain fleet vehicles. The warranty is non-transferable. After Chrysler's restructuring, the warranty program was replaced by five-year/100,000 mile transferrable warranty for 2010 or later vehicles.\n\nIn 2008, as a response to customer feedback citing the prospect of rising gas prices as a top concern, Chrysler launched the \"Let's Refuel America\" incentive campaign, which guaranteed new-car buyers a gasoline price of $2.99 for three years. With the U.S. purchase of eligible Chrysler, Jeep and Dodge vehicles, customers could enroll in the program and receive a gas card that immediately lowers their gas price to $2.99 a gallon, and keeps it there for the three years.\n\nChrysler plans for Lancia to codevelop products, with some vehicles being shared. Olivier Francois, Lancia's CEO, was appointed to the Chrysler division in October 2009. Francois plans to reestablish the Chrysler brand as an upscale brand.\n\nIn October 2009, Dodge's car and truck lines were separated, with the name \"Dodge\" being used for cars, minivans and crossovers and \"Ram\" for light- and medium-duty trucks and other commercial-use vehicles.<ref name=\"autoblog.com/2009\"></ref>\nIn 2011, Chrysler unveiled their \"Imported From Detroit\" campaign with ads featuring Detroit rapper Eminem, one of which aired during the Super Bowl. The campaign highlighted the rejuvenation of the entire product lineup, which included the new, redesigned and repackaged 2011 200 sedan and 200 convertible, the Chrysler 300 sedan and the Chrysler Town & Country minivan. As part of the campaign, Chrysler sold a line of clothing items featuring the Monument to Joe Louis, with proceeds being funneled to Detroit-area charities, including the Boys and Girls Clubs of Southeast Michigan, Habitat for Humanity Detroit and the Marshall Mathers Foundation. Following the Eminem ad, there was also an ad for Detroit Lions defensive tackle Ndamukong Suh driving a Chrysler 300 to Portland, Oregon, to visit his mother, an ad featuring Detroit-born fashion designer John Varvatos cruising through a shadowy Gotham while Kevin Yon's familiar baritone traces the designer's genesis.\n\nIn March 2011, Chrysler Group LLC filed a lawsuit against Moda Group LLC (owner of Pure Detroit clothing retailer) for copying and selling merchandise with the \"Imported from Detroit\" slogan. Chrysler claimed it had notified defendant of its pending trademark application February 14, but the defendant argued Chrysler had not secured a trademark for the \"Imported From Detroit\" phrase. On June 18, 2011, U.S. District Judge Arthur Tarnow ruled that Chrysler's request did not show that it would suffer irreparable harm or that it had a strong likelihood of winning its case. Therefore, Pure Detroit's owner, Detroit retailer Moda Group LLC, can continue selling its \"Imported from Detroit\" products. Tarnow also noted that Chrysler does not have a trademark on \"Imported from Detroit\" and rejected the automaker's argument that trademark law is not applicable to the case. In March 2012, Chrysler Group LLC and Pure Detroit agreed to a March 27 mediation to try to settle the lawsuit over the clothing company's use of \"Imported from Detroit\" slogan. Pure Detroit stated that Chrysler has made false claims about the origins of three vehicles - Chrysler 200, Chrysler 300 and Chrysler Town & Country - none of which are built in Detroit. Pure Detroit also said that Chrysler's Imported From Detroit merchandise is not being made in Detroit. In 2012 Chrysler and Pure Detroit came to an undisclosed settlement.\n\nChrysler's Jefferson North Assembly, which makes the Jeep Grand Cherokee and Dodge Durango, is the only car manufacturing plant of any company remaining entirely in Detroit (General Motors operates a plant which is partly in Detroit and partly in Hamtramck).\n\nIn 2011, Eminem settled a lawsuit against Audi alleging the defendant had ripped off the Chrysler 300 Super Bowl commercial in the Audi A6 Avant ad.\n\nAgain in 2012, Chrysler advertised during the Super Bowl. Its two-minute February 5, 2012 Super Bowl XLVI advertisement was titled \"Half Time in America\". The ad drew criticism from several leading U.S. conservatives, who suggested that its messaging implied that President Barack Obama deserved a second term and, as such, was political payback for Obama's support for the federal bailout of the company. Asked about the criticism in a \"60 Minutes\" interview with Steve Kroft, Sergio Marchionne responded \"just to rectify the record I paid back the loans at 19.7% Interest. I don't think I committed to do to a commercial on top of that\" and characterized the Republican reaction as \"unnecessary and out of place\".\n\n\nIn 2014, Chrysler started using a new slogan, \"America's Import\" in ads introducing their all-new 2015 Chrysler 200, targeting foreign automakers from Germany to Japan with such ads (German performance and Japanese quality), and at the ending of selected ads, the advertisement will say, \"We Built This\", indicating being built in America, instead of overseas.\n\n\n\n\nIn 2010, Fiat Auto was planning to sell seven of its vehicles in the U.S. by 2014, while Fiat-controlled Chrysler Group was to supply nine models to sell under Fiat brands in the European market, according to a five-year plan rolled out on April 21, 2010 in Turin, Italy, by Fiat and Chrysler CEO Sergio Marchionne. At least five of the Fiat Auto models were expected to be marketed in the U.S. under its Alfa Romeo brand. Showing the level of integration envisioned, a product introduction timeline envisaged Chrysler-built compact and full-size SUVs going on sale in 2012 and 2014, respectively, in both European and North American markets.\n\nFirst introduced as MyGig, Chrysler Uconnect is a system that brings interactive ability to the in-car radio and telemetric-like controls to car settings. As of mid-2015, it is installed in hundreds of thousands of Fiat Chrysler vehicles. It connects to the Internet via the mobile network of Sprint, providing the car with its own IP address. Internet connectivity using any Chrysler, Dodge, Jeep or Ram vehicle, via a Wi-Fi \"hot-spot\", is also available via Uconnect Web. According to Chrysler LLC, the hotspot range extends approximately from the vehicle in all directions, and combines both Wi-Fi and Sprint's 3G cellular connectivity. Uconnect is available on several current and was available on several discontinued Chrysler models including the current Dodge Dart, Chrysler 300, Aspen, Sebring, Town and Country, Dodge Avenger, Caliber, Grand Caravan, Challenger, Charger, Journey, Nitro, and Ram.\n\nIn July 2015, IT security researchers announced a severe security flaw assumed to affect every Chrysler vehicle with Uconnect produced from late 2013 to early 2015. It allows hackers to gain access to the car over the Internet, and in the case of a Jeep Cherokee was demonstrated to enable an attacker to take control not just of the radio, A/C, and windshield wipers, but also of the car's steering, brakes and transmission. Chrysler published a patch that car owners can download and install via a USB stick, or have a car dealer install for them.\n\nChrysler's quality and customer satisfaction ratings have been below average according to Consumer Reports and JD Powers since the late 1990s. Consumer Reports has consistently reported Chrysler brands at the bottom of their reliability ratings in the past decade as well as their Automotive Brand Report Card. JDP has found similar results over the same time period in both Initial Quality Studies and Customer Service Indexes as has the American Customer Satisfaction Index survey. Chrysler has had a few quality successes during this period. Strategic Vision named Chrysler an overall winner in 2015 noting strong customer appeal and that with the rise in quality of all cars the difference between high and low \"problem-counting\" ratings are relatively small.\n\nChrysler produced an experimental electric vehicle in 1979, the company developed Chrysler ETV-1 electric prototype in cooperation with U.S. Department of Energy.\n\nIn 1992, Chrysler developed the Dodge EPIC concept minivan. In 1993, Chrysler began to sell a limited-production electric minivan called the TEVan; however only 56 were produced. In 1997, a second generation, called the EPIC, was released. It was discontinued after 1999.\n\nChrysler once owned the Global Electric Motorcars company, building low-speed neighborhood electric vehicles, but sold GEM to Polaris Industries in 2011.\n\nIn September 2007, Chrysler established ENVI, an in-house organization focused on electric-drive vehicles and related technologies which was disbanded by late 2009. In August 2009, Chrysler took US$70 million in grants from the U.S. Department of Energy to develop a test fleet of 220 hybrid pickup trucks and minivans. \n\nThe first hybrid models, the Chrysler Aspen hybrid and the Dodge Durango hybrid, were discontinued a few months after production in 2008, sharing their GM-designed hybrid technology with GM, Daimler and BMW.\n\nChrysler is on the Advisory Council of the PHEV Research Center, and undertook a government sponsored demonstration project with Ram and minivan vehicles.\n\nIn 2012, FCA CEO Sergio Marchionne said that Chrysler and Fiat both plan to focus primarily on alternative fuels, such as CNG and Diesel, instead of hybrid and electric drivetrains for their consumer products.\n\nFiat Chrysler bought 8.2 million megagrams of U.S. greenhouse gas emission credits from competitors including Toyota, Honda, Tesla and Nissan.\n\nDuring World War II, essentially all of Chrysler's facilities were devoted to building military vehicles (the Jeep brand came later, after Chrysler acquired American Motors Corporation). They were also designing V12 and V16 hemi-engines producing for airplanes, but they did not make it into production as jets were developed and were seen as the future for air travel. During the 1950s Cold War period, Chrysler made air raid sirens powered by its Hemi V-8 engines.\n\nWhen the Radiation Laboratory at MIT was established in 1941 to develop microwave radars, one of the first projects resulted in the SCR-584, the most widely recognized radar system of the war era. This system included a parabolic antenna six feet in diameter that was mechanically aimed in a helical pattern (round and round as well as up and down).\n\nOne of Chrysler's most significant contributions to the war effort was not in the field of vehicles but in the radar field. For the final production design of this antenna and its highly complex drive mechanism, the Army's Signal Corps Laboratories turned to Chrysler's Central Engineering Office. There, the parabola was changed from aluminum to steel, allowing production forming using standard automotive presses. To keep weight down, 6,000 equally spaced holes were drilled in the face (this had no effect on the radiation pattern). The drive mechanism was completely redesigned, using technology derived from Chrysler's research in automotive gears and differentials. The changes resulted in improved performance, reduced weight, and easier maintenance. A large portion of the Dodge plant was used in building 1,500 of the SCR-584 antennas as well as the vans used in the systems.\n\n\nIn April 1950, the U.S. Army established the Ordnance Guided Missile Center (OGMC) at Redstone Arsenal, adjacent to Huntsville, Alabama. To form OGMC, over 1,000 civilian and military personnel were transferred from Fort Bliss, Texas. Included was a group of German scientists and engineers led by Wernher von Braun; this group had been brought to America under Project Paperclip. OGMC designed the Army's first short-range ballistic missile, the PGM-11 Redstone, based on the WWII German V-2 missile. Chrysler established the Missile Division to serve as the Redstone prime contractor, setting up an engineering operation in Huntsville and for production obtaining use from the U.S. Navy of a large plant in Sterling Heights, Michigan. The Redstone was in active service from 1958 to 1964; it was also the first missile to test-launch a live nuclear weapon, first detonated in a 1958 test in the South Pacific.\n\nWorking together, the Missile Division and von Braun's team greatly increased the capability of the Redstone, resulting in the PGM-19 Jupiter, a medium-range ballistic missile. In May 1959, a Jupiter missile launched two small monkeys into space in a nose cone; this was America's first successful flight and recovery of live space payloads. Responsibility for deploying Jupiter missiles was transferred from the Army to the Air Force; armed with nuclear warheads, they were first deployed in Italy and Turkey during the early 1960s.\n\nIn July 1959, NASA chose the Redstone missile as the basis for the Mercury-Redstone Launch Vehicle to be used for suborbital test flights of the Project Mercury spacecraft. Three unmanned MRLV launch attempts were made between November 1960 and March 1961, two of which were successful. The MRLV successfully launched the chimpanzee Ham, and astronauts Alan Shepard and Gus Grissom on three suborbital flights in January, May and July 1961, respectively.\n\nAmerica's more ambitious manned space travel plans included the design of the Saturn series of heavy-lift launch vehicles by a team headed by Wernher von Braun. Chrysler's Huntsville operation, then designated the Space Division, became Marshall Space Flight Center's prime contractor for the first stage of the Saturn I and Saturn IB versions. The design was based on a cluster of Redstone and Jupiter fuel tanks, and Chrysler built it for the Apollo program in the Michoud Assembly Facility in East New Orleans, one of the largest manufacturing plants in the world. Between October 1961 and July 1975, NASA used ten Saturn Is and nine Saturn IBs for suborbital and orbital flights, all of which were successful; Chrysler missiles and boosters never suffered a launch failure. The division was also a subcontractor which modified one of the Mobile Launcher Platforms for use with the Saturn IB rockets using Saturn V infrastructure.\n\n\n\n1. Fiat is exercising their right to increase their share in the company, and have announced that they want to buy an additional ~6.6% of the shares from VEBA Trust, but VEBA disagrees with the price set by Fiat. The matter is currently the subject of proceedings at Delaware Chancery Court.\n\n"}
{"id": "6883", "url": "https://en.wikipedia.org/wiki?curid=6883", "title": "City of London", "text": "City of London\n\nThe City of London is a city and county that contains the historic centre and central business district of London. It constituted most of London from its settlement by the Romans in the 1st century AD to the Middle Ages, but the agglomeration has since grown far beyond the City's borders. The City is now only a tiny part of the metropolis of London, though it remains a notable part of central London. Administratively, it forms one of the 33 local authority districts of Greater London; however, the City of London is not a London borough, a status reserved for the other 32 districts (including London's only other city, the City of Westminster). \n\nThe City of London is widely referred to simply as the City (differentiated from the phrase \"the city of London\" by capitalising \"City\") and is also colloquially known as the Square Mile, as it is in area. Both of these terms are also often used as metonyms for the United Kingdom's trading and financial services industries, which continue a notable history of being largely based in the City. The name \"London\" is now ordinarily used for a far wider area than just the City. \"London\" most often denotes the sprawling London metropolis, or the 32 London boroughs, in addition to the City of London itself. This wider usage of \"London\" is documented as far back as 1888, when the County of London was created.\n\nThe local authority for the City, namely the City of London Corporation, is unique in the UK and has some unusual responsibilities for a local council, such as being the police authority. It is also unusual in having responsibilities and ownerships beyond its boundaries. The Corporation is headed by the Lord Mayor of the City of London, an office separate from (and much older than) the Mayor of London. The current Lord Mayor, as of November 2016, is Andrew Parmley.\n\nThe City is a major business and financial centre. Throughout the 19th century, the City was the world's primary business centre, and it continues to be a major meeting point for businesses. London came top in the Worldwide Centres of Commerce Index, published in 2008. The insurance industry is focused around the eastern side of the City, around Lloyd's building. A secondary financial district exists outside of the City, at Canary Wharf, to the east.\n\nThe City has a resident population of about 7,000 (2011) but over 300,000 people commute to and work there, mainly in the financial services sector. The legal profession forms a major component of the northern and western sides of the City, especially in the Temple and Chancery Lane areas where the Inns of Court are located, of which two—Inner Temple and Middle Temple—fall within the City of London boundary.\n\nIt used to be widely held that \"Londinium\" was first established by merchants as a trading port on the tidal Thames in around 47 AD, during the early years of the Roman occupation of Britain. However, this date is only supposition. The Romans have left no record of when or how the city was founded and the first time they mention the city is in the annals of Tacitus (in 61 AD) when he relates how Londinium was among a group of important cities sacked by the Iceni, led by their queen, Boudica.\n\nMany historians now believe London was founded some time before the Roman conquest of Britain in 43 AD. They base this notion on evidence provided by both archaeology and Welsh literary legend. Archaeologists have claimed that as much as half of the best British Iron Age art and metalwork discovered in Britain has been found in the London area. One of the most prominent examples is the famously horned \"Waterloo Helmet\" dredged from the Thames in the early 1860s and now exhibited at the British Museum.\n\nAlso, according to an ancient Welsh legend, a king named Lud son of Heli substantially enlarged and improved a pre-existing settlement at London which afterwards came to be renamed after him. The same tradition relates how this Lud son of Heli was later buried at Ludgate (\"Welsh:\" Porthlud).\n\nLlydd was the eldest son. And after his father (Beli Mawr) was dead he took the government of the island. And he strengthened the walls of Llvndain, surrounded the city with many farmsteads, and lived in it the greater part of the year. And he had built within the city walls splendid buildings the like of which were not seen in all countries. And he called it Kaer Lvdd; and in the end it was called Kaer Lvndain. And, after the coming of the alien nation into it, it was called Kaer Lwndwn.\n\nNevertheless, after the conquest the Romans certainly developed the settlement and port, with its centre roughly where the shallow stream the Walbrook met the Thames. After the city had been destroyed by Boudica in 60 AD it was entirely rebuilt as a planned settlement (a \"civitas\"), and the new walled town was prosperous and grew to become the largest settlement in Roman Britain by the end of the 1st century. By the beginning of the 2nd century, Londinium had replaced Camulodunum (Colchester) as the capital of Roman Britain (\"Britannia\").\n\nAt its height, the Roman city had a population of approximately 45,000–60,000 inhabitants. Londonium was an ethnically diverse city, with inhabitants from across the Roman Empire, including natives of Britannia, continental Europe, the Middle East, and North Africa. The Romans built the London Wall some time between 190 and 225 AD. The boundaries of the Roman city were similar to those of the City of London today, though Londinium did not extend further west than Ludgate or the Fleet, and the mid-estuary Thames was undredged and wider than it is today thus, the City's shoreline was north of its present position. The Romans built a bridge across the river, as early as 50 AD, near to today's London Bridge.\n\nA number of Roman sites and artefacts can be seen in the City, including the Temple of Mithras, sections of the London Wall (at the Barbican and near Tower Hill), the London Stone and remains of the amphitheatre beneath the Guildhall. The Museum of London holds many of the Roman finds, has permanent Roman exhibitions and holds research collections.\n\nBy the time the London Wall was constructed, the City's fortunes were in decline, and it faced problems of plague and fire. The Roman Empire entered a long period of instability and decline, including the Carausian Revolt in Britain. In the 3rd and 4th centuries, the city was under attack from Picts, Scots, and Saxon raiders. The decline continued, both for Londinium and the Empire, and in 410 AD the Romans withdrew entirely from Britain. Many of the Roman public buildings in Londinium by this time had fallen into decay and disuse, and gradually after the formal withdrawal the city became almost (if not, at times, entirely) uninhabited. The centre of trade and population moved away from the walled Londinium to Lundenwic (\"London market\"), a settlement to the west, roughly in the modern day Strand/Aldwych/Covent Garden area.\n\nDuring the Anglo-Saxon Heptarchy, the London area came in turn under the Kingdoms of Essex, Mercia, and later Wessex, though from the mid 8th century it was frequently under the control or threat of the Vikings.\nBede records that in 604 AD St Augustine consecrated Mellitus as the first bishop to the Anglo-Saxon kingdom of the East Saxons and their king, Sæberht. Sæberht's uncle and overlord, Æthelberht, king of Kent, built a church dedicated to St Paul in London, as the seat of the new bishop. It is assumed, although unproven, that this first Anglo-Saxon cathedral stood on the same site as the later medieval and the present cathedrals.\n\nAlfred the Great, King of Wessex and arguably the first king of the \"English\", occupied and began the resettlement of the old Roman walled area, in 886, and appointed his son-in-law Earl Æthelred of Mercia over it as part of their reconquest of the Viking occupied parts of England. The refortified Anglo-Saxon settlement was known as Lundenburh (\"London Fort\", a borough). The historian Asser said that \"Alfred, king of the Anglo-Saxons, restored the city of London splendidly ... and made it habitable once more.\" Alfred's \"restoration\" entailed reoccupying and refurbishing the nearly deserted Roman walled city, building quays along the Thames, and laying a new city street plan.\n\nAlfred's taking of London and the rebuilding of the old Roman city was a turning point in history, not only as the permanent establishment of the City of London, but also as part of a unifying moment in early England, with Wessex becoming the dominant English kingdom and the repelling (to some degree) of the Viking occupation and raids. While London, and indeed England, were afterwards subjected to further periods of Viking and Danish raids and occupation, the establishment of the City of London and the Kingdom of England prevailed.\n\nIn the 10th century, Athelstan permitted eight mints to be established, compared with six in his capital, Winchester, indicating the wealth of the city. London Bridge, which had fallen into ruin following the Roman evacuation and abandonment of Londinium, was rebuilt by the Saxons, but was periodically destroyed by Viking raids and storms.\n\nAs the focus of trade and population was moved back to within the old Roman walls, the older Saxon settlement of Lundenwic was largely abandoned and gained the name of \"Ealdwic\" (the \"old settlement\"). The name survives today as Aldwych (the \"old market-place\"), a name of a street and an area of the City of Westminster between Westminster and the City of London.\n\nFollowing the Battle of Hastings, William the Conqueror marched on London \"(reaching as far as Southwark)\", but failed to get across London Bridge or to defeat the Londoners. He eventually crossed the River Thames at Wallingford, pillaging the land as he went. Rather than continuing the war, Edgar the Ætheling, Edwin of Mercia and Morcar of Northumbria surrendered at Berkhamsted. William granted the citizens of London a charter in 1075; the City was one of a few examples of the English retaining some authority. The City was not covered by the Domesday Book.\n\nWilliam built three castles nearby, to keep Londoners subdued:\n\n\nAbout 1130, Henry I granted a sheriff to the people of London, along with control of the county of Middlesex: this meant that the two entities were regarded as one administratively (not that the county was a dependency of the City) until the Local Government Act 1888. By 1141 the whole body of the citizenry was considered to constitute a single community. This 'commune' was the origin of the City of London Corporation and the citizens gained the right to appoint, with the king's consent, a Mayor in 1189—and to directly elect the Mayor from 1215.\n\nFrom medieval times, the City has been composed of 25 ancient wards, each headed by an Alderman, who chairs Wardmotes, which still take place at least annually. A Folkmoot, for the whole of the City held at the outdoor cross of St Paul's Cathedral, was formerly also held. Many of the medieval offices and traditions continue to the present day, demonstrating the unique nature of the City and its Corporation.\n\nIn 1381, the Peasants' Revolt affected London. The rebels took the City and the Tower of London, but the rebellion ended after its leader, Wat Tyler, was killed during a confrontation that included Lord Mayor William Walworth.\n\nThe City was burned severely on a number of occasions, the worst being in 1123 and (more famously) in the Great Fire of London in 1666. Both of these fires were referred to as \"the\" Great Fire. After the fire of 1666, a number of plans were drawn up to remodel the City and its street pattern into a renaissance-style city with planned urban blocks, squares and boulevards. These plans were almost entirely not taken up, and the medieval street pattern re-emerged almost intact.\n\nBy the late 16th century, London increasingly became a major centre for banking, international trade and commerce. The Royal Exchange was founded in 1565 by Sir Thomas Gresham as a centre of commerce for London's merchants, and gained Royal patronage in 1571. Although no longer used for its original purpose, its location at the corner of Cornhill and Threadneedle Street continues to be the geographical centre of the City's core of banking and financial services, with the Bank of England moving to its present site in 1734, opposite the Royal Exchange on Threadneedle Street. Immediately to the south of Cornhill, Lombard Street was the location from 1691 of Lloyd's Coffee House, which became the world-leading insurance market. London's insurance sector continues to be based in the area, particularly in Lime Street.\n\nIn 1708, Christopher Wren's masterpiece, St Paul's Cathedral, was completed on his birthday. The first service had been held on 2 December 1697, more than 10 years earlier. It replaced the original St Paul's, which had been completely destroyed in the Great Fire of London, and is considered to be one of the finest cathedrals in Britain and a fine example of Baroque architecture.\n\nThe 18th century was a period of rapid growth for London, reflecting an increasing national population, the early stirrings of the Industrial Revolution, and London's role at the centre of the evolving British Empire. The urban area expanded beyond the borders of the City of London, most notably during this period towards the West End and Westminster.\n\nExpansion continued and became more rapid by the beginning of the 19th century, with London growing in all directions. To the East the Port of London grew rapidly during the century, with the construction of many docks, needed as the Thames at the City could not cope with the volume of trade. The arrival of the railways and the Tube meant that London could expand over a much greater area. By the mid-19th century, with London still rapidly expanding in population and area, the City had already become only a small part of the wider metropolis.\n\nAn attempt was made in 1894 with the Royal Commission on the Amalgamation of the City and County of London to end the distinction between the City and the surrounding County of London, but a change of government at Westminster meant the option was not taken up. The City as a distinct polity survived despite its position within the London conurbation and numerous local government reforms. Supporting this status, the City was a special parliamentary borough that elected four members to the unreformed House of Commons, who were retained after the Reform Act 1832; reduced to two under the Redistribution of Seats Act 1885; and ceased to be a separate constituency under the Representation of the People Act 1948. Since then the City is a minority (in terms of population and area) of the Cities of London and Westminster.\nThe City's population fell rapidly in the 19th century and through most of the 20th century, as people moved outwards in all directions to London's vast suburbs, and many residential buildings were demolished to make way for office blocks. Like many areas of London and other British cities, the City fell victim to large scale and highly destructive aerial bombing during World War II, especially in the Blitz. Whilst St Paul's Cathedral survived the onslaught, large swathes of the area did not and the particularly heavy raids of late December 1940 led to a firestorm called the Second Great Fire of London.\n\nThere was a major rebuilding programme in the decades following the war, in some parts (such as at the Barbican) dramatically altering the urban landscape. But the destruction of the older historic fabric allowed the construction of modern and larger-scale developments, whereas in those parts not so badly affected by bomb damage the City retains its older character of smaller buildings. The street pattern, which is still largely medieval, was altered slightly in places, although there is a more recent trend of reversing some of the post-war modernist changes made, such as at Paternoster Square.\n\nThe City suffered terrorist attacks including the 1993 Bishopsgate bombing and the 7 July 2005 London bombings. In response to the 1993 bombing, a system of road barriers, checkpoints and surveillance cameras referred to as the \"ring of steel\" has been maintained to control entry points to the City.\n\nThe 1970s saw the construction of tall office buildings including the 600-foot (183 m), 47-storey Natwest Tower, the first skyscraper in the UK. Office space development has intensified especially in the central, northern and eastern parts, with skyscrapers including 30 St. Mary Axe (\"the Gherkin\"'), Leadenhall Building (\"the Cheesegrater\"), 20 Fenchurch Street (\"the Walkie-Talkie\"), the Broadgate Tower and the Heron Tower, the tallest in the City. Another skyscraper, 22 Bishopsgate, is under construction.\n\nThe main residential section of the City today is the Barbican Estate, constructed between 1965 and 1976. The Museum of London is based there, as are a number of other services provided by the Corporation.\n\nThe City has a unique political status, a legacy of its uninterrupted integrity as a corporate city since the Anglo-Saxon period and its singular relationship with the Crown. Historically its system of government was not unusual, but it was not reformed by the Municipal Reform Act 1835 and little changed by later reforms.\n\nIt is administered by the City of London Corporation, headed by the Lord Mayor of London (\"not the same as the more recent Mayor of London\"), which is responsible for a number of functions and has interests in land beyond the City's boundaries. Unlike other English local authorities, the Corporation has two council bodies: the (now largely ceremonial) Court of Aldermen and the Court of Common Council. The Court of Aldermen represents the wards, with each ward (irrespective of size) returning one Alderman. The chief executive of the Corporation holds the ancient office of Town Clerk of London.\n\nThe City is a ceremonial county which has a Commission of Lieutenancy headed by the Lord Mayor instead of a Lord-Lieutenant and has two Sheriffs instead of a High Sheriff (see list of Sheriffs of London), quasi-judicial offices appointed by the Livery Companies, an ancient political system based on the representation and protection of trades (Guilds). Senior members of the Livery Companies are known as Liverymen and form the Common Hall, which chooses the Lord Mayor, the Sheriffs and certain other officers.\n\nThe City is made up of . They are survivors of the medieval government system that allowed a very local area to exist as a self-governing unit within the wider city. They can be described as electoral/political divisions; ceremonial, geographic and administrative entities; sub-divisions of the City. Each ward has an Alderman, who until the mid-1960s held office for life but since put themselves up for re-election at least every 6 years. Wards continue to have a Beadle, an ancient position which is now largely ceremonial whose main remaining function is the running of an annual Wardmote of electors, representatives and officials. At the Wardmote the ward's Alderman appoints at least one Deputy for the year ahead. Each ward also has a Ward Club, which is similar to a residents' association.\n\nThe wards are ancient and their number has changed three times since time immemorial\n\nFollowing boundary changes in 1994, and later reform of the business vote in the City, there was a major boundary and electoral representation revision of the wards in 2003, and they were reviewed again in 2010 for change in 2013, though not to such a dramatic extent. The review was conducted by senior officers of the Corporation and senior judges of the Old Bailey; the wards are reviewed by this process to avoid malapportionment. The procedure of review is unique in the United Kingdom as it is not conducted by the Electoral Commission or a local government boundary commission every 8 to 12 years, which is the case for all other wards in Great Britain. Particular churches, livery company halls and other historic buildings and structures are associated with a ward, such as St Paul's Cathedral with Castle Baynard, and London Bridge with Bridge; boundary changes in 2003 removed some of these historic connections.\n\nEach ward elects an Alderman to the Court of Aldermen, and Commoners (the City equivalent of a Councillor) to the Court of Common Council of the Corporation. Only electors who are Freemen of the City of London are eligible to stand. The number of Commoners a ward sends to the Common Council varies from two to ten, depending on the number of electors in each ward. Since the 2003 review it has been agreed that the four more residential wards: Portsoken, Queenhithe, Aldersgate and Cripplegate together elect 20 of the 100 Commoners, whereas the business-dominated remainder elect the remaining 80 Commoners. 2003 and 2013 boundary changes have increased the residential emphasis of the mentioned four wards.\n\nCensus data provides eight nominal rather than 25 real wards, all of varying size and population. Being subject to renaming and definition at any time, these census 'wards' are notable in that four of the eight wards accounted for 67% of the 'square mile' and held 86% of the population, and these were in fact similar to and named after four City of London wards:\n\nThe City has a unique electoral system. Most of its voters are representatives of businesses and other bodies that occupy premises in the City. Its ancient wards have very unequal numbers of voters. In elections, both the businesses based in the City and the residents of the City vote.\n\nThe City of London Corporation was not reformed by the Municipal Corporations Act 1835, because it had a more extensive electoral franchise than any other borough or city; in fact, it widened this further with its own equivalent legislation allowing one to become a freeman without being a liveryman. In 1801, the City had a population of about 130,000, but increasing development of the City as a central business district led to this falling to below 5,000 after the Second World War. It has risen slightly to around 9,000 since, largely due to the development of the Barbican Estate. In 2009, the business vote was about 24,000, greatly exceeding residential voters. As the City of London Corporation has not been affected by other municipal legislation over the period of time since then, its electoral practice has become increasingly anomalous. Uniquely for city or borough elections, its elections remain independent-dominated.\n\nThe business or \"non-residential vote\" was abolished in other UK local council elections by the Representation of the People Act 1969, but was preserved in the City of London. The principal reason given by successive UK governments for retaining this mechanism for giving businesses representation, is that the City is \"primarily a place for doing business\". About 330,000 non-residents constitute the day-time population and use most of its services, far outnumbering residents, who number around 7,000 (2011). By contrast, opponents of the retention of the business vote argue that it is a cause of institutional inertia.\n\nThe City of London (Ward Elections) Act 2002, a private Act of Parliament, reformed the voting system and greatly increased the business franchise, allowing many more businesses to be represented. Under the new system, the number of non-resident voters has doubled from 16,000 to 32,000. Previously disenfranchised firms (and other organisations) are entitled to nominate voters, in addition to those already represented, and all such bodies are now required to choose their voters in a representative fashion. Bodies employing fewer than ten people may appoint one voter; those employing ten to 50 people one voter for every five employees; those employing more than 50 people ten voters and one additional voter for each 50 employees beyond the first 50. The Act also removed other anomalies which had been unchanged since the 1850s.\n\nInner Temple and Middle Temple (which neighbour each other) are two of the few remaining liberties, an old name for a geographic division. They are independent extra-parochial areas, historically not governed by the City of London Corporation (and are today regarded as local authorities for most purposes) and equally outside the ecclesiastical jurisdiction of the Bishop of London. They are within the boundaries and liberties of the City, but can be thought of as independent enclaves. They are both part of Farringdon Without.\n\nWithin the City, the Corporation owns and runs both Smithfield Market and Leadenhall Market. It owns land beyond its boundaries, including open spaces (parks, forests and commons) in and around Greater London, including most of Epping Forest, Hampstead Heath. The Honourable The Irish Society, a body closely linked with the Corporation, also owns many public spaces in Northern Ireland. The Corporation owns Old Spitalfields Market and Billingsgate Fish Market, in the neighbouring London Borough of Tower Hamlets. It owns and helps fund the Old Bailey, the Central Criminal Court for England and Wales, as a gift to the nation, having begun as the City and Middlesex Sessions.\n\nThe City has its own independent police force, the City of London Police—the Common Council (the main body of the Corporation) is the police authority. The rest of Greater London is policed by the Metropolitan Police Service, based at New Scotland Yard.\n\nThe City has one hospital, St Bartholomew's Hospital, also known as 'Barts'. Founded in 1123, it is located at Smithfield, and is undergoing a long-awaited regeneration after doubts as to its continuing use during the 1990s.\n\nThe City is the third largest UK patron of the arts. It oversees the Barbican Centre and subsidises several important performing arts companies.\n\nThe London Port Health Authority, which is the responsibility of the Corporation, is responsible for all port health functions on the tidal part of the Thames, including various seaports and London City Airport. The Corporation oversees the running of the Bridge House Trust, which maintains London Bridge, Blackfriars Bridge, Southwark Bridge, Tower Bridge and the Millennium Bridge. The City's flag flies over Tower Bridge, although neither footing is in the City.\n\nThe size of the City was constrained by a defensive perimeter wall, known as London Wall, which was built by the Romans in the late 2nd century to protect their strategic port city. However the boundaries of the City of London no longer coincide with the old city wall, as the City expanded its jurisdiction slightly over time. During the medieval era, the City's jurisdiction expanded westwards, crossing the historic western border of the original settlement—the River Fleet—along Fleet Street to Temple Bar. The City also took in the other \"City bars\" which were situated just beyond the old walled area, such as at Holborn, Aldersgate, Bishopsgate and Aldgate. These were the important entrances to the City and their control was vital in maintaining the City's special privileges over certain trades.\nMost of the wall has disappeared, but several sections remain visible. A section near the Museum of London was revealed after the devastation of an air raid on 29 December 1940 at the height of the Blitz. Other visible sections are at St Alphage, and there are two sections near the Tower of London. The River Fleet was canalised after the Great Fire of 1666 and then in stages was bricked up and has been since the 18th century one of London's \"lost rivers or streams\", today underground as a storm drain.\n\nThe boundary of the City was unchanged until minor boundary changes on 1 April 1994, when it expanded slightly to the west, north and east, taking small parcels of land from the London Boroughs of Westminster, Camden, Islington, Hackney and Tower Hamlets. The main purpose of these changes was to tidy up the boundary where it had been rendered obsolete by changes in the urban landscape. In this process the City also lost small parcels of land, though there was an overall net gain (the City grew from 1.05 to 1.12 square miles). Most notably, the changes placed the (then recently developed) Broadgate estate entirely in the City.\n\nSouthwark, to the south of the City on the other side of the Thames, was within the City between 1550 and 1899 as the \"Ward of Bridge Without\", a situation connected with the Guildable Manor. The City's administrative responsibility there had in practice disappeared by the mid-Victorian period as various aspects of metropolitan government were extended into the neighbouring areas. Today it is part of the London Borough of Southwark. The Tower of London has always been outside the City and comes under the London Borough of Tower Hamlets.\n\nThe Corporation of the City of London has a full achievement of armorial bearings consisting of a shield on which the arms are displayed, a crest displayed on a helm above the shield, supporters on either side and a motto displayed on a scroll beneath the arms.\n\nThe coat of arms is \"anciently recorded\" at the College of Arms. The arms consist of a silver shield bearing a red cross with a red upright sword in the first quarter. They combine the emblems of the patron saints of England and London: the Cross of St George with the symbol of the martyrdom of Saint Paul. The sword is often erroneously supposed to commemorate the killing of Peasants' Revolt leader Wat Tyler by Lord Mayor of London William Walworth. However the arms were in use some months before Tyler's death, and the tradition that Walworth's dagger is depicted may date from the late 17th century.\n\nThe Latin motto of the City is \"\"Domine dirige nos\"\", which translates as \"\"Lord, direct (guide) us\"\". It appears to have been adopted in the 17th century, as the earliest record of it is in 1633.\n\nA banner of the arms (the design on the shield) is flown as a flag.\n\nThe City is England's smallest ceremonial county by area and population, and the fourth most densely populated. Of the 326 English districts, it is the second smallest by population, after the Isles of Scilly, and the smallest by area. It is also the smallest English city by population (and in Britain, only two cities in Wales are smaller).\n\nThe elevation of the City ranges from sea level at the Thames to at the junction of High Holborn and Chancery Lane. Two small but notable hills are within the historic core, Ludgate Hill to the west and Cornhill to the east. Between them ran the Walbrook, one of the many \"lost\" rivers or streams of London (another is the Fleet).\n\nOfficial boundary map, with wards.\n\nBeginning in the west, where the City borders Westminster, the boundary crosses the Victoria Embankment from the Thames, passes to the west of Middle Temple, then turns for a short distance along Strand and then north up Chancery Lane, where it borders Camden. It turns east along Holborn to Holborn Circus, and then goes north east to Charterhouse Street. As it crosses Farringdon Road it becomes the boundary with Islington. It continues to Aldersgate, goes north, and turns east into some back streets soon after Aldersgate becomes Goswell Road, since 1994 embracing all of the Corporation's Golden Lane Estate. Here, at Baltic Street West, is the most northerly extent. The boundary includes all of the Barbican Estate and continues east along Ropemaker Street and its continuation on the other side of Moorgate, becomes South Place. It goes north, reaching the border with Hackney, then east, north, east on back streets, with Worship Street forming a northern boundary, so as to include the Broadgate estate. The boundary then turns south at Norton Folgate and becomes the border with Tower Hamlets. It continues south into Bishopsgate, and takes some backstreets to Middlesex Street (Petticoat Lane) where it continues south-east then south. It then turns south-west, crossing the Minories so as to exclude the Tower of London, and then reaches the river. It then runs up the centre of the Thames, with the exception that Blackfriars Bridge falls within the City; the City controls London Bridge (as part of Bridge ward) but only half of the river underneath it, a feature which is unique in British local administration.\n\nThe boundaries are marked by black bollards bearing the City's emblem, and by dragon boundary marks at major entrances, such as Holborn. A more substantial monument marks the boundary at Temple Bar on Fleet Street.\n\nIn some places the financial district extends slightly beyond the boundaries, notably to the north and east, into the London Boroughs of Tower Hamlets, Hackney and Islington, and informally these locations are seen as part of the \"Square Mile\". Since the 1990s the eastern fringe, extending into Hackney and Tower Hamlets, has increasingly been a focus for large office developments due to the availability of large sites compared to within the City.\n\nThe City has no sizeable parks within its boundary, but does have a network of a large number of gardens and small open spaces, many of them maintained by the Corporation. These range from formal gardens such as the one in Finsbury Circus, containing a bowling green and bandstand, to churchyards such as St Olave Hart Street, to water features and artwork in courtyards and pedestrianised lanes.\n\nGardens include:\n\nThere are a number of private gardens and open spaces, often within courtyards of the larger commercial developments. Two of the largest are those of the Inner Temple and Middle Temple Inns of Court, in the far southwest.\n\nThe Thames and its riverside walks are increasingly being valued as open space and in recent years efforts have been made to increase the ability for pedestrians to access and walk along the river.\n\nThe nearest weather station has historically been the London Weather Centre at Kingsway/ Holborn, although observations ceased in 2010. Now St. James Park provides the nearest official readings.\n\nThe City has an oceanic climate (Köppen \"Cfb\") modified by the Urban Heat Island in the centre of London. This generally causes higher night-time minima than outlying areas. For example, the August mean minimum of compares to a figure of for Greenwich and Heathrow whereas is at Wisley in the middle of several square miles of Metropolitan Green Belt. All figures refer to the observation period 1971–2000.\n\nAccordingly, the weather station holds the record for the UK's warmest overnight minimum temperature, , recorded on 4 August 1990. The maximum is , set on 10 August 2003. The absolute minimum for the weather station is a mere , compared to readings around towards the edges of London. Unusually, this temperature was during a windy and snowy cold spell (mid-January 1987), rather than a cold clear night—cold air drainage is arrested due to the vast urban area surrounding the city.\n\nThe station holds the record for the highest British mean monthly temperature, (mean maximum , mean minimum during July 2006). However, in terms of daytime maximum temperatures, Cambridge NIAB and Botanical Gardens with a mean maximum of , and Heathrow with all exceeded this.\n\nThe City is a police area and has its own police force, the City of London Police, separate from the Metropolitan Police Service covering the remainder of Greater London. The City Police have three police stations, at Snow Hill, Wood Street and Bishopsgate, and has 813 police officers, 85 Special Constables and 48 PCSOs. It is the smallest territorial police force in England and Wales, in both geographic area and the number of police officers.\n\nWhere the majority of British police forces have silver-coloured badges, those of the City Police are black and gold featuring the City crest. The force has unique red and white chequered cap bands and red and white striped duty arm bands on the sleeve of the tunics of constables and sergeants (red and white being the colours of the City), which in most other British police forces are black and white. City police sergeants and constables wear crested helmets whilst on foot patrol. These helmets do not feature either St Edward's Crown or the Brunswick Star, which are used on most other police helmets in England and Wales.\n\nThe City's position as the United Kingdom's financial centre and a critical part of the country's economy, contributing about 2.5% of the UK's gross national product, has resulted in it becoming a target for political violence. The Provisional IRA exploded several bombs in the early 1990s, including the 1993 Bishopsgate bombing.\n\nThe area is also spoken of as a possible target for al-Qaeda. For instance, when in May 2004 the BBC's \"Panorama\" programme examined the preparedness of Britain's emergency services for a terrorist attack on the scale of September 11, 2001 attacks, they simulated a chemical explosion on Bishopsgate in the east of the City.\n\nThe \"Ring of Steel\" is a particularly notable measure, established in the wake of the IRA bombings, that has been taken against terrorist threats.\n\nThe City has fire risks in many historic buildings, including St Paul's Cathedral, Old Bailey, Mansion House, Smithfield Market, the Guildhall, and also in numerous high-rise buildings. There is one London Fire Brigade station in the City, at Dowgate, with one pumping appliance. The City relies upon stations in the surrounding London boroughs to support it at some incidents. The first fire engine is in attendance in roughly five minutes on average, the second when required in a little over five and a half minutes. There were 1,814 incidents attended in the City in 2006/2007—the lowest in Greater London. No-one died in an event arising from a fire in the four years prior to 2007.\n\nThe Office for National Statistics recorded the population in 2011 as 7,000; approximately the same as that in the last census, 2001. At the 2001 census the ethnic composition was 84.6% White, 6.8% South Asian, 2.6% Black, 2.3% Mixed, 2.0% Chinese and 1.7% were listed as \"other\". To the right is a graph showing the change in population since 1801, based on decadal censuses. The first half of the 19th century shows a population of between 120,000–140,000, decreasing dramatically from 1851 to 1991, with a small increase between 1991 and 2001. The only notable boundary change since the first census in 1801 occurred in 1994.\n\nThe City's full-time working residents have much higher gross weekly pay than in London and Great Britain (England, Wales and Scotland): £773.30 compared to £598.60 and £491.00 respectively. There is a large inequality of income between genders (£1,085.90 in men compared to £653.50 in women). The 2001 Census showed the City as a unique district amongst 376 districts surveyed in England and Wales. The City had the highest proportional population increase, one-person households, people with qualifications at degree level or higher and the highest indications of overcrowding. It recorded the lowest proportion of households with cars or vans, people who travel to work by car, married couple households and the lowest average household size: just 1.58 people. It also ranked highest within the Greater London area for the percentage of people with no religion and people who are employed.\n\nThe City vies with New York City as the financial capital of the world; many banking and insurance institutions have their headquarters there. The London Stock Exchange (shares and bonds), Lloyd's of London (insurance) and the Bank of England are all based in the City. Over 500 banks have offices in the City, and the City is an established leader in trading in Eurobonds, foreign exchange, energy futures and global insurance. The Alternative Investment Market, a market for trades in equities of smaller firms, is a recent development. In 2009, the City of London accounted for 2.4% of UK GDP.\n\nLondon is the world's greatest foreign exchange market, with much of the trade conducted in the City of London. Of the $3.98 trillion daily global turnover, as measured in 2009, trading in London accounted for around $1.85 trillion, or 46.7% of the total. The pound sterling, the currency of the United Kingdom, is globally the fourth most traded currency and the third most held reserve currency.\n\nSince 1991 Canary Wharf, a few miles east of the City in Tower Hamlets, has become another centre for London's financial services industry which houses many banks and other institutions formerly located in the Square Mile. Although growth has continued in both locations, and there have been relocations in both directions, the Corporation has come to realise that its planning policies may have been causing financial firms to choose Canary Wharf as a location.\n\nMany major global companies have their headquarters in the City, including Aviva, BT Group, Lloyds Banking Group, Old Mutual, Prudential, Schroders, Standard Chartered, and Unilever.\n\nA number of the world's largest law firms are headquartered in the City, including Allen & Overy, Freshfields Bruckhaus Deringer, DLA Piper, Herbert Smith Freehills, Hogan Lovells, Linklaters, Eversheds and Slaughter and May.\n\nWhilst the financial sector, and related businesses and institutions, continue to dominate, the economy is not limited to that sector. The legal profession has a strong presence, especially in the west and north (i.e., towards the Inns of Court). Retail businesses were once important, but have gradually moved to the West End of London, though it is now Corporation policy to encourage retailing in some locations, for example at Cheapside near St Paul's. The City has a number of visitor attractions, mainly based on its historic heritage as well as the Barbican Centre and adjacent Museum of London, though tourism is not at present a major contributor to the City's economy or character. The City has many pubs, bars and restaurants, and the \"night-time\" economy does feature in the Bishopsgate area, towards Shoreditch. The meat market at Smithfield, wholly within the City, continues to be one of London's main markets (the only one remaining in central London) and the country's largest meat market. In the east is Leadenhall Market, a fresh food market that is also a visitor attraction.\n\nThe trend for purely office development is beginning to reverse as the Corporation encourages residential use, albeit with development occurring when it arises on windfall sites. The City has a target of 90 additional dwellings per year. Some of the extra accommodation is in small pre-World War II listed buildings, which are not suitable for occupation by the large companies which now provide much of the City's employment. Recent residential developments include \"the Heron\", a high-rise residential building on the Milton Court site adjacent to the Barbican, and the Heron Plaza development on Bishopsgate is also expected to include residential parts.\n\nSince the 1990s, the City has diversified away from near exclusive office use in other ways. For example, several hotels and the first department store opened in the 2000s. A shopping centre was more recently opened at One New Change, Cheapside (near St Paul's Cathedral) in October 2010, which is open seven days a week. However, large sections remain quiet at weekends, especially in the eastern section, and it is quite common to find shops, pubs and cafes closed on these days.\n\nFire, bombing and post-World War II redevelopment has meant that the City, despite its history, has relatively few intact notable historic structures. They include the Monument to the Great Fire of London (\"the Monument\"), St Paul's Cathedral, the Guildhall, the Royal Exchange, Dr. Johnson's House, Mansion House and a , many designed by Sir Christopher Wren, who also designed St Paul's. 2 King's Bench Walk and Prince Henry's Room are notable historic survivors of heavy bombing of the Temple area, which has largely been rebuilt to its historic form. Another example of a bomb-damaged place having been restored is Staple Inn on Holborn. A few small sections of the Roman London Wall exist, for example near the Tower of London and in the Barbican area. Among the twentieth-century listed buildings are Bracken House, the first post World War II buildings in the country to be given statutory protection, and the whole of the Barbican and Golden Lane Estate.\n\nThe Tower of London is not in the City, but is a notable visitor attraction which brings tourists to the southeast of the City. Other landmark buildings with historical significance include the Bank of England, the Old Bailey, the Custom House, Smithfield Market, Leadenhall Market and St Bartholomew's Hospital. Noteworthy contemporary buildings include a number of modern high-rise buildings (see section below) as well as the Lloyd's building.\n\n\nA growing number of tall buildings and skyscrapers are principally used by the financial sector. Almost all are situated in the eastern side around Bishopsgate, Leadenhall Street and Fenchurch Street, in the financial core of the City. In the north there is a smaller cluster comprising the Barbican Estate's three tall residential towers and the commercial CityPoint tower. In 2007, the tall Drapers' Gardens building was demolished and replaced by a shorter tower.\n\nThe City's buildings of more than in height are:\n\nThe timeline of the tallest building in the City is as follows:\n\nSeven of the eleven London Underground lines run through the City, serving eleven stations.\n\nThe Docklands Light Railway (DLR) has two stations within the City: Bank and Tower Gateway.\n\nThree longer-distance rail termini are in the City: Liverpool Street (services primarily to Essex and East Anglia including Southend Airport), Fenchurch Street (services to East London and South Essex) and Cannon Street (services to the South).\n\nMoorgate is the terminus for suburban services from Hertfordshire, and two through-routes operate mostly underground along the main axes:\n\nThe Northern line connects to two other main railway termini, Euston) and (Waterloo)); the latter has a direct connection to the City via the Waterloo and City Line.\n\nThe City is in Travelcard Zone 1.\n\nThe national A1, A10 A3, A4, and A40 road routes begin in the City. The City is in the London congestion charge zone, with the small exception on the eastern boundary of the sections of the A1210/A1211 that are part of the inner ring road. The following bridges, listed west to east (downstream), cross the River Thames: Blackfriars Bridge, Blackfriars Railway Bridge, Millennium Bridge (footbridge), Southwark Bridge, Cannon Street Railway Bridge and London Bridge; Tower Bridge is not in the City. The City, like most of central London, is well served by buses, including night buses. Two bus stations are in the City, at Aldgate on the eastern boundary with Tower Hamlets, and at Liverpool Street by the railway station. There are approximately 28 Barclays Cycle Hire docking stations in the City. A number of existing and proposed cycle routes criss-cross the City, as part of the London Cycle Network.\n\nOne London River Services pier is on the Thames in the City, Blackfriars Millennium Pier, though the Tower Millennium Pier lies adjacent to the boundary near the Tower of London. One of the Port of London's 25 safeguarded wharves, Walbrook Wharf, is adjacent to Cannon Street station, and is used by the Corporation to transfer waste via the river. Swan Lane Pier, just upstream of London Bridge, is proposed to be replaced and upgraded for regular passenger services, planned to take place in 2012–2015. Before then, Tower Pier is to be extended.\n\nThere is a public riverside walk along the river bank, opened in stages over recent years. The only section not running along the river is a short stretch at Queenhithe. The walk along Walbrook Wharf is closed to pedestrians when waste is being transferred onto barges.\n\nAccording to a survey conducted in March 2011, the methods by which employed residents 16-74 get to work varied widely: 48.4% go on foot; 19.5% via light rail, (i.e. the Underground, DLR, etc.); 9.2% work mainly from home; 5.8% take the train; 5.6% travel by bus, minibus, or coach; and 5.3% go by bicycle; with just 3.4% commuting by car or van, as driver or passenger.\n\nThe City has only one directly maintained primary school, Sir John Cass's Foundation Primary School at Aldgate (ages 4 to 11). It is a Voluntary-Aided (VA) Church of England school, maintained by the Education Service of the City of London.\n\nCity residents send their children to schools in neighbouring Local Education Authorities, such as Islington, Tower Hamlets, Westminster and Southwark.\n\nThe City controls three independent schools, City of London School (a boys' school) and City of London School for Girls in the City, and the City of London Freemen's School (co-educational day and boarding) in Ashtead, Surrey. The City of London School for Girls has its own preparatory department for entrance at age seven. It is the principal sponsor of The City Academy, Hackney, City of London Academy, Islington, and City of London Academy, Southwark.\n\nThe City is home to the Cass Business School, The London Institute of Banking & Finance, the Guildhall School of Music and Drama and parts of three of the universities in London: the Maughan Library of King's College London on Chancery Lane, the business school of London Metropolitan University, and a campus of the University of Chicago Graduate School of Business. The College of Law has its London campus in Moorgate. Part of Barts and The London School of Medicine and Dentistry is on the Barts hospital site at West Smithfield.\n\nLibraries operated by the Corporation include three lending libraries; Barbican Library, Shoe Lane Library and Artizan Street Library and Community Centre. Membership is open to all – with one official proof of address required to join.\n\nGuildhall Library, and City Business Library are also public reference libraries, specialising in the history of London and business reference resources.\n\nAuthor and journalist Nicholas Shaxson argued that, in return for raising loans and finance for the British government, the City \"has extracted privileges and freedoms from rules and laws to which the rest of Britain must submit\". He further claims that the assistance provided to the institutions based within it, many of which help their rich clients with offshore tax arrangements, mean that the City is \"a tax haven in its own right\".\n\n"}
{"id": "6884", "url": "https://en.wikipedia.org/wiki?curid=6884", "title": "Clitoris", "text": "Clitoris\n\nThe clitoris ( or ) is a female sex organ present in mammals, ostriches and a limited number of other animals. In humans, the visible button-like portion is near the front junction of the labia minora (inner lips), above the opening of the urethra. Unlike the penis, the male homologue (equivalent) to the clitoris, it usually does not contain the distal portion (or opening) of the urethra and is therefore not used for urination. While few animals urinate through the clitoris, the spotted hyena, which has an especially well-developed clitoris, urinates, mates and gives birth via the organ. Some other mammals, such as lemurs and spider monkeys, also have a well-developed clitoris.\n\nThe clitoris is the human female's most sensitive erogenous zone and generally the primary anatomical source of human female sexual pleasure. In humans and other mammals, it develops from an outgrowth in the embryo called the genital tubercle. Initially undifferentiated, the tubercle develops into either a penis or a clitoris, depending on the presence or absence of the protein tdf, which is codified by a single gene on the Y chromosome. The clitoris is a complex structure, and its size and sensitivity can vary. The glans (head) of the human clitoris is roughly the size and shape of a pea, and is estimated to have more than 8,000 sensory nerve endings.\n\nExtensive sociological, sexological and medical debate have focused on the clitoris, primarily concerning anatomical accuracy, orgasmic factors and their physiological explanation for the G-spot, and whether the clitoris is vestigial, an adaptation, or serves a reproductive function. Social perceptions of the clitoris range from the significance of its role in female sexual pleasure, assumptions about its true size and depth, and varying beliefs regarding genital modification such as clitoris enlargement, clitoris piercing and clitoridectomy. Genital modification may be for aesthetic, medical or cultural reasons.\n\nKnowledge of the clitoris is significantly impacted by cultural perceptions of the organ. Studies suggest that knowledge of its existence and anatomy is scant in comparison with that of other sexual organs, and that more education about it could help alleviate social stigmas associated with the female body and female sexual pleasure; for example, that the clitoris and vulva in general are visually unappealing, that female masturbation is taboo, or that men should be expected to master and control women's orgasms.\n\nThe \"Oxford English Dictionary\" states that the word \"clitoris\" likely has its origin in the Ancient Greek , \"kleitoris\", perhaps derived from the verb , \"kleiein\", \"to shut\". \"Clitoris\" is also Greek for the word \"key\", \"indicating that the ancient anatomists considered it the key\" to female sexuality. In addition to \"key,\" the \"Online Etymology Dictionary\" suggests other Greek candidates for the word's etymology include a noun meaning \"latch\" or \"hook\"; a verb meaning \"to touch or titillate lasciviously\", \"to tickle\" (one German synonym for the clitoris is \"der Kitzler\", \"the tickler\"), although this verb is more likely derived from \"clitoris\"; and a word meaning \"side of a hill\", from the same root as \"climax\". The \"Oxford English Dictionary\" also states that the shortened form \"clit\", the first occurrence of which was noted in the United States, has been used in print since 1958: until then, the common abbreviation was \"clitty\".\n\nThe plural forms are \"clitorises\" in English and \"clitorides\" in Latin. The Latin genitive is \"clitoridis\", as in \"glans clitoridis\". In medical and sexological literature, the clitoris is sometimes referred to as \"the female penis\" or pseudo-penis, and the term \"clitoris\" is commonly used to refer to the glans alone; partially because of this, there have been various terms for the organ that have historically confused its anatomy (see below).\n\nIn mammals, sexual differentiation is determined by the sperm that carries either an X or a Y (male) chromosome. The Y chromosome contains a sex-determining gene (SRY) that encodes a transcription factor for the protein tdf (testis determining factor) and triggers the creation of testosterone and Anti-Müllerian hormone for the embryo's development into a male. This differentiation begins about eight or nine weeks after conception. Some sources state that it continues until the twelfth week, while others state that it is clearly evident by the thirteenth week and that the sex organs are fully developed by the sixteenth week.\n\nThe clitoris develops from a phallic outgrowth in the embryo called the genital tubercle. Initially undifferentiated, the tubercle develops into either a clitoris or penis during development of the reproductive system depending on exposure to androgens (primarily male hormones). The clitoris forms from the same tissues that become the glans and upper shaft of the penis, and this shared embryonic origin makes these two organs homologous (different versions of the same structure).\n\nIf exposed to testosterone, the genital tubercle elongates to form the penis. By fusion of the urogenital folds – elongated spindle-shaped structures that contribute to the formation of the urethral groove on the belly aspect of the genital tubercle – the urogenital sinus closes completely and forms the spongy urethra, and the labioscrotal swellings unite to form the scrotum. In the absence of testosterone, the genital tubercle allows for formation of the clitoris; the initially rapid growth of the phallus gradually slows and the clitoris is formed. The urogenital sinus persists as the vestibule of the vagina, the two urogenital folds form the labia minora, and the labioscrotal swellings enlarge to form the labia majora, completing the female genitalia. A rare condition that can develop from higher than average androgen exposure is clitoromegaly.\n\nThe clitoris is a complex structure, containing external and internal components. It consists of the glans (including the frenulum of clitoris, which is a frenulum on the under-surface of the glans and is created by the two medial parts of the labia minora), the clitoral body (which is composed of two erectile bodies known as the corpora cavernosa), two clitoral crura, the clitoral hood (formed by the labia minora) and the vestibular or clitoral bulbs. The clitoral body is commonly referred to as the shaft (or internal shaft), while the length of the clitoris between the glans and the body may also be referred to as the shaft (or external shaft) because, like the shaft as a whole, it supports the glans, and its shape can be seen and felt through the clitoral hood.\n\nResearch indicates that clitoral tissue extends into the vagina's anterior wall. Şenaylı et al. said that the histological evaluation of the clitoris, \"especially of the corpora cavernosa, is incomplete because for many years the clitoris was considered a rudimentary and nonfunctional organ.\" They added that Baskin and colleagues examined the clitoris's masculinization after dissection and, using imaging software after Masson chrome staining, put the serial dissected specimens together; this revealed that the nerves of the clitoris surround the whole clitoral body (corpus).\n\nThe clitoris, vestibular bulbs, labia minora, and urethra involve two histologically distinct types of vascular tissue (tissue related to blood vessels), the first of which is trabeculated, erectile tissue. The trabeculated tissue has a spongy appearance; along with blood, it fills the large, dilated vascular spaces of the clitoris and the bulbs. Beneath the epithelium of the vascular areas is smooth muscle. It may also be that the urethral lumen (the inner open space or cavity of the urethra), which is surrounded by spongy tissue, has tissue that \"is grossly distinct from the vascular tissue of the clitoris and bulbs, and on macroscopic observation, is paler than the dark tissue\" of the clitoris and bulbs.\n\nThe second type of vascular tissue is non-erectile. Although the clitoral body becomes engorged with blood upon sexual arousal, erecting the clitoral glans, some sources describe the clitoral glans and labia minora as composed of non-erectile tissue; this is especially the case for the glans. They state that the clitoral glans and labia minora have blood vessels that are dispersed within a fibrous matrix and have only a minimal amount of smooth muscle, or that the clitoral glans is \"a midline, densely neural, non-erectile structure\". Other sources state that the glans is composed of erectile tissue and that erectile tissue is present within the labia minora; adipose tissue is absent in the labia minora, but the organ may be described as being made up of dense connective tissue, erectile tissue and elastic fibers.\n\nYang et al. are among the researchers who challenge the notion that the glans is not formed of erectile tissue, stating that their dissections clearly show glanular vascular spaces, although not as prominent as those in the clitoral body. \"The erectile tissue of the glans is slightly different from that of the body and crura. The vascular spaces are separated more by smooth muscle than in the body and crura,\" they concluded. They stated that there is a thick layer of tissue that supports the tissue between the epithelium and vascular spaces and that \"there is a dense distribution of nerves and sensory receptors\" in the epithelium and supporting tissue.\n\nHighly innervated, the glans exists at the tip of the clitoral body as a fibro-vascular cap, and is usually the size and shape of a pea, although it is sometimes much larger or smaller. While whether or not the glans is composed of erectile or non-erectile tissue is subject to debate (see above), it, or the entire clitoris, is estimated to have 8,000 or more sensory nerve endings.\nThe clitoral body forms a wishbone-shaped structure containing the corpora cavernosa – a pair of sponge-like regions of erectile tissue which contain most of the blood in the clitoris during clitoral erection. The two corpora forming the clitoral body are surrounded by thick fibro-elastic tunica albuginea, literally meaning \"white covering\", connective tissue. These corpora are separated incompletely from each other in the midline by a fibrous pectiniform septum – a comblike band of connective tissue extending between the corpora cavernosa.\n\nThe clitoral body extends up to several centimeters before reversing direction and branching, resulting in an inverted \"V\" shape that extends as a pair of crura (\"legs\"). The crura are the proximal portions of the arms of the wishbone. Ending at the glans of the clitoris, the tip of the body bends anteriorly away from the pubis. Each crus (singular form of crura) is attached to the corresponding ischial ramus – extensions of the copora beneath the descending pubic rami. Concealed behind the labia minora, the crura end with attachment at or just below the middle of the pubic arch. Associated are the urethral sponge, perineal sponge, a network of nerves and blood vessels, the suspensory ligament of the clitoris, muscles and the pelvic floor.\n\nThere is no identified correlation between the size of the clitoral glans, or clitoris as a whole, and a woman's age, height, weight, use of hormonal contraception, or being post-menopausal, although women who have given birth may have significantly larger clitoral measurements. Centimeter (cm) and millimeter (mm) measurements of the clitoris show variations in its size. The adult clitoral glans usually has a width less than 1 cm, with an average length of 1.5 to 2 cm. A 1992 study gives clitoral glans widths of , with the average size smaller than a pencil-top eraser. The study concluded that the total clitoral length, including glans and body, is .\n\nConcerning other studies, researchers from the Elizabeth Garrett Anderson and Obstetric Hospital in London measured the labia and other genital structures of 50 women from the age of 18 to 50, with a mean age of 35.6., from 2003 to 2004, and the results given for the clitoral glans were 3–10 mm for the range and 5.5 [1.7] mm for the mean. Other research indicates that the clitoral body can measure in length, while the clitoral body and crura together can be or more in length.\n\nThe clitoral hood projects at the front of the labia commissure, where the edges of the labia majora (outer lips) meet at the base of the pubic mound; it forms as part of the external folds of the labia minora (inner lips) and covers the glans and external shaft. There is considerable variation in how much of the glans protrudes from the hood and how much is covered by it, ranging from completely covered to fully exposed, and tissue of the labia minora also encircles the base of the glans.\n\nThe vestibular bulbs are more closely related to the clitoris than the vestibule because of the similarity of the trabecular and erectile tissue within the clitoris and bulbs, and the absence of trabecular tissue in other genital organs, with the erectile tissue's trabecular nature allowing engorgement and expansion during sexual arousal. The vestibular bulbs lie close to the crura on either side of the vaginal opening; internally, they are beneath the labia majora. When engorged with blood, they cuff the vaginal opening and cause the vulva to expand outward. Though some texts state that they surround the vaginal opening, this does not appear to be the case and tunica albuginea does not envelop the erectile tissue of the bulbs. In Yang et al.'s assessment of the bulbs' anatomy, they conclude that the bulbs \"arch over the distal urethra, outlining what might be appropriately called the 'bulbar urethra' in women.\"\n\nThe clitoris and penis are generally the same anatomical structure, although the distal portion (or opening) of the urethra is absent in the clitoris of humans and most other animals. The idea that males have clitorises was suggested in 1987 by researcher Josephine Lowndes Sevely, who theorized that the male corpora cavernosa (a pair of sponge-like regions of erectile tissue which contain most of the blood in the penis during penile erection) are the true counterpart of the clitoris. She argued that \"the male clitoris\" is directly beneath the rim of the glans penis, where the frenulum of prepuce of the penis (a fold of the prepuce) is located, and proposed that this area be called the \"Lownde's crown.\" Her theory and proposal, though acknowledged in anatomical literature, did not materialize in anatomy books. Modern anatomical texts instead show that the clitoris displays a hood that is the equivalent of the penis's foreskin, which covers the glans, and a shaft that is attached to the glans; the male corpora cavernosa are homologous to the corpus cavernosum clitoridis (the female cavernosa); the corpus spongiosum is homologous to the vestibular bulbs beneath the labia minora, and the scrotum is homologous to the labia minora and labia majora.\n\nUpon anatomical study, the penis can be described as a clitoris that has been mostly pulled out of the body and grafted on top of a significantly smaller piece of spongiosum containing the urethra. With regard to nerve endings, the human clitoris's estimated 8,000 or more (for its glans or clitoral body as a whole) is commonly cited as being twice as many as the nerve endings found in the human penis (for its glans or body as a whole), and as more than any other part of the human body. These reports sometimes conflict with other sources on clitoral anatomy or those concerning the nerve endings in the human penis. For example, while some sources estimate that the human penis has 4,000 nerve endings, other sources state that the glans or the entire penile structure have the same amount of nerve endings as the clitoral glans, or discuss whether the uncircumcised penis has thousands more than the circumcised penis or is generally more sensitive.\n\nSome sources state that in contrast to the glans penis, the clitoral glans lacks smooth muscle within its fibrovascular cap and is thus differentiated from the erectile tissues of the clitoris and bulbs; additionally, bulb size varies and may be dependent on age and estrogenization. Though the bulbs are considered the equivalent of the male spongiosum, they do not completely encircle the urethra.\n\nThe thin corpus spongiosum of the penis runs along the underside of the penile shaft, enveloping the urethra, and expands at the end to form the glans. It partially contributes to erection, which are primarily caused by the two corpora cavernosa that comprise the bulk of the shaft; like the female cavernosa, the male cavernosa soak up blood and become erect when sexually excited. The male corpora cavernosa taper off internally on reaching the spongiosum head. With regard to the Y-shape of the cavernosa – crown, body, and legs – the body accounts for much more of the structure in men, and the legs are stubbier; typically, the cavernosa are longer and thicker in males than in females.\n\nThe abundance of nerve endings in the clitoris, the majority of which exist specifically for sexual enjoyment, make it the human female's most sensitive erogenous zone and generally the primary anatomical source of human female sexual pleasure. Sexual stimulation of the clitoris can produce female sexual arousal and orgasm, and may be achieved by masturbation or with a sexual partner. The most effective sexual stimulation of the organ is usually through manual or oral stimulation (cunnilingus), often referred to as direct clitoral stimulation; in cases involving sexual penetration, these activities may also be referred to as additional or assisted clitoral stimulation.\n\nDirect clitoral stimulation involves physical stimulation to the external anatomy of the clitoris – glans, hood and the external shaft. Stimulation of the labia minora (inner lips), due to its external connection with the glans and hood, may have the same effect as direct clitoral stimulation. Though these areas may also receive indirect physical stimulation during sexual activity, such as when in friction with the labia majora (outer lips), indirect clitoral stimulation is more commonly attributed to penile-vaginal penetration. Penile-anal penetration may also indirectly stimulate the clitoris, either by the shared sensory nerves (especially the pudendal nerve, which gives off the inferior anal nerves and divides into two terminal branches: the perineal nerve and the dorsal nerve of the clitoris) or by the crura (\"legs\").\n\nDue to the glans's high sensitivity, direct stimulation to it is not always pleasurable; instead, direct stimulation to the hood or the areas near the glans are often more pleasurable, with the majority of females preferring to use the hood to stimulate the glans, or to have the glans rolled between the lips of the labia, for indirect touch. It is also common for women to \"enjoy a light caressing of the shaft of the clitoris\" combined with the occasional circling of the clitoral glans, with or without manual penetration of the vagina, while other women enjoy having the entire area of the vulva caressed. As opposed to use of dry fingers, stimulation from fingers that have been well-lubricated, either by vaginal lubrication or a personal lubricant, is usually more pleasurable for the external anatomy of the clitoris.\n\nAs the clitoris's external location does not allow for direct stimulation by sexual penetration, any external clitoral stimulation while in the missionary position usually results from the pubic bone area, the movement of the groins when in contact. As such, some couples may engage in the woman-on-top position or the coital alignment technique, a technique combining the \"riding high\" variation of the missionary position with pressure-counterpressure movements performed by each partner in rhythm with sexual penetration, to maximize clitoral stimulation. Lesbian couples may engage in tribadism for ample clitoral stimulation or for mutual clitoral stimulation during whole-body contact. Pressing the penis or a dildo in a gliding or circular motion against the clitoris (intercrural sex), or stimulating it by movement against another body part, during any number of sex positions, may also be practiced. A vibrator, or specifically a clitoral vibrator, or other sex toys, may be used during or absent of any of the aforementioned practices. Other women stimulate the clitoris by use of a pillow or other inanimate object, by a jet of water from the faucet of a bathtub or shower, or by closing their legs and rocking.\n\nDuring sexual arousal, the clitoris and the whole of the genitalia engorge and change color as the erectile tissues fill with blood (vasocongestion), and the individual experiences vaginal contractions. The ischiocavernosus and bulbocavernosus muscles, which insert into the corpora cavernosa, contract and compress the dorsal vein of the clitoris (the only vein that drains the blood from the spaces in the corpora cavernosa) and the arterial blood continues a steady flow and, having no way to drain out, fills the venous spaces until they become turgid and engorged with blood. This is what leads to clitoral erection.\n\nThe clitoral glans doubles in diameter upon arousal, and, upon further stimulation, it becomes less visible as it is covered by the swelling of tissues of the clitoral hood. The swelling protects the glans from direct contact, as direct contact at this stage can be more irritating than pleasurable. Vasocongestion eventually triggers a muscular reflex, which expels the blood that was trapped in surrounding tissues, and leads to an orgasm. A short time after stimulation has stopped, especially if orgasm has been achieved, the glans becomes visible again and returns to its normal state, with a few seconds (usually 5–10) to return to its normal position and 5–10 minutes to return to its original size. If orgasm is not achieved, the clitoris may remain engorged for a few hours, which women often find uncomfortable. Additionally, the clitoris is very sensitive after orgasm, making further stimulation initially painful for some women. Masters and Johnson documented the sexual response cycle, which has four phases and is still the clinically accepted definition of the human orgasm.\n\nPhysical sexual stimulation of the clitoris is the most common way for women to achieve orgasm; general statistics indicate that 70–80 percent of women require direct clitoral stimulation (consistent manual, oral or other concentrated friction against the external parts of the clitoris) to reach orgasm, though indirect clitoral stimulation (for example, via vaginal penetration) may also be sufficient for female orgasm. The area near the entrance of the vagina (the lower third) contains nearly 90 percent of the vaginal nerve endings, and there are areas in the anterior vaginal wall and between the top junction of the labia minora and the urethra that are especially sensitive, but intense sexual pleasure, including orgasm, solely from vaginal stimulation is occasional or otherwise absent because the vagina has significantly fewer nerve endings than the clitoris.\n\nProminent debate over the quantity of vaginal nerve endings began with Alfred Kinsey; although Sigmund Freud's theory that clitoral orgasms are a prepubertal or adolescent phenomenon and that vaginal (or G-spot) orgasms are something that only physically mature females experience had been criticized by few researchers before, Kinsey was the first researcher to harshly criticize the theory. Through his observations of female masturbation and interviews with thousands of women, Kinsey found that most of the women he observed and surveyed could not have vaginal orgasms, a finding that was also supported by his knowledge of sex organ anatomy. Scholar Janice M. Irvine stated that he \"criticized Freud and other theorists for projecting male constructs of sexuality onto women\" and \"viewed the clitoris as the main center of sexual response\". He considered the vagina to be \"relatively unimportant\" for sexual satisfaction, relaying that \"few women inserted fingers or objects into their vaginas when they masturbated\". Believing that vaginal orgasms are \"a physiological impossibility\" because the vagina has insufficient nerve endings for sexual pleasure or climax, he \"concluded that satisfaction from penile penetration [is] mainly psychological or perhaps the result of referred sensation\".\n\nMasters and Johnson's research, as well as Shere Hite's, generally supported Kinsey's findings about the female orgasm. Masters and Johnson were the first researchers to determine that the clitoral structures surround and extend along and within the labia. They observed that both clitoral and vaginal orgasms have the same stages of physical response, and found that the majority of their subjects could only achieve clitoral orgasms, while a minority achieved vaginal orgasms. On that basis, they argued that clitoral stimulation is the source of both kinds of orgasms, reasoning that the clitoris is stimulated during penetration by friction against its hood. The research came at the time of the second-wave feminist movement, which inspired feminists to reject the distinction made between clitoral and vaginal orgasms. Feminist Anne Koedt argued that because men \"have orgasms essentially by friction with the vagina\" and not the clitoral area, this is why women's biology had not been properly analyzed. \"Today, with extensive knowledge of anatomy, with [C. Lombard Kelly], Kinsey, and Masters and Johnson, to mention just a few sources, there is no ignorance on the subject [of the female orgasm],\" she stated in her 1970 article \"The Myth of the Vaginal Orgasm.\" She added, \"There are, however, social reasons why this knowledge has not been popularized. We are living in a male society which has not sought change in women's role.\"\n\nSupporting an anatomical relationship between the clitoris and vagina is a study published in 2005, which investigated the size of the clitoris; Australian urologist Helen O'Connell, described as having initiated discourse among mainstream medical professionals to refocus on and redefine the clitoris, noted a direct relationship between the legs or roots of the clitoris and the erectile tissue of the clitoral bulbs and corpora, and the distal urethra and vagina while using magnetic resonance imaging (MRI) technology. While some studies, using ultrasound, have found physiological evidence of the G-spot in women who report having orgasms during vaginal intercourse, O'Connell argues that this interconnected relationship is the physiological explanation for the conjectured G-Spot and experience of vaginal orgasms, taking into account the stimulation of the internal parts of the clitoris during vaginal penetration. \"The vaginal wall is, in fact, the clitoris,\" she said. \"If you lift the skin off the vagina on the side walls, you get the bulbs of the clitoris – triangular, crescental masses of erectile tissue.\" O'Connell et al., having performed dissections on the female genitals of cadavers and used photography to map the structure of nerves in the clitoris, made the assertion in 1998 that there is more erectile tissue associated with the clitoris than is generally described in anatomical textbooks, and were thus already aware that the clitoris is more than just its glans. They concluded that some females have more extensive clitoral tissues and nerves than others, especially having observed this in young cadavers compared to elderly ones, and therefore whereas the majority of females can only achieve orgasm by direct stimulation of the external parts of the clitoris, the stimulation of the more generalized tissues of the clitoris via vaginal intercourse may be sufficient for others.\n\nFrench researchers Odile Buisson and Pierre Foldès reported similar findings to that of O'Connell's. In 2008, they published the first complete 3D sonography of the stimulated clitoris, and republished it in 2009 with new research, demonstrating the ways in which erectile tissue of the clitoris engorges and surrounds the vagina. On the basis of their findings, they argued that women may be able to achieve vaginal orgasm via stimulation of the G-spot, because the highly innervated clitoris is pulled closely to the anterior wall of the vagina when the woman is sexually aroused and during vaginal penetration. They assert that since the front wall of the vagina is inextricably linked with the internal parts of the clitoris, stimulating the vagina without activating the clitoris may be next to impossible. In their 2009 published study, the \"coronal planes during perineal contraction and finger penetration demonstrated a close relationship between the root of the clitoris and the anterior vaginal wall\". Buisson and Foldès suggested \"that the special sensitivity of the lower anterior vaginal wall could be explained by pressure and movement of clitoris's root during a vaginal penetration and subsequent perineal contraction\".\n\nResearcher Vincenzo Puppo, who, while agreeing that the clitoris is the center of female sexual pleasure and believing that there is no anatomical evidence of the vaginal orgasm, disagrees with O'Connell and other researchers' terminological and anatomical descriptions of the clitoris (such as referring to the vestibular bulbs as the \"clitoral bulbs\") and states that \"the inner clitoris\" does not exist because the penis cannot come in contact with the congregation of multiple nerves/veins situated until the angle of the clitoris, detailed by Kobelt, or with the roots of the clitoris, which do not have sensory receptors or erogenous sensitivity, during vaginal intercourse. Puppo's belief contrasts the general belief among researchers that vaginal orgasms are the result of clitoral stimulation; they reaffirm that clitoral tissue extends, or is at least stimulated by its bulbs, even in the area most commonly reported to be the G-spot.\n\nThe G-spot being analogous to the base of the male penis has additionally been theorized, with sentiment from researcher Amichai Kilchevsky that because female fetal development is the \"default\" state in the absence of substantial exposure to male hormones and therefore the penis is essentially a clitoris enlarged by such hormones, there is no evolutionary reason why females would have an entity in addition to the clitoris that can produce orgasms. The general difficulty of achieving orgasms vaginally, which is a predicament that is likely due to nature easing the process of child bearing by drastically reducing the number of vaginal nerve endings, challenge arguments that vaginal orgasms help encourage sexual intercourse in order to facilitate reproduction. Supporting a distinct G-spot, however, is a study by Rutgers University, published in 2011, which was the first to map the female genitals onto the sensory portion of the brain; the scans indicated that the brain registered distinct feelings between stimulating the clitoris, the cervix and the vaginal wall – where the G-spot is reported to be – when several women stimulated themselves in a functional magnetic resonance (fMRI) machine. Barry Komisaruk, head of the research findings, stated that he feels that \"the bulk of the evidence shows that the G-spot is not a particular thing\" and that it is \"a region, it's a convergence of many different structures\".\n\nThere are intentional and unintentional modifications concerning the clitoris, including female genital mutilation (FGM), sex reassignment surgery, clitoris enlargement and genital piercings. For example, use of anabolic steroids by bodybuilders and other athletes can result in significant enlargement of the clitoris in concert with other masculinizing effects on their bodies. Abnormal enlargement of the clitoris may also be referred to as \"clitoromegaly\", but clitoromegaly is more commonly seen as a congenital anomaly of the genitalia.\n\nIn clitoridectomy, the clitoris may be removed as part of a radical vulvectomy to treat cancer such as vulvar intraepithelial neoplasia; however, modern treatments favor more conservative approaches, as invasive surgery can have psychosexual consequences. Clitoridectomy more often involves parts of the clitoris being partially or completely removed during FGM, which may be additionally known as female circumcision or female genital cutting (FGC). Removing the glans of the clitoris does not mean that the whole structure is lost, since the clitoris reaches deep into the genitals.\n\nIn reduction clitoroplasty, a common intersex operation, the glans is preserved and parts of the erectile bodies are excised. Problems with this technique include loss of sensation, sexual function, and sloughing of the glans. One way to preserve the clitoris with its innervations and function is to imbricate and bury the clitoral glans; however, Şenaylı et al. state that \"pain during stimulus because of trapped tissue under the scarring is nearly routine. In another method, 50 percent of the ventral clitoris is removed through the level base of the clitoral shaft, and it is reported that good sensation and clitoral function are observed in follow up\"; additionally, it has \"been reported that the complications are from the same as those in the older procedures for this method\".\n\nWhat is often referred to as \"clit piercing\" is actually the more common (and significantly less complicated) clitoral hood piercing. Since clitoral piercing is difficult and very painful, piercing of the clitoral hood is more common than piercing the clitoral shaft, owing to the small percentage of people who are anatomically suited for it. Clitoral hood piercings are usually channeled in the form of vertical piercings, and, to a lesser extent, horizontal piercings. The triangle piercing is a very deep horizontal hood piercing, and is done behind the clitoris as opposed to in front of it. For styles such as the Isabella, which pass through the clitoral shaft but are placed deep at the base, they provide unique stimulation and still require the proper genital build; the Isabella starts between the clitoral glans and the urethra, exiting at the top of the clitoral hood; this piercing is highly risky with regard to damage that may occur because of intersecting nerves.\n\nPersistent genital arousal disorder (PGAD) results in a spontaneous, persistent, and uncontrollable genital arousal in women, with or without orgasm, unrelated to any feelings of sexual desire. Clitoral priapism, also known as clitorism, is a rare, potentially painful medical condition and is sometimes described as an aspect of PGAD, in which the erect clitoris does not return to its relaxed state for an unusually extended period of time (ranging from minutes to days), despite the absence of both physical and psychological stimulation; PGAD can also be associated with morphometric and vascular modifications of the clitoris.\n\nDrugs may cause or affect clitoral priapism. The drug trazodone is known to cause male priapism as a side effect, but there is only one documented report that it may have caused clitoral priapism, in which case discontinuing the medication may be a remedy. Additionally, nefazodone is documented to have caused clitoral engorgement, as distinct from clitoral priapism, in one case, and clitoral priapism can sometimes start as a result of, or only after, the discontinuation of antipsychotics or selective serotonin reuptake inhibitors (SSRIs).\n\nBecause PGAD is relatively rare and, as its own concept apart from clitoral priapism, has only been researched since 2001, there is little research into what may cure or remedy the disorder. In some recorded cases, PGAD was caused by, or caused, a pelvic arterial-venous malformation with arterial branches to the clitoris; surgical treatment was effective in these cases.\n\nWith regard to historical and modern perceptions of the clitoris and associated sexual stimulation, for more than 2,500 years there were scholars who considered the clitoris and the penis equivalent in all respects except their arrangement. The clitoris was, however, subject to \"discovery\" and \"rediscovery\" through empirical documentation by male scholars, due to it being frequently omitted from, or misrepresented, in historical and contemporary anatomical texts. The ancient Greeks, ancient Romans, and Greek and Roman generations up to and throughout the Renaissance, were aware that male and female sex organs are anatomically similar, but prominent anatomists, notably Galen (129 – c. 200 AD) and Vesalius (1514–1564), regarded the vagina as the structural equivalent of the penis, except for being inverted; Vesalius argued against the existence of the clitoris in normal women, and his anatomical model described how the penis corresponds with the vagina, without a role for the clitoris.\n\nAncient Greek and Roman sexuality additionally designated penetration as \"male-defined\" sexuality. The term \"tribas\", or \"tribade\", was used to refer to a woman or intersex individual who actively penetrated another person (male or female) through use of the clitoris or a dildo. As any sexual act was believed to require that one of the partners be \"phallic\" and that therefore sexual activity between women was impossible without this feature, mythology popularly associated lesbians with either having enlarged clitorises or as incapable of enjoying sexual activity without the substitution of a phallus.\nIn 1545, Charles Estienne was the first writer to identify the clitoris in a work based on dissection, but he concluded that it had a urinary function. Following this study, Realdo Colombo (also known as Matteo Renaldo Colombo), a lecturer in surgery at the University of Padua, Italy, published a book called \"De re anatomica\" in 1559, in which he describes the \"seat of woman's delight\". In his role as researcher, Colombo concluded, \"Since no one has discerned these projections and their workings, if it is permissible to give names to things discovered by me, it should be called the love or sweetness of Venus.\", in reference to the mythological Venus, goddess of erotic love. Colombo's claim was disputed by his successor at Padua, Gabriele Falloppio (discoverer of the fallopian tube), who claimed that he was the first to discover the clitoris. In 1561, Falloppio stated, \"Modern anatomists have entirely neglected it ... and do not say a word about it ... and if others have spoken of it, know that they have taken it from me or my students.\" This caused an upset in the European medical community, and, having read Colombo's and Falloppio's detailed descriptions of the clitoris, Vesalius stated, \"It is unreasonable to blame others for incompetence on the basis of some sport of nature you have observed in some women and you can hardly ascribe this new and useless part, as if it were an organ, to healthy women.\" He concluded, \"I think that such a structure appears in hermaphrodites who otherwise have well formed genitals, as Paul of Aegina describes, but I have never once seen in any woman a penis (which Avicenna called albaratha and the Greeks called an enlarged nympha and classed as an illness) or even the rudiments of a tiny phallus.\"\n\nThe average anatomist had difficulty challenging Galen's or Vesalius's research; Galen was the most famous physician of the Greek era and his works were considered the standard of medical understanding up to and throughout the Renaissance (i.e. for almost two thousand years), and various terms being used to describe the clitoris seemed to have further confused the issue of its structure. In addition to Avicenna's naming it the \"albaratha\" or \"virga\" (\"rod\") and Colombo's calling it sweetness of Venus, Hippocrates used the term \"columella\" (\"little pillar'\"), and Albucasis, an Arabic medical authority, named it \"tentigo\" (\"tension\"). The names indicated that each description of the structures was about the body and glans of the clitoris, but usually the glans. It was additionally known to the Romans, who named it (vulgar slang) \"landica\". However, Albertus Magnus, one of the most prolific writers of the Middle Ages, felt that it was important to highlight \"homologies between male and female structures and function\" by adding \"a psychology of sexual arousal\" that Aristotle had not used to detail the clitoris. While in Constantine's treatise \"Liber de coitu\", the clitoris is referred to a few times, Magnus gave an equal amount of attention to male and female organs.\n\nLike Avicenna, Magnus also used the word \"virga\" for the clitoris, but employed it for the male and female genitals; despite his efforts to give equal ground to the clitoris, the cycle of suppression and rediscovery of the organ continued, and a 16th-century justification for clitoridectomy appears to have been confused by hermaphroditism and the imprecision created by the word \"nymphae\" substituted for the word \"clitoris\". Nymphotomia was a medical operation to excise an unusually large clitoris, but what was considered \"unusually large\" was often a matter of perception. The procedure was routinely performed on Egyptian women, due to physicians such as Jacques Daléchamps who believed that this version of the clitoris was \"an unusual feature that occurred in almost all Egyptian women [and] some of ours, so that when they find themselves in the company of other women, or their clothes rub them while they walk or their husbands wish to approach them, it erects like a male penis and indeed they use it to play with other women, as their husbands would do ... Thus the parts are cut\".\n\nCaspar Bartholin, a 17th-century Danish anatomist, dismissed Colombo's and Falloppio's claims that they discovered the clitoris, arguing that the clitoris had been widely known to medical science since the second century. Although 17th-century midwives recommended to men and women that women should aspire to achieve orgasms to help them get pregnant for general health and well-being and to keep their relationships healthy, debate about the importance of the clitoris persisted, notably in the work of Regnier de Graaf in the 17th century and Georg Ludwig Kobelt in the 19th.\n\nLike Falloppio and Bartholin, De Graaf criticized Colombo's claim of having discovered the clitoris; his work appears to have provided the first comprehensive account of clitoral anatomy. \"We are extremely surprised that some anatomists make no more mention of this part than if it did not exist at all in the universe of nature,\" he stated. \"In every cadaver we have so far dissected we have found it quite perceptible to sight and touch.\" De Graaf stressed the need to distinguish \"nympha\" from \"clitoris\", choosing to \"always give [the clitoris] the name clitoris\" to avoid confusion; this resulted in frequent use of the correct name for the organ among anatomists, but considering that \"nympha\" was also varied in its use and eventually became the term specific to the labia minora, more confusion ensued. Debate about whether orgasm was even necessary for women began in the Victorian era, and Freud's 1905 theory about the immaturity of clitoral orgasms (see above) negatively affected women's sexuality throughout most of the 20th century. From the 18th – 20th century, especially during the 20th, details of the clitoris from various genital diagrams presented in earlier centuries were omitted from later texts.\n\nThe full extent of the clitoris was alluded to by Masters and Johnson in 1966, but in such a muddled fashion that the significance of their description became obscured; in 1981, the Federation of Feminist Women's Health Clinics (FFWHC) continued this process with anatomically precise illustrations identifying 18 structures of the clitoris. Despite the FFWHC's illustrations, Josephine Lowndes Sevely, in 1987, described the vagina as more of the counterpart of the penis.\n\nConcerning other beliefs about the clitoris, Hite (1976 and 1981) found that, during sexual intimacy with a partner, clitoral stimulation was more often described by women as foreplay than as a primary method of sexual activity, including orgasm. Further, although the FFWHC's work created \"fertile ground for feminist reformation of anatomical texts\" and \"revolutionized existing descriptions and renderings of the clitoris\", it did not have a general impact on anatomical texts; it took Helen O'Connell's late 1990s research for the medical community to start changing the way the clitoris is anatomically defined. O'Connell describes typical textbook descriptions of the clitoris as lacking detail and including inaccuracies, such as older and modern anatomical descriptions of the female human urethral and genital anatomy having been based on dissections performed on elderly cadavers whose erectile (clitoral) tissue had shrunk. She instead credits the work of Georg Ludwig Kobelt as the most comprehensive and accurate description of clitoral anatomy. MRI measurements, which provide a live and multi-planar method of examination, now complement the FFWHC's, as well as O'Connell's, research efforts regarding the clitoris, showing that the volume of clitoral erectile tissue is ten times that which is shown in doctors' offices and in anatomy text books.\n\nIn Bruce Bagemihl's survey of \"The Zoological Record\" (1978–1997) – which contains over a million documents from over 6,000 scientific journals – 539 articles focusing on the penis were found, while 7 were found focusing on the clitoris. In 2000, researchers Shirley Ogletree and Harvey Ginsberg concluded that there is a general neglect of the word \"clitoris\" in common vernacular. They looked at the terms used to describe genitalia in the PsycINFO database from 1887 to 2000 and found that \"penis\" was used in 1,482 sources, \"vagina\" in 409, while \"clitoris\" was only mentioned in 83. They additionally analyzed 57 books listed in a computer database for sex instruction. In the majority of the books, \"penis\" was the most commonly discussed body part – mentioned more than \"clitoris\", \"vagina\", and \"uterus\" put together. They last investigated terminology used by college students, ranging from Euro-American (76%/76%), Hispanic (18%/14%), and African American (4%/7%), regarding the students' beliefs about sexuality and knowledge on the subject. The students were overwhelmingly educated to believe that the vagina is the female counterpart of the penis. The authors found that the students' belief that the inner portion of the vagina is the most sexually sensitive part of the female body correlated with negative attitudes toward masturbation and strong support for sexual myths.\n\nA 2005 study reported that, among a sample of undergraduate students, the most frequently cited sources for knowledge about the clitoris were school and friends, and that this was associated with the least amount of tested knowledge. Knowledge of the clitoris by self-exploration was the least cited, but \"respondents correctly answered, on average, three of the five clitoral knowledge measures\". The authors stated that \"[k]nowledge correlated significantly with the frequency of women's orgasm in masturbation but not partnered sex\" and that their \"results are discussed in light of gender inequality and a social construction of sexuality, endorsed by both men and women, that privileges men's sexual pleasure over women's, such that orgasm for women is pleasing, but ultimately incidental.\" They concluded that part of the solution to remedying \"this problem\" requires that males and females are taught more about the clitoris than is currently practiced.\n\nIn 2012, New York artist Sophia Wallace started work on a multimedia project to challenge misconceptions about the clitoris. Based on O'Connell's 1998 research, Wallace's work emphasizes the sheer scope and size of the human clitoris. She says that ignorance of this still seems to be pervasive in modern society. \"It is a curious dilemma to observe the paradox that on the one hand the female body is the primary metaphor for sexuality, its use saturates advertising, art and the mainstream erotic imaginary,\" she said. \"Yet, the clitoris, the true female sexual organ, is virtually invisible.\" The project is called \"Cliteracy\" and it includes a \"clit rodeo\", which is an interactive, climb-on model of a giant golden clitoris, including its inner parts, produced with the help of sculptor Kenneth Thomas. \"It's been a showstopper wherever it's been shown. People are hungry to be able to talk about this,\" Wallace said. \"I love seeing men standing up for the clit [...] Not having access to the pleasure that is your birthright is a deeply political act.\"\n\nIn May 2013, humanitarian group Clitoraid launched the first annual International Clitoris Awareness Week, from May 6 to May 12. Clitoraid spokesperson Nadine Gary stated that the group's mission is to raise public awareness about the clitoris because it has \"been ignored, vilified, made taboo, and considered sinful and shameful for centuries\".\n\nMotivations for clitoral modification and mutilation vary. Those taking hormones or other medications as part of female-to-male transition usually experience dramatic clitoral growth; individual desires and the difficulties of phalloplasty (construction of a penis) often result in the retention of the original genitalia with the enlarged clitoris as a penis analogue (metoidioplasty). However, the clitoris cannot reach the size of the penis through hormones. A surgery to add function to the clitoris, such as metoidioplasty, is an alternative to phalloplasty that permits retention of sexual sensation in the clitoris.\n\nSignificant controversy surrounds female genital mutilation (FGM), with the World Health Organization (WHO) being one of many health organizations that have campaigned against the procedures on behalf of human rights, stating that \"FGM has no health benefits\" and that it is \"a violation of the human rights of girls and women\" and \"reflects deep-rooted inequality between the sexes\". The practice has existed at one point or another in almost all human civilizations, most commonly to exert control over the sexual behavior, including masturbation, of girls and women, but also to change the clitoris's appearance. Custom and tradition are the most frequently cited reasons for FGM, with some cultures believing that not performing it has the possibility of disrupting the cohesiveness of their social and political systems, such as FGM also being a part of a girl's initiation into adulthood. Often, a girl is not considered an adult in a FGM-practicing society unless she has undergone FGM, and the \"removal of the clitoris and labia – viewed by some as the \"male parts\" of a woman's body – is thought to enhance the girl's femininity, often synonymous with docility and obedience\".\n\nFemale genital mutilation is carried out in several countries, especially in Africa, with 85 percent of genital mutilations performed in Africa consisting of clitoridectomy or excision, and to a lesser extent in other parts of the Middle East and Southeast Asia, on girls from a few days old to mid-adolescent, often to reduce sexual desire in an effort to preserve vaginal virginity. In the United States, it is sometimes practiced on girls born with a clitoris that is larger than usual. Comfort Momoh, who specializes in the topic of FGM, states that FGM might have been \"practiced in ancient Egypt as a sign of distinction among the aristocracy\"; there are reports that traces of infibulation are on Egyptian mummies. FGM is still routinely practiced in Egypt. Greenberg et al. report that \"one study found that 97% of married women in Egypt had had some form of genital mutilation performed.\" Amnesty International estimated in 1997 that more than two million FGM procedures are performed every year.\n\nWith regard to females who have the condition congenital adrenal hyperplasia, the largest group requiring surgical genital correction, researcher Atilla Şenaylı stated, \"The main expectations for the operations are to create a normal female anatomy, with minimal complications and improvement of life quality.\" Şenaylı added that \"[c]osmesis, structural integrity, and coital capacity of the vagina, and absence of pain during sexual activity are the parameters to be judged by the surgeon.\" (Cosmesis usually refers to the surgical correction of a disfiguring defect.) He stated that although \"expectations can be standardized within these few parameters, operative techniques have not yet become homogeneous. Investigators have preferred different operations for different ages of patients\".\n\nGender assessment and surgical treatment are the two main steps in intersex operations. \"The first treatments for clitoromegaly were simply resection of the clitoris. Later, it was understood that the clitoris glans and sensory input are important to facilitate orgasm,\" stated Atilla. The clitoral glans's epithelium \"has high cutaneous sensitivity, which is important in sexual responses\" and it is because of this that \"recession clitoroplasty was later devised as an alternative, but reduction clitoroplasty is the method currently performed.\"\n\nWhether the clitoris is vestigial, an adaptation, or serves a reproductive function has also been debated. Geoffrey Miller states that Helen Fisher, Meredith Small and Sarah Blaffer Hrdy \"have viewed the clitoral orgasm as a legitimate adaptation in its own right, with major implications for female sexual behavior and sexual evolution\". Like Lynn Margulis and Natalie Angier, Miller believes, \"The human clitoris shows no apparent signs of having evolved directly through male mate choice. It is not especially large, brightly colored, specifically shaped or selectively displayed during courtship.\" He contrasts this with other female species such as spider monkeys and spotted hyenas that have clitorises as long as their male counterparts. He suggests that the human clitoris \"could have evolved to be much more conspicuous if males had preferred sexual partners with larger brighter clitorises\" and that \"its inconspicuous design combined with its exquisite sensitivity suggests that the clitoris is important not as an object of male mate choice, but as a mechanism of female choice.\"\n\nWhile Miller states that male scientists such as Stephen Jay Gould and Donald Symons \"have viewed the female clitoral orgasm as an evolutionary side-effect of the male capacity for penile orgasm\" and that they \"suggested that clitoral orgasm cannot be an adaptation because it is too hard to achieve\", Gould acknowledged that \"most female orgasms emanate from a clitoral, rather than vaginal (or some other), site\" and that his nonadaptive belief \"has been widely misunderstood as a denial of either the adaptive value of female orgasm in general, or even as a claim that female orgasms lack significance in some broader sense\". He explained that although he accepts that \"clitoral orgasm plays a pleasurable and central role in female sexuality and its joys,\" \"[a]ll these favorable attributes, however, emerge just as clearly and just as easily, whether the clitoral site of orgasm arose as a spandrel or an adaptation\". He said that the \"male biologists who fretted over [the adaptionist questions] simply assumed that a deeply vaginal site, nearer the region of fertilization, would offer greater selective benefit\" due to their Darwinian, \"summum bonum\" beliefs about enhanced reproductive success.\n\nSimilar to Gould's beliefs about adaptionist views and that \"females grow nipples as adaptations for suckling, and males grow smaller unused nipples as a spandrel based upon the value of single development channels\", Elisabeth Lloyd suggests that there is little evidence to support an adaptionist account of female orgasm. \"Lloyd views female orgasm as an ontogenetic leftover; women have orgasms because the urogenital neurophysiology for orgasm is so strongly selected for in males that this developmental blueprint gets expressed in females without affecting fitness\" and this is similar to \"males hav[ing] nipples that serve no fitness-related function,\" stated Meredith L. Chivers.\n\nAt the 2002 conference for \"Canadian Society of Women in Philosophy\", Dr. Nancy Tuana asserted that the clitoris is unnecessary in reproduction; she states that it has been ignored because of \"a fear of pleasure. It is pleasure separated from reproduction. That's the fear.\" She reasoned that this fear causes ignorance, which veils female sexuality. O'Connell states, \"It boils down to rivalry between the sexes: the idea that one sex is sexual and the other reproductive. The truth is that both are sexual and both are reproductive.\" She reiterates that the vestibular bulbs appear to be part of the clitoris and that the distal urethra and vagina are intimately related structures, although they are not erectile in character, forming a tissue cluster with the clitoris that appears to be the location of female sexual function and orgasm.\n\nAlthough the clitoris exists in all mammal species, few detailed studies of the anatomy of the clitoris in non-humans exist. The clitoris is especially developed in fossas, apes, lemurs, and, like the penis, often contains a small bone, the os clitoridis. The clitoris exists in turtles, ostriches, crocodiles, and in species of birds in which the male counterpart has a penis. The clitoris erects in squirrel monkeys during dominance displays, which indirectly influences the squirrel monkeys' reproductive success. In female galagos (bush babies), the clitoris is long and pendulous with a urethra extending through the tip for urination. Some intersex female bears mate and give birth through the tip of the clitoris; these species are grizzly bears, brown bears, American black bears and polar bears. Although the bears have been described as having \"a birth canal that runs through the clitoris rather than forming a separate vagina\" (a feature that is estimated to make up 10 to 20 percent of the bears' population), scientists state that female spotted hyenas are the only non-hermaphroditic female mammals devoid of an external vaginal opening, and whose sexual anatomy is distinct from usual intersex cases. There are also several mole species with a peniform clitoris.\n\nIn spider monkeys, the clitoris is especially developed and has an interior passage, or urethra, that makes it almost identical to the penis, and it retains and distributes urine droplets as the female spider monkey moves around. Scholar Alan F. Dixson stated that this urine \"is voided at the bases of the clitoris, flows down the shallow groove on its perineal surface, and is held by the skin folds on each side of the groove\". Because spider monkeys of South America have pendulous and erectile clitorises long enough to be mistaken for a penis, researchers and observers of the species look for a scrotum to determine the animal's sex; a similar approach is to identify scent-marking glands that may also be present on the clitoris.\n\nThe clitoris of bonobos is larger and more externalized than in most mammals; Natalie Angier said that a young adolescent \"female bonobo is maybe half the weight of a human teenager, but her clitoris is three times bigger than the human equivalent, and visible enough to waggle unmistakably as she walks\". Female bonobos often engage in the practice of genital-genital (GG) rubbing, which is the non-human form of tribadism that human females engage in. Ethologist Jonathan Balcombe stated that female bonobos rub their clitorises together rapidly for ten to twenty seconds, and this behavior, \"which may be repeated in rapid succession, is usually accompanied by grinding, shrieking, and clitoral engorgement\"; he added that, on average, they engage in this practice \"about once every two hours\", and as bonobos sometimes mate face-to-face, \"evolutionary biologist Marlene Zuk has suggested that the position of the clitoris in bonobos and some other primates has evolved to maximize stimulation during sexual intercourse\".\n\nWhile female spotted hyenas are sometimes referred to as hermaphrodites or as intersex, and scientists of antiquity (ancient and later historical times) believed that they were hermaphrodites, modern scientists do not refer to them as such. That designation is typically reserved for those who simultaneously exhibit features of both sexes; the genetic makeup of female spotted hyenas \"are clearly distinct\" from male spotted hyenas.\n\nFemale spotted hyenas have a clitoris 90 percent as long and the same diameter as a male penis (171 millimeters long and 22 millimeters in diameter), and this pseudo-penis's formation seems largely androgen-independent because it appears in the female fetus before differentiation of the fetal ovary and adrenal gland. The spotted hyenas have a highly erectile clitoris, complete with a false scrotum; author John C. Wingfield stated that \"the resemblance to male genitalia is so close that sex can be determined with confidence only by palpation of the scrotum\". The pseudo-penis can also be distinguished from the males' genitalia by its greater thickness and more rounded glans. The female possesses no external vagina, as the labia are fused to form a pseudo-scrotum. In the females, this scrotum consists of soft adipose tissue. Like male spotted hyenas with regard to their penises, the female spotted hyenas have small penile spines on the head of their clitorises, which scholar Catherine Blackledge said makes \"the clitoris tip feel like soft sandpaper\". She added that the clitoris \"extends away from the body in a sleek and slender arc, measuring, on average, over 17 cm from root to tip. Just like a penis, [it] is fully erectile, raising its head in hyena greeting ceremonies, social displays, games of rough and tumble or when sniffing out peers\".\n\nDue to their higher levels of androgen exposure, the female hyenas are significantly more muscular and aggressive than their male counterparts; social-wise, they are of higher rank than the males, being dominant or dominant and alpha, and the females who have been exposed to higher levels of androgen than average become higher-ranking than their female peers. Subordinate females lick the clitorises of higher-ranked females as a sign of submission and obedience, but females also lick each other's clitorises as a greeting or to strengthen social bonds; in contrast, while all males lick the clitorises of dominant females, the females will not lick the penises of males because males are considered to be of lowest rank.\n\nThe urethra and vagina of the female spotted hyena exit through the clitoris, allowing the females to urinate, copulate and give birth through this organ. This trait makes mating more laborious for the male than in other mammals, and also makes attempts to sexually coerce (physically force sexual activity on) females futile. Joan Roughgarden, an ecologist and evolutionary biologist, said that because the hyena's clitoris is higher on the belly than the vagina in most mammals, the male hyena \"must slide his rear under the female when mating so that his penis lines up with [her clitoris]\". In an action similar to pushing up a shirtsleeve, the \"female retracts the [pseudo-penis] on itself, and creates an opening into which the male inserts his own penis\". The male must practice this act, which can take a couple of months to successfully perform. Female spotted hyenas exposed to larger doses of androgen have significantly damaged ovaries, making it difficult to conceive. After giving birth, the pseudo-penis is stretched and loses much of its original aspects; it becomes a slack-walled and reduced prepuce with an enlarged orifice with split lips. Approximately 15% of the females die during their first time giving birth, and over 60% of their species' firstborn young die.\n\nA 2006 Baskin et al. study concluded, \"The basic anatomical structures of the corporeal bodies in both sexes of humans and spotted hyenas were similar. As in humans, the dorsal nerve distribution was unique in being devoid of nerves at the 12 o'clock position in the penis and clitoris of the spotted hyena\" and that \"[d]orsal nerves of the penis/clitoris in humans and male spotted hyenas tracked along both sides of the corporeal body to the corpus spongiosum at the 5 and 7 o'clock positions. The dorsal nerves penetrated the corporeal body and distally the glans in the hyena\" and, in female hyenas, \"the dorsal nerves fanned out laterally on the clitoral body. Glans morphology was different in appearance in both sexes, being wide and blunt in the female and tapered in the male\".\n\nResearchers studying the peripheral and central afferent pathways from the feline clitoris concluded that \"Afferent neurons projecting to the clitoris of the cat were identified by WGA-HRP tracing in the S1 and S2 dorsal root ganglia. An average of 433 cells were identified on each side of the animal. 85 percent and 15 percent of the labeled cells were located in the S1 and S2 dorsal root ganglia, respectively. The average cross sectional area of clitoral afferent neuron profiles was 1.479±627 μm2.\" They also stated that light \"constant pressure on the clitoris produced an initial burst of single unit firing (maximum frequencies 170–255 Hz) followed by rapid adaptation and a sustained firing (maximum 40 Hz), which was maintained during the stimulation. Tonic firing increased to an average maximum of 145 Hz at 6–8 g/mm2 pressure\" and \"[t]hese results indicate that the clitoris is innervated by mechano-sensitive myelinated afferent fibers in the pudental nerve which project centrally to the region of the dorsal commissure in the L7-S1 spinal cord\".\n\nThe external phenotype and reproductive behavior of 21 freemartin sheep and two male pseudohermaphrodite sheep were recorded with the aim of identifying any characteristics that could predict a failure to breed. Among things recorded were the size and shape of the vulva and clitoris, the length of the vagina, the size of the teats, the presence or absence of inguinal gonads, and the ultrasonographic characteristics of the inguinal gonads: \"A subjective assessment of the masculinity of each animal's body form was also made, and its behavioural responses to a virile ram and to an oestrus ewe were recorded. A number of physical and behavioural abnormalities were detected but the only consistent finding in all 23 animals was a short vagina which varied in length from 3.1 to 7.0 cm, compared with 10 to 14 cm in normal animals.\"\n\nIn a study documenting the clitoral structure of mice, it was found that the mouse perineal urethra is surrounded by erectile tissue forming the bulbs of the clitoris, similar to the anatomy of human females: \"In the mouse, as in human females, tissue organization in the corpora cavernosa of the clitoris is essentially similar to that of the penis except for the absence of a subalbugineal layer interposed between the tunica albuginea and the erectile tissue.\"\n\n\n\n"}
{"id": "6886", "url": "https://en.wikipedia.org/wiki?curid=6886", "title": "Chicago", "text": "Chicago\n\nChicago ( or ), officially the City of Chicago, is the third-most populous city in the United States. With over 2.7 million residents, it is also the most populous city in both the state of Illinois and the Midwestern United States. It is the county seat of Cook County. The Chicago metropolitan area, often referred to as Chicagoland, has nearly 10 million people and is the third-largest in the U.S. Chicago has also been called a global architecture capital. In terms of wealth and economy, Chicago is considered one of the most important business centers in the world.\n\nChicago was incorporated as a city in 1837, near a portage between the Great Lakes and the Mississippi River watershed, and grew rapidly in the mid-nineteenth century. After the Great Chicago Fire of 1871, which razed several square miles and left more than 100,000 homeless, the city made a concerted effort to rebuild on the damage. The construction boom accelerated population growth throughout the following decades, leading Chicago to become among the five largest cities in the world by 1900. During this period Chicago is noted for its contribution to urban planning and zoning standards, new constructions styles (including the Chicago School of architecture), the embracement of the City Beautiful Movement, and the eventual creation of the steel-framed skyscraper.\n\nPositioned along Lake Michigan, the city is an international hub for finance, commerce, industry, technology, telecommunications, and transportation: O'Hare International Airport is the second-busiest airport in the world when measured by aircraft traffic; the region also has the largest number of U.S. highways and rail road freight. In 2012, Chicago was listed as an alpha global city by the Globalization and World Cities Research Network, and ranked seventh in the world in the 2016 Global Cities Index. Chicago has the third-largest gross metropolitan product in the United States—about $640 billion according to 2015 estimates. The city has one of the world's largest and most diversified economies with no single industry employing more than 14% of the workforce.\n\nIn 2016, Chicago hosted over 54 million domestic and international visitors, a new record making it one of the top visited cities in the nation. Landmarks in the city include Millennium Park, Navy Pier, the Magnificent Mile, Art Institute of Chicago, Museum Campus, the Willis (Sears) Tower, Museum of Science and Industry, and Lincoln Park Zoo. Chicago's culture includes the visual arts, novels, film, theater, especially improvisational comedy, and music, particularly jazz, blues, soul, hip-hop, gospel, and house music. There are many colleges and universities in the Chicago area; among these, Northwestern University, University of Chicago, and the University of Illinois at Chicago are classified as \"highest research\" doctoral universities.\n\nChicago has professional sports teams in each of the major professional leagues. The city has many nicknames, the best-known being the Windy City and Chi-Town.\n\nThe name \"Chicago\" is derived from a French rendering of the Native American word \"Shikaakwa\", known to botanists as Allium tricoccum, from the Miami-Illinois language. The first known reference to the site of the current city of Chicago as \"Checagou\" was by Robert de LaSalle around 1679 in a memoir. Henri Joutel, in his journal of 1688, noted that the wild garlic, called \"Chicagoua\", grew abundantly in the area. According to his diary of late September 1687: \nIn the mid-18th century, the area was inhabited by a Native American tribe known as the Potawatomi, who had taken the place of the Miami and Sauk and Fox peoples. The first known non-indigenous permanent settler in Chicago was Jean Baptiste Point du Sable. Du Sable was of African and French descent and arrived in the 1780s. He is commonly known as the \"Founder of Chicago\".\n\nIn 1795, following the Northwest Indian War, an area that was to be part of Chicago was turned over to the United States for a military post by native tribes in accordance with the Treaty of Greenville. In 1803, the United States Army built Fort Dearborn, which was destroyed in 1812 in the Battle of Fort Dearborn and later rebuilt. The Ottawa, Ojibwe, and Potawatomi tribes had ceded additional land to the United States in the 1816 Treaty of St. Louis. The Potawatomi were forcibly removed from their land after the Treaty of Chicago in 1833.\n\nOn August 12, 1833, the Town of Chicago was organized with a population of about 200. Within seven years it grew to more than 4,000 people. On June 15, 1835, the first public land sales began with Edmund Dick Taylor as U.S. Receiver of Public Monies. The City of Chicago was incorporated on Saturday, March 4, 1837 and for several decades was the world's fastest growing city.\n\nAs the site of the Chicago Portage, the city became an important transportation hub between the eastern and western United States. Chicago's first railway, Galena and Chicago Union Railroad, and the Illinois and Michigan Canal opened in 1848. The canal allowed steamboats and sailing ships on the Great Lakes to connect to the Mississippi River.\n\nA flourishing economy brought residents from rural communities and immigrants from abroad. Manufacturing and retail and finance sectors became dominant, influencing the American economy. The Chicago Board of Trade (established 1848) listed the first ever standardized 'exchange traded' forward contracts, which were called futures contracts.\nIn the 1850s, Chicago gained national political prominence as the home of Senator Stephen Douglas, the champion of the Kansas–Nebraska Act and the \"popular sovereignty\" approach to the issue of the spread of slavery. These issues also helped propel another Illinoisan, Abraham Lincoln, to the national stage. Lincoln was nominated in Chicago for US President at the 1860 Republican National Convention. He defeated Douglas in the general election, and this set the stage for the American Civil War.\n\nTo accommodate rapid population growth and demand for better sanitation, the city improved its infrastructure. In February 1856, Chicago's Common Council approved Chesbrough's plan to build the United States' first comprehensive sewerage system. The project raised much of central Chicago to a new grade. While elevating Chicago, and at first improving the city's health, the untreated sewage and industrial waste now flowed into the Chicago River, then into Lake Michigan, polluting the city's primary freshwater source.\n\nThe city responded by tunneling two miles (3 km) out into Lake Michigan to newly-built water cribs. In 1900, the problem of sewage contamination was largely resolved when the city completed a major engineering feat. It reversed the flow of the Chicago River so the water flowed away from Lake Michigan rather than into it. This project began with the construction and improvement of the Illinois and Michigan Canal, and was completed with the Chicago Sanitary and Ship Canal that connects to the Illinois River, which flows into the Mississippi River.\n\nIn 1871, the Great Chicago Fire destroyed an area of about 4 miles long and 1 mile wide, a large section of the city at the time. Much of the city, including railroads and stockyards, survived intact, and from the ruins of the previous wooden structures arose more modern constructions of steel and stone. These set a precedent for worldwide construction. During its rebuilding period, Chicago constructed the world's first skyscraper in 1885, using steel-skeleton construction.\n\nThe city grew significantly in size and population by incorporating many neighboring townships between 1851 and 1920, with the largest annexation happening in 1889, with five townships joining the city, including the Hyde Park Township, which now comprises most of the South Side of Chicago and the far southeast of Chicago, and the Jefferson Township, which now makes up most of Chicago's Northwest Side. The desire to join the city was driven by municipal services the city could provide its residents.\nChicago's flourishing economy attracted huge numbers of new immigrants from Europe and migrants from the Eastern United States. Of the total population in 1900, more than 77% were either foreign-born or born in the United States of foreign parentage. Germans, Irish, Poles, Swedes and Czechs made up nearly two-thirds of the foreign-born population (by 1900, whites were 98.1% of the city's population).\n\nLabor conflicts followed the industrial boom and the rapid expansion of the labor pool, including the Haymarket affair on May 4, 1886. Concern for social problems among Chicago's immigrant poor led Jane Addams and Ellen Gates Starr to found Hull House in 1889. Programs developed there became a model for the new field of social work.\n\nDuring the 1870s and 1880s, Chicago attained national stature as the leader in the movement to improve public health. City, and later state laws, that upgraded standards for the medical profession and fought urban epidemics of cholera, smallpox, and yellow fever were both passed and enforced. These laws became templates for public health reform in other cities and states.\n\nThe city established many large, well-landscaped municipal parks, which also included public sanitation facilities. The chief advocate for improving public health in Chicago was Dr. John H. Rauch, M.D.. Rauch established a plan for Chicago's park system in 1866. He created Lincoln Park by closing a cemetery filled with shallow graves, and in 1867, in response to an outbreak of cholera he helped establish a new Chicago Board of Health. Ten years later, he became the secretary and then the president of the first Illinois State Board of Health, which carried out most of its activities in Chicago.\n\nIn the 19th century, Chicago became the nation's railroad center, and by 1910 over 20 railroads operated passenger service out of six different downtown terminals. In 1883, Chicago's railway managers needed a general time convention, so they developed the standardized system of North American time zones. This system for telling time spread throughout the continent.\n\nIn 1893, Chicago hosted the World's Columbian Exposition on former marshland at the present location of Jackson Park. The Exposition drew 27.5 million visitors, and is considered the most influential world's fair in history. The University of Chicago, formerly at another location, moved to the same South Side location in 1892. The term \"midway\" for a fair or carnival referred originally to the Midway Plaisance, a strip of park land that still runs through the University of Chicago campus and connects the Washington and Jackson Parks.\n\nDuring World War I and the 1920s there was a major expansion in industry. The availability of jobs attracted African-Americans from the Southern United States. Between 1910 and 1930, the African-American population of Chicago increased dramatically, from 44,103 to 233,903. This Great Migration had an immense cultural impact, called the \"Chicago Black Renaissance\", part of the New Negro Movement, in art, literature, and music. Continuing racial tensions and violence, such as the Chicago Race Riot of 1919, also occurred.\n\nThe ratification of the 18th amendment to the Constitution in 1919 made the production and sale (including exportation) of alcoholic beverages illegal in the United States. This ushered in the beginning of what is known as the Gangster Era, a time that roughly spans from 1919 until 1933 when Prohibition was repealed. The 1920s saw gangsters, including Al Capone, Dion O'Banion, Bugs Moran and Tony Accardo battle law enforcement and each other on the streets of Chicago during the Prohibition era. Chicago was the location of the infamous St. Valentine's Day Massacre in 1929, when Al Capone sent men to gun down members of his rival gang, North Side, led by Bugs Moran.\n\nIn 1924, Chicago was the first American city to have a homosexual-rights organization, the Society for Human Rights. This organization produced the first American publication for homosexuals, \"Friendship and Freedom\". Police and political pressure caused the organization to disband.\n\nIn 1933, Chicago Mayor Anton Cermak was fatally wounded in Miami, Florida during a failed assassination attempt on President-elect Franklin D. Roosevelt. In 1933 and 1934, the city celebrated its centennial by hosting the Century of Progress International Exposition Worlds Fair. The theme of the fair was technological innovation over the century since Chicago's founding.\n\nIn March 1937, there was a violent strike by about 3,500 drivers for Checker and Yellow Cab Companies which included rioting that went on for weeks. The cab companies hired strike breakers, and the cab drivers union hired \"sluggers\" who raged through the downtown Chicago area looking for cabs and drivers not participating in the strike.\n\nOn December 2, 1942, physicist Enrico Fermi conducted the world's first controlled nuclear reaction at the University of Chicago as part of the top-secret Manhattan Project. This led to the creation of the atomic bomb by the United States, which it used in World War II in 1945.\n\nMayor Richard J. Daley, a Democrat, was elected in 1955, in the era of machine politics.\n\nBy the early 1960s, white residents in several neighborhoods left the city for the suburban areas – in many Northern American cities, a process known as white flight – as African Americans continued to move beyond the Black Belt. While home loan discriminatory redlining against blacks continued, the real estate industry practiced what became known as blockbusting, completely changing the racial composition of whole neighborhoods. Structural changes in industry, such as globalization and job outsourcing, caused heavy job losses for lower skilled workers. In 1966, Martin Luther King, Jr. and Albert Raby led the Chicago Freedom Movement, which culminated in agreements between Mayor Richard J. Daley and the movement leaders.\nTwo years later, the city hosted the tumultuous 1968 Democratic National Convention, which featured physical confrontations both inside and outside the convention hall, with anti-war protesters, journalists and bystanders being beaten by police. Major construction projects, including the Sears Tower (now known as the Willis Tower, which in 1974 became the world's tallest building), University of Illinois at Chicago, McCormick Place, and O'Hare International Airport, were undertaken during Richard J. Daley's tenure. In 1979, Jane Byrne, the city's first female mayor, was elected. She helped reduce crime in the Cabrini-Green housing project and led Chicago's school system out of a financial crisis.\n\nIn 1983, Harold Washington became the first black mayor of the city of Chicago. Washington's first term in office directed attention to poor and previously neglected minority neighborhoods. He was re‑elected in 1987 but died of a heart attack soon after. Washington was succeeded by 6th ward Alderman Eugene Sawyer, who was elected by the Chicago City Council and served until a special election.\n\nRichard M. Daley, son of Richard J. Daley, was elected in 1989. His accomplishments included improvements to parks and creating incentives for sustainable development, as well as closing Miegs Field in the middle of the night and destroying the runways. After successfully standing for re-election five times, and becoming Chicago's longest serving mayor, Richard M. Daley declined to run for a seventh term.\n\nIn 1992, a construction accident near the Kinzie Street Bridge produced a breach connecting the Chicago River to a tunnel below, which was part of an abandoned freight tunnel system extending throughout the downtown Loop district. The tunnels filled with of water, affecting buildings throughout the district and forcing a shutdown of electrical power. The area was shut down for three days and some buildings did not reopen for weeks; losses were estimated at $1.95 billion.\n\nOn February 23, 2011, former Illinois Congressman and White House Chief of Staff, Rahm Emanuel, won the mayoral election, after defeating challenges that he was not a Chicago resident and beating five rivals with 55 percent of the vote, and was sworn in as Mayor on May 16, 2011.\n\nChicago is located in northeastern Illinois on the southwestern shores of Lake Michigan. It is the principal city in the Chicago Metropolitan Area, situated in the Midwestern United States and the Great Lakes region. Chicago rests on a continental divide at the site of the Chicago Portage, connecting the Mississippi River and the Great Lakes watersheds. The city lies beside huge freshwater Lake Michigan, and two rivers—the Chicago River in downtown and the Calumet River in the industrial far South Side—flow entirely or partially through Chicago.\nChicago's history and economy are closely tied to its proximity to Lake Michigan. While the Chicago River historically handled much of the region's waterborne cargo, today's huge lake freighters use the city's Lake Calumet Harbor on the South Side. The lake also provides another positive effect, moderating Chicago's climate; making waterfront neighborhoods slightly warmer in winter and cooler in summer.\n\nWhen Chicago was founded in 1837, most of the early building was around the mouth of the Chicago River, as can be seen on a map of the city's original 58 blocks. The overall grade of the city's central, built-up areas, is relatively consistent with the natural flatness of its overall natural geography, generally exhibiting only slight differentiation otherwise. The average land elevation is above sea level. The lowest points are along the lake shore at , while the highest point, at , is the morainal ridge of Blue Island in the city's far south side.\n\nThe Chicago Loop is the central business district, but Chicago is also a city of neighborhoods. Lake Shore Drive runs adjacent to a large portion of Chicago's lakefront. Some of the parks along the waterfront include Lincoln Park, Grant Park, Burnham Park and Jackson Park. There are twenty-four public beaches across of the waterfront. Landfill extends into portions of the lake providing space for Navy Pier, Northerly Island, the Museum Campus, and large portions of the McCormick Place Convention Center. Most of the city's high-rise commercial and residential buildings are close to the waterfront.\n\nAn informal name for the entire Chicago metropolitan area is \"Chicagoland\". There is no precise definition for the term \"Chicagoland\", but it generally means the entire conurbation. The Chicago Tribune, which coined the term, includes the city of Chicago, the rest of Cook County, eight nearby Illinois counties: Lake, McHenry, DuPage, Kane, Kendall, Grundy, Will and Kankakee, and three counties in Indiana: Lake, Porter and LaPorte. The Illinois Department of Tourism defines Chicagoland as Cook County without the city of Chicago, and only Lake, DuPage, Kane and Will counties. The Chicagoland Chamber of Commerce defines it as all of Cook and DuPage, Kane, Lake, McHenry and Will counties.\nMajor sections of the city include the central business district, called The Loop, and the North, the South, and West Sides. The three sides of the city are represented on the Flag of Chicago by three horizontal white stripes. The North Side is the most densely populated residential section of the city, and many high-rises are located on this side of the city along the lakefront. The South Side is the largest section of the city, encompassing roughly 60% of the city's land area. The South Side contains the University of Chicago and most of the facilities of the Port of Chicago.\n\nIn the late 1920s, sociologists at the University of Chicago subdivided the city into 77 distinct community areas, which can further be subdivided into over 200 informally defined neighborhoods.\n\nChicago's streets were laid out in a street grid that grew from the city's original townsite plat, which was bounded by Lake Michigan on the east, North Avenue on the north, Wood Street on the west, and 22nd Street on the south. Streets following the Public Land Survey System section lines later became arterial streets in outlying sections. As new additions to the city were platted, city ordinance required them to be laid out with eight streets to the mile in one direction and sixteen in the other direction (about one street per 201 meters by two in the other direction). The grid's regularity provided an efficient means of developing new real estate property. A scattering of diagonal streets, many of them originally Native American trails, also cross the city (Elston, Milwaukee, Ogden, Lincoln, etc.). Many additional diagonal streets were recommended in the Plan of Chicago, but only the extension of Ogden Avenue was ever constructed.\n\nIn 2016, Chicago was ranked the sixth-most walkable large city in the United States. Many of the city's residential streets have a wide patch of grass and/or trees between the street and the sidewalk itself. This helps to keep pedestrians on the sidewalk further away from the street traffic. Chicago's Western Avenue is the longest continuous urban street in the world. Other famous streets include Michigan Avenue, State Street, Clark Street, and Belmont Avenue. The City Beautiful movement inspired Chicago's boulevards and parkways.\n\nThe destruction caused by the Great Chicago Fire led to the largest building boom in the history of the nation. In 1885, the first steel-framed high-rise building, the Home Insurance Building, rose in the city as Chicago ushered in the skyscraper era, which would then be followed by many other cities around the world. Today, Chicago's skyline is among the world's tallest and most dense.\n\nSome of the United States' tallest towers are located in Chicago; Willis Tower (formerly Sears Tower) is the second tallest building in the Western Hemisphere after One World Trade Center, and Trump International Hotel and Tower is the third tallest in the country. The Loop's historic buildings include the Chicago Board of Trade Building, the Fine Arts Building, 35 East Wacker, and the Chicago Building, 860-880 Lake Shore Drive Apartments by Mies van der Rohe. Many other architects have left their impression on the Chicago skyline such as Daniel Burnham, Louis Sullivan, Charles B. Atwood, John Root, and Helmut Jahn.\n\nThe Merchandise Mart, once first on the list of largest buildings in the world, currently listed as 44th-largest (as of September 9, 2013), had its own zip code until 2008, and stands near the junction of the North and South branches of the Chicago River. Presently, the four tallest buildings in the city are Willis Tower (formerly the Sears Tower, also a building with its own zip code), Trump International Hotel and Tower, the Aon Center (previously the Standard Oil Building), and the John Hancock Center. Industrial districts, such as some areas on the South Side, the areas along the Chicago Sanitary and Ship Canal, and the Northwest Indiana area are clustered.\n\nChicago gave its name to the Chicago School and was home to the Prairie School, two movements in architecture. Multiple kinds and scales of houses, townhouses, condominiums, and apartment buildings can be found throughout Chicago. Large swaths of the city's residential areas away from the lake are characterized by brick bungalows built from the early 20th century through the end of World War II. Chicago is also a prominent center of the Polish Cathedral style of church architecture. The Chicago suburb of Oak Park was home to famous architect Frank Lloyd Wright, who had designed The Robie House located near the University of Chicago.\n\nChicago is famous for its outdoor public art with donors establishing funding for such art as far back as Benjamin Ferguson's 1905 trust. A number of Chicago's public art works are by modern figurative artists. Among these are Chagall's Four Seasons; the Chicago Picasso; Miro's Chicago; Calder's Flamingo; Oldenburg's Batcolumn; Moore's Large Interior Form, 1953-54, Man Enters the Cosmos and Nuclear Energy; Dubuffet's Monument with Standing Beast, Abakanowicz's Agora; and, Anish Kapoor's Cloud Gate which has become an icon of the city. Some events which shaped the city's history have also been memorialized by art works, including the Great Northern Migration (Saar) and the centennial of statehood for Illinois. Finally, two fountains near the Loop also function as monumental works of art: Plensa's Crown Fountain as well as Burnham and Bennett's Buckingham Fountain.\n\nMore representational and portrait statuary includes a number of works by Lorado Taft (Fountain of Time, The Crusader, Eternal Silence, and the Heald Square Monument completed by Crunelle), French's Statue of the Republic, Edward Kemys's Lions, Saint-Gaudens's (a.k.a. Standing Lincoln) and (a.k.a. Seated Lincoln), Brioschi's Christopher Columbus, Meštrović's The Bowman and The Spearman, Dallin's Signal of Peace, Fairbanks's The Chicago Lincoln, Boyle's The Alarm, Polasek's memorial to Masaryk, memorials along \"Solidarity Promenade\" to Kościuszko, Havliček and Copernicus by Chodzinski, Strachovský, and Thorvaldsen, a memorial to General Logan by Saint-Gaudens, and Kearney's Moose (W-02-03). A number of statues also honor recent local heroes such as Michael Jordan (by Amrany and Rotblatt-Amrany), Stan Mikita, and Bobby Hull outside of the United Center; Harry Caray (by Amrany and Cella) outside Wrigley field, Jack Brickhouse (by McKenna) next to the WGN studios, and Irv Kupcinet at the Wabash Avenue Bridge.\n\nThere are preliminary plans to erect a 1:1‑scale replica of Wacław Szymanowski's \"Art Nouveau\" statue of Frédéric Chopin found in Warsaw's Royal Baths along Chicago's lakefront in addition to a different sculpture commemorating the artist in Chopin Park for the 200th anniversary of Frédéric Chopin's birth.\n\nThe city lies within the humid continental climate zone (Köppen: \"Dfa\"), and experiences four distinct seasons. Summers are warm to hot and often humid, with a July daily average of . In a normal summer, temperatures can exceed as many as 21 days. Winters are cold and snowy with few sunny days, and the normal January high is just below freezing. Spring and autumn are mild seasons with low humidity. Dewpoint temperatures in the summer range from in June to in July. The city is part of the USDA Plant Hardiness zone 6a, transitioning to 5b in the suburbs.\n\nAccording to the National Weather Service, Chicago's highest official temperature reading of was recorded on July 24, 1934, although Midway Airport reached one day prior and recorded a heat index of during the 1995 heatwave. The lowest official temperature of was recorded on January 20, 1985, at O'Hare Airport. The city can experience extreme winter cold waves and summer heat waves that may last for several consecutive days. Thunderstorms are common during the spring and summer months which may sometimes produce hail, high winds, and tornadoes. Like other major cities, Chicago also experiences urban heat island, making the city and its suburbs milder than surrounding rural areas, especially at night and in winter. Also, the proximity to Lake Michigan keeps lakefront Chicago cooler in early summer and milder in winter than areas to the west.\n\nDuring its first hundred years, Chicago was one of the fastest-growing cities in the world. When founded in 1833, fewer than 200 people had settled on what was then the American frontier. By the time of its first census, seven years later, the population had reached over 4,000. In the forty years from 1850 to 1890, the city's population grew from slightly under 30,000 to over 1 million. At the end of the 19th century, Chicago was the fifth-largest city in the world, and the largest of the cities that did not exist at the dawn of the century. Within sixty years of the Great Chicago Fire of 1871, the population went from about 300,000 to over 3 million, and reached its highest ever recorded population of 3.6 million for the 1950 census.\n\nFrom the last two decades of the 19th century, Chicago was the destination of waves of immigrants from Ireland, Southern, Central and Eastern Europe, including Italians, Jews, Poles, Lithuanians, Albanians, Croatians, Serbs, Bosnians, Montenegrins and Czechs. To these ethnic groups, the basis of the city's industrial working class, were added an additional influx of African-Americans from the American South — with Chicago's black population doubling between 1910 and 1920 and doubling again between 1920 and 1930.\n\nIn the 1920s and 1930s, the great majority of African Americans moving to Chicago were clustered in a so‑called \"Black Belt\" on the city's South Side. By 1930, two-thirds of Chicago's African-American population lived in sections of the city which were 90% black in racial composition. Chicago's South Side emerged as America's second-largest urban black concentration, following New York's Harlem.\n\nChicago's population declined sharply in the latter half of the 20th century, from over 3.6 million in 1950 down to under 2.7 million by 2010. In 1984, it was overtaken by Los Angeles as America's second largest city.\n\nSince 2010, Chicago's population has rebounded adding nearly 25,000 people in the most recent 2015 population estimates.\n\nAs of the 2010 census, there were 2,695,598 people with 1,045,560 households living in Chicago. More than half the population of the state of Illinois lives in the Chicago metropolitan area. Chicago is one of the United States' most densely populated major cities, and the largest city in the Great Lakes Megalopolis. The racial composition of the city was:\nChicago has a Hispanic or Latino population of 28.9%. (Its members may belong to any race; 21.4% Mexican, 3.8% Puerto Rican, 0.7% Guatemalan, 0.6% Ecuadorian, 0.3% Cuban, 0.3% Colombian, 0.2% Honduran, 0.2% Salvadoran, 0.2% Peruvian)\n\nThe city's previous largest ethnic group, non-Hispanic white, declined from 59% in 1970 to 31.7% in 2010.\n\nChicago has the third-largest LGBT population in the United States. In 2015, roughly 4% of the population identified as LGBT. Since the 2013 legalization of same-sex marriage in Illinois, over 10,000 same-sex couples have wed in Cook County, a majority in Chicago.\n\nAccording to the U.S. Census Bureau's American Community Survey data estimates for 2008–2012, the median income for a household in the city was $47,408, and the median income for a family was $54,188. Male full-time workers had a median income of $47,074 versus $42,063 for females. About 18.3% of families and 22.1% of the population lived below the poverty line.\n\nAccording to the 2008–2012 American Community Survey, the ancestral groups having 10,000 or more persons in Chicago were:\n\nPersons identifying themselves as \"Other groups\" were classified at 1.72 million, and unclassified or not reported were approximately 153,000.\n\n71% of Chicagoans identify as Christians, 7% identity with other faiths, and 22% have no religious affiliation. Chicago also has many Jews, Muslims, Buddhists, Hindus, and others.\nChicago is the headquarters of several religious denominations, including the Evangelical Covenant Church and the Evangelical Lutheran Church in America. It is the seat of several diocese. The Fourth Presbyterian Church is one of the largest Presbyterian congregations in the United States based on memberships.\n\nThe first two Parliament of the World's Religions in 1893 and 1993 were held in Chicago. Many international religious leaders have visited Chicago, including Mother Teresa, the Dalai Lama, and Pope John Paul II in 1979.\n\nChicago has the third-largest gross metropolitan product in the United States—about $658.6 billion according to 2014–2016 estimates. The city has also been rated as having the most balanced economy in the United States, due to its high level of diversification. In 2007, Chicago was named the fourth-most important business center in the world in the MasterCard Worldwide Centers of Commerce Index. Additionally, the Chicago metropolitan area recorded the greatest number of new or expanded corporate facilities in the United States for calendar year 2014. The Chicago metropolitan area has the third-largest science and engineering work force of any metropolitan area in the nation. In 2009 Chicago placed 9th on the UBS list of the world's richest cities. Chicago was the base of commercial operations for industrialists John Crerar, John Whitfield Bunn, Richard Teller Crane, Marshall Field, John Farwell, Julius Rosenwald and many other commercial visionaries who laid the foundation for Midwestern and global industry.\n\nChicago is a major world financial center, with the second-largest central business district in the United States. The city is the headquarters of the Federal Reserve Bank of Chicago (the Seventh District of the Federal Reserve). The city has major financial and futures exchanges, including the Chicago Stock Exchange, the Chicago Board Options Exchange (CBOE), and the Chicago Mercantile Exchange (the \"Merc\"), which is owned, along with the Chicago Board of Trade (CBOT) by Chicago's CME Group. The CME Group, in addition, owns the New York Mercantile Exchange (NYMEX), the Commodities Exchange Inc. (COMEX) and the Dow Jones Indexes. Perhaps due to the influence of the Chicago school of economics, the city also has markets trading unusual contracts such as emissions (on the Chicago Climate Exchange) and equity style indices (on the U.S. Futures Exchange). Chase Bank has its commercial and retail banking headquarters in Chicago's Chase Tower.\n\nThe city and its surrounding metropolitan area contain the third-largest labor pool in the United States with about 4.48 million workers, .\n\nManufacturing, printing, publishing and food processing also play major roles in the city's economy. Several medical products and services companies are headquartered in the Chicago area, including Baxter International, Boeing, Abbott Laboratories, and the Healthcare division of General Electric. In addition to Boeing, which located its headquarters in Chicago in 2001, and United Airlines in 2011, GE Transportation moved its offices to the city in 2013 and GE Healthcare moved its HQ to the city in 2016, as did ThyssenKrupp North America, and agriculture giant Archer Daniels Midland. Moreover, the construction of the Illinois and Michigan Canal, which helped move goods from the Great Lakes south on the Mississippi River, and of the railroads in the 19th century made the city a major transportation center in the United States. In the 1840s, Chicago became a major grain port, and in the 1850s and 1860s Chicago's pork and beef industry expanded. As the major meat companies grew in Chicago many, such as Armour and Company, created global enterprises. Though the meatpacking industry currently plays a lesser role in the city's economy, Chicago continues to be a major transportation and distribution center. Lured by a combination of large business customers, federal research dollars, and a large hiring pool fed by the area's universities, Chicago is also the site of a growing number of web startup companies like CareerBuilder, Orbitz, 37signals, Groupon, Feedburner, and NowSecure.\n\nChicago has been a hub of the Retail sector since its early development, with Montgomery Ward, Sears, and Marshall Field's. Today the Chicago metropolitan area is the headquarters of several retailers, including Walgreens, Sears, Ace Hardware, Claire's, ULTA Beauty and Crate & Barrel.\n\nLate in the 19th century, Chicago was part of the bicycle craze, with the Western Wheel Company, which introduced stamping to the production process and significantly reduced costs, while early in the 20th century, the city was part of the automobile revolution, hosting the Brass Era car builder Bugmobile, which was founded there in 1907. Chicago was also the site of the Schwinn Bicycle Company.\n\nChicago is a major world convention destination. The city's main convention center is McCormick Place. With its four interconnected buildings, it is the largest convention center in the nation and third-largest in the world. Chicago also ranks third in the U.S. (behind Las Vegas and Orlando) in number of conventions hosted annually.\n\nChicago's minimum wage for non-tipped employees is one of the highest in the nation and will incrementally reach $13 per hour by 2019.\n\nThe city's waterfront location and nightlife has attracted residents and tourists alike. Over a third of the city population is concentrated in the lakefront neighborhoods from Rogers Park in the north to South Shore in the south. The city has many upscale dining establishments as well as many ethnic restaurant districts. These districts include the Mexican American neighborhoods, such as Pilsen along 18th street, and \"La Villita\" along 26th Street; the Puerto Rican enclave of Paseo Boricua in the Humboldt Park neighborhood; Greektown, along South Halsted Street, immediately west of downtown; Little Italy, along Taylor Street; Chinatown in Armour Square; Polish Patches in West Town; Little Seoul in Albany Park around Lawrence Avenue; Little Vietnam near Broadway in Uptown; and the Desi area, along Devon Avenue in West Ridge.\n\nDowntown is the center of Chicago's financial, cultural, governmental and commercial institutions and the site of Grant Park and many of the city's skyscrapers. Many of the city's financial institutions, such as the CBOT and the Federal Reserve Bank of Chicago, are located within a section of downtown called \"The Loop\", which is an eight-block by five-block area of city streets that is encircled by elevated rail tracks. The term \"The Loop\" is largely used by locals to refer to the entire downtown area as well. The central area includes the Near North Side, the Near South Side, and the Near West Side, as well as the Loop. These areas contribute famous skyscrapers, abundant restaurants, shopping, museums, a stadium for the Chicago Bears, convention facilities, parkland, and beaches.\n\nLincoln Park contains the Lincoln Park Zoo and the Lincoln Park Conservatory. The River North Gallery District features the nation's largest concentration of contemporary art galleries outside of New York City.\n\nLakeview is home to Boystown (pronounced boys town), which, along with Andersonville, are some of the best-known LGBT neighborhoods in the nation. Each year in June, Boystown hosts the Chicago Pride Parade, one of the world's largest with over 1,000,000 people in attendance.\n\nThe South Side neighborhood of Hyde Park is the home of former US President Barack Obama. It also contains the University of Chicago (U of C), ranked one of the world's top ten universities; and the Museum of Science and Industry. The long Burnham Park stretches along the waterfront of the South Side. Two of the city's largest parks are also located on this side of the city: Jackson Park, bordering the waterfront, hosted the World's Columbian Exposition in 1893, and is the site of the aforementioned museum; and slightly west sits Washington Park. The two parks themselves are connected by a wide strip of parkland called the Midway Plaisance, running adjacent to the University of Chicago. The South Side hosts one of the city's largest parades, the annual African American Bud Billiken Parade and Picnic, which travels through Bronzeville to Washington Park. Ford Motor Company has an automobile assembly plant on the South Side in Hegewisch, and most of the facilities of the Port of Chicago are also on the South Side.\n\nThe West Side holds the Garfield Park Conservatory, one of the largest collections of tropical plants in any U.S. city. Prominent Latino cultural attractions found here include Humboldt Park's Institute of Puerto Rican Arts and Culture and the annual Puerto Rican People's Parade, as well as the National Museum of Mexican Art and St. Adalbert's Church in Pilsen. The Near West Side holds the University of Illinois at Chicago and was once home to Oprah Winfrey's Harpo Studios.\n\nThe city's distinctive accent, made famous by its use in classic films like \"The Blues Brothers\" and television programs like the \"Saturday Night Live\" skit \"Bill Swerski's Superfans\", is an advanced form of Inland Northern American English. This dialect can also be found in other cities bordering the Great Lakes such as Cleveland, Milwaukee, Detroit, and Rochester, New York, and most prominently features a rearrangement of certain vowel sounds, such as the short 'a' sound as in \"cat\", which can sound more like \"kyet\" to outsiders. The accent remains well associated with the city.\n\nRenowned Chicago theater companies include the Goodman Theatre in the Loop; the Steppenwolf Theatre Company and Victory Gardens Theater in Lincoln Park; and the Chicago Shakespeare Theater at Navy Pier. Broadway In Chicago offers Broadway-style entertainment at five theaters: the Ford Center for the Performing Arts Oriental Theatre, Bank of America Theatre, Cadillac Palace Theatre, Auditorium Building of Roosevelt University, and Broadway Playhouse at Water Tower Place. Polish language productions for Chicago's large Polish speaking population can be seen at the historic Gateway Theatre in Jefferson Park. Since 1968, the Joseph Jefferson Awards are given annually to acknowledge excellence in theater in the Chicago area. Chicago's theater community spawned modern improvisational theater, and includes the prominent groups The Second City and I.O. (formerly ImprovOlympic).\n\nThe Chicago Symphony Orchestra (CSO) performs at Symphony Center, and is recognized as one of the best orchestras in the world. Also performing regularly at Symphony Center is the Chicago Sinfonietta, a more diverse and multicultural counterpart to the CSO. In the summer, many outdoor concerts are given in Grant Park and Millennium Park. Ravinia Festival, located north of Chicago, is the summer home of the CSO, and is a favorite destination for many Chicagoans. The Civic Opera House is home to the Lyric Opera of Chicago. The Lithuanian Opera Company of Chicago was founded by Lithuanian Chicagoans in 1956, and presents operas in Lithuanian.\n\nThe Joffrey Ballet and Chicago Festival Ballet perform in various venues, including the Harris Theater in Millennium Park. Chicago has several other contemporary and jazz dance troupes, such as the Hubbard Street Dance Chicago and Chicago Dance Crash.\n\nOther live-music genre which are part of the city's cultural heritage include Chicago blues, Chicago soul, jazz, and gospel. The city is the birthplace of house music, a very popular form of Electronic Dance Music, and industrial music and is the site of an influential hip-hop scene. In the 1980s and 90s, the city was the global center for house and industrial music, two forms of music created in Chicago, as well as being popular for alternative rock, punk, and new wave. The city has been an epicenter for rave culture, since the 1980s. A flourishing independent rock music culture brought forth Chicago indie. Annual festivals feature various acts, such as Lollapalooza and the Pitchfork Music Festival. A 2007 report on the Chicago music industry by the University of Chicago Cultural Policy Center ranked Chicago third among metropolitan U.S. areas in \"size of music industry\" and fourth among all U.S. cities in \"number of concerts and performances\".\n\nChicago has a distinctive fine art tradition. For much of the twentieth century, it nurtured a strong style of figurative surrealism, as in the works of Ivan Albright and Ed Paschke. In 1968 and 1969, members of the Chicago Imagists, such as Roger Brown, Leon Golub, Robert Lostutter, Jim Nutt, and Barbara Rossi produced bizarre representational paintings.\n\nChicago contains a number of large, outdoor works by well-known artists. These include the Chicago Picasso, \"Miró's Chicago\", \"Flamingo\" and \"Flying Dragon\" by Alexander Calder, \"Agora\" by Magdalena Abakanowicz, \"Monument with Standing Beast\" by Jean Dubuffet, \"Batcolumn\" by Claes Oldenburg, \"Cloud Gate\" by Anish Kapoor, \"Crown Fountain\" by Jaume Plensa, and the \"Four Seasons\" mosaic by Marc Chagall.\n\nChicago also has a nationally televised Thanksgiving parade that occurs annually. The McDonald's Thanksgiving Parade is seen across the nation on WGN-TV and WGN America, featuring a variety of diverse acts from the community, marching bands from across the country, and is the only parade in the city to feature inflatable balloons every year.\n\n, Chicago attracted 50.17 million domestic leisure travelers, 11.09 million domestic business travelers and 1.308 million overseas visitors. These visitors contributed more than billion to Chicago's economy. Upscale shopping along the Magnificent Mile and State Street, thousands of restaurants, as well as Chicago's eminent architecture, continue to draw tourists. The city is the United States' third-largest convention destination. A 2011 study by Walk Score ranked Chicago the fourth-most walkable of fifty largest cities in the United States. Most conventions are held at McCormick Place, just south of Soldier Field. The historic Chicago Cultural Center (1897), originally serving as the Chicago Public Library, now houses the city's Visitor Information Center, galleries and exhibit halls. The ceiling of its Preston Bradley Hall includes a Tiffany glass dome. Grant Park holds Millennium Park, Buckingham Fountain (1927), and the Art Institute of Chicago. The park also hosts the annual Taste of Chicago festival. In Millennium Park, there is the reflective \"Cloud Gate\" sculpture. Cloud Gate, a public sculpture by Indian-born British artist Anish Kapoor, is the centerpiece of the AT&T Plaza in Millennium Park. Also, an outdoor restaurant transforms into an ice rink in the winter season. Two tall glass sculptures make up the Crown Fountain. The fountain's two towers display visual effects from LED images of Chicagoans' faces, along with water spouting from their lips. Frank Gehry's detailed, stainless steel band shell, the Jay Pritzker Pavilion, hosts the classical Grant Park Music Festival concert series. Behind the pavilion's stage is the Harris Theater for Music and Dance, an indoor venue for mid-sized performing arts companies, including the Chicago Opera Theater and Music of the Baroque.\n\nNavy Pier, located just east of Streeterville, is long and houses retail stores, restaurants, museums, exhibition halls and auditoriums. In the summer of 2016, Navy Pier will have constructed their new DW60 Ferris wheel. Dutch Wheels, a world renowned company that manufactures ferris wheels, was selected to design the new wheel. It will feature 42 navy blue gondolas that can hold up to eight adults and two kids. It will also have entertainment systems inside the gondolas as well as a climate controlled environment. The DW60 will stand at approximately 196 ft (60 m), which is 46 ft taller than the previous wheel. The new DW60 will be the first in the United States and will be the sixth tallest in the U.S. Chicago was the first city in the world to ever erect a ferris wheel.\n\nOn June 4, 1998, the city officially opened the Museum Campus, a lakefront park, surrounding three of the city's main museums, each of which is of national importance: the Adler Planetarium & Astronomy Museum, the Field Museum of Natural History, and the Shedd Aquarium. The Museum Campus joins the southern section of Grant Park, which includes the renowned Art Institute of Chicago. Buckingham Fountain anchors the downtown park along the lakefront. The University of Chicago Oriental Institute has an extensive collection of ancient Egyptian and Near Eastern archaeological artifacts. Other museums and galleries in Chicago include the Chicago History Museum, the Driehaus Museum, the DuSable Museum of African American History, the Museum of Contemporary Art, the Peggy Notebaert Nature Museum, the Polish Museum of America, the Museum of Broadcast Communications, the Pritzker Military Library, the Chicago Architecture Foundation, and the Museum of Science and Industry.\n\nWith an estimated completion date of 2020, the Barack Obama Presidential Center will be housed at the University of Chicago in Hyde Park and include both the Obama presidential library and offices of the Obama Foundation.\n\nThe Willis Tower (formerly named Sears Tower) is a popular destination for tourists. The Willis Tower has an observation deck open to tourists year round with high up views overlooking Chicago and Lake Michigan. The observation deck includes an enclosed glass balcony that extends 10 feet out on the side of the building. Tourists are able to look straight down.\n\nIn 2013, Chicago was chosen as one of the \"Top Ten Cities in the United States\" to visit for its restaurants, skyscrapers, museums, and waterfront, by the readers of \"Condé Nast Traveler\".\n\nChicago lays claim to a large number of regional specialties that reflect the city's ethnic and working-class roots. Included among these are its nationally renowned deep-dish pizza; this style is said to have originated at Pizzeria Uno. The Chicago-style thin crust is also popular in the city.\n\nThe Chicago-style hot dog, typically an all-beef hot dog, is loaded with an array of toppings that often includes pickle relish, yellow mustard, pickled sport peppers, tomato wedges, dill pickle spear and topped off with celery salt on a poppy seed bun. Enthusiasts of the Chicago-style dog frown upon the use of ketchup as a garnish, but may prefer to add giardiniera.\n\nThere are several distinctly Chicago sandwiches, among them the Italian beef sandwich, which is thinly sliced beef simmered in au jus and served on an Italian roll with sweet peppers or spicy giardiniera. A popular modification is the Combo—an Italian beef sandwich with the addition of an Italian sausage. Another is the Maxwell Street Polish, a grilled or deep-fried kielbasa — on a hot dog roll, topped with grilled onions, yellow mustard, and hot sport peppers.\n\nEthnically originated creations include chicken Vesuvio, with roasted bone-in chicken cooked in oil and garlic next to garlicky oven-roasted potato wedges and a sprinkling of green peas. Another is the Puerto Rican-influenced jibarito, a sandwich made with flattened, fried green plantains instead of bread. There is also the mother-in-law, a tamale topped with chili and served on a hot dog bun. The tradition of serving the Greek dish, saganaki while aflame, has its origins in Chicago's Greek community. The appetizer, which consists of a square of fried cheese, is doused with Metaxa and flambéed table-side.\n\nTwo of the world's most decorated restaurants and also receiving the Michelin Guide 3 Star Award, Alinea and Grace are both located in Chicago. In addition, a number of well-known chefs have had restaurants in Chicago, including Charlie Trotter, Rick Tramonto, Grant Achatz, and Rick Bayless. In 2003, \"Robb Report\" named Chicago the country's \"most exceptional dining destination\".\n\nChicago literature finds its roots in the city's tradition of lucid, direct journalism, lending to a strong tradition of social realism. In the \"Encyclopedia of Chicago\", Northwestern University Professor Bill Savage describes Chicago fiction as prose which tries to \"\"capture the essence of the city, its spaces and its people\"\". The challenge for early writers was that Chicago was a frontier outpost that transformed into a global metropolis in the span of two generations. Narrative fiction of that time, much of it in the style of \"high-flown romance\" and \"genteel realism\", needed a new approach to describe the urban social, political, and economic conditions of Chicago. Nonetheless, Chicagoans worked hard to create a literary tradition that would stand the test of time, and create a \"city of feeling\" out of concrete, steel, vast lake, and open prairie. Much notable Chicago fiction focuses on the city itself, with social criticism keeping exultation in check.\n\nAt least, three short periods in the history of Chicago have had a lasting influence on American Literature. These include from the time of the Great Chicago Fire to about 1900, what became known as the Chicago Literary Renaissance in the 1910s and early 1920s, and the period of the Great Depression through the 1940s.\n\nWhat would become the influential \"Poetry\" magazine was founded in 1912 by Harriet Monroe, who was working as an art critic for the \"Chicago Tribune\". The magazine discovered such poets as Gwendolyn Brooks, James Merrill, and John Ashbery. T. S. Eliot's first professionally published poem, \"The Love Song of J. Alfred Prufrock\", was first published by \"Poetry\". Contributors have included Ezra Pound, William Butler Yeats, William Carlos Williams, Langston Hughes, and Carl Sandburg, among others. The magazine was instrumental in launching the Imagist and Objectivist poetic movements.\n\n\"Sporting News\" named Chicago the \"Best Sports City\" in the United States in 1993, 2006, and 2010. Along with Boston, Chicago is the only city to continuously host major professional sports since 1871, having only taken 1872 and 1873 off due to the Great Chicago Fire. Additionally, Chicago is one of the six cities in the United States to have won championships in the four major professional leagues and, along with New York and Los Angeles, is one of three cities to have won soccer championships as well. Several major franchises have won championships within recent years – the Bears (1985), the Bulls (91, '92, '93, '96, '97, and '98), the White Sox (2005), the Cubs (2016), the Blackhawks (2010, 2013, 2015), and the Fire (1998).\n\nThe city has two Major League Baseball (MLB) teams: the Chicago Cubs of the National League play in Wrigley Field on the North Side; and the Chicago White Sox of the American League play in Guaranteed Rate Field on the South Side. Chicago is the only city that has had more than one MLB franchise every year since the AL began in 1901 (New York hosted only one between 1958 and early 1962). The Cubs are the oldest Major League Baseball team to have never changed their city; they have played in Chicago since 1871, and continuously so since 1874 due to the Great Chicago Fire. They have played more games and have more wins than any other team in Major League baseball since 1876. They have won three World Series titles, including the 2016 World Series, but had the dubious honor of having the two longest droughts in American professional sports: They had not won their sport's title since 1908, and had not participated in a World Series since 1945, both records, until they beat the Cleveland Indians in the 2016 World Series.\n\nThe White Sox have played on the South Side continuously since 1901, with all three of their home fields throughout the years being within blocks of one another. They have won three World Series titles (1906, 1917, 2005) and six American League pennants, including the first in 1901. The Sox are fifth in the American League in all-time wins, and sixth in pennants.\n\nThe Chicago Bears, one of the last two remaining charter members of the National Football League (NFL), have won nine NFL Championships, including the 1985 Super Bowl XX. The other remaining charter franchise, the Chicago Cardinals, also started out in the city, but is now known as the Arizona Cardinals. The Bears have won more games in the history of the NFL than any other team, and only the Green Bay Packers, their longtime rivals, have won more championships. The Bears play their home games at Soldier Field. Soldier Field re-opened in 2003 after an extensive renovation.\n\nThe Chicago Bulls of the National Basketball Association (NBA) is one of the most recognized basketball teams in the world. During the 1990s, with Michael Jordan leading them, the Bulls won six NBA championships in eight seasons. They also boast the youngest player to win the NBA Most Valuable Player Award, Derrick Rose, who won it for the 2010–11 season.\n\nThe Chicago Blackhawks of the National Hockey League (NHL) began play in 1926, and are one of the \"Original Six\" teams of the NHL. The Blackhawks have won six Stanley Cups, including in 2010, 2013, and 2015. Both the Bulls and the Blackhawks play at the United Center.\n\nThe Chicago Fire Soccer Club is a member of Major League Soccer (MLS) and plays at Toyota Park in suburban Bridgeview, after playing its first eight seasons at Soldier Field. The Fire have won one league title and four U.S. Open Cups, since their founding in 1997. In 1994, the United States hosted a successful FIFA World Cup with games played at Soldier Field.\nThe Chicago Sky is a professional basketball team based in Rosemont, Illinois, playing in the Women's National Basketball Association (WNBA). They play home games at the Allstate Arena. The team was founded before the 2006 WNBA season began.\n\nThe Chicago Marathon has been held each year since 1977 except for 1987, when a half marathon was run in its place. The Chicago Marathon is one of six World Marathon Majors.\n\nFive area colleges play in Division I conferences: two from major conferences—the DePaul Blue Demons (Big East Conference) and the Northwestern Wildcats (Big Ten Conference)—and three from other D1 conferences—the Chicago State Cougars (Western Athletic Conference); the Loyola Ramblers (Missouri Valley Conference); and the UIC Flames (Horizon League).\n\nWhen Chicago was incorporated in 1837, it chose the motto \"Urbs in Horto\", a Latin phrase which means \"City in a Garden\". Today, the Chicago Park District consists of more than 570 parks with over of municipal parkland. There are 31 sand beaches, a plethora of museums, two world-class conservatories, and 50 nature areas. Lincoln Park, the largest of the city's parks, covers and has over 20 million visitors each year, making it third in the number of visitors after Central Park in New York City, and the National Mall and Memorial Parks in Washington, D.C.\n\nThere is a historic boulevard system, a network of wide, tree-lined boulevards which connect a number of Chicago parks. The boulevards and the parks were authorized by the Illinois legislature in 1869. A number of Chicago neighborhoods emerged along these roadways in the 19th century. The building of the boulevard system continued intermittently until 1942. It includes nineteen boulevards, eight parks, and six squares, along twenty-six miles of interconnected streets. Part of the system in the Logan Square Boulevards Historic District was listed in the National Register of Historic Places in 1985.\n\nWith berths for more than 6,000 boats, the Chicago Park District operates the nation's largest municipal harbor system. In addition to ongoing beautification and renewal projects for the existing parks, a number of new parks have been added in recent years, such as the Ping Tom Memorial Park in Chinatown, DuSable Park on the Near North Side, and most notably, Millennium Park, which is in the northwestern corner of one of Chicago's oldest parks, Grant Park in the Chicago Loop.\n\nThe wealth of greenspace afforded by Chicago's parks is further augmented by the Cook County Forest Preserves, a network of open spaces containing forest, prairie, wetland, streams, and lakes that are set aside as natural areas which lie along the city's outskirts, including both the Chicago Botanic Garden in Glencoe and the Brookfield Zoo in Brookfield. Washington Park is also one of the city's biggest parks; covering nearly . The park is listed on the National Register of Historic Places listings in South Side Chicago.\n\nThe government of the City of Chicago is divided into executive and legislative branches. The Mayor of Chicago is the chief executive, elected by general election for a term of four years, with no term limits. The current mayor is Rahm Emanuel. The mayor appoints commissioners and other officials who oversee the various departments. As well as the mayor, Chicago's clerk and treasurer are also elected citywide. The City Council is the legislative branch and is made up of 50 aldermen, one elected from each ward in the city. The council takes official action through the passage of ordinances and resolutions and approves the city budget.\n\nThe Chicago Police Department provides law enforcement and the Chicago Fire Department provides fire suppression and emergency medical services for the city and its residents. Civil and criminal law cases are heard in the Cook County Circuit Court of the State of Illinois court system, or in the Northern District of Illinois, in the federal system. In the state court, the public prosecutor is the Illinois State's Attorney; in the Federal court it is the United States Attorney.\n\nDuring much of the last half of the 19th century, Chicago's politics were dominated by a growing Democratic Party organization. During the 1880s and 1890s, Chicago had a powerful radical tradition with large and highly organized socialist, anarchist and labor organizations. For much of the 20th century, Chicago has been among the largest and most reliable Democratic strongholds in the United States; with Chicago's Democratic vote the state of Illinois has been \"solid blue\" in presidential elections since 1992. Even before then, it was not unheard of for Republican presidential candidates to win handily in downstate Illinois, only to lose statewide due to large Democratic margins in Chicago. The citizens of Chicago have not elected a Republican mayor since 1927, when William Thompson was voted into office. The strength of the party in the city is partly a consequence of Illinois state politics, where the Republicans have come to represent rural and farm concerns while the Democrats support urban issues such as Chicago's public school funding. Chicago contains less than 25% of the state's population, but 8 of Illinois' 19 U.S. Representatives have part of Chicago in their districts.\n\nMachine politics persisted in Chicago after the decline of similar machines in other large U.S. cities. During much of that time, the city administration found opposition mainly from a liberal \"independent\" faction of the Democratic Party. The independents finally gained control of city government in 1983 with the election of Harold Washington (in office 1983–1987). From 1989 until May 16, 2011, Chicago was under the leadership of its longest serving mayor, Richard M. Daley, the son of Richard J. Daley. On May 16, 2011, Rahm Emanuel was sworn in as the 55th mayor of Chicago. Because of the dominance of the Democratic Party in Chicago, the Democratic primary vote held in the spring is generally more significant than the general elections in November for U.S. House and Illinois State seats. The aldermanic, mayoral, and other city offices are filled through nonpartisan elections with runoffs as needed.\n\nFormerly a state legislator representing Chicago and later a US Senator, the city is home of former United States President Barack Obama and First Lady Michelle Obama. The Obama's residence is located near the University of Chicago in Kenwood on the city's south side.\n\nChicago had a murder rate of 18.5 per 100,000 residents in 2012, ranking 16th among cities with 100,000 people or more. This was higher than in New York City and Los Angeles, the two largest cities in the United States, which have lower murder rates and lower total homicides. However, it was less than in many smaller American cities, including New Orleans, Newark, and Detroit, which had 53 murders per 100,000 residents in 2012. The 2015 year-end crime statistics showed there were 468 murders in Chicago in 2015 compared with 416 the year before, a 12.5% increase, as well as 2,900 shootings—13% more than the year prior, and up 29% since 2013. Chicago had more homicides than any other city in 2015 in total but not on per capita basis, according to the Chicago Tribune. In its annual crime statistics for 2016, the Chicago Police Department reported that the city experienced a dramatic rise in gun violence, with 4,331 shooting victims. The department also reported 762 murders in Chicago for the year 2016, a total that marked a 62.8% increase in homicides from 2015. In June 2017, the Chicago Police Department and the Federal ATF announced a new task force, similar to past task forces, to address the flow of illegal guns and repeat offenses with guns.\nAccording to reports in 2013, \"most of Chicago's violent crime comes from gangs trying to maintain control of drug-selling territories\", and is specifically related to the activities of the Sinaloa Cartel, which by 2006 had decided to seek to control illicit drug distribution, against local street gangs. Violent crime rates vary significantly by area of the city, with more economically developed areas having low rates, but other sections have much higher rates of crime. In 2013, the violent crime rate was 910 per 100,000 people; the murder rate was 10.4 – while high crime districts saw 38.9, low crime districts saw 2.5 murders per 100,000.\n\nThe number of murders in Chicago peaked at 970 in 1974, when the city's population was over 3 million people (a murder rate of about 29 per 100,000), and it reached 943 murders in 1992, (a murder rate of 34 per 100,000). However, Chicago, like other major U.S. cities, experienced a significant reduction in violent crime rates through the 1990s, falling to 448 homicides in 2004, its lowest total since 1965 and only 15.65 murders per 100,000. Chicago's homicide tally remained low during 2005 (449), 2006 (452), and 2007 (435) but rose to 510 in 2008, breaking 500 for the first time since 2003. In 2009, the murder count fell to 458 (10% down). and in 2010 Chicago's murder rate fell to 435 (16.14 per 100,000), a 5% decrease from 2009 and lowest levels since 1965. In 2011, Chicago's murders fell another 1.2% to 431 (a rate of 15.94 per 100,000). but shot up to 506 in 2012.\n\nIn 2012, Chicago ranked 21st in the United States in numbers of homicides per person, but in the first half of 2013 there was a significant drop per-person, in all categories of violent crime, including homicide (down 26%). Chicago ended 2013 with 415 murders, the lowest number of murders since 1965, and overall crime rates dropped by 16 percent. (In 1965, there were 397 murders.)\n\nJens Ludwig, director of the University of Chicago Crime Lab, estimated that shootings cost the city of Chicago $2.5 billion in 2012.\n\nIn 2014, the Chicago police department reported a total murder count of 390 through December 20, 2014, according to the \"Chicago Sun-Times\". That means that Chicago was able to record their lowest number of murder totals in close to five years for the second continuous calendar year, despite an overall increase in shootings. The Cook County medical examiner's office had reported a total of 410 homicides with 16 of those including fatal police shootings, all within the same time period.\n\nChicago Public Schools (CPS) is the governing body of the school district that contains over 600 public elementary and high schools citywide, including several selective-admission magnet schools. There are eleven selective enrollment high schools in the Chicago Public Schools, designed to meet the needs of Chicago's most academically advanced students. These schools offer a rigorous curriculum with mainly honors and Advanced Placement (AP) courses. Northside College Preparatory High School is ranked number one in the city of Chicago and the state of Illinois. Walter Payton College Prep High School is ranked second, Jones College Prep is third, and the oldest magnet school in the city, Whitney M. Young Magnet High School, which was opened in 1975, is ranked fourth. The magnet school with the largest enrollment is Lane Technical College Prep High School. Lane is one of the oldest schools in Chicago and in 2012 was designated a National Blue Ribbon School by the U.S. Department of Education.\n\nChicago high school rankings are determined by the average test scores on state achievement tests. The district, with an enrollment exceeding 400,545 students (2013–2014 20th Day Enrollment), is the third-largest in the U.S. On September 10, 2012, teachers for the Chicago Teachers Union went on strike for the first time since 1987 over pay, resources and other issues. According to data compiled in 2014, Chicago's \"choice system\", where students who test or apply and may attend one of a number of public high schools (there are about 130), sorts students of different achievement levels into different schools (high performing, middle performing, and low performing schools).\n\nChicago has a network of Lutheran schools, and several private schools are run by other denominations and faiths, such as the Ida Crown Jewish Academy in West Ridge. Several private schools are completely secular, such as the Latin School of Chicago in the Near North Side neighborhood, the University of Chicago Laboratory Schools in Hyde Park, the British School of Chicago and the Francis W. Parker School in Lincoln Park, the Lycée Français de Chicago in Uptown, the Feltre School in River North and the Morgan Park Academy. There are also the private Chicago Academy for the Arts, a high school focused on six different categories of the arts and the public Chicago High School for the Arts, a high school focused on five categories (visual arts, theatre, musical theatre, dance, and music) of the arts.\n\nThe Roman Catholic Archdiocese of Chicago operates Catholic schools, that include Jesuit preparatory schools and others including St. Rita of Cascia High School, De La Salle Institute, Josephinum Academy, DePaul College Prep, Cristo Rey Jesuit High School, Brother Rice High School, St. Ignatius College Preparatory School, Mount Carmel High School, Queen of Peace High School, Mother McAuley Liberal Arts High School, Marist High School, St. Patrick High School and Resurrection High School.\n\nThe Chicago Public Library system operates 79 public libraries, including the central library, two regional libraries, and numerous branches distributed throughout the city.\n\nSince the 1850s, Chicago has been a world center of higher education and research with several universities that are in the city proper or in the immediate environs. These institutions consistently rank among the top \"National Universities\" in the United States, as determined by \"U.S. News & World Report\". Top universities in Chicago are: the University of Chicago; Illinois Institute of Technology; Northwestern University; Loyola University Chicago; DePaul University; Columbia College Chicago and University of Illinois at Chicago. Other notable schools include: Chicago State University; the School of the Art Institute of Chicago, the Illinois Institute of Art – Chicago; East–West University; National Louis University; North Park University; Northeastern Illinois University; Robert Morris University Illinois; Roosevelt University; Saint Xavier University; Rush University; and Shimer College.\n\nWilliam Rainey Harper, the first president of the University of Chicago, was instrumental in the creation of the junior college concept, establishing nearby Joliet Junior College as the first in the nation in 1901. His legacy continues with the multiple community colleges in the Chicago proper, including the seven City Colleges of Chicago: Richard J. Daley College, Kennedy–King College, Malcolm X College, Olive–Harvey College, Truman College, Harold Washington College and Wilbur Wright College, in addition to the privately held MacCormac College.\n\nChicago also has a high concentration of post-baccalaureate institutions, graduate schools, seminaries, and theological schools, such as the Adler School of Professional Psychology, The Chicago School of Professional Psychology, the Erikson Institute, The Institute for Clinical Social Work, the Lutheran School of Theology at Chicago, the Catholic Theological Union, the Moody Bible Institute, the John Marshall Law School and the University of Chicago Divinity School.\n\nThe Chicago metropolitan area is the third-largest media market in North America, after New York City and Los Angeles. Each of the big four U.S. television networks, CBS, ABC, NBC and Fox, directly owns and operates a high-definition television station in Chicago (WBBM 2, WLS 7, WMAQ 5 and WFLD 32, respectively). Former CW affiliate WGN-TV 9, which is owned by the Tribune Media, is carried with some programming differences, as \"WGN America\" on cable and satellite TV nationwide and in parts of the Caribbean. The city has also been the base of several talk shows, including, formerly, \"The Oprah Winfrey Show\". Chicago Public Radio produces programs such as PRI's \"This American Life\" and NPR's \"Wait Wait...Don't Tell Me!\" The city also has two PBS member stations: WTTW 11, producer of shows such as \"Sneak Previews\", \"The Frugal Gourmet\", \"Lamb Chop's Play-Along\" and \"The McLaughlin Group\", just to name a few, and WYCC 20.\n\nTwo major daily newspapers are published in Chicago: the \"Chicago Tribune\" and the \"Chicago Sun-Times\", with the Tribune having the larger circulation. There are also several regional and special-interest newspapers and magazines, such as \"Chicago\", the \"Dziennik Związkowy\" (\"Polish Daily News\"), \"Draugas\" (the Lithuanian daily newspaper), the \"Chicago Reader\", the \"SouthtownStar\", the \"Chicago Defender\", the \"Daily Herald\", \"Newcity\", \"StreetWise\" and the \"Windy City Times\". The entertainment and cultural magazine \"Time Out Chicago\" and \"GRAB\" magazine are also published in the city, as well as local music magazine \"Chicago Innerview\". In addition, Chicago is the recent home of satirical national news outlet, \"The Onion\", as well as its sister pop-culture publication, \"The A.V. Club\".\n\nSince the 1980s, many motion pictures have been filmed and/or set in the city such as \"The Blues Brothers\", \"Brewster's Millions\", \"Ferris Bueller's Day Off\", \"Sixteen Candles\", \"Home Alone\", \"The Fugitive\", \"I, Robot\", \"Mean Girls\", \"Wanted\", \"Batman Begins\", \"The Dark Knight\", \"\", \"\", \"\", \"Divergent\", \"\", \"Sinister 2\" and \"Suicide Squad\".\n\nChicago has also been the setting for many popular television shows, including the situation comedies \"Perfect Strangers\" and its spinoff \"Family Matters\", \"Punky Brewster\", \"Married... with Children\", \"Kenan & Kel\", \"Still Standing\", \"The League\", \"The Bob Newhart Show\", and \"Shake It Up\". The city served as the venue for the medical dramas \"ER\" and \"Chicago Hope\", as well as the fantasy drama series \"Early Edition\" and the 2005–2009 drama \"Prison Break\". Discovery Channel films two shows in Chicago: \"Cook County Jail\" and the Chicago version of \"Cash Cab\". Chicago is currently the setting for CBS's \"The Good Wife\" and \"Mike and Molly\", Showtime's \"Shameless\", and NBC's \"Chicago Fire\", \"Chicago P.D.\" and \"Chicago Med\".\n\nChicago has five 50,000 watt AM radio stations: the CBS Radio-owned WBBM and WSCR; the Tribune Broadcasting-owned WGN; the Cumulus Media-owned WLS; and the ESPN Radio-owned WMVP. Chicago is also home to a number of national radio shows, including \"Beyond the Beltway\" with Bruce DuMont on Sunday evenings.\n\nChicago is also featured in a few video games, including \"Watch Dogs\" and \"Midtown Madness\", a real-life, car-driving simulation game. In 2005, indie rock artist Sufjan Stevens created a concept album about Illinois titled \"Illinois\"; many of its songs were about Chicago and its history.\n\nChicago is a major transportation hub in the United States. It is an important component in global distribution, as it is the third-largest inter-modal port in the world after Hong Kong and Singapore.\n\nSeven mainline and four auxiliary interstate highways (55, 57, 65 (only in Indiana), 80 (also in Indiana), 88, 90 (also in Indiana), 94 (also in Indiana), 190, 290, 294, and 355) run through Chicago and its suburbs. Segments that link to the city center are named after influential politicians, with three of them named after former U.S. Presidents (Eisenhower, Kennedy, and Reagan) and one named after two-time Democratic candidate Adlai Stevenson.\n\nThe Kennedy and Dan Ryan Expressways are the busiest state maintained routes in the entire state of Illinois.\n\nThe Regional Transportation Authority (RTA) coordinates the operation of the three service boards: CTA, Metra, and Pace.\n\n\nGreyhound Lines provides inter-city bus service to and from the city, and Chicago is also the hub for the Midwest network of Megabus (North America).\n\nAmtrak long distance and commuter rail services originate from Union Station. Chicago is one of the largest hubs of passenger rail service in the nation. The services terminate in San Francisco, Washington, D.C., New York City, Indianapolis, New Orleans, Portland, Seattle, Milwaukee, Quincy, St. Louis, Carbondale, Boston, Grand Rapids, Port Huron, Pontiac, Los Angeles, and San Antonio. An attempt was made in the early 20th century to link Chicago with New York City via the Chicago – New York Electric Air Line Railroad. Parts of this were built, but it was never completed.\n\nChicago's Department of Transportation oversees operation of Divvy, North America's largest bicycle-sharing system (by geography), allowing residents and visitors the ability to check out public bikes from any of hundreds of automated stations located over a large area of the city, take them for short rides, and return them to any station of their choosing. Divvy was initially launched in 2013 with 750 bikes and 75 docking stations and has since expanded to 5,800 bikes and 580 stations as of December 2016.\n\nChicago is the largest hub in the railroad industry. Six of the seven Class I railroads meet in Chicago, with the exception being the Kansas City Southern Railway. As of 2002, severe freight train congestion caused trains to take as long to get through the Chicago region as it took to get there from the West Coast of the country (about 2 days). According to U.S. Department of Transportation, the volume of imported and exported goods transported via rail to, from, or through Chicago is forecast to increase nearly 150 percent between 2010 and 2040. CREATE, the Chicago Region Environmental and Transport Efficiency program, comprises about 70 programs, including crossovers, overpasses and underpasses, that intend to significantly improve the speed of freight movements in the Chicago area.\n\nChicago is served by O'Hare International Airport, the world's second-busiest airport measured by airline operations, on the far Northwest Side, and Midway International Airport on the Southwest Side. In 2005, O'Hare was the world's busiest airport by aircraft movements and the second-busiest by total passenger traffic. Both O'Hare and Midway are owned and operated by the City of Chicago. Gary/Chicago International Airport and Chicago Rockford International Airport, located in Gary, Indiana and Rockford, Illinois, respectively, can serve as alternate Chicago area airports, however they do not offer as many commercial flights as O'Hare and Midway. In recent years the state of Illinois has been leaning towards building an entirely new airport in the Illinois suburbs of Chicago. The City of Chicago is the world headquarters for United Airlines, the world's third-largest airline.\n\nThe Port of Chicago consists of several major port facilities within the city of Chicago operated by the Illinois International Port District (formerly known as the Chicago Regional Port District). The central element of the Port District, Calumet Harbor, is maintained by the U.S. Army Corps of Engineers.\n\n\nElectricity for most of northern Illinois is provided by Commonwealth Edison, also known as ComEd. Their service territory borders Iroquois County to the south, the Wisconsin border to the north, the Iowa border to the west and the Indiana border to the east. In northern Illinois, ComEd (a division of Exelon) operates the greatest number of nuclear generating plants in any US state. Because of this, ComEd reports indicate that Chicago receives about 75% of its electricity from nuclear power. Recently, the city began installing wind turbines on government buildings to promote renewable energy.\n\nNatural gas is provided by Peoples Gas, a subsidiary of Integrys Energy Group, which is headquartered in Chicago.\n\nDomestic and industrial waste was once incinerated but it is now landfilled, mainly in the Calumet area. From 1995 to 2008, the city had a blue bag program to divert recyclable refuse from landfills. Because of low participation in the blue bag programs, the city began a pilot program for blue bin recycling like other cities. This proved successful and blue bins were rolled out across the city.\n\nThe Illinois Medical District is on the Near West Side. It includes Rush University Medical Center, ranked as the second best hospital in the Chicago metropolitan area by \"U.S. News & World Report\" for 2014–15, the University of Illinois Medical Center at Chicago, Jesse Brown VA Hospital, and John H. Stroger, Jr. Hospital of Cook County, one of the busiest trauma centers in the nation.\n\nTwo of the country's premier academic medical centers reside in Chicago, including Northwestern Memorial Hospital and the University of Chicago Medical Center. The Chicago campus of Northwestern University includes the Feinberg School of Medicine; Northwestern Memorial Hospital, which is ranked as the best hospital in the Chicago metropolitan area by \"U.S. News & World Report\" for 2010–11; the Rehabilitation Institute of Chicago, which is ranked the best U.S. rehabilitation hospital by \"U.S. News & World Report\"; the new Prentice Women's Hospital; and Ann & Robert H. Lurie Children's Hospital of Chicago.\n\nThe University of Illinois College of Medicine at UIC is the second largest medical school in the United States (2,600 students including those at campuses in Peoria, Rockford and Urbana–Champaign).\n\nIn addition, the Chicago Medical School and Loyola University Chicago's Stritch School of Medicine are located in the suburbs of North Chicago and Maywood, respectively. The Midwestern University Chicago College of Osteopathic Medicine is in Downers Grove.\n\nThe American Medical Association, Accreditation Council for Graduate Medical Education, Accreditation Council for Continuing Medical Education, American Osteopathic Association, American Dental Association, Academy of General Dentistry, Academy of Nutrition and Dietetics, American Association of Nurse Anesthetists, American College of Surgeons, American Society for Clinical Pathology, American College of Healthcare Executives, the American Hospital Association and Blue Cross and Blue Shield Association are all based in Chicago.\n\nChicago has 28 sister cities around the world. Like Chicago, many of them are or were the second-most populous city or second-most influential city of their country, or they are the main city of a country that has had large amounts of immigrants settle in Chicago. These relationships have sought to promote economic, cultural, educational, and other ties.\n\nTo celebrate the sister cities, Chicago hosts a yearly festival in Daley Plaza, which features cultural acts and food tastings from the other cities. In addition, the Chicago Sister Cities program hosts a number of delegation and formal exchanges. In some cases, these exchanges have led to further informal collaborations, such as the academic relationship between the Buehler Center on Aging, Health & Society at the Feinberg School of Medicine of Northwestern University and the Institute of Gerontology of Ukraine (originally of the Soviet Union), that was originally established as part of the Chicago-Kiev sister cities program.\n\nSister cities\n\n\n"}
{"id": "6887", "url": "https://en.wikipedia.org/wiki?curid=6887", "title": "Cyrix 6x86", "text": "Cyrix 6x86\n\nThe Cyrix 6x86 (codename M1) is a sixth-generation, 32-bit x86-compatible microprocessor designed by Cyrix and manufactured by IBM and SGS-Thomson. It was originally released in 1996.\n\nThe 6x86 is superscalar and superpipelined and performs register renaming, speculative execution, out-of-order execution, and data dependency removal. However, it continued to use native x86 execution and ordinary microcode only, like Centaur's Winchip, unlike competitors Intel and AMD which introduced the method of \"dynamic\" translation to micro-operations with Pentium Pro and K5.\n\nWith regard to internal caches, it has a 16-kB primary cache and is socket-compatible with the Intel P54C Pentium. It was also unique in that it was the only x86 design to incorporate a 256-byte \"Level 0\" scratchpad cache. It has six performance levels: PR 90+, PR 120+, PR 133+, PR 150+, PR 166+ and PR 200+. These performance levels do not map to the clock speed of the chip itself (for example, a PR 133+ ran at 110 MHz, a PR 166+ ran at 133 MHz, etc.).\n\nThe 6x86 and 6x86L weren't completely compatible with the Intel P5 Pentium instruction set and is not multi-processor capable. For this reason, the chip identified itself as a 80486 and disabled the CPUID instruction by default. CPUID support could be enabled by first enabling extended CCR registers then setting bit 7 in CCR4. The lack of full P5 Pentium compatibility caused problems with some applications because programmers had begun to use P5 Pentium-specific instructions. Some companies released patches for their products to make them function on the 6x86.\n\nThe first generation of 6x86 had heat problems. This was primarily caused by their higher heat output than other x86 CPUs of the day and, as such, computer builders sometimes did not equip them with adequate cooling. The CPUs topped out at around 25 W heat output (like the AMD K6), whereas the P5 Pentium produced around 15 W of waste heat at its peak. However, both numbers would be a fraction of the heat generated by many high performance processors, some years later.\n\nThe 6x86L (codename M1L) was later released by Cyrix to address heat issues; the \"L\" standing for \"low-power\". Improved manufacturing technologies permitted usage of a lower Vcore. Just like the Pentium MMX the 6x86L required a split powerplane voltage regulator with separate voltages for I/O and CPU core. Another release of the 6x86, the 6x86MX, added MMX compatibility, introduced the EMMI instruction set, and quadrupled the primary cache size to 64 KB. Later revisions of this chip were renamed MII, to better compete with the Pentium II processor.\n\nIt has been, somewhat erroneously, speculated by experts that 6x86 was designed to perform well specifically on business-oriented benchmarks of the time, most notably Ziff-Davis' Winstone benchmark, however the cpu design was aimed solely at providing a high performance platform for business applications. In reality, despite being considerably faster than its Intel counterparts when compared on a clock for clock basis, it scored slower on many tests, highlighting deficiencies in many benchmarking schemes in use at that time. Winstone ran various speed tests using several popular applications. It was one of the leading benchmarks during the mid-'90s and was used in some leading magazines, such as \"Computer Shopper\" and \"PC Magazine\", as a deciding factor for system ratings.\n\nCyrix used a PR rating (Performance Rating) to relate their performance to the Intel P5 Pentium (pre-P55C), because a 6x86 at a lower clock rate outperformed the higher-clocked P5 Pentium. For example, a 133 MHz 6x86 will outperform a P5 Pentium at 166 MHz, and as a result Cyrix could market the 133 MHz chip as being a P5 Pentium 166's equal. A PR rating was also necessary because the 6x86 could not clock as high as P5 Pentium and maintain equivalent manufacturing yields, so it was critical to establish the slower clock speeds as equal in the minds of the consumer. However, the PR rating was not an entirely truthful representation of the 6x86's performance.\n\nWhile the 6x86's integer performance was significantly higher than P5 Pentium's, its floating point performance was more mediocre—between 2 and 4 times the performance of the 486 FPU per clock cycle (depending on the operation and precision). The FPU in the 6x86 was largely the same circuitry that was developed for Cyrix's earlier high performance 8087/80287/80387-compatible coprocessors, which was very fast for its time—the Cyrix FPU was much faster than the 80387, and even the 80486 FPU. However, it was still considerably slower than the new and completely redesigned P5 Pentium and P6 Pentium Pro-Pentium III FPUs. During the 6x86's development, the majority of applications (office software as well as games) performed almost entirely integer operations. The designers foresaw that future applications would most likely maintain this instruction focus. So, to optimize the chip's performance for what they believed to be the most likely application of the CPU, the integer execution resources received most of the transistor budget.\n\nThe popularity of the P5 Pentium caused many software developers to hand-optimize code in assembly language, to take advantage of the P5 Pentium's tightly pipelined and lower latency FPU. For example, the highly anticipated first person shooter Quake used highly optimized assembly code designed almost entirely around the P5 Pentium's FPU. As a result, the P5 Pentium significantly outperformed other CPUs in the game. Fortunately for the 6x86 (and AMD K6), many games continued to be integer-based throughout the chip's lifetime.\n\nThe 6x86 successor—MII—was late to market, and couldn't scale well in clock speed with the manufacturing processes used at the time. Similar to the AMD K5, the Cyrix 6x86 was a design far more focused on integer per-clock performance than clock scalability, something that proved to be a strategic mistake. Therefore, despite being very fast clock by clock, the 6x86 and MII were forced to compete at the low-end of the market as AMD K6 and Intel P6 Pentium II were always ahead on clock speed. The 6x86's and MII's old generation \"486 class\" floating point unit combined with an integer section that was at best on-par with the newer P6 and K6 chips meant that Cyrix could no longer compete in performance.\n\n"}
{"id": "6888", "url": "https://en.wikipedia.org/wiki?curid=6888", "title": "Colon classification", "text": "Colon classification\n\nColon classification (CC) is a system of library classification developed by S. R. Ranganathan. It was the first ever faceted (or analytico-synthetic) classification. The first edition was published in 1933. Since then six more editions have been published. It is especially used in libraries in India.\n\nIts name \"colon classification\" comes from the use of colons to separate facets in class numbers. However, many other classification schemes, some of which are completely unrelated, also use colons and other punctuation in various functions.\n\nIn CC, facets describe \"personality\" (the most specific subject), matter, energy, space, and time (PMEST). These facets are generally associated with every item in a library, and so form a reasonably universal sorting system.\n\nAs an example, the subject \"research in the cure of tuberculosis of lungs by x-ray conducted in India in 1950\" would be categorized as:\n\nThis is summarized in a specific call number:\n\nThe colon classification uses 42 main classes that are combined with other letters, numbers and marks in a manner resembling the Library of Congress Classification to sort a publication.\n\nCC uses five primary categories, or facets, to further specify the sorting of a publication. Collectively, they are called \"PMEST\":\n\nThe following are the main classes of CC, with some subclasses, the main method used to sort the subclass using the PMEST scheme and examples showing application of PMEST.\n\nA common example of the colon classification is:\n\n\n\n\n"}
{"id": "6889", "url": "https://en.wikipedia.org/wiki?curid=6889", "title": "Census", "text": "Census\n\nA census is the procedure of systematically acquiring and recording information about the members of a given population. The term is used mostly in connection with national population and housing censuses; other common censuses include agriculture, business, and traffic censuses. The United Nations defines the essential features of population and housing censuses as \"individual enumeration, universality within a defined territory, simultaneity and defined periodicity\", and recommends that population censuses be taken at least every 10 years. United Nations recommendations also cover census topics to be collected, official definitions, classifications and other useful information to co-ordinate international practice.\n\nThe word is of Latin origin: during the Roman Republic, the census was a list that kept track of all adult males fit for military service. The modern census is essential to international comparisons of any kind of statistics, and censuses collect data on many attributes of a population, not just how many people there are but now census takes its place within a system of surveys where it typically began as the only national demographic data collection. Although population estimates remain an important function of a census, including exactly the geographic distribution of the population, statistics can be produced about combinations of attributes e.g. education by age and sex in different regions. Current administrative data systems allow for other approaches to enumeration with the same level of detail but raise concerns about privacy and the possibility of biasing estimates.\n\nA census can be contrasted with sampling in which information is obtained only from a subset of a population, typically main population estimates are updated by such intercensal estimates. Modern census data are commonly used for research, business marketing, and planning, and as a baseline for designing sample surveys by providing a sampling frame such as an address register. Census counts are necessary to adjust samples to be representative of a population by weighting them as is common in opinion polling. Similarly, stratification requires knowledge of the relative sizes of different population strata which can be derived from census enumerations. In some countries, the census provides the official counts used to apportion the number of elected representatives to regions (sometimes controversially – e.g., \"Utah v. Evans\"). In many cases, a carefully chosen random sample can provide more accurate information than attempts to get a population census.\n\nA census is often construed as the opposite of a sample as its intent is to count everyone in a population rather than a fraction. However, population censuses rely on a sampling frame to count the population. This is the only way to be sure that everyone has been included as otherwise those not responding would not be followed up on and individuals could be missed. The fundamental premise of a census is that the population is not known and a new estimate is to be made by the analysis of primary data. \nThe use of a sampling frame is counterintuitive as it suggests that the population size is already known. However, a census is also used to collect attribute data on the individuals in the nation. This process of sampling marks the difference between historical census, which was a house to house process or the product of an imperial decree, and the modern statistical project.\nThe sampling frame used by census is almost always an address register. Thus it is not known if there is anyone resident or how many people there are in each household. Depending on the mode of enumeration, a form is sent to the householder, an enumerator calls, or administrative records for the dwelling are accessed. As a preliminary to the dispatch of forms, census workers will check any address problems on the ground.\nWhile it may seem straightforward to use the postal service file for this purpose, this can be out of date and some dwellings may contain a number of independent households. A particular problem is what are termed 'communal establishments' which category includes student residences, religious orders, homes for the elderly, people in prisons etc. As these are not easily enumerated by a single householder, they are often treated differently and visited by special teams of census workers to ensure they are classified appropriately.\n\nIndividuals are normally counted within households and information is typically collected about the household structure and the housing. For this reason international documents refer to censuses of population and housing. Normally the census response is made by a household, indicating details of individuals resident there.\nAn important aspect of census enumerations is determining which individuals can be counted from which cannot be counted. Broadly, three definitions can be used: \"de facto\" residence; \"de jure\" residence; and, permanent residence. This is important to consider individuals who have multiple or temporary addresses. Every person should be identified uniquely as resident in one place but where they happen to be on Census Day, their \"de facto\" residence, may not be the best place to count them. Where an individual uses services may be more useful and this is at their usual, or \"de jure\", residence. An individual may be represented at a permanent address, perhaps a family home for students or long term migrants.\nIt is necessary to have a precise definition of residence to decide whether visitors to a country should be included in the population count. This is becoming more important as students travel abroad for education for a period of several years. Other groups causing problems of enumeration are new born babies, refugees, people away on holiday, people moving home around census day, and people without a fixed address.\nPeople having second homes because of working in another part of the country or retaining a holiday cottage are difficult to fix at a particular address sometimes causing double counting or houses being mistakenly identified as vacant. Another problem is where people use a different address at different times e.g. students living at their place of education in term time but returning to a family home during vacations or children whose parents have separated who effectively have two family homes. Census enumeration has always been based on finding people where they live as there is no systematic alternative - any list you could use to find people is derived from census activities in the first place. Recent UN guidelines provide recommendation on enumerating such complex households.\n\nHistorical censuses used crude enumeration assuming absolute accuracy. Modern approaches take into account the problems of overcount and undercount, and the coherence of census enumerations with other official sources of data. This reflects a realist approach to measurement, acknowledging that under any definition of residence there is a true value of the population but this can never be measured with complete accuracy. An important aspect of the census process is to evaluate the quality of the data.\n\nMany countries use a post-enumeration survey to adjust the raw census counts. This works in a similar manner to capture-recapture estimation for animal populations. In census circles this method is called dual system enumeration (DSE). A sample of households are visited by interviewers who record the details of the household as at census day. These data are then matched to census records and the number of people missed can be estimated by considering the number missed in the census or survey but counted in the other. This way counts can be adjusted for non-response varying between different demographic groups. An explanation using a fishing analogy can be found in \"Trout, Catfish and Roach...\" which won an award from the Royal Statistical Society for excellence in official statistics in 2011.\n\nTriple system enumeration has been proposed as an improvement as it would allow evaluation of the statistical dependence of pairs of sources. However, as the matching process is the most difficult aspect of census estimation this has never been implemented for a national enumeration. It would also be difficult to identify three different sources that were sufficiently different to make the triple system effort worthwhile. The DSE approach has another weakness in that it assumes there is no person counted twice (over count). In \"de facto\" residence definitions this would not be a problem but in \"de jure\" definitions individuals risk being recorded on more than one form leading to double counting. A particular problem here are students who often have a term time and family address.\n\nSeveral countries have used a system which is known as short form/long form. This is a sampling strategy which randomly chooses a proportion of people to send a more detailed questionnaire to (the long form). Everyone receives the short form questions. Thereby more data are collected but not imposing a burden on the whole population. This also reduces the burden on the statistical office. Indeed, in the UK all residents were required to fill in the whole form but only a 10% sample were coded and analysed in detail, until 2001. New technology means that all data are now scanned and processed. Recently there has been controversy in Canada about the cessation of the long form with the head, Munir Sheikh resigning.\n\nThe use of alternative enumeration strategies is increasing but these are not so simple as many people assume and only occur in developed countries. The Netherlands has been most advanced in adopting a census using administrative data. This allows a simulated census to be conducted by linking several different administrative databases at an agreed time. Data can be matched and an overall enumeration established accounting for where the different sources are discrepant. A validation survey is still conducted in a similar way to the post enumeration survey employed in a traditional census.\nOther countries which have a population register use this as a basis for all the census statistics needed by users. This is most common amongst Nordic countries but requires a large number of different registers to be combined including population, housing, employment and education. These registers are then combined and brought up to the standard of a statistical register by comparing the data in different sources and ensuring the quality is sufficient for official statistics to be produced.\nA recent innovation is the French instigation of a rolling census programme with different regions enumerated each year such that the whole country is completely enumerated every 5 to 10 years. In Europe, in connection with the 2010 census round, a large number of countries adopted alternative census methodologies, often based on the combination of data from registers, surveys and other sources.\n\nCensuses have evolved in their use of technology with the latest censuses, the 2010 round, using many new types of computing. In Brazil, handheld devices were used by enumerators to locate residences on the ground. In many countries, census returns could be made via the Internet as well as in paper form. DSE is facilitated by computer matching techniques which can be automated, such as propensity score matching. In the UK, all census formats are scanned and stored electronically before being destroyed, replacing the need for physical archives. The record linking to perform an administrative census would not be possible without large databases being stored on computer systems.\n\nNew technology is not without problems in its introduction. The US census had intended to use the handheld computers but cost escalated and this was abandoned, with the contract being sold to Brazil. Online response is a good idea but one of the functions of census is to make sure everyone is counted accurately. A system which allowed people to enter their address without verification would be open to abuse. Therefore, households have to be verified on the ground, typically by an enumerator visit or post out. Paper forms are still necessary for those without access to Internet connections. It is also possible that the hidden nature of an administrative census means that users are not engaged with the importance of contributing their data to official statistics.\n\nAlternatively, population estimations may be carried out remotely with GIS and remote sensing technologies.\n\nAccording to UNFPA, “The information generated by a population and housing census – numbers of people, their distribution, their living conditions and other key data – is critical for development.” This is because this type of data is essential for policymakers so that they know where to invest. Unfortunately, many countries have outdated or inaccurate data about their populations and therefore, without accurate data are unable to address the needs of their population.\n\nUNFPA stated that,\n\n“The unique advantage of the census is that it represents the entire statistical universe, down to the smallest geographical units, of a country or region. Planners need this information for all kinds of development work, including: assessing demographic trends; analysing socio-economic conditions; designing evidence-based poverty-reduction strategies; monitoring and evaluating the effectiveness of policies; and tracking progress toward national and internationally agreed development goals.”\n\nIn addition to making policymakers aware about population issues, it is also an important tool for identifying forms of social, demographic or economic exclusions, such as inequalities relating to race, ethics and religion as well as disadvantaged groups such as those with disabilities and the poor.\n\nAn accurate census can empower local communities by providing them with the necessary information to participate in local decision-making and ensuring they are represented.\n\nIn the nineteenth century, the first censuses collected paper enumerations that had to be collated by hand so the statistical uses were very basic. The government owned the data and were able to publish statistics themselves on the state of the nation. Uses were to measure changes in the population and apportion representation. Population estimates could be compared to those of other countries.\n\nBy the beginning of the twentieth century, censuses were recording households and some indications of their employment. In some countries, census archives are released for public examination after many decades, allowing genealogists to track the ancestry of interested people. Archives provide a substantial historical record which may challenge established notions of tradition. It is also possible to understand the societal history through job titles and arrangements for the destitute and sick.\n\nAs governments assumed responsibility for schooling and welfare, large government research departments made extensive use of census data. Actuarial estimates could be made to project populations and plan for provision in local government and regions. It was also possible for central government to allocate funding on the basis of census data.\nEven into the mid twentieth century, census data was only directly accessible to large government departments. However, computers meant that tabulations could be used directly by university researchers, large businesses and local government offices. They could use the detail of the data to answer new questions and add to local and specialist knowledge.\n\nNow, census data are published in a wide variety of formats to be accessible to business, all levels of governance, media, students and teachers, charities and any citizen who is interested; researchers in particular have an interest in the role of \"Census Field Officers\" (CFO) and their assistants. Data can be represented visually or analysed in complex statistical models, to show the difference between certain areas, or to understand the association between different personal characteristics. Census data offer a unique insight into small areas and small demographic groups which sample data would be unable to capture with precision.\n\nAlthough the census provides a useful way of obtaining statistical information about a population, such information can sometimes lead to abuses, political or otherwise, made possible by the linking of individuals' identities to anonymous census data. This consideration is particularly important when individuals' census responses are made available in microdata form, but even aggregate-level data can result in privacy breaches when dealing with small areas and/or rare subpopulations.\n\nFor instance, when reporting data from a large city, it might be appropriate to give the average income for black males aged between 50 and 60. However, doing this for a town that only has two black males in this age group would be a breach of privacy because either of those persons, knowing his own income and the reported average, could determine the other man's income.\n\nTypically, census data are processed to obscure such individual information. Some agencies do this by intentionally introducing small statistical errors to prevent the identification of individuals in marginal populations; others swap variables for similar respondents. Whatever measures have been taken to reduce the privacy risk in census data, new technology in the form of better electronic analysis of data poses increasing challenges to the protection of sensitive individual information. This is known as statistical disclosure control.\n\nAnother possibility is to present survey results by means of statistical models in the form of a multivariate distribution mixture. The statistical information in the form of conditional distributions (histograms) can be derived interactively from the estimated mixture model without any further access to the original database. As the final product does not contain any protected microdata, the model based interactive software can be distributed without any confidentiality concerns.\n\nAnother method is simply to release no data at all, except very large scale data directly to the central government. Different release strategies between government have led to an international project (IPUMS) to co-ordinate access to microdata and corresponding metadata. Such projects also promote standardising metadata by projects such as SDMX so that best use can be made of the minimal data available.\n\nCensuses in Egypt first appears in the late Middle Kingdom and develops in the New Kingdom Pharaoh Amasis, according to Herodotus, require every Egyptian to declare annually to the nomarch, \"whence he gained his living\". Under the Ptolemies and the Romans several censuses were conducted in Egypt by governments officials \n\nThere are several accounts of ancient Greek city states carrying out censuses.\n\nCensuses are mentioned in the Bible. God commands a per capita tax to be paid with the census in for the upkeep of the Tabernacle. The Book of Numbers is named after the counting of the Israelite population (in ) according to the house of the Fathers after the exodus from Egypt. A second census was taken while the Israelite were camped in the plains of Moab, in .\n\nKing David performed a census that produced disastrous results (in and ). His son, King Solomon, had all of the foreigners in Israel counted in .\n\nWhen the Romans took over Judea in 6, the legate Publius Sulpicius Quirinius organised a census for tax purposes. The Gospel of Luke links the birth of Jesus to this event. .\n\nOne of the world's earliest preserved censuses was held in China in 2 during the Han Dynasty, and is still considered by scholars to be quite accurate. Another census was held in 144.\n\nThe oldest recorded census in India is thought to have occurred around 300 during the reign of The Emperor Chandragupta Maurya under the leadership of Kautilya or Chanakya and Ashoka.\n\nThe word \"census\" originated in ancient Rome from the Latin word \"\" (\"to estimate\"). The census played a crucial role in the administration of the Roman Empire, as it was used to determine taxes. With few interruptions, it was usually carried out every five years. It provided a register of citizens and their property from which their duties and privileges could be listed. It is said to have been instituted by the Roman king Servius Tullius in the at which time the number of arms-bearing citizens was supposedly counted at around 80,000. The 6 \"census of Quirinius\" undertaken following the imposition of direct Roman rule in Judea was partially responsible for the development of the Zealot movement and several failed rebellions against Rome that ended in the Diaspora. The 15-year indiction cycle established by Diocletian in 297 was based on quindecennial censuses and formed the basis for dating in late antiquity and under the Byzantine Empire.\n\nIn the Middle Ages, the Caliphate began conducting regular censuses soon after its formation, beginning with the one ordered by the second Rashidun caliph, Umar.\n\nThe Domesday Book was undertaken in 1086 by William I of England so that he could properly tax the land he had recently conquered in medieval Europe. In 1183, a census was taken of the crusader Kingdom of Jerusalem, to ascertain the number of men and amount of money that could possibly be raised against an invasion by Saladin, sultan of Egypt and Syria.\n\nIn the 15th century, the Inca Empire had a unique way to record census information. The Incas did not have any written language but recorded information collected during censuses and other numeric information as well as non-numeric data on quipus, strings from llama or alpaca hair or cotton cords with numeric and other values encoded by knots in a base-10 positional system.\n\nOn May 25, 1577, King Philip II of Spain ordered by royal cédula the preparation of a general description of Spain's holdings in the Indies. Instructions and a questionnaire, issued in 1577 by the Office of the Cronista Mayor, were distributed to local officials in the Viceroyalties of New Spain and Peru to direct the gathering of information. The questionnaire, composed of fifty items, was designed to elicit basic information about the nature of the land and the life of its peoples. The replies, known as \",\" were written between 1579 and 1585 and were returned to the Cronista Mayor in Spain by the Council of the Indies.\n\nThe earliest estimate of the world population was made by Giovanni Battista Riccioli in 1661; the next by Johann Peter Süssmilch in 1741, revised in 1762; the third by Karl Friedrich Wilhelm Dieterici in 1859.\n\nIn 1931 Walter Willcox published a table in his book, \"International Migrations: Volume II Interpretations\", that estimated the 1929 world population to be roughly 1.8 billion.\n\n\n\n"}
{"id": "6896", "url": "https://en.wikipedia.org/wiki?curid=6896", "title": "Outline of chemistry", "text": "Outline of chemistry\n\nThe following outline is provided as an overview of and topical guide to chemistry:\n\nChemistry – science of atomic matter (matter that is composed of chemical elements), especially its chemical reactions, but also including its properties, structure, composition, behavior, and changes as they relate the chemical reactions. Chemistry is centrally concerned with atoms and their interactions with other atoms, and particularly with the properties of chemical bonds.\nChemistry can be described as all of the following:\n\n\nHistory of chemistry\n\n\nAtomic theory\nThe Atomic Model Timeline\n\nThe Democritus Model\n\nThe John Dalton Model\n\nJ. J. Thomson: The Plum Pudding Model\n\nThermochemistry\n\n\n\nHow to calculate the enthalpy of N₂+3H₂ =2NH₃?\n\n\n\n\n\n\n\n"}
{"id": "6901", "url": "https://en.wikipedia.org/wiki?curid=6901", "title": "Outline of critical theory", "text": "Outline of critical theory\n\nThe following outline is provided as an overview of and topical guide to critical theory:\n\nCritical theory – the examination and critique of society and culture, drawing from knowledge across the social sciences and humanities. The term has two different meanings with different origins and histories: one originating in sociology and the other in literary criticism. This has led to the very literal use of 'critical theory' as an umbrella term to describe any theory founded upon critique.\n\n\n\nGender studies\n\nMarxist philosophy\n\nPostcolonialism\n\nStructuralism\n\n\nDeconstruction\n\nPostmodernism\n\nReconstructivism\n\nPsychoanalytic theory\n\nQueer theory\n\nSemiotics\n\nCultural anthropology\n\n\n\n\nList of critical theorists\n\n\n"}
{"id": "6902", "url": "https://en.wikipedia.org/wiki?curid=6902", "title": "Cotswolds", "text": "Cotswolds\n\nThe Cotswolds is an area in south central England containing the Cotswold Hills, a range of rolling hills which rise from the meadows of the upper Thames to an escarpment, known as the Cotswold Edge, above the Severn Valley and Evesham Vale. The area is defined by the bedrock of Jurassic limestone that creates a type of grassland habitat rare in the UK and that is quarried for the golden coloured Cotswold stone. It contains unique features derived from the use of this mineral; the predominantly rural landscape contains stone-built villages, historical towns and stately homes and gardens.\n\nThe well-established boundaries of the Cotswolds have expanded considerably since moving out of the cities and into the countryside gained popularity. Now the Cotswolds boundaries are roughly 25 miles (40 km) across and 90 miles (145 km) long, stretching south-west from just south of Stratford-upon-Avon to just south of Bath. It lies across the boundaries of several English counties; mainly Gloucestershire and Oxfordshire, and parts of Wiltshire, Somerset, Worcestershire and Warwickshire. The hills give their name to the Cotswold local-government district in Gloucestershire, which administers a large part of the area. The highest point of the region is Cleeve Hill at , just to the north of Cheltenham.\n\nThere is evidence of Neolithic settlement from burial chambers on Cotswold Edge, and there are remains of Bronze and Iron Age forts. Later the Romans built villas, such as at Chedworth, settlements such as Gloucester, and paved the Celtic path later known as Fosse Way.\n\nDuring the Middle Ages, thanks to the breed of sheep known as the Cotswold Lion, the Cotswolds became prosperous from the wool trade with the continent, with much of the money made from wool directed towards the building of churches. The area still preserves numerous large, handsome Cotswold Stone \"wool churches\". The affluent area in the 21st century has attracted wealthy Londoners and others who own second homes there or have chosen to retire to the Cotswolds.\n\nThe name Cotswold is popularly attributed the meaning \"sheep enclosure in rolling hillsides\", incorporating the term, \"wold\", meaning hills. Compare also the Weald from the Saxon/German word \"Wald\" meaning 'wood'. However, the English Place-Name Society has for many years accepted that the term Cotswold is derived from \"Codesuualt\" of the 12th century or other variations on this form, the etymology of which was given, 'Cod's-wold', which is 'Cod's high open land'. Cod was interpreted as an Old English personal name, which may be recognised in further names: Cutsdean, Codeswellan, and Codesbyrig, some of which date back to the eighth century AD. It has subsequently been noticed that \"Cod\" could derive philologically from a Brittonic female cognate \"\"Cuda\"\", a hypothetical mother goddess in Celtic mythology postulated to have been worshipped in the Cotswold region.\n\nThe spine of the Cotswolds runs southwest to northeast through six counties, particularly Gloucestershire, west Oxfordshire and south western Warwickshire. The northern and western edges of the Cotswolds are marked by steep escarpments down to the Severn valley and the Warwickshire Avon. This feature, known as the Cotswold escarpment, or sometimes the Cotswold Edge, is a result of the uplifting (tilting) of the limestone layer, exposing its broken edge. This is a cuesta, in geological terms. The dip slope is to the southeast. On the eastern boundary lies the city of Oxford and on the west is Stroud. To the southeast, the upper reaches of the Thames Valley and towns such as Lechlade, Tetbury and Fairford are often considered to mark the limit of this region. To the south the Cotswolds, with the characteristic uplift of the Cotswold Edge, reach beyond Bath, and towns such as Chipping Sodbury and Marshfield share elements of Cotswold character.\n\nThe area is characterised by attractive small towns and villages built of the underlying Cotswold stone (a yellow oolitic limestone). This limestone is rich in fossils, particularly of fossilised sea urchins. Cotswold towns include Bourton-on-the-Water, Broadway, Burford, Chipping Norton, Dursley, Moreton-in-Marsh, Nailsworth, Northleach, Stow-on-the-Wold, Stroud and Winchcombe. Bath, Cheltenham, Cirencester, Gloucester and Stroud are larger urban centres that border on, or are virtually surrounded by, the Cotswold AONB.\n\nThe town of Chipping Campden is notable for being the home of the Arts and Crafts movement, founded by William Morris at the end of the 19th and beginning of the 20th centuries. William Morris lived occasionally in Broadway Tower, a folly, now part of a country park. Chipping Campden also is known for the annual Cotswold Olimpick Games, a celebration of sports and games dating back to the early 17th century.\n\nCotswold stone is a yellow oolitic Jurassic limestone. This limestone is rich in fossils, particularly of fossilised sea urchins. When weathered, the colour of buildings made or faced with this stone is often described as honey or golden. The stone varies in colour from north to south, being honey-coloured in the north and north east of the region, as shown in Cotswold villages such as Stanton and Broadway; golden-coloured in the central and southern areas, as shown in Dursley and Cirencester; and pearly white in Bath. The rock outcrops at places on the Cotswold Edge; small quarries are common. The exposures are rarely sufficiently compact to be good for rock-climbing. However, an exception is Castle Rock, on Cleeve Hill, above Bishop's Cleeve, near Cheltenham. Due to the rapid expansion of the Cotswolds in order for nearby areas to capitalize on increased house prices, well known ironstone villages, such as Hook Norton, have even been claimed by some to be in the Cotswolds despite lacking key features of Cotswolds villages such as Cotswold stone and are instead built using a deep red/orange ironstone, known locally as Horton Stone.\nThe Cotswolds were designated as an Area of Outstanding Natural Beauty (AONB) in 1966, with an expansion on 21 December 1990 to . In 1991, all AONBs were measured again using modern methods. The official area of the Cotswolds AONB was increased to . In 2000, the government confirmed that AONBs had the same landscape quality and status as National Parks.\nThe Cotswolds AONB, which is the largest in England and Wales, stretches from the border regions of South Warwickshire and Worcestershire, through West Oxfordshire and Gloucestershire, and takes in parts of Wiltshire, Bath and North East Somerset in the south.\nGloucestershire County Council is responsible for sixty-three percent of the AONB.\n\nThe Cotswolds Conservation Board has the task of conserving and enhancing the AONB. Established under statute in 2004 as an independent public body, the Board carries out a range of work from securing funding for 'on the ground' conservation projects, to providing a strategic overview of the area for key decision makers, such as planning officials. The Board is funded by Natural England and the seventeen local authorities that are covered by the AONB.\n\nWhile the beauty of the Cotswolds AONB is intertwined with that of the villages that seem almost to grow out of the landscape, the Cotswolds were primarily designated an Area of Outstanding Natural Beauty for the rare limestone grassland habitats as well as the old growth beech woodlands that typify the area. These habitat areas are also the last refuge for many other flora and fauna, with some so endangered that they are protected under the Wildlife and Countryside Act 1981. Cleeve Hill, and its associated commons, is a fine example of a limestone grassland and it is one of the few locations where the Duke of Burgundy butterfly may still be found in abundance.\n\nThe uniqueness and value of the Cotswolds is shown in the fact that five European Special Areas of Conservation, three National Nature Reserves and more than eighty Sites of Special Scientific Interest are within the Cotswolds AONB.\n\nThe Cotswold Voluntary Wardens Service was established in 1968 to help conserve and enhance the area, and now has more than 300 wardens.\n\nThe Cotswold Way is a long-distance footpath, just over long, running the length of the AONB, mainly on the edge of the Cotswold escarpment with views over the Severn Valley and the Vale of Evesham.\n\nPictured right is the Garden of Sudeley Castle at Winchcombe. The present structure was built in the 15th century and may have been on the site of a 12th-century castle. It is situated north of the Spa town of Cheltenham which has much Georgian architecture of some merit. Close by on the A4135 in Beaverston village is the ancient fortress known as Beverston Castle founded in 1229 by Maurice de Gaunt. Within the Cotswold area lies Calcot Manor which can be accessed on the A4135 road from Beaverston and is located some west of Tetbury. The Manor house building was established in about 1300 AD by Henry of Kingswood as a tithe barn.\n\nTetbury Market House is perhaps worth a mention as it was built in 1655. During the Middle Ages, Tetbury became an important market for Cotswold wool and yarn. Chavenage House is an Elizabethan era manor house 2.4 kilometres (1.5 mi) northwest of Tetbury. Of some interest is Chedworth Roman Villa. Recent excavations have revealed more of the structure and mosaics, which are now excellently presented. It is located just off the Roman road known as the Fosse Way, and 8 miles (13 km) north of the important town of Corinium Dobunnorum (Cirencester). Cirencester Abbey was founded as an Augustinian monastery in 1117 and Malmesbury Abbey was one of the few English houses with a continual history from the 7th century through to the Dissolution of the Monasteries.\n\nAn unusual house in this area is Quarwood a Victorian Gothic house in Stow-on-the-Wold, Gloucestershire. The grounds, covering , include parkland, fish ponds, paddocks, garages, woodlands and seven cottages. Another is Woodchester Mansion, an unfinished, Gothic revival mansion house in Woodchester Park near Nympsfield in Woodchester, Gloucestershire. Newark Park is a Grade I listed country house of Tudor origins located near the village of Ozleworth, Wotton-under-Edge, Gloucestershire. The house sits in an estate of at the southern end of the Cotswold escarpment.\n\nOf the many Manor houses built in the area Owlpen Manor is a Tudor Grade I listed manor house of the Mander family, situated in the village of Owlpen in the Stroud district of Gloucestershire. Moving further north, Broadway Tower is a folly on Broadway Hill, near the village of Broadway, in the English county of Worcestershire. To the south of the Cotswolds is Corsham Court an English country house in a park designed by Capability Brown situated in the town of Corsham, 3 miles (5 km) west of Chippenham, Wiltshire.\n\nThe Cotswolds lie between the M5, M40 and M4 motorways. The main A-roads through the area are the A46: Bath – Stroud – Cheltenham; the A419: Swindon – Cirencester – Stroud; the A429: Cirencester – Stow-on-the-Wold – Moreton-in-Marsh; and the A40: Oxford – Burford – Cheltenham. These all roughly follow the routes of ancient roads, some laid down by the Romans, such as Ermin Way and the Fosse Way.\n\nThere are local bus services across the area, but some are infrequent.\n\nThe River Thames flows from the Cotswolds and is navigable from Inglesham and Lechlade-on-Thames downstream to Oxford.\n\nThe area is bounded by two major rail routes: in the south by the main Bristol–Bath–London High Speed line (including the South Wales Main Line) and in the west by the Bristol–Birmingham main line. In addition, the Cotswold Line runs through the Cotswolds from Oxford to Worcester, and the Golden Valley Line runs from Swindon via Stroud to Gloucester, carrying high speed and local services.\n\nMainline, high-speed rail services to the big cities run from railway stations such as Bath, Swindon, Oxford, Cheltenham and Worcester. Mainline trains run by First Great Western to London Paddington also are available from Kemble station near Cirencester, Kingham station near Stow-on-the-Wold, Charlbury station and Moreton-in-Marsh station.\n\nAdditionally, there is the Gloucestershire Warwickshire Railway, a steam heritage railway serving the Cotswolds from Cheltenham Racecourse through Gotherington, Winchcombe and Hayles Abbey Halt to Toddington and Laverton. The preserved line is currently being extended to Broadway, with the aim of reaching Honeybourne and making a reconnection with the Cotswold Line.\n\nThe Cotswold region has inspired several notable English composers. In the early 1900s, Herbert Howells and Ivor Gurney used to take long walks together over the hills, and Gurney urged Howells to make the landscape, including the nearby Malvern Hills, the inspiration for his future work. Accepting, in 1916, Howells wrote his first major piece, the \"Piano Quartet in A minor,\" inspired by the magnificent view of the Malverns; he dedicated it to \"the hill at Chosen (Churchdown) and Ivor Gurney who knows it\". Another contemporary of theirs, Gerald Finzi, lived in nearby Painswick.\n\nGustav Holst titled his Symphony in F major, Op. 8 H47 \"The Cotswolds\". The composer Ralph Vaughan Williams composed his opera \"\"Hugh the Drover\"\" from 1913 to 1924, which depicts life in a Cotswold village and incorporates local folk melodies. In 1988 the 6th symphony (Op. 109) of composer Derek Bourgeois was titled \"\"A Cotswold Symphony\"\".\nThe film \"Better Things\" (2008), directed by Duane Hopkins, is set in a small Cotswold village. The fictional detective Agatha Raisin lives in the fictional village of Carsely in the Cotswolds. The Chipping Norton set are based in the Cotswolds.\n\nMany episodes of Agatha Christie's Poirot take place in the Cotswolds region. The 2013 television series Father Brown is almost entirely filmed in the Cotswolds.\n\n\n"}
{"id": "6903", "url": "https://en.wikipedia.org/wiki?curid=6903", "title": "A.C. ChievoVerona", "text": "A.C. ChievoVerona\n\nAssociazione Calcio ChievoVerona (more commonly known as ChievoVerona or simply Chievo ) is an Italian professional football club named after and based in Chievo, a suburb of 4,500 inhabitants in Verona, Veneto, and owned by Paluani, a bakery product company and the inspiration for their original name, Paluani Chievo. The club shares the 38,402 seater Marc'Antonio Bentegodi stadium with its cross-town rivals Hellas Verona.\n\nThe team was founded in 1929 by a small number of football fans from the small borough of Chievo, a Verona neighbourhood. Initially the club was not officially affiliated to the Italian Football Federation (FIGC), but nonetheless played several amateur tournament and friendly matches under the denomination \"O.N.D. Chievo,\" a title imposed by the fascist regime. The club's formal debut in an official league was on 8 November 1931. The team colours at the time were blue and white. Chievo disbanded in 1936, however, due to economic woes but returned to play in 1948 after World War II, being registered in the regional league of \"Seconda Divisione\" (Second Division). In 1957, the team moved to the \"Carlantonio Bottagisio\" parish field, where they played until 1986. In 1959, after the restructuring of the football leagues, Chievo was admitted to play the \"Seconda Categoria\" (Second Category), a regional league placed next-to-last in the Italian football pyramid. That year, Chievo changed its name to \"Cardi Chievo,\" after a new sponsor, and was quickly promoted to the \"Prima Categoria,\" from which it experienced its first-ever relegation in 1962.\n\nIn 1964, Luigi Campedelli, a businessman and owner of the Paluani company, was named new Chievo chairman. Under Campedelli's presidency, Chievo climbed through the entire Italian football pyramid, reaching the Serie D after the 1974–75 season. Under the name \"Paluani Chievo,\" the team was promoted to Serie C2 in 1986. As a consequence of promotion, Chievo was forced to move to the Stadio Marcantonio Bentegodi, the main venue in Verona; another promotion, to Serie C1, followed in 1989. In 1990, the team changed its name to its current one, \"A.C. ChievoVerona.\"\n\nIn 1992, President Luigi Campedelli, who had returned at the helm of the club two years before, died of a heart attack, and his son Luca Campedelli, aged just 23, became the new and youngest chairman of an Italian professional football club. Campedelli promoted Giovanni Sartori to director of football and named Alberto Malesani as the new head coach. Under Malesani, the team astonishingly won the Serie C1 and was promoted to Serie B, where city rival Hellas Verona was playing at the time. In 1997, after Malesani signed for Fiorentina, Silvio Baldini was appointed the new head coach. The following season, with Domenico Caso as the coach, saw the first dismissal of a coach during the presidency of Luca Campedelli, with Caso being fired and replaced with Lorenzo Balestro. It was during these years that the nickname \"\"mussi volanti\"\" (\"flying donkeys\") was born. It originated from supporters of their crosstown rivals Hellas, who would mock long-suffering Chievo supporters that Chievo will only be promoted if \"donkeys could fly\" (equivalent of the English language falsism \"if pigs could fly\", denoting an impossible dream).\n\nIn 2000–01, Luigi Delneri was signed as coach and led Chievo, by virtue of its third-place finish in Serie B, to promotion to Serie A, the first time in team history that it had reached the top tier of Italian football.\n\nIn its 2001–02, Chievo's Serie A debut season, the team was most critics' choice for an instant return to Serie B. However, they became the surprise team in the league, playing often spectacular and entertaining football and even leading the league for six consecutive weeks. The club finally ended the season with a highly respectable fifth-place finish, qualifying the team to play in the UEFA Cup.\n\nIn 2002–03, Chievo debuted at the European level but were eliminated in the first round by Red Star Belgrade. The team finished the Serie A season in seventh place, again proving itself one of the better Serie A teams. The 2003–04 season, the last with Delneri at the helm, saw Chievo finish ninth. \n\nThe 2004–05 season is remembered as one of the toughest ever in Chievo's history. Mario Beretta, a Serie A novice from Ternana, was named the coach but, after a strong start that brought Chievo to third behind Juventus and Milan, the team slowly lost position in the league table. With three matches remaining in the season, Chievo was third-from-last, a position which would see it relegated to Serie B. As a last resort, Beretta was fired and Maurizio D'Angelo, a former Chievo player, was appointed temporarily to replace him as coach. Morale improved, and two wins and a draw from the final three matches proved just enough to keep Chievo in Serie A.\n\nIn 2005–06, Giuseppe Pillon of Treviso FBC was appointed as new coach. The team experienced a return to the successful Delneri era, both in style of play and results, which resulted in Chievo ending the season in seventh and gaining a berth in the UEFA Cup. However, because of the football scandal involving several top-class teams, all of which finished higher than Chievo in the 2005–06 season, the Flying Donkeys were awarded a place in the next Champions League preliminary phase.\n\nOn 14 July 2006, the verdict in the scandal was made public. Juventus, Milan and Fiorentina, who had all originally qualified for the 2006–07 Champions League, and Lazio, who had originally qualified for the 2006–07 UEFA Cup, were all banned from UEFA competition for the 2006–07 season, although Milan were allowed to enter the Champions League after their appeal to the FIGC. Chievo took up a place in the third qualifying stage of the competition along with Milan and faced Bulgarian side Levski Sofia. Chievo lost the first leg 2–0 in Sofia and managed a 2–2 home draw on the second leg and were eliminated by a 4–2 aggregate score with Levski advancing to the Champions League group stage. As a Champions League third round qualifying loser, Chievo was given a place in the UEFA Cup final qualifying round. On 25 August 2006, they were drawn to face Portuguese side Braga. The first leg, played on 14 September in Braga, ended in a 2–0 win for the Portuguese. The return match, played on 28 September in Verona, although won by Chievo 2–1, resulted in a 3–2 aggregate loss and the club's elimination from the competition.\n\nOn 16 October 2006, following a 1–0 defeat against Torino, head coach Giuseppe Pillon was fired, and replaced by Luigi Delneri, one of the original symbols of the \"miracle Chievo\", who had led the club to the Serie A in 2002.\n\nOn 27 May 2007, the last match day of the 2006–07 Serie A season, Chievo was one of five teams in danger of falling into the last undecided relegation spot. Needing only a tie against Catania, a direct competitor in the relegation battle, Chievo lost 2–0 playing on a neutral field in Bologna. Wins by Parma, Siena and Reggina condemned Chievo to Serie B for the 2007–08 season after six seasons in the top flight.\n\nEven as a relatively-successful Serie A team the club, which averages only 9,000 to 10,000 fans and is kept afloat mainly by money from television rights, does not have the same number of fan supporters as Hellas, the oldest team in Verona. The difference between the clubs supporters' number is highlighted during local derby games played in season 2001–02 at the clubs' shared stadium when, for Chievo's \"home\" fixtures, the Chievo fans were located in \"away\" end of the stadium (the area of the stadium Chievo's supporters by years claim as \"theirs,\" in fact the main supporters faction's name is \"North Side,\" the side of the stadium usually assigned to away teams' supporters), while the most of the rest of the stadium seats was assigned to Hellas supporters.\n\nChievo bounced back quickly from the disappointment of their relegation on the last matchday of 2006–07, going in search of an immediate promotion back to the top flight. After the expected departure of several top-quality players including Franco Semioli, Salvatore Lanna, Matteo Brighi, Paolo Sammarco and Erjon Bogdani, the manager Delneri also parted ways with the club. Giuseppe Iachini replaced him and the captain, Lorenzo D'Anna, gave way to Sergio Pellissier at the end of the transfer window. A new squad was constructed, most notably including the arrivals of midfielders Maurizio Ciaramitaro and Simone Bentivoglio, defender César and forward Antimo Iunco. This new incarnation of the \"gialloblu\" were crowned winter champions (along with Bologna), en route to a 41st matchday promotion after a 1–1 draw at Grosseto left them four points clear of third-place Lecce with one match remaining. In addition to winning promotion, they were conferred with the Ali della Vittoria trophy on the final matchday of the season, their first league title of any kind in 14 years.\n\nIn their first season back to the top flight, Chievo immediately struggled in the league resulting in the dismissal of Iachini in November and his replacement with former Parma boss Domenico Di Carlo. After Di Carlo's appointment, Chievo managed a remarkable resurgence that led the \"gialloblu\" out of the relegation zone after having collected just nine points from their first 17 matches. Highlight matches included a 3–0 defeat of Lazio (who then won the 2008–09 Coppa Italia title) at the Stadio Olimpico, and a thrilling 3–3 draw away to Juventus in which captain and longtime Chievo striker Sergio Pellissier scored a late equaliser to complete his first career hat-trick. A series of hard-fought draws against top clubs Roma, Internazionale and Genoa in the final stretch of the season solidified \"Ceo\"'s position outside the drop zone and Serie A status was finally confirmed on matchday 37 with a home draw against Bologna. A largely unchanged lineup earned safety the following season with four matchdays to spare, and Chievo is therefore a part of the inaugural Lega Calcio Serie A in 2010–11, their third consecutive season (and ninth season in the last ten years) in the top flight of Italian football.\n\n\nNote: this list includes players that have reached international status.\n\nThe club's original colours were blue and white and not the current blue and yellow. The club's historic nickname is \"Gialloblu\" (from the club colours of yellow and blue), although throughout Italian football, the Verona's team recognised in the past by most fans as \"Gialloblu\" are Hellas Verona, Chievo's main rivals. The club is sometimes referred to today as the \"Mussi Volanti\" (\"flying donkeys\" in the Verona dialect of Venetian). Local supporters often call the club simply \"Ceo\", which is Veronese for Chievo. The \"Flying Donkeys\" nickname was originally a derogatory term from a match chant sung by fans from crosstown rivals Hellas, which said that \"when donkeys'll fly, we'll have a derby in Serie A,\" of course sung before the two derbies attended in 2001–02. However, with later successes by Chievo and contemporaneous Serie B and Serie C1 struggles for Hellas, Chievo fans have now largely embraced the nickname as a badge of honour.\n\nThe current club crest represents Cangrande I della Scala, a medieval lord of Verona.\n\nStadio Marcantonio Bentegodi is a stadium in Verona, Italy. It is also the home of Chievo Verona city rival Hellas.\n\nInaugurated as a state-of-the-art facility and as one of Italy's finest venues in 1963, the stadium appeared excessive for a team (Hellas) that had spent the best part of the previous 35 years in Serie B. For the 1990 FIFA World Cup renovations included an extra tier and a roof to cover all sections, improved visibility, public transport connections, an urban motorway connecting the city centre with the stadium and the Verona Nord motorway exit and services.\n\nWithin the city of Verona, Chievo are considered the second club to Hellas. Since their rise through the Italian leagues however they have built up their own fanbase with crowds that generally average between 9,000 and 13,000.\n\nThere are many different supporters groups which can be found in the stadium at every home match. The largest and noisiest of which is known as North Side.\n\n"}
{"id": "6904", "url": "https://en.wikipedia.org/wiki?curid=6904", "title": "Context switch", "text": "Context switch\n\nIn computing, a context switch is the process of storing and restoring the state (more specifically, the execution context) of a process or thread so that execution can be resumed from the same point at a later time. This enables multiple processes to share a single CPU and is an essential feature of a multitasking operating system.\n\nThe precise meaning of \"context switch\" varies significantly in usage, most often to mean \"thread switch or process switch\" or \"process switch only\", either of which may be referred to as a \"task switch\". More finely, one can distinguish \"thread switch\" (switching between two threads within a given process), \"process switch\" (switching between two processes), \"mode switch\" (\"domain crossing\": switching between user mode and kernel mode within a given thread), \"register switch\", a \"stack frame switch\", and \"address space switch\" (\"memory map switch\": changing virtual memory to physical memory map). The computational cost of context switches varies significantly depending on what precisely it entails, from little more than a subroutine call for light-weight user processes, to very expensive, though typically much less than that of saving or restoring a process image.\n\nContext switches are usually computationally intensive, and much of the design of operating systems is to optimize the use of context switches. Switching from one process to another requires a certain amount of time for doing the administration saving and loading registers and memory maps, updating various tables and lists, etc. What is actually involved in a context switch varies between these senses and between processors and operating systems. For example, in the Linux kernel, context switching involves switching registers, stack pointer, and program counter, but is independent of address space switching, though in a process switch an address space switch also happens. Further still, analogous context switching happens between user threads, notably green threads, and is often very light-weight, saving and restoring minimal context. In extreme cases, such as switching between goroutines in Go, a context switch is equivalent to a coroutine yield, which is only marginally more expensive than a subroutine call.\n\nThere are three potential triggers for a context switch:\n\nMost commonly, within some scheduling scheme, one process must be switched out of the CPU so another process can run.\nThis context switch can be triggered by the process making itself unrunnable, such as by waiting for an I/O or synchronization operation to complete. On a pre-emptive multitasking system, the scheduler may also switch out processes which are still runnable. To prevent other processes from being starved of CPU time, preemptive schedulers often configure a timer interrupt to fire when a process exceeds its time slice. This interrupt ensures that the scheduler will gain control to perform a context switch.\n\nModern architectures are interrupt driven. This means that if the CPU requests data from a disk, for example, it does not need to busy-wait until the read is over; it can issue the request and continue with some other execution. When the read is over, the CPU can be \"interrupted\" and presented with the read. For interrupts, a program called an \"interrupt handler\" is installed, and it is the interrupt handler that handles the interrupt from the disk.\n\nWhen an interrupt occurs, the hardware automatically switches a part of the context (at least enough to allow the handler to return to the interrupted code). The handler may save additional context, depending on details of the particular hardware and software designs. Often only a minimal part of the context is changed in order to minimize the amount of time spent handling the interrupt.\nThe kernel does not spawn or schedule a special process to handle interrupts, but instead the handler executes in the (often partial) context established at the beginning of interrupt handling. Once interrupt servicing is complete, the context in effect before the interrupt occurred is restored so that the interrupted process can resume execution in its proper state.\n\nWhen a transition between user mode and kernel mode is required in an operating system, a context switch is not necessary; a mode transition is \"not\" by itself a context switch. However, depending on the operating system, a context switch may also take place at this time.\n\nIn a switch, the state of process currently executing must be saved somehow, so that when it is rescheduled, this state can be restored.\n\nThe process state includes all the registers that the process may be using, especially the program counter, plus any other operating system specific data that may be necessary. This is usually stored in a data structure called a process control block (PCB) or switchframe.\n\nThe PCB might be stored on a per-process stack in kernel memory (as opposed to the user-mode call stack), or there may be some specific operating system defined data structure for this information. A handle to the PCB is added to a queue of processes that are ready to run, often called the ready queue.\n\nSince the operating system has effectively suspended the execution of one process, it can then switch context by choosing a process from the ready queue and restoring its PCB. In doing so, the program counter from the PCB is loaded, and thus execution can continue in the chosen process. Process and thread priority can influence which process is chosen from the ready queue (i.e., it may be a priority queue).\n\nContext switching itself has a cost in performance, due to running the task scheduler, TLB flushes, and indirectly due to sharing the CPU cache between multiple tasks. Switching between threads of a single process can be faster than between two separate processes, because threads share the same virtual memory maps, so a TLB flush is not necessary.\n\nContext switching can be performed primarily by software or hardware. Some processors, like the Intel 80386 and its successors, have hardware support for context switches, by making use of a special data segment designated the task state segment or TSS. A task switch can be explicitly triggered with a CALL or JMP instruction targeted at a TSS descriptor in the global descriptor table. It can occur implicitly when an interrupt or exception is triggered if there's a task gate in the interrupt descriptor table. When a task switch occurs the CPU can automatically load the new state from the TSS.\n\nAs with other tasks performed in hardware, one would expect this to be rather fast; however, mainstream operating systems, including Windows and Linux, do not use this feature. This is mainly due to two reasons:\n\n\n"}
{"id": "6905", "url": "https://en.wikipedia.org/wiki?curid=6905", "title": "Carnatic", "text": "Carnatic\n\nCarnatic usually refers to:\n\nIt may also refer to:\n"}
{"id": "6907", "url": "https://en.wikipedia.org/wiki?curid=6907", "title": "Chakra", "text": "Chakra\n\nChakra (IAST: C̣akra, meaning \"wheel, circle\"), sometimes spelled Cakra or Cakka, is any center of subtle body believed to be psychic-energy centers in the esoteric traditions of Indian religions.\n\nThe concept is found particularly in the tantric traditions of Hinduism, Buddhism and Jainism. They are conceived as an energy focal point, bodily functions or psychic node in the subtle body. The Chakra theories are elaborate part of the Kundalini system. These theories differ between the Indian religions, with esoteric Buddhist literature mentioning four Chakras, while esoteric Hindu texts stating seven. They are believed to be part of the subtle body, not the physical body, and connected by energy channels called Nadi. In the Kundalini version of yoga, breath exercises focus, in part, on mastering and channeling energy through Chakras.\n\nThe word \"Chakra\" (चक्र) derives from the Sanskrit word meaning \"wheel,\" as well as \"circle\" and \"cycle\". One of the Hindu scriptures \"Rigveda\" mentions \"Chakra\" with the meaning of \"wheel\", with \"ara\" (spokes). According to Frits Staal, \"Chakra\" has Indo-European roots, is \"related to \"Kuklos\" (Greek) from which comes English \"cycle\", Latin \"circus\", Anglo-Saxon \"hveohl\" and English \"wheel\".\" However, the Vedic period texts use the same word as a simile in other contexts, such as the \"wheel of time\" or \"wheel of dharma\", such as in \"Rigveda\" hymn verse 1.164.11.\n\nIn Buddhism, the Sanskrit term \"cakra\" (Pali \"cakka\") also means \"wheel\", but it is used in the additional sense of \"circle\" connoting rebirth in six realms of existence where a being is reborn after each death.\n\nIn Jainism, the term \"Chakra\" also means \"wheel\" and appears in various context in its ancient literature. Like other Indian religions, \"Chakra\" in esoteric theories in Jainism such as those by Buddhisagarsuri means yogic-energy centers.\n\nThe term \"Chakra\" already appears in Vedic literature, but not in the sense of psychic energy centers, rather as \"chakravartin\" or the king who \"turns the wheel of his empire\" in all directions from a center, representing his influence and power. The iconography popular in representing the \"Chakras\", states White, trace back to the five symbols of yajna, the Vedic fire altar: \"square, circle, triangle, half moon and dumpling\".\n\nThe hymn 10.136 of the \"Rigveda\" mentions a loner yogi ascetic with a female named \"kunamnama\". Literally, it means \"she who is bent, coiled\", and it probably is either a minor goddess or one of many embedded puzzles and hidden references within the \"Rigveda\". Some scholars, such as David Gordon White and Georg Feuerstein interpret this might be related to kundalini shakti, and a prelude to the terms such as chakra that emerged later.\n\nBreath channels (nāḍi) of Yoga practices are mentioned in the classical Upanishads of Hinduism dated to 1st millennium BCE, but not psychic-energy Chakra theories. The latter, states White, were introduced about 8th-century CE in Buddhist texts as hierarchies of inner energy centers, such as in the \"Hevajra Tantra\" and \"Caryāgiti\". These are called by various terms such as \"cakka\", \"padma\" (lotus) or \"pitha\" (mound). These medieval Buddhist texts mention only four chakras, while later texts such as the \"Kubjikāmata\" and \"Kaulajñānanirnaya\" expanded the list to many more.\n\nIn contrast to White, according to Feuerstein, early Upanishads of Hinduism do mention \"cakra\" in the sense of \"psychospiritual vortices\", along with other terms found in tantra: \"prana\" or \"vayu\" (life energy) along with \"nadi\" (energy carrying arteries). According to Galvin Flood, the ancient texts do not present \"chakra\" and kundalini-style yoga theories although these words appear in the earliest Vedic literature in many contexts. The \"chakra\" in the sense of four or more vital energy centers appear in the medieval era Hindu and Buddhist texts.\n\nChakra is a part of esoteric medieval era theories about physiology and psychic centers that emerged across Indian traditions. The theory posited that human life simultaneously exists in two parallel dimensions, one \"physical body\" (\"sthula sarira\") and other \"psychological, emotional, mind, non-physical\" it called the \"subtle body\" (\"suksma sarira\"). This subtle body is energy, while the physical body is mass. The psyche or mind plane corresponds to and interacts with the body plane, and the theory posits that the body and the mind mutually affect each other. The subtle body consists of nadi (energy channels) connected by nodes of psychic energy it called \"chakra\". The theory grew into extensive elaboration, with some suggesting 88,000 cakras throughout the subtle body. The chakra it considered most important varied between various traditions, but they typically ranged between four and seven.\nThe important chakras are stated in Buddhist and Hindu texts to be arranged in a column along the spinal cord, from its base to the top of the head, connected by vertical channels. The tantric traditions sought to master them, awaken and energize them through various breathing exercises or with assistance of a teacher. These chakras were also symbolically mapped to specific human physiological capacity, seed syllables (bija), sounds, subtle elements (tanmatra), in some cases deities, colors and other motifs.\n\nThe chakra theories of Buddhism and Hinduism differs from the historic Chinese system of meridians in acupuncture. Unlike the latter, the \"chakra\" relates to subtle body, wherein it has a position but no definite nervous node or precise physical connection. The tantric systems envision it as a continually present, highly relevant and a means to psychic and emotional energy. It is useful in a type of yogic rituals and meditative discovery of radiant inner energy (\"prana\" flows) and mind-body connections. The meditation is aided by extensive symbology, mantras, diagrams, models (deity and mandala). The practitioner proceeds step by step from perceptible models, to increasingly abstract models where deity and external mandala are abandoned, inner self and internal mandalas are awakened.\n\nThese ideas are not unique to Buddhist and Hindu traditions. Similar and overlapping concepts emerged in other cultures in the East and the West, and these are variously called by other names such as subtle body, spirit body, esoteric anatomy, sideral body and etheric body. According to Geoffrey Samuel and Jay Johnston, professors of Religious studies known for their studies on Yoga and esoteric traditions:\n\nChakra and related theories have been important to the esoteric traditions, but they are not directly related to mainstream yoga. According to Edwin Bryant and other scholars, the goals of classical yoga such as spiritual liberation (freedom, self-knowledge, moksha) is \"attained entirely differently in classical yoga, and the \"cakra / nadi / kundalini\" physiology is completely peripheral to it.\"\n\nThe classical eastern traditions, particularly those that developed in India during the 1st millennium CE, primarily describe \"nadi\" and \"cakra\" in a \"subtle body\" context. To them, they are the parallel dimension of psyche-mind reality that is invisible yet real. In the \"nadi\" and \"cakra\" flow the \"prana\" (breath, life energy). The concept of \"life energy\" varies between the texts, ranging from simple inhalation-exhalation to far more complex association with breath-mind-emotions-sexual energy. These are envisioned as an life energy essence that flows through channels in the subtle body and meet at nodes called chakra. This essence is what vanishes when a person dies, leaving a gross body. Some of it, states this subtle body theory, is what withdraws within when one sleeps. All of it is believed to be reachable, awake-able and important for an individual's body-mind health, and how one relates to other people in one's life. This subtle body network of \"nadi\" and \"chakra\" is, according to these Indian theories, closely associated with emotions, mind, mood, feeling about oneself and feeling for others.\n\nThe esoteric traditions in Hinduism mention numerous chakras, of which they state seven are most important. The seven system, according to David Gordon White, are one among many systems found in Hindu tantric literature. These texts teach many different Chakra theories.\n\nThe Chakra methodology is extensively developed in the goddess tradition of Hinduism called Shaktism. It is an important concept along with yantras, mandalas and kundalini yoga system in its practice. Chakra in Shakta tantrism means circle, a \"energy center\" within, as well as is a term of group rituals such as in \"chakra-puja\" (worship within a circle) which may or may not involve tantra practice. The cakra-based system is a part of the meditative exercises called Laya yoga.\n\nSome sub-traditions within the Shiva-related (Shaivism) school of Hinduism also developed texts and practices on Nadi and Chakra systems. According to Geoffrey, these systems were mapped to consciousness, energy or emotion, much like Vajrayana Buddhism. These Hindu traditions also developed the yoga sub-school called the \"kriya yoga\", or \"yoga of ritual action\", believed by its practitioners to activate Chakra and energy centers in the body.\n\nThe esoteric traditions in Buddhism generally teach four chakras. These are the Manipura, the Andhata, the Visuddha and the Usnisa Kamala. In another version, these four are the Nirmana, the Dharma, the Sambhoga and the Mahasukha (respectively corresponding to the Shaiva tantra school's following four of seven chakra: Svadhisthana, the Anahata, the Visuddha and the Sahasrara). However, depending on the meditational tradition, these vary between three and six.\n\nChakras play an important role in the Tibetan Buddhism in completion stage practices. It is practiced to bring the subtle winds of the body into the central channel, to realise the clear light of bliss and emptiness, and to attain Buddhahood.\n\nAccording to Geoffrey, the Tibetan and esoteric Buddhist traditions developed cakra and nadi as \"central to their soteriological process\". The theories were coupled with a tradition of physical exercises, now sometimes called \"yantra yoga\", but traditionally referred to a \"'phrul 'khor\" in Tibetan. This style of yoga emphasizes visualizations and internal practices, somewhat similar to the \"kriya yoga\" practices in some sub-traditions of Hinduism. The differences between the two styles, according to Geoffrey, has been that the Tibetan tradition focussed more on \"offering rituals to benign deities\" already prevalent in Tibet, while the Indic traditions focussed more on the internal practices linked to subtle body concepts. The \"yantra yoga\" at the Completion Stage of esoteric Buddhism typically followed its \"deity-yoga\" practices of the Generation Stage.\n\nThe Chakra in the Tibetan practice are considered psycho-physical centers, each associated with a cosmic Buddha.\n\nChakras, according to the Bon tradition, influence the quality of experience, because movement of vayu cannot be separated from experience. Each of the six major chakras is linked to experiential qualities of one of the six realms of existence.\n\nThe tsa lung practices such as those embodied in Trul khor lineages open channels so \"lung\" (the Tibetan term for vayu) may move without obstruction. Yoga opens chakras and evokes positive qualities associated with a particular chakra. In the hard drive analogy, the screen is cleared and a file is called up that contains positive, supportive qualities. A bīja (seed syllable) is used both as a password that evokes the positive quality and the armour that sustains the quality.\n\nTantric practice is said to eventually transform all experience into bliss. The practice aims to liberate from negative conditioning and leads to control over perception and cognition.\n\nQigong () also relies on a similar model of the human body as an esoteric energy system, except that it involves the circulation of qì (, also \"ki\") or life-energy. The qì, equivalent to the Hindu prana, flows through the energy channels called meridians, equivalent to the nadi, but two other energies are also important: \"jīng\", or primordial essence, and \"shén\", or spirit energy.\n\nIn the principle circuit of qì, called the microcosmic orbit, energy rises up a main meridian along the spine, but also comes back down the front torso. Throughout its cycle it enters various dantian (elixir fields) which act as furnaces, where the types of energy in the body (jing, qi and shen) are progressively refined. These dantian play a very similar role to that of chakras. The number of dantian varies depending on the system; the navel dantian is the most well-known, but there is usually a dantian located at the heart and between the eyebrows. The lower dantian at or below the navel transforms essence, or jīng, into qì. The middle dantian in the middle of the chest transforms qì into shén, or spirit, and the higher dantian at the level of the forehead (or at the top of the head), transforms shen into wuji, infinite space of void.\n\nTraditional spirituality in the Malay Archipelago borrows heavily from Hindu-Buddhist concepts. In Malay and Indonesian metaphysical theory, the chakras' energy rotates outwards along diagonal lines. Defensive energy emits outwards from the centre line, while offensive energy moves inwards from the sides of the body. This can be applied to energy-healing, meditation, or martial arts. Silat practitioners learn to harmonise their movements with the chakras, thereby increasing the power and effectiveness of attacks and movements.\n\nThe more common and most studied esoteric system incorporates seven major chakras, which are arranged vertically along the axial channel (sushumna nadi in Hindu texts, Avadhuti in some Buddhist texts). It was the chakra system translated in early 20th century by Sir John Woodroffe (also called Arthur Avalon) in the text \"The Serpent Power.\" Avalon translated the Hindu text \"Sat-Cakra-Nirupana\".\n\nThe Chakras are considered as meditation aids, wherein the yogi progresses from lower located Chakras to the highest Chakra blossoming in the crown of the head reflecting the journey of spiritual ascent. In both the Hindu and Buddhist traditions, the Chakra are visualized with an energy goddess residing dormant in the lowest chakra, and one of the aims is to awaken her within. In Hindu texts she is known as Kundalini, while in Buddhist texts she is called Candali or Tummo (Tibetan: \"gtum mo\", \"fierce one\"). While both systems associate deities with their chakra-knot systems (Tibetan: \"rtsa 'khor\"), the meditational goals are different: in Hindu systems, the aim to discover and realize the Shiva within. In Buddhist system, is to transcend the ordinary truth and discover the truth of the Buddha, or according to the \"Hevajra Tantra\" burn the conventional Buddhas and attain the Buddhahood of Hevajra.\n\nBelow is a description of these seven chakras:\n\nHridhiya chakra (also known as \"hrid chakra\") is measured from centre of Anahata chakra, two fingers to the left and continue with two finger down, whereby the heart beat can be felt. Talu chakra is located at behind of Reticular Formation at Fourth Ventrical before beginning of spinal cord. There are said to be 21 minor chakras which are reflected points of the major chakras.\n\nThere are said to be three chakras that are beyond the physical and spiritual. They are called Golata, Lalata, and Lalana and \"located on the uvula at the back of the throat, above the Ajna chakra, and within the soft upper palate\".\n\nIn 1918, the translation of two Indian texts: the \"Sat-Cakra-Nirupana\" and the \"Padaka-Pancaka\", by Sir John Woodroffe, alias Arthur Avalon, in a book titled \"The Serpent Power\" introduced the shakta theory of seven main chakras in the West. This book is extremely detailed and complex, and later the ideas were developed into the predominant Western view of the chakras by C. W. Leadbeater in his book \"The Chakras\". Many of the views which directed Leadbeater's understanding of the chakras were influenced by previous theosophist authors, in particular Johann Georg Gichtel, a disciple of Jakob Böhme, and his book \"Theosophia Practica (1696)\", in which Gichtel directly refers to inner \"force centres\", a concept reminiscent of the chakras.\n\nA completely separate contemplative movement within the Eastern Orthodox Church is Hesychasm, a form of Christian meditation. Comparisons have been made between the Hesychastic centres of prayer and the position of the chakras. Particular emphasis is placed upon the heart area. However, there is no talk about these centres as having any sort of metaphysical existence. Far more than in any of the cases discussed above, the centres are simply places to focus the concentration during prayer.\n\nIn \"Anatomy of the Spirit\" (1996), Caroline Myss describes the function of chakras as follows: \"Every thought and experience you've ever had in your life gets filtered through these chakra databases. Each event is recorded into your cells...\". The chakras are described as being aligned in an ascending column from the base of the spine to the top of the head. New Age practices often associate each chakra with a certain colour. In various traditions, chakras are associated with multiple physiological functions, an aspect of consciousness, a classical element, and other distinguishing characteristics. They are visualised as lotuses or flowers with a different number of petals in every chakra.\n\nThe chakras are thought to vitalise the physical body and to be associated with interactions of a physical, emotional and mental nature. They are considered of life energy or prana (which New Age belief equates with \"shakti\", \"qi\" in Chinese, \"ki \"in Japanese, \"koach-ha-guf\" in Hebrew, \"bios \"in Greek, and \"aether\"\" \"in both Greek and English), which is thought to flow among them along pathways called nadi. The function of the chakras is to spin and draw in this energy to keep the spiritual, mental, emotional and physical health of the body in balance.\n\nRudolf Steiner considered the chakra system to be dynamic and evolving. He suggested that this system has become different for modern people than it was in ancient times and that it will, in turn, be radically different in future times. Steiner described a sequence of development that begins with the upper chakras and moves down, rather than moving in the opposite direction. He gave suggestions on how to develop the chakras through disciplining thoughts, feelings, and will.\n\nAccording to Florin Lowndes, a \"spiritual student\" can further develop and deepen or elevate thinking consciousness when taking the step from the \"ancient path\" of schooling to the \"new path\" represented by Steiner's \"The Philosophy of Freedom\".\n\nChakras and their importance are posited to reside in the psyche. However, there are those who believe that chakras have a physical manifestation as well. Gary Osborn, for instance, has described the chakras as metaphysical counterparts to the endocrine glands, while Anodea Judith noted a marked similarity between the positions of the two and the roles described for each. Stephen Sturgess also links the lower six chakras to specific nerve plexuses along the spinal cord as well as glands. C.W. Leadbeater associated the Ajna chakra with the pineal gland, which is a part of the endocrine system. These associations remain speculative, however, and have yet to be empirically validated.\n\n"}
{"id": "6910", "url": "https://en.wikipedia.org/wiki?curid=6910", "title": "Cloning", "text": "Cloning\n\nIn biology, cloning is the process of producing similar populations of genetically identical individuals that occurs in nature when organisms such as bacteria, insects or plants reproduce asexually. Cloning in biotechnology refers to processes used to create copies of DNA fragments (molecular cloning), cells (cell cloning), or organisms. The term also refers to the production of multiple copies of a product such as digital media or software.\n\nThe term clone, invented by J. B. S. Haldane, is derived from the Ancient Greek word κλών \"klōn\", \"twig\", referring to the process whereby a new plant can be created from a twig. In horticulture, the spelling \"clon\" was used until the twentieth century; the final \"e\" came into use to indicate the vowel is a \"long o\" instead of a \"short o\". Since the term entered the popular lexicon in a more general context, the spelling \"clone\" has been used exclusively.\n\nIn botany, the term lusus was traditionally used.\n\nCloning is a natural form of reproduction that has allowed life forms to spread for more than 50 thousand years. It is the reproduction method used by plants, fungi, and bacteria, and is also the way that clonal colonies reproduce themselves. Examples of these organisms include blueberry plants, hazel trees, the Pando trees, the Kentucky coffeetree, \"Myrica\"s, and the American sweetgum.\n\nMolecular cloning refers to the process of making multiple molecules. Cloning is commonly used to amplify DNA fragments containing whole genes, but it can also be used to amplify any DNA sequence such as promoters, non-coding sequences and randomly fragmented DNA. It is used in a wide array of biological experiments and practical applications ranging from genetic fingerprinting to large scale protein production. Occasionally, the term cloning is misleadingly used to refer to the identification of the chromosomal location of a gene associated with a particular phenotype of interest, such as in positional cloning. In practice, localization of the gene to a chromosome or genomic region does not necessarily enable one to isolate or amplify the relevant genomic sequence. To amplify any DNA sequence in a living organism, that sequence must be linked to an origin of replication, which is a sequence of DNA capable of directing the propagation of itself and any linked sequence. However, a number of other features are needed, and a variety of specialised cloning vectors (small piece of DNA into which a foreign DNA fragment can be inserted) exist that allow protein production, affinity tagging, single stranded RNA or DNA production and a host of other molecular biology tools.\n\nCloning of any DNA fragment essentially involves four steps\n\nAlthough these steps are invariable among cloning procedures a number of alternative routes can be selected; these are summarized as a \"cloning strategy\".\n\nInitially, the DNA of interest needs to be isolated to provide a DNA segment of suitable size. Subsequently, a ligation procedure is used where the amplified fragment is inserted into a vector (piece of DNA). The vector (which is frequently circular) is linearised using restriction enzymes, and incubated with the fragment of interest under appropriate conditions with an enzyme called DNA ligase. Following ligation the vector with the insert of interest is transfected into cells. A number of alternative techniques are available, such as chemical sensitivation of cells, electroporation, optical injection and biolistics. Finally, the transfected cells are cultured. As the aforementioned procedures are of particularly low efficiency, there is a need to identify the cells that have been successfully transfected with the vector construct containing the desired insertion sequence in the required orientation. Modern cloning vectors include selectable antibiotic resistance markers, which allow only cells in which the vector has been transfected, to grow. Additionally, the cloning vectors may contain colour selection markers, which provide blue/white screening (alpha-factor complementation) on X-gal medium. Nevertheless, these selection steps do not absolutely guarantee that the DNA insert is present in the cells obtained. Further investigation of the resulting colonies must be required to confirm that cloning was successful. This may be accomplished by means of PCR, restriction fragment analysis and/or DNA sequencing.\n\nCloning a cell means to derive a population of cells from a single cell. In the case of unicellular organisms such as bacteria and yeast, this process is remarkably simple and essentially only requires the inoculation of the appropriate medium. However, in the case of cell cultures from multi-cellular organisms, cell cloning is an arduous task as these cells will not readily grow in standard media.\n\nA useful tissue culture technique used to clone distinct lineages of cell lines involves the use of cloning rings (cylinders). In this technique a single-cell suspension of cells that have been exposed to a mutagenic agent or drug used to drive selection is plated at high dilution to create isolated colonies, each arising from a single and potentially clonal distinct cell. At an early growth stage when colonies consist of only a few cells, sterile polystyrene rings (cloning rings), which have been dipped in grease, are placed over an individual colony and a small amount of trypsin is added. Cloned cells are collected from inside the ring and transferred to a new vessel for further growth.\n\nSomatic-cell nuclear transfer, known as SCNT, can also be used to create embryos for research or therapeutic purposes. The most likely purpose for this is to produce embryos for use in stem cell research. This process is also called \"research cloning\" or \"therapeutic cloning.\" The goal is not to create cloned human beings (called \"reproductive cloning\"), but rather to harvest stem cells that can be used to study human development and to potentially treat disease. While a clonal human blastocyst has been created, stem cell lines are yet to be isolated from a clonal source.\n\nTherapeutic cloning is achieved by creating embryonic stem cells in the hopes of treating diseases such as diabetes and Alzheimer's. The process begins by removing the nucleus (containing the DNA) from an egg cell and inserting a nucleus from the adult cell to be cloned. In the case of someone with Alzheimer's disease, the nucleus from a skin cell of that patient is placed into an empty egg. The reprogrammed cell begins to develop into an embryo because the egg reacts with the transferred nucleus. The embryo will become genetically identical to the patient. The embryo will then form a blastocyst which has the potential to form/become any cell in the body.\n\nThe reason why SCNT is used for cloning is because somatic cells can be easily acquired and cultured in the lab. This process can either add or delete specific genomes of farm animals. A key point to remember is that cloning is achieved when the oocyte maintains its normal functions and instead of using sperm and egg genomes to replicate, the oocyte is inserted into the donor’s somatic cell nucleus. The oocyte will react on the somatic cell nucleus, the same way it would on sperm cells.\n\nThe process of cloning a particular farm animal using SCNT is relatively the same for all animals. The first step is to collect the somatic cells from the animal that will be cloned. The somatic cells could be used immediately or stored in the laboratory for later use. The hardest part of SCNT is removing maternal DNA from an oocyte at metaphase II. Once this has been done, the somatic nucleus can be inserted into an egg cytoplasm. This creates a one-cell embryo. The grouped somatic cell and egg cytoplasm are then introduced to an electrical current. This energy will hopefully allow the cloned embryo to begin development. The successfully developed embryos are then placed in surrogate recipients, such as a cow or sheep in the case of farm animals.\n\nSCNT is seen as a good method for producing agriculture animals for food consumption. It successfully cloned sheep, cattle, goats, and pigs. Another benefit is SCNT is seen as a solution to clone endangered species that are on the verge of going extinct. However, stresses placed on both the egg cell and the introduced nucleus can be enormous, which led to a high loss in resulting cells in early research. For example, the cloned sheep Dolly was born after 277 eggs were used for SCNT, which created 29 viable embryos. Only three of these embryos survived until birth, and only one survived to adulthood. As the procedure could not be automated, and had to be performed manually under a microscope, SCNT was very resource intensive. The biochemistry involved in reprogramming the differentiated somatic cell nucleus and activating the recipient egg was also far from being well understood. However, by 2014 researchers were reporting cloning success rates of seven to eight out of ten and in 2016, a Korean Company Sooam Biotech was reported to be producing 500 cloned embryos per day.\n\nIn SCNT, not all of the donor cell's genetic information is transferred, as the donor cell's mitochondria that contain their own mitochondrial DNA are left behind. The resulting hybrid cells retain those mitochondrial structures which originally belonged to the egg. As a consequence, clones such as Dolly that are born from SCNT are not perfect copies of the donor of the nucleus.\n\nOrganism cloning (also called reproductive cloning) refers to the procedure of creating a new multicellular organism, genetically identical to another. In essence this form of cloning is an asexual method of reproduction, where fertilization or inter-gamete contact does not take place. Asexual reproduction is a naturally occurring phenomenon in many species, including most plants (see vegetative reproduction) and some insects. Scientists have made some major achievements with cloning, including the asexual reproduction of sheep and cows. There is a lot of ethical debate over whether or not cloning should be used. However, cloning, or asexual propagation, has been common practice in the horticultural world for hundreds of years.\n\nThe term \"clone\" is used in horticulture to refer to descendants of a single plant which were produced by vegetative reproduction or apomixis. Many horticultural plant cultivars are clones, having been derived from a single individual, multiplied by some process other than sexual reproduction. As an example, some European cultivars of grapes represent clones that have been propagated for over two millennia. Other examples are potato and banana. Grafting can be regarded as cloning, since all the shoots and branches coming from the graft are genetically a clone of a single individual, but this particular kind of cloning has not come under ethical scrutiny and is generally treated as an entirely different kind of operation.\n\nMany trees, shrubs, vines, ferns and other herbaceous perennials form clonal colonies naturally. Parts of an individual plant may become detached by fragmentation and grow on to become separate clonal individuals. A common example is in the vegetative reproduction of moss and liverwort gametophyte clones by means of gemmae. Some vascular plants e.g. dandelion and certain viviparous grasses also form seeds asexually, termed apomixis, resulting in clonal populations of genetically identical individuals.\n\nClonal derivation exists in nature in some animal species and is referred to as parthenogenesis (reproduction of an organism by itself without a mate). This is an asexual form of reproduction that is only found in females of some insects, crustaceans, nematodes, fish (for example the hammerhead shark), the Komodo dragon and lizards. The growth and development occurs without fertilization by a male. In plants, parthenogenesis means the development of an embryo from an unfertilized egg cell, and is a component process of apomixis. In species that use the XY sex-determination system, the offspring will always be female. An example is the little fire ant (\"Wasmannia auropunctata\"), which is native to Central and South America but has spread throughout many tropical environments.\n\nArtificial cloning of organisms may also be called \"reproductive cloning\".\n\nHans Spemann, a German embryologist was awarded a Nobel Prize in Physiology or Medicine in 1935 for his discovery of the effect now known as embryonic induction, exercised by various parts of the embryo, that directs the development of groups of cells into particular tissues and organs. In 1928 he and his student, Hilde Mangold, were the first to perform somatic-cell nuclear transfer using amphibian embryos – one of the first moves towards cloning.\n\nReproductive cloning generally uses \"somatic cell nuclear transfer\" (SCNT) to create animals that are genetically identical. This process entails the transfer of a nucleus from a donor adult cell (somatic cell) to an egg from which the nucleus has been removed, or to a cell from a blastocyst from which the nucleus has been removed. If the egg begins to divide normally it is transferred into the uterus of the surrogate mother. Such clones are not strictly identical since the somatic cells may contain mutations in their nuclear DNA. Additionally, the mitochondria in the cytoplasm also contains DNA and during SCNT this mitochondrial DNA is wholly from the cytoplasmic donor's egg, thus the mitochondrial genome is not the same as that of the nucleus donor cell from which it was produced. This may have important implications for cross-species nuclear transfer in which nuclear-mitochondrial incompatibilities may lead to death.\n\nArtificial \"embryo splitting\" or \"embryo twinning\", a technique that creates monozygotic twins from a single embryo, is not considered in the same fashion as other methods of cloning. During that procedure, a donor embryo is split in two distinct embryos, that can then be transferred via embryo transfer. It is optimally performed at the 6- to 8-cell stage, where it can be used as an expansion of IVF to increase the number of available embryos. If both embryos are successful, it gives rise to monozygotic (identical) twins.\n\nDolly, a Finn-Dorset ewe, was the first mammal to have been successfully cloned from an adult somatic cell. Dolly was formed by taking a cell from the udder of her 6-year old biological mother. Dolly's embryo was created by taking the cell and inserting it into a sheep ovum. It took 434 attempts before an embryo was successful. The embryo was then placed inside a female sheep that went through a normal pregnancy. She was cloned at the Roslin Institute in Scotland by British scientists Sir Ian Wilmut and Keith Campbell and lived there from her birth in 1996 until her death in 2003 when she was six. She was born on 5 July 1996 but not announced to the world until 22 February 1997. Her stuffed remains were placed at Edinburgh's Royal Museum, part of the National Museums of Scotland.\n\nDolly was publicly significant because the effort showed that genetic material from a specific adult cell, programmed to express only a distinct subset of its genes, can be reprogrammed to grow an entirely new organism. Before this demonstration, it had been shown by John Gurdon that nuclei from differentiated cells could give rise to an entire organism after transplantation into an enucleated egg. However, this concept was not yet demonstrated in a mammalian system.\n\nThe first mammalian cloning (resulting in Dolly the sheep) had a success rate of 29 embryos per 277 fertilized eggs, which produced three lambs at birth, one of which lived. In a bovine experiment involving 70 cloned calves, one-third of the calves died young. The first successfully cloned horse, Prometea, took 814 attempts. Notably, although the first clones were frogs, no adult cloned frog has yet been produced from a somatic adult nucleus donor cell.\n\nThere were early claims that Dolly the sheep had pathologies resembling accelerated aging. Scientists speculated that Dolly's death in 2003 was related to the shortening of telomeres, DNA-protein complexes that protect the end of linear chromosomes. However, other researchers, including Ian Wilmut who led the team that successfully cloned Dolly, argue that Dolly's early death due to respiratory infection was unrelated to deficiencies with the cloning process. This idea that the nuclei have not irreversibly aged was shown in 2013 to be true for mice.\n\nDolly was named after performer Dolly Parton because the cells cloned to make her were from a mammary gland cell, and Parton is known for her ample cleavage.\n\nThe modern cloning techniques involving nuclear transfer have been successfully performed on several species. Notable experiments include:\n\nHuman cloning is the creation of a genetically identical copy of a human. The term is generally used to refer to artificial human cloning, which is the reproduction of human cells and tissues. It does not refer to the natural conception and delivery of identical twins. The possibility of human cloning has raised controversies. These ethical concerns have prompted several nations to pass legislature regarding human cloning and its legality.\n\nTwo commonly discussed types of theoretical human cloning are \"therapeutic cloning\" and \"reproductive cloning\". Therapeutic cloning would involve cloning cells from a human for use in medicine and transplants, and is an active area of research, but is not in medical practice anywhere in the world, as of 2014. Two common methods of therapeutic cloning that are being researched are somatic-cell nuclear transfer and, more recently, pluripotent stem cell induction. Reproductive cloning would involve making an entire cloned human, instead of just specific cells or tissues.\n\nThere are a variety of ethical positions regarding the possibilities of cloning, especially human cloning. While many of these views are religious in origin, the questions raised by cloning are faced by secular perspectives as well. Perspectives on human cloning are theoretical, as human therapeutic and reproductive cloning are not commercially used; animals are currently cloned in laboratories and in livestock production.\n\nAdvocates support development of therapeutic cloning in order to generate tissues and whole organs to treat patients who otherwise cannot obtain transplants, to avoid the need for immunosuppressive drugs, and to stave off the effects of aging. Advocates for reproductive cloning believe that parents who cannot otherwise procreate should have access to the technology.\n\nOpponents of cloning have concerns that technology is not yet developed enough to be safe and that it could be prone to abuse (leading to the generation of humans from whom organs and tissues would be harvested), as well as concerns about how cloned individuals could integrate with families and with society at large.\n\nReligious groups are divided, with some opposing the technology as usurping \"God's place\" and, to the extent embryos are used, destroying a human life; others support therapeutic cloning's potential life-saving benefits.\n\nCloning of animals is opposed by animal-groups due to the number of cloned animals that suffer from malformations before they die, and while food from cloned animals has been approved by the US FDA, its use is opposed by groups concerned about food safety.\n\nCloning, or more precisely, the reconstruction of functional DNA from extinct species has, for decades, been a dream. Possible implications of this were dramatized in the 1984 novel \"Carnosaur\" and the 1990 novel \"Jurassic Park\". The best current cloning techniques have an average success rate of 9.4 percent (and as high as 25 percent) when working with familiar species such as mice, while cloning wild animals is usually less than 1 percent successful. Several tissue banks have come into existence, including the \"Frozen Zoo\" at the San Diego Zoo, to store frozen tissue from the world's rarest and most endangered species.\n\nIn 2001, a cow named Bessie gave birth to a cloned Asian gaur, an endangered species, but the calf died after two days. In 2003, a banteng was successfully cloned, followed by three African wildcats from a thawed frozen embryo. These successes provided hope that similar techniques (using surrogate mothers of another species) might be used to clone extinct species. Anticipating this possibility, tissue samples from the last \"bucardo\" (Pyrenean ibex) were frozen in liquid nitrogen immediately after it died in 2000. Researchers are also considering cloning endangered species such as the giant panda and cheetah.\n\nIn 2002, geneticists at the Australian Museum announced that they had replicated DNA of the thylacine (Tasmanian tiger), at the time extinct for about 65 years, using polymerase chain reaction. However, on 15 February 2005 the museum announced that it was stopping the project after tests showed the specimens' DNA had been too badly degraded by the (ethanol) preservative. On 15 May 2005 it was announced that the thylacine project would be revived, with new participation from researchers in New South Wales and Victoria.\n\nIn January 2009, for the first time, an extinct animal, the Pyrenean ibex mentioned above was cloned, at the Centre of Food Technology and Research of Aragon, using the preserved frozen cell nucleus of the skin samples from 2001 and domestic goat egg-cells. The ibex died shortly after birth due to physical defects in its lungs.\n\nOne of the most anticipated targets for cloning was once the woolly mammoth, but attempts to extract DNA from frozen mammoths have been unsuccessful, though a joint Russo-Japanese team is currently working toward this goal. In January 2011, it was reported by Yomiuri Shimbun that a team of scientists headed by Akira Iritani of Kyoto University had built upon research by Dr. Wakayama, saying that they will extract DNA from a mammoth carcass that had been preserved in a Russian laboratory and insert it into the egg cells of an African elephant in hopes of producing a mammoth embryo. The researchers said they hoped to produce a baby mammoth within six years. It was noted, however that the result, if possible, would be an elephant-mammoth hybrid rather than a true mammoth. Another problem is the survival of the reconstructed mammoth: ruminants rely on a symbiosis with specific microbiota in their stomachs for digestion.\n\nScientists at the University of Newcastle and University of New South Wales announced in March 2013 that the very recently extinct gastric-brooding frog would be the subject of a cloning attempt to resurrect the species.\n\nMany such \"de-extinction\" projects are described in the Long Now Foundation's Revive and Restore Project.\n\nAfter an eight-year project involving the use of a pioneering cloning technique, Japanese researchers created 25 generations of healthy cloned mice with normal lifespans, demonstrating that clones are not intrinsically shorter-lived than naturally born animals. Other sources have noted that the offspring of clones tend to be healthier than the original clones and indistinguishable from animals produced naturally.\n\nIn a detailed study released in 2016 and less detailed studies by others suggest that once cloned animals get past the first month or two of life they are generally healthy. However, early pregnancy loss and neonatal losses are still greater with cloning than natural conception or assisted reproduction (IVF). Current research endeavors are attempting to overcome this problem.\n\nIn an article in the 8 November 1993 article of \"Time\", cloning was portrayed in a negative way, modifying Michelangelo's \"Creation of Adam\" to depict Adam with five identical hands. \"Newsweek\"'s 10 March 1997 issue also critiqued the ethics of human cloning, and included a graphic depicting identical babies in beakers.\n\nCloning is a recurring theme in a wide variety of contemporary science fiction, ranging from action films such as \"Jurassic Park\" (1993), \"\" (1997), \"The 6th Day\" (2000), \"Resident Evil\" (2002), \"\" (2002) and \"The Island\" (2005), to comedies such as Woody Allen's 1973 film \"Sleeper\".\n\nScience fiction has used cloning, most commonly and specifically human cloning, due to the fact that it brings up controversial questions of identity. \"A Number\" is a 2002 play by English playwright Caryl Churchill which addresses the subject of human cloning and identity, especially nature and nurture. The story, set in the near future, is structured around the conflict between a father (Salter) and his sons (Bernard 1, Bernard 2, and Michael Black) – two of whom are clones of the first one. \"A Number\" was adapted by Caryl Churchill for television, in a co-production between the BBC and HBO Films.\n\nA recurring sub-theme of cloning fiction is the use of clones as a supply of organs for transplantation. The 2005 Kazuo Ishiguro novel \"Never Let Me Go\" and the 2010 film adaption are set in an alternate history in which cloned humans are created for the sole purpose of providing organ donations to naturally born humans, despite the fact that they are fully sentient and self-aware. The 2005 film \"The Island\" revolves around a similar plot, with the exception that the clones are unaware of the reason for their existence.\n\nThe use of human cloning for military purposes has also been explored in several works. \"Star Wars\" portrays human cloning in \"Clone Wars\".\n\nThe exploitation of human clones for dangerous and undesirable work was examined in the 2009 British science fiction film \"Moon\". In the futuristic novel \"Cloud Atlas\" and subsequent film, one of the story lines focuses on a genetically-engineered fabricant clone named Sonmi~451 who is one of millions raised in an artificial \"wombtank,\" destined to serve from birth. She is one of thousands of clones created for manual and emotional labor; Sonmi herself works as a server in a restaurant. She later discovers that the sole source of food for clones, called 'Soap', is manufactured from the clones themselves.\n\nCloning has been used in fiction as a way of recreating historical figures. In the 1976 Ira Levin novel \"The Boys from Brazil\" and its 1978 film adaptation, Josef Mengele uses cloning to create copies of Adolf Hitler.\n\nIn 2012, a Japanese television show named \"Bunshin\" was created. The story's main character, Mariko, is a woman studying child welfare in Hokkaido. She grew up always doubtful about the love from her mother, who looked nothing like her and who died nine years before. One day, she finds some of her mother's belongings at a relative's house, and heads to Tokyo to seek out the truth behind her birth. She later discovered that she was a clone.\n\nIn the 2013 television show \"Orphan Black\", cloning is used as a scientific study on the behavioral adaptation of the clones. In a similar vein, the book \"The Double\" by Nobel Prize winner José Saramago explores the emotional experience of a man who discovers that he is a clone.\n\n\n"}
{"id": "6911", "url": "https://en.wikipedia.org/wiki?curid=6911", "title": "Cellulose", "text": "Cellulose\n\nCellulose is an organic compound with the formula , a polysaccharide consisting of a linear chain of several hundred to many thousands of β(1→4) linked -glucose units. Cellulose is an important structural component of the primary cell wall of green plants, many forms of algae and the oomycetes. Some species of bacteria secrete it to form biofilms. Cellulose is the most abundant organic polymer on Earth. The cellulose content of cotton fiber is 90%, that of wood is 40–50%, and that of dried hemp is approximately 57%.\n\nCellulose is mainly used to produce paperboard and paper. Smaller quantities are converted into a wide variety of derivative products such as cellophane and rayon. Conversion of cellulose from energy crops into biofuels such as cellulosic ethanol is under investigation as an alternative fuel source. Cellulose for industrial use is mainly obtained from wood pulp and cotton.\n\nSome animals, particularly ruminants and termites, can digest cellulose with the help of symbiotic micro-organisms that live in their guts, such as \"Trichonympha\". In human nutrition, cellulose is a non-digestible constituent of insoluble dietary fiber, acting as a hydrophilic bulking agent for feces and potentially aiding in defecation.\n\nCellulose was discovered in 1838 by the French chemist Anselme Payen, who isolated it from plant matter and determined its chemical formula. Cellulose was used to produce the first successful thermoplastic polymer, celluloid, by Hyatt Manufacturing Company in 1870. Production of rayon (\"artificial silk\") from cellulose began in the 1890s and cellophane was invented in 1912. Hermann Staudinger determined the polymer structure of cellulose in 1920. The compound was first chemically synthesized (without the use of any biologically derived enzymes) in 1992, by Kobayashi and Shoda.\n\nCellulose has no taste, is odorless, is hydrophilic with the contact angle of 20–30 degrees, is insoluble in water and most organic solvents, is chiral and is biodegradable. It was shown to melt at 467 °C in 2016. It can be broken down chemically into its glucose units by treating it with concentrated mineral acids at high temperature.\n\nCellulose is derived from -glucose units, which condense through β(1→4)-glycosidic bonds. This linkage motif contrasts with that for α(1→4)-glycosidic bonds present in starch and glycogen. Cellulose is a straight chain polymer: unlike starch, no coiling or branching occurs, and the molecule adopts an extended and rather stiff rod-like conformation, aided by the equatorial conformation of the glucose residues. The multiple hydroxyl groups on the glucose from one chain form hydrogen bonds with oxygen atoms on the same or on a neighbor chain, holding the chains firmly together side-by-side and forming \"microfibrils\" with high tensile strength. This confers tensile strength in cell walls, where cellulose microfibrils are meshed into a polysaccharide \"matrix\".\n\nCompared to starch, cellulose is also much more crystalline. Whereas starch undergoes a crystalline to amorphous transition when heated beyond 60–70 °C in water (as in cooking), cellulose requires a temperature of 320 °C and pressure of 25 MPa to become amorphous in water.\n\nSeveral different crystalline structures of cellulose are known, corresponding to the location of hydrogen bonds between and within strands. Natural cellulose is cellulose I, with structures I and I. Cellulose produced by bacteria and algae is enriched in I while cellulose of higher plants consists mainly of I. Cellulose in regenerated cellulose fibers is cellulose II. The conversion of cellulose I to cellulose II is irreversible, suggesting that cellulose I is metastable and cellulose II is stable. With various chemical treatments it is possible to produce the structures cellulose III and cellulose IV.\n\nMany properties of cellulose depend on its chain length or degree of polymerization, the number of glucose units that make up one polymer molecule. Cellulose from wood pulp has typical chain lengths between 300 and 1700 units; cotton and other plant fibers as well as bacterial cellulose have chain lengths ranging from 800 to 10,000 units. Molecules with very small chain length resulting from the breakdown of cellulose are known as cellodextrins; in contrast to long-chain cellulose, cellodextrins are typically soluble in water and organic solvents.\n\nPlant-derived cellulose is usually found in a mixture with hemicellulose, lignin, pectin and other substances, while bacterial cellulose is quite pure, has a much higher water content and higher tensile strength due to higher chain lengths.\n\nCellulose is soluble in Schweizer's reagent, cupriethylenediamine (CED), cadmiumethylenediamine (Cadoxen), \"N\"-methylmorpholine \"N\"-oxide, and lithium chloride / dimethylacetamide. This is used in the production of regenerated celluloses (such as viscose and cellophane) from dissolving pulp. Cellulose is also soluble in many kinds of ionic liquids.\n\nCellulose consists of crystalline and amorphous regions. By treating it with strong acid, the amorphous regions can be broken up, thereby producing nanocrystalline cellulose, a novel material with many desirable properties. Recently, nanocrystalline cellulose was used as the filler phase in bio-based polymer matrices to produce nanocomposites with superior thermal and mechanical properties.\n\nGiven a cellulose-containing material, the carbohydrate portion that does not dissolve in a 17.5% solution of sodium hydroxide at 20 °C is \"α cellulose\", which is true cellulose. Acidification of the extract precipitates \"β cellulose\". The portion that dissolves in base but does not precipitate with acid is \"γ cellulose\".\n\nCellulose can be assayed using a method described by Updegraff in 1969, where the fiber is dissolved in acetic and nitric acid to remove lignin, hemicellulose, and xylosans. The resulting cellulose is allowed to react with anthrone in sulfuric acid. The resulting coloured compound is assayed spectrophotometrically at a wavelength of approximately 635 nm.\n\nIn addition, cellulose is represented by the difference between acid detergent fiber (ADF) and acid detergent lignin (ADL).\n\nLuminescent conjugated oligothiophenes can also be used to detect cellulose using fluorescence microscopy or spectrofluorometric methods.\n\nIn vascular plants cellulose is synthesized at the plasma membrane by rosette terminal complexes (RTCs). The RTCs are hexameric protein structures, approximately 25 nm in diameter, that contain the cellulose synthase enzymes that synthesise the individual cellulose chains. Each RTC floats in the cell's plasma membrane and \"spins\" a microfibril into the cell wall.\n\nRTCs contain at least three different cellulose synthases, encoded by \"CesA\" genes, in an unknown stoichiometry. Separate sets of \"CesA\" genes are involved in primary and secondary cell wall biosynthesis. There are known to be about seven subfamilies in the \"CesA\" superfamily. These cellulose synthases use UDP-glucose to form the β(1→4)-linked cellulose.\n\nCellulose synthesis requires chain initiation and elongation, and the two processes are separate.\n\"CesA\" glucosyltransferase initiates cellulose polymerization using a steroid primer, sitosterol-beta-glucoside, and UDP-glucose. Cellulose synthase utilizes UDP-D-glucose precursors to elongate the growing cellulose chain. A cellulase may function to cleave the primer from the mature chain.\n\nCellulose is also synthesised by animals, particularly in the tests of ascidians (where the cellulose was historically termed \"tunicine\") although it is also a minor component of mammalian connective tissue.\n\nCellulolysis is the process of breaking down cellulose into smaller polysaccharides called cellodextrins or completely into glucose units; this is a hydrolysis reaction. Because cellulose molecules bind strongly to each other, cellulolysis is relatively difficult compared to the breakdown of other polysaccharides. However, this process can be significantly intensified in a proper solvent, e.g. in an ionic liquid.\n\nMost mammals have limited ability to digest dietary fiber such as cellulose. Some ruminants like cows and sheep contain certain symbiotic anaerobic bacteria (like \"Cellulomonas\") in the flora of the rumen, and these bacteria produce enzymes called cellulases that help the microorganism to digest cellulose; the breakdown products are then used by the bacteria for proliferation. The bacterial mass is later digested by the ruminant in its digestive system (stomach and small intestine). Horses use cellulose in their diet by fermentation in their hindgut via symbiotic bacteria which produce cellulase to digest cellulose. Similarly, some termites contain in their hindguts certain flagellate protozoa producing such enzymes, whereas others contain bacteria or may produce cellulase.\n\nThe enzymes used to cleave the glycosidic linkage in cellulose are glycoside hydrolases including endo-acting cellulases and exo-acting glucosidases. Such enzymes are usually secreted as part of multienzyme complexes that may include dockerins and carbohydrate-binding modules.\n\nAt temperatures above 350 °C, cellulose undergoes thermolysis (also called ‘pyrolysis’), decomposing into solid char, vapors, aerosols, and gases such as carbon dioxide. Maximum yield of vapors which condense to a liquid called \"bio-oil\" is obtained at 500 °C.\n\nSemi-crystalline cellulose polymers react at pyrolysis temperatures (350–600 °C) in a few seconds; this transformation has been shown to occur via a solid-to-liquid-to-vapor transition, with the liquid (called \"intermediate liquid cellulose\" or \"molten cellulose\") existing for only a fraction of a second. Glycosidic bond cleavage produces short cellulose chains of two-to-seven monomers comprising the melt. Vapor bubbling of intermediate liquid cellulose produces aerosols, which consist of short chain anhydro-oligomers derived from the melt.\n\nContinuing decomposition of molten cellulose produces volatile compounds including levoglucosan, furans, pyrans, light oxygenates and gases via primary reactions. Within thick cellulose samples, volatile compounds such as levoglucosan undergo ‘secondary reactions’ to volatile products including pyrans and light oxygenates such as glycolaldehyde.\n\nHemicellulose is a polysaccharide related to cellulose that comprises about 20% of the biomass of most plants. In contrast to cellulose, hemicellulose is derived from several sugars in addition to glucose, especially xylose but also including mannose, galactose, rhamnose, and arabinose. Hemicellulose consists of shorter chains – between 500 and 3000 sugar units. Furthermore, hemicellulose is branched, whereas cellulose is unbranched.\n\nThe hydroxyl groups (-OH) of cellulose can be partially or fully reacted with various reagents to afford derivatives with useful properties like mainly cellulose esters and cellulose ethers (-OR). In principle, though not always in current industrial practice, cellulosic polymers are renewable resources.\n\nEster derivatives include:\n\nThe cellulose acetate and cellulose triacetate are film- and fiber-forming materials that find a variety of uses. The nitrocellulose was initially used as an explosive and was an early film forming material. With camphor, nitrocellulose gives celluloid.\n\nEther derivatives include:\n\nThe sodium carboxymethyl cellulose can be cross-linked to give the croscarmellose sodium (E468) for use as a disintegrant in pharmaceutical formulations.\n\nCellulose for industrial use is mainly obtained from wood pulp and cotton. The kraft process is used to separate cellulose from lignin, another major component of plant matter.\n\n\nMicrobial cellulose\n\n"}
{"id": "6913", "url": "https://en.wikipedia.org/wiki?curid=6913", "title": "Cortez", "text": "Cortez\n\n\n\n\n\n\n"}
{"id": "6916", "url": "https://en.wikipedia.org/wiki?curid=6916", "title": "Colony", "text": "Colony\n\nIn politics and history, a colony is a territory under the immediate political control of a state, distinct from the home territory of the sovereign. For colonies in antiquity, city-states would often found their own colonies. Some colonies were historically countries, while others were territories without definite statehood from their inception.\n\nThe metropolitan state is the state that rules the colony. In Ancient Greece, the city that founded a colony was known as the metropolis. \"Mother country\" is a reference to the metropolitan state from the point of view of citizens who live in its colony. There is a United Nations list of Non-Self-Governing Territories.\n\nUnlike a puppet state or satellite state, a colony has no independent international representation, and its top-level administration is under direct control of the metropolitan state.\n\nThe term \"informal colony\" is used by some historians to refer to a country under the \"de facto\" control of another state, although this term is often contentious.\n\nThe word \"colony\" comes from the Latin word \"colōnia\". This in turn derives from the word \"colōnus\", which means colonist but also implies a farmer. Cologne is an example of a settlement preserving this etymology. Other, less obvious settlements that began as Roman colonia include cities from Belgrade to York. A tell-tale sign of a settlement once being a Roman Colony is a city centre with a grid pattern. The terminology is taken from architectural analogy, where a column pillar is beneath the (often stylized) head capital, which is also a biological analog of the body as subservient beneath the controlling head (with 'capital' coming from the Latin word \"caput\", meaning 'head'). So colonies are not independently self-controlled, but rather are controlled from a separate entity that serves the capital function.\n\nRoman colonies first appeared when the Romans conquered neighbouring Italic peoples. These were small farming settlements that appeared when the Romans had subdued an enemy in war. A colony could take many forms, as a trade outpost or a military base in enemy territory. Its original definition as a settlement created by people migrating from a central region to an outlying one became the modern definition.\n\n\n\nThe Special Committee on Decolonization maintains the United Nations list of Non-Self-Governing Territories, which identifies areas the United Nations (though not without controversy) believes are colonies. Given that dependent territories have varying degrees of autonomy and political power in the affairs of the controlling state, there is disagreement over the classification of \"colony\".\n\n\n"}
{"id": "6918", "url": "https://en.wikipedia.org/wiki?curid=6918", "title": "Rod (optics)", "text": "Rod (optics)\n\n\"Rods\" (sometimes known as \"skyfish\", \"air rods\", or \"solar entities\") is a term used in cryptozoology, ufology, and outdoor photography to refer to elongated artifacts in the form of light-rods produced by cameras. Videos of rod-shaped objects moving quickly through the air were claimed by some ufologists and cryptozoologists to be alien life forms, \"extradimensional\" creatures, or very small UFOs. Subsequent experiments showed that these rods appear in film because of an optical illusion/collusion (especially in interlaced video recording), and are typically traces of a flying insect's wingbeats.\n\nVarious paranormal interpretations appeared in the popular culture, and one of the more outspoken proponents of rods as alien life forms is Jose Escamilla, who claims to have been the first to film them on March 19, 1994 at Roswell, New Mexico, while attempting to film a UFO. Since then, Escamilla has made additional videos and embarked on lecture tours to promote his claims.\n\nThe Straight Dope columnist Cecil Adams called rods a hoax \"where unscrupulous people are exploiting a gullible public for profit\", and said that investigators have shown that rods are mere tricks of light which result from how images (primarily video images) of flying insects are recorded and played back. In particular, the fast passage before the camera of an insect flapping its wings has been shown to produce rodlike effects, due to motion blur, if the camera is shooting with relatively long exposure times.\n\nIn August 2005, China Central Television (CCTV) aired a two-part documentary about flying rods in China. It reported the events from May to June of the same year at Tonghua Zhenguo Pharmaceutical Company in Tonghua City, Jilin Province, which debunked the flying rods. Surveillance cameras in the facility's compound captured video footage of flying rods identical to those shown in Jose Escamilla's video. Getting no satisfactory answer to the phenomenon, curious scientists at the facility decided that they would try to solve the mystery by attempting to catch these airborne creatures. Huge nets were set up and the same surveillance cameras then captured images of rods flying into the trap. When the nets were inspected, the \"rods\" were no more than regular moths and other ordinary flying insects. Subsequent investigations proved that the appearance of flying rods on video was an optical illusion created by the slower recording speed of the camera.\n\nAfter attending a lecture by Jose Escamilla, UFO investigator Robert Sheaffer wrote that \"some of his “rods” were obviously insects zipping across the field at a high angular rate\" and others appeared to be “appendages” which were birds' wings blurred by the camera exposure.\n\n\n"}
{"id": "6920", "url": "https://en.wikipedia.org/wiki?curid=6920", "title": "Column", "text": "Column\n\nA column or pillar in architecture and structural engineering is a structural element that transmits, through compression, the weight of the structure above to other structural elements below. In other words, a column is a compression member. The term column applies especially to a large round support (the \"shaft\" of the column) with a capital and a \"base\" or pedestal and made of stone, or appearing to be so. A small wooden or metal support is typically called a post, and supports with a rectangular or other non-round section are usually called piers. For the purpose of wind or earthquake engineering, columns may be designed to resist lateral forces. Other compression members are often termed \"columns\" because of the similar stress conditions. Columns are frequently used to support beams or arches on which the upper parts of walls or ceilings rest. In architecture, \"column\" refers to such a structural element that also has certain proportional and decorative features. A column might also be a decorative element not needed for structural purposes; many columns are \"engaged\", that is to say form part of a wall.\n\nAll significant Iron Age civilizations of the Near East and Mediterranean made some use of columns. In Ancient Egyptian architecture as early as 2600 BC the architect Imhotep made use of stone columns whose surface was carved to reflect the organic form of bundled reeds; in later Egyptian architecture faceted cylinders were also common. Egyptian columns are famously present in the Great Hypostyle Hall of Karnak (ca. 1224 BC), where 134 columns are lined up in 16 rows, with some columns reaching heights of 24 metres.\n\nSome of the most elaborate columns in the ancient world were those of the Persians, especially the massive stone columns erected in Persepolis. They included double-bull structures in their capitals. The Hall of Hundred Columns at Persepolis, measuring 70 × 70 metres, was built by the Achaemenid king Darius I (524–486 BC). Many of the ancient Persian columns are standing, some being more than 30 metres tall.\nThe Minoans used whole tree-trunks, usually turned upside down in order to prevent re-growth, stood on a base set in the stylobate (floor base) and topped by a simple round capital. These were then painted as in the most famous Minoan palace of Knossos. The Minoans employed columns to create large open-plan spaces, light-wells and as a focal point for religious rituals. These traditions were continued by the later Mycenaean civilization, particularly in the megaron or hall at the heart of their palaces. The importance of columns and their reference to palaces and therefore authority is evidenced in their use in heraldic motifs such as the famous lion-gate of Mycenae where two lions stand each side of a column. Being made of wood these early columns have not survived, but their stone bases have and through these we may see their use and arrangement in these palace buildings.\n\nThe Egyptians, Persians and other civilizations mostly used columns for the practical purpose of holding up the roof inside a building, preferring outside walls to be decorated with reliefs or painting, but the Ancient Greeks, followed by the Romans, loved to use them on the outside as well, and the extensive use of columns on the interior and exterior of buildings is one of the most characteristic features of classical architecture, in buildings like the Parthenon. The Greeks developed the classical orders of architecture, which are most easily distinguished by the form of the column and its various elements. Their Doric, Ionic, and Corinthian orders were expanded by the Romans to include the Tuscan and Composite orders (see below).\n\nColumns, or at least large structural exterior ones, became much less significant in the architecture of the Middle Ages. The classical forms were abandoned in both Byzantine architecture and the Romanesque and Gothic architecture or Europe in favour of more flexible forms, with capitals often using various types of foliage decoration, and in the West scenes with figures carved in relief. Renaissance architecture was keen to revive the classical vocabulary and styles, and the informed use and variation of the classical orders remained fundamental to the training of architects throughout Baroque, Rococo and Neo-classical architecture.\n\nEarly columns were constructed of stone, some out of a single piece of stone. Monolithic columns are among the heaviest stones used in architecture. Other stone columns are created out of multiple sections of stone, mortared or dry-fit together. In many classical sites, sectioned columns were carved with a centre hole or depression so that they could be pegged together, using stone or metal pins. The design of most classical columns incorporates entasis (the inclusion of a slight outward curve in the sides) plus a reduction in diameter along the height of the column, so that the top is as little as 83% of the bottom diameter. This reduction mimics the parallax effects which the eye expects to see, and tends to make columns look taller and straighter than they are while entasis adds to that effect.\n\nMost classical columns arise from a basis, or base, that rests on the stylobate, or foundation, except for those of the Doric order, which usually rest directly on the stylobate. The basis may consist of several elements, beginning with a wide, square slab known as a plinth. The simplest bases consist of the plinth alone, sometimes separated from the column by a convex circular cushion known as a torus. More elaborate bases include two toruses, separated by a concave section or channel known as a scotia or trochilus. Scotiae could also occur in pairs, separated by a convex section called an astragal, or bead, narrower than a torus. Sometimes these sections were accompanied by still narrower convex sections, known as annulets or fillets.\n\nAt the top of the shaft is a capital, upon which the roof or other architectural elements rest. In the case of Doric columns, the capital usually consists of a round, tapering cushion, or echinus, supporting a square slab, known as an abax or abacus. Ionic capitals feature a pair of volutes, or scrolls, while Corinthian capitals are decorated with reliefs in the form of acanthus leaves. Either type of capital could be accompanied by the same moldings as the base. In the case of free-standing columns, the decorative elements atop the shaft are known as a finial.\n\nModern columns may be constructed out of steel, poured or precast concrete, or brick, left bare or clad in an architectural covering, or veneer. Used to support an arch, an impost, or pier, is the topmost member of a column. The bottom-most part of the arch, called the springing, rests on the impost.\n\nAs the axial load on a perfectly straight slender column with elastic material properties is increased in magnitude, this ideal column passes through three states: stable equilibrium, neutral equilibrium, and instability. The straight column under load is in stable equilibrium if a lateral force, applied between the two ends of the column, produces a small lateral deflection which disappears and the column returns to its straight form when the lateral force is removed. If the column load is gradually increased, a condition is reached in which the straight form of equilibrium becomes so-called neutral equilibrium, and a small lateral force will produce a deflection that does not disappear and the column remains in this slightly bent form when the lateral force is removed. The load at which neutral equilibrium of a column is reached is called the critical or buckling load. The state of instability is reached when a slight increase of the column load causes uncontrollably growing lateral deflections leading to complete collapse.\n\nFor an axially loaded straight column with any end support conditions, the equation of static equilibrium, in the form of a differential equation, can be solved for the deflected shape and critical load of the column. With hinged, fixed or free end support conditions the deflected shape in neutral equilibrium of an initially straight column with uniform cross section throughout its length always follows a partial or composite sinusoidal curve shape, and the critical load is given by\n\nformula_1\nwhere \"r\" = radius of gyration of [column]cross-section which is equal to the square root of (I/A), \"K\" = ratio of the longest half sine wave to the actual column length, and \"KL\" = effective length (length of an equivalent hinged-hinged column). From Equation (2) it can be noted that the buckling strength of a column is inversely proportional to the square of its length.\n\nWhen the critical stress, \"F\" (\"F\" =\"P\"/\"A\", where \"A\" = cross-sectional area of the column), is greater than the proportional limit of the material, the column is experiencing inelastic buckling. Since at this stress the slope of the material's stress-strain curve, \"E\" (called the tangent modulus), is smaller than that below the proportional limit, the critical load at inelastic buckling is reduced. More complex formulas and procedures apply for such cases, but in its simplest form the critical buckling load formula is given as Equation (3),\n\nformula_2\n\nwhere \"E\" = tangent modulus at the stress \"F\"\n\nA column with a cross section that lacks symmetry may suffer torsional buckling (sudden twisting) before, or in combination with, lateral buckling. The presence of the twisting deformations renders both theoretical analyses and practical designs rather complex.\n\nEccentricity of the load, or imperfections such as initial crookedness, decreases column strength. If the axial load on the column is not concentric, that is, its line of action is not precisely coincident with the centroidal axis of the column, the column is characterized as eccentrically loaded. The eccentricity of the load, or an initial curvature, subjects the column to immediate bending. The increased stresses due to the combined axial-plus-flexural stresses result in a reduced load-carrying ability.\n\nColumn elements are considered to be massive if minimal side dimension is equal or more than 400 mm. Massive columns have ability to increase concrete strength during long time period (even during exploitation period). Taking into account possible loads onto structure increase in future (and even threat of progressive failure, terroristic attacks, explosions etc.) massive columns have advantage comparing with not ones. A little economy today has no sense as usual for future. Moreover, relatively small sections are not technological for reinforced structures during their production. Balance between economy, mass of structures and so called \"sustainable\" construction is necessary.\n\nWhen a column is too long to be built or transported in one piece, it has to be extended or spliced at the construction site. A reinforced concrete column is extended by having the steel reinforcing bars protrude a few inches or feet above the top of the concrete, then placing the next level of reinforcing bars to overlap, and pouring the concrete of the next level. A steel column is extended by welding or bolting splice plates on the flanges and webs or walls of the columns to provide a few inches or feet of load transfer from the upper to the lower column section. A timber column is usually extended by the use of a steel tube or wrapped-around sheet-metal plate bolted onto the two connecting timber sections.\n\nA column that carries the load down to a foundation must have means to transfer the load without overstressing the foundation material. Reinforced concrete and masonry columns are generally built directly on top of concrete foundations. When seated on a concrete foundation, a steel column must have a base plate to spread the load over a larger area, and thereby reduce the bearing pressure. The base plate is a thick, rectangular steel plate usually welded to the bottom end of the column.\n\nThe Roman author Vitruvius, relying on the writings (now lost) of Greek authors, tells us that the ancient Greeks believed that their Doric order developed from techniques for building in wood. The earlier smoothed tree-trunk was replaced by a stone cylinder.\n\nThe Doric order is the oldest and simplest of the classical orders. It is composed of a vertical cylinder that is wider at the bottom. It generally has neither a base nor a detailed capital. It is instead often topped with an inverted frustum of a shallow cone or a cylindrical band of carvings. It is often referred to as the masculine order because it is represented in the bottom level of the Colosseum and the Parthenon, and was therefore considered to be able to hold more weight. The height-to-thickness ratio is about 8:1. The shaft of a Doric Column is almost always fluted.\n\nThe Greek Doric, developed in the western Dorian region of Greece, is the heaviest and most massive of the orders. It rises from the stylobate without any base; it is from four to six times as tall as its diameter; it has twenty broad flutes; the capital consists simply of a banded necking swelling out into a smooth echinus, which carries a flat square abacus; the Doric entablature is also the heaviest, being about one-fourth the height column. The Greek Doric order was not used after c. 100 B.C. until its “rediscovery” in the mid-eighteenth century.\nThe Tuscan order, also known as Roman Doric, is also a simple design, the base and capital both being series of cylindrical disks of alternating diameter. The shaft is almost never fluted. The proportions vary, but are generally similar to Doric columns. Height to width ratio is about 7:1.\n\nThe Ionic column is considerably more complex than the Doric or Tuscan. It usually has a base and the shaft is often fluted (it has grooves carved up its length). The capital features a volute, an ornament shaped like a scroll, at the four corners. The height-to-thickness ratio is around 9:1. Due to the more refined proportions and scroll capitals, the Ionic column is sometimes associated with academic buildings. Ionic style columns were used on the second level of the Colosseum.\n\nThe Corinthian order is named for the Greek city-state of Corinth, to which it was connected in the period. However, according to the architectural historian Vitruvius, the column was created by the sculptor Callimachus, probably an Athenian, who drew acanthus leaves growing around a votive basket. In fact, the oldest known Corinthian capital was found in Bassae, dated at 427 BC. It is sometimes called the feminine order because it is on the top level of the Colosseum and holding up the least weight, and also has the slenderest ratio of thickness to height. Height to width ratio is about 10:1.\n\nThe Composite order draws its name from the capital being a composite of the Ionic and Corinthian capitals. The acanthus of the Corinthian column already has a scroll-like element, so the distinction is sometimes subtle. Generally the Composite is similar to the Corinthian in proportion and employment, often in the upper tiers of colonnades. Height to width ratio is about 11:1 or 12:1.\n\nA Solomonic column, sometimes called \"barley sugar\", begins on a base and ends in a capital, which may be of any order, but the shaft twists in a tight spiral, producing a dramatic, serpentine effect of movement. Solomonic columns were developed in the ancient world, but remained rare there. A famous marble set, probably 2nd century, was brought to St Peter's, Rome by Constantine I, and placed round the saint's shrine, and was thus familiar throughout the Middle Ages, by which time they were thought to have been removed from the Temple of Jerusalem. The style was used in bronze by Bernini for his spectacular St. Peter's baldachin, actually a ciborium (which displaced Constantine's columns), and thereafter became very popular with Baroque and Rococo church architects, above all in Latin America, where they were very often used, especially on a small scale, as they are easy to produce in wood by turning on a lathe (hence also the style's popularity for spindles on furniture and stairs).\n\nPillar tombs are monumental graves, which typically feature a single, prominent pillar or column, often made of stone. A number of world cultures incorporated pillars into tomb structures. In the Ancient Greek colony of Lycia in Anatolia, one of these edifices is located at the tomb of Xanthos. In the town of Hannassa in southern Somalia, ruins of houses with archways and courtyards have also been found along with other pillar tombs, including a rare octagonal tomb.\n\n"}
{"id": "6921", "url": "https://en.wikipedia.org/wiki?curid=6921", "title": "Carmilla", "text": "Carmilla\n\nCarmilla is a Gothic novella by Joseph Sheridan Le Fanu and one of the early works of vampire fiction, predating Bram Stoker's \"Dracula\" (1897) by 26 years. First published as a serial in \"The Dark Blue\" (1871–72), the story is narrated by a young woman preyed upon by a female vampire named Carmilla, later revealed to be Mircalla, Countess Karnstein (Carmilla is an anagram of Mircalla). The story is often anthologized and has been adapted many times in film and other media.\n\n\"Carmilla,\" serialized in the literary magazine \"The Dark Blue\" in late 1871 and early 1872, was reprinted in Le Fanu's short story collection \"In a Glass Darkly\" (1872). Comparing the work of the two illustrators, David Henry Friston and Michael Fitzgerald, whose work appears in the magazine but not in modern printings of the book, reveals inconsistencies in the characters' depictions. Consequently, confusion has arisen relating the pictures to the plot. Isabella Mazzanti illustrated the book's 2014 anniversary edition, published by Editions Soleil and translated by Gaid Girard.\n\nLe Fanu presents the story as part of the casebook of Dr. Hesselius, whose departures from medical orthodoxy rank him as the first occult doctor in literature.\n\nLaura, the protagonist, narrates, beginning with her childhood in a \"picturesque and solitary\" castle amid an extensive forest in Styria, where she lives with her father, a wealthy English widower retired from service to the Austrian Empire. When she was six, Laura had a vision of a beautiful visitor in her bedchamber. She later claims to have been punctured in her breast, although no wound was found.\n\nTwelve years later, Laura and her father are admiring the sunset in front of the castle when her father tells her of a letter from his friend, General Spielsdorf. The General was supposed to bring his niece, Bertha Rheinfeldt, to visit the two, but the niece suddenly died under mysterious circumstances. The General ambiguously concludes that he will discuss the circumstances in detail when they meet later.\n\nLaura, saddened by the loss of a potential friend, longs for a companion. A carriage accident outside Laura's home unexpectedly brings a girl of Laura's age into the family's care. Her name is Carmilla. Both girls instantly recognize the other from the \"dream\" they both had when they were young.\n\nCarmilla appears injured after her carriage accident, but her mysterious mother informs Laura's father that her journey is urgent and cannot be delayed. She arranges to leave her daughter with Laura and her father until she can return in three months. Before she leaves, she sternly notes that her daughter will not disclose any information whatsoever about her family, past, or herself, and that Carmilla is of sound mind. Laura comments that this information seems needless to say, and her father laughs it off.\n\nCarmilla and Laura grow to be very close friends, but occasionally Carmilla's mood abruptly changes. She sometimes makes romantic advances towards Laura. Carmilla refuses to tell anything about herself, despite questioning by Laura. Her secrecy is not the only mysterious thing about Carmilla; she never joins the household in its prayers, she sleeps much of the day, and she seems to sleepwalk outside at night.\n\nMeanwhile, young women and girls in the nearby towns have begun dying from an unknown malady. When the funeral procession of one such victim passes by the two girls, Laura joins in the funeral hymn. Carmilla bursts out in rage and scolds Laura, complaining that the hymn hurts her ears.\n\nWhen a shipment of restored heirloom paintings arrives, Laura finds a portrait of her ancestor, Mircalla, Countess Karnstein, dated 1698. The portrait resembles Carmilla exactly, down to the mole on her neck. Carmilla says she might be descended from the Karnsteins even though the family died out centuries before.\n\nDuring Carmilla's stay, Laura has nightmares of a large cat-like beast entering her room and biting her on the chest. The beast then takes the form of a female figure and disappears through the door without opening it. In another nightmare, Laura hears a voice say, \"Your mother warns you to beware of the assassin,\" and a sudden light reveals Carmilla standing at the foot of her bed, her nightdress drenched in blood. Laura's health declines, and her father has a doctor examine her. He finds a small blue spot on her chest and speaks privately with her father, only asking that Laura never be unattended.\n\nHer father then sets out with Laura, in a carriage, for the ruined village of Karnstein, three miles distant. They leave a message behind asking Carmilla and one of the governesses to follow once the perpetually late-sleeping Carmilla wakes. En route to Karnstein, Laura and her father encounter General Spielsdorf. He tells them his own ghastly story.\n\nAt a costume ball, Spielsdorf and his niece Bertha had met a young woman named Millarca and her enigmatic mother. Bertha was immediately taken with Millarca. The mother convinced the General that she was an old friend of his and asked that Millarca be allowed to stay with them for three weeks while she attended to a secret matter of great importance.\n\nBertha fell mysteriously ill, suffering the same symptoms as Laura. After consulting with a specially ordered priestly doctor, the General realized that Bertha was being visited by a vampire. He hid with a sword and waited until a large black creature crawled onto his niece's bed and to her neck. He leapt from his hiding place and attacked the beast, which took the form of Millarca. She fled through the locked door, unharmed. Bertha died immediately afterward.\n\nUpon arriving at Karnstein, the General asks a woodman where he can find the tomb of Mircalla Karnstein. The woodman says the tomb was relocated long ago by the hero who vanquished the vampires that haunted the region.\n\nWhile the General and Laura are alone in the ruined chapel, Carmilla appears. The General and Carmilla both fly into a rage upon seeing each other, and the General attacks her with an axe. Carmilla disarms the General and disappears. The General explains that Carmilla is also Millarca, both anagrams for the original name of the vampire Mircalla, Countess Karnstein.\n\nThe party is joined by Baron Vordenburg, the descendant of the hero who rid the area of vampires long ago. Vordenburg, an authority on vampires, has discovered that his ancestor was romantically involved with the Countess Karnstein before she died and became one of the undead. Using his forefather's notes, he locates Mircalla's hidden tomb. An Imperial Commission exhumes the vampire's body. Immersed in blood, it seems to be breathing faintly, its heart beating, its eyes open. A stake is driven through its heart, and it gives a corresponding shriek; then the head is struck off. The body and head are burned to ashes, which are thrown into a river.\n\nAfterwards, Laura's father takes his daughter on a year-long tour through Italy to recover from the trauma and regain her health, which she never fully does.\n\nAs with \"Dracula\", critics have looked for the sources used in the writing of \"Carmilla\". One source used was from a dissertation on magic, vampires and the apparitions of spirits written by Dom Augustin Calmet's titled \"Traité sur les apparitions des esprits et sur les vampires ou les revenans de Hongrie, de Moravie, &c.\" (1751). This is evidenced by a report analyzed by Calmet, from a priest who learned information of a town being tormented by a vampiric entity 3 years earlier. Having traveled to the town to investigate and collecting information of the various inhabitants there, the priest learned that a vampire had tormented many of the inhabitants at night by coming from the nearby cemetery and would haunt many of the residents on their beds. An unknown Hungarian traveler came to the town during this period and helped the town by setting a trap at the cemetery and decapitating the vampire that resided there, curing the town of their torment. This story was retold by LeFanu and adapted into the thirteenth chapter of Carmilla \n\nAccording to Matthew Gibson, the Reverend Sabine Baring-Gould's \"The Book of Were-wolves\" (1863) and his account of Elizabeth Báthory, Coleridge's \"Christabel\" (Part 1, 1797 and Part 2, 1800), and Captain Basil Hall's \"Schloss Hainfeld; or a Winter in Lower Styria\" (London and Edinburgh, 1836) are other sources for Le Fanu's \"Carmilla\". Hall's account provides much of the Styrian background and, in particular, a model for both Carmilla and Laura in the figure of Jane Anne Cranstoun, Countess Purgstall.\n\nCarmilla, the title character, is the original prototype for a legion of female and lesbian vampires. Though Le Fanu portrays his vampire's sexuality with the circumspection that one would expect for his time, it is evident that lesbian attraction is the main dynamic between Carmilla and the narrator of the story:\n\nWhen compared to other literary vampires of the 19th century, Carmilla is a similar product of a culture with strict sexual mores and tangible religious fear. While Carmilla selected exclusively female victims, she only becomes emotionally involved with a few. Carmilla had nocturnal habits, but was not confined to the darkness. She had unearthly beauty, and was able to change her form and to pass through solid walls. Her animal alter ego was a monstrous black cat, not a large dog as in \"Dracula\". She did, however, sleep in a coffin. \"Carmilla\" works as a Gothic horror story because her victims are portrayed as succumbing to a perverse and unholy temptation that has severe metaphysical consequences for them.\n\nSome critics, among them William Veeder, suggest that \"Carmilla\", notably in its outlandish use of narrative frames, was an important influence on Henry James' \"The Turn of the Screw\" (1898).\n\nAlthough \"Carmilla\" is a lesser known and far shorter Gothic vampire story than the generally considered master work of that genre, \"Dracula\", the latter is heavily influenced by Le Fanu's novella. Stoker's posthumously published short story \"Dracula's Guest\" (1914), known as the deleted first chapter to \"Dracula\", shows a more obvious and intact debt to \"Carmilla\":\n\n\n\n\n\n\n\n\n(Chronological) \n\n\n\n\n\n"}
{"id": "6922", "url": "https://en.wikipedia.org/wiki?curid=6922", "title": "Clitoridectomy", "text": "Clitoridectomy\n\nClitoridectomy or clitorectomy is the surgical removal, reduction, or partial removal of the clitoris. It is rarely used as a therapeutic medical procedure, such as when cancer has developed in or spread to the clitoris. It is often performed on intersex newborns. Commonly, non-medical removal of the clitoris is performed during female genital mutilation (FGM). \n\nA clitoridectomy is often done to remove malignancy or necrosis of the clitoris. This is sometimes done along with a radical complete vulvectomy. Surgery may also become necessary due to therapeutic radiation treatments to the pelvic area.\n\nFemale infants born with a 46,XX genotype but have genitalia affected by congenital adrenal hyperplasia and are treated surgically with vaginoplasty that often reduces the size of the clitoris without its total removal. The atypical size of the clitoris is due to an endocrine imbalance in utero. This treatment raises human rights concerns, see below. Other reasons for the surgery include issues involving a microphallus and those who have Mayer-Rokitansky-Kustner disorder. Removal of the clitoris may be due to malignancy or trauma.\n\nCloridectomy surgical techniques are used to remove invasive malignancy that extends to the clitoris. Standard surgical procedures are followed in these cases. This includes evaluation including biopsy. Other factors that will effect the technique selected are age, other existing medical conditions, and obesity. Other considerations are the probability of extended hospital care and the development of infection at the surgical site.\nThe surgery proceeds with the use of general anethesia, and prior to the vulvectomy/cloridectomy an inguinal lymphyadenectomy is first done. The extent of the surgical site extends one to two centimeters beyond the boundaries of malignancy. Superficial lymph nodes may also need to be removed. If the malignancy is present in muscular tissue in the region, it is also removed. In some cases, the surgeon is able to preserve the clitoris though the malignancy may be extensive. The cancerous tissue is removed and the incision is closed.\n\nPost operative care may employ the use of suction drainage to allow the deeper tissues to heal toward the surface. Follow up after surgery includes the stripping of the drainage device to prevent blockage. A typical hospital stay can be up to two weeks. The site of the surgery is left unbandaged to allow for frequent examination.\nComplications can be the development of lymphedema though not removing the saphenous vein during the surgery will help prevent this. In some instances, foot elevation, diuretic medication and compression stockings can reduce the build up of fluid.\n\nIn a clitoridectomy for intersex infants, the clitoris is often reduced instead of removed. The surgeon cuts the shaft of the elongated phallus and sews the glans and preserved nerves back onto the stump. In a less common surgery called clitoral recession, the surgeon hides the clitoral shaft under a fold of skin so only the glans remains visible.\n\nIn the 19th century, a clitoridectomy was thought to curb female masturbation. Isaac Baker Brown (1812–1873), an English gynaecologist who was president of the Medical Society of London believed that the \"unnatural irritation\" of the clitoris caused epilepsy, hysteria, and mania, and he worked \"to remove [it] whenever he had the opportunity of doing so\", according to his obituary in the \"Medical Times and Gazette\". Peter Lewis Allen writes that Brown's views caused outrage, and he died penniless after being expelled from the Obstetrical Society.\n\nFor a time female circumcision was done as a cure for insanity. Some practitioners of medicine in the Victorian era believed that mental and emotional disorders were related to female reproductive organs. Some thought that removing the clitoris would cure the neurosis. This treatment was discontinued in 1867.\n\nAesthetics may determine clitoral norms. A lack of ambiguity of the genitalia is seen as necessary in the assignment of a sex to infants and therefore whether a child's genitalia is normal, but what is ambiguous or normal can vary from person to person.\n\nSexual behavior is another reason for clitoridectomies. Author Sarah Rodriguez stated that the history of medical textbooks has indirectly created accepted ideas about the female body. Medical and gynecological textbooks are also at fault in the way that the clitoris is described in comparison to a male's penis. The importance and originality of a female's clitoris is underscored because it is seen as \"a less significant organ, since anatomy texts compared the penis and the clitoris in only one direction.\" Rodriguez said that a male's penis created the framework of the sexual organ.\n\nClitoridectomies are the most common form of female genital mutilation. The World Health Organization (WHO) estimates that clitordectomies have been performed on 200 million girls and women that are currently alive. The regions that most clitodectomies take place are Asia, the Middle East and west, north and east Africa. The practice also exists in migrants originating from these regions. Most of the surgeries are for cultural or religious reasons.\n\nClitoridectomy of women with intersex conditions is controversial when it takes place during childhood or under duress. Intersex women exposed to such treatment have spoken of their loss of physical sensation, and loss of autonomy. In recent years, multiple human rights institutions have criticized early surgical management of such characteristics.\n\nIn 2013, it was disclosed in a medical journal that four unnamed elite female athletes from developing countries were subjected to gonadectomies and partial clitoridectomies after testosterone testing revealed that they had an intersex condition. In April 2016, the United Nations Special Rapporteur on health, Dainius Pūras, condemned this treatment as a form of female genital mutilation \"in the absence of symptoms or health issues warranting those procedures.\"\n\n\n"}
{"id": "6924", "url": "https://en.wikipedia.org/wiki?curid=6924", "title": "Cabal", "text": "Cabal\n\nA cabal is a group of people united in some close design together, usually to promote their private views or interests in an ideology, state, or other community, often by , usually unbeknown to persons outside their group. The use of this term usually carries strong connotations of shadowy corners, back rooms and insidious influence. The term is frequently used in conspiracy theories; some Masonic theories describe Freemasonry as an internationalist secret cabal.\n\nThe term \"cabal\" derives from Cabala (a word that has numerous spelling variations), the Jewish mystical interpretation of the Hebrew scripture. In Hebrew it means \"reception\" or \"tradition\", denoting the \"sod\" (secret) level of Jewish exegesis. In European culture (Christian Cabala, Hermetic Qabalah) it became associated with occult doctrine or a secret.\n\nThe term took on its present meaning from a group of ministers of King Charles II of England (Sir Thomas Clifford, Lord Arlington, the Duke of Buckingham, Lord Ashley, and Lord Lauderdale), whose initial letters coincidentally spelled CABAL, and who were the signatories of the Secret Treaty of Dover that allied England to France in a prospective war against the Netherlands. However, the Cabal Ministry they formed can hardly be seen as such; the Scot Lauderdale was not much involved in English governance at all, while the Catholic ministers of the Cabal (Clifford and Arlington) were never much in sympathy with the Protestants (Buckingham and Ashley). Nor did Buckingham and Ashley get on very well with each other. Thus the \"Cabal Ministry\" never really unified in its members' aims and sympathies, and fell apart by 1672; Lord Ashley, who became Earl of Shaftesbury, later became one of Charles II's fiercest opponents. The theory that the word originated as an acronym from the names of the group of ministers is a folk etymology, although the coincidence was noted at the time and could possibly have popularized its use. The group, who came to prominence after the fall of Charles' first Chief Minister, Lord Clarendon, in 1667, was rather called the Cabal because of its secretiveness and lack of responsibility to the \"Country party\" then run out of power.\n\nDuring the early years of the Usenet internet messaging system, the term \"backbone cabal\" was used as a semi-ironic description of the efforts of people to maintain some order over the structure of the community, and led to a popular phrase in the network, \"There Is No Cabal\" (abbreviated to \"TINC\").\n\nThe computer game company Valve Corporation uses \"Cabal Rooms\" when working on specific areas of projects.\n\nThe Conficker Cabal is a team of specialists working to defeat the Conficker computer worm, including several notable computer security specialists.\n\nIn Haskell programming language there is a package manager called \"cabal\", used to download and build Haskell libraries.\n"}
{"id": "6925", "url": "https://en.wikipedia.org/wiki?curid=6925", "title": "Cytochrome", "text": "Cytochrome\n\nCytochromes are iron containing hemeproteins central to which are heme groups that are primarily responsible for the generation of ATP via electron transport.\n\nThey are found either as monomeric proteins (e.g., cytochrome c) or as subunits of larger enzymatic complexes that catalyze redox reactions.\n\nCytochromes were initially described in 1884 by MacMunn as respiratory pigments (myohematin or histohematin). In the 1920s, Keilin rediscovered these respiratory pigments and named them the cytochromes, or “cellular pigments”, and classified these heme proteins, on the basis of the position of their lowest energy absorption band in the reduced state, as\ncytochromes \"a\" (605 nm), \"b\" (~565 nm), and \"c\" (550 nm). The ultra-violet (UV) to visible spectroscopic signatures of hemes are still used to identify heme type from the reduced bis-pyridine-ligated state, i.e., the pyridine hemochrome method. Within each class, cytochrome \"a\", \"b\", or \"c\", early cytochromes are numbered consecutively, e.g. cyt \"c\", cyt \"c\", and cyt \"c\", with more recent examples designated by their reduced state R-band maximum, e.g. cyt \"c\".\n\nThe heme group is a highly conjugated ring system (which allows its electrons to be very mobile) surrounding a metal ion, which readily interconverts between the oxidation states. For many cytochromes, the metal ion present is that of \"iron\", which interconverts between Fe (reduced) and Fe (oxidized) states (electron-transfer processes). Cytochromes are, thus, capable of performing oxidation and reduction. Because the cytochromes (as well as other complexes) are held within membranes in an organized way, the redox reactions are carried out in the proper sequence for maximum efficiency.\n\nIn the process of oxidative phosphorylation, which is the principal energy-generating process undertaken by organisms, other membrane-bound and -soluble complexes and cofactors are involved in the chain of redox reactions, with the additional net effect that protons (H) are transported across the mitochondrial inner membrane. The resulting transmembrane proton gradient (protonmotive force) is used to generate ATP, which is the universal chemical energy currency of life. ATP is consumed to drive cellular processes that require energy (such as synthesis of macromolecules, active transport of molecules across the membrane, and assembly of flagella).\n\nSeveral kinds of cytochrome exist and can be distinguished by spectroscopy, exact structure of the heme group, inhibitor sensitivity, and reduction potential.\n\nThree types of cytochrome are distinguished by their prosthetic groups:\n\nThe definition of cytochrome c is not defined in terms of the heme group. There is no \"cytochrome e,\" but there is a cytochrome f, which is often considered a type of cytochrome c.\n\nIn mitochondria and chloroplasts, these cytochromes are often combined in electron transport and related metabolic pathways:\n\nA completely distinct family of CCox is known as the cytochrome P450 oxidases, so named for the characteristic Soret peak formed by absorbance of light at wavelengths near 450 nm when the heme iron is reduced (with sodium dithionite) and complexed to carbon monoxide. These enzymes are primarily involved in steroidogenesis and detoxification.\n\n"}
{"id": "6927", "url": "https://en.wikipedia.org/wiki?curid=6927", "title": "Crowded House", "text": "Crowded House\n\nCrowded House is a rock band formed in Melbourne, Australia, in 1985. The founding members were New Zealander Neil Finn (vocalist, guitarist, primary songwriter) and Australians Paul Hester (drums) and Nick Seymour (bass). Later band members included Neil Finn's brother, Tim Finn, and Americans Mark Hart and Matt Sherrod.\n\nOriginally active from 1985 to 1996, the band had consistent commercial and critical success in Australia and New Zealand and international chart success in two phases, beginning with their self-titled debut album, which reached number twelve on the US Album Chart in 1987 and provided the Top Ten hits \"Don't Dream It's Over\" and \"Something So Strong\". Further international success came in the UK, Europe and South Africa with their third and fourth albums, \"Woodface\" and \"Together Alone\" and the compilation album \"Recurring Dream\", which included the hits \"Fall at Your Feet\", \"Weather with You\", \"Distant Sun\", \"Locked Out\", \"Instinct\" and \"Not the Girl You Think You Are\". Neil and Tim Finn were each awarded an OBE in June 1993, for their contribution to the music of New Zealand.\n\nFounding drummer Hester left in May 1994 citing family reasons, but briefly returned for their \"Farewell to the World\" concerts in Melbourne and Sydney in 1996. Neil Finn had decided to end the band to concentrate on his solo career and the Finn Brothers project with Tim. On 26 March 2005 Hester died by suicide, aged 46. In 2006 the group re-formed with a new drummer Matt Sherrod and released two further albums (in 2007 and 2010), both of which reached number one on Australia's album chart. As of July 2010 the group has sold 10 million albums. In November 2016 they were inducted into the ARIA Hall of Fame.\n\nNeil Finn (vocals, guitar, piano) and drummer Paul Hester (ex-The Cheks, Deckchairs Overboard) were former members of New Zealand band Split Enz, which spent part of 1975–6 in Australia and several years in England. Neil Finn is the younger brother of Split Enz founding member Tim Finn, who joined Crowded House in 1990 on vocals, guitars and keyboards for the album \"Woodface\". Bassist Nick Seymour (ex-Plays with Marionettes, Bang, The Horla) is the younger brother of singer-songwriter and guitarist Mark Seymour of the now defunct Australian rock group Hunters & Collectors.\n\nFinn and Hester decided to form a new band during the first Split Enz farewell tour, \"Enz with a Bang\", in late 1984. Seymour approached Finn during the after party for the Melbourne show and asked if he could audition for the new band. The Mullanes formed in Melbourne in early 1985 with Finn, Hester, Seymour and guitarist Craig Hooper (ex-The Reels) and first performed on 11 June. They secured a record contract with Capitol Records, but Hooper left the band before the remaining trio moved to Los Angeles to record their debut album. At Capitol's behest, the band's name was changed to Crowded House, which alluded to the lack of space at the small Hollywood Hills house they shared during the recording of the album \"Crowded House\". Former Split Enz keyboardist Eddie Rayner produced the track \"Can't Carry On\" and was asked to join the band. He toured with them in 1988, but was unable to become a full member due to family commitments.\n\nThanks to their Split Enz connection, the newly formed Crowded House had an established Australasian fanbase. They began by playing at festivals in Australia and New Zealand and released their debut album, \"Crowded House\", in June 1986. Capitol Records initially failed to see the band's potential and gave them only low-key promotion, forcing the band to play at small venues to try and gain attention. The album's first single, \"Mean to Me\", reached the Australian Kent Music Report Singles Chart top 30 in June. It failed to chart in the US, but moderate American airplay introduced US listeners to the group.\n\nA single, \"Don't Dream It's Over\", was released in December 1986 and proved an international hit, reaching number two on the US \"Billboard\" Hot 100 and number one in Canada. New Zealand radio stations initially gave the song little support until months later when it became successful internationally. Ultimately, the song reached number one on the New Zealand singles chart and number eight in Australia. It remains the group's most commercially successful song.\n\nIn March 1987, the group were awarded \"Best New Talent\", along with \"Song of the Year\" and \"Best Video\" awards for \"Don't Dream It's Over\" at the inaugural ARIA Music Awards. The video also earned the group the MTV Video Music Award for Best New Artist that year. The song has often been covered by other artists and gave Paul Young a hit single in 1991. It was also used for a New Zealand Tourism Board advertisement in its \"100% Pure New Zealand\" worldwide promotion from October 2005. In May 2001, \"Don't Dream it's Over\" was voted seventh in a poll of the best Australian songs of all time by the Australasian Performing Rights Association.\n\nIn June 1987, a year after its release, \"Crowded House\" finally reached number one on the Kent Music Report Album Charts. It also reached number three in New Zealand and number twelve on the US Billboard album chart. The follow-up to \"Don't Dream it's Over\", \"Something So Strong\", was another global smash, reaching the Top 10 in New Zealand, America, and Canada. \"World Where You Live\" and \"Now We're Getting Somewhere\" were also released as singles with chart success.\n\nAs the band's primary songwriter, Neil Finn was under pressure to create a second album to match their debut and the band joked that one potential title for the new release was \"Mediocre Follow-Up\". Eventually titled \"Temple of Low Men\", their second album was released in July 1988 with strong promotion by Capitol Records. The album did not fare as well as their debut in the US, only reaching number 40, but it achieved Australasian success, reaching number one in Australia and number two in New Zealand. The first single \"Better Be Home Soon\" peaked at number two on both Australian and New Zealand singles charts and reached top 50 in the US, though the following four singles were less successful. Crowded House undertook a short tour of Australia and Canada to promote the album, with Eddie Rayner on keyboards. Multi-instrumentalist Mark Hart, who would eventually become a full band member, replaced Rayner in January 1989. After the tour, Finn fired Seymour from the band. Music journalist Ed Nimmervoll claimed that Seymour's temporary departure was because Finn blamed him for causing his writer's block; however, Finn cited \"artistic differences\" as the reason. Seymour said that after a month he contacted Finn and they agreed that he would return to the band.\n\nCrowded House took a break after the Canadian leg of the \"Temple of Low Men\" tour. Neil Finn and his brother Tim recorded songs they had co-written for their own album, \"Finn\". Following the recording sessions with Tim, Neil began writing and recording a third Crowded House album with Hester and Seymour, but these tracks were rejected by the record company, so Neil asked Tim if Crowded House could use the \"Finn\" songs. Tim jokingly agreed on the proviso that he become a member, which Neil apparently took literally. With Tim as an official member, the band returned to the studio. The new tracks, as well as some from the previously rejected recordings were combined to make \"Woodface\", which was released in July 1991. The album features eight tracks co-written by Neil and Tim, which feature the brothers harmonising on lead vocals, except on the sombre \"All I Ask\" on which Tim sang lead. The track was later used on AIDS awareness commercials in Australia. Five of the album's tracks were Neil's solo compositions and two were by Hester, the exuberant \"Italian Plastic\", which became a crowd favourite at concerts and the hidden track \"I'm Still Here\".\n\n\"Chocolate Cake\", a humorous comment on American excesses that was not taken well by some US critics and sections of the American public, was released in June 1991 as the first single. Perhaps unsurprisingly it failed to chart in the US, however it reached number two on Billboard's Modern Rock Tracks chart. The song peaked at number seven in New Zealand and reached the top 20 in Australia. The second single, \"Fall at Your Feet\", was less successful in Australia and New Zealand but did at least reach the US Hot 100. The album reached number one in New Zealand, number two in Australia, number six in the UK and made the top 20 in several European countries. The third single from \"Woodface\", \"Weather With You\", peaked at No. 7 in early 1992 giving the band their highest UK chart placement. By contrast, the album had limited success in the US, only reaching number 83 on the Billboard 200 Album Chart.\n\nTim Finn left Crowded House during the \"Woodface\" tour in November 1991, part-way through the UK leg. Performances on this tour, at the Town and Country Club in London, were recorded live and given a limited release in Australia, while individual songs from those shows were released as B-sides of singles in some countries. In June 1993 the New Zealand Government recommended that the Queen award an OBE to Neil and Tim Finn for their contribution to the music of New Zealand.\n\nFor their fourth album, \"Together Alone\", Crowded House used producer Martin Glover (aka \"Youth\") and invited touring musician Mark Hart (guitar and keyboards) to become a permanent band member. The album was recorded at Karekare Beach, New Zealand, which gave its name to the opening track, \"Kare Kare\". The album was released in October 1993 and sold well internationally on the strength of lead single \"Distant Sun\" and followup \"Private Universe\". It topped the New Zealand Album Chart, reached number 2 in Australia and number 4 in the UK. \"Locked Out\" was the album's first US single and received airplay on MTV and VH1. This track and \"My Sharona\" by The Knack, which were both included the soundtrack of the film \"Reality Bites\", were bundled together on a jukebox single to promote the film soundtrack.\n\nCrowded House were midway through a US tour when Paul Hester quit the band on 15 April 1994. He flew home to Melbourne to await the birth of his first child and indicated that he required more time with his family. Wally Ingram, drummer for support act Sheryl Crow, temporarily filled in until a replacement, Peter Jones (ex-Harem Scarem, Vince Jones, Kate Ceberano's Septet) was found. After the tour, the Finn Brothers released their album \"Finn\" in November 1995. In June 1996, at a press conference to announce the release of their greatest hits album \"Recurring Dream\", Neil revealed that Crowded House were to disband. The June 1996 concerts in Europe and Canada were to be their final performances.\n\n\"Recurring Dream\" contained four songs from each of the band's studio albums, along with three new songs. The album debuted at number one in Australia, New Zealand and the UK in July 1996. Early copies included a bonus CD of live material. The album's three new songs, which were released as singles, were \"Instinct\", \"Not the Girl You Think You Are\" and \"Everything Is Good for You\", which featured backing vocals from Pearl Jam's Eddie Vedder. Paul Hester returned to the band to play drums on the three new tracks.\n\nWorried that their goodbye had been too low-key and had disregarded their home fans, the band performed the \"Farewell to the World\" concert on the steps of the Sydney Opera House on 24 November 1996, which raised funds for the Sydney Children's Hospital. The concert featured the line-up of Neil Finn, Nick Seymour, Mark Hart and Paul Hester. Tim Finn and Peter Jones both made guest appearances. Support bands on the day were Custard, Powderfinger and You Am I. The concert had one of the highest live audiences in Australian history with the crowd being estimated at between 120,000 and 250,000 people. \"Farewell to the World\" was released on VHS in December 1996. In 2007, a double CD and a DVD were issued as to commemorate the concert's tenth anniversary. The DVD featured newly recorded audio commentary by Finn, Hart and Seymour and other new bonus material.\n\nFollowing the 1996 break-up of Crowded House, the members embarked upon a variety of projects. Neil Finn released two solo studio albums, \"Try Whistling This\" (1998) and \"One Nil\" (2001), as well as two live albums, \"Sessions at West 54th\" (2000) and \"7 Worlds Collide\" (2001). \"7 Worlds Collide\" saw him performing with guest musicians including Eddie Vedder, Johnny Marr, Ed O'Brien and Phil Selway of Radiohead, Tim Finn, Sebastian Steinberg, Lisa Germano and Betchadupa (featuring his son Liam Finn). A double CD and DVD of the shows were released in November 2001.\n\nTim Finn had resumed his solo career after leaving the group in 1992 and he also worked with Neil on a second Finn Brothers album, \"Everyone Is Here\", which was released in 2004. Paul Hester joined The Finn Brothers on stage for three songs at their Palais Theatre show in Melbourne at the end of 2004. Nick Seymour also joined them on stage in Dublin, where he was living, in 2004. Peter Jones and Nick Seymour joined Australian group Deadstar for their second album, \"Milk\", in 1997. Seymour later worked as a record producer in Dublin, producing Irish group Bell X1's debut album, \"Neither Am I\" in 2000. Mark Hart rejoined Supertramp in the late 1990s and later toured with Ringo Starr & His All-Starr Band. In 2001 he released a solo album, \"Nada Sonata\".\n\nPaul Hester worked with children's entertainers The Wiggles, playing \"Paul the Cook\". He also had his own ABC show \"Hessie's Shed\" in Australia from late 1997. He formed the band Largest Living Things, which was the name rejected by Capitol Records in favour of Crowded House. It was on \"Hessie's Shed\" that Finn, Hester and Seymour last shared a stage, on an episode filmed as part of Finn's promotion for his solo album \"Try Whistling This\" in 1998. Finn and Hester performed \"Not the Girl You Think You Are\" with Largest Living Things, before being joined by Seymour for \"Sister Madly\" and a version of Paul Kelly's \"Leaps and Bounds\", which also featured Kelly on vocals. In late 2003, Hester hosted the series \"Music Max's Sessions\". Hester and Seymour were reunited when they both joined singer-songwriter Matt O'Donnell's Melbourne-based group Tarmac Adam. The band released one album, 2003's \"Handheld Torch\", which was produced by Seymour.\n\nIn May 1999 Crowded House issued a compilation of unreleased songs, \"Afterglow\", which included the track \"Recurring Dream\", recorded when the group were still called The Mullanes and included Craig Hooper on guitar. The album's liner notes included information about the songs, written by music journalist David Hepworth. Some limited-release versions included a second CD with songwriting commentary by Finn. The liner notes confirmed that Crowded House had no plans to reunite at that time. A 2003 compilation album, \"Classic Masters\", was released only in the US, while 2005 saw the release of the album \"She Will Have Her Way\", a collection of cover versions of Crowded House, Split Enz, Tim Finn and Finn Brothers songs by Australasian female artists. The album reached the top 5 in Australia and New Zealand.\n\nOn 26 March 2005 Paul Hester was found dead, after hanging himself from a tree in a park near his home in Melbourne. He was 46 years old. His obituary in \"The Sydney Morning Herald\" stated that he had fought \"a long battle with depression.\" Following the news of Hester's death, Nick Seymour joined The Finn Brothers on stage at the Royal Albert Hall in London, where the three played in memory of Paul. A snare drum with a top hat on it stood at the front of the stage as a tribute. Writing in 2010 Neil Finn said, \"When we lost Paul it was like someone pulled the rug out from underneath everything, a terrible jolt out of the dark blue. He was the best drummer I had ever played with and for many years, my closest friend.\"\n\nIn 2006 Neil Finn asked Nick Seymour to play bass on his third solo album. Seymour agreed and the two joined up with producer and multi-instrumentalist Ethan Johns to begin recording. As the recording sessions progressed it was decided that the album would be issued under the Crowded House band name, rather than as a Neil Finn solo album. In January 2007, the group publicly announced their reformation and on 23 February, after 20 days of auditions, former Beck drummer Matt Sherrod joined Finn, Seymour and Mark Hart to complete the new line up. As Sherrod and Hart had not participated in the initial sessions, four new tracks were recorded with producer Steve Lillywhite including the album's first single \"Don't Stop Now\".\n\nOn 17 March 2007 the band played a live show at their rehearsal studio in front of around fifty fans, friends and family. The performance was streamed live as a webcast. The two-and-a-half-hour set included some new tracks, including \"Silent House\" co-written by Finn with the Dixie Chicks. A concert onboard \"The Thekla\", moored in Bristol, followed on 19 March. Crowded House played at the Marquee Theatre in Tempe, Arizona on 26 April as a warm-up for their appearance at the Coachella Festival on 29 April in Indio, California. They also played at the Australian Live Earth concert in Sydney on 7 July. The next day, Finn and Seymour were interviewed on \"Rove Live\" and the band, with Hart and Sherrod, performed \"Don't Stop Now\" to promote the new album, which was titled \"Time on Earth\". The single was a minor hit in Australia and the UK. The album was released worldwide in June and July. It topped the album chart in New Zealand and made number 2 in Australia and number 3 in the UK.\n\nOn 6 December 2008 Crowded House played the Homebake festival in Sydney, with warm up gigs at small venues in Hobart, Melbourne and Sydney. For these shows the band were augmented by multi-instrumentalist Don McGlashan and Neil's younger son, Elroy Finn, on guitar. On 14 March 2009 the band joined Neil's older son, Liam Finn, on stage for three songs at the Sound Relief concert in Melbourne.\n\nCrowded House began recording their follow-up to \"Time on Earth\" in April 2009, at Finn's own Roundhead Studios. The album, \"Intriguer\", was produced by Jim Scott who had worked on \"The Sun Came Out\" by Neil's 7 Worlds Collide project. In August 2009, Finn travelled to Los Angeles to record some overdubs at Jim Scott's Los Angeles studio before they began mixing tracks. The album was released in June 2010, in time for the band's appearance at the West Coast Blues & Roots Festival near Perth. Finn stated that the album contains some, \"Unexpected twists and turns\" and some songs that, \"Sound like nothing we've done before.\" \"Intriguer\" topped the Australian album chart, reached number 3 in New Zealand and number 12 in the UK.\n\nCrowded House undertook an extensive world tour in 2010 in support of \"Intriguer\". This was the first album where the band regularly interacted with fans via the internet on their own re-launched website, Twitter and Facebook. The band sold recordings of the shows on the \"Intriguer\" tour on USB flash drives and made individual live tracks available for free download.\n\nA new compilation album, The Very Very Best of Crowded House, was released in October 2010 to celebrate the band's 25th anniversary. It includes 19 of the band's greatest hits and is also available in a box set with a 25 track DVD of their music videos. A deluxe digital version, available for download only, has 32 tracks including a rare 1987 live recording of the band's version of the Hunters & Collectors song \"Throw Your Arms Around Me\". No mention of this album has been made on the band's official website or Twitter page, which suggests that they are not involved with its release.\n\nFollowing the success of the album \"She Will Have Her Way\" in 2005, a second album of cover versions of Finn Brothers songs (including numerous Crowded House songs) was released on 12 November 2010. Entitled \"He Will Have His Way\", all tracks on this album are performed by Australasian male artists. In November 2011, there was an Australian tour by various artists involved with the \"She Will Have Her Way\" and \"He Will Have His Way\" projects, including Paul Dempsey, Clare Bowditch, Seeker Lover Keeper (Sarah Blasko, Sally Seltmann and Holly Throsby), Alexander Gow (Oh Mercy) and Lior.\n\nFormer Crowded House drummer Peter Jones died from brain cancer on 18 May 2012 aged 49. A statement issued by the band described him as, \"A warm-hearted, funny and talented man, who was a valuable member of Crowded House.\"\n\nIn September 2015, the song \"Help Is Coming\" from the \"Afterglow\" album, was released as a download and limited edition 7\" single to raise money for the charity Save the Children. The B-side, \"Anthem\", was a previously unreleased track that was initially recorded in 1995, with the final vocal added in 2015. The money will be used to provide shelter, water, sanitation and hygiene for refugees in Syria, Lebanon and Iraq. Neil Finn said of \"Help Is Coming\"...\"It was always a song about refugees, even if at the time I was thinking about the immigrants setting off on ships from Europe to America, looking for a better life for their families. There is such a huge scale and urgency to the current refugee crises that barely a day goes by without some crushing image or news account to confront us. We can't be silent any more.\"\n\nIn 2016, Neil Finn mentioned in an interview with the Dutch newspaper \"Volkskrant\" that Crowded House are on hiatus. Later that year, he and Seymour announced a series of concerts at the Sydney Opera House to mark the 20th anniversary of the \"Farewell to the World\" show (24 Nov 1996). The band performed four shows, 24–27 November 2016. Around the same time, each of the band's 7 studio albums (including the rarities collection \"Afterglow\") was reissued in deluxe 2-CD format with bonus tracks including demos, live recordings, alternate mixes, b-sides and outtakes.\n\nAs the primary songwriter for the band, Neil Finn has always set the tone for the band's sound. Allmusic said that Finn \"has consistently proven his knack for crafting high-quality songs that combine irresistible melodies with meticulous lyrical detail.\" Neil's brother Tim was an early and important musical influence. Neil first saw Tim play with Split Enz in 1972, and said \"that performance and those first songs made a lasting impression on me.\" His mother was another significant musical influence, encouraging him to listen to a variety of genres, including Irish folk music and Māori music. She would play piano at family parties and encourage Neil and Tim to accompany her.\n\nBassist Nick Seymour, who is also an artist, designed or co-designed all of the band's album covers and interior artwork. He also designed some of the costumes worn by the group, notably those from the cover of the group's debut album \"Crowded House\". Seymour collaborated with Finn and Hester on the set design of some of their early music videos, including \"Don't Dream It's Over\" and \"Better Be Home Soon\". Since the band reunited, Seymour has again designed their album covers.\n\nThe majority of the covers for the band's singles were not designed by Seymour. The artwork for \"Pineapple Head\" was created by Reg Mombassa of Mental As Anything. For the first four albums Mombassa and Noel Crombie, who had been the main designer of Split Enz's artwork, assisted Seymour in creating sets and costumes. For the \"Farewell to the World\" concerts Crombie designed the set, while Mombassa and Seymour designed promotional materials and artwork.\n\n\n\n\n\n\nCrowded House has won several national and international awards. In Australia, the group has won eleven ARIA Awards from 26 nominations, including the inaugural \"Best New Talent\" award in 1987. The majority of their ARIAs were awarded for their first two albums, \"Crowded House\" and \"Temple of Low Men\". They won eight APRA Awards from eleven nominations and were nominated for \"The New Zealand Silver Scroll\" for \"Don't Stop Now\" in 2007. \"Don't Dream It's Over\" was named the seventh best Australian song of all time in 2001. In 1987, Crowded House won the American MTV Video Music Award for \"Best New Artist\" for their song \"Don't Dream It's Over\", which was also nominated for three other awards. In 1994, the group was named \"International Group of the Year\" at the BRIT Awards. In 2009, \"Don't Dream It's Over\" was ranked number fifty on the Triple J \"Hottest 100 of All Time\", voted by the Australian public.\n\nIn November 2016 Crowded House were inducted into the ARIA Hall of Fame, 30 years after their formation.\n\n\n\n\n\n"}
{"id": "6928", "url": "https://en.wikipedia.org/wiki?curid=6928", "title": "Colette", "text": "Colette\n\nColette (; Sidonie-Gabrielle Colette, 28 January 1873 – 3 August 1954) was a French novelist nominated for the Nobel Prize in Literature in 1948. Her best known work, the novella \"Gigi\" (1944), was the basis for the film and Lerner and Loewe stage production of the same name. She was also a mime, an actress and a journalist.\n\nSidonie-Gabrielle Colette was born on January 28, 1873, to war hero and tax collector Jules-Joseph Colette and his wife Adèle Eugénie Sidonie (\"Sido\"), \"nėe\" Landoy, in the village of Saint-Sauveur-en-Puisaye in the \"département\" of Yonne, Burgundy. The family was initially well off, but by the time she was of school age poor financial management had substantially reduced her father's income and she attended a public school from the ages of 6 to 17—this was, nevertheless, a fairly extensive education for a girl of the period.\n\nIn 1893 she married Henry Gauthier-Villars (1859–1931) or 'Willy', his nom-de-plume, a well-known author and publisher, and her first four novels—the four Claudine stories, \"Claudine à l'école\" (1900), \"Claudine à Paris\" (1901), \"Claudine en menage\" (1902), and \"Claudine s'en va\" (1903)—appeared under his name. They chart the coming of age of their heroine, Claudine, from an unconventional fifteen-year-old in a Burgundian village to the literary salons of turn-of-the-century Paris. (The four are published in English as \"Claudine at School\", \"Claudine in Paris\", \"Claudine Married\", and \"Claudine and Annie\"). The story they tell is semi-autobiographical, but not entirely—most strikingly, Claudine, unlike Colette, is motherless.\n\nWilly, fourteen years older than his wife and one of the most notorious libertines in Paris, introduced Colette into avant-garde intellectual and artistic circles while engaging in sexual affairs and encouraging her own lesbian dalliances. It was he who chose the titillating subject-matter of the Claudine novels, \"the secondary myth of Sappho...the girls' school or convent ruled by a seductive female teacher\" (Ladimer, p. 53). Colette later said that she would never have become a writer if not for Willy.\n\nColette and Willy separated in 1906, although it was not until 1910 that the divorce became final. She had no access to the sizable earnings of the Claudine books—the copyright belonged to Willy—and until 1912 she followed a stage career in music halls across France, sometimes playing Claudine in sketches from her own novels, earning barely enough to survive and often hungry and unwell. This period of her life is recalled in \"La Vagabonde\" (1910), which deals with women's independence in a male society, a theme to which she would regularly return in future works. During these years she embarked on a series of relationships with other women, notably with Mathilde de Morny, Marquise de Belbeuf (\"Missy\"), with whom she sometimes shared the stage. On January 3, 1907, an onstage kiss between Missy and Colette in a pantomime entitled \"Rêve d'Égypte\" caused a near-riot, and as a result they were no longer able to live together openly, although their relationship continued for another five years.\n\nIn 1912 she married Henry de Jouvenel, the editor of \"Le Matin\". A daughter, Colette de Jouvenel, nicknamed \"Bel-Gazou\", was born in 1913. During the war she devoted herself to journalism, but marriage allowed her to devote her time to writing.\n\nIn 1920 Colette published \"Chéri\", portraying love between an older woman and a much younger man. Chéri is the lover of Léa, a wealthy courtesan; Léa is devastated when Chéri marries a girl his own age, and delighted when he returns to her, but after one final night together she sends him away again.\n\nThe marriage to Jouvenel ended in divorce in 1924, partly due to Jouvenel's infidelities and partly to Colette's own affair with her sixteen-year-old stepson, Bertrand de Jouvenel. In 1925 she met Maurice Goudeket, who became her final husband (the couple stayed together until her death).\n\nAlready an established writer (\"The Vagabond\" had received three votes for the prestigious \"Prix Goncourt\"), the decades of the 1920s and 1930s were Colette's most productive and innovative period. Set mostly in Burgundy or Paris during the Belle Époque, her work treated married life, sexuality, and the problems of a woman's struggle for independence. It was frequently quasi-autobiographical: \"Chéri\" (1920) and \"Le Blé en herbe\" (1923) both deal with love between an aging woman and a very young man, a situation reflecting her relationship with Bertrand de Jouvenel and even Goudeket, who was sixteen years her junior. \"La Naissance du Jour\" (1928) is her explicit criticism of the conventional lives of women, expressed in a meditation on age and the renunciation of love through the character of her mother, Sido.\n\nBy this period Colette was frequently acclaimed as France's greatest woman writer. \"It ... has no plot, and yet tells of three lives all that should be known\", wrote Janet Flanner of \"Sido\". \"Once again, and at greater length than usual, she has been hailed for her genius, humanities and perfect prose by those literary journals which years ago ... lifted nothing at all in her direction except the finger of scorn.\"\n\nColette was 67 years old at the fall of France, and remained in Paris, in her apartment in the Palais Royal. Her husband Maurice Goudeket, a Jew, was arrested by the Gestapo in December 1941, and although he was released after a few months through the intervention of the French wife of the German ambassador, Colette lived through the rest of the war years with the anxiety of a possible second arrest. During the Occupation she produced two volumes of memoirs, \"Journal à rebours\" (1941) and \"De ma fenêtre\" (1942 — the two issued in English in 1975 as \"Looking Backwards\").\n\nIn 1944 she published what became perhaps her most famous work, \"Gigi\", telling the story of sixteen year old Gilberte (\"Gigi\") Alvar. Born into a family of demimondaines, Gigi is being trained as a courtesan to captivate a wealthy lover, but breaks with tradition by marrying him instead. In 1949 it was made into a French film starring Danièle Delorme and Gaby Morlay, then in 1951 adapted for the stage with the then-unknown Audrey Hepburn in the title role, picked by Colette personally; the 1958 Hollywood musical, starring Leslie Caron and Louis Jourdan, with a screenplay by Alan Jay Lerner and a score by Lerner and Frederick Loewe, won the Academy Award for Best Picture.\n\nIn the postwar years, she became a famous public figure, crippled by arthritis and cared for by Goudeket who supervised the preparation of her collected works, or \"Oeuvres completes\" (1948–1950). She continued to write during these years, bringing out \"L'Etoile vesper\" (1944) and \"Le fanal bleu\" (1949), in which she reflected on the problems of a writer whose inspiration is primarily autobiographical. On her death on August 3, 1954, she was refused a religious funeral by the Catholic Church on account of her divorces, but was given a state funeral, the first French woman of letters to be granted this honour, and interred in Père-Lachaise cemetery.\n\nColette was elected to the Belgian Royal Academy (1935), the Académie Goncourt (1945, and President in 1949), and a Chevalier (1920) and Grand Officer (1953) of the Légion d'honneur.\n\nInitially considered a limited if talented novelist (despite the outspoken admiration in her lifetime of figures such as André Gide and Henri de Montherlant), she has been increasingly recognised as an important voice in women's writing.\n\nSinger-songwriter Rosanne Cash paid tribute to the writer in the song, \"The Summer I Read Colette\", on her 1996 album \"10 Song Demo\".\n\nTruman Capote wrote a short story about her (1970) called \"The White Rose\".\n\nThe Colette Study Centre in France has numerous items related to Colette's life. \n\nJane Gilmour, Ph.D, wrote \"\" (Hardie Grant Books), which is a book \"about Colette’s life through the places where she lived\".\n\nIn 2014, SUNY Press published \"Shipwrecked on a Traffic Island and Other Previously Untranslated Gems\" (translated by Zack Rogow and Renée Morel), a collection of sketches, mini-essays, radio talks, reminiscences, and journalistic pieces written by Colette. This was the first new work by Colette to appear in English in half a century.\n\n\"Lucette Stranded on the Island\" by Julia Holter, from her 2015 album \"Have You in My Wilderness\", is based on a minor character from Colette's short story \"Chance Acquaintances\".\n\n\n\n\n\n"}
{"id": "6932", "url": "https://en.wikipedia.org/wiki?curid=6932", "title": "Charles Alston", "text": "Charles Alston\n\nCharles Henry Alston (November 28, 1907 – April 27, 1977) was an African-American painter, sculptor, illustrator, muralist and teacher who lived and worked in the New York City neighborhood of Harlem. Alston was active in the Harlem Renaissance; Alston was the first African-American supervisor for the Works Progress Administration's Federal Art Project. Alston designed and painted murals at the Harlem Hospital and the Golden State Mutual Life Insurance Building. In 1990 Alston's bust of Martin Luther King, Jr. became the first image of an African American displayed at the White House.\n\nCharles Henry Alston was born on November 28, 1907, in Charlotte, North Carolina, to Reverend Primus Priss Alston and Anna Elizabeth Miller Alston, and was the youngest of five children. Only three survived past infancy: his sister Rousmaniere, and his brothers Wendell and Charles. His father was born into slavery in 1851 in Pittsboro, North Carolina; after the Civil War, he graduated from St. Augustine's College and became a prominent minister and founder of St. Michael's Episcopal Church. He was described as a \"race man\": an African American who dedicated his skills to the furtherance of the black race. Reverend Alston met his wife when she was a student at his school. Charles was nicknamed \"Spinky\" by his father, and kept the nickname as an adult. In 1910, when Charles was three, his father died suddenly of a cerebral hemorrhage. Locals described him in admiration as the \"Booker T. Washington of Charlotte\".\n\nIn 1913 Anna Alston married Harry Bearden. Through the marriage, the future artist Romare Bearden became Charles’ cousin. The two Bearden families lived across the street from each other; the friendship between Romare and Charles would last a lifetime. As a child Alston was inspired by his older brother Wendell's drawings of trains and cars, which the young artist copied. Charles also played with clay, creating a sculpture of North Carolina. As an adult he reflected on his memories of sculpting with clay as a child: \"I’d get buckets of it and put it through strainers and make things out of it. I think that's the first art experience I remember, making things.\" His mother was a skilled embroiderer and took up painting at the age of 75. His father was also good at drawing, wooing Alston's mother with small sketches in the medians of letters he wrote her.\n\nIn 1915 the family moved to New York, as many African-American families did during the Great Migration. Alston's step-father, Henry Bearden, left before his wife and children to secure a job overseeing elevator operations and the newsstand staff at the Bretton Hotel in the Upper West Side. The family lived in Harlem and was considered middle-class. During the Great Depression, the people of Harlem suffered economically. The \"stoic strength\" seen within the community was later expressed in Charles’ fine art. At Public School 179 in Manhattan, the boy's artistic abilities were recognized and he was asked to draw all of the school posters during his years there.\n\nAlston graduated from DeWitt Clinton High School, where he was nominated for academic excellence and was the art editor of the school's magazine, \"The Magpie\". He was a member of the Arista - National Honor Society and also studied drawing and anatomy at the Saturday school of the National Academy of Art . In high school he was given his first oil paints and learned about his aunt Bessye Bearden's art salons, which stars like Duke Ellington and Langston Hughes attended. After graduating in 1925, he attended Columbia University, turning down a scholarship to the Yale School of Fine Arts.\n\nAlston entered the pre-architectural program only to lose interest upon seeing the lack of success many African-American architects had in the field. After also experimenting with pre-med, he decided that math, physics and chemistry \"was not just my bag\" and he entered the fine arts program. During his time at Columbia he joined Alpha Phi Alpha, worked on the university's \"Columbia Daily Spectator\" and drew cartoons for the school's magazine \"Jester\". He also hung out in Harlem restaurants and clubs, where his love for jazz and black music would be fostered. In 1929 he graduated and received a fellowship to study at Teachers College, where he obtained his Master's in 1931.\n\nFor the years 1942–43 Alston was stationed in the army at Fort Huachuca in Arizona. Upon returning to New York on April 8, 1944, he married Dr. Myra Adele Logan, then an intern at the Harlem Hospital. They met when he was working on a mural project at the hospital. Their home, including his studio, as on Edgecombe Avenue near Highbridge Park. The couple lived close to family; at their frequent gatherings Alston enjoyed cooking and Myra played piano. During the 1940s Alston also took occasional art classes studying under Alexander Kostellow.\n\nIn January 1977 Myra Logan died. Months later on April 27, 1977, Charles \"Spinky\" Alston died after a long bout with cancer. His memorial service was held at St. Martins Episcopal Church on May 21, 1977, in New York City.\n\nWhile obtaining his master's degree, Alston was the boys’ work director at the Utopia Children's House, started by James Lesesne Wells. He also began teaching at the Harlem Community Art Center, founded by Augusta Savage in the basement of what is now the Schomburg Center for Research in Black Culture. Alston's teaching style was influenced by the work of John Dewey, Arthur Wesley Dow, and Thomas Munro. During this period, Alston began to teach the 10-year-old Jacob Lawrence, whom he strongly influenced. Alston was introduced to African art by the poet Alain Locke. In the late 1920s Alston joined Bearden and other black artists who refused to exhibit in William E. Harmon Foundation shows, which featured all-black artists in their traveling exhibits. Alston and his friends thought the exhibits were curated for a white audience, a form of segregation which the men protested. They did not want to be set aside but exhibited on the same level as art peers of every skin color.\n\nIn 1938 the Rosenwald Fund provided money for Alston to travel to the South, which was his first return there since leaving as a child. His travel with Giles Hubert, an inspector for the Farm Security Administration, gave him access to certain situations and he photographed many aspects of rural life. These photographs serves as the basis for a series of genre portraits depicting southern black life. In 1940 he completed \"Tobacco Farmer\", the portrait of a young black farmer in white overalls and a blue shirt with a youthful yet serious look upon his face, sitting in front of the landscape and buildings he works on and in. That same year he received a second round of funding from the Rosenwald Fund to travel South, and he spent extended time at Atlanta University.\n\nDuring the 1930s and early 1940s, Alston created illustrations for magazines such as \"Fortune\", \"Mademoiselle\", \"The New Yorker\", \"Melody Maker\" and others. He also designed album covers for artists such as Duke Ellington and Coleman Hawkins. Alston became staff artist at the Office of War Information and Public Relations in 1940, creating drawings of notable African Americans. These images were used in over 200 black newspapers across the country by the government to \"foster goodwill with the black citizenry.\"\n\nEventually Alston left commercial work to focus on his own artwork. In 1950, he became the first African-American instructor at the Art Students League, where he remained on faculty until 1971. In 1950, his \"Painting\" was exhibited at the Metropolitan Museum of Art and his artwork was one of few purchased by the museum. He landed his first solo exhibition in 1953 at the John Heller Gallery, which represented artists such as Roy Lichtenstein. He exhibited there five times from 1953 to 1958.\n\nIn 1956, he became the first African-American instructor at the Museum of Modern Art, where he taught for a year before going to Belgium on behalf of MOMA and the State Department. He coordinated the children's community center at Expo 58. In 1958 he was awarded a grant from and was elected as a member of the American Academy of Arts and Letters.\n\nIn 1963, Alston co-founded Spiral with Romare Bearden and Hale Woodruff. Spiral served as a collective of conversation and artistic exploration for a large group of artists who \"addressed how black artists should relate to American society in a time of segregation.\" Artists and arts supporters gathered for Spiral, such as Emma Amos, Perry Ferguson and Merton Simpson. \n\nIn 1968, Alston received a presidential appointment from Lyndon Johnson to the National Council of Culture and the Arts. Mayor John Lindsay appointed him to the New York City Art Commission in 1969. He was made full professor at City College of New York in 1973 where he had taught since 1968. In 1975 he was awarded the first Distinguished Alumni Award from Teachers College. The Art Student's League created a 21-year merit scholarship in 1977 under Alston's name to commemorate each year of his tenure.\n\nAlston shared studio space with Henry Bannarn at 306 W. 141st Street, which served as an open space for artists, photographers, musicians, writers and the like. Other artists held studio space at 306, such as Jacob Lawrence, Addison Bate and his brother Leon. During this time Alston founded the Harlem Artists Guild with Savage and Elba Lightfoot to work towards equality in WPA art programs in New York. During the early years of 306, Alston focused on mastering portraiture. Early works such as \"Portrait of a Man\" (1929) show Alston's detailed and realistic style depicted through pastels and charcoals, inspired by the style of Winold Reiss. In his \"Girl in a Red Dress\" (1934) and \"The Blue Shirt\" (1935), he used modern and innovative techniques for his portraits of young individuals in Harlem. \"Blue Shirt\" is thought to be a portrait of Jacob Lawrence. During this time he also created \"Man Seated with Travel Bag\" (c. 1938–40), showing the seedy and bleak environment, contrasting with work like the racially charged \"Vaudeville\" (c. 1930) and its caricature style of a man in blackface.\n\nInspired from his trip south, Alston began his \"family series\" in the 1940s. Intensity and angularity come through in the faces of the youth in his portraits \"Untitled (Portrait of a Girl)\" and \"Untitled (Portrait of a Boy)\". These works also show the influence that African sculpture had on his portraiture, with \"Portrait of a Boy\" showing more cubist features. Later family portraits show Alston's exploration of religious symbolism, color, form and space. His family group portraits are often faceless, which Alston states is the way that white America views blacks. Paintings such as \"Family\" (1955) show a woman seated and a man standing with two children – the parents seem almost solemn while the children are described as hopeful and with a use of color made famous by Cézanne. In \"Family Group\" (c. 1950) Alston's use of gray and ochre tones brings together the parents and son as if one with geometric patterns connecting them together as if a puzzle. The simplicity of the look, style and emotion upon the family is reflective and probably inspired by Alston's trip south. His work during this time has been described as being \"characterized by his reductive use of form combined with a sun-hued\". During this time he also started to experiment with ink and wash painting seen in work such as \"Portrait of a Woman\" (1955) as well as creating portraits to illustrate the music surrounding him in Harlem. \"Blues Singer #4\" shows a female singer on stage with a white flower on her shoulder and a bold red dress, reminiscent of Ella Fitzgerald. \"Girl in a Red Dress\" is thought to be Bessie Smith, for whom he drew many times when she was recording and performing. Jazz was an important influence in Alston's work and social life, representing itself in other works like \"Jazz\" (1950) and \"Harlem at Night\".\n\nThe 1960s civil rights movement influenced his work heavily with artworks influenced by inequality and race relations in the United States. One of his few religious artworks was created in 1960, \"Christ Head\", with an angular \"Modiglianiesque\" portrait of Jesus Christ. Seven years later he created \"You never really meant it, did you, Mr. Charlie?\" which, in a similar style as \"Christ Head\" shows a black man standing against a red sky \"looking as frustrated as any individual can look\", according to Alston.\n\nExperimenting with the use of negative space and organic forms in the late 1940s, by the mid-1950s Alston began creating notably modernist style paintings. \"Woman with Flowers\" (1949) has been described as a tribute to Modigliani and African art makes another strong appearance in \"Ceremonial\" (1950). Untitled works during the era show his use of color overlay using muted colors to create simple layered abstracts of still live. \"Symbol\" (1953) relates to Picasso's \"Guernica\", which was a favorite work of Alston's. His final work of the 1950s, \"Walking\", was inspired by the Montgomery Bus Boycott and has come to represent \"the surge of energy among African Americans to organize in their struggle for full equality.\" About the artwork, Alston is quoted \"The idea of a march was growing...It was in the air...and this painting just came. I called it \"Walking\" on purpose. It wasn't the militancy that you saw later. It was a very definite walk-not going back, no hesitation.\"\n\nThe Civil Rights Movement of the 1960s was a major influence on Alston. Considered to be one of his most powerful and impressive periods in the late 1950s he began working in black and white up until the mid-1960s. Some of the works are simple abstracts of black ink on white paper, similar to a Rorschach test. \"Untitled\" (c. 1960s) shows a boxing match in great simplicity with an attempt to express the drama of the fight through few brushstrokes. Alston worked with oil-on-Masonite during this period as well, utilizing impasto, cream and ochre to create a moody cave-like artwork. \"Black and White #1\" (1959) is one of Alston's more \"monumental\" works. Gray, white and black come together to fight for space on an abstract canvas, in a softer form than the more harsh Franz Kline. Alston continued to explore the relationship between monochromatic hues throughout the series which Wardlaw describes as \"some of the most profoundly beautiful works of twentieth-century American art.\"\n\nIn the beginning Charles Alston's mural work was inspired by the work of Aaron Douglas, Diego Rivera and José Clemente Orozco, the latter who he met when they did mural work in New York. In 1943 Alston was elected to the board of directors of the National Society of Mural Painters. He created murals for the Harlem Hospital, Golden State Mutual, American Museum of Natural History, Public School 154, the Bronx Family and Criminal Court and the Abraham Lincoln High School in Brooklyn, New York.\n\nOriginally hired as an easel painter, in 1935 Alston became the first African-American supervisor to work for the WPA's Federal Art Project (FAP) in New York, which would also serve as his first mural work. At this time he was awarded WPA Project Number 1262 – an opportunity to oversee a group of artists creating murals and to supervise their painting for the Harlem Hospital. The first government commission ever awarded to African-American artists including Beauford Delaney, Seabrook Powell and Vertis Hayes. He also had the chance to create and paint his own contribution to the collection: \"Magic in Medicine\" and \"Modern Medicine\". These paintings were part of a diptych completed in 1936 depicting the history of medicine in the African-American community and Beauford Delaney served as assistant. When creating the murals Alston was inspired by the work of Aaron Douglas, who a year earlier had created the public art piece \"Aspects of Negro Life\" for the New York Public Library, and researched traditional African culture, including traditional African medicine. \"Magic in Medicine\", which depicts African culture and holistic healing, is considered one of \"America's first public scenes of Africa\". All of the murals sketches submitted were accepted by the FAP, however, four were denied creation by the hospital superintendent Lawrence T. Dermody and commissioner of hospitals S.S. Goldwater due to the excessive amount of African-American representation in the works. The artists fought the response through letter writing and four years later succeeded in gaining the right to complete the murals. The sketches for \"Magic in Medicine\" and \"Modern Medicine\" were exhibited in the Museum of Modern Art's \"New Horizons in American Art\".\n\nAlston's murals were hung in the Women's Pavilion of the hospital over uncapped radiators which caused the paintings to deteriorate from the steam. Plans failed to recap the radiators. In 1959 Alston estimated, in a letter to the Department of Public Works, that the conservation would cost $1,500 but the funds were never acquired. In 1968, after Martin Luther King Jr.'s death, Alston was asked to create another mural for the hospital to be placed in a pavilion named after the assassinated civil rights leader titled \"Man Emerging from the Darkness of Poverty and Ignorance into the Light of a Better World.\" One year after Alston's death in 1977, a group of artists and historians, including the renowned painter and collagist Romare Bearden and art historian Greta Berman, together with administrators from the hospital, and from the NYC Art Commission, examined the murals, and presented a proposal for their restoration to then-mayor Ed Koch. The request was approved, and conservator Alan Farancz set to work in 1979, rescuing the murals from further decay. Many years passed, and the murals began to deteriorate again – especially the Alston works, which continued to suffer effects from the radiators. In 1991 the Municipal Art Society's Adopt-a-Mural program was launched and the Harlem Hospital murals were chosen for further restoration (Greta Berman. Personal experience). A grant from Alston's sister Rousmaniere Wilson and step-sister Aida Bearden Winters assisted in completing a restoration of the works in 1993. In 2005 Harlem Hospital announced a $2 million project to conserve Alston's murals and three other pieces in the original commissioned project as part of a $225 million hospital expansion.\n\nIn the late 1940s Alston became involved in a mural project commissioned by Golden State Mutual Life Insurance Company which asked the artists to create work involving African-American contributions to the settling of California. Alston worked with Hale Woodruff on the murals in a large studio space in New York where they utilized ladders to reach the upper parts of the canvas. The artworks, which are considered \"priceless contributions to American narrative art\", consists of two panels: \"Exploration and Colonization\" by Alston and \"Settlement and Development\" by Woodruff. Alston's piece covers the post-colonial period of 1527 to 1850. Images of James Beckwourth, Biddy Mason, and William Leidesdorff are portrayed in the well detailed historical mural. While both artists kept in contact with African Americans on the West Coast during its creation, influencing the content and depictions. The murals, which were unveiled in 1949, have been on display in the lobby of the Golden State Mutual Headquarters. Due to economic downturn Golden State was forced to sell their entire art collection to ward off its mounting debts and as of spring 2011 the National Museum of African American History and Culture had offered $750,000 to purchase the artworks which led to a controversy regarding the importance of the artworks which have been estimated to be worth at least $5 million. It was requested that the murals be covered by city landmark protections by the Los Angeles Conservancy. The state of California had declined philanthropic proposals to keep the murals in their original location and the Smithsonian withdrew their offer. The murals are currently awaiting their fate in California courts.\n\nAlston also created sculptures. \"Head of a Woman\" (1957) shows his move towards a \"reductive and modern approach to sculpture...where facial features were suggested rather than fully formulated in three dimensions,\". In 1970 Alston was commissioned by the Community Church of New York to create a bust of Martin Luther King Jr. for $5,000, with only five copies produced. In 1990 Alston's bronze bust of Martin Luther King Jr. (1970), became the first image of an African American displayed in the White House.\n\nArt critic Emily Genauer stated that Alston \"refused to be pigeonholed\", regarding his varied exploration in his artwork. Patron Lemoine Pierce said of Alston's work: \"Never thought of as an innovative artist, Alston generally ignored popular art trends and violated many mainstream art conventions; he produced abstract and figurative paintings often simultaneously, refusing to be stylistically consistent, and during his 40-year career he worked prolifically and unapologetically in both commercial and fine art.\" Romare Bearden described Alston as \"...one of the most versatile artists whose enormous skill led him to a diversity of styles...\" Bearden also describes the professionalism and impact that Alston had on Harlem and the African-American community: \"'was a consummate artist and a voice in the development of African American art who never doubted the excellence of all people's sensitivity and creative ability. During his long professional career, Alston significantly enriched the cultural life of Harlem. In a profound sense, he was a man who built bridges between Black artists in varying fields, and between other Americans.\" Writer June Jordan described Alston as \"an American artist of first magnitude, and he is a Black American artist of undisturbed integrity.\"\n\n\n\n\n\n"}
{"id": "6933", "url": "https://en.wikipedia.org/wiki?curid=6933", "title": "Chromatin", "text": "Chromatin\n\nChromatin is a complex of macromolecules found in cells, consisting of DNA, protein, and RNA. The primary functions of chromatin are 1) to package DNA into a more compact, denser shape, 2) to reinforce the DNA macromolecule to allow mitosis, 3) to prevent DNA damage, and 4) to control gene expression and DNA replication. The primary protein components of chromatin are histones that compact the DNA. Chromatin is only found in eukaryotic cells (cells with defined nuclei). Prokaryotic cells have a different organization of their DNA (the prokaryotic chromosome equivalent is called genophore and is localized within the nucleoid region).\n\nChromatin's structure is currently poorly understood despite being subjected to intense investigation. Its structure depends on several factors. The overall structure depends on the stage of the cell cycle. During interphase, the chromatin is structurally loose to allow access to RNA and DNA polymerases that transcribe and replicate the DNA. The local structure of chromatin during interphase depends on the genes present on the DNA. That DNA which codes genes that are actively transcribed (\"turned on\") is more loosely packaged and associated with RNA polymerases (referred to as euchromatin) while that DNA which codes inactive genes (\"turned off\") is more condensed and associated with structural proteins (heterochromatin). Epigenetic chemical modification of the structural proteins in chromatin also alters the local chromatin structure, in particular chemical modifications of histone proteins by methylation and acetylation. As the cell prepares to divide, i.e. enters mitosis or meiosis, the chromatin packages more tightly to facilitate segregation of the chromosomes during anaphase. During this stage of the cell cycle this makes the individual chromosomes in many cells visible by optical microscope.\n\nIn general terms, there are three levels of chromatin organization:\nThere are, however, many cells that do not follow this organisation. For example, spermatozoa and avian red blood cells have more tightly packed chromatin than most eukaryotic cells, and trypanosomatid protozoa do not condense their chromatin into visible chromosomes for mitosis.\n\nChromatin undergoes various structural changes during a cell cycle. Histone proteins are the basic packer and arranger of chromatin and can be modified by various post-translational modifications to alter chromatin packing (Histone modification). Most of the modifications occur on the histone tail. The consequences in terms of chromatin accessibility and compaction depend both on the amino-acid that is modified and the type of modification. For example, Histone acetylation results in loosening and increased accessibility of chromatin for replication and transcription. Lysine tri-methylation can either be correlated with transcriptional activity (tri-methylation of histone H3 Lysine 4) or transcriptional repression and chromatin compaction (tri-methylation of histone H3 Lysine 9 or 27). Several studies suggested that different modifications could occur simultaneously. For example, it was proposed that a bivalent structure (with tri-methylation of both Lysine 4 and 27 on histone H3) was involved in mammalian early development.\n\nPolycomb-group proteins play a role in regulating genes through modulation of chromatin structure.\n\nFor additional information, see Histone modifications in chromatin regulation and RNA polymerase control by chromatin structure.\n\nIn nature, DNA can form three structures, A-, B-, and Z-DNA. A- and B-DNA are very similar, forming right-handed helices, whereas Z-DNA is a left-handed helix with a zig-zag phosphate backbone. Z-DNA is thought to play a specific role in chromatin structure and transcription because of the properties of the junction between B- and Z-DNA.\n\nAt the junction of B- and Z-DNA, one pair of bases is flipped out from normal bonding. These play a dual role of a site of recognition by many proteins and as a sink for torsional stress from RNA polymerase or nucleosome binding.\n\nThe basic repeat element of chromatin is the nucleosome, interconnected by sections of linker DNA, a far shorter arrangement than pure DNA in solution.\n\nIn addition to the core histones, there is the linker histone, H1, which contacts the exit/entry of the DNA strand on the nucleosome. The nucleosome core particle, together with histone H1, is known as a chromatosome. Nucleosomes, with about 20 to 60 base pairs of linker DNA, can form, under non-physiological conditions, an approximately 10 nm \"beads-on-a-string\" fibre. (Fig. 1-2). .\n\nThe nucleosomes bind DNA non-specifically, as required by their function in general DNA packaging. There are, however, large DNA sequence preferences that govern nucleosome positioning. This is due primarily to the varying physical properties of different DNA sequences: For instance, adenine and thymine are more favorably compressed into the inner minor grooves. This means nucleosomes can bind preferentially at one position approximately every 10 base pairs (the helical repeat of DNA)- where the DNA is rotated to maximise the number of A and T bases that will lie in the inner minor groove. (See mechanical properties of DNA.)\n\nWith addition of H1, the beads-on-a-string structure in turn coils into a 30 nm diameter helical structure known as the 30 nm fibre or filament. The precise structure of the chromatin fibre in the cell is not known in detail, and there is still some debate over this.\n\nThis level of chromatin structure is thought to be the form of heterochromatin, which contains mostly transcriptionally silent genes. EM studies have demonstrated that the 30 nm fibre is highly dynamic such that it unfolds into a 10 nm fiber (\"beads-on-a-string\") structure when transversed by an RNA polymerase engaged in transcription.\nThe existing models commonly accept that the nucleosomes lie perpendicular to the axis of the fibre, with linker histones arranged internally.\nA stable 30 nm fibre relies on the regular positioning of nucleosomes along DNA. Linker DNA is relatively resistant to bending and rotation. This makes the length of linker DNA critical to the stability of the fibre, requiring nucleosomes to be separated by lengths that permit rotation and folding into the required orientation without excessive stress to the DNA.\nIn this view, different lengths of the linker DNA should produce different folding topologies of the chromatin fiber. Recent theoretical work, based on electron-microscopy images\nof reconstituted fibers supports this view.\n\nThe spatial arrangement of the chromatin within the nucleus is not random - specific regions of the chromatin can be found in certain territories. Territories are, for example, the lamina-associated domains (LADs), and the topological association domains (TADs), which are bound together by protein complexes. Currently, polymer models such as the Strings & Binders Switch (SBS) model and the Dynamic Loop (DL) model are used to describe the folding of chromatin within the nucleus.\n\n\nChromatin and its interaction with enzymes has been researched, and a conclusion being made is that it is relevant and an important factor in gene expression. Vincent G. Allfrey, a professor at Rockefeller University, stated that RNA synthesis is related to histone acetylation. The lysine amino acid attached to the end of the histones is positively charged. The acetylation of these tails would make the chromatin ends neutral, allowing for DNA access.\n\nWhen the chromatin decondenses, the DNA is open to entry of molecular machinery. Fluctuations between open and closed chromatin may contribute to the discontinuity of transcription, or transcriptional bursting. Other factors are probably involved, such as the association and dissociation of transcription factor complexes with chromatin. The phenomenon, as opposed to simple probabilistic models of transcription, can account for the high variability in gene expression occurring between cells in isogenic populations\n\nDuring metazoan spermiogenesis, the spermatid's chromatin is remodeled into a more spaced-packaged, widened, almost crystal-like structure. This process is associated with the cessation of transcription and involves nuclear protein exchange. The histones are mostly displaced, and replaced by protamines (small, arginine-rich proteins). It is proposed that in yeast, regions devoid of histones become very fragile after transcription; HMO1 an HMGB protein helps in stabilizing nucleosomes-free chromatin.\n\nThe packaging of eukaryotic DNA into chromatin presents a barrier to all DNA-based processes that require recruitment of enzymes to their sites of action. To allow the critical cellular process of DNA repair, the chromatin must be remodeled. In eukaryotes, ATP dependent chromatin remodeling complexes and histone-modifying enzymes are two predominant factors employed to accomplish this remodeling process.\n\nChromatin relaxation occurs rapidly at the site of a DNA damage. This process is initiated by PARP1 protein that starts to appear at DNA damage in less than a second, with half maximum accumulation within 1.6 seconds after the damage occurs. Next the chromatin remodeler Alc1 quickly attaches to the product of PARP1, and completes arrival at the DNA damage within 10 seconds of the damage. About half of the maximum chromatin relaxation, presumably due to action of Alc1, occurs by 10 seconds. This then allows recruitment of the DNA repair enzyme MRE11, to initiate DNA repair, within 13 seconds.\n\nγH2AX, the phosphorylated form of H2AX is also involved in the early steps leading to chromatin decondensation after DNA damage occurrence. The histone variant H2AX constitutes about 10% of the H2A histones in human chromatin. γH2AX (H2AX phosphorylated on serine 139) can be detected as soon as 20 seconds after irradiation of cells (with DNA double-strand break formation), and half maximum accumulation of γH2AX occurs in one minute. The extent of chromatin with phosphorylated γH2AX is about two million base pairs at the site of a DNA double-strand break. γH2AX does not, itself, cause chromatin decondensation, but within 30 seconds of irradiation, RNF8 protein can be detected in association with γH2AX. RNF8 mediates extensive chromatin decondensation, through its subsequent interaction with CHD4, a component of the nucleosome remodeling and deacetylase complex NuRD.\n\nAfter undergoing relaxation subsequent to DNA damage, followed by DNA repair, chromatin recovers to a compaction state close to its pre-damage level after about 20 min.\n\n\nThe term, introduced by Walther Flemming, has multiple meanings:\n\nThe following scientists were recognized for their contributions to chromatin research with Nobel Prizes:\n\n\n"}
{"id": "6934", "url": "https://en.wikipedia.org/wiki?curid=6934", "title": "Condition number", "text": "Condition number\n\nIn the field of numerical analysis, the condition number of a function with respect to an argument measures how much the output value of the function can change for a small change in the input argument. This is used to measure how sensitive a function is to changes or errors in the input, and how much error in the output results from an error in the input. Very frequently, one is solving the inverse problem – given formula_1 one is solving for \"x,\" and thus the condition number of the (local) inverse must be used. In linear regression the condition number can be used as a diagnostic for multicollinearity.\n\nThe condition number is an application of the derivative, and is formally defined as the value of the asymptotic worst-case relative change in output for a relative change in input. The \"function\" is the solution of a problem and the \"arguments\" are the data in the problem. The condition number is frequently applied to questions in linear algebra, in which case the derivative is straightforward but the error could be in many different directions, and is thus computed from the geometry of the matrix. More generally, condition numbers can be defined for non-linear functions in several variables.\n\nA problem with a low condition number is said to be well-conditioned, while a problem with a high condition number is said to be ill-conditioned. The condition number is a property of the problem. Paired with the problem are any number of algorithms that can be used to solve the problem, that is, to calculate the solution. Some algorithms have a property called backward stability. In general, a backward stable algorithm can be expected to accurately solve well-conditioned problems. Numerical analysis textbooks give formulas for the condition numbers of problems and identify known backward stable algorithms.\n\nAs a rule of thumb, if the condition number formula_2, then you may lose up to formula_3 digits of accuracy on top of what would be lost to the numerical method due to loss of precision from arithmetic methods. However, the condition number does not give the exact value of the maximum inaccuracy that may occur in the algorithm. It generally just bounds it with an estimate (whose computed value depends on the choice of the norm to measure the inaccuracy).\n\nFor example, the condition number associated with the linear equation\n\"Ax\" = \"b\" gives a bound on how inaccurate the solution \"x\" will be after approximation. Note that this is before the effects of round-off error are taken into account; conditioning is a property of the matrix, not the algorithm or floating point accuracy of the computer used to solve the corresponding system. In particular, one should think of the condition number as being (very roughly) the rate at which the solution, \"x\", will change with respect to a change in \"b\". Thus, if the condition number is large, even a small error in \"b\" may cause a large error in \"x\". On the other hand, if the condition number is small then the error in \"x\" will not be much bigger than the error in \"b\".\n\nThe condition number is defined more precisely to be the maximum ratio of the relative error in \"x\" divided by the relative error in \"b\".\n\nLet \"e\" be the error in \"b\". Assuming that \"A\" is a nonsingular matrix, the error in the solution \"A\"\"b\" is \"A\"\"e\". The ratio of the relative error in the solution to the relative error in \"b\" is\n\nThis is easily transformed to\n\nThe maximum value (for nonzero \"b\" and \"e\") is then seen to be the product of the two operator norms as follows:\n\nThe same definition is used for any consistent norm, i.e. one that satisfies\n\nWhen the condition number is exactly one (which can only happen if \"A\" is a scalar multiple of a linear isometry), then a solution algorithm can find (in principle, meaning if the algorithm introduces no errors of its own) an approximation of the solution whose precision is no worse than that of the data.\n\nHowever, it does not mean that the algorithm will converge rapidly to this solution, just that it won't diverge arbitrarily because of inaccuracy on the source data (backward error), provided that the forward error introduced by the algorithm does not diverge as well because of accumulating intermediate rounding errors.\n\nThe condition number may also be infinite, but this implies that the problem is ill-posed (does not possess a unique, well-defined solution for each choice of data -- that is, the matrix is not invertible), and no algorithm can be expected to reliably find a solution.\n\nThe definition of the condition number depends on the choice of norm, as can be illustrated by two examples.\n\nIf formula_9 is the norm (usually noted as formula_10) defined in the square-summable sequence space ℓ (which matches the usual distance in a standard Euclidean space), then\nwhere formula_12 and formula_13 are maximal and minimal singular values of formula_14 respectively. Hence\nwhere formula_17 and formula_18 are maximal and minimal (by moduli) eigenvalues of formula_15 respectively.\nThe condition number with respect to \"L\" arises so often in numerical linear algebra that it is given a name, the condition number of a matrix.\n\nIf formula_9 is the norm (usually denoted by formula_23) defined in the sequence space ℓ of all bounded sequences (which matches the maximum of distances measured on projections into the base subspaces), and formula_15 is lower triangular non-singular (i.e., formula_25) then\nThe condition number computed with this norm is generally larger than the condition number computed with square-summable sequences, but it can be evaluated more easily (and this is often the only practicably computable condition number, when the problem to solve involves a \"non-linear algebra\", for example when approximating irrational and transcendental functions or numbers with numerical methods).\n\nIf the condition number is not too much larger than one (but it can still be a multiple of one), the matrix is well conditioned which means its inverse can be computed with good accuracy. If the condition number is very large, then the matrix is said to be ill-conditioned. Practically, such a matrix is almost singular, and the computation of its inverse, or solution of a linear system of equations is prone to large numerical errors. A matrix that is not invertible has condition number equal to infinity.\n\nCondition numbers can also be defined for nonlinear functions, and can be computed using calculus. The condition number varies with the point; in some cases one can use the maximum (or supremum) condition number over the domain of the function or domain of the question as an overall condition number, while in other cases the condition number at a particular point is of more interest.\n\nThe condition number of a differentiable function \"f\" in one variable as a function is formula_27 Evaluated at a point \"x\" this is:\nMost elegantly, this can be understood as (the absolute value of) the ratio of the logarithmic derivative of \"f,\" which is formula_29 and the logarithmic derivative of \"x,\" which is formula_30 yielding a ratio of formula_27 This is because the logarithmic derivative is the infinitesimal rate of relative change in a function: it is the derivative formula_32 scaled by the value of \"f.\" Note that if a function has a zero at a point, its condition number at the point is infinite, as infinitesimal changes in the input can change the output from zero to positive or negative, yielding a ratio with zero in the denominator, hence infinite relative change.\n\nMore directly, given a small change formula_33 in \"x,\" the relative change in \"x\" is formula_34 while the relative change in formula_35 is formula_36 Taking the ratio yields:\nThe last term is the difference quotient (the slope of the secant line), and taking the limit yields the derivative.\n\nCondition numbers of common elementary functions are particularly important in computing significant figures, and can be computed immediately from the derivative; see significance arithmetic of transcendental functions. A few important ones are given below:\n\nCondition numbers can be defined for any function \"ƒ\" mapping its data from some domain (e.g. an \"m\"-tuple of real numbers \"x\") into some codomain [e.g. an \"n\"-tuple of real numbers \"ƒ\"(\"x\")], where both the domain and codomain are Banach spaces. They express how sensitive that function is to small changes (or small errors) in its arguments. This is crucial in assessing the sensitivity and potential accuracy difficulties of numerous computational problems, for example polynomial root finding or computing eigenvalues.\n\nThe condition number of \"ƒ\" at a point \"x\" (specifically, its relative condition number) is then defined to be the maximum ratio of the fractional change in \"ƒ\"(\"x\") to any fractional change in \"x\", in the limit where the change δ\"x\" in \"x\" becomes infinitesimally small:\n\nwhere formula_55 is a norm on the domain/codomain of \"ƒ\"(\"x\").\n\nIf \"ƒ\" is differentiable, this is equivalent to:\n\nwhere \"J(x)\" denotes the Jacobian matrix of partial derivatives of \"ƒ\" at \"x\" and formula_57 is the induced norm on the matrix.\n\n\n"}
{"id": "6936", "url": "https://en.wikipedia.org/wiki?curid=6936", "title": "Cheddar cheese", "text": "Cheddar cheese\n\nCheddar cheese is a relatively hard, off-white (or orange if spices such as annatto are added), sometimes sharp-tasting (i.e., bitter), natural cheese. Originating in the British village of Cheddar in Somerset, cheeses of this style are produced beyond this region and in several countries around the world.\n\nCheddar is the most popular type of cheese in the UK, accounting for 51% of the country's £1.9 billion annual cheese market. It is the second-most popular cheese in the US (behind mozzarella), with an average annual consumption of per capita. The US produced approximately in 2014, and the UK in 2008.\n\nThe term \"Cheddar cheese\" is widely used, but has no Protected Designation of Origin within the European Union. However, in 2007, a Protected Designation of Origin, \"West Country Farmhouse Cheddar\", was created and only Cheddar produced from local milk within Somerset, Dorset, Devon and Cornwall and manufactured using traditional methods may use the name. Outside of Europe, the style and quality of cheeses labelled as cheddar may vary greatly; furthermore, cheeses that are more similar in taste and appearance to Red Leicester are sometimes popularly marketed as \"Red Cheddar\".\n\nThe cheese originates from the village of Cheddar in Somerset, south west England. Cheddar Gorge on the edge of the village contains a number of caves, which provided the ideal humidity and steady temperature for maturing the cheese. Cheddar cheese traditionally had to be made within of Wells Cathedral.\n\nCheddar has been produced since at least the 12th century. A pipe roll of King Henry II from 1170 records the purchase of at a farthing per pound (totalling £10.13s.4d).\nCharles I (1600–1649) also bought cheese from the village.\nRomans may have brought the recipe to Britain from the Cantal region of France.\n\nCentral to the modernisation and standardisation of Cheddar cheese was the 19th-century Somerset dairyman Joseph Harding.\nFor his technical innovations, promotion of dairy hygiene, and volunteer dissemination of modern cheese-making techniques, he has been dubbed \"the father of Cheddar cheese\".\nHarding introduced new equipment to the process of cheese-making, including his \"revolving breaker\" for curd cutting, saving much manual effort.\nThe \"Joseph Harding method\" was the first modern system for Cheddar production based upon scientific principles. Harding stated that Cheddar cheese is \"not made in the field, nor in the byre, nor even in the cow, it is made in the dairy\". His wife and he were behind the introduction of the cheese into Scotland and North America. His sons, Henry and William Harding, were responsible for introducing Cheddar cheese production to Australia and facilitating the establishment of the cheese industry in New Zealand, respectively.\n\nDuring the Second World War, and for nearly a decade after, most milk in Britain was used for the making of one single kind of cheese nicknamed \"government Cheddar\" as part of war economies and rationing. This almost resulted in wiping out all other cheese production in the country. Before the First World War, more than 3,500 cheese producers were in Britain; fewer than 100 remained after the Second World War.\n\nAccording to a United States Department of Agriculture researcher, Cheddar cheese is the world's most popular variety of cheese, and the most studied type of cheese in scientific publications.\n\nThe curds and whey are separated using rennet, an enzyme complex normally produced from the stomachs of newborn calves (in vegetarian or kosher cheeses, bacterial, yeast or mould-derived chymosin is used).\n\n\"Cheddaring\" refers to an additional step in the production of Cheddar cheese where, after heating, the curd is kneaded with salt, cut into cubes to drain the whey, and then stacked and turned. Strong, extra-mature Cheddar, sometimes called vintage, needs to be matured for up to 15 months. The cheese is kept at a constant temperature, often requiring special facilities. As with other hard cheese varieties produced worldwide, caves provide an ideal environment for maturing cheese; still, today, some Cheddar cheese is matured in the caves at Wookey Hole and Cheddar Gorge. Additionally, some versions of Cheddar cheese are smoked.\n\nThe ideal quality of the original Somerset Cheddar was described by Joseph Harding in 1864 as \"close and firm in texture, yet mellow in character or quality; it is rich with a tendency to melt in the mouth, the flavour full and fine, approaching to that of a hazelnut\".\n\nCheddar made in the classical way tends to have a sharp, pungent flavour, often slightly earthy. The \"sharpness\" of cheddar is associated with the levels of bitter peptides in the cheese. This bitterness has been found to be significant to the overall perception of the aged Cheddar flavor. The texture is firm, with farmhouse traditional Cheddar being slightly crumbly; it should also, if mature, contain large cheese crystals consisting of calcium lactate – often precipitated when matured for times longer than six months.\n\nCheddar can be a deep to pale yellow (off-white) colour, or a yellow-orange colour when certain plant extracts are added. One commonly used spice is annatto, extracted from seeds of the tropical achiote tree. Originally added to simulate the colour of high-quality milk from grass-fed Jersey and Guernsey cows, annatto may also impart a sweet, nutty flavour. The largest producer of Cheddar cheese in the United States, Kraft, uses a combination of annatto and oleoresin paprika, an extract of the lipophilic (oily) portion of paprika.\n\nCheddar cheese was sometimes (and still can be found) packaged in black wax, but was more commonly packaged in larded cloth, which was impermeable to contaminants, but still allowed the cheese to \"breathe\".\n\nThe Slow Food Movement has created a Cheddar Presidium, claiming that only three cheeses should be called \"original Cheddar\". Their specifications, which go further than the \"West Country Farmhouse Cheddar\" PDO, require that Cheddar cheese be made in Somerset and with traditional methods, such as using raw milk, traditional animal rennet, and a cloth wrapping.\n\nThe Cheddar cheese name is used internationally; its name does not have a PDO, but the use of the name \"West Country Farmhouse Cheddar\" does. As well as the United Kingdom, countries making Cheddar cheese include Australia, Argentina, Belgium, Canada, Ireland, the Netherlands, New Zealand, South Africa, Sweden, Finland and the United States. Cheddars can be industrial or artisan cheeses. The flavour, colour, and quality of industrial cheese varies significantly, and food packaging will usually indicate a strength, such as mild, medium, strong, tasty, sharp, extra sharp, mature, old, or vintage; this may indicate the maturation period, or food additives used to enhance the flavour. Artisan varieties develop strong and diverse flavours over time.\n\nAs of 2013, Cheddar accounts for over 55% of the Australian cheese market, with average annual consumption around per person. Cheddar is so commonly found that the name is rarely used: instead, Cheddar is sold by strength alone as e.g. \"mild\", \"tasty\" or \"sharp\".\n\nFollowing a wheat midge outbreak in Canada in the mid-19th century, farmers in Ontario began to convert to dairy farming in large numbers, and Cheddar cheese became their main exportable product, even being exported to England. By the turn of the 20th century, 1,242 Cheddar factories were in Ontario, and Cheddar had become Canada’s second-largest export after timber. Cheddar exports totalled in 1904, but by 2012, Canada was a net importer of cheese. James L. Kraft grew up on a dairy farm in Ontario, before moving to Chicago. According to the writer Sarah Champman, \"Although we cannot wholly lay the decline of cheese craft in Canada at the feet of James Lewis Kraft, it did correspond with the rise of Kraft’s processed cheese empire.\" Most Canadian Cheddar is produced by a number of large companies in Ontario, though other provinces produce some and some smaller artisanal producers exist. The annual production is 120,000 tons. It is aged a minimum of three months, but much of it is held for much longer, up to 10 years.\n\nCanadian Cheddar cheese soup is a featured dish at the Canada pavilion at Epcot, in Walt Disney World.\n\nMuch of the Cheddar cheese in New Zealand is factory produced. While most of it is sold young within the country, the Anchor dairy company ships New Zealand Cheddars to the UK, where the blocks mature for another year or so.\n\nOnly one producer of the cheese is now based in Cheddar itself, the Cheddar Gorge Cheese Co. The name \"cheddar\" is not protected by the European Union, though the name \"West Country Farmhouse Cheddar\" has an EU protected designation of origin, and may only be produced in Somerset, Devon, Dorset and Cornwall, using milk sourced from those counties. Cheddar is usually sold as mild, medium, mature, extra mature or vintage. Mature cheddar is the best-selling variety in the UK. Cheddar produced in Orkney is registered as an EU protected geographical indication under the name \"Orkney Scottish Island Cheddar\".\n\nThe state of Wisconsin produces the most Cheddar cheese in the US; other centers of production include: California, Idaho, upstate New York, Vermont, Oregon, Texas, and Oklahoma. It is sold in several varieties (mild, medium, sharp, extra-sharp, New York-style, white-, and Vermont). New York-style Cheddar is particularly \"sharp\"/acidic, but tends to be somewhat softer than the milder-tasting varieties. Cheddar that does not contain annatto is frequently labelled \"white Cheddar\" or \"Vermont Cheddar\" (regardless of whether it was actually produced there). Vermont's three creameries produce what is regarded as first-class Cheddar cheeses: the Cabot Creamery, which produces the 16-month-old \"Private Stock Cheddar\", the Grafton Village Cheese Company, and Shelburne Farms.\n\nSome cheeses called \"Cheddar\" are actually flavoured processed cheeses or \"cheese foods\"; they often bear little resemblance to their natural namesakes. Examples include Easy Cheese: a cheese-food packaged in a pressurized spray can; also, as packs of square, sliced, individually wrapped, \"processed cheese\" (sometimes also pasteurised).\n\nCheddar is one of several products used by the United States Department of Agriculture to track the status of America's overall dairy industry; reports are issued weekly detailing prices and production quantities.\n\nU.S. President Andrew Jackson once held an open house party at the White House at which he served a block of Cheddar cheese.\n\nA cheese of was produced in Ingersoll, Ontario, in 1866 and exhibited in New York and Britain; it was immortalised in the poem \"Ode on the Mammoth Cheese Weighing over 7,000 Pounds\" by James McIntyre, a Canadian poet.\n\nIn 1893, farmers from the town of Perth, Ontario, produced \"The Mammoth Cheese\", which weighed for the Chicago World's Fair. It was planned to be exhibited at the Canadian display, but the mammoth cheese fell through the floor and was placed on a reinforced concrete floor in the Agricultural Building. It received the most journalistic attention at the fair and was awarded the bronze medal. A larger, Wisconsin cheese of was made for the 1964 New York World's Fair. A cheese this size would use the equivalent of the daily milk production of 16,000 cows.\n\nOregon members of the Federation of American Cheese-makers created the largest Cheddar cheese in 1989. The cheese weighed .\n\n\n"}
{"id": "6938", "url": "https://en.wikipedia.org/wiki?curid=6938", "title": "Classical order", "text": "Classical order\n\n\"\"An Order in architecture is a certain assemblage of parts subject to uniform established proportions, regulated by the office that each part has to perform\".\"\nComing down to the present from Ancient Greek and Ancient Roman civilization, the Architectural Orders are the styles of classical architecture, each distinguished by its proportions and characteristic profiles and details, and most readily recognizable by the type of column employed. The three orders of architecture—the Doric, Ionic, and Corinthian—originated in Greece. To these the Romans added, in practice if not in name, the Tuscan, which they made simpler than Doric, and the Composite, which was more ornamental than the Corinthian. The Architectural Order of a classical building is akin to the mode or key of classical music, the grammar or rhetoric of a written composition. It is established by certain \"modules\" like the intervals of music, and it raises certain expectations in an audience attuned to its language.\n\nWhereas the orders were essentially structural in Greek architecture, which made little use of the arch until its late period, in Roman architecture where the arch was often dominant, the orders became increasingly decorative elements except in porticos and similar uses. Columns shrank into half-columns emerging from walls or turned into pilasters. This treatment continued after the conscious and \"correct\" use of the orders, initially following exclusively Roman models, returned in the Italian Renaissance. Greek Revival architecture, inspired by increasing knowledge of Greek originals, returned to more authentic models, including ones from relatively early periods.\n\nEach style has distinctive capitals at the top of columns and horizontal entablatures which it supports, while the rest of the building does not in itself vary between the orders. The column shaft and base also varies with the order, and is sometimes articulated with vertical hollow grooves known as fluting. The shaft is wider at the bottom than at the top, because its entasis, beginning a third of the way up, imperceptibly makes the column slightly more slender at the top, although some Doric columns, especially early Greek ones, are visibly \"flared\", with straight profiles that narrow going up the shaft.\n\nThe capital rests on the shaft. It has a load-bearing function, which concentrates the weight of the entablature on the supportive column, but it primarily serves an aesthetic purpose. The necking is the continuation of the shaft, but is visually separated by one or many grooves. The echinus lies atop the necking. It is a circular block that bulges outwards towards the top to support the abacus, which is a square or shaped block that in turn supports the entablature. The entablature consists of three horizontal layers, all of which are visually separated from each other using moldings or bands. In Roman and post-Renaissance work, the entablature may be carried from column to column in the form of an arch that springs from the column that bears its weight, retaining its divisions and sculptural enrichment, if any. There are names for all the many parts of the orders.\n\nThe height of columns are calculated in terms of a ratio between the diameter of the shaft at its base and the height of the column. A Doric column can be described as seven diameters high, an Ionic column as eight diameters high and a Corinthian column nine diameters high, although the actual ratios used vary considerably in both ancient and revived examples, but keeping to the trend of increasing slimness between the orders. Sometimes this is phrased as \"lower diameters high\", to establish which part of the shaft has been measured.\n\nThere are three distinct orders in Ancient Greek architecture: Doric, Ionic, and Corinthian. These three were adopted by the Romans, who modified their capitals. The Roman adoption of the Greek orders took place in the 1st century BC. The three Ancient Greek orders have since been consistently used in neo-classical European architecture.\n\nSometimes the Doric order is considered the earliest order, but there is no evidence to support this. Rather, the Doric and Ionic orders seem to have appeared at around the same time, the Ionic in eastern Greece and the Doric in the west and mainland.\n\nBoth the Doric and the Ionic order appear to have originated in wood. The Temple of Hera in Olympia is the oldest well-preserved temple of Doric architecture. It was built just after 600 BC. The Doric order later spread across Greece and into Sicily where it was the chief order for monumental architecture for 800 years.\n\nThe Doric order originated on the mainland and western Greece. It is the simplest of the orders, characterized by short, faceted, heavy columns with plain, round capitals (tops) and no base. With a height that is only four to eight times its diameter, the columns are the most squat of all orders. The shaft of the Doric order is channeled with 20 flutes. The capital consists of a necking which is of a simple form. The echinus is convex and the abacus is square.\n\nAbove the capital is a square abacus connecting the capital to the entablature. The Entablature is divided into three horizontal registers, the lower part of which is either smooth or divided by horizontal lines. The upper half is distinctive for the Doric order. The frieze of the Doric entablature is divided into triglyphs and metopes. A triglyph is a unit consisting of three vertical bands which are separated by grooves. Metopes are the plain or carved reliefs between two triglyphs.\n\nThe Greek forms of the Doric order come without an individual base. They instead are placed directly on the stylobate. Later forms, however, came with the conventional base consisting of a plinth and a torus. The Roman versions of the Doric order have smaller proportions. As a result, they appear lighter than the Greek orders.\n\nThe Ionic order came from eastern Greece, where its origins are entwined with the similar but little known Aeolic order. It is distinguished by slender, fluted pillars with a large base and two opposed \"volutes\" (also called \"scrolls\") in the echinus of the capital. The echinus itself is decorated with an egg-and-dart motif. The Ionic shaft comes with four more flutes than the Doric counterpart (totalling 24). The Ionic base has two convex moldings called \"tori\" which are separated by a scotia.\n\nThe Ionic order is also marked by an entasis, a curved tapering in the column shaft. A column of the ionic order is nine times its lower diameter. The shaft itself is eight diameters high. The architrave of the entablature commonly consists of three stepped bands (\"fasciae\"). The frieze comes without the Doric \"triglyph\" and \"metope\". The frieze sometimes comes with a continuous ornament such as carved figures instead.\n\nThe Corinthian order is the most ornate of the Greek orders, characterized by a slender fluted column having an ornate capital decorated with two rows of acanthus leaves and four scrolls. It is commonly regarded as the most elegant of the three orders. The shaft of the Corinthian order has 24 flutes. The column is commonly ten diameters high.\n\nThe Roman writer Vitruvius credited the invention of the Corinthian order to Callimachus, a Greek sculptor of the 5th century BC. The oldest known building built according to this order is the Choragic Monument of Lysicrates in Athens, constructed from 335 to 334 BC. The Corinthian order was raised to rank by the writings of Vitruvius in the 1st century BC.\n\nThe Romans adapted all the Greek orders and also developed two orders of their own, basically modifications of Greek orders. However, it was not until the Renaissance that these were named and formalized as the Tuscan and Composite, respectively the plainest and most ornate of the orders. The Romans also invented the superposed order. A superposed order is when successive stories of a building have different orders. The heaviest orders were at the bottom, whilst the lightest came at the top. This means that the Doric order was the order of the ground floor, the Ionic order was used for the middle story, while the Corinthian or the Composite order was used for the top story.\n\nThe Colossal order was invented by architects in the Renaissance. The Colossal order is characterized by columns that extend the height of two or more stories.\n\nThe Tuscan order has a very plain design, with a plain shaft, and a simple capital, base, and frieze. It is a simplified adaptation of the Doric order by the Greeks. The Tuscan order is characterized by an unfluted shaft and a capital that only consists of an echinus and an abacus. In proportions it is similar to the Doric order, but overall it is significantly plainer. The column is normally seven diameters high. Compared to the other orders, the Tuscan order looks the most solid.\n\nThe Composite order is a mixed order, combining the volutes of the Ionic with the leaves of the Corinthian order. Until the Renaissance it was not ranked as a separate order. Instead it was considered as a late Roman form of the Corinthian order. The column of the Composite order is typically ten diameters high.\n\nThe Renaissance period saw renewed interest in the literary sources of the ancient cultures of Greece and Rome, and the fertile development of a new architecture based on classical principles. The treatise \"De architectura\" by Roman theoretician, architect and engineer Vitruvius, is the only architectural writing that survived from Antiquity. Rediscovered in the 15th century, Vitruvius was instantly hailed as the authority on architecture. However, in his text the word \"order\" is not to be found. To describe the four species of columns (he only mentions: Tuscan, Doric, Ionic and Corinthian) he uses, in fact, various words such as: \"genus\" (gender), \"mos\" (habit, fashion, manner), \"opera\" (work).\n\nThe term \"order\", as well as the idea of redefining the \"canon\" started circulating in Rome, at the beginning of the 16th century, probably during the studies of Vitruvius' text conducted and shared by Peruzzi, Raphael and Sangallo.\nEver since, the definition of the \"canon\" has been a collective endeavor that involved several generations of European architects, from Renaissance and Baroque periods, basing their theories both on the study of Vitruvius' writings and the observation of Roman ruins (the Greek ruins became available only after Greek Independence, 1821–23). What was added were rules for the use of the Architectural Orders, and the exact proportions of them down to the most minute detail. Commentary on the appropriateness of the orders for temples devoted to particular deities (Vitruvius I.2.5) were elaborated by Renaissance theorists, with Doric characterized as bold and manly, Ionic as matronly, and Corinthian as maidenly.\n\nFollowing the examples of Vitruvius and the five books of the \"Regole generali di architettura sopra le cinque maniere de gli edifici\" by Sebastiano Serlio, published from 1537 onwards, Giacomo Barozzi da Vignola produced an architecture rule book that was not only more practical than the previous two treatises, but also was systematically and consistently adopting, for the first time, the term order to define each of the five different species of columns inherited from Antiquity. A first publication of the various plates, as separate sheets, appeared in Rome in 1562, with the title: \"Regola delli Cinque Ordini di Architettura\" (\"Canon of the Five Orders of Architecture \"). As David Watkin has pointed out, Vignola's book \"was to have an astonishing publishing history of over 500 editions in 400 years in ten languages, Italian, Dutch, English, Flemish, French, German, Portuguese, Russian, Spanish, Swedish, during which it became perhaps the most influential book of all times\".\nThe book consisted simply of an introduction followed by 32 annotated plates, highlighting the proportional system with all the minute details of the Five Architectural Orders. According to Christof Thoenes, the main expert of Renaissance architectural treatises, \"in accordance with Vitruvius’s example, Vignola chose a “module” equal to a half-diameter which is the base of the system. All the other measurements are expressed in fractions or in multiples of this module. The result is an arithmetical model, and with its help each order, harmoniously proportioned, can easily be adapted to any given height, of a façade or an interior. From this point of view, Vignola’s Regola is a remarkable intellectual achievement\".\n\nIn America, \"The American Builder's Companion\", written in the early 19th century by the architect Asher Benjamin, influenced many builders in the eastern states, particularly those who developed what became known as the Federal style. The last American re-interpretation of Vignola's \"Regola\", was edited in 1904 by William Robert Ware.\n\nThe break from the classical mode came first with the Gothic revival, then the development of modernism during the 19th century. The Bauhaus promoted pure functionalism, stripped of superfluous ornament, and that has become one of the defining characteristics of modern architecture. There are some exceptions. Postmodernism introduced an ironic use of the orders as a cultural reference, divorced from the strict rules of composition. On the other hand, a few practitioners e.g. Quinlan Terry and Stuart Martin still work in a traditional classical idiom.\n\nSeveral orders, usually based upon the composite order and only varying in the design of the capitals, have been invented under the inspiration of specific occasions, but have not been used again. Thus they may be termed \"nonce orders\" on the analogy of nonce words. Robert Adam's brother James was in Rome in 1762, drawing antiquities under the direction of Clérisseau; he invented a British Order, of which his ink-and-wash rendering with red highlighting is at the Avery Library, Columbia University. Adam published an engraving of it. In its capital the heraldic lion and unicorn take the place of the Composite's volutes, a Byzantine/Romanesque conception, but expressed in terms of neoclassical realism. In 1789 George Dance invented an Ammonite Order, a variant of Ionic substituting volutes in the form of fossil ammonites for John Boydell's Shakespeare Gallery in Pall Mall, London. An adaptation of the Corinthian order by William Donthorne that used turnip leaves and mangelwurzel is termed the Agricultural Order.\n\nIn the United States Benjamin Latrobe, the architect of the Capitol building in Washington DC, designed a series of botanically American orders. Most famous is the order substituting corncobs and their husks, which was executed by Giuseppe Franzoni and employed in the small domed Vestibule of the Supreme Court. Only the Supreme Court survived the fire of August 24, 1814, nearly intact. With peace restored, Latrobe designed an American order that substituted for the acanthus tobacco leaves, of which he sent a sketch to Thomas Jefferson in a letter, November 5, 1816. He was encouraged to send a model of it, which remains at Monticello. In the 1830s Alexander Jackson Davis admired it enough to make a drawing of it. In 1809 Latrobe invented a second American order, employing magnolia flowers constrained within the profile of classical mouldings, as his drawing demonstrates. It was intended for \"the Upper Columns in the Gallery of the Entrance of the Chamber of the Senate\" (United States Capitol exhibit).\nEdwin Lutyens, who from 1912 laid out New Delhi as the new seat of government for the British Empire in India, designed a Delhi Order having a capital displaying a band of vertical ridges, and with bells hanging at each corner as a replacement for volutes. His design for the new city's central palace, Viceroy's House, now the Presidential residence Rashtrapati Bhavan, was a thorough integration of elements of Indian architecture into a building of classical forms and proportions, and made use of the order throughout. The Delhi Order reappears in some later Lutyens buildings including Campion Hall, Oxford.\n\nThese nonce orders all express the \"speaking architecture\" (\"architecture parlante\") that was taught in the Paris courses, most explicitly by Étienne-Louis Boullée, in which sculptural details of classical architecture could be enlisted to speak symbolically, the better to express the purpose of the structure and enrich its visual meaning with specific appropriateness. This idea was taken up strongly in the training of Beaux-Arts architecture, ca 1875-1915. \n\n\n\n"}
{"id": "6941", "url": "https://en.wikipedia.org/wiki?curid=6941", "title": "Colin Kapp", "text": "Colin Kapp\n\nColin Kapp (3 April 1928 – 3 August 2007) was a British science fiction author.\n\nA contemporary of Brian Aldiss and James White, Kapp is best known for his stories about the Unorthodox Engineers.\n\n\n\n\nCollected in \"The Unorthodox Engineers\" (1979)\n\n\n"}
{"id": "6942", "url": "https://en.wikipedia.org/wiki?curid=6942", "title": "Catherine of Aragon", "text": "Catherine of Aragon\n\nCatherine of Aragon (), also spelled Katherine, (16 December 1485 – 7 January 1536) was Queen of England from June 1509 until May 1533 as the first wife of King Henry VIII; she was previously Princess of Wales as the wife of Henry's elder brother Arthur.\n\nThe daughter of Isabella I of Castile and Ferdinand II of Aragon, Catherine was three years old when she was betrothed to Arthur, Prince of Wales, heir apparent to the English throne. They married in 1501, but Arthur died five months later. In 1507, she held the position of ambassador of the Aragonese Crown in England, the first female ambassador in European history. Catherine subsequently married Arthur's younger brother, the recently ascended Henry VIII, in 1509. For six months in 1513, she served as regent of England while Henry VIII was in France. During that time the English won the Battle of Flodden, an event in which Catherine played an important part with an emotional speech about English courage.\n\nBy 1525, Henry VIII was infatuated with Anne Boleyn and dissatisfied that his marriage to Catherine had produced no surviving sons, leaving their daughter, the future Mary I of England, as heir presumptive at a time when there was no established precedent for a woman on the throne. He sought to have their marriage annulled, setting in motion a chain of events that led to England's schism with the Catholic Church. When Pope Clement VII refused to annul the marriage, Henry defied him by assuming supremacy over religious matters. In 1533 their marriage was consequently declared invalid and Henry married Anne on the judgement of clergy in England, without reference to the Pope. Catherine refused to accept Henry as Supreme Head of the Church in England and considered herself the King's rightful wife and queen, attracting much popular sympathy. Despite this, she was acknowledged only as Dowager Princess of Wales by Henry. After being banished from court, she lived out the remainder of her life at Kimbolton Castle, and died there on 7 January 1536. English people held Catherine in high esteem, and her death set off tremendous mourning.\n\nThe controversial book \"The Education of a Christian Woman\" by Juan Luis Vives, which claimed women have the right to an education, was commissioned by and dedicated to her. Such was Catherine's impression on people that even her enemy, Thomas Cromwell, said of her, \"If not for her sex, she could have defied all the heroes of History.\" She successfully appealed for the lives of the rebels involved in the Evil May Day, for the sake of their families. Catherine also won widespread admiration by starting an extensive programme for the relief of the poor. She was a patron of Renaissance humanism, and a friend of the great scholars Erasmus of Rotterdam and Thomas More.\n\nCatherine was born at the Archbishop's Palace in Alcalá de Henares near Madrid, on the night of 16 December 1485. She was the youngest surviving child of King Ferdinand II of Aragon and Queen Isabella I of Castile. Catherine was quite short in stature with long red hair, wide blue eyes, a round face, and a fair complexion. She was descended, on her maternal side, from the English royal house; her great-grandmother Catherine of Lancaster, after whom she was named, and her great-great-grandmother Philippa of Lancaster were both daughters of John of Gaunt and granddaughters of Edward III of England. Consequently, she was third cousin of her father-in-law, Henry VII of England, and fourth cousin of her mother-in-law Elizabeth of York.\n\nCatherine was educated by a tutor, Alessandro Geraldini, who was a clerk in Holy Orders. She studied arithmetic, canon and civil law, classical literature, genealogy and heraldry, history, philosophy, religion, and theology. She had a strong religious upbringing and developed her Roman Catholic faith that would play a major role in later life. She learned to speak, read and write in Spanish and Latin, and spoke French and Greek. She was also taught domestic skills, such as cooking, dancing, drawing, embroidery, good manners, lace-making, music, needlepoint, sewing, spinning, and weaving. Scholar Erasmus later said that Catherine \"loved good literature which she had studied with success since childhood\".\n\nAt an early age, Catherine was considered a suitable wife for Arthur, Prince of Wales, heir apparent to the English throne, due to the English ancestry she inherited from her mother. By means of her mother, Catherine had a stronger legitimate claim to the English throne than King Henry VII himself through the first two wives of John of Gaunt, 1st Duke of Lancaster: Blanche of Lancaster and Constance of Castile. In contrast, Henry VII was the descendant of Gaunt's third marriage to Katherine Swynford, whose children were born out of wedlock and only legitimised after the death of Constance and the marriage of John to Katherine. The children of John and Katherine, while legitimised, were barred from inheriting the English throne, a stricture that was ignored in later generations. Because of Henry's descent through illegitimate children barred from succession to the English throne, the Tudor monarchy was not accepted by all European kingdoms. At the time, the House of Trastámara was the most prestigious in Europe, due to the rule of the Catholic Monarchs, so the alliance of Catherine and Arthur validated the House of Tudor in the eyes of European royalty and strengthened the Tudor claim to the English throne via Catherine of Aragon's ancestry. It would have given a male heir an indisputable claim to the throne. The two were married by proxy on 19 May 1499 and corresponded in Latin until Arthur turned fifteen, when it was decided that they were old enough to be married.\n\nWhen Catherine of Aragon travelled to London, she brought a group of her African attendants with her, including one identified as the trumpeter John Blanke. They are the first Africans recorded to have arrived in London at the time, and were considered luxury servants. They caused a great impression about the princess and the power of her family.\n\nCatherine and Arthur met on 4 November 1501 at Dogmersfield in Hampshire. Little is known about their first impressions of each other, but Arthur did write to his parents-in-law that he would be \"a true and loving husband\" and told his parents that he was immensely happy to \"behold the face of his lovely bride\". The couple had corresponded in Latin, but found that they could not understand each other, since they had learned different pronunciations. Ten days later, on 14 November 1501, they were married at Old St. Paul's Cathedral. A dowry of 200,000 crowns had been agreed, and half was paid shortly after the marriage.\n\nOnce married, Arthur was sent to Ludlow Castle on the borders of Wales to preside over the Council of Wales and the Marches, as was his duty as Prince of Wales, and his bride accompanied him. The couple stayed at Castle Lodge, Ludlow. A few months later, they both became ill, possibly with the sweating sickness, which was sweeping the area. Arthur died on 2 April 1502; Catherine recovered to find herself a widow.\n\nAt this point, Henry VII faced the challenge of avoiding the obligation to return her 200,000 ducat dowry, half of which he had not yet received, to her father, as required by her marriage contract should she return home. Following the death of his queen, Elizabeth of York, in February 1503, Henry VII initially considered marrying Catherine himself, but the opposition of her father and potential questions over the legitimacy of the couple's issue ended the idea. To settle the matter, it was agreed that Catherine would marry Henry VII's second son, Henry, Duke of York, who was five years younger than she was. The death of Catherine's mother, however, meant that her \"value\" in the marriage market decreased. Castile was a much larger kingdom than Aragon, and it was inherited by Catherine's mentally unstable elder sister, Joanna. Ostensibly, the marriage was delayed until Henry was old enough, but Ferdinand II procrastinated so much over payment of the remainder of Catherine's dowry that it became doubtful that the marriage would take place. She lived as a virtual prisoner at Durham House in London. Some of the letters she wrote to her father complaining of her treatment have survived. In one of these letters she tells him that \"I choose what I believe, and say nothing. For I am not as simple as I may seem.\" She had little money and struggled to cope, as she had to support her ladies-in-waiting as well as herself. In 1507 she served as the Spanish ambassador to England, the first female ambassador in European history. While Henry VII and his councillors expected her to be easily manipulated, Catherine went on to prove them wrong.\n\nMarriage to Arthur's brother depended on the Pope granting a dispensation because canon law forbade a man to marry his brother's widow (Lev. 18:16). Catherine testified that her marriage to Arthur was never consummated as, also according to canon law, a marriage was not valid until consummated.\n\nCatherine's wedding took place on 11 June 1509, seven years after Prince Arthur's death. She married Henry VIII, who had only just acceded to the throne, in a private ceremony in the church of the Observant Friars outside Greenwich Palace. She was 23 years of age. The king was just days short of his 18th birthday.\n\nOn Saturday 23 June 1509, the traditional eve-of-coronation procession to Westminster was greeted by a large and enthusiastic crowd. As was the custom, the couple spent the night before their coronation at the Tower of London. On Midsummer's Day, Sunday, 1509, Henry VIII and Catherine were anointed and crowned together by the Archbishop of Canterbury at a lavish ceremony at Westminster Abbey. The coronation was followed by a banquet in Westminster Hall. Many new Knights of the Bath were created in honour of the coronation.\nIn that month that followed, many social occasions presented the new Queen to the English public. She made a fine impression and was well received by the people of England.\n\nCatherine was pregnant seven times altogether:\n\nOn 11June 1513, Henry appointed Catherine Regent in England with the titles \"Governor of the Realm and Captain General,\" while he went to France on a military campaign.\nWhen Louis d'Orléans, Duke of Longueville, was captured at Thérouanne, Henry sent him to stay in Catherine's household. She wrote to Wolsey that she and her council would prefer the Duke to stay in the Tower of London as the Scots were \"so busy as they now be\" and she added her prayers for \"God to sende us as good lukke against the Scotts, as the King hath ther.\" The war with Scotland occupied her subjects, and she was \"horrible busy with making standards, banners, and badges\" at Richmond Palace. The Scots invaded and on 3 September 1513, she ordered Thomas Lovell to raise an army in the midland counties.\n\nCatherine rode north in full armour to address the troops, despite being heavily pregnant at the time. Her fine speech was reported to the historian Peter Martyr d'Anghiera in Valladolid within a fortnight. Although an Italian newsletter said she was north of London when news of the victory at Battle of Flodden Field reached her, she was near Buckingham. From Woburn Abbey she sent a letter to Henry along with a piece of the bloodied coat of King James IV of Scotland, who died in the battle, for Henry to use as a banner at the siege of Tournai.\n\nCatherine's religious dedication increased as she became older, as did her interest in academics. She continued to broaden her knowledge and provide training for her daughter, Mary. Education among women became fashionable, partly because of Catherine's influence, and she donated large sums of money to several colleges. Henry, however, still considered a male heir essential. The Tudor dynasty was new, and its legitimacy might still be tested. A long civil war (1135–54) had been fought the last time a woman, (Empress Matilda), had inherited the throne. The disasters of civil war were still fresh in living memory from the Wars of the Roses.\n\nIn 1520, Catherine's nephew, the Holy Roman Emperor Charles V, paid a state visit to England, and she urged Henry to enter an alliance with Charles rather than with France. Immediately after his departure, she accompanied Henry to France on the celebrated visit to Francis I, the so-called Field of the Cloth of Gold. Within two years, war was declared against France and the Emperor was once again welcome in England, where plans were afoot to betroth him to Catherine's daughter Mary.\n\nIn 1525, Henry VIII became enamoured of Anne Boleyn, a lady-in-waiting to Queen Catherine who was 11 years younger than Henry. Henry began pursuing her; Catherine was no longer able to bear children by this time. Henry began to believe that his marriage was cursed and sought confirmation from the Bible, which he interpreted to say that if a man marries his brother's wife, the couple will be childless. Even if her marriage to Arthur had not been consummated (and Catherine would insist to her dying day that she had come to Henry's bed a virgin), Henry's interpretation of that biblical passage meant that their marriage had been wrong in the eyes of God. Whether the Pope at the time of Henry and Catherine's marriage had had the right to overrule Henry's claimed scriptural impediment would become a hot topic in Henry's campaign to wrest an annulment from the present Pope. It is possible that the idea of annulment had been suggested to Henry much earlier than this, and is highly probable that it was motivated by his desire for a son. Before Henry's father ascended the throne, England was beset by civil warfare over rival claims to the English crown, and Henry may have wanted to avoid a similar uncertainty over the succession.\n\nIt soon became the one absorbing object of Henry's desires to secure an annulment. Catherine was defiant when it was suggested that she quietly retire to a nunnery, saying: \"God never called me to a nunnery. I am the King's true and legitimate wife\". He set his hopes upon an appeal to the Holy See, acting independently of Cardinal Thomas Wolsey, whom he told nothing of his plans. William Knight, the King's secretary, was sent to Pope Clement VII to sue for an annulment, on the grounds that the dispensing bull of Pope Julius II was obtained by false pretences.\n\nAs the Pope was, at that time, the prisoner of Catherine's nephew, Emperor Charles V, following the Sack of Rome in May 1527, Knight had difficulty in obtaining access to him. In the end, Henry's envoy had to return without accomplishing much. Henry now had no choice but to put this great matter into the hands of Wolsey, who did all he could to secure a decision in Henry's favour.\n\nWhen Henry decided to annul his marriage to Catherine, John Fisher became her most trusted counsellor and one of her chief supporters. He appeared in the legates' court on her behalf, where he shocked people with the directness of his language, and by declaring that, like John the Baptist, he was ready to die on behalf of the indissolubility of marriage. Henry was so enraged by this that he wrote a long Latin address to the legates in answer to Fisher's speech. Fisher's copy of this still exists, with his manuscript annotations in the margin which show how little he feared Henry's anger. The removal of the cause to Rome ended Fisher's role in the matter, but Henry never forgave him. Other people who supported Catherine's case included Thomas More; Henry's own sister Mary Tudor, Queen of France (though as a member of the Tudor family and of royal blood, she was safe from any punishment and execution); María de Salinas; Holy Roman Emperor Charles V; Pope Paul III and Protestant Reformers Martin Luther and William Tyndale.\n\nUpon returning to Dover from a meeting with King Francis I of France in Calais, Henry married Anne Boleyn in a secret ceremony. Some sources speculate that Anne was already pregnant at the time (and Henry did not want to risk a son being born illegitimate) but others testify that Anne (who had seen her sister Mary Boleyn taken up as the king's mistress and summarily cast aside) refused to sleep with Henry until they were married. Henry defended the legality of their union by pointing out that Catherine had previously been married. If she and Arthur had consummated their marriage, Henry by canon law had the right to remarry. On 23 May 1533, Cranmer, sitting in judgement at a special court convened at Dunstable Priory to rule on the validity of Henry's marriage to Catherine, declared the marriage illegal, even though Catherine testified she and Arthur had never had physical relations. Cranmer ruled Henry and Anne's marriage valid five days later, on 28 May 1533.\n\nUntil the end of her life, Catherine would refer to herself as Henry's only lawful wedded wife and England's only rightful queen, and her servants continued to address her by that title. Henry refused her the right to any title but \"Dowager Princess of Wales\" in recognition of her position as his brother's widow.\n\nCatherine went to live at The More castle in the winter of 1531/32. In 1535 she was transferred to Kimbolton Castle. There, she confined herself to one room (which she left only to attend Mass), dressed only in the hair shirt of the Order of St. Francis, and fasted continuously. While she was permitted to receive occasional visitors, she was forbidden to see her daughter Mary. They were also forbidden to communicate in writing, but sympathizers discreetly ferried letters between the two. Henry offered both mother and daughter better quarters and permission to see each other if they would acknowledge Anne Boleyn as the new queen. Both refused.\n\nIn late December 1535, sensing her death was near, Catherine made her will, and wrote to her nephew, the Emperor Charles V, asking him to protect her daughter. She then penned one final letter to Henry, her \"most dear lord and husband\":\nCatherine died at Kimbolton Castle on 1536. The following day, news of her death reached the king. At the time there were rumours that she was poisoned, possibly by Gregory di Casale. According to the chronicler Edward Hall, Anne Boleyn wore yellow for the mourning, which has been interpreted in various ways; Polydore Vergil interpreted this to mean that Anne did not mourn. Chapuys reported that it was King Henry who decked himself in yellow, celebrating the news and making a great show of his and Anne's daughter, Elizabeth, to his courtiers. This was seen as distasteful and vulgar by many. Another theory is that the dressing in yellow was out of respect for Catherine as yellow was said to be the Spanish colour of mourning. Certainly, later in the day it is reported that Henry and Anne both individually and privately wept for her death. On the day of Catherine's funeral, Anne Boleyn miscarried a boy. Rumours then circulated that Catherine had been poisoned by Anne or Henry, or both, as Anne had threatened to murder both Catherine and Mary on several occasions. The rumours were born after the apparent discovery during her embalming that there was a black growth on her heart that might have been caused by poisoning. Modern medical experts are in agreement that her heart's discolouration was due not to poisoning, but to cancer, something which was not understood at the time.\n\nCatherine was buried in Peterborough Cathedral with the ceremony due to a Dowager Princess of Wales, not a queen. Henry did not attend the funeral and forbade Mary to attend.\n\nCatherine was a member of the Third Order of Saint Francis and she was punctilious in her religious obligations in the Order, integrating without demur her necessary duties as queen with her personal piety. After her divorce, she was quoted \"I would rather be a poor beggar’s wife and be sure of heaven, than queen of all the world and stand in doubt thereof by reason of my own consent.\"\n\nThe outward celebration of saints and holy relics formed no major part of her personal devotions, which she rather expressed in the Mass, prayer, confession and penance. Privately, however, she was aware of what she identified as the shortcomings of the papacy and church officialdom. Her doubts about Church improprieties certainly did not extend so far as to support the allegations of corruption made public by Martin Luther in Wittenberg in 1517, which were soon to have such far-reaching consequences in initiating the Protestant Reformation.\n\nIn 1523 Alfonso de Villa Sancta, a learned friar of the Observant (reform) branch of the Friars Minor and friend of the king's old advisor Erasmus, dedicated to the queen his book \"De Liberio Arbitrio adversus Melanchthonem\" denouncing Philip Melanchthon, a supporter of Luther. Acting as her confessor, he was able to nominate her for the title of \"Defender of the Faith\" for denying Luther's arguments.\n\nCatherine was of a very fair complexion, had blue eyes, and had a hair colour that was between reddish-blonde and auburn like her mother and sister Joanna. In her youth she was described as \"the most beautiful creature in the world\" and that there was \"nothing lacking in her that the most beautiful girl should have\". Thomas More and Lord Herbert would reflect later in her lifetime that in regard to her appearance \"there were few women who could compete with the Queen [Catherine] in her prime.\"\n\nThe controversial book \"The Education of Christian Women\" by Juan Luis Vives, which claimed women have the right to an education, was dedicated to and commissioned by her. Such was Catherine's impression on people, that even her enemy, Thomas Cromwell, said of her \"If not for her sex, she could have defied all the heroes of History.\" She successfully appealed for the lives of the rebels involved in the Evil May Day for the sake of their families. Furthermore, Catherine won widespread admiration by starting an extensive programme for the relief of the poor. She was also a patron of Renaissance humanism, and a friend of the great scholars Erasmus of Rotterdam and Saint Thomas More. Some saw her as a martyr.\n\nIn the reign of her daughter Mary I of England, her marriage to Henry VIII was declared \"good and valid\". Her daughter Queen Mary also had several portraits commissioned of Catherine, and it would not by any means be the last time she was painted. After her death, numerous portraits were painted of her, particularly of her speech at the Legatine Trial, a moment accurately rendered in Shakespeare's play about Henry VIII.\n\nHer tomb in Peterborough Cathedral can be seen and there is hardly ever a time when it is not decorated with flowers or pomegranates, her heraldic symbol. It bears the title \"Katharine Queen of England\".\n\nIn the 20th century, George V's wife, Mary of Teck, had her grave upgraded and there are now banners there denoting Catherine as a Queen of England. Every year at Peterborough Cathedral there is a service in her memory. There are processions, prayers, and various events in the Cathedral including processions to Catherine's grave in which candles, pomegranates, flowers and other offerings are placed on her grave. On the service commemorating the 470th anniversary of her death, the Spanish Ambassador to the United Kingdom attended. During the 2010 service a rendition of Catherine of Aragon's speech before the Legatine court was read by Jane Lapotaire. There is a statue of her in her birthplace of Alcalá de Henares, as a young woman holding a book and a rose.\n\nCatherine has remained a popular biographical subject to the present day. The American historian Garrett Mattingly was the author of a popular biography \"Katherine of Aragon\" in 1942. In 1966, Catherine and her many supporters at court were the subjects of \"Catherine of Aragon and her Friends\", a biography by John E. Paul. In 1967, Mary M. Luke wrote the first book of her Tudor trilogy, \"Catherine the Queen\" which portrayed her and the controversial era of English history through which she lived.\n\n\nHer baptismal name was \"Catalina\", but \"Katherine\" was soon the accepted form in England after her marriage to Arthur. Catherine herself signed her name \"Katherine\", \"Katherina\", \"Katharine\" and sometimes \"Katharina\". In a letter to her, Arthur, her husband, addressed her as \"Princess Katerine\". Her daughter Queen Mary I called her \"Quene Kateryn\", in her will. Rarely were names, particularly first names, written in an exact manner during the sixteenth century and it is evident from Catherine's own letters that she endorsed different variations.\nLoveknots built into his various palaces by her husband, Henry VIII, display the initials \"H & K\", as do other items belonging to Henry and Catherine, including gold goblets, a gold salt cellar, basins of gold, and candlesticks. Her tomb in Peterborough Cathedral is marked \"Katharine Queen of England\".\n\nOver the years, numerous artistic and cultural works have been dedicated to Catherine, have been written about her, or have mentioned her, including some by her husband Henry VIII, who wrote \"Grene growth the holy\" about and for her, and Juan Luis Vives, who dedicated \"The Education of Christian Women\" to her.\n\nCatherine of Aragon has been portrayed in film, television, plays, novels, songs, poems, and other creative forms many times, and as a result she has stayed very much in popular memory. There has never been a film or television series in which she is the main character, the nearest is the first episode of \"The Six Wives of Henry VIII\", which is told from her point of view (and in which she is portrayed by Annette Crosbie). William Shakespeare's play \"Henry VIII\" succeeds in recreating with great accuracy Catherine's statement about the legitimacy of her marriage at the court in Blackfriars before King Henry, and Shakespeare's portrayal of Catherine is remarkably sympathetic; however, most of the rest of the play is an attempt to absolve many, especially Henry VIII, and the timing of key incidents (including Catherine's death) is changed and other events are avoided (the play makes Henry nearly an innocent pawn in the hands of a dastardly Cardinal Wolsey, and the play stops short of Anne Boleyn's execution).\n\nAlthough Catherine is often portrayed in film and on stage as having possessed stereotypically Spanish dark hair and eyes and olive complexion, existing portraits and contemporary descriptions depict her with blue eyes, fair skin, and reddish-blonde hair, not uncommon for Spaniards from the northern regions of Spain, including her father's land of Aragon. And she was part English, through her ancestresses Katherine of Lancaster and Philippa of Lancaster, who were daughters of John of Gaunt, 1st Duke of Lancaster.\n\nCatherine often is played with a Spanish accent. From most reports, this is accurate, as she never fully mastered the English language.\n\nIn January, 2013, the National Portrait Gallery in London revealed that its curators had recently discovered that a portrait at Lambeth Palace formerly believed to have been a portrait of Catherine Parr in fact shows Catherine of Aragon. The National Portrait Gallery announced that the painting, which had hung in a private sitting room of the Archbishop of Canterbury since at least the 19th century, would be paired with a portrait of Henry VIII already in the museum's collection, and would remain at the museum on loan.\n\n\nCatherine is the main character in:\n\nCatherine is a character in:\n\nCatherine was portrayed by:\n\n\n\n\n\n"}
{"id": "6943", "url": "https://en.wikipedia.org/wiki?curid=6943", "title": "Cathode ray", "text": "Cathode ray\n\nCathode rays (also called an electron beam or e-beam) are streams of electrons observed in vacuum tubes. If an evacuated glass tube is equipped with two electrodes and a voltage is applied, the glass behind of the positive electrode is observed to glow, due to electrons emitted from and traveling away from the cathode (the electrode connected to the negative terminal of the voltage supply). They were first observed in 1869 by German physicist Johann Hittorf, and were named in 1876 by Eugen Goldstein \"Kathodenstrahlen\", or cathode rays.\n\nElectrons were discovered as the constituents of cathode rays. In 1897, British physicist J. J. Thomson showed the rays were composed of a previously unknown negatively charged particle, which was later named the \"electron\". Cathode ray tubes (CRTs) use a focused beam of electrons deflected by electric or magnetic fields to create the image in a television set.\n\nCathode rays are so named because they are emitted by the negative electrode, or cathode, in a vacuum tube. This contrasts with cations, positively charged ions which are also found in some vacuum tubes and are attracted toward the cathode. To release electrons into the tube, they first must be detached from the atoms of the cathode. In the early cold cathode vacuum tubes, called Crookes tubes, this was done by using a high electrical potential between the anode and the cathode to ionize the residual gas in the tube; the ions were accelerated by the electric field and released electrons when they collided with the cathode. Modern vacuum tubes use thermionic emission, in which the cathode is made of a thin wire filament which is heated by a separate electric current passing through it. The increased random heat motion of the filament knocks electrons out of the surface of the filament, into the evacuated space of the tube.\n\nSince the electrons have a negative charge, they are repelled by the cathode and attracted to the anode. They travel in straight lines through the empty tube. The voltage applied between the electrodes accelerates these low mass particles to high velocities. Cathode rays are invisible, but their presence was first detected in early vacuum tubes when they struck the glass wall of the tube, exciting the atoms of the glass and causing them to emit light, a glow called fluorescence. Researchers noticed that objects placed in the tube in front of the cathode could cast a shadow on the glowing wall, and realized that something must be travelling in straight lines from the cathode. After the electrons reach the anode, they travel through the anode wire to the power supply and back to the cathode, so cathode rays carry electric current through the tube.\n\nThe current in a beam of cathode rays through a tube can be controlled by passing it through a metal screen of wires (a grid) to which a small voltage is applied. The electric field of the wires deflects some of the electrons, preventing them from reaching the anode. Thus a small voltage on the grid can be made to control a much larger voltage on the anode. This is the principle used in vacuum tubes to amplify electrical signals. High speed beams of cathode rays can also be steered and manipulated by electric fields created by additional metal plates in the tube to which voltage is applied, or magnetic fields created by coils of wire (electromagnets). These are used in cathode ray tubes, found in televisions and computer monitors, and in electron microscopes.\n\nAfter the 1654 invention of the vacuum pump by Otto von Guericke, physicists began to experiment with passing high voltage electricity through rarefied air. In 1705, it was noted that electrostatic generator sparks travel a longer distance through low pressure air than through atmospheric pressure air.\n\nIn 1838, Michael Faraday passed a current through a rarefied air filled glass tube and noticed a strange light arc with its beginning at the cathode (negative electrode) and its end are at the anode (positive electrode). In 1857, German physicist and glassblower Heinrich Geissler sucked even more air out with an improved pump, to a pressure of around 10 atm and found that, instead of an arc, a glow filled the tube. The voltage applied between the two electrodes of the tubes, generated by an induction coil, was anywhere between a few kilovolts and 100 kV. These were called Geissler tubes, similar to today's neon signs.\n\nThe explanation of these effects was that the high voltage accelerated electrically charged atoms (ions) naturally present in the air of the tube. At low pressure, there was enough space between the gas atoms that the ions could accelerate to high enough speeds that when they struck another atom they knocked electrons off of it, creating more positive ions and free electrons in a chain reaction, known as a Townsend discharge.\n\nThe positive ions are attracted to the cathode. When they struck it they knocked many electrons out of the metal. The free electrons were all attracted to the anode.\n\nGeissler tubes had enough air in them that the electrons could only travel a tiny distance before colliding with an atom. The electrons in these tubes moved in a slow diffusion process, never gaining much speed, so these tubes didn't produce cathode rays. Instead they produced a colorful glow discharge (as in a modern neon light), caused when the electrons or ions struck gas atoms, exciting their orbital electrons to higher energy levels. The electrons released this energy as light. This process is called fluorescence.\n\nBy the 1870s, British physicist William Crookes and others were able to evacuate tubes to a lower pressure, below 10 atm. These were called Crookes tubes. Faraday had been the first to notice a dark space just in front of the cathode, where there was no luminescence. This came to be called the \"cathode dark space\", \"Faraday dark space\" or \"Crookes dark space\". Crookes found that as he pumped more air out of the tubes, the Faraday dark space spread down the tube from the cathode toward the anode, until the tube was totally dark. But at the anode (positive) end of the tube, the glass of the tube itself began to glow.\n\nWhat was happening was that as more air was pumped from the tube, the electrons could travel farther, on average, before they struck a gas atom. By the time the tube was dark, most of the electrons could travel in straight lines from the cathode to the anode end of the tube without a collision. With no obstructions, these low mass particles were accelerated to high velocities by the voltage between the electrodes.These were the cathode rays.\n\nWhen they reached the anode end of the tube, they were traveling so fast that, although they were attracted to it, they often flew past the anode and struck the back wall of the tube. When they struck atoms in the glass wall, they excited their orbital electrons to higher energy levels, causing them to fluoresce. Later researchers painted the inside back wall with fluorescent chemicals such as zinc sulfide, to make the glow more visible.\n\nCathode rays themselves are invisible, but this accidental fluorescence allowed researchers to notice that objects in the tube in front of the cathode, such as the anode, cast sharp-edged shadows on the glowing back wall. In 1869, German physicist Johann Hittorf was first to realize that something must be traveling in straight lines from the cathode to cast the shadows. Eugen Goldstein named them \"cathode rays\".\n\nAt this time, atoms were the smallest particles known, and were believed to be indivisible. What carried electric currents was a mystery. During the last quarter of the 19th century many experiments were done to determine what cathode rays were. There were two theories. Crookes and Arthur Schuster believed they were particles of \"radiant matter,\" that is, electrically charged atoms. German scientists Eilhard Wiedemann, Heinrich Hertz and Goldstein believed they were \"aether waves\", some new form of electromagnetic radiation, and were separate from what carried the electric current through the tube.\n\nThe debate was resolved in 1897 when J. J. Thomson measured the mass of cathode rays, showing they were made of particles, but were around 1800 times lighter than the lightest atom, hydrogen. Therefore, they were not atoms, but a new particle, the first \"subatomic\" particle to be discovered, which he originally called \"\"corpuscle\"\" but was later named \"electron\", after particles postulated by George Johnstone Stoney in 1874. He also showed they were identical with particles given off by photoelectric and radioactive materials. It was quickly recognized that they are the particles that carry electric currents in metal wires, and carry the negative electric charge of the atom.\n\nThomson was given the 1906 Nobel prize for physics for this work. Philipp Lenard also contributed a great deal to cathode ray theory, winning the Nobel prize for physics in 1905 for his research on cathode rays and their properties.\n\nThe gas ionization (or cold cathode) method of producing cathode rays used in Crookes tubes was unreliable, because it depended on the pressure of the residual air in the tube. Over time, the air was absorbed by the walls of the tube, and it stopped working.\n\nA more reliable and controllable method of producing cathode rays was investigated by Hittorf and Goldstein, and rediscovered by Thomas Edison in 1880. A cathode made of a wire filament heated red hot by a separate current passing through it would release electrons into the tube by a process called thermionic emission. The first true electronic vacuum tubes, invented in 1904, used this hot cathode technique, and they superseded Crookes tubes. These tubes didn't need gas in them to work, so they were evacuated to a lower pressure, around 10 atm (10 Pa). The ionization method of creating cathode rays used in Crookes tubes is today only used in a few specialized gas discharge tubes such as krytrons.\n\nLee De Forest in 1906 found that a small voltage on a grid of metal wires could control a much larger current in a beam of cathode rays passing through a vacuum tube. His invention, called the triode, was the first device that could amplify electric signals, and founded the field of \"electronics\". Vacuum tubes made radio and television broadcasting possible, as well as radar, talking movies, audio recording, and long distance telephone service, and were the foundation of consumer electronic devices until the 1960s when the transistor brought the era of vacuum tubes to a close.\n\nCathode rays are now usually called electron beams. The technology of manipulating electron beams pioneered in these early tubes was applied practically in the design of vacuum tubes, particularly in the invention of the cathode ray tube (CRT) by Ferdinand Braun in 1897 which was used in television sets and oscilloscopes. It is today employed in sophisticated devices such as electron microscopes, electron beam lithography and particle accelerators.\n\nLike a wave, cathode rays travel in straight lines, and produce a shadow when obstructed by objects. Ernest Rutherford demonstrated that rays could pass through thin metal foils, behavior expected of a particle. These conflicting properties caused disruptions when trying to classify it as a wave or particle. Crookes insisted it was a particle, while Hertz maintained it was a wave. The debate was resolved when an electric field was used to deflect the rays by J. J. Thomson. This was evidence that the beams were composed of particles because scientists knew it was impossible to deflect electromagnetic waves with an electric field. These can also create mechanical effects, fluorescence, etc.\n\nLouis de Broglie later (1924) showed in his doctoral dissertation that electrons are in fact much like photons in the respect that they act both as waves and as particles in a dual manner as Einstein had shown earlier for light. The wave-like behaviour of cathode rays was later directly demonstrated using a crystal lattice by Davisson and Germer in 1927.\n\n\n\n\n"}
{"id": "6944", "url": "https://en.wikipedia.org/wiki?curid=6944", "title": "Cathode", "text": "Cathode\n\nA cathode is the electrode from which a conventional current leaves a polarized electrical device. (This definition can be recalled by using the mnemonic \"CCD\" for \"cathode current departs\".) A conventional current describes the direction in which positive electronic charges move. Electrons have a negative charge, so the movement of electrons is opposite to the conventional current flow. Consequently, the mnemonic \"cathode current departs\" also means that electrons flow into the device's cathode.\n\nCathode polarity with respect to the anode can be positive or negative; it depends on how the device operates. Although positively charged cations always move towards the cathode (hence their name) and negatively charged anions move away from it, cathode polarity depends on the device type, and can even vary according to the operating mode. In a device which takes energy (such as recharging a battery), the cathode is negative, and in a device which provides energy (such as discharging a battery), the cathode is positive:\n\nAn electrode through which current flows the other way (into the device) is termed an anode.\n\nThe word was coined in 1834 from the Greek κάθοδος (\"kathodos\"), 'descent' or 'way down', by William Whewell, who had been consulted by Michael Faraday over some new names needed to complete a paper on the recently discovered process of electrolysis. In that paper Faraday explained that when an electrolytic cell is oriented so that electric current traverses the \"decomposing body\" (electrolyte) in a direction \"from East to West, or, which will strengthen this help to the memory, that in which the sun appears to move\", the cathode is where the current leaves the electrolyte, on the West side: \"\"kata\" downwards, \"`odos\" a way ; the way which the sun sets\".\n\nThe use of 'West' to mean the 'out' direction (actually 'out' → 'West' → 'sunset' → 'down', i.e. 'out of view') may appear unnecessarily contrived. Previously, as related in the first reference cited above, Faraday had used the more straightforward term \"exode\" (the doorway where the current exits). His motivation for changing it to something meaning 'the West electrode' (other candidates had been \"westode\", \"occiode\" and \"dysiode\") was to make it immune to a possible later change in the direction convention for current, whose exact nature was not known at the time. The reference he used to this effect was the Earth's magnetic field direction, which at that time was believed to be invariant. He fundamentally defined his arbitrary orientation for the cell as being that in which the internal current would run parallel to and in the same direction as a hypothetical magnetizing current loop around the local line of latitude which would induce a magnetic dipole field oriented like the Earth's. This made the internal current East to West as previously mentioned, but in the event of a later convention change it would have become West to East, so that the West electrode would not have been the 'way out' any more. Therefore, \"exode\" would have become inappropriate, whereas \"cathode\" meaning 'West electrode' would have remained correct with respect to the unchanged direction of the actual phenomenon underlying the current, then unknown but, he thought, unambiguously defined by the magnetic reference. In retrospect the name change was unfortunate, not only because the Greek roots alone do not reveal the cathode's function any more, but more importantly because, as we now know, the Earth's magnetic field direction on which the \"cathode\" term is based is subject to reversals whereas the current direction convention on which the \"exode\" term was based has no reason to change in the future.\n\nSince the later discovery of the electron, an easier to remember, and more durably technically correct (although historically false), etymology has been suggested: cathode, from the Greek \"kathodos\", 'way down', 'the way (down) into the cell (or other device) for electrons'.\n\nThe flow of electrons is almost always from anode to cathode outside of the cell or device, regardless of the cell or device type and operating mode. An exception is when a diode reverse-conducts, either by accident (breakdown of a normal diode) or by design (breakdown of a Zener diode, photo-current of a photodiode).\n\nIn chemistry, a cathode is the electrode of an electrochemical cell at which reduction occurs; a useful mnemonic to remember this is AnOx RedCat (Oxidation at the Anode = Reduction at the Cathode). Another mnemonic is to note the cathode has a 'c', as does 'reduction'. Hence, reduction at the cathode. Perhaps most useful would be to remember cathode corresponds to cation (acceptor) and anode corresponds to anion (donor). The cathode can be negative like when the cell is electrolytic (where electrical energy provided to the cell is being used for decomposing chemical compounds); or positive as when the cell is galvanic (where chemical reactions are used for generating electrical energy). The cathode supplies electrons to the positively charged cations which flow to it from the electrolyte (even if the cell is galvanic, i.e., when the cathode is positive and therefore would be expected to repel the positively charged cations; this is due to electrode potential relative to the electrolyte solution being different for the anode and cathode metal/electrolyte systems in a galvanic cell).\n\nThe cathodic current, in electrochemistry, is the flow of electrons from the cathode interface to a species in solution. The anodic current is the flow of electrons into the anode from a species in solution.\n\nIn an electrolytic cell, the cathode is where the negative polarity is applied to drive the cell. Common results of reduction at the cathode are hydrogen gas or pure metal from metal ions. When discussing the relative reducing power of two redox agents, the couple for generating the more reducing species is said to be more \"cathodic\" with respect to the more easily reduced reagent.\n\nIn a galvanic cell, the cathode is where the positive pole is connected to allow the circuit to be completed: as the anode of the galvanic cell gives off electrons, they return from the circuit into the cell through the cathode.\n\nWhen metal ions are reduced from ionic solution, they form a pure metal surface on the cathode. Items to be plated with pure metal are attached to and become part of the cathode in the electrolytic solution.\n\nIn physics or electronics, a cathode is an electrode that emits electrons into the device. This contrasts with an anode, which accepts electrons.\n\nIn a vacuum tube or electronic vacuum system, the cathode is a metal surface which emits free electrons into the evacuated space. Since the electrons are attracted to the positive nuclei of the metal atoms, they normally stay inside the metal and require energy to leave it; this is called the \"work function\" of the metal. Cathodes are induced to emit electrons by several mechanisms:\n\n\nCathodes can be divided into two types:\n\nA hot cathode is a cathode that is heated by a filament to produce electrons by thermionic emission. The filament is a thin wire of a refractory metal like tungsten heated red-hot by an electric current passing through it. Before the advent of transistors in the 1960s, virtually all electronic equipment used hot-cathode vacuum tubes. Today hot cathodes are used in vacuum tubes in radio transmitters and microwave ovens, to produce the electron beams in older cathode ray tube (CRT) type televisions and computer monitors, in x-ray generators, electron microscopes, and fluorescent tubes.\n\nThere are two types of hot cathodes:\n\nIn order to improve electron emission, cathodes are treated with chemicals, usually compounds of metals with a low work function. Treated cathodes require less surface area, lower temperatures and less power to supply the same cathode current. The untreated tungsten filaments used in early tubes (called \"bright emitters\") had to be heated to 1400 °C (~2500 °F), white-hot, to produce sufficient thermionic emission for use, while modern coated cathodes produce far more electrons at a given temperature so they only have to be heated to 425–600 °C (~800–1100 °F) () There are two main types of treated cathodes:\n\n\nThis is a cathode that is not heated by a filament. They may emit electrons by field electron emission, and in gas-filled tubes by secondary emission. Some examples are electrodes in neon lights, cold-cathode fluorescent lamps (CCFLs) used as backlights in laptops, thyratron tubes, and Crookes tubes. They do not necessarily operate at room temperature; in some devices the cathode is heated by the electron current flowing through it to a temperature at which thermionic emission occurs. For example, in some fluorescent tubes a momentary high voltage is applied to the electrodes to start the current through the tube; after starting the electrodes are heated enough by the current to keep emitting electrons to sustain the discharge.\n\nCold cathodes may also emit electrons by photoelectric emission. These are often called \"photocathodes\" and are used in phototubes used in scientific instruments and image intensifier tubes used in night vision goggles.\n\nIn a semiconductor diode, the cathode is the N–doped layer of the PN junction with a high density of free electrons due to doping, and an equal density of fixed positive charges, which are the dopants that have been thermally ionized. In the anode, the converse applies: It features a high density of free \"holes\" and consequently fixed negative dopants which have captured an electron (hence the origin of the holes).\n\nWhen P and N-doped layers are created adjacent to each other, diffusion ensures that electrons flow from high to low density areas: That is, from the N to the P side. They leave behind the fixed positively charged dopants near the junction. Similarly, holes diffuse from P to N leaving behind fixed negative ionised dopants near the junction. These layers of fixed positive and negative charges are collectively known as the depletion layer because they are depleted of free electrons and holes. The depletion layer at the junction is at the origin of the diode's rectifying properties. This is due to the resulting internal field and corresponding potential barrier which inhibit current flow in reverse applied bias which increases the internal depletion layer field. Conversely, they allow it in forwards applied bias where the applied bias reduces the built in potential barrier.\n\nElectrons which diffuse from the cathode into the P-doped layer, or anode, become what are termed \"minority carriers\" and tend to recombine there with the majority carriers, which are holes, on a timescale characteristic of the material which is the p-type minority carrier lifetime. Similarly, holes diffusing into the N-doped layer become minority carriers and tend to recombine with electrons. In equilibrium, with no applied bias, thermally assisted diffusion of electrons and holes in opposite directions across the depletion layer ensure a zero net current with electrons flowing from cathode to anode and recombining, and holes flowing from anode to cathode across the junction or depletion layer and recombining.\n\nLike a typical diode, there is a fixed anode and cathode in a Zener diode, but it will conduct current in the reverse direction (electrons flow from anode to cathode) if its breakdown voltage or \"Zener voltage\" is exceeded.\n\n"}
{"id": "6945", "url": "https://en.wikipedia.org/wiki?curid=6945", "title": "Chrominance", "text": "Chrominance\n\nChrominance (\"chroma\" or C for short) is the signal used in video systems to convey the color information of the picture, separately from the accompanying luma signal (or Y for short). Chrominance is usually represented as two color-difference components: U = B′ − Y′ (blue − luma) and V = R′ − Y′ (red − luma). Each of these difference components may have scale factors and offsets applied to it, as specified by the applicable video standard. \n\nIn composite video signals, the U and V signals modulate a color subcarrier signal, and the result is referred to as the chrominance signal; the phase and amplitude of this modulated chrominance signal correspond approximately to the hue and saturation of the color. In digital-video and still-image color spaces such as Y′CbCr, the luma and chrominance components are digital sample values.\n\nSeparating RGB color signals into luma and chrominance allows the bandwidth of each to be determined separately. Typically, the chrominance bandwidth is reduced in analog composite video by reducing the bandwidth of a modulated color subcarrier, and in digital systems by chroma subsampling.\n\nThe idea of transmitting a color television signal with distinct luma and chrominance components originated with Georges Valensi, who patented the idea in 1938. Valensi's patent application described:\nThe use of two channels, one transmitting the predominating color (signal T), and the other the mean brilliance (signal t) output from a single television transmitter to be received not only by color television receivers provided with the necessary more expensive equipment, but also by the ordinary type of television receiver which is more numerous and less expensive and which reproduces the pictures in black and white only.\nPrevious schemes for color television systems, which were incompatible with existing monochrome receivers, transmitted RGB signals in various ways.\n\nIn analog television, chrominance is encoded into a video signal using a subcarrier frequency. Depending on the video standard, the chrominance subcarrier may be either quadrature-amplitude-modulated (NTSC and PAL) or frequency-modulated (SECAM).\n\nIn the PAL system, the color subcarrier is 4.43 MHz above the video carrier, while in the NTSC system it is 3.58 MHz above the video carrier. The NTSC and PAL standards are the most commonly used, although there are other video standards that employ different subcarrier frequencies. For example, PAL-M (Brazil) uses a 3.58 MHz subcarrier, and SECAM uses two different frequencies, 4.250 MHz and 4.40625 MHz above the video carrier.\n\nThe presence of chrominance in a video signal is indicated by a color burst signal transmitted on the back porch, just after horizontal synchronization and before each line of video starts. If the color burst signal were visible on a television screen, it would appear as a vertical strip of a very dark olive color. In NTSC and PAL, hue is represented by a phase shift of the chrominance signal relative to the color burst, while saturation is determined by the amplitude of the subcarrier. In SECAM (R′ − Y′) and (B′ − Y′) signals are transmitted alternately and phase does not matter.\n\nChrominance is represented by the U-V color plane in PAL and SECAM video signals, and by the I-Q color plane in NTSC.\n\nDigital video and digital still photography systems sometimes use a luma/chroma decomposition for improved compression. For example, when an ordinary RGB digital image is compressed via the JPEG standard, the RGB colorspace is first converted (by a rotation matrix) to a YCbCr colorspace, because the three components in that space have less correlation redundancy and because the chrominance components can then be subsampled by a factor of 2 or 4 to further compress the image. On decompression, the Y′CbCr space is rotated back to RGB.\n\n"}
{"id": "6946", "url": "https://en.wikipedia.org/wiki?curid=6946", "title": "Chirality (disambiguation)", "text": "Chirality (disambiguation)\n\nChirality (\"handedness\") is a property of asymmetry.\n\nChirality may also refer to:\n\n\n"}
{"id": "6947", "url": "https://en.wikipedia.org/wiki?curid=6947", "title": "Campus", "text": "Campus\n\nA campus is traditionally the land on which a college or university and related institutional buildings are situated. Usually a college campus includes libraries, lecture halls, residence halls, student centers or dining halls, and park-like settings.\n\nA modern campus is a collection of buildings and grounds that belong to a given institution, either academic or non-academic. Examples include the Googleplex and the Apple Campus.\n\nThe word derives from a Latin word for \"field\" and was first used to describe the large field adjacent Nassau Hall of the College of New Jersey (now Princeton University) in 1774. The field separated Princeton from the small nearby town.\n\nSome other American colleges later adopted the word to describe individual fields at their own institutions, but \"campus\" did not yet describe the whole university property. A school might have one space called a campus, one called a field, and another called a yard.\n\nThe tradition of a campus began with the medieval European universities where the students and teachers lived and worked together in a cloistered environment. The notion of the importance of the setting to academic life later migrated to America, and early colonial educational institutions were based on the Scottish and English collegiate system.\n\nThe campus evolved from the cloistered model in Europe to a diverse set of independent styles in the United States. Early colonial colleges were all built in proprietary styles, with some contained in single buildings, such as the campus of Princeton University or arranged in a version of the cloister reflecting American values, such as Harvard's. Both the campus designs and the architecture of colleges throughout the country have evolved in response to trends in the broader world, with most representing several different contemporary and historical styles and arrangements.\n\nThe meaning expanded to include the whole institutional property during the 20th century, with the old meaning persisting into the 1950s in some places.\n\nSometimes the lands on which company office buildings sit, along with the buildings, are called campuses. The Microsoft Campus in Redmond, Washington is a good example. Hospitals, and even airports sometimes use the term to describe the territory of their facilities.\n\nThe word \"campus\" has also been applied to European universities, although most such institutions are characterized by ownership of individual buildings in urban settings rather than park-like lawns in which buildings are placed.\n\n\n"}
{"id": "6948", "url": "https://en.wikipedia.org/wiki?curid=6948", "title": "Crossbow", "text": "Crossbow\n\nA crossbow is a type of weapon based on the bow and consisting of a horizontal bow-like assembly mounted on a stock. It shoots projectiles called bolts or quarrels. The medieval crossbow was called by many names, most of which were derived from the word ballista, a torsion siege engine resembling a crossbow.\n\nHistorically, crossbows played a significant role in the warfare of East Asia, Europe, and the Mediterranean. The earliest crossbows in the world were invented in ancient China and caused a major shift in the role of projectile weaponry. The traditional bow and arrow had long been a specialized weapon that required a considerable training, physical strength, and expertise to operate with any degree of efficiency. In many cultures, bowmen were considered a separate and superior caste, despite usually being drawn from the common class, as their archery skill-set was essentially developed from birth (similar to many horseman cultures) and was impossible to reproduce outside a pre-established cultural tradition, which many nations lacked. In contrast, the crossbow was the first projectile weapon to be simple, cheap, and physically undemanding enough to be operated by large numbers of conscript soldiers, thus enabling virtually any nation to field a potent force of ranged crossbowmen with little expense beyond the cost of the weapons themselves.\n\nIn modern times, crossbows have been largely supplanted by firearms in most roles, but are still widely used for shooting sports, hunting, and when shooting in relative silence is an important consideration.\n\nA crossbow is a bow mounted on a stick (called a tiller or stock) with a mechanism in it that holds the drawn bow string. The earliest designs featured a slot in the stock, down into which the string was placed. To shoot this design, a vertical rod is thrust up through a hole in the bottom of the notch, forcing the string out. This rod is usually attached perpendicular to a rear-facing lever called a trigger or \"tickler\". A later design implemented a rolling cylindrical pawl called a \"nut\" to retain the string. This nut has a perpendicular centre slot for the bolt, and an intersecting axial slot for the string, along with a lower face or slot against which the internal trigger sits. They often also have some form of strengthening internal \"sear\" or trigger face, usually of metal. These \"roller nuts\" were either free-floating in their close-fitting hole across the stock, tied in with a binding of sinew or other strong cording; or mounted on a metal axle or pins. Removable or integral plates of wood, ivory, or metal on the sides of the stock kept the nut in place laterally. Nuts were made of antler, bone, or metal. Bows could be kept taut and ready to shoot for some time with little effort, allowing crossbowmen to aim better.\n\nThe bow (called the \"prod\" or \"lath\" on a crossbow) of early crossbows was made of a single piece of wood, usually ash or yew. Composite bows are made from layers of different material, often wood, horn, and sinew glued together and bound with animal tendon. These composite bows made of several layers are much stronger and more efficient in releasing energy than simple wooden bows. As steel became more widely available in Europe around the 14th century, steel prods came into use.\n\nThe crossbow prod is very short compared to ordinary bows, resulting in a short draw length. This leads to a higher draw weight in order to store the same amount of energy. Furthermore, the thick prods are a bit less efficient at releasing energy, but more energy can be stored by a crossbow. Traditionally, the prod was often lashed to the stock with rope, whipcord, or other strong cording. This cording is called the \"bridle\".\n\nThe strings for a crossbow are typically made of strong fibres that would not tend to fray. Whipcord was very common; however linen, hemp, and sinew were used as well. In wet conditions, twisted mulberry root was occasionally used.\n\nVery light crossbows can be drawn by hand, but heavier types need the help of mechanical devices. The simplest version of mechanical cocking device is a hook attached to a belt, drawing the bow by straightening the legs. Other devices are hinged levers, which either pulled or pushed the string into place, cranked rack-and-pinion devices called \"cranequins\" and multiple cord-and-pulley cranked devices called windlasses.\n\nCrossbows exist in different variants. One way to classify them is the acceleration system, while another is the size and energy, degree of automation or projectiles.\n\nA recurve crossbow is a bow that has tips curving away from the archer. The recurve bow's bent limbs have a longer draw length than an equivalent straight-limbed bow, giving more acceleration to the projectile and less hand shock. Recurved limbs also put greater strain on the materials used to make the bow, and they may make more noise with the shot.\n\nMultiple bow systems have a special system of pulling the sinew via several bows (which can be recurve bows). The workings can be compared to a modern compound bow system. The weapon uses several different bows instead of one bow with a tackle system to achieve a higher acceleration of the sinew via the multiplication with each bow's pulling effect.\n\nA compound crossbow is a modern crossbow and is similar to a compound bow. The limbs are usually much stiffer than those of a recurve crossbow. This limb stiffness makes the compound bow more energy efficient than other bows, but the limbs are too stiff to be drawn comfortably with a string attached directly to them. The compound bow has the string attached to the pulleys, one or both of which has one or more cables attached to the opposite limb. When the string is drawn back, the string causes the pulleys to turn. This causes the pulleys to pull the cables, which in turn causes the limbs to bend and thus store energy. Other types of compound bows use either (one or both) cam shaped or eccentrically mounted pulleys in order to provide a \"let off\", such that the archer is not holding against the maximum draw weight of the bow while trying to aim. But, in a crossbow, the string is held back mechanically, so there is no advantage in providing a let off. Therefore, compound crossbows generally only use pulleys that are both round and concentrically mounted, in order to capture the maximum available energy from the relatively short draw length.\nThe smallest crossbows are pistol crossbows. Others are simple long stocks with the crossbow mounted on them. These could be shot from under the arm. The next step in development was stocks of the shape that would later be used for firearms, which allowed better aiming. The arbalest was a heavy crossbow that required special systems for pulling the sinew via windlasses. For siege warfare, the size of crossbows was further increased to hurl large projectiles, such as rocks, at fortifications. The required crossbows needed a massive base frame and powerful windlass devices. Such devices include the oxybeles. The ballista has torsion springs replacing the elastic prod of the oxybeles, but later also developed into smaller versions. \"Ballista\" is still the root word for crossbow in Romance languages such as Italian (\"balestra\") and Spanish (\"ballesta\").\n\nThe repeating crossbow automated the separate actions of stringing the bow, placing the projectile and shooting. This way the task can be accomplished with a simple one-handed movement, while keeping the weapon stationary. As a result, it is possible to shoot at a faster rate compared to an unmodified version. The Greek Polybolos was an ancient repeating ballista reputedly invented by Dionysius of Alexandria in the 3rd century BC. The Chinese repeating crossbow, Chu Ko Nu, is a handheld crossbow that accomplishes the task with a magazine containing a number of bolts on top. The mechanism is worked by moving a rectangular lever forward and backward. The weapon was mainly used as a weapon against lightly armored soldiers, since it shot small bolts that were often dipped in poison.\n\nA bullet crossbow is a type of handheld crossbow that, instead of arrows or bolts, shoots spherical projectiles made of stone, clay or lead. There are two variants; one has a double string with a pocket for the projectile, and the other has a barrel with a slot for the string.\n\nA slurbow is a type of crossbow with a wood or metal barrel over the top of the stock that is arguably influenced by the emergence of the pistol.\n\nThe arrow-like projectiles of a crossbow are called bolts. These are much shorter than arrows, but can be several times heavier. There is an optimum weight for bolts to achieve maximum kinetic energy, which varies depending on the strength and characteristics of the crossbow, but most could pass through common mail. In ancient times, the bolts of a strong crossbow were usually several times heavier than arrows. Modern bolts are stamped with a proof mark to ensure their consistent weight and do not have fletching, i.e. feathered ends like those commonly seen on arrows. Crossbow bolts can be fitted with a variety of heads, some with sickle-shaped heads to cut rope or rigging; but the most common today is a four-sided point called a quarrel. A highly specialized type of bolt is employed to collect blubber biopsy samples used in biology research.\n\nMost modern crossbows are designed to shoot arrows instead of bolts. Crossbow arrows are of similar construction to ordinary bow arrows, just shorter in length because of reduced power stroke.\n\nCrossbows can also be adapted to shoot lead bullets or rocks, in which case they are called stone-bows. Primarily used for hunting wildfowl, these usually have a double string with a pouch between the strings to hold the projectile.\n\nEven relatively small differences in arrow weight can have a considerable impact on its drop and, conversely, its flight trajectory.\n\nThe ancient Chinese crossbow often included a metal (i.e. bronze or steel) grid serving as iron sights. Modern crossbow sights often use similar technology to modern firearm sights, such as red dot sights and telescopic sights. Many crossbow scopes feature multiple crosshairs to compensate for the significant effects of gravity over different ranges. In most cases, a newly bought crossbow will need to be sighted for accurate shooting.\n\nQuivers can be mounted to hold ammunition. These are often made from plastic and usually hold the bolts in fixed positions along the structure. A popular detachable design consists of a main arm that is attached to the weapon, a plate on one end that secures four or more individual bolts at a point on their shafts and at the other end a cover that secures their heads. This kind of quiver is attached under the front of the crossbow, parallel to the string and is designed to be quickly detached and reattached. Other designs hold bolts underneath the crossbow parallel to the stock, sometimes on either side of the crossbow.\n\nA major cause of the sound of shooting a crossbow is vibration of various components. Crossbow silencers are multiple components placed on high vibration parts, such as the string and limbs, to dampen vibration and suppress the sound of loosing the bolt.\n\n \nThe earliest evidence of crossbows comes from ancient China in the form of crossbow triggers dating back to the 6th century BC. According to Sir Joseph Needham in his Science and Civilisation in China, it is not possible to pinpoint exactly which of the East Asian peoples invented the crossbow. However, there is unquestionable evidence that the crossbow was used for military purposes at least as far back as the Warring States period from the second half of the 4th century BC onwards.\nIn terms of archaeological evidence, bronze crossbow bolts dating from as early as the mid-5th century BC have been found at a Chu burial site in Yutaishan, Hubei. The earliest handheld crossbow stocks with bronze trigger, dating from the 6th century BC, were found in Tomb 3 and 12 at Qufu, Shandong, previously the capital of Lu, ancient China. Other early finds of crossbows were discovered in Tomb 138 at Saobatang, Hunan, dating to the mid-4th century BC. Ammunition for crossbows could have also been spherical. In discussing the astronomical topics such as solar and lunar eclipses, the Western-Han era mathematician and music theorist Jing Fang (78-37 BC) wrote that the moon, shaped like a ball, produced no light and was illuminated only by the sun, which he compared to the shape of a round crossbow bullet.\n\nRepeating crossbows, first mentioned in the \"Records of the Three Kingdoms\", were discovered in 1986 in Tomb 47 at Qinjiazui, Hubei, and were dated to around the 4th century BC. The earliest Chinese document mentioning a crossbow were texts from the 4th to 3rd centuries BC attributed to the followers of Mozi. Sun Tzu's influential treatise on war, \"The Art of War\" (first appearance dated to sometime between 500 BC to 300 BC) refers in chapter five to the traits of crossbows and in chapter twelve, to the usage of crossbows. One of the earliest reliable descriptions of this weapon in warfare is of an ambush in 341 BC, the Battle of Ma-Ling. In the opinion of one authority, the crossbow () had become \"nothing less than the standard weapon of the Han armies\" by the 2nd century BC.\n\nThe earliest textual evidence of the \"handheld\" crossbow used in battle dates to the 4th century BC. Handheld crossbows with complex bronze trigger mechanisms have also been found with the Terracotta Army in the tomb of Qin Shihuang (r. 221–210 BC) that are similar to specimens from the subsequent Han Dynasty (202 BC–220 AD), while crossbowmen described in the Qin and Han Dynasty learned drill formations, some were even mounted as cavalry units, and Han Dynasty writers attributed the success of numerous battles against the Xiongnu to massed crossbow volleys. The bronze triggers were designed in such a way that they were able to store a large amount of energy within the bow when drawn, but was easily shot with little recoil when the trigger were pulled (this allowed it for precision shooting). The metal portions of the crossbow were also mass-produced with precision, with the bronze mechanisms being interchangeable. Finally, the Qin and Han Dynasties also developed crossbow shooting lines, with alternating rows of crossbowmen shooting and reloading in a manner similar to a musket firing line.\nMany archaeological specimens of the crossbow (ranging from 2 to 1 BC) were excavated near Pyongyang. The books of Samgukhsagi (三國史記), Gikhguandji (職官志), Muguahnjo (武官條) and Goryeodjeon (高麗傳) of the Book of Zhou (周書) records detailed descriptions of the usage of crossbows of Goguryeo and Silla. Goguryeo used greatly large versions of the crossbow, called Pohnoh (砲弩) (Stationary) and Geauhnoh (車弩). Korean craftsmanship of crossbows and all other bows were renowned in China. The Tang, who had terrible relations with Goguryeo and Beakje, relied on Silla for high quality crossbows. A Sillan craftsmen, Nosa (弩師) Gutchindjeon (仇珍川) in particular, was taken by the Tang for him to produce high quality crossbows for China. \n\nIn Vietnamese historical legend, general Thục Phán, who ruled over the ancient kingdom of Âu Lạc from 257 to 207 BC, is said to have owed his power to a magic crossbow, capable of shooting thousands of bolts at once.\n\nCrossbow technology for multi-proded crossbows was transferred from the Chinese to Champa, which Champa used in its invasion of the Khmer Empire's Angkor in 1177. China transferred crossbow technology to Champa. When the Chams sacked Angkor they used the Chinese siege crossbow. Crossbows were given to the Chams by China. Crossbows and archery while mounted were instructed to the Cham by a Chinese in 1171.\n\nDifferent varieties of crossbows were also developed, such as the repeating crossbow, multi-shot crossbow, and repeating multi-shot crossbow.\n\nThe earliest reasonably reliable date for the utilization of crossbows in Europe is in ancient Greece from the 5th century BC. The historian Diodorus Siculus (fl. 1st century BC), described the invention of a mechanical arrow shooting catapult (\"katapeltikon\") by a Greek task force in 399 BC. According to the inventor Hero of Alexandria (fl. 1st century AD), who referred to the now lost works of the 3rd-century BC engineer Ctesibius, this weapon was inspired by an earlier hand crossbow, called the \"gastraphetes\" (\"belly shooter\"), which could store more energy than the Greek bows. A detailed description of the \"gastraphetes\", along with a drawing, is found in Heron's technical treatise \"Belopoeica\". The \"gastraphetes\" was powered by a composite bow. It was cocked by resting the stomach in a concavity at the rear of the stock and pressing down with all strength. In this way, considerably more energy can be summoned up than by using only one arm of the archer as in the hand-bow. The heavy weight and bulk of the \"gastraphetes\" may have necessitated a prop to keep it standing, i.e. by mounting it on a defensive wall or using a portable prop.\n\nA third Greek author, Biton (fl. 2nd century BC), whose reliability has been positively reevaluated by recent scholarship, described two advanced forms of the \"gastraphetes\", which he credits to Zopyros, an engineer from southern Italy. Zopyrus has been plausibly equated with a Pythagorean of that name who seems to have flourished in the late 5th century BC. He probably designed his bow-machines on the occasion of the sieges of Cumae and Milet between 421 BC and 401 BC. The bows of these machines already featured a winched pull back system and could apparently throw two missiles at once.\n\nFrom the mid-4th century BC onwards, evidence of the Greek use of crossbows becomes more dense and varied: Arrow-shooting machines (\"katapeltai\") are briefly mentioned by Aeneas Tacticus in his treatise on siegecraft written around 350 BC. An Athenian inventory from 330–329 BC includes catapults bolts with heads and flights. Arrow-shooting machines in action are reported from Philip II's siege of Perinthos in Thrace in 340 BC. At the same time, Greek fortifications began to feature high towers with shuttered windows in the top, presumably to house anti-personnel arrow shooters, as in Aigosthena.\n\nThe transition to torsion catapults, which are not considered crossbows and came to dominate Greek and Roman artillery design, is first evident in inventories of the Athenian arsenal from between 338 and 326 BC.\n\nThe ancient world knew a variety of mechanical hand-held weapons similar to the later medieval crossbow. The exact terminology is a subject of continuing scholarly debate.\nRoman authors like Vegetius (fl. 4th century) note repeatedly the use of arrow shooting weapons such as \"arcuballista\" and \"manuballista\" respectively \"cheiroballista\". While most scholars agree that one or more of these terms refer to handheld mechanical weapons, there is disagreement whether these were flexion bows or torsion powered like the recent Xanten find.\n\nThe Roman commander Arrian (c. 86 – after 146) records in his \"Tactica\" Roman cavalry training for shooting some mechanical handheld weapon from horseback.\nSculptural reliefs from Roman Gaul depict the use of crossbows in hunting scenes. These are remarkably similar to the later medieval crossbow.\n\nThe crossbow is portrayed as a hunting weapon on four Pictish stones from early medieval Scotland (6th to 9th centuries): St. Vigeans no. 1, Glenferness, Shandwick, and Meigle. The use of crossbows in European warfare is again evident from the Battle of Hastings until about the year 1500. They almost completely superseded hand bows in many European armies in the 12th century for a number of reasons.\n\nIn modern tests, longbows showed a higher rate of shot than crossbows of the same energy, due to the difficulty of the shooter in handling the mechanical parts for loading in the same time as the bow was pulled. With lots of training, a longbowman can achieve a high degree of accuracy that is comparable to the much steeper learning curve in aimed shooting with the crossbow. Despite strength training, there are physical limits to the longbow, unlike the crossbow, which can store several times the energy, but will be less efficient in translating stored into kinetic energy due to the thicker spring material. There is no record from the Middle Ages comparing longbowmen and crossbowmen shooting in one army from a similar position, although such occasions are known with visiting Englishmen in the Baltic and Scots in the French army.\n\nIn the armies of Europe, mounted and unmounted crossbowmen, often mixed with slingers, javelineers and archers, occupied a central position in battle formations. Usually they engaged the enemy in offensive skirmishes before an assault of mounted knights. Crossbowmen were also valuable in counterattacks to protect their infantry. The rank of commanding officer of the crossbowmen corps was one of the highest positions in any army of this time. Along with polearm weapons made from farming equipment, the crossbow was also a weapon of choice for insurgent peasants such as the Taborites.\n\nMounted knights armed with lances proved ineffective against formations of pikemen combined with crossbowmen whose weapons could penetrate most knights' armor. The invention of pushlever and ratchet drawing mechanisms enabled the use of crossbows on horseback, leading to the development of new cavalry tactics. Knights and mercenaries deployed in triangular formations, with the most heavily armored knights at the front. Some of these riders would carry small, powerful all-metal crossbows of their own. Crossbows were eventually replaced in warfare by more powerful gunpowder weapons, although early guns had slower rates of fire and much worse accuracy than contemporary crossbows. Later, similar competing tactics would feature harquebusiers or musketeers in formation with pikemen (pike and shot), pitted against cavalry firing pistols or carbines.\n\nThe Saracens called the crossbow \"qaws Ferengi\", or \"Frankish bow\", as the Crusaders used the crossbow against the Arab and Turkic horsemen with remarkable success. The adapted crossbow was used by the Islamic armies in defence of their castles. Later, footstrapped versions became very popular among the Muslim armies in Iberia. During the Crusades, Europeans were exposed to Saracen composite bows, made from layers of different material—often wood, horn and sinew—glued together and bound with animal tendon. These composite bows could be much more powerful than wooden bows, and were adopted for crossbow prods across Europe. Crossbow prods could be more easily waterproofed than hand bows, which was essential in the humid European climate.\n\nIn Western Africa and Central Africa, crossbows served as a scouting weapon and for hunting, with enslaved Africans bringing this technology to natives in America. In the American South, the crossbow was used for hunting and warfare when firearms or gunpowder were unavailable because of economic hardships or isolation. In the North of Northern America, light hunting crossbows were traditionally used by the Inuit. These are technologically similar to the African derived crossbows, but have a different route of influence.\n\nThe native Montagnards of Vietnam's Central Highlands were also known to have used crossbows, as both a tool for hunting, and later, an effective weapon against the Viet Cong during the Vietnam War. Montagnard fighters armed with crossbows proved a highly valuable asset to the US Special Forces operating in Vietnam, and it was not uncommon for the Green Berets to integrate Montagnard crossbowmen into their strike teams.\n\nThe French, and the British used a Sauterelle (French for grasshopper) in World War I. It was lighter and more portable than the Leach Trench Catapult, but less powerful. It weighed and could throw an F1 grenade or Mills bomb . The Sauterelle replaced the Leach Catapult in British service and was in turn replaced in 1916 by the 2 inch Medium Trench Mortar and Stokes mortar.\n\nCrossbows are used for shooting sports and bowhunting in modern archery and for blubber biopsy samples in scientific research. In some countries such as Canada or the United Kingdom, they may be less heavily regulated than firearms, and thus more popular for hunting; some jurisdictions have bow and/or crossbow only seasons.\n\nIn modern times, crossbows are no longer used for assassinations, but there are still some applications. For example, in the Americas, the Peruvian army (Ejército) equips some soldiers with crossbows and rope, to establish a zip-line in difficult terrain. In Brazil the CIGS (Jungle Warfare Training Center) also trains soldiers in the use of crossbows. In the United States, SAA International Ltd manufacture a 150 ft·lb crossbow-launched version of the U.S. Army type classified Launched Grapnel Hook (LGH), among other mine countermeasure solutions designed for the middle-eastern theatre. It has been successfully evaluated in Cambodia and Bosnia. It is used to probe for and detonate tripwire initiated mines and booby traps at up to 50 meters. The concept is similar to the LGH device originally only fired from a rifle, as a plastic retrieval line is attached. Reusable up to 20 times, the line can be reeled back in without exposing oneself. The device is of particular use in tactical situations where noise discipline is important.\nIn Europe, British-based Barnett International supplied crossbows to Serbian forces which according to \"The Guardian\" were later used \"in ambushes and as a counter-sniper weapon\", against the Kosovo Liberation Army during the Kosovo War in the areas of Pec and Djakovica, south west of Kosovo. Whitehall launched an investigation, though the department of trade and industry established that not being \"on the military list\" crossbows were not covered by such export regulations. Paul Beaver of Jane's defence publications commented that, \"They are not only a silent killer, they also have a psychological effect\". On 15 February 2008, Serbian Minister of Defence Dragan Sutanovac was pictured testing a Barnett crossbow during a public exercise of the Serbian army's Special Forces in Nis, 200 km south of capital Belgrade. Special forces in both Greece and Turkey also continue to employ the crossbow. Spain's Green Berets still use the crossbow as well.\n\nIn Asia, some Chinese armed forces use crossbows, including the special force Snow Leopard Commando Unit of the People's Armed Police and the People's Liberation Army. One justification for this comes in the crossbow's ability to stop persons carrying explosives without risk of causing detonation. During the Xinjiang riots of July 2009, crossbows were used alongside modern military hardware to quell protests. The Indian Navy's Marine Commando Force were equipped until the late 1980s with crossbows supplied with cyanide-tipped bolts, as an alternative to suppressed handguns.\n\nWith a crossbow, archers could release a draw force far in excess of what they could have handled with a bow. Furthermore, the crossbow could hold the tension for a long time, whereas even the strongest longbowman could only hold a drawn bow for a short period of time. The ease of use of a crossbow allows it to be used effectively with little training, while other types of bows take far more skill to shoot accurately. The disadvantage is the greater weight and clumsiness compared to a bow, as well as the slower rate of shooting and the lower efficiency of the acceleration system, but there would be reduced elastic hysteresis, making the crossbow a more accurate weapon.\n\nCrossbows have a much smaller draw length than bows. This means that for the same energy to be imparted to the arrow (or bolt), the crossbow has to have a much higher draw weight.\n\nA direct comparison between a fast hand-drawn replica crossbow and a longbow show a 6:10 rate of shooting or a 4:9 rate within 30 seconds and comparable weapons.\n\nCan. 29 of the Second Lateran Council under Pope Innocent II in 1139 banned the use of crossbows, as well as slings and bows, against Christians.\n\nToday, the crossbow often has a complicated legal status due to the possibility of lethal use and its similarities to both firearms and archery weapons. While some jurisdictions regard crossbows the same as firearms, many others do not require any sort of license to own a crossbow. The legality of using a crossbow for hunting varies widely around the world, and even within different jurisdictions of some federal countries.\n\nFor example, in Canada you do not need a valid licence or registration certificate to possess any other type of bow, including a crossbow that is longer than 500 mm and that requires the use of both hands.\n\n\n"}
{"id": "6949", "url": "https://en.wikipedia.org/wiki?curid=6949", "title": "Carbamazepine", "text": "Carbamazepine\n\nCarbamazepine (CBZ), sold under the tradename Tegretol among others, is a medication used primarily in the treatment of epilepsy and neuropathic pain. It is not effective for absence seizures or myoclonic seizures. It is used in schizophrenia along with other medications and as a second line agent in bipolar disorder. Carbamazepine appears to work as well as phenytoin and valproate.\nCommon side effects include nausea and drowsiness. Serious side effects may include skin rashes, decreased bone marrow function, suicidal thoughts, or confusion. It should not be used in those with a history of bone marrow problems. Use during pregnancy may cause harm to the baby; however stopping it in pregnant women with seizures is not recommended. Its use during breastfeeding is not recommended. Care should be taken in those with either kidney or liver problems.\nCarbamazepine was discovered in 1953 by Swiss chemist Walter Schindler. It was first marketed in 1962. It is available as a generic medication and is not very expensive. It is on the World Health Organization's List of Essential Medicines, the most effective and safe medicines needed in a health system. The wholesale cost in the developing world is between 0.01 and 0.07 USD per dose as of 2014.\n\nCarbamazepine is typically used for the treatment of seizure disorders and neuropathic pain. It is used off-label as a second-line treatment for bipolar disorder and in combination with an antipsychotic in some cases of schizophrenia when treatment with a conventional antipsychotic alone has failed. It is not effective for absence seizures or myoclonic seizures.\n\nIn the United States, the FDA-approved medical uses are epilepsy (including partial seizures, generalized tonic-clonic seizures and mixed seizures), trigeminal neuralgia, and manic and mixed episodes of bipolar I disorder.\n\nThe drug is also claimed to be effective for ADHD.\n\nAs of 2014 a controlled release formulation was available for which there is tentative evidence showing fewer side effects and unclear evidence with regard to whether there is a difference in efficacy.\n\nIn the US, the label for carbamazepine contains warnings concerning:\n\nCommon adverse effects may include drowsiness, dizziness, headaches and migraines, motor coordination impairment, nausea, vomiting, and/or constipation. Alcohol use while taking carbamazepine may lead to enhanced depression of the central nervous system. Less common side effects may include increased risk of seizures in people with mixed seizure disorders, abnormal heart rhythms, blurry or double vision. Also, rare case reports of an auditory side effect have been made, whereby patients perceive sounds about a semitone lower than previously; this unusual side effect is usually not noticed by most people, and disappears after the person stops taking carbamazepine.\n\nCarbamazepine has a potential for drug interactions; caution should be used in combining other medicines with it, including other antiepileptics and mood stabilizers. Lower levels of carbamazepine are seen when administrated with phenobarbital, phenytoin, or primidone, which can result in breakthrough seizure activity. Carbamazepine, as a CYP450 inducer, may increase clearance of many drugs, decreasing their concentration in the blood to subtherapeutic levels and reducing their desired effects. Drugs that are more rapidly metabolized with carbamazepine include warfarin, lamotrigine, phenytoin, theophylline, and valproic acid. Drugs that decrease the metabolism of carbamazepine or otherwise increase its levels include erythromycin, cimetidine, propoxyphene, and calcium channel blockers. Carbamazepine also increases the metabolism of the hormones in birth control pills and can reduce their effectiveness, potentially leading to unexpected pregnancies. As a drug that induces cytochrome P450 enzymes, it accelerates elimination of many benzodiazepines and decreases their action.\n\nValproic acid and valnoctamide both inhibit microsomal epoxide hydrolase (MEH), the enzyme responsible for the breakdown of carbamazepine-10,11 epoxide into inactive metabolites. By inhibiting MEH, valproic acid and valnoctamide cause a build-up of the active metabolite, prolonging the effects of carbamazepine and delaying its excretion.\n\nGrapefruit juice raises the bioavailability of carbamazepine by inhibiting CYP3A4 enzymes in the gut wall and in the liver. Carbamazepine increases the processing of methadone resulting in lower blood levels.\n\nDangerous and potentially fatal skin reactions, including Stevens–Johnson syndrome and toxic epidermal necrolysis, caused by carbamazepine therapy are significantly more common in patients with a particular human leukocyte antigen allele, HLA-B*1502. Odds ratios for the development of Stevens-Johnson syndrome or toxic epidermal necrolysis in patients who carry the allele can be in the double, triple or even quadruple digits, depending on the population studied. HLA-B*1502 occurs almost exclusively in patients with ancestry across broad areas of Asia, but has a very low or absent frequency in European, Japanese, Korean and African populations. However, the HLA-A*31:01 allele has been shown to be a strong predictor of both mild and severe adverse reactions to carbamazepine among Japanese and Europeans.\n\nCarbamazepine is relatively slowly but well absorbed after oral administration. Its plasma half-life is about 30 hours when it is given as single dose, but it is a strong inducer of hepatic enzymes and the plasma half-life shortens to about 15 hours when it is given repeatedly. \n\nCarbamazepine is a sodium channel blocker. It binds preferentially to voltage-gated sodium channels in their inactive conformation, which prevents repetitive and sustained firing of an action potential. Carbamazepine has effects on serotonin systems but the relevance to its antiseizure effects is uncertain. There is evidence that it is a serotonin releasing agent and possibly even a serotonin reuptake inhibitor.\n\nCarbamazepine was discovered by chemist Walter Schindler at J.R. Geigy AG (now part of Novartis) in Basel, Switzerland, in 1953. It was first marketed as a drug to treat epilepsy in Switzerland in 1963 under the brand name \"Tegretol\"; its use for trigeminal neuralgia (formerly known as tic douloureux) was introduced at the same time. It has been used as an anticonvulsant and antiepileptic in the UK since 1965, and has been approved in the US since 1968.\n\nIn 1971, Drs. Takezaki and Hanaoka first used carbamazepine to control mania in patients refractory to antipsychotics (lithium was not available in Japan at that time). Dr. Okuma, working independently, did the same thing with success. As they were also epileptologists, they had some familiarity with the antiaggression effects of this drug. Carbamazepine was studied for bipolar disorder throughout the 1970s.\n\nCarbamazepine has been detected in wastewater effluent. Field and laboratory studies have been conducted to understand the accumulation of carbamazepine in food plants grown in soil treated with sludge, which vary with respect to the concentrations of carbamazepine present in sludge and in the concentrations of sludge in the soil; taking into account only studies that used concentrations normally found, a 2014 review found that \"the accumulation of carbamazepine into plants grown in soil amended with biosolids poses a \"de minimis\" risk to human health according to the approach.\"\n\nCarbamazepine is available worldwide under many brand names.\n\n\n"}
{"id": "6951", "url": "https://en.wikipedia.org/wiki?curid=6951", "title": "CCIR", "text": "CCIR\n\nCCIR is a four-letter abbreviation that may stand for:\n\n\n"}
{"id": "6955", "url": "https://en.wikipedia.org/wiki?curid=6955", "title": "Chalcedonian Definition", "text": "Chalcedonian Definition\n\nThe Chalcedonian Definition (also called the Chalcedonian Creed) was adopted at the Council of Chalcedon in A.D. 451. Chalcedon was an early centre of Christianity located in Asia Minor (modern Turkey). The Council was the fourth of the Ecumenical Councils that are accepted by Chalcedonian churches which include the Eastern Orthodox, Catholic, and most Protestant churches. It was the first Council \"not\" to be recognised by any Oriental Orthodox church; these churches may be classified as non-Chalcedonian.\n\nThe Definition defines that Christ is 'acknowledged in two natures', which 'come together into one person and one hypostasis'. The formal definition of 'two natures' in Christ was understood by the critics of the council at the time, and is understood by many historians and theologians today, to side with western and Antiochene Christology and to diverge from the teaching of Cyril of Alexandria, who always stressed that Christ is 'one'. However, a modern analysis of the sources of the creed (by A. de Halleux, in Revue Theologique de Louvain 7, 1976) and a reading of the acts, or proceedings, of the council (recently translated into English) show that the bishops considered Cyril the great authority and that even the language of 'two natures' derives from him.\n\nThe Chalcedonian Definition was written amid controversy between the western and eastern churches over the meaning of the Incarnation (see Christology), the ecclesiastical influence of the emperor, and the supremacy of the Bishop of Rome. The western churches readily accepted the creed, but some eastern churches did not.\n\nIt became standard orthodox doctrine. However the Coptic Church of Alexandria dissented, holding to Cyril of Alexandria's preferred formula for the oneness of Christ’s nature in the incarnation of God the Word as \"out of two natures\". Cyril's language is not consistent and he may have countenanced the view that it is possible to contemplate in theory two natures after the incarnation, but the Church of Alexandria felt that the Definition should have stated that Christ be acknowledged \"out of two natures\" rather than \"in two natures\".\n\nThis miaphysite position, historically characterised by Chalcedonian followers as \"monophysitism\" though this is denied by the dissenters, formed the basis for the distinction from other churches of the Coptic Church of Egypt and Ethiopia and the \"Jacobite\" churches of Syria and Armenia (see Oriental Orthodoxy).\n\nThe key section runs:<br>\nFollowing, then, the holy Fathers, we all unanimously teach that our Lord Jesus Christ is to us One and the same Son, the Self-same Perfect in Godhead, the Self-same Perfect in Manhood; truly God and truly Man; the Self-same of a rational soul and body; co-essential with the Father according to the Godhead, the Self-same co-essential with us according to the Manhood; like us in all things, sin apart; before the ages begotten of the Father as to the Godhead, but in the last days, the Self-same, for us and for our salvation (born) of Mary the Virgin Theotokos as to the Manhood; One and the Same Christ, Son, Lord, Only-begotten; acknowledged in Two Natures unconfusedly, unchangeably, indivisibly, inseparably; the difference of the Natures being in no way removed because of the Union, but rather the properties of each Nature being preserved, and (both) concurring into One Person and One Hypostasis; not as though He were parted or divided into Two Persons, but One and the Self-same Son and Only-begotten God, Word, Lord, Jesus Christ; even as from the beginning the prophets have taught concerning Him, and as the Lord Jesus Christ Himself hath taught us, and as the Symbol of the Fathers hath handed down to us.\nThe full text of the definition which reaffirms the decisions of the Council of Ephesus, the pre-eminence of the Creed of Nicaea (325) and the further definitions of the Council of Constantinople (381) can be found here It also affirms the authority of two of Cyril of Alexandria's letters and the Tome of Leo written against Eutyches and sent to Archbishop Flavian of Constantinople in 449.\n\n"}
{"id": "6956", "url": "https://en.wikipedia.org/wiki?curid=6956", "title": "Conservation law", "text": "Conservation law\n\nIn physics, a conservation law states that a particular measurable property of an isolated physical system does not change as the system evolves over time. Exact conservation laws include conservation of energy, conservation of linear momentum, conservation of angular momentum, and conservation of electric charge. There are also many approximate conservation laws, which apply to such quantities as mass, parity, lepton number, baryon number, strangeness, hypercharge, etc. These quantities are conserved in certain classes of physics processes, but not in all.\n\nA local conservation law is usually expressed mathematically as a continuity equation, a partial differential equation which gives a relation between the amount of the quantity and the \"transport\" of that quantity. It states that the amount of the conserved quantity at a point or within a volume can only change by the amount of the quantity which flows in or out of the volume.\n\nFrom Noether's theorem, each conservation law is associated with a symmetry in the underlying physics.\n\nConservation laws are fundamental to our understanding of the physical world, in that they describe which processes can or cannot occur in nature. For example, the conservation law of energy states that the total quantity of energy in an isolated system does not change, though it may change form. In general, the total quantity of the property governed by that law remains unchanged during physical processes. With respect to classical physics, conservation laws include conservation of energy, mass (or matter), linear momentum, angular momentum, and electric charge. With respect to particle physics, particles cannot be created or destroyed except in pairs, where one is ordinary and the other is an antiparticle. With respect to symmetries and invariance principles, three special conservation laws have been described, associated with inversion or reversal of space, time, and charge.\n\nConservation laws are considered to be fundamental laws of nature, with broad application in physics, as well as in other fields such as chemistry, biology, geology, and engineering.\n\nMost conservation laws are exact, or absolute, in the sense that they apply to all possible processes. Some conservation laws are partial, in that they hold for some processes but not for others.\n\nOne particularly important result concerning conservation laws is Noether's theorem, which states that there is a one-to-one correspondence between each one of them and a differentiable symmetry of nature. For example, the conservation of energy follows from the time-invariance of physical systems, and the conservation of angular momentum arises from the fact that physical systems behave the same regardless of how they are oriented in space.\n\nA partial listing of physical conservation equations due to symmetry that are said to be exact laws, or more precisely \"have never been proven to be violated:\"\n\nThere are also approximate conservation laws. These are approximately true in particular situations, such as low speeds, short time scales, or certain interactions.\n\n\nThe total amount of some conserved quantity in the universe could remain unchanged if an equal amount were to appear at one point \"A\" and simultaneously disappear from another separate point \"B\". For example, an amount of energy could appear on Earth without changing the total amount in the Universe if the same amount of energy were to disappear from a remote region of the Universe. This weak form of \"global\" conservation is really not a conservation law because it is not Lorentz invariant, so phenomena like the above do not occur in nature. Due to Special Relativity, if the appearance of the energy at \"A\" and disappearance of the energy at \"B\" are simultaneous in one inertial reference frame, they will not be simultaneous in other inertial reference frames moving with respect to the first. In a moving frame one will occur before the other; either the energy at \"A\" will appear \"before\" or \"after\" the energy at \"B\" disappears. In both cases, during the interval energy will not be conserved. \n\nA stronger form of conservation law requires that, for the amount of a conserved quantity at a point to change, there must be a flow, or \"flux\" of the quantity into or out of the point. For example, the amount of electric charge in a volume is never found to change without an electric current into or out of the volume that carries the difference in charge. Since it only involves continuous \"local\" changes, this stronger type of conservation law is Lorentz invariant; a quantity conserved in one reference frame is conserved in all moving reference frames. This is called a \"local conservation\" law. Local conservation also implies global conservation; that the total amount of the conserved quantity in the Universe remains constant. All of the conservation laws listed above are local conservation laws. A local conservation law is expressed mathematically by a \"continuity equation\", which states that the change in the quantity in a volume is equal to the total net \"flux\" of the quantity through the surface of the volume. The following sections discuss continuity equations in general.\n\nIn continuum mechanics, the most general form of an exact conservation law is given by a continuity equation. For example, conservation of electric charge \"q\" is\n\nwhere ∇⋅ is the divergence operator, \"ρ\" is the density of \"q\" (amount per unit volume), j is the flux of \"q\" (amount crossing a unit area in unit time), and \"t\" is time.\n\nIf we assume that the motion u of the charge is a continuous function of position and time, then\n\nIn one space dimension this can be put into the form of a homogeneous first-order quasilinear hyperbolic equation:\n\nwhere the dependent variable \"y\" is called the \"density\" of a \"conserved quantity\", and \"A(y)\" is called the \"current jacobian\", and the subscript notation for partial derivatives has been employed. The more general inhomogeneous case:\n\nis not a conservation equation but the general kind of balance equation describing a dissipative system. The dependent variable \"y\" is called a \"nonconserved quantity\", and the inhomogeneous term \"s(y,x,t)\" is the-\"source\", or dissipation. For example, balance equations of this kind are the momentum and energy Navier-Stokes equations, or the entropy balance for a general isolated system.\n\nIn the one-dimensional space a conservation equation is a first-order quasilinear hyperbolic equation that can be put into the \"advection\" form:\n\nwhere the dependent variable \"y(x,t)\" is called the density of the \"conserved\" (scalar) quantity (c.q.(d.) = conserved quantity (density)), and \"a(y)\" is called the current coefficient, usually corresponding to the partial derivative in the conserved quantity of a current density (c.d.) of the conserved quantity \"j(y)\":\n\nIn this case since the chain rule applies:\n\nthe conservation equation can be put into the current density form:\n\nIn a space with more than one dimension the former definition can be extended to an equation that can be put into the form:\n\nwhere the \"conserved quantity\" is \"y(r,t)\", \"formula_11\" denotes the scalar product, \"∇\" is the nabla operator, here indicating a gradient, and \"a(y)\" is a vector of current coefficients, analogously corresponding to the divergence of a vector c.d. associated to the c.q. j(y):\n\nThis is the case for the continuity equation:\n\nHere the conserved quantity is the mass, with density \"ρ\"(r,t) and current density \"ρ\"u, identical to the momentum density, while u(r,t) is the flow velocity.\n\nIn the general case a conservation equation can be also a system of this kind of equations (a vector equation) in the form:\n\nwhere y is called the \"conserved\" (vector) quantity, ∇ y is its gradient, 0 is the zero vector, and A(y) is called the Jacobian of the current density. In fact as in the former scalar case, also in the vector case A(y) usually corresponding to the Jacobian of a current density matrix J(y):\n\nand the conservation equation can be put into the form:\n\nFor example, this the case for Euler equations (fluid dynamics). In the simple incompressible case they are:\n\nwhere:\n\nIt can be shown that the conserved (vector) quantity and the c.d. matrix for these equations are respectively:\n\nwhere \"formula_19\" denotes the outer product.\n\nConservation equations can be also expressed in integral form: the advantage of the latter is substantially that it requires less smoothness of the solution, which paves the way to weak form, extending the class of admissible solutions to include discontinuous solutions. By integrating in any space-time domain the current density form in 1-D space:\n\nand by using Green's theorem, the integral form is:\n\nIn a similar fashion, for the scalar multidimensional space, the integral form is:\n\nwhere the line integration is performed along the boundary of the domain, in an anticlock-wise manner.\n\nMoreover, by defining a test function φ(r,t) continuously differentiable both in time and space with compact support, the weak form can be obtained pivoting on the initial condition. In 1-D space it is:\n\nNote that in the weak form all the partial derivatives of the density and current density have been passed on to the test function, which with the former hypothesis is sufficiently smooth to admit these derivatives.\n\n\n\n\n"}
{"id": "6959", "url": "https://en.wikipedia.org/wiki?curid=6959", "title": "Chord", "text": "Chord\n\nChord may refer to:\n\n\nChord may also refer to:\n\nThe Chords may refer to:\n\nChords may refer to:\n\n"}
{"id": "6960", "url": "https://en.wikipedia.org/wiki?curid=6960", "title": "Car Talk", "text": "Car Talk\n\nCar Talk is a Peabody Award-winning radio talk show broadcast weekly on NPR stations and elsewhere. Its subjects were automobiles and automotive repair, discussed often in a humorous way. It was hosted by brothers Tom and Ray Magliozzi, known also as \"Click and Clack, the Tappet Brothers\". The show was produced from 1977 to October 2012, when the Magliozzi brothers retired. Edited reruns (which are introduced as \"The Best of Car Talk\") continue to be available for weekly airing on NPR affiliates, although in July 2016 the network announced its intention to end the broadcasts after September 30, 2017.\n\n\"Car Talk\" was presented in the form of a call-in radio show: listeners called in with questions related to motor vehicle maintenance and repair. Most of the advice sought was diagnostic, with callers describing symptoms and demonstrating sounds of an ailing vehicle while the Magliozzis made an attempt to identify the malfunction over the telephone and give advice on how to fix it. While the hosts peppered their call-in sessions with jokes directed at both the caller and at themselves, the Magliozzis were usually able to arrive at a diagnosis. However, when they were stumped, they attempted anyway with an answer they claimed was \"\"unencumbered by the thought process\"\", the official motto of the show.\n\nEdited reruns are carried on XM Satellite Radio via both the Public Radio and NPR Now channels.\n\nThe \"Car Talk\" theme music was \"Dawggy Mountain Breakdown\" by bluegrass artist David Grisman.\n\nThroughout the program, listeners were encouraged to dial the toll-free telephone number, 1-888-CAR-TALK (1-888-227-8255), which connected to a 24-hour answering service. Although the approximately 2,000 queries received each week were screened by the \"Car Talk\" staff, the questions were unknown to the Magliozzis in advance as \"that would entail researching the right answer, which is what? ... Work.\" Producers selected and contacted the callers several days ahead of the show's Wednesday taping to arrange the segment. The caller spoke briefly to a producer before being connected live with the hosts and was given little coaching other than being told to be prepared to talk, not to use any written preparation and to \"have fun\". The show deliberately taped more callers than it had time to air each week in order to be able to choose the best ones for broadcast. Those segments that did make it to air were generally edited for time. For the last four years of the show, new shows included previously broadcast segments as much as 10 years old. The re-used segments, including re-used puzzlers, were not acknowledged as old material and sometimes new caller material was mixed in alongside the recycled calls.\n\nThe show originally consisted of two segments with a break in between but was changed to three segments. After the shift to the three-segment format, it became a running joke to refer to the last segment as \"the third half\" of the program.\n\nThe show opened with a short comedy segment, typically jokes sent in by listeners, followed by eight call-in sessions. The hosts ran a contest called the \"Puzzler\", in which a riddle, sometimes car-related, was presented. The answer to the previous week's \"Puzzler\" was given at the beginning of the \"second half\" of the show, and a new \"Puzzler\" was given at the start of the \"third half\". The hosts gave instructions to listeners to write answers addressed to \"Puzzler Tower\" on some non-existent or expensive object, such as a \"$26 bill\" or an advanced digital SLR camera. This gag initially started as suggestions that the answers be written \"on the back of a $20 bill\". A running gag concerned Tom's inability to remember the previous week's \"Puzzler\" without heavy prompting from Ray. For each puzzler, one correct answer was chosen at random, with the winner receiving a $26 gift certificate to the \"Car Talk\" store, referred to as the \"Shameless Commerce Division\". It was originally $25, but was increased for inflation after a few years. Originally, the winner received a specific item from the store, but it soon changed to a gift certificate to allow the winner to choose the item they wanted (though Tom often made an item suggestion).\n\nA recurring feature was \"Stump the Chumps,\" in which the hosts revisited a caller from a previous show to determine the accuracy and the effect, if any, of their advice. A similar feature began in May 2001, \"Where Are They Now, Tommy?\" It began with a comical musical theme with a sputtering, backfiring car engine and a horn as a backdrop. Tom then announced who the previous caller was, followed by a short replay of the essence of the previous call, preceded and followed by harp music often used in other audiovisual media to indicate recalling and returning from a dream. The hosts then greeted the previous caller, confirmed that they had not spoken since their previous appearance and asked them if there had been any influences on the answer they were about to relate, such as arcane bribes by the NPR staff. The repair story was then discussed, followed by a fanfare and applause if the Tappet Brothers' diagnosis was correct, or a wah-wah-wah music piece mixed with a car starter operated by a weak battery (an engine which wouldn't start) if the diagnosis was wrong. The hosts then thanked the caller for their return appearance.\n\nThe brothers also had an official Animal-Vehicle Biologist and Wildlife Guru named Kieran Lindsey. She answered questions like \"How do I remove a snake from my car?\" and offered advice on how those living in cities and suburbs could reconnect with wildlife.\n\nIn addition to at least one on-orbit call, the Brothers once received a call asking advice on winterizing an electric car. When they asked what kind of car, the caller stated it was a \"kit car\", a $400 million \"kit car\". It was a joke call from the Jet Propulsion Laboratory concerning the preparation of the Mars rover for the oncoming Martian winter. Click and Clack have also been featured in editorial cartoons, including one where a befuddled NASA engineer called them to ask how to fix the Space Shuttle.\n\nHumor and wisecracking pervaded the program. Tom and Ray are known for their self-deprecating humor, often joking about the supposedly poor quality of their advice and the show in general. They also commented at the end of each show: \"Well, it's happened again—you've wasted another perfectly good hour listening to \"Car Talk\".\"\n\nAt some point in almost every show, usually when giving the address for the Puzzler answers or fan mail, Ray mentioned Cambridge, Massachusetts (where the show originated), at which point Tom reverently interjected with a tone of civic pride, \"Our fair city\". Ray invariably mocked \"'Cambridge, MA', the United States Postal Service's two-letter abbreviation for 'Massachusetts\"', by pronouncing the \"MA\" as a word.\n\nPreceding each break in the show, one of the hosts led up to the network identification with a humorous take on a disgusted reaction of some usually famous person to hearing that identification. The full line went along the pattern of, for example, \"And even though Roger Clemens stabs his radio with a syringe whenever he hears \"us\" say it, this is NPR: National Public Radio\" (later just \"... this is NPR\").\n\nAt one point in the show, often after the break, Ray usually stated that: \"Support for this show is provided by,\" followed by an absurd fundraiser.\n\nThe ending credits of the show started with thanks to the colorfully nicknamed actual staffers: producer Doug \"the subway fugitive, not a slave to fashion, bongo boy frogman\" Berman; \"John 'Bugsy' Lawlor, just back from the ...\" every week a different eating event with rhyming foodstuff names; David \"Calves of Belleville\" Greene; Catherine \"Frau Blücher\" Fenollosa, whose name caused a horse to neigh and gallop (an allusion to a running gag in the movie \"Young Frankenstein\"); and Carly \"High Voltage\" Nix, among others. Following the real staff was a lengthy list of pun-filled fictional staffers and sponsors such as statistician Marge Innovera (\"margin of error\"), customer care representative Haywood Jabuzoff (\"Hey, would ya buzz off\"), meteorologist Claudio Vernight (\"cloudy overnight\"), optometric firm C. F. Eye Care (\"see if I care\"), Russian chauffeur Pikup Andropov (\"pick up and drop off\"), Leo Tolstoy biographer Warren Peace (\"War and Peace\"), hygiene officer and chief of the Tokyo office Oteka Shawa (\"oh take a shower\"), Swedish snowboard instructor Soren Derkeister (\"sore in the keister\"), law firm Dewey, Cheetham & Howe (\"Do we cheat 'em? And how!\"), and many, many others, usually concluding with Erasmus B. Dragon (\"Her ass must be draggin'\"), whose job title varied, but who was often said to be head of the show's working mothers' support group. They sometimes advised that \"our chief counsel from the law firm of Dewey, Cheetham, & Howe is Hugh Louis Dewey, known to [group of people] in Harvard Square as Huey Louie Dewey.\" Huey, Louie, and Dewey were the juvenile nephews being raised by Donald Duck in Walt Disney's Comics and Stories. Guest accommodations were provided by The Horseshoe Road Inn (\"the horse you rode in\").\n\nAt the end of the show, Ray warned the audience, \"Don't drive like my brother!\" to which Tom replied, \"And don't drive like \"my\" brother!\" The original tag line was \"Don't drive like a knucklehead!\" There were variations such as, \"Don't drive like my brother ...\" \"And don't drive like his brother!\" and \"Don't drive like my sister ...\" \"And don't drive like \"my\" sister!\" The tagline was heard in the Pixar film \"Cars\", in which Tom and Ray voiced anthropomorphized vehicles (Rusty and Dusty Rust-eze, respectively a 1963 Dodge Dart V1.0 and 1963 Dodge A100 van, as Lightning McQueen's racing sponsors) with personalities similar to their own on-air personae. Tom notoriously once owned a \"convertible, green with large areas of rust!\" Dodge Dart, known jokingly on the program by the faux-elegant name \"Dartre\".\n\nIn 1977, radio station WBUR-FM in Boston scheduled a panel of local car mechanics to discuss car repairs on one of its programs, but only Tom Magliozzi showed up. He did so well that he was asked to return as a guest, and he invited his younger brother Ray (who was actually more of a car repair expert) to join him. The brothers were soon asked to host their own radio show on WBUR, which they continued to do every week. In 1986, NPR decided to distribute their show nationally.\n\nIn 1992, \"Car Talk\" won a Peabody Award, saying \"Each week, master mechanics Tom and Ray Magliozzi provide useful information about preserving and protecting our cars. But the real core of this program is what it tells us about human mechanics ... The insight and laughter provided by Messrs. Magliozzi, in conjunction with their producer Doug Berman, provide a weekly mental tune-up for a vast and ever-growing public radio audience.\"\n\nIn May 2007, the program, which previously had been available digitally only as a paid subscription from Audible.com, became a free podcast distributed by NPR, after a two-month test period where only a \"call of the week\" was available via podcast.\n\nAs of 2012, it had 3.3 million listeners each week, on about 660 stations. On June 8, 2012, the brothers announced that they would no longer broadcast new episodes as of October. Executive producer Doug Berman said the best material from 25 years of past shows would be used to put together \"repurposed\" shows for NPR to broadcast. Berman estimated the archives contain enough for eight years' worth of material before anything would have to be repeated. Ray Magliozzi, however, would occasionally record new taglines and sponsor announcements that were aired at the end of the show.\n\nThe show was inducted into the National Radio Hall of Fame in 2014.\n\nRay Magliozzi hosted a special \"Car Talk\" memorial episode for his brother Tom after he died in November 2014. However, Ray continued to write their syndicated newspaper column, saying that his brother would want him to.\n\nThe Magliozzis were long-time auto mechanics. Ray Magliozzi has a bachelor of science degree in humanities and science from MIT, while Tom had a bachelor of science degree in economics from MIT and an MBA and DBA from the Boston University School of Management.\n\nThe duo, usually led by Tom, were known for rants on the evils of the internal combustion engine, people who talk on mobile phones while driving, Peugeots, women named Donna who always seem to drive Chevrolet Camaros, lawyers, the clever use of the English language, people who choose to live in Alaska (or similar snowy, icy climates), and practically anything else, including themselves. They had a relaxed and humorous approach to cars, car repair, cup holders, pets, lawyers, car repair mechanics, SUVs, and almost everything else. They often cast a critical, jaundiced insider's eye toward the auto industry. Tom and Ray were committed to the values of defensive driving and environmentalism.\n\nThe Magliozzis operated a do-it-yourself garage together in the 1970s which became more of a conventional repair shop in the 1980s. Ray continued to have a hand in the day-to-day operations of the shop for years, while his brother Tom semi-retired, often joking on \"Car Talk\" about his distaste for doing \"actual work\". The show's offices were located near their shop at the corner of JFK Street and Brattle Street in Harvard Square, marked as \"Dewey, Cheetham & Howe\", the imaginary law firm to which they referred on-air. DC&H doubled as the business name of Tappet Brothers Associates, the corporation established to manage the business end of \"Car Talk\". Initially a joke, the company was incorporated after the show expanded from a single station to national syndication.\n\nThe two were commencement speakers at MIT in 1999.\n\nExecutive producer Doug Berman said in 2012, \"The guys are culturally right up there with Mark Twain and the Marx Brothers. They will stand the test of time. People will still be enjoying them years from now. They're that good.\"\n\nTom Magliozzi died on November 3, 2014, at age 77, due to complications from Alzheimer's disease.\n\nThe show was the inspiration for the short-lived \"The George Wendt Show\", which briefly aired on CBS in the 1994-1995 season- as a mid-season replacement.\n\nIn July 2007, PBS announced that it had green-lit an animated adaptation of \"Car Talk\", to air on prime-time in 2008. The show, titled \"Click and Clack's As the Wrench Turns\" is based on the adventures of the fictional \"Click and Clack\" brothers' garage at \"Car Talk Plaza\". The ten episodes aired in July and August 2008.\n\n\"Car Talk: The Musical!!!\" was written and directed by Wesley Savick, and composed by Michael Wartofsky. The adaptation was presented by Suffolk University, and opened on March 31, 2011, at the Modern Theatre in Boston, Massachusetts. The play was not officially endorsed by the Magliozzis, but they participated in the production, lending their voices to a central puppet character named \"The Wizard of Cahs\".\n\n"}
{"id": "6962", "url": "https://en.wikipedia.org/wiki?curid=6962", "title": "Council of Chalcedon", "text": "Council of Chalcedon\n\nThe Council of Chalcedon ( or ) was a church council held from October 8 to November 1, AD 451, at Chalcedon. The Council is numbered as the fourth ecumenical council by the Catholic Church, the Eastern Orthodox Church, and most Protestants. Its most important achievement was to issue the Chalcedonian Definition. The Council's judgments and definitions regarding the divine marked a significant turning point in the Christological debates. A minority of Christians do not agree with the council's teachings. Chalcedon was a city in Bithynia, on the Asian side of the Bosphorus; today the city it is part of the Republic of Turkey and is known as Kadıköy (a district of Istanbul).\n\nThe Council of Chalcedon was convened by Emperor Marcian, with the reluctant approval of Pope Leo the Great, to set aside the 449 Second Council of Ephesus which would become known as the \"Latrocinium\" or \"Robber Council\". The Council of Chalcedon issued the Chalcedonian Definition, which repudiated the notion of a single nature in Christ, and declared that he has two natures in one person and hypostasis. It also insisted on the completeness of his two natures: Godhead and manhood. The council also issued 27 disciplinary canons governing church administration and authority. In a further decree, later known as canon 28, the bishops declared that the See of Constantinople (New Rome) had the same patriarchal status as the See of Rome.\n\nThe teachings of the Council are accepted by the Eastern Orthodox Church, the Catholic Church (collectively known as the \"Great Church\"), Old Catholics and various other Western Christian groups. As such, it is recognized as infallible in its dogmatic definitions by the Catholic and Eastern Orthodox Churches. Most Protestants also agree that the teachings regarding the Trinity and the Incarnation, as defined at Nicaea (in 325) and Chalcedon, are orthodox doctrine to which they adhere. The Council, however, is not accepted by the Oriental Orthodox churches. These include the Coptic Orthodox Church of Alexandria, Ethiopian Orthodox Tewahedo Church, Eritrean Orthodox Tewahedo Church, Syriac Orthodox Church, Malankara Orthodox Syrian Church, and the Armenian Apostolic Church. They instead teach that \"The Lord Jesus Christ is God the Incarnate Word. He possesses the perfect Godhead and the perfect manhood. His fully divine nature is united with His fully human nature yet without mixing, blending or alteration\" These Churches claim that this latter teaching has been misunderstood as monophysitism - an appellation with which they strongly disagree. Nevertheless, the Oriental Orthodox churches refuse to accept the decrees of the Council regarding monophysitism.\n\nMany Anglicans and most Protestants consider it to be the last authoritative ecumenical council. These churches, per Martin Luther, hold that both conscience and scripture preempt doctrinal councils and generally agree that the conclusions of later councils were unsupported by or contradictory to scripture.\n\nIn 325, the first ecumenical council (First Council of Nicaea) determined that Jesus Christ was God, \"consubstantial\" with the Father, and rejected the Arian contention that Jesus was a created being. This was reaffirmed at the First Council of Constantinople (381) and the Council of Ephesus (431).\n\nAfter the Council of Ephesus had condemned Nestorianism, there remained a conflict between Patriarchs John of Antioch and Cyril of Alexandria. Cyril claimed that John remained Nestorian in outlook, while John claimed that Cyril held to the Apollinarian heresy. The two settled their differences under the mediation of the Bishop of Beroea, Acacius, on April 12, 433. In the following year, Theodoret of Cyrrhus assented to this formula as well. He agreed to anathematize Nestorius as a heretic in 451, during the Council of Chalcedon, as the price to be paid for being restored to his see (after deposition at the Council of Ephesus of 449). This put a final end to Nestorianism within the Roman Empire.\n\nAbout two years after Cyril of Alexandria's death in 444, an aged monk from Constantinople named Eutyches began teaching a subtle variation on the traditional Christology in an attempt (as he described in a letter to Pope Leo I in 448) to stop a new outbreak of Nestorianism. He claimed to be a faithful follower of Cyril's teaching, which was declared orthodox in the Union of 433.\n\nCyril had taught that \"There is only one \"physis\", since it is the Incarnation, of God the Word.\" Cyril had apparently understood the Greek word \"physis\" to mean approximately what the Latin word \"persona\" (person) means, while most Greek theologians would have interpreted that word to mean \"natura\" (nature). Thus, many understood Eutyches to be advocating Docetism, a sort of reversal of Arianism—where Arius had denied the consubstantial divinity of Jesus, Eutyches seemed to be denying his human nature. Cyril's orthodoxy was not called into question, since the Union of 433 had explicitly spoken of two \"physeis\" in this context. \n\nLeo I wrote that Eutyches' error seemed to be more from a lack of skill on the matters than from malice. Further, his side of the controversy tended not to enter into arguments with their opponents, which prevented the misunderstanding from being uncovered. Nonetheless, due to the high regard in which Eutyches was held (second only to the Patriarch of Constantinople in the East), his teaching spread rapidly throughout the East. \n\nIn November 448, during a local synod in Constantinople, Eutyches was denounced as a heretic by the Bishop Eusebius of Dorylaeum. Eusebius demanded that Eutyches be removed from office. Patriarch Flavian of Constantinople preferred not to press the matter on account of Eutyches' great popularity. He finally relented and Eutyches was condemned as a heretic by the synod. However, the Emperor Theodosius II and Pope Dioscorus I of Alexandria, rejected this decision ostensibly because Eutyches had repented and confessed his orthodoxy. Dioscorus then held his own synod which reinstated Eutyches. The competing claims between the Patriarchs of Constantinople and Alexandria led the Emperor to call a council which was held in Ephesus in 449. The emperor invited Pope Leo I to preside. He declined to attend on account of the invasion of Italy by Attila the Hun. However, he agreed to send four legates to represent him. Leo provided his legates, one of whom died en route, with a letter addressed to Flavian of Constantinople explaining Rome's position in the controversy. Leo's letter, now known as Leo's Tome, confessed that Christ had two natures, and was not of or from two natures. Although it could be reconciled with Cyril's Formula of Reunion, it was not compatible in its wording with Cyril's Twelve Anathemas. In particular, the third anathema reads: \"If anyone divides in the one Christ the hypostases after the union, joining them only by a conjunction of dignity or authority or power, and not rather by a coming together in a union by nature, let him be anathema.\" This appeared to some to be incompatible with Leo's definition of two natures hypostatically joined. However, the Council would determine (with the exception of 13 Egyptian bishops) that this was an issue of wording and not of doctrine; a committee of bishops appointed to study the orthodoxy of the Tome using Cyril's letters (which included the twelve anathemas) as their criteria unanimously determined it to be orthodox, and the Council, with few exceptions, supported this.\n\nOn August 8, 449 the Second Council of Ephesus began its first session with Pope Dioscorus of Alexandria presiding by command of the Emperor. Dioscorus began the council by banning all members of the November 447 synod which had deposed Eutyches. He then introduced Eutyches who publicly professed that while Christ had two natures before the incarnation, the two natures had merged to form a single nature after the incarnation. Of the 130 assembled bishops, 111 voted to rehabilitate Eutyches. Throughout these proceedings, Hilary (one of the papal legates) repeatedly called for the reading of Leo's Tome, but was ignored. Dioscorus then moved to depose Flavian and Eusebius of Dorylaeum on the grounds that they taught the Word had been made flesh and not just assumed flesh from the Virgin and that Christ had two natures. When Flavian and Hilary objected, Dioscorus called for a pro-monophysite mob to enter the church and assault Flavian as he clung to the altar. Flavian was mortally wounded. Dioscorus then placed Eusebius of Dorylaeum under arrest and demanded the assembled bishops approve his actions. Fearing the mob, they all did. The papal legates refused to attend the second session at which several more orthodox bishops were deposed, including Ibas of Edessa, Irenaeus of Tyre (a close personal friend of Nestorius), Domnus of Antioch, and Theodoret. Dioscorus then pressed his advantage by having Cyril of Alexandria's Twelve Anathemas posthumously declared orthodox with the intent of condemning any confession other than one nature in Christ. Hilary, who later became pope and dedicated an oratory in the Lateran Basilica in thanks for his life, managed to escape from Constantinople and brought news of the Council to Leo who immediately dubbed it a \"synod of robbers\"—Latrocinium—and refused to accept its pronouncements. The decisions of this council now threatened schism between the East and the West.\n\nThe situation continued to deteriorate, with Leo demanding the convocation of a new council and Emperor Theodosius II refusing to budge, all the while appointing bishops in agreement with Dioscorus. All this changed dramatically with the Emperor's death and the elevation of Marcian, an orthodox Christian, to the imperial throne. To resolve the simmering tensions, Marcian announced his intention to hold a new council. Leo had pressed for it to take place in Italy, but Emperor Marcian instead called for it to convene at Nicaea. Hunnish invasions forced it to move at the last moment to Chalcedon, where the council opened on October 8, 451. Marcian had the bishops deposed by Dioscorus returned to their dioceses and had the body of Flavian brought to the capital to be buried honorably.\n\nThe Emperor asked Leo to preside over the council, but Leo again chose to send legates in his place. This time, Bishops Paschasinus of Lilybaeum and Julian of Cos and two priests Boniface and Basil represented the western church at the council. The Council of Chalcedon condemned the work of the Robber Council and professed the doctrine of the Incarnation presented in Leo's Tome. The council was attended by about 520 bishops or their representatives and was the largest and best-documented of the first seven ecumenical councils. Paschasinus refused to give Dioscorus (who had excommunicated Leo leading up to the council) a seat at the council. As a result, he was moved to the nave of the church. Paschasinus further ordered the reinstatement of Theodoret and that he be given a seat, but this move caused such an uproar among the council fathers, that Theodoret also sat in the nave, though he was given a vote in the proceedings, which began with a trial of Dioscorus.\n\nMarcian wished to bring proceedings to a speedy end, and asked the council to make a pronouncement on the doctrine of the Incarnation before continuing the trial. The council fathers, however, felt that no new creed was necessary, and that the doctrine had been laid out clearly in Leo's Tome. They were also hesitant to write a new creed as the Council of Ephesus had forbidden the composition or use of any new creed. The second session of the council ended with shouts from the bishops, \"It is Peter who says this through Leo. This is what we all of us believe. This is the faith of the Apostles. Leo and Cyril teach the same thing.\" However, during the reading of Leo's Tome, three passages were challenged as being potentially Nestorian, and their orthodoxy was defended by using the writings of Cyril. Nonetheless due to such concerns, the Council decided to adjourn and appoint a special committee to investigate the orthodoxy of Leo's Tome, judging it by the standard of Cyril's Twelve Chapters, as some of the bishops present raised concerns about their compatibility. This committee was headed by Anatolius, Patriarch of Constantinople, and was given five days to carefully study the matter; Cyril's Twelve Chapters were to be used as the orthodox standard. The committee unanimously decided in favor of the orthodoxy of Leo, determining that what he said was compatible with the teaching of Cyril. A number of other bishops also entered statements to the effect that they believed that Leo's Tome was not in contradiction with the teaching of Cyril as well.\n\nThe council continued with Dioscorus' trial, but he refused to appear before the assembly. As a result, he was condemned, but by an underwhelming amount (more than half the bishops present for the previous sessions did not attend his condemnation), and all of his decrees were declared null. Marcian responded by exiling Dioscorus. All of the bishops were then asked to sign their assent to the Tome, but a group of thirteen Egyptians refused, saying that they would assent to \"the traditional faith\". As a result, the Emperor's commissioners decided that a \"credo\" would indeed be necessary and presented a text to the fathers. No consensus was reached, and indeed the text has not survived to the present. Paschasinus threatened to return to Rome to reassemble the council in Italy. Marcian agreed, saying that if a clause were not added to the \"credo\" supporting Leo's doctrine , the bishops would have to relocate. The bishops relented and added a clause, saying that, according to the decision of Leo, in Christ there are two natures united, inconvertible, inseparable.\n\nThe Confession of Chalcedon provides a clear statement on the human and divine nature of Christ:\n\nThe full text of the definition which reaffirms the decisions of the Council of Ephesus, the pre-eminence of the Creed of Nicea (325) and the further definitions of the Council of Constantinople (381) can be found here It also canonises as authoritative two of Cyril of Alexandria's letters and the Tome of Leo written against Eutyches and sent to Archbishop Flavian of Constantinople in 449.\n\nThe work of the council was completed by a series of 30 disciplinary canons the Ancient Epitomes of which are:\n\nCanon 28 grants equal privileges (\"\") to Constantinople as of Rome because Constantinople is the New Rome as renewed by canon 36 of the Quinisext Council. Pope Leo fully approved the canons of this council , the “Holy, Great and Universal Council” simply addressed the bishop of Rome as “Archbishop Leo”. \n\nAccording to some ancient Greek collections, canons 29 and 30 are attributed to the council: canon 29, which states that an unworthy bishop cannot be demoted but can be removed, is an extract from the minutes of the 19th session; canon 30, which grants the Egyptians time to consider their rejection of Leo's \"Tome\", is an extract from the minutes of the fourth session.\n\nIn all likelihood an official record of the proceedings was made either during the council itself or shortly afterwards. The assembled bishops informed the pope that a copy of all the \"Acta\" would be transmitted to him; in March, 453, Pope Leo commissioned Julian of Cos, then at Constantinople, to make a collection of all the Acts and translate them into Latin. Most of the documents, chiefly the minutes of the sessions, were written in Greek; others, e.g. the imperial letters, were issued in both languages; others, again, e.g. the papal letters, were written in Latin. Eventually nearly all of them were translated into both languages.\n\nThe metropolitan of Jerusalem was given independence from the metropolitan of Antioch and from any other higher-ranking bishop, given what is now known as autocephaly, in the council's seventh session whose \"Decree on the Jurisdiction of Jerusalem and Antioch\" contains: \"the bishop of Jerusalem, or rather the most holy Church which is under him, shall have under his own power the three Palestines\". This led to Jerusalem becoming a patriarchate, one of the five patriarchates known as the pentarchy, when the title of \"patriarch\" was created in 531 by Justinian. The Oxford Dictionary of the Christian Church, s.v. \"patriarch (ecclesiastical)\", also calls it \"a title dating from the 6th century, for the bishops of the five great sees of Christendom\". Merriam-Webster's Encyclopedia of World Religions, says: \"Five patriarchates, collectively called the pentarchy, were the first to be recognized by the legislation of the emperor Justinian (reigned 527–565)\".\n\nIn a canon of disputed validity, the Council of Chalcedon also elevated the See of Constantinople to a position \"second in eminence and power to the Bishop of Rome\".\n\nThe Council of Nicaea in 325 had noted the primacy of the See of Rome, followed by the Sees of Alexandria and Antioch. At the time, the See of Constantinople was not yet of ecclesiastical prominence, but its proximity to the Imperial court gave rise to its importance. The Council of Constantinople in 381 modified the situation somewhat by placing Constantinople second in honor, above Alexandria and Antioch, stating in Canon III, that \"the bishop of Constantinople... shall have the prerogative of honor after the bishop of Rome; because Constantinople is New Rome\". In the early 5th century, this status was challenged by the bishops of Alexandria, but the Council of Chalcedon confirmed in Canon XXVIII:\nIn making their case, the council fathers argued that tradition had accorded \"honor\" to the see of older Rome because it was the first imperial city. Accordingly, \"moved by the same purposes\" the fathers \"apportioned equal prerogatives to the most holy see of new Rome\" because \"the city which is honored by the imperial power and senate and enjoying privileges equaling older imperial Rome should also be elevated to her level in ecclesiastical affairs and take second place after her\". The framework for allocating ecclesiastical authority advocated by the council fathers mirrored the allocation of imperial authority in the later period of the Roman Empire. The Eastern position could be characterized as being political in nature, as opposed to a doctrinal view. In practice, all Christians East and West addressed the papacy as the See of Peter and Paul or the Apostolic See rather than the See of the Imperial Capital. Rome understands this to indicate that its precedence has always come from its direct lineage from the apostles Peter and Paul rather than its association with Imperial authority.\n\nAfter the passage of the Canon 28, Rome filed a protest against the reduction of honor given to Antioch and Alexandria. However, fearing that withholding Rome's approval would be interpreted as a rejection of the entire council, in 453 the pope confirmed the council's canons with a protest against the 28th.\n\nThe near-immediate result of the council was a major schism. The bishops that were uneasy with the language of Pope Leo's Tome repudiated the council, saying that the acceptance of two \"physes\" was tantamount to Nestorianism. Pope Dioscorus of Alexandria advocated miaphysitism and had dominated the Council of Ephesus. Churches that rejected Chalcedon in favor of Ephesus broke off from the rest of the Eastern Church in a schism, the most significant among these being the Church of Alexandria, today known as the Coptic Orthodox Church of Alexandria.\n\nJustinian I attempted to bring those monks who still rejected the decision of the Council of Chalcedon into communion with the greater church. The exact time of this event is unknown, but it is believed to have been between 535 and 548. St Abraham of Farshut was summoned to Constantinople and he chose to bring with him four monks. Upon arrival, Justinian summoned them and informed them that they would either accept the decision of the Council or lose their positions. Abraham refused to entertain the idea. Theodora tried to persuade Justinian to change his mind, seemingly to no avail. Abraham himself stated in a letter to his monks that he preferred to remain in exile rather than subscribe to a faith contrary to that of Athanasius. They were not alone, and the non-Chalcedon churches compose Oriental Orthodoxy, with the Church of Alexandria as their primus inter pares. Only in recent years has a degree of rapprochement between Chalcedonian Christians and the Oriental Orthodox been seen.\n\nThe Eastern Orthodox Church commemorates the \"Holy Fathers of the 4th Ecumenical Council, who assembled in Chalcedon\" on the Sunday on or after July 13;\n\nFor both of the above complete propers have been composed and are found in the Menaion.\n\nFor the former \"The Office of the 630 Holy and God-bearing Fathers of the 4th ... Summoned against the Monophysites Eftyches and Dioskoros ...\" was composed in the middle of the 14th century by Patriarch Philotheus I of Constantinople. This contains numerous hymns exposing the council's teaching, commemorating its leaders whom it praises and whose prayers it implores, and naming its opponents pejoratively. \"e.g.\", \"Come let us clearly reject the errors of ... but praise in divine songs the fourth council of pious fathers.\"\n\nFor the latter the propers are titled \"We Commemorate Six Holy Ecumenical Councils\". This repeatedly damns those anathematized by the councils with such rhetoric as \"Christ-smashing deception enslaved Nestorius\" and \"mindless Arius and ... is tormented in the fires of Gehenna ...\" while the fathers of the councils are praised and the dogmas of the councils are expounded in the hymns therein.\n\n\n"}
{"id": "6963", "url": "https://en.wikipedia.org/wiki?curid=6963", "title": "Canadian football", "text": "Canadian football\n\nCanadian football () is a form of gridiron football played in Canada in which two teams of 12 players each compete for territorial control of a field of play long and wide attempting to advance a pointed prolate spheroid ball into the opposing team's scoring area (end zone).\n\nIn Canada, the term \"football\" may refer to Canadian football and American football collectively, or to either sport specifically, depending on context. The two sports have shared origins and are closely related but have significant differences.\n\nRugby football in Canada originated in the early 1860s, and over time, the game known as Canadian football developed. Both the Canadian Football League (CFL), the sport's top professional league, and Football Canada, the governing body for amateur play, trace their roots to 1880 and the founding of the Canadian Rugby Football Union. Active teams such as the Toronto Argonauts and Hamilton Tiger-Cats have similar longevity.\n\nThe CFL is the most popular and only major professional Canadian football league. Its championship game, the Grey Cup, is one of Canada's largest sporting events, attracting a broad television audience. In 2009, about 40% of Canada's population watched part of the game; in 2014, it was closer to 33%, peaking at 5.1 million viewers in the fourth quarter.\n\nCanadian football is also played at the bantam, high school, junior, collegiate, and semi-professional levels: the Canadian Junior Football League, formed May 8, 1974, and Quebec Junior Football League are leagues for players aged 18–22, many post-secondary institutions compete in U Sports football for the Vanier Cup, and senior leagues such as the Alberta Football League have grown in popularity in recent years. Great achievements in Canadian football are enshrined in the Canadian Football Hall of Fame located in Hamilton, Ontario.\n\nOther organizations across Canada perform senior league Canadian football during the summer.\n\nThe first documented football match was a practice game played on November 9, 1861, at University College, University of Toronto (approximately west of Queen's Park). One of the participants in the game involving University of Toronto students was Sir William Mulock, later Chancellor of the school. A football club was formed at the university soon afterward, although its rules of play at this stage are unclear.\n\nThe first written account of a game played was on October 15, 1862, on the Montreal Cricket Grounds. It was between the First Battalion Grenadier Guards and the Second Battalion Scots Fusilier Guards resulting in a win by the Grenadier Guards 3 goals, 2 rouges to nothing. In 1864, at Trinity College, Toronto, F. Barlow Cumberland, Frederick A. Bethune, and Christopher Gwynn, one of the founders of Milton, Massachusetts, devised rules based on rugby football. The game gradually gained a following, with the Hamilton Football Club formed on November 3, 1869, (the oldest football club in Canada). Montreal formed a team April 8, 1872, Toronto was formed on October 4, 1873, and the Ottawa FBC on September 20, 1876.\n\nThis rugby-football soon became popular at Montreal's McGill University. McGill challenged Harvard University to a game, in 1874 using a hybrid game of English rugby devised by the University of McGill.\n\nThe first attempt to establish a proper governing body and adopted the current set of Rugby rules was the Foot Ball Association of Canada, organized on March 24, 1873 followed by the Canadian Rugby Football Union (CRFU) founded June 12, 1880, which included teams from Ontario and Quebec. Later both the Ontario and Quebec Rugby Football Union (ORFU and QRFU) were formed (January 1883), and then the Interprovincial (1907) and Western Interprovincial Football Union (1936) (IRFU and WIFU). The CRFU reorganized into an umbrella organization forming the Canadian Rugby Union (CRU) in 1891. The original forerunners to the current Canadian Football League, was established in 1956 when the IRFU and WIFU formed an umbrella organization, The Canadian Football Council (CFC). And then in 1958 the CFC left The CRFU to become the CFL.\n\nThe Burnside rules closely resembling American football that were incorporated in 1903 by The ORFU, was an effort to distinguish it from a more rugby-oriented game. The Burnside Rules had teams reduced to 12 men per side, introduced the Snap-Back system, required the offensive team to gain 10 yards on three downs, eliminated the Throw-In from the sidelines, allowed only six men on the line, stated that all goals by kicking were to be worth two points and the opposition was to line up 10 yards from the defenders on all kicks. The rules were an attempt to standardize the rules throughout the country. The CIRFU, QRFU and CRU refused to adopt the new rules at first. Forward passes were not allowed in the Canadian game until 1929, and touchdowns, which had been five points, were increased to six points in 1956, in both cases several decades after the Americans had adopted the same changes. The primary differences between the Canadian and American games stem from rule changes that the American side of the border adopted but the Canadian side did not (originally, both sides had three downs, goal posts on the goal lines and unlimited forward motion, but the American side modified these rules and the Canadians did not). The Canadian field width was one rule that was not based on American rules, as the Canadian game was played in wider fields and stadiums that were not as narrow as the American stadiums.\n\nThe Grey Cup was established in 1909 after being donated by Albert Grey, 4th Earl Grey, The Governor General of Canada as the championship of teams under the CRU for the Rugby Football Championship of Canada. Initially an amateur competition, it eventually became dominated by professional teams in the 1940s and early 1950s. The Ontario Rugby Football Union, the last amateur organization to compete for the trophy, withdrew from competition in 1954. The move ushered in the modern era of Canadian professional football.\n\nCanadian football has mostly been confined to Canada, with the United States being the only other country to have hosted high-level Canadian football games. The CFL's controversial \"South Division\" as it would come to be officially known attempted to put CFL teams in the United States playing under Canadian rules between 1992 and 1995. The move was aborted after three years; the Baltimore Stallions were the most successful of the numerous Americans teams to play in the CFL, winning the 83rd Grey Cup. Continuing financial losses, a lack of proper Canadian football venues, a pervasive belief that the American teams were simply pawns to provide the struggling Canadian teams with expansion fee revenue, and the return of the NFL to Baltimore prompted the end of Canadian football on the American side of the border.\n\nThe CFL hosted the Touchdown Atlantic regular season game at Nova Scotia in 2005 and New Brunswick in 2010, 2011 and 2013. In 2013, Newfoundland and Labrador became the last province to establish football at the minor league level, with teams playing on the Avalon Peninsula and in Labrador City. The province however has yet to host a college or CFL game. Prince Edward Island, the smallest of the provinces, has also never hosted a CFL game.\n\nCanadian football is played at several levels in Canada; the top league is the professional nine-team Canadian Football League (CFL). The CFL regular season begins in June, and playoffs for the Grey Cup are completed by mid-November. In cities with outdoor stadiums such as Edmonton, Winnipeg, and Regina, low temperatures and icy field conditions can seriously affect the outcome of a game.\n\nAmateur football is governed by Football Canada. At the university level, 26 teams play in four conferences under the auspices of U Sports (known from 2001–2016 as Canadian Interuniversity Sport); the U Sports champion is awarded the Vanier Cup. Junior football is played by many after high school before joining the university ranks. There are 20 junior teams in three divisions in the Canadian Junior Football League competing for the Canadian Bowl. The Quebec Junior Football League includes teams from Ontario and Quebec who battle for the Manson Cup.\n\nSemi-professional leagues have grown in popularity in recent years, with the Alberta Football League becoming especially popular. The Northern Football Conference formed in Ontario in 1954 has also surged in popularity for former college players who do not continue to professional football. The Ontario champion plays against the Alberta champion for the \"National Championship\". The Canadian Major Football League is the governing body for the semi-professional game.\n\nWomen's football is starting to gain attention in Canada. The first Canadian women's league to begin operations was the Maritime Women's Football League in 2004. The largest women's league is the Western Women's Canadian Football League.\n\nThe Canadian football field is long and wide, within which the end zones are deep, and the goal lines are apart.\n\nAt each goal line is a set of goalposts, which consist of two \"uprights\" joined by an crossbar which is above the goal line. The goalposts may be H-shaped (both posts fixed in the ground) although in the higher-calibre competitions the tuning-fork design (supported by a single curved post behind the goal line, so that each post starts above the ground) is preferred.\n\nThe sides of the field are marked by white sidelines, the goal line is marked in white, and white lines are drawn laterally across the field every from the goal line. These lateral lines are called \"yard lines\" and often marked with the distance in yards from and an arrow pointed toward the nearest goal line. In previous decades, arrows were not used and every yard line was usually marked with the distance to the goal line, including the goal line itself which was marked with a \"0\"; in most stadiums today, the 10-, 20-, 30-, 40-, and 50-yard lines are marked with numbers, with the goal line sometimes being marked with a \"G\". The centre (55-yard) line usually is marked with a \"C\". \"Hash marks\" are painted in white, parallel to the yardage lines, at intervals, from the sidelines.\n\nOn fields that have a surrounding running track, such as Molson Stadium and many universities, the end zones are often cut off in the corners to accommodate the track. Until 1986, the end zones were deep, giving the field an overall length of , and a correspondingly larger cutoff could be required at the corners. This was particularly common among U.S.-based teams during the CFL's American expansion, where few American stadiums were able to accommodate the much longer and noticeably wider CFL field. The end zones in Toronto's BMO Field are only 18 yards instead of 20 yards.\n\nTeams advance across the field through the execution of quick, distinct plays, which involve the possession of a brown, prolate spheroid ball with ends tapered to a point. The ball has two one-inch-wide white stripes.\n\nAt the beginning of a match, an official tosses a coin and allows the captain of the visiting team call heads or tails. The captain of the team winning the coin toss is given the option of having first choice, or of deferring first choice to the other captain. The captain making first choice may either choose a) to kick off or receive the kick and the beginning of the half, or b) which direction of the field to play in. The remaining choice is given to the opposing captain. Before the resumption of play in the second half, the captain that did not have first choice in the first half is given first choice. Teams usually choose to defer, so it is typical for the team that wins the coin toss to kick to begin the first half and receive to begin the second.\n\nPlay begins at the start of each half with one team place-kicking the ball from its own 35-yard line. Both teams then attempt to catch the ball. The player who recovers the ball may run while holding the ball, or lateral throw the ball to a teammate.\n\nPlay stops when the ball carrier's knee, elbow, or any other body part aside from the feet and hands, is forced to the ground (a \"tackle\"); when a forward pass is not caught on the fly (during a scrimmage); when a touchdown (see below) or a field goal is scored; when the ball leaves the playing area by any means (being carried, thrown, or fumbled out of bounds); or when the ball carrier is in a standing position but can no longer move forwards (called forward progress). If no score has been made, the next play starts from \"scrimmage\".\n\nBefore scrimmage, an official places the ball at the spot it was at the stop of clock, but no nearer than 24 yards from the sideline or 1 yard from the goal line. The line parallel to the goal line passing through the ball (line from sideline to sideline for the length of the ball) is referred to as the line of scrimmage. This line is similar to \"no-man's land\"; players must stay on their respective sides of this line until the play has begun again. For a scrimmage to be valid the team in possession of the football must have seven players, excluding the quarterback, within one yard of the line of scrimmage. The defending team must stay a yard or more back from the line of scrimmage.\nOn the field at the beginning of a play are two teams of 12 (unlike 11 in American football). The team in possession of the ball is the offence and the team defending is referred to as the defence. Play begins with a backwards pass through the legs (the snap) by a member of the offensive team, to another member of the offensive team. This is usually the quarterback or punter, but a \"direct snap\" to a running back is also not uncommon. If the quarterback or punter receives the ball, he may then do any of the following:\n\nEach play constitutes a \"down\". The offence must advance the ball at least ten yards towards the opponents' goal line within three downs or forfeit the ball to their opponents. Once ten yards have been gained the offence gains a new set of three downs (rather than the four downs given in American football). Downs do not accumulate. If the offensive team completes 10 yards on their first play, they lose the other two downs and are granted another set of three. If a team fails to gain ten yards in two downs they usually punt the ball on third down or try to kick a field goal (see below), depending on their position on the field. The team may, however use its third down in an attempt to advance the ball and gain a cumulative 10 yards.\n\nThe ball changes possession in the following instances:\n\nThere are many rules to contact in this type of football. First, the only player on the field who may be legally tackled is the player currently in possession of the football (the ball carrier). Second, a receiver, that is to say, an offensive player sent down the field to receive a pass, may not be interfered with (have his motion impeded, be blocked, etc.) unless he is within one yard of the line of scrimmage (instead of in American football). Any player may block another player's passage, so long as he does not hold or trip the player he intends to block. The kicker may not be contacted after the kick but before his kicking leg returns to the ground (this rule is not enforced upon a player who has blocked a kick), and the quarterback, having already thrown the ball, may not be hit or tackled.\n\nInfractions of the rules are punished with \"penalties\", typically a loss of yardage of 5, 10 or 15 yards against the penalized team. Minor violations such as \"offside\" (a player from either side encroaching into scrimmage zone before the play starts) are penalized five yards, more serious penalties (such as holding) are penalized 10 yards, and severe violations of the rules (such as face-masking) are typically penalized 15 yards. Depending on the penalty, the penalty yardage may be assessed from the original line of scrimmage, from where the violation occurred (for example, for a pass interference infraction), or from where the ball ended after the play. Penalties on the offence may, or may not, result in a loss of down; penalties on the defence may result in a first down being automatically awarded to the offence. For particularly severe conduct, the game official(s) may eject players (ejected players may be substituted for), or in exceptional cases, declare the game over and award victory to one side or the other. Penalties do not affect the yard line which the offence must reach to gain a first down (unless the penalty results in a first down being awarded); if a penalty against the defence results in the first down yardage being attained, then the offence is awarded a first down.\n\nIf the defence is penalized on a two-point convert attempt and the offence chooses to attempt the play again, the offence must attempt another two-point convert; it cannot change to a one-point attempt. Conversely, the offence can attempt a two-point convert following a defensive penalty on a one-point attempt.\n\nPenalties may occur before a play starts (such as offside), during the play (such as holding), or in a dead-ball situation (such as unsportsmanlike conduct).\n\nPenalties never result in a score for the offence. For example, a point-of-foul infraction committed by the defence in their end zone is not ruled a touchdown, but instead advances the ball to the one-yard line with an automatic first down. For a distance penalty, if the yardage is greater than half the distance to the goal line, then the ball is advanced half the distance to the goal line, though only up to the one-yard line (unlike American football, in Canadian football no scrimmage may start inside either one-yard line). If the original penalty yardage would have resulted in a first down or moving the ball past the goal line, a first down is awarded.\n\nIn most cases, the non-penalized team will have the option of \"declining\" the penalty; in which case the results of the previous play stand as if the penalty had not been called. One notable exception to this rule is if the kicking team on a 3rd down punt play is penalized before the kick occurs: the receiving team may not decline the penalty and take over on downs. After the kick is made, change of possession occurs and subsequent penalties are assessed against either the spot where the ball is caught, or the runback.\n\nCanadian football distinguishes four ways of kicking the ball:\n\n\nOn any kicking play, all onside players (the kicker, and teammates behind the kicker at the time of the kick) may recover and advance the ball. Players on the kicking team who are not onside may not approach within five yards of the ball until it has been touched by the receiving team, or by an onside teammate.\n\nThe methods of scoring are:\n\n\nResumption of play following a score is conducted under procedures which vary with the type of score.\n\nThe game consists of two 30-minute halves, each of which is divided into two 15-minute quarters. The clock counts down from 15:00 in each quarter. Timing rules change when there are three minutes remaining in a half.\nA short break interval of 2 minutes occurs after the end of each quarter (a longer break of 15 minutes at halftime), and the two teams then change goals.\n\nIn the first 27 minutes of a half, the clock stops when:\n\nThe clock starts again when the referee determines the ball is ready for scrimmage, except for team time-outs (where the clock starts at the snap), after a time count foul (at the snap) and kickoffs (where the clock starts not at the kick but when the ball is first touched after the kick).\n\nIn the last three minutes of a half, the clock stops whenever the ball becomes dead. On kickoffs, the clock starts when the ball is first touched after the kick. On scrimmages, when it starts depends on what ended the previous play. The clock starts when the ball is ready for scrimmage except that it starts on the snap when on the previous play\n\nDuring the last three minutes of a half, the penalty for failure to place the ball in play within the 20-second play clock, known as \"time count\" (this foul is known as \"delay of game\" in American football), is dramatically different from during the first 27 minutes. Instead of the penalty being 5 yards with the down repeated, the base penalty (except during convert attempts) becomes loss of down on first or second down, and 10 yards on third down with the down repeated. In addition, as noted previously, the referee can give possession to the defence for repeated deliberate time count violations on third down.\n\nThe clock does not run during convert attempts in the last three minutes of a half. If the 15 minutes of a quarter expire while the ball is live, the quarter is extended until the ball becomes dead. If a quarter's time expires while the ball is dead, the quarter is extended for one more scrimmage. A quarter cannot end while a penalty is pending: after the penalty yardage is applied, the quarter is extended one scrimmage. Note that the non-penalized team has the option to \"decline\" any penalty it considers disadvantageous, so a losing team cannot indefinitely prolong a game by repeatedly committing infractions.\n\nIn the CFL, if the game is tied at the end of regulation play, then each team is given an equal number of offensive possessions to break the tie. A coin toss is held to determine which team will take possession first; the first team scrimmages the ball at the opponent's 35-yard line and conducts a series of downs until it scores or loses possession. If the team scores a touchdown, starting with the 2010 season, it is required to attempt a two-point conversion.\nThe other team then scrimmages the ball at the opponent's 35-yard line and has the same opportunity to score. After the teams have completed their possessions, if one team is ahead, then it is declared the winner; otherwise, the two teams each get another chance to score, scrimmaging from the other 35-yard line. After this second round, if there is still no winner, during the regular season the game ends as a tie. In a playoff game, the teams continue to attempt to score from alternating 35-yard lines, until one team is leading after both have had an equal number of possessions.\n\nIn U Sports football, for the Uteck Bowl, Mitchell Bowl, and Vanier Cup, the same overtime procedure is followed until there is a winner.\n\nThe offensive positions found in Canadian football have, for the most part, evolved throughout the years, and are not officially defined in the rules. However, among offensive players, the rules recognize three different types of players:\n\n\nSpecific offensive positions include:\n\n\nThe rules do not constrain how the defence may arrange itself (other than the requirement that they must remain one yard behind the line of scrimmage until the play starts).\n\n\n\"Special teams\" generally refers to kicking plays, which typically involve a change in possession.\n\n\n\n"}
{"id": "6966", "url": "https://en.wikipedia.org/wiki?curid=6966", "title": "Chinese calendar", "text": "Chinese calendar\n\nTraditional Chinese calendar is a lunisolar calendar which reckons years, months and days according to astronomical phenomena. Currently, the Chinese calendar is defined by GB/T 33661-2017 \"Calculation and promulgation of the Chinese calendar,\" which is issued by the Standardization Administration of the People's Republic of China on May 12, 2017.\n\nThe Chinese calendar is used for traditional activities in China and overseas Chinese communities. It depicts and lists the dates of traditional Chinese holidays, and guides Chinese people in selecting the most auspicious days for weddings, funerals, moving, or beginning a business.\n\nIn the Chinese calendar, the days begin and end at midnight. The months begin on the day with the dark (new) moon. The years begin with the dark moon near the midpoint between winter solstice and spring equinox. The solar terms are the important components of the Chinese calendar. In a month, there are one to three solar terms.\n\nThe currently used traditional Chinese calendar is the end result of centuries of evolution. Many astronomical and seasonal factors were added by ancient scientists, and people can reckon the date of natural phenomena such as the moon phase and tide upon the Chinese calendar. The Chinese calendar has over 100 variants, whose characteristics reflect the calendar's evolutionary path. As with Chinese characters, different variants are used in different parts of the Chinese cultural sphere.\n\nIn Korea, Vietnam, and the Ryukyu Islands, the Chinese calendar was adopted completely and evolved into Korean, Ryukyuan, and Vietnamese calendar, with the main difference being the use of different meridians which leads to some astronomical events falling on different dates in different countries and thus the same event may occasionally be assigned a different date in each of those calendars. The traditional Japanese calendar was also derived from the Chinese calendar, based on a Japanese meridian, however its official use in Japan was abolished in the early 20th century and its usage has mostly disappeared since then. Calendars in Mongolia and Tibet have absorbed elements from the Chinese calendar and elements from other systems, but they are not direct descendants of the Chinese calendar.\n\nThe official calendar in China is the Gregorian calendar, but the traditional Chinese calendar still plays an important role there. The Chinese calendar is known officially as the \"Rural Calendar\" (), but is often referred to by other names, such as the \"Former Calendar\" (), the \"Traditional Calendar\" (), or the \"Lunar Calendar\" (). The Chinese calendar preserves traditional East Asian culture.\n\nAlthough the month sequences of Chinese calendar is decided by the solar term, the Chinese calendar is not an agriculture calendar.\n\nIn ancient China, the calendars marked the name/stem – branch of the year, month names, month length flags (大/小=Long/Short), the stems of 1/11/21 (1/11/21 of each month are same in stem, use a character), the branches of 1/11/21, and the date/stem-branch/time of the solar terms in the month.\n\nThe calendar has a year, month and date frame. The key elements are the day, synodic month and solar year. The Chinese calendar is a lunisolar calendar, similar to the Hindu and Hebrew calendars.\n\nThe concepts in the Chinese, Hindu, and Hebrew calendars:\n\nThe movements of the Sun, the Moon, Mercury, Venus, Mars, Jupiter, and Saturn are the key references for calendar calculations. These are known as the seven luminaries. \nThe Big Dipper is regarded as the compass in the sky, and the handle's direction decides the season and solar month.\nThe stars are divided into 3 enclosures and 28 mansions according to the location in the sky. The mansions are named with 28 characters according to the shape. \nThe moon moves about 1 mansion per day. Therefore, the 28 mansions are used to count days too. In the Tang Dynasty, Yuan Tiangang () matched the 28 mansions, 7 luminaries and animal signs, such as horn-wood-flood dragon ().\n\nSeveral coding systems are used for some special circumstances in order to avoid ambiguity, such as continuous day or year count. \n\nIn Modern China, people use the Western hour-minute-second system to divide time. In Ancient China, people used the \"shi-ke\" system to divide the time during the day and the \"geng-dian\" system to divide the time during the night.. For example:\nIn the Chinese calendar, the day begins at midnight and ends at the next midnight, but people tend to regard the days as beginning at dawn.\n\nThe Chinese appear to have adopted the seven-day week from the Hellenistic system by the 4th century, although by which route is not entirely clear. It was again transmitted to China in the 8th century by Manichaeans, via the country of Kang (a Central Asian polity near Samarkand). It is the most predominantly used system in modern China.\n\nOther than the seven-day week system, in ancient China, the days were grouped into 10-day weeks with the stems, 12-day weeks with the branches, or 9/10-day weeks () with the date in the month.\n\nThe ten-day week was used in antiquity (reportedly as early as in the Bronze Age Xia dynasty). In modern time, it is still used in counting special days including Three Fu Days ().\n\nThe law during the Han dynasty (206 BC – AD 220) required officials of the empire to rest every five days, called \"mu\" (沐), while it was changed into 10 days in the Tang dynasty (AD 618 – 907), called \"huan\" (澣/浣) or \"xún\" (旬).\n\nMonths were almost three weeks long (alternating 29 and 30 days to keep in line with the lunation). As a practice, the months are divided into 3 \"xún\". The first 10 days is the \"early xún\" (), the middle 10 days is the \"mid xún\" (), and the last 9 or 10 days is the \"late xún\" ().\n\nMarkets in Japan followed the Chinese \"jun\" (旬) system; see Japanese calendar. In Korea, it was called \"Sun\" (순,旬).\n\nIn winter, there is also a 9-day cycle counting start from the winter solstice, which would last for 9 cycles until 81 days later when it is deemed as the end of winter.\n\nMonth is the time between the dark moon. In the early days, the month length was estimated, and balanced. In general, 15-months-cycles and 17-months-cycles alternated for compliance with the synodic month. \nIn different ages, the calendar use different major cycle, which contains several 15-months-cycles and 17-months-cycle. The synodic month of Taichu calendar is 29/ days, so the major cycle contains three 17-months-cycles and two 15-months-cycles.\n\nIn 7th century, the \"Wùyín Yuán Calendar\" of Tang dynasty in 7th century, the month length was determined by the real synodic month for the first time, instead of the cycling method, which mean month lengths is determined by observation and prediction starting from Tang dynasty, except a few brief period of time.\n\nBecause astronomical observation is used to determine month length, date of the Chinese calendar corresponds to the moon phase.\n\nAs the beginning of every month is determined by the time when the new moon occur, thus other countries who have adopted the calendar and use time standard that are different from China to calculate their own version of the calendar could result in deviation. For instance, the first new moon in the year 1968 in Gregorian calendar happened in UTC Jan 29 16:29, which would translate to Jan 29 23:29 in UTC+7 timezone (which is what North Vietnam used to calculate their Vietnamese calendar) while it would be Jan 30 00:15 based on the longitude of Beijing (as used by South Vietnam at the time), causing the two countries celebrate Tết holiday in different date that year and result in asynchronized attacks in Tet Offensive.\n\nThe solar year () is the time between the winter solstices. The solar year is divided into 24 solar terms.\n\nIn ancient China, the solar year and solar terms were estimated and balanced, and the solar term is just the / of the solar year, about 15/ days.\n\nStarting from the 17th century, when the \"Shixian Calendar\" of Qing dynasty was adopted, the solar year was determined by the real tropical year instead. The solar terms correspond to intervals of 15° along the ecliptic.\n\nDifferent version of traditional Chinese calendar might have different average year length. For instance, one solar year of \"Taichu calendar\", which were implemented in 1st century BC, is 365/ days, while one solar year of \"Shoushi calendar\", which were implemented in 13th century, is 365/ days, which is the same as the Gregorian calendar.\n\nCouples of solar terms are climate terms (solar months). The first of each couples is \"pre-climate\" (), and the second of the each couple is \"mid-climate\" ().\n\nIn general, there are 11 or 12 complete months and 2 incomplete months, which contains the winter solstice, in a solar year. The 11 mid-climates except the winter solstice are in the 11 or 12 complete months. The first month without a mid-climate is the leap month.\n\nThe complete months except the intercalary month, queues up from 0 to 10, and the incomplete months follows this queue, to be 11. The intercalary follows the queue number before by rule.\n\nThe civil year starts from the first spring month (1), and ends at the last winter month (0/0i). The first and last month is called as \"Zhēngyuè\" (, capital month) and \"Làyuè\" (, sacrificial month), and the other month is called according to the queue number (except that the 0th month is \"Shieryue\", if the \"Layue\" is a leap month).\n\nThere are 12/13 months in each year. The years with 12 months are common years, or 353~355 days, is a common year. The years with 13 months, or 383~385 days, is a long year.\n\nYears were numbered after the reign title in Ancient China, but the reign title was no longer used after the founding of PRC in 1949. People use the stem-branches to demarcate the years. For example, the year from \"February 8, 2016\" to \"January 27, 2017\" is a \"Bǐngshēnnían\", long.\n\nTo Encode the date in the Chinese calendar, the flag of the intercalary month should be considered. For example, \"Run Liuyue 6, Dingyounian: 408-6i-06 (Timestamp: 40806106)\"\n\nIn \"Tang Dynasty\", the earthly branches are used to mark the months for about 150 days (Dec, 761~May, 762). At that time, the year starts from the month with Winter Solstice, and the month from Zhengyue to Layue are named as: Yinyue, Maoyue, Chenyue, Siyue, Wuyue, Weiyue, Shenyue Youyue, Xuyue, Haiyue, Ziyue, and Chouyue.\n\n\nA typical graphical representation of the Chinese calendar is the vernal cattle diagram (), which help people calculate the date. In the vernal cattle diagram: \n\nIn China, age for official use is based on the Gregorian calendar. For traditional use, age is based on the Chinese calendar. For the first year from the birthday, the child is considered one year old. After each New Year's Eve, add one year. \"Ring out the old age and ring in the new one ()\" is the literary express of New Year Ceremony. For example, if one's birthday is \"Làyuè\" 29th 2013, he is 2 years old at \"Zhēngyuè\" 1st 2014. On the other hand, people say months old instead of years old, if someone is too young. It is that the age sequence is \"1 month old, 2 months old, ... 10 months old, 2 years old, 3 years old...\".\n\nAfter the actual age () was introduced into China, the Chinese traditional age was referred to as the nominal age (). Divided the year into two halves by the birthday in the Chinese calendar, the nominal age is 2 older than the actual age in the first half, and the nominal age is 1 older than the actual age in the second half ().\n\nJust as it is awkward to define the birthday of someone born on the 29th of February in the Gregorian calendar, special rules are used for birthdays or other anniversaries during the intercalary month or on the 30th day.\n\nIn the Ancient China, years were numbered from 1, beginning when a new emperor ascended the throne or the current emperor announced a new era name. The first reign title was \"Jiànyuán\" (, from 140 BCE), and the last reign title was \"Xuāntǒng\" (, from 1908 CE). The era system was abolished in 1912 CE, after which the Current Era or Republican era was used. The epoch of the Current Era is just the same as the era name of Emperor Ping of Han, \"Yuánshí\" ().\n\n\nThe 60 stem-branches were used to mark the date continually from Shang Dynasty. Before Han Dynasty, people knew the orbital period of Jupiter is about 4332 days, which is about 12*361 days. So, the orbital period of Jupiter was divided into 12 periods, which was used to number the year. The Jupiter was called as the star of age (), and the / Jupiter orbital period was called as the age ().\n\n361 days is just 6 cycles of 60-stem-branches, so the stem-branches of the first day move forward one after each \"sui\". The first day of each \"sui\" was called as the \"sui\" capital ().\n\nAnd the stem-branches of the \"taisui\" was used to mark the year. Obviously, there're two \"taisui\" in some year for the \"sui\" is shorter than solar rear. About after each 86 year, a \"taisui\" was leaped. The leaped of the \"sui\" was called as beyond the star ().\n\nAt the eastern Han Dynasty, the \"chaochen\" are abolished, and the 60 stem-branches are used to mark year continually without leap.\n\nThe Stem-branches year number system provided a solution for the defect of era system (unequal length of the reign titles)\n\n\nOccasionally, nomenclature similar to that of the Christian era has been used, such as\nNo reference date is universally accepted.\n\nOn January 2, 1912, Sun Yat-sen declared a change to the official calendar and era. In his declaration, January 1, 1912 is called \"Shíyīyuè 13th, 4609 AH\" which assumes an epoch (1st year) of 2698 BCE. This declaration was adopted by many overseas Chinese communities outside Southeast Asia such as San Francisco's Chinatown.\n\nIn the 17th century, the Jesuits tried to determine what year should be considered the epoch of the Han calendar. In his \"Sinicae historiae decas prima\" (first published in Munich in 1658), Martino Martini (1614–1661) dated the ascension of the Yellow Emperor to 2697 BC, but started the Chinese calendar with the reign of Fuxi, which he claimed started in 2952 BCE. Philippe Couplet's (1623–1693) \"Chronological table of Chinese monarchs\" (\"Tabula chronologica monarchiae sinicae\"; 1686) also gave the same date for the Yellow Emperor. The Jesuits' dates provoked great interest in Europe, where they were used for comparisons with Biblical chronology.\n\nModern Chinese chronology has generally accepted Martini's dates, except that it usually places the reign of the Yellow Emperor in 2698 BC and omits the Yellow Emperor's predecessors Fuxi and Shennong, who are considered \"too legendary to include\".\n\nStarting in 1903, radical publications started using the projected date of birth of the Yellow Emperor as the first year of the Han calendar. Different newspapers and magazines proposed different dates. Jiangsu, for example, counted 1905 as year 4396 (use an epoch of 2491 BCE), whereas the newspaper \"Ming Pao\" () reckoned 1905 as 4603 (use an epoch of 2698 BCE). Liu Shipei (; 1884–1919) created the Yellow Emperor Calendar, now often used to calculate the date, to show the unbroken continuity of the Han race and Han culture from earliest times. Liu's calendar started with the birth of the Yellow Emperor, which he determined to be 2711 BCe. There is no evidence that this calendar was used before the 20th century. Liu calculated that the 1900 international expedition sent by the Eight-Nation Alliance to suppress the Boxer Rebellion entered Beijing in the 4611th year of the Yellow Emperor.\n\n\nThere is an epoch for each version of the Chinese calendar, which is called \"Lìyuán\" (). The epoch is the optimal origin of the calendar, and it is a \"Jiǎzǐrì\", the first day of a lunar month, and the dark moon and solstice are just at the midnight (). And tracing back to a perfect day, such as that day with the magical star sign, there's a supreme epoch (). The continuous year based on the supreme epoch is \"shàngyuán jīnián\" (). More and more factors were added into the supreme epoch, and the \"shàngyuán jīnián\" became a huge number. So, the supreme epoch and \"shàngyuán jīnián\" were neglected from the \"Shòushí\" calendar.\n\n\nShao Yong ( 1011–1077), a philosopher, cosmologist, poet, and historian who greatly influenced the development of Neo-Confucianism in China, introduced a time system in his \"The Ultimate which Manages the World\" ()\n\nIn his time system, 1 \"yuán\" (), which contains 12'9600 years, is a lifecycle of the world. Each \"yuán\" is divided into 12 \"huì\" (). Each \"huì\" is divided into 30 \"yùn\" (), and each \"yùn\" is divided into 12 \"shì\" (). So, each \"shì\" is equivalent to 30 years. The \"yuán-huì-yùn-shì\" corresponds with \"nián-yuè-rì-shí\". So the \"yuán-huì-yùn-shì\" is called the \"major tend\" or the \"numbers of the heaven\", and the \"nián-yuè-rì-shí\" is called the \"minor tend\" or the \"numbers of the earth\".\n\nThe \"minor tend\" of the birth is adapted by people for predicting destiny or fate. The numbers of \"nián-yuè-rì-shí\" are encoded with stem-branches and show a form of \"Bāzì\". The \"nián-yuè-rì-shí\" are called the Four Pillars of Destiny. For example, the \"Bāzì\" of the Qianlong Emperor is \"Xīnmǎo, Dīngyǒu, Gēngwǔ, Bǐngzǐ\" (). Shào \"Huángjíjīngshì\" recorded the history of the timing system from the first year of the 180 \"yùn\" or 2149 \"shì\" (\"HYSN 0630-0101\", 2577 BC) and marked the year with the reign title from the \"Jiǎchénnián\" of the 2156 \"shì\" (\"HYSN 0630-0811\", 2357 BC, \"Tángyáo 1\", ). According to this timing system, 2014-1-31 is \"HYSN/YR 0712-1001/0101\".\n\nThe table below shows the kinds of year number system along with correspondences to the Western (Gregorian) calendar. Alternatively, see this larger table of the full 60-year cycle.\n\nIn the Sinosphere, the traditional festivals are calculated using the date or solar terms, and are considered auspicious.\n\nBefore the Zhou dynasty, the Chinese calendars used a solar calendar.\nAccording to Ancient Chinese literature, the first version was the five-phases calendar (), which came from the tying knots culture. In the five-phases calendar, a year was divided into five phases which were expressed by five ropes. Each rope was folded into halves, and the day in the corner was the capital day (). They're three sections in each halves, and the Chinese Character of phase is the pictograph of the rope of the tying knots. The ten half-ropes were arranged into a row, and a man shape was engraved by the ropes. The part of man shape derived into 10 heaven stems. The days in each sections were recorded with 12 earthly branches. So, in the five-phases calendar, a year is fives phases or ten months, and a phase is six sections or 73 days. The remainder of each phases are marked in the Hetu, which is found in Song Dynasty.\n\nThe second version is the four-seasons calendar (). In the four-seasons calendar, the days were counting by ten, and three ten-days weeks were built into a month. There were 12 months in a year, and a week were intercalated in the hot month. In the age of four-seasons calendar, the 10 heaven stems and 12 earthly branches were used to mark days synchronously.\n\nThe third version is the balanced calendar () a year was defined into 365.25 days, and the month was defined into 29.5 days. And after each 16 months, a half-month was intercalated. There half-months were merged into months later, and the archetype of the Chinese calendar was brought out in the Spring and Autumn ages.\n\nOracle bone records indicate that the calendar of Shang Dynasty were a balanced calendar, and the 12, 13, even 14 months were packed into a year roughly. Generally, the month after the winter solstice was named as the capital month ().\n\nIn Zhou dynasty, the authority issued the official calendar, which is a primitive lunisolar calendar. The year beginning of Zhou's calendar () is the day with dark moon before the winter solstice, and the epoch is the Winter Solstice of a Dīngyǒu year.\n\nSome remote vassal states issued their own calendars upon the rule of Zhou's calendar, such as:\nDuring the Spring and Autumn period and Warring States period, Some vassal states got out of control of Zhou, and issues their own official calendar, such as:\nThese six calendars are called as the six ancient calendars (), and are the quarter remainder calendars (). The months of these calendars begin on the day with the darkmoon, and there are 12 or 13 month within a year. The intercalary month is placed at the end of the year, and called as 13th month.\n\nThe modern version of the \"Zhuanxu's\" calendar is the Chinese Qiang calendar and Chinese Dai calendar, which are the calendar of mountain peoples.\n\nAfter Qin Shi Huang unified China under the Qin dynasty in 221 BCE, Qin's calendar () was promulgated. The Qin's calendar follows the rules of Zhuanxu's calendar, but the month order follows the Xia calendar. The months in the year are from the 10th month to the 9th month, and the intercalary month is called as the second Jiuyue (). In the early Han dynasty, the Qin calendar continued to be used.\n\nEmperor Wu of the Han dynasty introduced reforms halfway through his administration. His Taichu or Grand Inception Calendar ( introduced 24 solar terms which determined the month names. The solar year was defined as 365 / days, and divided into 24 solar terms. Each couples of solar terms are associated into 12 climate terms. The lunar month was defined as 29 / days and named according to the closest climate term. The mid-climate in the month decides the month name, and a month without mid-climate is an intercalary month.\n\nThe Taichu calendar established the frame of the Chinese calendar, Ever since then, there have been over 100 official calendars in Chinese which are consecutive and follow the structure of \"Tàichū\" calendar both. There're several innovation in calendar calculation in the history of over 2100 years, such as:\n\nThe Chinese calendar lost the status of the official statutory calendar in China in the beginning of the 20th century, however it has been continually being used for various purposes.\n\nBecause the Republic of China adopted the UTC+8 timezone instead of using Beijing Mean Solar Time in 1928 CE, Chinese calendars produced in Mainland China have switched to use UTC+8 in the following year. However, the switch in time standard used in Chinese calendars has not been universally adopted in areas like Taiwan and Hong Kong, and some calendars were still follow the last calendar of Qing dynasty that was published in 1908. In 1978, this practice caused confusion on what date the 1978 Mid-autumn festival occur, and caused those areas to switch to the UTC+8-based Chinese calendar thereafter.\n\nIn the late Ming dynasty, Xu Guangqi and his colleagues worked out the new calendar based on western astronomical arithmetic. But the new calendar was not released before the end of the Ming dynasty. In the early Qing dynasty, Johann Adam Schall von Bell submitted the calendar to the Shunzhi Emperor. The Qing government released the calendar under the name the \"Shíxiàn\" calendar, which means seasonal charter.\nIn the \"Shíxiàn\" calendar, the solar terms each correspond to 15° along the ecliptic. It meant the Chinese calendar can be used as astronomical calendar. However, the length of the climate term near the perihelion is shorter than 30 days and there may be two mid-climate terms. The rule of the mid-climate terms decides the months, which is used for thousands years, lose its validity. The \"Shíxiàn\" calendar changed the rule to \"decides the month in sequence, except the intercalary month.\"\n\nThe version of the traditional Chinese calendar currently being used follows the rules of the \"Shíxiàn\" calendar, except that: \n\nTo optimize the Chinese calendar, astronomers have released many proposed changes. A typical proposal was released by Gao Pingzi (; 1888-1970), a Chinese astronomer who was one of the founders of Purple Mountain Observatory. In his proposal, the month numbers are calculated before the dark moons and the solar terms were rounded to the day. Under his proposal, the month numbers are the same for the Chinese calendar upon different time zones.\n\nAs the intercalary month is determined by the first month without mid-climate and the exact time when each mid-climate happen would vary according to time zone, countries that have adopted the calendar but calculate with their own time could vary from the one used in China because of this. For instance, the 2012 FTG happened in UTC May 20 15:15, which would translate to May 20 23:15 in UTC+8, making FTG the mid-climate for the fourth month of that traditional Chinese year [April 21 ~ May 20 in Gregorian calendar], but in Korea it happened in May 21 00:15 in UTC+9, and as new moon take place in May 21 in that month, therefore the month before that would only consist of the SC solar term, lacking mid-climate. As a result, the month starting at April 21 would be an intercalary month in Korean calendar, but not in Chinese Calendar, and the intercalary month in Chinese calendar would start in the month after, in the fifth month starting from May 21, which would only consist of the solar term STG, while the month in Korean Calendar would have both FTG and STG solar term in it.\n\nAmong the ethnic groups inhabiting the mountains and plateaus of southwestern China, and those living in the grasslands of northern China, their civil calendars show a diversity of practice based upon their characteristic phenology and culture, but they are based on the algorithm of the Chinese calendar of different periods, especially those of the Tang dynasty and pre-Qin dynasty period.\n\n\n\n\n\n"}
{"id": "6968", "url": "https://en.wikipedia.org/wiki?curid=6968", "title": "Customer relationship management", "text": "Customer relationship management\n\nCustomer relationship management (CRM) is an approach to managing a company's interaction with current and potential customers. It uses data analysis about customers' history with a company and to improve business relationships with customers, specifically focusing on customer retention and ultimately driving sales growth.\n\nOne important aspect of the CRM approach is the systems of CRM that compile data from a range of different communication channels, including a company's website, telephone, email, live chat, marketing materials, and more recently, social media. Through the CRM approach and the systems used to facilitate it, businesses learn more about their target audiences and how to best cater to their needs. However, adopting the CRM approach may also occasionally lead to favoritism within an audience of consumers, resulting in dissatisfaction among customers and defeating the purpose of CRM.\n\nThe concept of customer relationship management started in the early 1970s, when customer satisfaction was evaluated using annual surveys or by front-line asking. At that time, businesses had to rely on standalone mainframe systems to automate sales, but the extent of technology allowed them to categorize customers in spreadsheets and lists. In 1982, Kate and Robert Kestnbaum introduced the concept of Database marketing, namely applying statistical methods to analyze and gather customer data. By 1986, Pat Sullivan and Mike Muhney released a customer evaluation system called ACT! based on the principle of digital rolodex, which offered a contact management service for the first time. \n\nThe trend was followed by numerous developers trying to maximize leads' potential, including Tom Siebel, who signed the first CRM product Siebel Systems in 1993. Nevertheless, customer relationship management popularized in 1997, due to the work of Siebel, Gartner, and IBM. Between 1997 and 2000, leading CRM products were enriched with enterprise resource planning functions, and shipping and marketing capabilities. Siebel introduced the first mobile CRM app called Siebel Sales Handheld in 1999. The idea of a cloud-hosted and moveable customer bases was soon adopted by other leading providers at the time, including PeopleSoft, Oracle, and SAP.\n\nThe first open-source CRM system was developed by SugarCRM in 2004. During this period, CRM was rapidly migrating to cloud, as a result of which it became accessible to sole entrepreneurs and small teams, and underwent a huge wave of price reduction. Around 2009, developers began considering the options to profit from social media's momentum, and designed tools to help companies become accessible on all users' favorite networks. Many startups at the time benefited from this trend to provide exclusively social CRM solutions, including Base and Nutshell. The same year, Gartner organized and held the first Customer Relationship Management Summit, and summarized the features systems should offer to be classified as CRM solutions. In 2013 and 2014, most of the popular CRM products were linked to business intelligence systems and communication software to improve corporate communication and end-users' experience. The leading trend is to replace standardized CRM solutions with industry-specific ones, or to make them customizable enough to meet the needs of every business.\n\nThe primary goal of customer relationship management systems is to integrate and automate sales, marketing, and customer support. Therefore, these systems typically have a dashboard that gives an overall view of the three functions on a single customer view, a single page for each customer that a company may have. The dashboard may provide client information, past sales, previous marketing efforts, and more, summarizing all of the relationships between the customer and the firm. Operational CRM is made up of 3 main components: sales force automation, marketing automation, and service automation.\n\nThe role of analytical CRM systems is to analyze customer data collected through multiple sources, and present it so that business managers can make more informed decisions. Analytical CRM systems use techniques such as data mining, correlation, and pattern recognition to analyze the customer data. These analytics help improve customer service by finding small problems which can be solved, perhaps, by marketing to different parts of a consumer audience differently. For example, through the analysis of a customer base's buying behavior, a company might see that this customer base has not been buying a lot of products recently. After scanning through this data, the company might think to market to this subset of consumers differently, in order to best communicate how this company's products might benefit this group specifically.\n\nThe third primary aim of CRM systems is to incorporate external stakeholders such as suppliers, vendors, and distributors, and share customer information across organizations. For example, feedback can be collected from technical support call, which could help provide direction for marketing products and services to that particular customer in the future.\n\nThe main components of CRM are building and managing customer relationships through marketing, observing relationships as they mature through distinct phases, managing these relationships at each stage and recognizing that the distribution of value of a relationship to the firm is not homogenous. When building and managing customer relationships through marketing, firms might benefit from using a variety of tools to help organizational design, incentive schemes, customer structures, and more to optimize the reach of its marketing campaigns. Through the acknowledgement of the distinct phases of CRM, businesses will be able to benefit from seeing the interaction of multiple relationships as connected transactions. The final factor of CRM highlights the importance of CRM through accounting for the profitability of customer relationships. Through studying the particular spending habits of customers, a firm may be able to dedicate different resources and amounts of attention to different types of consumers.\n\nRelational Intelligence, or awareness of the variety of relationships a customer can have with a firm, is an important component to the main phases of CRM. Companies may be good at capturing demographic data, such as gender, age, income, and education, and connecting them with purchasing information to categorize customers into profitability tiers, but this is only a firm's mechanical view of customer relationships. This therefore is a sign that firms believe that customers are still resources that can be used for up-sell or cross-sell opportunities, rather than humans looking for interesting and personalized interactions.\n\nCRM systems include:\n\n\nCustomer satisfaction has important implications for the economic performance of firms because it has the ability to increase customer loyalty and usage behavior and reduce customer complaints and the likelihood of customer defection. The implementation of a CRM approach is likely to have an effect on customer satisfaction and customer knowledge for a variety of different reasons.\n\nFirstly, firms are able to customize their offerings for each customer. By accumulating information across customer interactions and processing this information to discover hidden patterns, CRM applications help firms customize their offerings to suit the individual tastes of their customers. This customization enhances the perceived quality of products and services from a customer's viewpoint, and because perceived quality is a determinant of customer satisfaction, it follows that CRM applications indirectly affect customer satisfaction. CRM applications also enable firms to provide timely, accurate processing of customer orders and requests and the ongoing management of customer accounts. For example, Piccoli and Applegate discuss how Wyndham uses IT tools to deliver a consistent service experience across its various properties to a customer. Both an improved ability to customize and a reduced variability of the consumption experience enhance perceived quality, which in turn positively affects customer satisfaction. Furthermore, CRM applications also help firms manage customer relationships more effectively across the stages of relationship initiation, maintenance, and termination.\n\nWith CRM systems customers are served better on day to day process and with more reliable information their demand of self service from companies will decrease. If there is less need to interact with the company for different problems, customer satisfaction level increases. These central benefits of CRM will be connected hypothetically to the three kinds of equity that are relationship, value and brand, and in the end to customer equity. Seven benefits were recognized to provide value drivers.\nIn 2012, after reviewing the previous studies, someone selected some of those benefits which are more significant in customer's satisfaction and summarized them into the following cases:\n\n\nResearch has found a 5% increase in customer retention boosts lifetime customer profits by 50% on average across multiple industries, as well as a boost of up to 90% within specific industries such as insurance. Companies that have mastered customer relationship strategies have the most successful CRM programs. For example, MBNA Europe has had a 75% annual profit growth since 1995. The firm heavily invests in screening potential cardholders. Once proper clients are identified, the firm retains 97% of its profitable customers. They implement CRM by marketing the right products to the right customers. The firm's customers' card usage is 52% above industry norm, and the average expenditure is 30% more per transaction. Also 10% of their account holders ask for more information on cross-sale products.\n\nAmazon has also seen great success through its customer proposition. The firm implemented personal greetings, collaborative filtering, and more for the customer. They also used CRM training for the employees to see up to 80% of customers repeat.\n\nConsultants, such as Bain & Company, argue that it is important for companies establishing strong CRM systems to improve their relational intelligence. According to this argument, a company must recognize that people have many different types of relationships with different brands. One research study analyzed relationships between consumers in China, Germany, Spain, and the United States, with over 200 brands in 11 industries including airlines, cars and media. This information is valuable as it provides demographic, behavioral, and value-based customer segmentation. These types of relationships can be both positive and negative. Some customers view themselves as friends of the brands, while others as enemies, and some are mixed with a love-hate relationship with the brand. Some relationships are distant, intimate or anything in between.\n\nManagers must understand the different reasons for the types of relationships, and provide the customer with what they are looking for. Companies can collect this information by using surveys, interviews, and more, with current customers. For example, Frito-Lay conducted many ethnographic interviews with customers to try and understand the relationships they wanted with the companies and the brands. They found that most customers were adults who used the product to feel more playful. They may have enjoyed the company's bright orange color, messiness and shape.\n\nCompanies must also improve their relational intelligence of their CRM systems. These days, companies store and receive huge amounts of data through emails, online chat sessions, phone calls, and more. Many companies do not properly make use of this great amount of data, however. All of these are signs of what types of relationships the customer wants with the firm, and therefore companies may consider investing more time and effort in building out their relational intelligence. Companies can use data mining technologies and web searches to understand relational signals. Social media such as Facebook, Twitter, blogs, etc. is also a very important factor in picking up and analyzing information. Understanding the customer and capturing this data allows companies to convert customer's signals into information and knowledge that the firm can use to understand a potential customer's desired relations with a brand.\n\nIt is also very important to analyze all of this information to determine which relationships prove the most valuable. This helps convert data into profits for the firm. Stronger bonds contribute to building market share. By managing different portfolios for different segments of the customer base, the firm can achieve strategic goals.\n\nMany firms have also implemented training programs to teach employees how to recognize and effectively create strong customer-brand relationships. For example, Harley Davidson sent its employees on the road with customers, who were motorcycle enthusiasts, to help solidify relationships. Other employees have also been trained in social psychology and the social sciences to help bolster strong customer relationships. Customer service representatives must be educated to value customer relationships, and trained to understand existing customer profiles. Even the finance and legal departments should understand how to manage and build relationships with customers.\n\nApplying new technologies while using CRM systems requires changes in infrastructure of the organization as well as deployment of new technologies such as business rules, databases and information technology.\n\nContact center CRM providers are popular for small and mid-market businesses. These systems codify the interactions between company and customers by using analytics and key performance indicators to give the users information on where to focus their marketing and customer service. This allows agents to have access to a caller's history to provide personalized customer communication. The intention is to maximize average revenue per user, decrease churn rate and decrease idle and unproductive contact with the customers.\n\nGrowing in popularity is the idea of gamifying, or using game design elements and game principles in a non-game environment such as customer service environments. The gamification of customer service environments includes providing elements found in games like rewards and bonus points to customer service representatives as a method of feedback for a job well done.\nGamification tools can motivate agents by tapping into their desire for rewards, recognition, achievements, and competition.\n\nContact center automation, the practice of having an integrated system that coordinates contacts between an organization and the public, is designed to reduce the repetitive and tedious parts of a contact center agent's job. Automation prevents this by having pre-recorded audio messages that help customers solve their problems. For example, an automated contact center may be able to re-route a customer through a series of commands asking him or her to select a certain number in order to speak with a particular contact center agent who specializes in the field in which the customer has a question. Software tools can also integrate with the agent's desktop tools to handle customer questions and requests. This also saves time on behalf of the employees.\n\nSocial CRM involves the use of social media and technology to engage and learn from consumers. Because the public, especially among young people, has increasingly using social networking sites, companies use these sites to draw attention to their products, services and brands, with the aim of building up customer relationships to increase demand.\n\nSome CRM systems integrate social media sites like Twitter, LinkedIn and Facebook to track and communicate with customers. These customers also share their own opinions and experiences with a company's products and services, giving these firms more insight. Therefore, these firms can both share their own opinions and also track the opinions of their customers.\n\nEnterprise feedback management software platforms, such as Confirmit, Medallia, and Satmetrix, combine internal survey data with trends identified through social media to allow businesses to make more accurate decisions on which products to supply.\n\nCRM systems can also include technologies that create geographic marketing campaigns. The systems take in information based on a customer's physical location and sometimes integrates it with popular location-based GPS applications. It can be used for networking or contact management as well to help increase sales based on location.\n\nDespite the general notion that CRM systems were created for the customer-centric businesses, they can also be applied to B2B environments to streamline and improve customer management conditions. For the best level of CRM operation in a B2B environment, the software must be personalized and delivered at individual levels.\n\nThe main differences between business-to-consumer (B2C) and business-to-business CRM systems concern aspects like sizing of contact databases and length of relationships. Business-to-business companies tend to have smaller contact databases than business-to-consumer, the volume of sales in business-to-business is relatively small. There are fewer figure propositions in business-to-business, but in some cases, they cost a lot more than business-to-consumer items and relationships in business-to-business environment are built over a longer period of time. Furthermore, business-to-business CRM must be easily integrated with products from other companies. Such integration enables the creation of forecasts about customer behavior based on their buying history, bills, business success, etc. An application for a business-to-business company must have a function to connect all the contacts, processes and deals among the customers segment and then prepare a paper. Automation of sales process is an important requirement for business-to-business products. It should effectively manage the deal and progress it through all the phases towards signing. Finally, a crucial point is personalization. It helps the business-to-business company to create and maintain strong and long-lasting relationship with the customer.\n\nThe overall CRM market grew by 12.3 percent in 2015. The following table lists the top vendors in 2006–2008 and 2012-2014 (figures in millions of US dollars) published in Gartner studies.\n\nThe four largest vendors with CRM system offerings are Salesforce, SAP, Oracle, and Microsoft, which represented 42 percent of the market in 2015. Other providers also are popular for small and mid market businesses. Splitting CRM providers into nine different categories (Enterprise CRM Suite, Midmarket CRM Suite, Small-Business CRM Suite, sales force automation, incentive management, marketing solutions, business intelligence, data quality, consultancies), each category has a different market leader. Additionally, applications often focus on professional fields such as healthcare, manufacturing, and other areas with branche-specific requirements.\n\nIn the Gartner CRM Summit 2010 challenges like \"system tries to capture data from social networking traffic like Twitter, handles Facebook page addresses or other online social networking sites\" were discussed and solutions were provided that would help in bringing more clientele. Many CRM vendors offer subscription-based web tools (cloud computing) and SaaS. Some CRM systems are equipped with mobile capabilities, making information accessible to remote sales staff.Salesforce.com was the first company to provide enterprise applications through a web browser, and has maintained its leadership position. \n\nTraditional providers have recently moved into the cloud-based market via acquisitions of smaller providers: Oracle purchased RightNow in October 2011 and SAP acquired SuccessFactors in December 2011.\n\nThe era of the \"social customer\" refers to the use of social media (Twitter, Facebook, LinkedIn, Google Plus, Pinterest, Instagram, Yelp, customer reviews in Amazon, etc.) by customers. CRM philosophy and strategy has shifted to encompass social networks and user communities.\n\nSales forces also play an important role in CRM, as maximizing sales effectiveness and increasing sales productivity is a driving force behind the adoption of CRM. Empowering sales managers was listed as one of the top 5 CRM trends in 2013.\n\nAnother related development is vendor relationship management (VRM), which provide tools and services that allow customers to manage their individual relationship with vendors. VRM development has grown out of efforts by ProjectVRM at Harvard's Berkman Center for Internet & Society and Identity Commons' Internet Identity Workshops, as well as by a growing number of startups and established companies. VRM was the subject of a cover story in the May 2010 issue of \"CRM\" Magazine.\n\nPharmaceutical companies were some of the first investors in sales force automation (SFA) and some are on their third- or fourth-generation implementations. However, until recently, the deployments did not extend beyond SFA—limiting their scope and interest to Gartner analysts.\n\nAnother trend worth noting is the rise of Customer Success as a discipline within companies. More and more companies establish Customer Success teams as separate from the traditional Sales team and task them with managing existing customer relations. This trend fuels demand for additional capabilities for more holistic understanding of the customer health, which is a limitation for many existing vendors in the space. As a result, a growing number of new entrants enter the market, while existing vendors add capabilities in this area to their suites. In 2017, artificial intelligence and predictive analytics were identified as the newest trends in CRM.\n\nCompanies face large challenges when trying to implement CRM systems. Consumer companies frequently manage their customer relationships haphazardly and unprofitably. They may not effectively or adequately use their connections with their customers, due to misunderstandings or misinterpretations of a CRM system's analysis. Clients who want to be treated more like a friend may be treated like just a party for exchange, rather than a unique individual, due to, occasionally, a lack of a bridge between the CRM data and the CRM analysis output. Many studies show that customers are frequently frustrated by a company's inability to meet their relationship expectations, and on the other side, companies do not always know how to translate the data they have gained from CRM software into a feasible action plan. In 2003, a Gartner report estimated that more than $2 billion had been spent on software that was not being used. According to CSO Insights, less than 40 percent of 1,275 participating companies had end-user adoption rates above 90 percent. Many corporations only use CRM systems on a partial or fragmented basis. In a 2007 survey from the UK, four-fifths of senior executives reported that their biggest challenge is getting their staff to use the systems they had installed. 43 percent of respondents said they use less than half the functionality of their existing systems. However, market research regarding consumers' preferences may increase the adoption of CRM among the developing countries' consumers.\n\nCollection of customer data such as personally identifiable information must strictly obey customer privacy laws, which often requires extra expenditures on legal support.\n\nPart of the paradox with CRM stems from the challenge of determining exactly what CRM is and what it can do for a company. The CRM paradox, also referred to as the \"Dark side of CRM\", may entail favoritism and differential treatment of some customers. This may cause perceptions of unfairness among other customers' buyers. They may opt out of relationships, spread negative information, or engage in misbehavior that may damage the firm and its reputation. Such perceived inequality may cause dissatisfaction, mistrust and result in unfair practices. A customer shows trust when he or she engages in a relationship with a firm under the idea that the firm is acting fairly and adding value to his or her life somehow. However, customers may not trust that firms will be fair in splitting the value of their products or services. For example, Amazon's test use of dynamic pricing (different prices for different customers) ended with very poor public relations for the company. As seen in the Amazon example, although firms use both human and technological factors to assess a proper CRM process, experts suggest that focusing on the human factors, like management, increases the potential of successful CRM, since managers can make a coordinated effort on organizational changes within a company, which often affects customer satisfaction.\n\nCRM technologies can easily become ineffective if there is no proper management, and they are not implemented correctly. The data sets must also be connected, distributed, and organized properly, so that the users can access the information that they need quickly and easily. Research studies also show that customers are increasingly becoming dissatisfied with contact center experiences due to lags and wait times. They also request and demand multiple channels of communications with a company, and these channels must transfer information seamlessly. Therefore, it is increasingly important for companies to deliver a cross-channel customer experience that can be both consistent as well as reliable.\n"}
{"id": "6970", "url": "https://en.wikipedia.org/wiki?curid=6970", "title": "Chuck-a-luck", "text": "Chuck-a-luck\n\nChuck-a-luck, also known as birdcage, is a game of chance played with three dice. It is derived from grand hazard and both can be considered a variant of sic bo, which is a popular casino game, although chuck-a-luck is more of a carnival game than a true casino game. The game is sometimes used as a fundraiser for charity.\n\nChuck-a-luck is played with three standard dice that are kept in a device shaped somewhat like an hourglass that resembles a wire-frame bird cage and pivots about its centre. The dealer rotates the cage end over end, with the dice landing on the bottom.\n\nWagers are placed based on possible combinations that can appear on the three dice. The possible wagers are usually fewer than the wagers that are possible in sic bo and, in that sense, chuck-a-luck can be considered to be a simpler game.\n\nThe wagers, and their associated odds, that are typically available are set out in the table below.\n\nChuck-a-luck is a game of chance. That is, on average, the players are expected to lose more than they win. The casino's advantage (house advantage or house edge) is greater than most other casino games and can be much greater.\n\nFor example, there are 216 (6 × 6 × 6) possible outcomes for a single throw of three dice. For a specific number:\n\n\nAt odds of 1 to 1, 2 to 1 and 10 to 1 respectively for each of these types of outcome, the expected loss as a percentage of the stake wagered is:\n\n1 - ((75/216) × 2 + (15/216) × 3 + (1/216) × 11) = 4.6%\n\nAt worse odds of 1 to 1, 2 to 1 and 3 to 1, the expected loss as a percentage of the stake wagered is:\n\n1 - ((75/216) × 2 + (15/216) × 3 + (1/216) × 4) = 7.9%\n\nIt should be noted that if the odds are adjusted to 1 to 1, 3 to 1 and 5 to 1 respectively, the expected loss as a percentage is:\n\n1 - ((75/216) × 2 + (15/216) × 4 + (1/216) × 6) = 0%\n\nHowever, commercially organised gambling games always have a house advantage which acts as a fee for the privilege of being allowed to play the game, so the last scenario does not represent real practice.\n\n\nThere is a reference to chuck-a-luck in the Abbott and Costello film \"Hold That Ghost\".\n\nIn Fritz Lang's 1952 film, \"Rancho Notorious\", chuck-a-luck is the name of the ranch run by Altar Keane (played by Marlene Dietrich) where outlaws hide from the law. Chuck-a-luck is featured in the lyrics to the theme song and in some plot points.\n\nThe game is played by Lazar in the James Bond movie \"The Man with the Golden Gun\".\n\nThe game is played by Freddie Rumsen in \"Mad Men Season 2 Episode 9: Six-Month Leave\".\n\n\nAnthonyThomas01.com.\n"}
{"id": "6972", "url": "https://en.wikipedia.org/wiki?curid=6972", "title": "Chipmunk", "text": "Chipmunk\n\nChipmunks are small, striped rodents of the family Sciuridae. Chipmunks are found in North America, with the exception of the Siberian chipmunk which is found primarily in Asia.\n\nChipmunks may be classified either as a single genus, \"Tamias\" (), or as three genera: \"Tamias\", which includes the eastern chipmunk; \"Eutamias\", which includes the Siberian chipmunk; and \"Neotamias\", which includes the 23 remaining, mostly western, species. These classifications are arbitrary, and most taxonomies over the twentieth century have placed the chipmunks in a single genus. However, studies of mitochondrial DNA show that the divergence between each of the three chipmunk groups is comparable to the genetic dissimilarity between \"Marmota\" and \"Spermophilus\".\n\nThe genus name \"Tamias\" is Greek for \"treasurer\", \"steward\", or \"housekeeper\", which is a reference to the animals' role in plant dispersal through their habit of collecting and storing food for winter use.\n\nThe common name originally may have been spelled \"chitmunk,\" from the native Odawa (Ottawa) word \"jidmoonh\", meaning \"red squirrel\" (\"cf.\" Ojibwe, \"ajidamoo\"). The earliest form cited in the \"Oxford English Dictionary\" (from 1842) is \"chipmonk,\" however, \"chipmunk\" appears in several books from the 1820s and 1830s. Other early forms include \"chipmuck\" and \"chipminck,\" and in the 1830s they were also referred to as \"chip squirrels;\" probably in reference to the sound they make. In the mid-1800s, John James Audubon and his sons included a lithograph of the chipmunk in their \"Viviparous Quadrupeds of North America\", calling it the \"chipping squirrel [or] hackee.\" Chipmunks have also been referred to as \"striped squirrels,\" \"timber tigers,\" and \"ground squirrels\" (although the name \"ground squirrel\" usually refers to other squirrels, such as those of the genus \"Spermophilus\").\n\nChipmunks have an omnivorous diet primarily consisting of seeds, nuts and other fruits, and buds. They also commonly eat grass, shoots, and many other forms of plant matter, as well as fungi, insects and other arthropods, small frogs, worms, and bird eggs. Around humans, chipmunks can eat cultivated grains and vegetables, and other plants from farms and gardens, so they are sometimes considered pests. Chipmunks mostly forage on the ground, but they climb trees to obtain nuts such as hazelnuts and acorns. At the beginning of autumn, many species of chipmunk begin to stockpile nonperishable foods for winter. They mostly cache their foods in a larder in their burrows and remain in their nests until spring, unlike some other species which make many small caches of food. Cheek pouches allow chipmunks to carry food items to their burrows for either storage or consumption.\n\nEastern chipmunks mate in early spring and again in early summer, producing litters of four or five young twice each year. Western chipmunks breed only once a year. The young emerge from the burrow after about six weeks and strike out on their own within the next two weeks.\n\nThese small mammals fulfill several important functions in forest ecosystems. Their activities harvesting and hoarding tree seeds play a crucial role in seedling establishment. They consume many different kinds of fungi, including those involved in symbiotic mycorrhizal associations with trees, and are an important vector for dispersal of the spores of subterranean sporocarps (truffles) which have co-evolved with these and other mycophagous mammals and thus lost the ability to disperse their spores through the air.\n\nChipmunks construct expansive burrows which can be more than in length with several well-concealed entrances. The sleeping quarters are kept clean as shells and feces are stored in refuse tunnels.\n\nThe eastern chipmunk hibernates in the winter, while western chipmunks do not, relying on the stores in their burrows.\n\nChipmunks play an important role as prey for various predatory mammals and birds but are also opportunistic predators themselves, particularly with regard to bird eggs and nestlings, as in the case of eastern chipmunks and mountain bluebirds (\"Siala currucoides\").\n\nChipmunks typically live about three years although some have been observed living to nine years in captivity.\n\nChipmunks in captivity are said to sleep for an average of about 15 hours a day. It is thought that mammals which can sleep in hiding, such as rodents and bats, tend to sleep longer than those that must remain on alert.\n\nSubgenus \"Eutamias\"\n\nSubgenus \"Tamias\"\n\nSubgenus \"Neotamias\"\n\nExtinct:\n\n\n\n"}
{"id": "6974", "url": "https://en.wikipedia.org/wiki?curid=6974", "title": "Computer music", "text": "Computer music\n\nComputer music is the application of computing technology in music composition, to help human composers create new music or to have computers independently create music, such as with algorithmic composition programs. It includes the theory and application of new and existing computer software technologies and basic aspects of music, such as sound synthesis, digital signal processing, sound design, sonic diffusion, acoustics, and psychoacoustics. The field of computer music can trace its roots back to the origins of electronic music, and the very first experiments and innovations with electronic instruments at the turn of the 20th century.\n\nIn the 2000s, with the widespread availability of relatively affordable home computers that have a fast processing speed, and the growth of home recording using digital audio recording systems ranging from Garageband to Protools, the term is sometimes used to describe music that has been created using digital technology.\n\nMuch of the work on computer music has drawn on the relationship between music theory and mathematics, a relationship which has been noted since the Ancient Greeks described the \"harmony of the spheres\". The world's first computer to play music was CSIRAC, which was designed and built by Trevor Pearcey and Maston Beard in the 1950s. Mathematician Geoff Hill programmed the CSIRAC to play popular musical melodies from the very early 1950s. In 1951 it publicly played the \"Colonel Bogey March\" of which no known recordings exist.\nHowever, CSIRAC played standard repertoire and was not used to extend musical thinking or composition practice which is current computer-music practice.\n\nThe oldest known recordings of computer generated music were played by the Ferranti Mark 1 computer, a commercial version of the Baby Machine from the University of Manchester in the autumn of 1951. The music program was written by Christopher Strachey. During a session recorded by the BBC, the machine managed to work its way through \"Baa Baa Black Sheep\", \"God Save the King\" and part of \"In the Mood\".\n\nTwo further major 1950s developments were the origins of digital sound synthesis by computer, and of algorithmic composition programs beyond rote playback. Max Mathews at Bell Laboratories developed the influential MUSIC I program and its descendents, further popularising computer music through a 1963 article in \"Science\". Amongst other pioneers, the musical chemists Lejaren Hiller and Leonard Isaacson worked on a series of algorithmic composition experiments from 1956-9, manifested in the 1957 premiere of the \"Illiac Suite\" for string quartet.\n\nIn Japan, experiments in computer music date back to 1962, when Keio University professor Sekine and Toshiba engineer Hayashi experimented with the computer. This resulted in a piece entitled \"TOSBAC Suite\", influenced by the \"Illiac Suite\". Later Japanese computer music compositions include a piece by Kenjiro Ezaki presented during Osaka Expo '70 and \"Panoramic Sonore\" (1974) by music critic Akimichi Takeda. Ezaki also published an article called \"Contemporary Music and Computers\" in 1970. Since then, Japanese research in computer music has largely been carried out for commercial purposes in popular music, though some of the more serious Japanese musicians used large computer systems such as the \"Fairlight\" in the 1970s.\n\nEarly computer-music programs typically did not run in real time. Programs would run for hours or days, on multimillion-dollar computers, to generate a few minutes of music. One way around this was to use a 'hybrid system', most notably the Roland MC-8 Microcomposer, where a microprocessor-based system controls an analog synthesizer, released in 1978. John Chowning's work on FM synthesis from the 1960s to the 1970s allowed much more efficient digital synthesis, eventually leading to the development of the affordable FM synthesis-based Yamaha DX7 digital synthesizer, released in 1983. In addition to the Yamaha DX7, the advent of inexpensive digital chips and microcomputers opened the door to real-time generation of computer music. In the 1980s, Japanese personal computers such as the NEC PC-88 came installed with FM synthesis sound chips and featured audio programming languages such as Music Macro Language (MML) and MIDI interfaces, which were most often used to produce video game music, or chiptunes. By the early 1990s, the performance of microprocessor-based computers reached the point that real-time generation of computer music using more general programs and algorithms became possible.\nInteresting sounds must have a fluidity and changeability that allows them to remain fresh to the ear. In computer music this subtle ingredient is bought at a high computational cost, both in terms of the number of items requiring detail in a score and in the amount of interpretive work the instruments must produce to realize this detail in sound. \n\nAdvances in computing power and software for manipulation of digital media have dramatically affected the way computer music is generated and performed. Current-generation micro-computers are powerful enough to perform very sophisticated audio synthesis using a wide variety of algorithms and approaches. Computer music systems and approaches are now ubiquitous, and so firmly embedded in the process of creating music that we hardly give them a second thought: computer-based synthesizers, digital mixers, and effects units have become so commonplace that use of digital rather than analog technology to create and record music is the norm, rather than the exception.\n\nDespite the ubiquity of computer music in contemporary culture, there is considerable activity in the field of computer music, as researchers continue to pursue new and interesting computer-based synthesis, composition, and performance approaches. Throughout the world there are many organizations and institutions dedicated to the area of computer and electronic music study and research, including the ICMA (International Computer Music Association), IRCAM, GRAME, SEAMUS (Society for Electro Acoustic Music in the United States), CEC (Canadian Electroacoustic Community), and a great number of institutions of higher learning around the world.\n\nComputer-generated music is music composed by, or with the extensive aid of, a computer. Although any music which uses computers in its composition or realisation is computer-generated to some extent, the use of computers is now so widespread (in the editing of pop songs, for instance) that the phrase computer-generated music is generally used to mean a kind of music which could not have been created \"without\" the use of computers.\n\nWe can distinguish two groups of computer-generated music: music in which a computer generated the score, which could be performed by humans, and music which is both composed and performed by computers. There is a large genre of music that is organized, synthesized, and created on computers.\n\nLater, composers such as Gottfried Michael Koenig had computers generate the sounds of the composition as well as the score. Koenig produced algorithmic composition programs which were a generalisation of his own serial composition practice. This is not exactly similar to Xenakis' work as he used mathematical abstractions and examined how far he could explore these musically. Koenig's software translated the calculation of mathematical equations into codes which represented musical notation. This could be converted into musical notation by hand and then performed by human players. His programs Project 1 and Project 2 are examples of this kind of software. Later, he extended the same kind of principles into the realm of synthesis, enabling the computer to produce the sound directly. SSP is an example of a program which performs this kind of function. All of these programs were produced by Koenig at the Institute of Sonology in Utrecht in the 1970s.\n\nProcedures such as those used by Koenig and Xenakis are still in use today. Since the invention of the MIDI system in the early 1980s, for example, some people have worked on programs which map MIDI notes to an algorithm and then can either output sounds or music through the computer's sound card or write an audio file for other programs to play.\n\nSome of these simple programs are based on fractal geometry, and can map midi notes to specific fractals, or fractal equations. Although such programs are widely available and are sometimes seen as clever toys for the non-musician, some professional musicians have given them attention also. The resulting 'music' can be more like noise, or can sound quite familiar and pleasant. As with much algorithmic music, and algorithmic art in general, more depends on the way in which the parameters are mapped to aspects of these equations than on the equations themselves. Thus, for example, the same equation can be made to produce both a lyrical and melodic piece of music in the style of the mid-nineteenth century, and a fantastically dissonant cacophony more reminiscent of the avant-garde music of the 1950s and 1960s.\n\nOther programs can map mathematical formulae and constants to produce sequences of notes. In this manner, an irrational number can give an infinite sequence of notes where each note is a digit in the decimal expression of that number. This sequence can in turn be a composition in itself, or simply the basis for further elaboration.\n\nOperations such as these, and even more elaborate operations can also be performed in computer music programming languages such as Max/MSP, SuperCollider, Csound, Pure Data (Pd), Keykit, and ChucK. These programs now easily run on most personal computers, and are often capable of more complex functions than those which would have necessitated the most powerful mainframe computers several decades ago.\n\nThere exist programs that generate \"human-sounding\" melodies by using a vast database of phrases. One example is Band-in-a-Box, which is capable of creating jazz, blues and rock instrumental solos with almost no user interaction. Another is Impro-Visor, which uses a stochastic context-free grammar to generate phrases and complete solos.\n\nAnother 'cybernetic' approach to computer composition uses specialized hardware to detect external stimuli which are then mapped by the computer to realize the performance. Examples of this style of computer music can be found in the middle-80's work of David Rokeby (Very Nervous System) where audience/performer motions are 'translated' to MIDI segments. Computer controlled music is also found in the performance pieces by the Canadian composer Udo Kasemets such as the Marce(ntennia)l Circus C(ag)elebrating Duchamp (1987), a realization of the Marcel Duchamp process piece \"Erratum Musical\" using an electric model train to collect a hopper-car of stones to be deposited on a drum wired to an Analog:Digital converter, mapping the stone impacts to a score display (performed in Toronto by pianist Gordon Monahan during the 1987 Duchamp Centennial), or his installations and performance works (e.g. Spectrascapes) based on his Geo(sono)scope (1986) 15x4-channel computer-controlled audio mixer. In these latter works, the computer generates sound-scapes from tape-loop sound samples, live shortwave or sine-wave generators.\n\nMany systems for generating musical scores actually existed well before the time of computers. One of these was Musikalisches Würfelspiel \"(Musical dice game\"; 18th century), a system which used throws of the dice to randomly select measures from a large collection of small phrases. When patched together, these phrases combined to create musical pieces which could be performed by human players. Although these works were not actually composed with a computer in the modern sense, it uses a rudimentary form of the random combinatorial techniques sometimes used in computer-generated composition.\n\nThe world's first digital computer music was generated in Australia by programmer Geoff Hill on the CSIRAC computer which was designed and built by Trevor Pearcey and Maston Beard, although it was only used to play standard tunes of the day. Subsequently, one of the first composers to write music with a computer was Iannis Xenakis. He wrote programs in the FORTRAN language that generated numeric data that he transcribed into scores to be played by traditional musical instruments. An example is \"ST/48\" of 1962. Although Xenakis could well have composed this music by hand, the intensity of the calculations needed to transform probabilistic mathematics into musical notation was best left to the number-crunching power of the computer.\n\nComputers have also been used in an attempt to imitate the music of great composers of the past, such as Mozart. A present exponent of this technique is David Cope. He wrote computer programs that analyse works of other composers to produce new works in a similar style. He has used this program to great effect with composers such as Bach and Mozart (his program \"Experiments in Musical Intelligence\" is famous for creating \"Mozart's 42nd Symphony\"), and also within his own pieces, combining his own creations with that of the computer.\n\nMelomics, a research project from the University of Málaga, Spain, developed a computer composition cluster named Iamus, which composes complex, multi-instrument pieces for editing and performance. Since its inception, Iamus has composed a full album in 2012, appropriately named Iamus, which New Scientist described as \"The first major work composed by a computer and performed by a full orchestra.\" The group has also developed an API for developers to utilize the technology, and makes its music available on its website.\n\nComputer-aided algorithmic composition (CAAC, pronounced \"sea-ack\") is the implementation and use of algorithmic composition techniques in software. This label is derived from the combination of two labels, each too vague for continued use. The label \"computer-aided composition\" lacks the specificity of using generative algorithms. Music produced with notation or sequencing software could easily be considered computer-aided composition. The label \"algorithmic composition\" is likewise too broad, particularly in that it does not specify the use of a computer. The term computer-aided, rather than computer-assisted, is used in the same manner as computer-aided design.\n\nMachine improvisation uses computer algorithms to create improvisation on existing music materials. This is usually done by sophisticated recombination of musical phrases extracted from existing music, either live or pre-recorded. In order to achieve credible improvisation in particular style, machine improvisation uses machine learning and pattern matching algorithms to analyze existing musical examples. The resulting patterns are then used to create new variations \"in the style\" of the original music, developing a notion of stylistic reinjection.\nThis is different from other improvisation methods with computers that use algorithmic composition to generate new music without performing analysis of existing music examples.\n\nStyle modeling implies building a computational representation of the musical surface that captures important stylistic features from data. Statistical approaches are used to capture the redundancies in terms of pattern dictionaries or repetitions, which are later recombined to generate new musical data. Style mixing can be realized by analysis of a database containing multiple musical examples in different styles. Machine Improvisation builds upon a long musical tradition of statistical modeling that began with Hiller and Isaacson's \"Illiac Suite for String Quartet\" (1957) and Xenakis' uses of Markov chains and stochastic processes. Modern methods include the use of lossless data compression for incremental parsing, prediction suffix tree and string searching by factor oracle algorithm (basically a \"factor oracle\" is a ﬁnite state automaton constructed in linear time and space in an incremental fashion).\n\nMachine improvisation encourages musical creativity by providing automatic modeling and transformation structures for existing music. This creates a natural interface with the musician without need for coding musical algorithms. In live performance, the system re-injects the musician's material in several different ways, allowing a semantics-level representation of the session and a smart recombination and transformation of this material in real-time. In offline version, machine improvisation can be used to achieve style mixing, an approach inspired by Vannevar Bush's memex imaginary machine.\n\nThe first system implementing interactive machine improvisation by means of Markov models and style modeling techniques is the Continuator, , developed by François Pachet at Sony CSL Paris in 2002 based on work on non-real time style modeling.\nMatlab implementation of the Factor Oracle machine improvisation can be found as part of Computer Audition toolbox.\n\nOMax is a software environment developed in IRCAM. OMax uses OpenMusic and Max. It is based on researches on stylistic modeling carried out by Gerard Assayag and Shlomo Dubnov and on researches on improvisation with the computer by G. Assayag, M. Chemillier and G. Bloch (a.k.a. the \"OMax Brothers\") in the Ircam Music Representations group.\n\nGerard Assayag (IRCAM, France),\nJeremy Baguyos (University of Nebraska at Omaha, USA)\nTim Blackwell (Goldsmiths College, Great Britain),\nGeorge Bloch (Composer, France),\nMarc Chemiller (IRCAM/CNRS, France),\nNick Collins (University of Sussex, UK),\nShlomo Dubnov (Composer, Israel / USA),\nMari Kimura (Juilliard, New York City),\nGeorge Lewis (Columbia University, New York City),\nBernard Lubat (Pianist, France),\nFrançois Pachet (Sony CSL, France),\nJoel Ryan (Institute of Sonology, Netherlands),\nMichel Waisvisz (STEIM, Netherlands),\nDavid Wessel (CNMAT, California),\nMichael Young (Goldsmiths College, Great Britain),\nPietro Grossi (CNUCE, Institute of the National Research Council, Pisa, Italy),\nToby Gifford and Andrew Brown (Griffith University, Brisbane, Australia),\nDavis Salks (jazz composer, Hamburg, PA, USA),\nDoug Van Nort (electroacoustic improviser, Montreal/New York)\n\nLive coding (sometimes known as 'interactive programming', 'on-the-fly programming', 'just in time programming') is the name given to the process of writing software in realtime as part of a performance. Recently it has been explored as a more rigorous alternative to laptop musicians who, live coders often feel, lack the charisma and pizzazz of musicians performing live.\n\nGenerally, this practice stages a more general approach: one of interactive programming, of writing (parts of) programs while they are interpreted. Traditionally most computer music programs have tended toward the old write/compile/run model which evolved when computers were much less powerful. This approach has locked out code-level innovation by people whose programming skills are more modest. Some programs have gradually integrated real-time controllers and gesturing (for example, MIDI-driven software synthesis and parameter control). Until recently, however, the musician/composer rarely had the capability of real-time modification of program code itself. This legacy distinction is somewhat erased by languages such as ChucK, SuperCollider, and Impromptu.\n\nTOPLAP, an ad-hoc conglomerate of artists interested in live coding was formed in 2004, and promotes the use, proliferation and exploration of a range of software, languages and techniques to implement live coding. This is a parallel and collaborative effort e.g. with research at the Princeton Sound Lab, the University of Cologne, and the Computational Arts Research Group at Queensland University of Technology.\n\n\n"}
{"id": "6978", "url": "https://en.wikipedia.org/wiki?curid=6978", "title": "Concept", "text": "Concept\n\nConcepts are the fundamental building blocks of our thoughts and beliefs. They play an important role in all aspects of cognition.\n\nConcepts arise as abstractions or generalisations from experience; from the result of a transformation of existing ideas; or from innate properties. A concept is instantiated (reified) by all of its actual or potential instances, whether these are things in the real world or other ideas.\n\nConcepts are studied as components of human cognition in the cognitive science disciplines of linguistics, psychology and philosophy, where an ongoing debate asks whether all cognition must occur through concepts. Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence where they are sometimes called classes, schema or categories. In informal use the word \"concept\" often just means any idea, but formally it involves the abstraction component. Concepts are sometimes known by other names in everyday language such as \"kinds\", \"types\" or \"sorts\", as in \"an oak is a kind of tree\", or \"this object is a kind of tree\".\n\nIn metaphysics, and especially ontology, a concept is a fundamental category of existence. In contemporary philosophy, there are at least three prevailing ways to understand what a concept is:\n\n\nConcepts can be organized into a hierarchy, higher levels of which are termed \"superordinate\" and lower levels termed \"subordinate\". Additionally, there is the \"basic\" or \"middle\" level at which people will most readily categorize a concept. For example, a basic-level concept would be \"chair\", with its superordinate, \"furniture\", and its subordinate, \"easy chair\".\n\nIn a platonist theory of mind, concepts are construed as abstract objects. This debate concerns the ontological status of concepts – what they are really like.\n\nThere is debate as to the relationship between concepts and natural language. However, it is necessary at least to begin by understanding that the concept \"dog\" is philosophically distinct from the things in the world grouped by this concept – or the reference class or extension. Concepts that can be equated to a single word are called \"lexical concepts\".\n\nStudy of concepts and conceptual structure falls into the disciplines of linguistics, philosophy, psychology, and cognitive science.\n\nIn the simplest terms, a concept is a name or label that regards or treats an abstraction as if it had concrete or material existence, such as a person, a place, or a thing. It may represent a natural object that exists in the real world like a tree, an animal, a stone, etc. It may also name an artificial (man-made) object like a chair, computer, house, etc. Abstract ideas and knowledge domains such as freedom, equality, science, happiness, etc., are also symbolized by concepts. It is important to realize that a concept is merely a symbol, a representation of the abstraction. The word is not to be mistaken for the thing. For example, the word \"moon\" (a concept) is not the large, bright, shape-changing object up in the sky, but only \"represents\" that celestial object. Concepts are created (named) to describe, explain and capture reality as it is known and understood.\n\nKant declared that human minds possess pure or \"a priori\" concepts. Instead of being abstracted from individual perceptions, like empirical concepts, they originate in the mind itself. He called these concepts categories, in the sense of the word that means predicate, attribute, characteristic, or quality. But these pure categories are predicates of things \"in general\", not of a particular thing. According to Kant, there are 12 categories that constitute the understanding of phenomenal objects. Each category is that one predicate which is common to multiple empirical concepts. In order to explain how an \"a priori\" concept can relate to individual phenomena, in a manner analogous to an \"a posteriori\" concept, Kant employed the technical concept of the schema. He held that the account of the concept as an abstraction of experience is only partly correct. He called those concepts that result from abstraction \"a posteriori concepts\" (meaning concepts that arise out of experience). An empirical or an \"a posteriori\" concept is a general representation (\"Vorstellung\") or non-specific thought of that which is common to several specific perceived objects (Logic, I, 1., §1, Note 1)\n\nA concept is a common feature or characteristic. Kant investigated the way that empirical \"a posteriori\" concepts are created.\nIn cognitive linguistics, abstract concepts are transformations of concrete concepts derived from embodied experience. The mechanism of transformation is structural mapping, in which properties of two or more source domains are selectively mapped onto a blended space (Fauconnier & Turner, 1995; see conceptual blending). A common class of blends are metaphors. This theory contrasts with the rationalist view that concepts are perceptions (or \"recollections\", in Plato's term) of an independently existing world of ideas, in that it denies the existence of any such realm. It also contrasts with the empiricist view that concepts are abstract generalizations of individual experiences, because the contingent and bodily experience is preserved in a concept, and not abstracted away. While the perspective is compatible with Jamesian pragmatism, the notion of the transformation of embodied concepts through structural mapping makes a distinct contribution to the problem of concept formation.\n\nPlato was the starkest proponent of the realist thesis of universal concepts. By his view, concepts (and ideas in general) are innate ideas that were instantiations of a transcendental world of pure forms that lay behind the veil of the physical world. In this way, universals were explained as transcendent objects. Needless to say this form of realism was tied deeply with Plato's ontological projects. This remark on Plato is not of merely historical interest. For example, the view that numbers are Platonic objects was revived by Kurt Gödel as a result of certain puzzles that he took to arise from the phenomenological accounts.\n\nGottlob Frege, founder of the analytic tradition in philosophy, famously argued for the analysis of language in terms of sense and reference. For him, the sense of an expression in language describes a certain state of affairs in the world, namely, the way that some object is presented. Since many commentators view the notion of sense as identical to the notion of concept, and Frege regards senses as the linguistic representations of states of affairs in the world, it seems to follow that we may understand concepts as the manner in which we grasp the world. Accordingly, concepts (as senses) have an ontological status (Morgolis:7).\n\nAccording to Carl Benjamin Boyer, in the introduction to his \"The History of the Calculus and its Conceptual Development\", concepts in calculus do not refer to perceptions. As long as the concepts are useful and mutually compatible, they are accepted on their own. For example, the concepts of the derivative and the integral are not considered to refer to spatial or temporal perceptions of the external world of experience. Neither are they related in any way to mysterious limits in which quantities are on the verge of nascence or evanescence, that is, coming into or going out of existence. The abstract concepts are now considered to be totally autonomous, even though they originated from the process of abstracting or taking away qualities from perceptions until only the common, essential attributes remained.\n\nCan two people ever come to learn exactly the same concept? If person A has seen 100 trees and person B has seen a different 100 trees, they will not always generalize the same set of features in their concept of trees. The two concepts are sometimes written as TREE_A and TREE_B to emphasise their difference. If A and B have these different concepts, and intend them by their use of the English word, \"tree\", then how can they ever have a meaningful debate to decide the truth of a statement about \"trees\"? A statement that is true of TREE_A may be false of TREE_B, and the two parties will talk past one another. Concept theorists suggest that this is the root of many, especially political, disagreements in the world, and that more productive resolutions should be found by the participants exploring each other's different concepts and trying to locate the conceptual source of the disagreement.\n\nThe situation becomes even more complex when reasoning about other people's beliefs. For example, is the statement \"George Bush thinks conservatism is bad\" true or false? Bush presumably possesses some concept in his own mind, CONSERVATISM_BUSH, but the reasoner (eg. ones self) does not have access to this exact concept. If the reasoner is a liberal, it is likely that their concept CONSERVATISM_REASONER will be defined differently to that of Bush. It is likely that it will contain many properties which are bad. The reasoner can conclude that \"CONSERVATISM_REASONER is bad\", and might even have reason to believe that if this version of the concept was explained to Bush, then Bush would also think it is bad. But the reasoner has no access to Bush's own concept and can therefore assign no deep truth value to statements about it. They might have heard Bush say \"conservatism is good\" and thus have evidence that \"Bush thinks CONSERVATISM_BUSH is good\", but this is only a weak statement about the Fregean sense of the concept and not its (deep) referent. Concept theorists again suggest that this type of confusion could help to resolve many real-world, especially political, disagreements.\n\nIn a physicalist theory of mind, a concept is a mental representation, which the brain uses to denote a class of things in the world. This is to say that it is literally, a symbol or group of symbols together made from the physical material of the brain. Concepts are mental representations that allow us to draw appropriate inferences about the type of entities we encounter in our everyday lives. Concepts do not encompass all mental representations, but are merely a subset of them. The use of concepts is necessary to cognitive processes such as categorization, memory, decision making, learning, and inference.\n\nConcepts are thought to be stored in long term cortical memory, in contrast to episodic memory of the particular objects and events which they abstract, which are stored in hippocampus. Evidence for this separation comes from hippocampal damaged patients such as patient HM. The abstraction from the day's hippocampal events and objects into cortical concepts is often considered to be the computation underlying (some stages of) sleep and dreaming. Many people (beginning with Aristotle) report memories of dreams which appear to mix the day's events with analogous or related historical concepts and memories, and suggest that they were being sorted or organised into more abstract concepts. (\"Sort\" is itself another word for concept, and \"sorting\" thus means to organise into concepts.)\n\nThe classical theory of concepts, also referred to as the empiricist theory of concepts, is the oldest theory about the structure of concepts (it can be traced back to Aristotle), and was prominently held until the 1970s. The classical theory of concepts says that concepts have a definitional structure. Adequate definitions of the kind required by this theory usually take the form of a list of features. These features must have two important qualities to provide a comprehensive definition. Features entailed by the definition of a concept must be both \"necessary\" and \"sufficient\" for membership in the class of things covered by a particular concept. A feature is considered necessary if every member of the denoted class has that feature. A feature is considered sufficient if something has all the parts required by the definition. For example, the classic example \"bachelor\" is said to be defined by \"unmarried\" and \"man\". An entity is a bachelor (by this definition) if and only if it is both unmarried and a man. To check whether something is a member of the class, you compare its qualities to the features in the definition. Another key part of this theory is that it obeys the \"law of the excluded middle\", which means that there are no partial members of a class, you are either in or out.\n\nThe classical theory persisted for so long unquestioned because it seemed intuitively correct and has great explanatory power. It can explain how concepts would be acquired, how we use them to categorize and how we use the structure of a concept to determine its referent class. In fact, for many years it was one of the major activities in philosophy – concept analysis. Concept analysis is the act of trying to articulate the necessary and sufficient conditions for the membership in the referent class of a concept. For example, Shoemaker's classic \"Time Without Change\" explored whether the concept of the flow of time can include flows where no changes take place, though change is usually taken as a definition of time.\n\nGiven that most later theories of concepts were born out of the rejection of some or all of the classical theory, it seems appropriate to give an account of what might be wrong with this theory. In the 20th century, philosophers such as Wittgenstein and Rosch argued against the classical theory. There are six primary arguments summarized as follows:\n\nPrototype theory came out of problems with the classical view of conceptual structure. Prototype theory says that concepts specify properties that members of a class tend to possess, rather than must possess. Wittgenstein, Rosch, Mervis, Berlin, Anglin, and Posner are a few of the key proponents and creators of this theory. Wittgenstein describes the relationship between members of a class as \"family resemblances\". There are not necessarily any necessary conditions for membership, a dog can still be a dog with only three legs. This view is particularly supported by psychological experimental evidence for prototypicality effects. Participants willingly and consistently rate objects in categories like 'vegetable' or 'furniture' as more or less typical of that class. It seems that our categories are fuzzy psychologically, and so this structure has explanatory power. We can judge an item's membership to the referent class of a concept by comparing it to the typical member – the most central member of the concept. If it is similar enough in the relevant ways, it will be cognitively admitted as a member of the relevant class of entities. Rosch suggests that every category is represented by a central exemplar which embodies all or the maximum possible number of features of a given category. According to Lech, Gunturkun, and Suchan explain that categorization involves many areas of the brain, some of these are; visual association areas, prefrontal cortex, basal ganglia, and temporal lobe.\n\nTheory-theory is a reaction to the previous two theories and develops them further. This theory postulates that categorization by concepts is something like scientific theorizing. Concepts are not learned in isolation, but rather are learned as a part of our experiences with the world around us. In this sense, concepts' structure relies on their relationships to other concepts as mandated by a particular mental theory about the state of the world. How this is supposed to work is a little less clear than in the previous two theories, but is still a prominent and notable theory. This is supposed to explain some of the issues of ignorance and error that come up in prototype and classical theories as concepts that are structured around each other seem to account for errors such as whale as a fish (this misconception came from an incorrect theory about what a whale is like, combining with our theory of what a fish is). When we learn that a whale is not a fish, we are recognizing that whales don't in fact fit the theory we had about what makes something a fish. In this sense, the Theory–Theory of concepts is responding to some of the issues of prototype theory and classic theory.\n\nAccording to the theory of ideasthesia (or \"sensing concepts\"), activation of a concept may be the main mechanism responsible for creation of phenomenal experiences. Therefore, understanding how the brain processes concepts may be central to solving the mystery of how conscious experiences (or qualia) emerge within a physical system e.g., the sourness of the sour taste of lemon. This question is also known as the hard problem of consciousness. Research on ideasthesia emerged from research on synesthesia where it was noted that a synesthetic experience requires first an activation of a concept of the inducer. Later research expanded these results into everyday perception.\n\nThere is a lot of discussion on the most effective theory in concepts. Another theory is semantic pointers, which use perceptual and motor representations and these representations are like symbols.\n\nThe term \"concept\" is traced back to 1554–60 (Latin \"\" – \"something conceived\"), but what is today termed \"the classical theory of concepts\" is the theory of Aristotle on the definition of terms. The meaning of \"concept\" is explored in mainstream information science, cognitive science, metaphysics, and philosophy of mind. In computer and information science contexts, especially, the term 'concept' is often used in unclear or inconsistent ways.\n\n"}
{"id": "6979", "url": "https://en.wikipedia.org/wiki?curid=6979", "title": "Cell Cycle (journal)", "text": "Cell Cycle (journal)\n\nCell Cycle is a biweekly peer-reviewed scientific journal covering cell biology. The editor-in-chief is Mikhail V. Blagosklonny (Roswell Park Cancer Institute). The journal is abstracted and indexed in Medline/PubMed and the Science Citation Index Expanded.\n\n"}
{"id": "6982", "url": "https://en.wikipedia.org/wiki?curid=6982", "title": "List of classical music competitions", "text": "List of classical music competitions\n\nEuropean Classical music has long relied on music competitions to provide a public forum that identifies the strongest players and contributes to the establishment of their professional careers. This is a list of current competitions in classical music, with each competition and reference link given only once. Many offer competitions across a range of categories and in these cases they are listed under \"General/mixed\". Competitions with age restrictions are listed under \"Young musicians\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "6984", "url": "https://en.wikipedia.org/wiki?curid=6984", "title": "Colin Powell", "text": "Colin Powell\n\nColin Luther Powell (; born April 5, 1937) is an American statesman and a retired four-star general in the United States Army. Powell was born in Harlem as the son of Jamaican immigrants. During his military career, Powell also served as National Security Advisor (1987–1989), as Commander of the U.S. Army Forces Command (1989) and as Chairman of the Joint Chiefs of Staff (1989–1993), holding the latter position during the Persian Gulf War. Powell was the first, and so far the only, African American to serve on the Joint Chiefs of Staff. He was the 65th United States Secretary of State, serving under U.S. President George W. Bush from 2001 to 2005, the first African American to serve in that position.\n\nPowell was born in New York City in 1937 and was raised in the South Bronx. His parents, Luther and Maud Powell, immigrated to the United States from Jamaica. Powell was educated in the New York City public schools, graduating from the City College of New York (CCNY), where he earned a bachelor's degree in geology. He also participated in ROTC at CCNY and received a commission as an Army second lieutenant upon graduation in June 1958. His further academic achievements include a Master of Business Administration degree from George Washington University.\n\nPowell was a professional soldier for 35 years, during which time he held myriad command and staff positions and rose to the rank of 4-star General. His last assignment, from October 1, 1989 to September 30, 1993, was as the 12th Chairman of the Joint Chiefs of Staff, the highest military position in the Department of Defense. During this time, he oversaw 28 crises, including Operation Desert Storm in the 1991 Persian Gulf War. He also formulated the Powell Doctrine.\n\nFollowing his military retirement, Powell wrote his best-selling autobiography, \"My American Journey\". In addition, he pursued a career as a public speaker, addressing audiences across the country and abroad. Prior to his appointment as Secretary of State, Powell was the chairman of America's Promise - The Alliance for Youth, a national nonprofit organization dedicated to mobilizing people from every sector of American life to build the character and competence of young people. He was nominated by President Bush on December 16, 2000 as Secretary of State. After being unanimously confirmed by the U.S. Senate, he was sworn in as the 65th Secretary of State on January 20, 2001.\n\nPowell is the recipient of numerous U.S. and foreign military awards and decorations. Powell's civilian awards include two Presidential Medal of Freedom, the President's Citizens Medal, the Congressional Gold Medal, the Secretary of State Distinguished Service Medal, and the Secretary of Energy Distinguished Service Medal. Several schools and other institutions have been named in his honor and he holds honorary degrees from universities and colleges across the country. Powell is married to the former Alma Vivian Johnson of Birmingham, Alabama. The Powell family includes son Michael (ex-chairman of the Federal Communications Commission); daughters Linda and Anne; daughter-in-law Jane; and grandsons Jeffrey and Bryan.\n\nIn 2016, while not a candidate for that year's election, Powell received three electoral votes for the office of President of the United States.\n\nPowell was born on April 5, 1937, in Harlem, a neighborhood in the New York City borough of Manhattan, to Jamaican immigrant parents Maud Arial (née McKoy) and Luther Theophilus Powell. His parents were both of mixed African and Scots ancestry. Luther worked as a shipping clerk and Maud as a seamstress. Powell was raised in the South Bronx and attended Morris High School, from which he graduated in 1954. (This school has since closed.)\n\nWhile at school, Powell worked at a local baby furniture store, where he picked up Yiddish from the eastern European Jewish shopkeepers and some of the customers. He also served as a Shabbos goy, helping Orthodox families with needed tasks on the Sabbath. He received a Bachelor of Science degree in Geology from the City College of New York in 1958 and has said he was a 'C average' student. He later earned an MBA degree from the George Washington University in 1971, after his second tour in Vietnam.\n\nDespite his parents' pronunciation of his name as , Powell has pronounced his name since childhood, after the heroic World War II flyer Colin P. Kelly Jr. Public officials and radio and television reporters have used Powell's preferred pronunciation.\n\nPowell was a professional soldier for 35 years, holding a variety of command and staff positions and rising to the rank of General.\n\nPowell described joining the Reserve Officers' Training Corps (ROTC) during college as one of the happiest experiences of his life; discovering something he loved and could do well, he felt he had \"found himself.\" According to Powell: It was only once I was in college, about six months into college when I found something that I liked, and that was ROTC, Reserve Officer Training Corps in the military. And I not only liked it, but I was pretty good at it. That's what you really have to look for in life, something that you like, and something that you think you're pretty good at. And if you can put those two things together, then you're on the right track, and just drive on. Cadet Powell joined the Pershing Rifles, the ROTC fraternal organization and drill team begun by General John Pershing. Even after he had become a general, Powell kept on his desk a pen set he had won for a drill team competition.\n\nUpon graduation, he received a commission as an Army second lieutenant. After attending basic training at Fort Benning, Powell was assigned to the 48th Infantry, in West Germany, as a platoon leader.\n\nIn his autobiography, Powell said he is haunted by the nightmare of the Vietnam War and felt that the leadership was very ineffective.\n\nCaptain Powell served a tour in Vietnam as a South Vietnamese Army (ARVN) advisor from 1962 to 1963. While on patrol in a Viet Cong-held area, he was wounded by stepping on a punji stake. The large infection made it difficult for him to walk, and caused his foot to swell for a short time, shortening his first tour.\n\nHe returned to Vietnam as a major in 1968, serving in the 23rd Infantry Division, then as assistant chief of staff of operations for the Americal Division. During the second tour in Vietnam he was decorated for bravery after he survived a helicopter crash, single-handedly rescuing three others, including division commander Major General Charles Martin Gettys, from the burning wreckage.\n\nPowell was charged with investigating a detailed letter by 11th Light Infantry Brigade soldier Tom Glen, which backed up rumored allegations of the My Lai Massacre. He wrote: \"In direct refutation of this portrayal is the fact that relations between American soldiers and the Vietnamese people are excellent.\" Later, Powell's assessment would be described as whitewashing the news of the massacre, and questions would continue to remain undisclosed to the public. In May 2004 Powell said to television and radio host Larry King, \"I was in a unit that was responsible for My Lai. I got there after My Lai happened. So, in war, these sorts of horrible things happen every now and again, but they are still to be deplored.\"\n\nPowell served a White House Fellowship under President Richard Nixon from 1972 to 1973. During 1975–1976 he attended the National War College, Washington, D.C.\n\nIn his autobiography, \"My American Journey\", Powell named several officers he served under who inspired and mentored him. As a lieutenant colonel serving in South Korea, Powell was very close to General Henry \"Gunfighter\" Emerson. Powell said he regarded Emerson as one of the most caring officers he ever met. Emerson insisted his troops train at night to fight a possible North Korean attack, and made them repeatedly watch the television film \"Brian's Song\" to promote racial harmony. Powell always professed that what set Emerson apart was his great love of his soldiers and concern for their welfare. After a race riot occurred, in which African American soldiers almost killed a Caucasian officer, Powell was charged by Emerson to crack down on black militants; Powell's efforts led to the discharge of one soldier, and other efforts to reduce racial tensions.\n\nIn the early 1980s, Powell served at Fort Carson, Colorado. After he left Fort Carson, Powell became senior military assistant to Secretary of Defense Caspar Weinberger, whom he assisted during the 1983 invasion of Grenada and the 1986 airstrike on Libya.\nIn 1986, Powell took over the command of V Corps in Frankfurt, Germany, from Robert Lewis \"Sam\" Wetzel.\n\nFollowing the Iran Contra scandal, Powell became, at the age of 49, Ronald Reagan's National Security Advisor, serving from 1987 to 1989 while retaining his Army commission as a lieutenant general.\n\nIn April 1989, after his tenure with the National Security Council, Powell was promoted to four-star general under President George H. W. Bush and briefly served as the Commander in Chief, Forces Command (FORSCOM), headquartered at Fort McPherson, Georgia, overseeing all Army, Army Reserve, and National Guard units in the Continental U.S., Alaska, Hawaii, and Puerto Rico. He became the third general since World War II to reach four-star rank without ever serving as a division commander, joining Dwight D. Eisenhower and Alexander Haig.\n\nLater that year, President George H. W. Bush selected him as Chairman of the Joint Chiefs of Staff.\n\nPowell's last military assignment, from October 1, 1989, to September 30, 1993, was as the 12th Chairman of the Joint Chiefs of Staff, the highest military position in the Department of Defense. At age 52, he became the youngest officer, and first Afro-Caribbean American, to serve in this position. Powell was also the first JCS Chair who received his commission through ROTC.\n\nDuring this time, he oversaw 28 crises, including the invasion of Panama in 1989 to remove General Manuel Noriega from power and Operation Desert Storm in the 1991 Persian Gulf War. During these events, Powell earned his nickname, \"the reluctant warrior.\" He rarely advocated military intervention as the first solution to an international crisis, and instead usually prescribed diplomacy and containment.\n\nAs a military strategist, Powell advocated an approach to military conflicts that maximizes the potential for success and minimizes casualties. A component of this approach is the use of overwhelming force, which he applied to Operation Desert Storm in 1991. His approach has been dubbed the \"Powell Doctrine\". Powell continued as chairman of the JCS into the Clinton presidency but as a dedicated \"realist\" he considered himself a bad fit for an administration largely made up of liberal internationalists. He clashed with then-U.S. ambassador to the United Nations Madeleine Albright over the Bosnian crisis, as he opposed any military interventions that didn't involve US interests.\n\nDuring his chairmanship of the JCS, there was discussion of awarding Powell a fifth star, granting him the rank of General of the Army. But even in the wake of public and Congressional pressure to do so, Clinton-Gore presidential transition team staffers decided against it.\n\nFirst printed in the August 13, 1989 issue of \"Parade\" magazine, these are Colin Powell's 13 Rules of Leadership.\n\nPowell's experience in military matters made him a very popular figure with both American political parties. Many Democrats admired his moderate stance on military matters, while many Republicans saw him as a great asset associated with the successes of past Republican administrations. Put forth as a potential Democratic Vice Presidential nominee in the 1992 U.S. presidential election or even potentially replacing Vice President Dan Quayle as the Republican Vice Presidential nominee, Powell eventually declared himself a Republican and began to campaign for Republican candidates in 1995. He was touted as a possible opponent of Bill Clinton in the 1996 U.S. presidential election, possibly capitalizing on a split conservative vote in Iowa and even leading New Hampshire polls for the GOP nomination, but Powell declined, citing a lack of passion for politics. Powell defeated Clinton 50–38 in a hypothetical match-up proposed to voters in the exit polls conducted on Election Day. Despite not standing in the race, Powell won the Republican New Hampshire Vice-Presidential primary on write-in votes.\n\nIn 1997 Powell founded America's Promise with the objective of helping children from all socioeconomic sectors. That same year saw the establishment of The Colin L. Powell Center for Leadership and Service. The mission of the Center is to \"prepare new generations of publicly engaged leaders from populations previously underrepresented in public service and policy circles, to build a strong culture of civic engagement at City College, and to mobilize campus resources to meet pressing community needs and serve the public good.\" \n\nPowell was mentioned as a potential candidate in the 2000 U.S. presidential election, but decided against running. Once Texas Governor George W. Bush secured the Republican nomination, Powell endorsed him for president and spoke at the 2000 Republican National Convention. Bush eventually won, and Powell was appointed Secretary of State.\n\nIn the electoral college vote count of 2016, Powell received three votes from faithless electors from Washington.\n\nAs Secretary of State in the Bush administration, Powell was perceived as moderate. Powell was unanimously confirmed by the United States Senate. Over the course of his tenure he traveled less than any other U.S. Secretary of State in 30 years.\nOn September 11, 2001, Powell was in Lima, Peru, meeting with President Alejandro Toledo and US Ambassador John Hamilton, and attending the special session of the OAS General Assembly that subsequently adopted the Inter-American Democratic Charter. After the September 11 attacks, Powell's job became of critical importance in managing America's relationships with foreign countries in order to secure a stable coalition in the War on Terrorism.\n\nPowell came under fire for his role in building the case for the 2003 Invasion of Iraq. In a press statement on February 24, 2001, he had said that sanctions against Iraq had prevented the development of any weapons of mass destruction by Saddam Hussein. As was the case in the days leading up to the Persian Gulf War, Powell was initially opposed to a forcible overthrow of Saddam, preferring to continue a policy of containment. However, Powell eventually agreed to go along with the Bush administration's determination to remove Saddam. He had often clashed with others in the administration, who were reportedly planning an Iraq invasion even before the September 11 attacks, an insight supported by testimony by former terrorism czar Richard Clarke in front of the 9/11 Commission. The main concession Powell wanted before he would offer his full support for the Iraq War was the involvement of the international community in the invasion, as opposed to a unilateral approach. He was also successful in persuading Bush to take the case of Iraq to the United Nations, and in moderating other initiatives. Powell was placed at the forefront of this diplomatic campaign.\n\nPowell's chief role was to garner international support for a multi-national coalition to mount the invasion. To this end, Powell addressed a plenary session of the United Nations Security Council on February 5, 2003, to argue in favor of military action. Citing numerous anonymous Iraqi defectors, Powell asserted that \"there can be no doubt that Saddam Hussein has biological weapons and the capability to rapidly produce more, many more.\" Powell also stated that there was \"no doubt in my mind\" that Saddam was working to obtain key components to produce nuclear weapons.\n\nMost observers praised Powell's oratorical skills. However, Britain's \"Channel 4 News\" reported soon afterwards that a UK intelligence dossier that Powell had referred to as a \"fine paper\" during his presentation had been based on old material and plagiarized an essay by American graduate student Ibrahim al-Marashi.\nA 2004 report by the Iraq Survey Group concluded that the evidence that Powell offered to support the allegation that the Iraqi government possessed weapons of mass destruction (WMDs) was inaccurate.\n\nIn an interview with Charlie Rose, Powell contended that prior to his UN presentation, he had merely four days to review the data concerning WMD in Iraq.\n\nA Senate report on intelligence failures would later detail the intense debate that went on behind the scenes on what to include in Powell's speech. State Department analysts had found dozens of factual problems in drafts of the speech. Some of the claims were taken out, but others were left in, such as claims based on the yellowcake forgery. The administration came under fire for having acted on faulty intelligence, particularly what was single-sourced to the informant known as Curveball. Powell later recounted how Vice President Dick Cheney had joked with him before he gave the speech, telling him, \"You've got high poll ratings; you can afford to lose a few points.\" Powell's longtime aide-de-camp and Chief of Staff from 1989–2003, Colonel Lawrence Wilkerson, later characterized Cheney's view of Powell's mission as to \"go up there and sell it, and we'll have moved forward a peg or two. Fall on your damn sword and kill yourself, and I'll be happy, too.\"\n\nIn September 2005, Powell was asked about the speech during an interview with Barbara Walters and responded that it was a \"blot\" on his record. He went on to say, \"It will always be a part of my record. It was painful. It's painful now.\"\n\nWilkerson said that he inadvertently participated in a hoax on the American people in preparing Powell's erroneous testimony before the United Nations Security Council.\n\nBecause Powell was seen as more moderate than most figures in the administration, he was spared many of the attacks that have been leveled at more controversial advocates of the invasion, such as Donald Rumsfeld and Paul Wolfowitz. At times, infighting among the Powell-led State Department, the Rumsfeld-led Defense Department, and Cheney's office had the effect of polarizing the administration on crucial issues, such as what actions to take regarding Iran and North Korea.\n\nAfter Saddam Hussein had been deposed, Powell's new role was to once again establish a working international coalition, this time to assist in the rebuilding of post-war Iraq. On September 13, 2004, Powell testified before the Senate Governmental Affairs Committee, acknowledging that the sources who provided much of the information in his February 2003 UN presentation were \"wrong\" and that it was \"unlikely\" that any stockpiles of WMDs would be found. Claiming that he was unaware that some intelligence officials questioned the information prior to his presentation, Powell pushed for reform in the intelligence community, including the creation of a national intelligence director who would assure that \"what one person knew, everyone else knew.\"\n\nAdditionally, Powell has been critical of other instances of U.S. foreign policy in the past, such as its support for the 1973 Chilean coup d'état. From two separate interviews in 2003, Powell stated in one about the 1973 event \"I can't justify or explain the actions and decisions that were made at that time. It was a different time. There was a great deal of concern about communism in this part of the world. Communism was a threat to the democracies in this part of the world. It was a threat to the United States.\" In another interview, however, he also simply stated \"With respect to your earlier comment about Chile in the 1970s and what happened with Mr. Allende, it is not a part of American history that we're proud of.\"\n\nPowell announced his resignation as Secretary of State on November 15, 2004. According to \"The Washington Post\", he had been asked to resign by the president's chief of staff, Andrew Card. Powell announced that he would stay on until the end of Bush's first term or until his replacement's confirmation by Congress. The following day, Bush nominated National Security Advisor Condoleezza Rice as Powell's successor. News of Powell's leaving the Administration spurred mixed reactions from politicians around the world — some upset at the loss of a statesman seen as a moderating factor within the Bush administration, but others hoping for Powell's successor to wield more influence within the cabinet.\n\nIn mid-November, Powell stated that he had seen new evidence suggesting that Iran was adapting missiles for a nuclear delivery system. The accusation came at the same time as the settlement of an agreement between Iran, the IAEA, and the European Union.\n\nOn December 31, 2004, Powell rang in the New Year by pressing a button in Times Square with New York City Mayor Michael Bloomberg to initiate the ball drop and 60 second countdown, ushering in the year 2005. He appeared on the networks that were broadcasting New Year's Eve specials and talked about this honor, as well as being a native of New York City.\n\nAfter retiring from the role of Secretary of State, Powell returned to private life. In April 2005, he was privately telephoned by Republican senators Lincoln Chafee and Chuck Hagel, at which time Powell expressed reservations and mixed reviews about the nomination of John R. Bolton as ambassador to the United Nations, but refrained from advising the senators to oppose Bolton (Powell had clashed with Bolton during Bush's first term). The decision was viewed as potentially dealing significant damage to Bolton's chances of confirmation. Bolton was put into the position via a recess appointment because of the strong opposition in the Senate.\nOn April 28, 2005, an opinion piece in \"The Guardian\" by Sidney Blumenthal (a former top aide to President Bill Clinton) claimed that Powell was in fact \"conducting a campaign\" against Bolton because of the acrimonious battles they had had while working together, which among other things had resulted in Powell cutting Bolton out of talks with Iran and Libya after complaints about Bolton's involvement from the British. Blumenthal added that \"The foreign relations committee has discovered that Bolton made a highly unusual request and gained access to 10 intercepts by the National Security Agency. Staff members on the committee believe that Bolton was probably spying on Powell, his senior advisors and other officials reporting to him on diplomatic initiatives that Bolton opposed.\"\n\nIn July 2005, Powell joined Kleiner, Perkins, Caufield & Byers, a well-known Silicon Valley venture capital firm, with the title of \"strategic limited partner.\"\n\nIn September 2005, Powell criticized the response to Hurricane Katrina. Powell said that thousands of people were not properly protected, but because they were poor rather than because they were black.\n\nOn January 5, 2006, he participated in a meeting at the White House of former Secretaries of Defense and State to discuss United States foreign policy with Bush administration officials. In September 2006, Powell sided with more moderate Senate Republicans in supporting more rights for detainees and opposing President Bush's terrorism bill. He backed Senators John Warner, John McCain and Lindsey Graham in their statement that U.S. military and intelligence personnel in future wars will suffer for abuses committed in 2006 by the U.S. in the name of fighting terrorism. Powell stated that \"The world is beginning to doubt the moral basis of [America's] fight against terrorism.\"\n\nAlso in 2006, Powell began appearing as a speaker at a series of motivational events called \"Get Motivated\", along with former New York Mayor Rudy Giuliani. In his speeches for the tour, he openly criticized the Bush Administration on a number of issues. Powell has been the recipient of mild criticism for his role with \"Get Motivated\" which has been called a \"get-rich-quick-without-much-effort, feel-good schemology.\"\n\nIn 2007 he joined the Board of Directors of Steve Case's new company Revolution Health. Powell also serves on the Council on Foreign Relations Board of directors.\n\nPowell, in honor of Martin Luther King Day, dropped the ceremonial first puck at a New York Islanders ice hockey game at Nassau Coliseum on January 21, 2008. On November 11, 2008, Powell again dropped the puck in recognition of Military Appreciation Day and Veterans Day.\n\nRecently, Powell has encouraged young people to continue to use new technologies to their advantage in the future. In a speech at the Center for Strategic and International Studies to a room of young professionals, he said, \"That's your generation...a generation that is hard-wired digital, a generation that understands the power of the information revolution and how it is transforming the world. A generation that you represent, and you're coming together to share; to debate; to decide; to connect with each other.\" At this event, he encouraged the next generation to involve themselves politically on the upcoming Next America Project, which uses online debate to provide policy recommendations for the upcoming administration.\n\nIn 2008, Powell served as a spokesperson for National Mentoring Month, a campaign held each January to recruit volunteer mentors for at-risk youth.\n\nSoon after Barack Obama's 2008 election, Powell began being mentioned as a possible cabinet member. He was not nominated.\n\nIn September 2009, Powell advised President Obama against surging US forces in Afghanistan. The president announced the surge the following December.\n\nOn March 14, 2014, Salesforce.com announced that Powell had joined its Board of Directors.\n\nA liberal Republican, Powell is well known for his willingness to support liberal or centrist causes. He is pro-choice regarding abortion, and in favor of \"reasonable\" gun control. He stated in his autobiography that he supports affirmative action that levels the playing field, without giving a leg up to undeserving persons because of racial issues. Powell was also instrumental in the 1993 implementation of the military's don't ask, don't tell policy, though he later supported its repeal as proposed by Robert Gates and Admiral Mike Mullen in January 2010, saying \"circumstances had changed\".\n\nThe Vietnam War had a profound effect on Powell's views of the proper use of military force. These views are described in detail in the autobiography \"My American Journey\". The Powell Doctrine, as the views became known, was a central component of U.S. policy in the Persian Gulf War (the first U.S. war in Iraq) and U.S. invasion of Afghanistan (the overthrow of the Taliban regime in Afghanistan following the September 11 attacks). The hallmark of both operations was strong international cooperation, and the use of overwhelming military force.\n\nPowell was the subject of controversy in 2004 when, in a conversation with British Foreign Secretary Jack Straw, he reportedly referred to neoconservatives within the Bush administration as \"fucking crazies.\" In addition to being reported in the press (although the expletive was generally censored in the U.S. press), the quotation was used by James Naughtie in his book, \"The Accidental American: Tony Blair and the Presidency\", and by Chris Patten in his book, \"Cousins and Strangers: America, Britain, and Europe in a New Century\".\n\nIn a September 2006 letter to Sen. John McCain, General Powell expressed opposition to President Bush's push for military tribunals of those formerly and currently classified as enemy combatants. Specifically, he objected to the effort in Congress to \"redefine Common Article 3 of the Geneva Convention.\" He also asserted: \"The world is beginning to doubt the moral basis of our fight against terrorism.\"\n\nPowell endorsed President Obama in 2008 and again in 2012. When asked why he is still a Republican on Meet the Press he said, \"I’m still a Republican. And I think the Republican Party needs me more than the Democratic Party needs me. And you can be a Republican and still feel strongly about issues such as immigration, and improving our education system, and doing something about some of the social problems that exist in our society and our country. I don’t think there's anything inconsistent with this.\" \n\nWhile Powell was wary of a military solution, he supported the decision to invade Iraq after the Bush administration concluded that diplomatic efforts had failed. After his departure from the State Department, Powell repeatedly emphasized his continued support for American involvement in the Iraq War.\n\nAt the 2007 Aspen Ideas Festival in Colorado, Powell revealed that he had spent two and a half hours explaining to President Bush \"the consequences of going into an Arab country and becoming the occupiers.\" During this discussion, he insisted that the U.S. appeal to the United Nations first, but if diplomacy failed, he would support the invasion: \"I also had to say to him that you are the President, you will have to make the ultimate judgment, and if the judgment is this isn't working and we don't think it is going to solve the problem, then if military action is undertaken I'm with you, I support you.\"\n\nIn a 2008 interview on CNN, Powell reiterated his support for the 2003 decision to invade Iraq in the context of his endorsement of Barack Obama, stating: \"My role has been very, very straightforward. I wanted to avoid a war. The president [Bush] agreed with me. We tried to do that. We couldn't get it through the U.N. and when the president made the decision, I supported that decision. And I've never blinked from that. I've never said I didn't support a decision to go to war.\"\n\nPowell's position on the Iraq War troop surge of 2007 has been less consistent. In December 2006, he expressed skepticism that the strategy would work and whether the U.S. military had enough troops to carry it out successfully. He stated: \"I am not persuaded that another surge of troops into Baghdad for the purposes of suppressing this communitarian violence, this civil war, will work.\" Following his endorsement of Barack Obama in October 2008, however, Powell praised General David Petraeus and U.S. troops, as well as the Iraqi government, concluding that \"it's starting to turn around.\" By mid-2009, he had concluded a surge of U.S. forces in Iraq should have come sooner, perhaps in late 2003. Throughout this period, Powell consistently argued that Iraqi political progress was essential, not just military force.\n\nPowell donated the maximum allowable amount to John McCain's campaign in the summer of 2007 and in early 2008, his name was listed as a possible running mate for Republican nominee McCain's bid during the 2008 U.S. presidential election. However, on October 19, 2008, Powell announced his endorsement of Barack Obama during a \"Meet the Press\" interview, citing \"his ability to inspire, because of the inclusive nature of his campaign, because he is reaching out all across America, because of who he is and his rhetorical abilities\", in addition to his \"style and substance.\" He additionally referred to Obama as a \"transformational figure\". Powell further questioned McCain's judgment in appointing Sarah Palin as the vice presidential candidate, stating that despite the fact that she is admired, \"now that we have had a chance to watch her for some seven weeks, I don't believe she's ready to be president of the United States, which is the job of the vice president.\" He said that Obama's choice for vice-president, Joe Biden, was ready to be president. He also added that he was \"troubled\" by the \"false intimations that Obama was Muslim.\" Powell stated that \"[Obama] is a Christian—he's always been a Christian... But the really right answer is, what if he is? Is there something wrong with being a Muslim in this country? The answer's no, that's not America.\" Powell then mentioned Kareem Rashad Sultan Khan, a Muslim American soldier in the U.S. Army who served and died in the Iraq War. He later stated, \"Over the last seven weeks, the approach of the Republican Party has become narrower and narrower [...] I look at these kind of approaches to the campaign, and they trouble me.\" Powell concluded his Sunday morning talk show comments, \"It isn't easy for me to disappoint Sen. McCain in the way that I have this morning, and I regret that [...] I think we need a transformational figure. I think we need a president who is a generational change and that's why I'm supporting Barack Obama, not out of any lack of respect or admiration for Sen. John McCain.\" Later in a December 12, 2008, CNN interview with Fareed Zakaria, Powell reiterated his belief that during the last few months of the campaign, Palin pushed the Republican party further to the right and had a polarizing impact on it.\n\nIn a July 2009 CNN interview with John King, Powell expressed concern over President Obama growing the size of the federal government and the size of the federal budget deficit. In September 2010, he criticized the Obama administration for not focusing \"like a razor blade\" on the economy and job creation. Powell reiterated that Obama was a \"transformational figure.\" In a video that aired on CNN.com in November 2011, Colin Powell said in reference to Barack Obama, \"many of his decisions have been quite sound. The financial system was put back on a stable basis.\"\n\nOn October 25, 2012, 12 days before the presidential election, he gave his endorsement to President Obama for re-election during a broadcast of CBS This Morning. He cited success and forward progress in foreign and domestic policy arenas under the Obama Administration, and made the following statement: \"I voted for him in 2008 and I plan to stick with him in 2012 and I'll be voting for and for Vice President Joe Biden next month.\"\n\nAs additional reason for his endorsement, Powell cited the changing positions and perceived lack of thoughtfulness of Mitt Romney on foreign affairs, and a concern for the validity of Romney's economic plans.\n\nIn an interview with ABC's Diane Sawyer and George Stephanopoulos during ABC's coverage of President Obama's second inauguration, Powell criticized members of the Republican Party who \"demonize[d] the president\". He called on GOP leaders to publicly denounce such talk.\n\nPowell has been very vocal on the state of the Republican party. Speaking at a Washington Ideas forum in early October 2015, he warned the audience that the Republican party had begun a move to the fringe right, lessening the chances of a Republican White House in the future. He also remarked on Republican presidential contender Donald Trump's statements regarding immigrants, noting that there were many immigrants working in Trump hotels.\n\nIn March 2016, Powell denounced the \"nastiness\" of the 2016 Republican primaries during an interview on CBS \"This Morning\". He compared the race to a \"reality show\", and stated that the campaign had gone \"into the mud\".\n\nIn August 2016, Powell accused the Clinton campaign of trying to pin Democratic presidential nominee Hillary Clinton's email controversy on him. Speaking to \"People\" magazine, Powell said, \"The truth is, she was using [the private email server] for a year before I sent her a memo telling her what I did.\"\n\nOn September 13, 2016, emails were obtained that revealed Powell's private communications regarding both Donald Trump and Hillary Clinton. Powell privately reiterated his comments regarding Clinton's email scandal, writing, \"I have told Hillary's minions repeatedly that they are making a mistake trying to drag me in, yet they still try,\" and complaining that \"Hillary’s mafia keeps trying to suck me into it\" in another email. In another email discussing Clinton's controversy, Powell noted that she should have told everyone what she did \"two years ago\", and said that she has not \"been covering herself with glory.\" Writing on the 2012 Benghazi attack controversy surrounding Clinton, Powell said to then U.S. Ambassador Susan Rice, \"Benghazi is a stupid witch hunt.\" Commenting on Clinton in a general sense, Powell mused that \"Everything [Clinton] touches she kind of screws up with hubris\", and in another email stated \"I would rather not have to vote for her, although she is a friend I respect.\"\n\nPowell referred to Donald Trump as a \"national disgrace\", with \"no sense of shame\". He wrote candidly of Trump's role in the birther movement, which he referred to as \"racist\". Powell suggested that the media ignore Trump, saying, \"To go on and call him an idiot just emboldens him.\" The emails were obtained by the media as the result of a hack.\n\nPowell endorsed Clinton on October 25, 2016, stating it was \"because I think she's qualified, and the other gentleman is not qualified.\"\n\nDespite not running in the election, Powell received three electoral votes for president from faithless electors in Washington who had pledged to vote for Clinton, coming in third overall. After Barack Obama, Powell was only the second African American to receive electoral votes in a presidential election. He was also the first Republican since 1984 to receive electoral votes from Washington in a presidential election, as well as the first Republican African American to do so.\n\nPowell married Alma Johnson on August 25, 1962. Their son, Michael Powell, was the chairman of the Federal Communications Commission (FCC) from 2001 to 2005. His daughters are Linda Powell, an actress, and Annemarie Powell. As a hobby, Powell restores old Volvo and Saab cars. In 2013, he faced questions about a relationship with a Romanian diplomat, after a hacked AOL email account had been made public. He acknowledged a \"very personal\" email relationship but denied further involvement.\n\nPowell's civilian awards include two Presidential Medals of Freedom (the second with distinction), the President's Citizens Medal, the Congressional Gold Medal, the Secretary of State Distinguished Service Medal, the Secretary of Energy Distinguished Service Medal, and the Ronald Reagan Freedom Award. Several schools and other institutions have been named in his honor and he holds honorary degrees from universities and colleges across the country.\n\n\n\n\n"}
{"id": "6985", "url": "https://en.wikipedia.org/wiki?curid=6985", "title": "Chlorophyll", "text": "Chlorophyll\n\nChlorophyll (also chlorophyl) is any of several closely related green pigments found in cyanobacteria and the chloroplasts of algae and plants. Its name is derived from the Greek words χλωρός, \"chloros\" (\"green\") and φύλλον, \"phyllon\" (\"leaf\"). Chlorophyll is essential in photosynthesis, allowing plants to absorb energy from light.\n\nChlorophyll absorbs light most strongly in the blue portion of the electromagnetic spectrum, followed by the red portion. Conversely, it is a poor absorber of green and near-green portions of the spectrum, which it reflects, producing the green color of chlorophyll-containing tissues. Chlorophyll molecules are specifically arranged in and around photosystems that are embedded in the thylakoid membranes of chloroplasts. Two types of chlorophyll exist in the photosystems of green plants: chlorophyll a and b.\n\nChlorophyll was first isolated and named by Joseph Bienaimé Caventou and Pierre Joseph Pelletier in 1817.\n\nChlorophyll is vital for photosynthesis, which allows plants to absorb energy from light.\n\nChlorophyll molecules are specifically arranged in and around photosystems that are embedded in the thylakoid membranes of chloroplasts. In these complexes, chlorophyll serves two primary functions. The function of the vast majority of chlorophyll (up to several hundred molecules per photosystem) is to absorb light and transfer that light energy by resonance energy transfer to a specific chlorophyll pair in the reaction center of the photosystems.\nThe two currently accepted photosystem units are photosystem II and photosystem I, which have their own distinct reaction centres, named P680 and P700, respectively. These centres are named after the wavelength (in nanometers) of their red-peak absorption maximum. The identity, function and spectral properties of the types of chlorophyll in each photosystem are distinct and determined by each other and the protein structure surrounding them. Once extracted from the protein into a solvent (such as acetone or methanol), these chlorophyll pigments can be separated into chlorophyll a and chlorophyll b.\n\nThe function of the reaction center of chlorophyll is to absorb light energy and transfer it to other parts of the photosystem. The absorbed energy of the photon is transferred to an electron in a process called charge separation. The removal of the electron from the chlorophyll is an oxidation reaction. The chlorophyll donates the high energy electron to a series of molecular intermediates called an electron transport chain. The charged reaction center of chlorophyll (P680) is then reduced back to its ground state by accepting an electron stripped from water. The electron that reduces P680 ultimately comes from the oxidation of water into O and H through several intermediates. This reaction is how photosynthetic organisms such as plants produce O gas, and is the source for practically all the O in Earth's atmosphere. Photosystem I typically works in series with Photosystem II; thus the P700 of Photosystem I is usually reduced as it accepts the electron, via many intermediates in the thylakoid membrane, by electrons coming, ultimately, from Photosystem II. Electron transfer reactions in the thylakoid membranes are complex, however, and the source of electrons used to reduce P700 can vary.\n\nThe electron flow produced by the reaction center chlorophyll pigments is used to pump H ions across the thylakoid membrane, setting up a chemiosmotic potential used mainly in the production of ATP (stored chemical energy) or to reduce NADP to NADPH. NADPH is a universal agent used to reduce CO into sugars as well as other biosynthetic reactions.\n\nReaction center chlorophyll–protein complexes are capable of directly absorbing light and performing charge separation events without the assistance of other chlorophyll pigments, but the probability of that happening under a given light intensity is small. Thus, the other chlorophylls in the photosystem and antenna pigment proteins all cooperatively absorb and funnel light energy to the reaction center. Besides chlorophyll \"a\", there are other pigments, called accessory pigments, which occur in these pigment–protein antenna complexes.\n\nChlorophyll is a chlorin pigment, which is structurally similar to and produced through the same metabolic pathway as other porphyrin pigments such as heme. At the center of the chlorin ring is a magnesium ion. This was discovered in 1906, and was the first time that magnesium had been detected in living tissue. For the structures depicted in this article, some of the ligands attached to the Mg center are omitted for clarity. The chlorin ring can have several different side chains, usually including a long phytol chain. There are a few different forms that occur naturally, but the most widely distributed form in terrestrial plants is chlorophyll \"a\". After initial work done by German chemist Richard Willstätter spanning from 1905 to 1915, the general structure of chlorophyll \"a\" was elucidated by Hans Fischer in 1940. By 1960, when most of the stereochemistry of chlorophyll \"a\" was known, Robert Burns Woodward published a total synthesis of the molecule. In 1967, the last remaining stereochemical elucidation was completed by Ian Fleming, and in 1990 Woodward and co-authors published an updated synthesis. Chlorophyll f was announced to be present in cyanobacteria and other oxygenic microorganisms that form stromatolites in 2010; a molecular formula of CHONMg and a structure of (2-formyl)-chlorophyll \"a\" were deduced based on NMR, optical and mass spectra. The different structures of chlorophyll are summarized below:\n\nWhen leaves degreen in the process of plant senescence, chlorophyll is converted to a group of colourless tetrapyrroles known as nonfluorescent chlorophyll catabolites (NCC's) with the general structure:\n\nThese compounds have also been identified in several ripening fruits.\n\nMeasurement of the absorption of light is complicated by the solvent used to extract the chlorophyll from plant material, which affects the values obtained,\n\nBy measuring the absorption of light in the red and far red regions, it is possible to estimate the concentration of chlorophyll within a leaf.\n\nRatio fluorescence emission can be used to measure chlorophyll content. By exciting chlorophyll “a” fluorescence at a lower wavelength, the ratio of chlorophyll fluorescence emission at 705 nm +/- 10 nm and 735 nm +/-10 nm can provide a linear relationship of chlorophyll content when compared to chemical testing. The ratio F735/F700 provided a correlation value of r 0.96 compared to chemical testing in the range from 41 mg m up to 675 mg m. Gitelson also developed a formula for direct readout of chlorophyll content in mg m. The formula provided a reliable method of measuring chlorophyll content from 41 mg m up to 675 mg m with a correlation r value of 0.95.\n\nIn plants, chlorophyll may be synthesized from succinyl-CoA and glycine, although the immediate precursor to chlorophyll \"a\" and \"b\" is protochlorophyllide. In Angiosperm plants, the last step, the conversion of protochlorophyllide to chlorophyll, is light-dependent and such plants are pale (etiolated) if grown in darkness. Non-vascular plants and green algae have an additional light-independent enzyme and grow green even in darkness.\n\nChlorophyll itself is bound to proteins and can transfer the absorbed energy in the required direction. Protochlorophyllide occurs mostly in the free form and, under light conditions, acts as a photosensitizer, forming highly toxic free radicals. Hence, plants need an efficient mechanism of regulating the amount of chlorophyll precursor. In angiosperms, this is done at the step of aminolevulinic acid (ALA), one of the intermediate compounds in the biosynthesis pathway. Plants that are fed by ALA accumulate high and toxic levels of protochlorophyllide; so do the mutants with the damaged regulatory system.\nChlorosis is a condition in which leaves produce insufficient chlorophyll, turning them yellow. Chlorosis can be caused by a nutrient deficiency of iron—called iron chlorosis—or by a shortage of magnesium or nitrogen. Soil pH sometimes plays a role in nutrient-caused chlorosis; many plants are adapted to grow in soils with specific pH levels and their ability to absorb nutrients from the soil can be dependent on this. Chlorosis can also be caused by pathogens including viruses, bacteria and fungal infections, or sap-sucking insects.\n\nAnthocyanins are other plant pigments. The absorbance pattern responsible for the red color of anthocyanins may be complementary to that of green chlorophyll in photosynthetically active tissues such as young \"Quercus coccifera\" leaves. It may protect the leaves from attacks by plant eaters that may be attracted by green color.\n\nThe chlorophyll maps show milligrams of chlorophyll per cubic meter of seawater each month. Places where chlorophyll amounts were very low, indicating very low numbers of phytoplankton, are blue. Places where chlorophyll concentrations were high, meaning many phytoplankton were growing, are yellow. The observations come from the Moderate Resolution Imaging Spectroradiometer (MODIS) on NASA's Aqua satellite. Land is dark gray, and places where MODIS could not collect data because of sea ice, polar darkness, or clouds are light gray.The highest chlorophyll concentrations, where tiny surface-dwelling ocean plants are thriving, are in cold polar waters or in places where ocean currents bring cold water to the surface, such as around the equator and along the shores of continents. It is not the cold water itself that stimulates the phytoplankton. Instead, the cool temperatures are often a sign that the water has welled up to the surface from deeper in the ocean, carrying nutrients that have built up over time. In polar waters, nutrients accumulate in surface waters during the dark winter months when plants cannot grow. When sunlight returns in the spring and summer, the plants flourish in high concentrations.\n\nChlorophyll is registered as a food additive (colorant), and its E number is E140. Chefs use chlorophyll to color a variety of foods and beverages green, such as pasta and absinthe. Chlorophyll is not soluble in water, and it is first mixed with a small quantity of vegetable oil to obtain the desired solution.\n\n"}

{"id": "4746", "url": "https://en.wikipedia.org/wiki?curid=4746", "title": "Plague (disease)", "text": "Plague (disease)\n\nPlague is an infectious disease that is caused by the bacterium \"Yersinia pestis\". Depending on lung infection, or sanitary conditions, plague can be spread in the air, by direct contact, or very rarely by contaminated undercooked food. The symptoms of plague depend on the concentrated areas of infection in each person: bubonic plague in lymph nodes, septicemic plague in blood vessels, pneumonic plague in lungs. It is treatable if detected early. Plague is still relatively common in some remote parts of the world.\n\nUntil June 2007, plague was one of the three epidemic diseases specifically reportable to the World Health Organization (cholera and yellow fever the other two). The bacterium is named after the French-Swiss bacteriologist Alexandre Yersin.\n\nHistorically, what are thought to have been massive pandemics of plague swept through Eurasia with very high death rates and causing major cultural changes. The largest of these were the Plague of Justinian of 541–542, The Black Death of the 1340s, continuing in the Second plague pandemic to break out at intervals, and the Third plague pandemic beginning in 1855 and considered inactive from 1959.\n\nThe epidemiological use of the term \"plague\" is currently applied to any severe bubo inflammation resulting from an infection with \"Y. pestis\". Historically, the medical use of the term \"plague\" has been applied to pandemic infections in general. Plague is often synonymous with bubonic plague, but this describes just one of its manifestations. Other names have been used to describe this disease, such as Black Plague and the Black Death; the latter is now used primarily by scholars to describe the second, and most devastating, pandemic of the disease. The etymology of the word \"plague\" is believed to come from the Latin word \"plāga\" (\"blow, wound\") and \"plangere\" (“to strike, or to strike down”), cf. German \"Plage\" (“infestation”).\nTransmission of \"Y. pestis\" to an uninfected individual is possible by any of the following means.\n\"Yersinia pestis\" circulates in animal reservoirs, particularly in rodents, in the natural foci of infection found on all continents except Australia. The natural foci of plague are situated in a broad belt in the tropical and sub-tropical latitudes and the warmer parts of the temperate latitudes around the globe, between the parallels 55 degrees North and 40 degrees South.\nContrary to popular belief, rats did not directly start the spread of the bubonic plague. It is mainly a disease in the fleas (\"Xenopsylla cheopis\") that infested the rats, making the rats themselves the first victims of the plague. Infection in a human occurs when a person is bitten by a flea that has been infected by biting a rodent that itself has been infected by the bite of a flea carrying the disease. The bacteria multiply inside the flea, sticking together to form a plug that blocks its stomach and causes it to starve. The flea then bites a host and continues to feed, even though it cannot quell its hunger, and consequently the flea vomits blood tainted with the bacteria back into the bite wound. The bubonic plague bacterium then infects a new victim, and the flea eventually dies from starvation. Serious outbreaks of plague are usually started by other disease outbreaks in rodents, or a rise in the rodent population.\n\nIn 1894, two bacteriologists, Alexandre Yersin of France and Kitasato Shibasaburō of Japan, independently isolated the bacterium in Hong Kong responsible for the Third Pandemic. Though both investigators reported their findings, a series of confusing and contradictory statements by Kitasato eventually led to the acceptance of Yersin as the primary discoverer of the organism. Yersin named it \"Pasteurella pestis\" in honor of the Pasteur Institute, where he worked, but in 1967 it was moved to a new genus, renamed \"Yersinia pestis\" in honor of Yersin. Yersin also noted that rats were affected by plague not only during plague epidemics but also often preceding such epidemics in humans, and that plague was regarded by many locals as a disease of rats: villagers in China and India asserted that, when large numbers of rats were found dead, plague outbreaks soon followed.\n\nIn 1898, the French scientist Paul-Louis Simond (who had also come to China to battle the Third Pandemic) established the rat-flea vector that drives the disease. He had noted that persons who became ill did not have to be in close contact with each other to acquire the disease. In Yunnan, China, inhabitants would flee from their homes as soon as they saw dead rats, and on the island of Formosa (Taiwan), residents considered the handling of dead rats heightened the risks of developing plague. These observations led him to suspect that the flea might be an intermediary factor in the transmission of plague, since people acquired plague only if they were in contact with recently dead rats, who had died less than 24 hours before. In a now classic experiment, Simond demonstrated how a healthy rat died of plague, after infected fleas had jumped to it, from a rat which had recently died of the plague.\n\nWhen a flea bites a human and contaminates the wound with regurgitated blood, the plague carrying bacteria are passed into the tissue. \"Y. pestis\" can reproduce inside cells, so even if phagocytosed, they can still survive. Once in the body, the bacteria can enter the lymphatic system, which drains interstitial fluid. Plague bacteria secrete several toxins, one of which is known to cause dangerous beta-adrenergic blockade.\n\n\"Y. pestis\" spreads through the lymphatic vessels of the infected human until it reaches a lymph node, where it stimulates severe haemorrhagic inflammation that causes the lymph nodes to expand. The swollen lymph nodes form the characteristic buboes associated with the disease.\n\nIf the lymph node is overwhelmed, the infection can pass into the bloodstream, causing \"secondary septicemic plague\" and if the lungs are seeded, it can cause \"secondary pneumonic plague\".\n\nLymphatics ultimately drain into the bloodstream, so the plague bacteria may enter the blood and travel to almost any part of the body. In septicemic plague, bacterial endotoxins cause disseminated intravascular coagulation (DIC), causing tiny clots throughout the body and possibly ischaemic necrosis (tissue death due to lack of circulation/perfusion to that tissue) from the clots. DIC results in depletion of the body's clotting resources, so that it can no longer control bleeding. Consequently, there is bleeding into the skin and other organs, which can cause red and/or black patchy rash and hemoptysis/hematemesis (coughing up/ vomiting of blood). There are bumps on the skin that look somewhat like insect bites; these are usually red, and sometimes white in the center. Untreated, septicemic plague is usually fatal. Early treatment with antibiotics reduces the mortality rate to between 4 and 15 percent. People who die from this form of plague often die on the same day symptoms first appear.\n\nThe pneumonic form of plague arises from infection of the lungs. It causes coughing and sneezing and thereby produces airborne droplets that contain bacterial cells and are likely to infect anyone inhaling them. The incubation period for pneumonic plague is short, usually two to four days, but sometimes just a few hours. The initial signs are indistinguishable from several other respiratory illnesses; they include headache, weakness, and hemoptysis or hematemesis (spitting or vomiting of blood). The course of the disease is rapid; unless diagnosed and treated soon enough, typically within a few hours, death may follow in one to six days; in untreated cases mortality is nearly 100%.\n\nThis is an uncommon form of plague that resembles tonsillitis found in cases of close contact of patients with other forms of plague.\n\nThis form of plague occurs when bacteria cross the blood-brain barrier, leading to infectious meningitis.\n\nThere are a few other rare manifestations of plague, including asymptomatic plague and abortive plague. \"Cellulocutaneous plague\" sometimes results in infection of the skin and soft tissue, often around the bite site of a flea.\n\nSince human plague is rare in most parts of the world, routine vaccination is not needed other than for those at particularly high risk of exposure, nor for people living in areas with enzootic plague, meaning it occurs at regular, predictable rates in populations and specific areas, such as the western United States. It is not even indicated for most travellers to countries with known recent reported cases, particularly if their travel is limited to urban areas with modern hotels. The CDC thus only recommends vaccination for: (1) all laboratory and field personnel who are working with \"Y. pestis\" organisms resistant to antimicrobials; (2) people engaged in aerosol experiments with \"Y. pestis\"; and (3) people engaged in field operations in areas with enzootic plague where preventing exposure is not possible (such as some disaster areas).\n\nA systematic review by the Cochrane Collaboration found no studies of sufficient quality to make any statement on the efficacy of the vaccine.\n\nWaldemar Haffkine, a doctor who worked in Bombay, India, was the first to invent and test a plague vaccine against bubonic plague in 1897.\n\nIf diagnosed in time the various forms of plague are usually highly responsive to antibiotic therapy. The antibiotics often used are streptomycin, chloramphenicol and tetracycline. Amongst the newer generation of antibiotics, gentamicin and doxycycline have proven effective in monotherapeutic treatment of plague.\n\nThe plague bacterium could develop drug-resistance and again become a major health threat. One case of a drug-resistant form of the bacterium was found in Madagascar in 1995. A further outbreak in Madagascar was reported in November 2014.\n\nIn 1994, there was a pneumonic plague epidemic in Surat, India that resulted in 52 deaths and in a large internal migration of about 300,000 residents, who fled fearing quarantine.\n\nA combination of heavy monsoon rain and clogged sewers led to massive flooding which resulted in unhygienic conditions and a number of uncleared animal carcasses. It is believed that this situation precipitated the epidemic. There was widespread fear that the sudden rush of people from this area might spread the epidemic to other parts of India and the world, but that scenario was averted, probably as a result of effective public health response mounted by the Indian health authorities. Some countries, especially those in the nearby Gulf region, took the step of cancelling some flights and putting a pause on shipments from India.\n\nMuch like the Black Death that spread through medieval Europe, some questions still remain unanswered about the 1994 epidemic in Surat.\n\nInitial questions about whether it was an epidemic of plague arose because the Indian health authorities were unable to culture \"Yersinia pestis\", but this could have been due to poor laboratory procedures. Yet several lines of evidence strongly suggest that it was a plague epidemic: blood tests for Yersinia were positive, a number of individuals showed antibodies against Yersinia and the clinical symptoms displayed by the affected were all consistent with the disease being plague.\n\n\nPlasmids of \"Y. pestis\" have been detected in archaeological samples of the teeth of seven Bronze Age individuals from 5000 years ago (3000 BC), in the Afanasievo culture in Siberia, the Corded Ware culture in Estonia, the Sintashta culture in Russia, the Unetice culture in Poland and the Andronovo culture in Siberia. \"Y. pestis\" existed over Eurasia during the Bronze Age. Estimates of the age of the Most recent common ancestor of all \"Y. pestis\" is estimated at 5,783 years Before Present.\n\nThe \"Yersinia\" murine toxin (\"ymt\") allows the bacteria to infect fleas, which can then transmit bubonic plague. Early ancestral versions of \"Y. pestis\" did not have the \"ymt\" gene, which was only detected in a 951 calibrated BC sample.\n\nThe Amarna letters and the Plague Prayers of Mursili II describe an outbreak of a disease among the Hittites, though some modern sources say it may be Tularemia. The First Book of Samuel describes a possible plague outbreak in Philistia, and the Septuagint version says it was caused by a \"ravaging of mice\".\n\nIn the second year of the Peloponnesian War (430 BC), Thucydides described an epidemic disease which was said to have begun in Ethiopia, passed through Egypt and Libya, then come to the Greek world. In the Plague of Athens, the city lost possibly one third of its population, including Pericles. Modern historians disagree on whether the plague was a critical factor in the loss of the war. Although this epidemic has long been considered an outbreak of plague, many modern scholars believe that typhus, smallpox, or measles may better fit the surviving descriptions. A recent study of DNA found in the dental pulp of plague victims suggests that typhoid was actually responsible.\n\nIn the first century AD, Rufus of Ephesus, a Greek anatomist, refers to an outbreak of plague in Libya, Egypt, and Syria. He records that Alexandrian doctors named Dioscorides and Posidonius described symptoms including acute fever, pain, agitation, and delirium. Buboes—large, hard, and non-suppurating—developed behind the knees, around the elbows, and \"in the usual places.\" The death toll of those infected was very high. Rufus also wrote that similar buboes were reported by a Dionysius Curtus, who may have practiced medicine in Alexandria in the third century BC. If this is correct, the eastern Mediterranean world may have been familiar with bubonic plague at that early date.\n\nIn the second century, the Antonine Plague, named after Marcus Aurelius’ family name of Antoninus and also known as the Plague of Galen, who had first hand knowledge of the disease, may in fact have been smallpox. Galen was in Rome when it struck in 166 AD, and was also present in the winter of 168–69 during an outbreak among troops stationed at Aquileia; he had experience with the epidemic, referring to it as very long lasting, and describes its symptoms and his treatment of it. Unfortunately, his references are scattered and brief. According to Barthold Georg Niebuhr \"this pestilence must have raged with incredible fury; it carried off innumerable victims. The ancient world never recovered from the blow inflected upon it by the plague which visited it in the reign of M. Aurelius.\" The mortality rate of the plague was 7–10 percent; the outbreak in 165/6–168 would have caused approximately 3.5 to 5 million deaths. Otto Seek believes that over half the population of the empire perished. J. F. Gilliam believes that the Antonine plague probably caused more deaths than any other epidemic during the empire before the mid-3rd century.\n\nLocal outbreaks of the plague are grouped into three plague pandemics, whereby the respective start and end dates and the assignment of some outbreaks to either pandemic are still subject to discussion. According to Joseph P. Byrne from Belmont University, the pandemics were:\nHowever, the late medieval Black Death is sometimes seen not as the start of the second, but as the end of the first pandemic – in that case, the second pandemic's start would be 1361; also vary the end dates of the second pandemic given in literature, e.g. ~1890 instead of ~1840.\n\nThe Plague of Justinian in AD 541–542 is the first known attack on record, and marks the first firmly recorded pattern of bubonic plague. This disease is thought to have originated in China. It then spread to Africa from where the huge city of Constantinople imported massive amounts of grain, mostly from Egypt, to feed its citizens. The grain ships were the source of contagion for the city, with massive public granaries nurturing the rat and flea population. At its peak, Procopius said the plague was killing 10,000 people in Constantinople every day. The real number was more likely close to 5,000 a day. The plague ultimately killed perhaps 40% of the city's inhabitants, and then continued to kill up to a quarter of the human population of the eastern Mediterranean.\n\nIn AD 588 a second major wave of plague spread through the Mediterranean into what is now France. It is estimated that the Plague of Justinian killed as many as people across the world. It caused Europe's population to drop by around 50% between 541 and 700. It also may have contributed to the success of the Arab conquests. An outbreak of it in the AD 560s was described in AD 790 as causing \"swellings in the glands ... in the manner of a nut or date\" in the groin \"and in other rather delicate places followed by an unbearable fever\". While the swellings in this description have been identified by some as buboes, there is some contention as to whether the pandemic should be attributed to the bubonic plague, \"Yersinia pestis\", known in modern times.\n\nFrom 1347 to 1351, the Black Death, a massive and deadly pandemic originating in China, spread along the Silk Road and swept through Asia, Europe and Africa. It may have reduced the world's population from to between 350 and . China lost around half of its population, from around to around ; Europe around of its population, from about to about ; and Africa approximately of its population, from around to (mortality rates tended to be correlated with population density so Africa, being less dense overall, had the lowest death rate). This makes the Black Death the largest death toll from any known non-viral epidemic. Although accurate statistical data does not exist, it is thought that 1.4 million died in England ( of England's 4.2 million people), while an even higher percentage of Italy's population was likely wiped out. On the other hand, north-eastern Germany, Bohemia, Poland and Hungary are believed to have suffered less, and there are no estimates available for Russia or the Balkans. It is conceivable that Russia may not have been as affected due to its very cold climate and large size, hence often less close contact with the contagion.\n\nThe plague repeatedly returned to haunt Europe and the Mediterranean throughout the 14th to 17th centuries. According to Biraben, plague was present somewhere in Europe in every year between 1346 and 1671. The was particularly widespread in the following years: 1360–1363; 1374; 1400; 1438–1439; 1456–1457; 1464–1466; 1481–1485; 1500–1503; 1518–1531; 1544–1548; 1563–1566; 1573–1588; 1596–1599; 1602–1611; 1623–1640; 1644–1654; and 1664–1667; subsequent outbreaks, though severe, marked the retreat from most of Europe (18th century) and northern Africa (19th century). According to Geoffrey Parker, \"France alone lost almost a million people to plague in the epidemic of 1628–31.\"\n\nIn England, in the absence of census figures, historians propose a range of pre-incident population figures from as high as 7 million to as low as 4 million in 1300, and a postincident population figure as low as 2 million. By the end of 1350, the Black Death subsided, but it never really died out in England. Over the next few hundred years, further outbreaks occurred in 1361–62, 1369, 1379–83, 1389–93, and throughout the first half of the 15th century. An outbreak in 1471 took as much as 10–15% of the population, while the death rate of the plague of 1479–80 could have been as high as 20%. The most general outbreaks in Tudor and Stuart England seem to have begun in 1498, 1535, 1543, 1563, 1589, 1603, 1625, and 1636, and ended with the Great Plague of London in 1665.\nIn 1466, perhaps 40,000 people died of plague in Paris. During the 16th and 17th centuries, plague visited Paris for almost one year out of three. The Black Death ravaged Europe for three years before it continued on into Russia, where the disease hit somewhere once every five or six years from 1350 to 1490. Plague epidemics ravaged London in 1563, 1593, 1603, 1625, 1636, and 1665, reducing its population by 10 to 30% during those years. Over 10% of Amsterdam's population died in 1623–1625, and again in 1635–1636, 1655, and 1664. There were 22 outbreaks of plague in Venice between 1361 and 1528. The plague of 1576–1577 killed 50,000 in Venice, almost a third of the population. Late outbreaks in central Europe included the Italian Plague of 1629–1631, which is associated with troop movements during the Thirty Years' War, and the Great Plague of Vienna in 1679. Over 60% of Norway's population died from 1348 to 1350. The last plague outbreak ravaged Oslo in 1654.\n\nIn the first half of the 17th century, the Great Plague of Milan claimed some 1.7 million victims in Italy, or about 14% of the population. In 1656, the plague killed about half of Naples' 300,000 inhabitants. More than 1.25 million deaths resulted from the extreme incidence of plague in 17th-century Spain. The plague of 1649 probably reduced the population of Seville by half. In 1709–1713, a plague epidemic that followed the Great Northern War (1700–1721, Sweden v. Russia and allies) killed about 100,000 in Sweden, and 300,000 in Prussia. The plague killed two-thirds of the inhabitants of Helsinki, and claimed a third of Stockholm's population. Western Europe's last major epidemic occurred in 1720 in Marseilles, in Central Europe the last major outbreaks happened during the plague during the Great Northern War, and in Eastern Europe during the Russian plague of 1770–72.\n\nThe Black Death ravaged much of the Islamic world. Plague was present in at least one location in the Islamic world virtually every year between 1500 and 1850. Plague repeatedly struck the cities of North Africa. Algiers lost 30,000–50,000 to it in 1620–1621, and again in 1654–1657, 1665, 1691, and 1740–1742. Plague remained a major event in Ottoman society until the second quarter of the 19th century. Between 1701 and 1750, 37 larger and smaller epidemics were recorded in Constantinople, and 31 between 1751 and 1800. Baghdad has suffered severely from visitations of the plague, and sometimes two-thirds of its population has been wiped out.\n\nIn the early 20th century, following the identification by Yersin and Kitasato of the plague bacterium that caused the late 19th and early 20th century Asian bubonic plague (the Third Pandemic), most scientists and historians came to believe that the Black Death was an incidence of this plague, with a strong presence of the more contagious pneumonic and septicemic varieties increasing the pace of infection, spreading the disease deep into inland areas of the continents.\n\nSome modern researchers have argued that the disease was more likely to have been viral, pointing to the absence of rats from some parts of Europe that were badly affected and to the conviction of people at the time that the disease was spread by direct human contact. According to the accounts of the time the Black Death was extremely virulent, unlike the 19th and early 20th century bubonic plague. Samuel K. Cohn has made a comprehensive attempt to rebut the bubonic plague theory. Researchers have offered a mathematical model based on the changing demography of Europe from AD 1000 to 1800 demonstrating how plague epidemics, 1347 to 1670, could have provided the selection pressure that raised the frequency of a mutation to the level seen today that prevent HIV from entering macrophages and CD4+ T cells that carry the mutation (the average frequency of this allele is 10% in European populations). It is suggested that the original single mutation appeared over 2,500 years ago and that persistent epidemics of a hemorrhagic fever struck at the early classical civilizations.\n\nHowever, there is evidence that two previously unknown clades (variant strains) of \"Y. pestis\" were responsible for the Black Death. A multinational team conducted new surveys that used both ancient DNA analyses and protein-specific detection to find DNA and protein signatures specific for \"Y. pestis\" in human skeletons from widely distributed mass graves in northern, central and southern Europe that were associated archaeologically with the Black Death and subsequent resurgences. The authors concluded that this research, together with prior analyses from the south of France and Germany,\n\nThe study also identified two previously unknown but related strains of \"Y. pestis\" that were associated with distinct medieval mass graves. These were found to be ancestral to modern isolates of the present-day \"Y. pestis\" strains 'Orientalis' and 'Medievalis', suggesting that these variant strains (which are now presumed to be extinct) may have entered Europe in two waves. Surveys of plague pit remains in France and England indicate that the first variant entered Europe through the port of Marseille around November 1347 and spread through France over the next two years, eventually reaching England in the spring of 1349, where it spread through the country in three successive epidemics.\n\nSurveys of plague pit remains from the Netherlands town of Bergen op Zoom showed evidence of a second \"Y. pestis\" genotype which differed from that found in Britain and France and this second strain is now thought to have been responsible for the pandemic that spread through the Low Countries from 1350. This discovery implies that Bergen op Zoom (and possibly other parts of the southern Netherlands) was not directly infected from England or France c. AD 1349, and the researchers have suggested that a second wave of plague infection, distinct from that which occurred in Britain and France, may have been carried to the Low Countries from Norway, the Hanseatic cities, or another site.\n\nThe Third Pandemic began in China's Yunnan province in 1855, spreading plague to all inhabited continents and ultimately killing more than people in India and China alone. Casualty patterns indicate that waves of this pandemic may have come from two different sources. The first was primarily bubonic and was carried around the world through ocean-going trade, transporting infected persons, rats, and cargoes harboring fleas. The second, more virulent strain was primarily pneumonic in character, with a strong person-to-person contagion. This strain was largely confined to Manchuria and Mongolia. Researchers during the \"Third Pandemic\" identified plague vectors and the plague bacterium (see above), leading in time to modern treatment methods.\n\nPlague occurred in Russia in 1877–1889 in rural areas near the Ural Mountains and the Caspian Sea. Efforts in hygiene and patient isolation reduced the spread of the disease, with approximately 420 deaths in the region. Significantly, the region of Vetlianka in this area is near a population of the bobak marmot, a small rodent considered a very dangerous plague reservoir. The last significant Russian outbreak of Plague was in Siberia in 1910 after sudden demand for marmot skins (a substitute for sable) increased the price by 400 percent. The traditional hunters would not hunt a sick Marmot and it was taboo to eat the fat from under the arm (the axillary lymphatic gland that often harboured the plague) so outbreaks tended to be confined to single individuals. The price increase, however, attracted thousands of Chinese hunters from Manchuria who not only caught the sick animals but also ate the fat, which was considered a delicacy. The plague spread from the hunting grounds to the terminus of the Chinese Eastern Railway and then followed the track for 2,700 km. The plague lasted 7 months and killed 60,000 people.\nThe bubonic plague continued to circulate through different ports globally for the next fifty years; however, it was primarily found in Southeast Asia. An epidemic in Hong Kong in 1894 had particularly high death rates, 90%. As late as 1897, medical authorities in the European powers organized a conference in Venice, seeking ways to keep the plague out of Europe. Mumbai plague epidemic struck the city of Bombay (Mumbai) in 1896. The disease reached the Territory of Hawaii in December 1899, and the Board of Health's decision to initiate controlled burns of select buildings in Honolulu's Chinatown turned into an uncontrolled fire which led to the inadvertent burning of most of Chinatown on January 20, 1900. Shortly thereafter, plague reached the continental US, initiating the San Francisco plague of 1900–1904. Plague persisted in Hawaii on the outer islands of Maui and Hawaii (The Big Island) until it was finally eradicated in 1959.\n\nAlthough the outbreak that began in China in 1855 is conventionally known as the Third Pandemic (see above), it is unclear whether there have been fewer, or more, than three major outbreaks of bubonic plague. Most modern outbreaks of bubonic plague amongst humans have been preceded by a striking, high mortality amongst rats, yet this phenomenon is absent from descriptions of some earlier plagues, especially the Black Death. The buboes, or swellings in the groin, that are especially characteristic of bubonic plague, are a feature of other diseases as well.\n\nResearch done by a team of biologists from the Institute of Pasteur in Paris and Johannes Gutenberg University Mainz in Germany by analyzing the DNA and proteins from plague pits was published in October 2010, reported beyond doubt that all 'the three major plagues' were due to at least two previously unknown strains of \"Yersinia pestis\" and originated from China. A team of medical geneticists led by Mark Achtman of University College Cork in Ireland reconstructed a family tree of the bacterium and concluded in an online issue of Nature Genetics published on 31 October 2010 that all three of the great waves of plague originated from China.\n\nPlague has a long history as a biological weapon. Historical accounts from ancient China and medieval Europe detail the use of infected animal carcasses, such as cows or horses, and human carcasses, by the Xiongnu/Huns, Mongols, Turks, and other groups, to contaminate enemy water supplies. Han Dynasty General Huo Qubing is recorded to have died of such a contamination while engaging in warfare against the Xiongnu. Plague victims were also reported to have been tossed by catapult into cities under siege.\n\nIn 1347, the Genoese possession of Caffa, a great trade emporium on the Crimean peninsula, came under siege by an army of Mongol warriors of the Golden Horde under the command of Janibeg. After a protracted siege during which the Mongol army was reportedly withering from the disease, they decided to use the infected corpses as a biological weapon. The corpses were catapulted over the city walls, infecting the inhabitants. The Genoese traders fled, transferring the plague (Black Death) via their ships into the south of Europe,\nhence its rapid spread.\n\nDuring World War II, the Japanese Army developed weaponised plague, based on the breeding and release of large numbers of fleas. During the Japanese occupation of Manchuria, Unit 731 deliberately infected Chinese, Korean, and Manchurian civilians and prisoners of war with the plague bacterium. These subjects, termed \"maruta\", or \"logs\", were then studied by dissection, others by vivisection while still conscious. Members of the unit such as Shiro Ishii were exonerated from the Tokyo tribunal by Douglas MacArthur but 12 of them were prosecuted in the Khabarovsk War Crime Trials in 1949 during which some admitted having spread bubonic plague within a 36-km radius around the city of Changde.\n\nIshii innovated bombs containing live mice and fleas, with very small explosive loads, to deliver the weaponized microbes, overcoming the problem of the explosive killing the infected animal and insect by the use of a ceramic, rather than metal, casing for the warhead. While no records survive of the actual usage of the ceramic shells, prototypes exist and are believed to have been used in experiments during WWII.\n\nAfter World War II, both the United States and the Soviet Union developed means of weaponising pneumonic plague. Experiments included various delivery methods, vacuum drying, sizing the bacterium, developing strains resistant to antibiotics, combining the bacterium with other diseases (such as diphtheria), and genetic engineering. Scientists who worked in USSR bio-weapons programs have stated that the Soviet effort was formidable and that large stocks of weaponised plague bacteria were produced. Information on many of the Soviet projects is largely unavailable. Aerosolized pneumonic plague remains the most significant threat.\n\nThe plague can be easily treated with antibiotics, which some countries, such as the United States, have large supplies on hand if such an attack should occur, thus making the threat less severe.\n\n"}
{"id": "4748", "url": "https://en.wikipedia.org/wiki?curid=4748", "title": "Baudot code", "text": "Baudot code\n\nThe Baudot code, invented by Émile Baudot, is a character set predating EBCDIC and ASCII. It was the predecessor to the International Telegraph Alphabet No. 2 (ITA2), the teleprinter code in use until the advent of ASCII. Each character in the alphabet is represented by a series of five bits, sent over a communication channel such as a telegraph wire or a radio signal. The symbol rate measurement is known as baud, and is derived from the same name.\n\nTechnically, five-bit codes began in the 16th century, when Francis Bacon developed the cipher now called Bacon's cipher. However, this cipher is not a machine cipher and as such is not readily suitable for telecommunications.\n\nBaudot invented his original code in 1870 and patented it in 1874. It was a 5-bit code, with equal on and off intervals, which allowed telegraph transmission of the Roman alphabet and punctuation and control signals. It was based on an earlier code developed by Carl Friedrich Gauss and Wilhelm Weber in 1834. It was a Gray code (when vowels and consonants are sorted in their alphabetical order), nonetheless, the code by itself was not patented (only the machine) because French patent law does not allow concepts to be patented.\n\nBaudot's original code was adapted to be sent from a manual keyboard, and no teleprinter equipment was ever constructed that used it in its original form. The code was entered on a keyboard which had just five piano type keys, operated with two fingers of the left hand and three fingers of the right hand. Once the keys had been pressed they were locked down until mechanical contacts in a distributor unit passed over the sector connected to that particular keyboard, when the keyboard was unlocked ready for the next character to be entered, with an audible click (known as the \"cadence signal\") to warn the operator. Operators had to maintain a steady rhythm, and the usual speed of operation was 30 words per minute.\n\nThe table on the right \"shows the allocation of the Baudot code which was employed in the British Post Office for continental and inland services. It will be observed that a number of characters in the continental code are replaced by fractionals in the inland code. Code elements 1, 2 and 3 are transmitted by keys 1, 2 and 3, and these are operated by the first three fingers of the right hand. Code elements 4 and 5 are transmitted by keys 4 and 5, and these are operated by the first two fingers of the left hand.\"\n\nBaudot's code became known as International Telegraph Alphabet No. 1 (ITA1), and is no longer used.\n\nIn 1901, Baudot's code was modified by Donald Murray (1865–1945), prompted by his development of a typewriter-like keyboard. The Murray system employed an intermediate step, a keyboard perforator, which allowed an operator to punch a paper tape, and a tape transmitter for sending the message from the punched tape. At the receiving end of the line, a printing mechanism would print on a paper tape, and/or a reperforator could be used to make a perforated copy of the message. As there was no longer a connection between the operator's hand movement and the bits transmitted, there was no concern about arranging the code to minimize operator fatigue, and instead Murray designed the code to minimize wear on the machinery, assigning the code combinations with the fewest punched holes to the most frequently used characters.\n\nFor example, the one-hole letters are E and T. The ten two-hole letters are AOINSHRDLZ, very similar to the \"Etaoin shrdlu\" order used in Linotype machines. Ten more letters have three holes, and the four-hole letters are VXKQ.\n\nThe Murray code also introduced what became known as \"format effectors\" or \"control characters\" the CR (Carriage Return) and LF (Line Feed) codes. A few of Baudot's codes moved to the positions where they have stayed ever since: the NULL or BLANK and the DEL code. NULL/BLANK was used as an idle code for when no messages were being sent, but the same code was used to encode the space separation between words. Sequences of DEL codes (fully punched columns) were used at start or end of messages or between them, allowing easy separation of distinct messages (BELL codes could be inserted in those sequences to signal to the remote operator that a new message was coming or that transmission of a message was terminated).\n\nEarly British Creed machines used the Murray system.\n\nMurray's code was adopted by Western Union which used it until the 1950s, with a few changes that consisted of omitting some characters and adding more control codes. An explicit SPC (space) character was introduced, in place of the BLANK/NULL, and a new BEL code rang a bell or otherwise produced an audible signal at the receiver. Additionally, the WRU or \"Who aRe yoU?\" code was introduced, which caused a receiving machine to send an identification stream back to the sender.\n\nIn 1924, the CCITT introduced the International Telegraph Alphabet No. 2 (ITA2) code as an international standard, which was based on the Western Union code with some minor changes. The US standardized on a version of ITA2 called the American Teletypewriter code (US TTY) which was the basis for 5-bit teletypewriter codes until the debut of 7-bit ASCII in 1963.\n\nSome code points (marked blue in the table) were reserved for national-specific usage.\n\nThe code position assigned to Null was in fact used only for the idle state of teleprinters. During long periods of idle time, the impulse rate was not synchronized between both devices (which could even be powered off or not permanently interconnected on commuted phone lines). To start a message it was first necessary to calibrate the impulse rate a sequence of regularly timed \"mark\" pulses (1) by group of five pulses, which could also be detected by simple passive electronic devices to turn on the teleprinter; this series of pulse was generating series of Erasure/Delete and also initializing the receiver state to the Letters shift mode, however the first pulse could be lost, so this power on procedure could then be terminated by a single Null immediately followed by an Erasure/Delete character. To preserve the synchronization between devices, the Null code could not be used arbitrarily in the middle of messages (this was an improvement to the initial Baudot system where spaces were not explicitly differentiated, so it was difficult to maintain the pulse counters for repeating spaces on teleprinters). But it was then possible to resynchronize devices at any time by sending a Null in the middle of a message (immediately followed by an Erasure/Delete/LS control if followed by a letter, or by a FS control if followed by a figure). Sending Null controls also did not cause the paper band to advance to the next row (as nothing was punched), so this saved precious lengths of punchable paper band. On the opposite the Erasure/Delete/LS control code was always punched and always shifted to the (initial) letters mode. According to some sources, the Null code point was reserved for country-internal usage only.\n\nThe Shift to Letters code (LS) is also usable as a way to cancel/delete text from a punched tape after it has been read, allowing a safe destruction of the message before recycling the punched band. For that function, it also plays the same role of filler as the Delete code in ASCII (and in other 7-bit or 8-bit encodings, including EBCDIC for punched cards). Once codes for a fragment text has been replaced by arbitrary number of LS codes, what follows is still preserved and decodable. It can also be used as an initiator to make sure that the decoding of the first code will not give a digit or another symbol from the figures page (because the Null code may be arbitrarily inserted near the end of a punch band or at start of it, and has to be ignored, whereas the Space code is significant in text).\n\nThe cells marked as reserved for extensions (using the LS code again from the letters shift page, just after a first LS code to shift from the figures page) has been defined to shift into a new mode: in this new mode, the letters page are containing lowercase letters only, but a third page of codes is still accessible for the uppercase letters, either temporarily for a single letter (encode LS before that letter), may be locked (with FS+LS) for an unlimited number of capital letters or digits and then unlocked to return to lowercase mode (with a single LS). The cell marked as \"Reserved\" is also usable (using the FS code from the figures shift page) to switch the page of figures (which normally contains digits and \"national\" lowercase letters or symbols) to a fourth page (where national letters are uppercased and other symbols may be encoded).\n\nITA2 is still used in telecommunications devices for the deaf (TDD), telex, and some amateur radio applications, such as radioteletype (\"RTTY\"). ITA2 is also used in Enhanced Broadcast Solution (an early 21st century financial protocol specified by Deutsche Börse) to reduce the character encoding footprint.\n\nNearly all 20th-century teleprinter equipment used Western Union's code, ITA2, or variants thereof. Radio amateurs casually call ITA2 and variants \"Baudot\" incorrectly, and even the American Radio Relay League's Amateur Radio Handbook does so, though in more recent editions the tables of codes correctly identifies it as ITA2.\n\nNOTE: This table presumes the space called \"1\" by Baudot and Murray is rightmost, and least significant. The way the transmitted bits were packed into larger codes varied by manufacturer; the most common solution allocates the bits from the least significant bit towards the most significant bit (leaving the three most significant bits of a byte unused).\n\nIn ITA2, characters are expressed using five bits. ITA2 uses two code sub-sets, the \"letter shift\" (LTRS), and the \"figure shift\" (FIGS). The FIGS character (11011) signals that the following characters are to be interpreted as being in the FIGS set, until this is reset by the LTRS (11111) character. In use, the LTRS or FIGS shift key is pressed and released, transmitting the corresponding shift character to the other machine. The desired letters or figures characters are then typed. Unlike a typewriter or modern computer keyboard the shift key isn't kept depressed whilst the corresponding characters are typed. \"ENQuiry\" will trigger the other machine's answerback. It means \"Who are you?\"\n\nCR is carriage return, LF is line feed, BEL is the bell character which rang a small bell (often used to alert operators to an incoming message), SP is space, and NUL is the null character (blank tape).\n\nNote: the binary conversions of the codepoints are often shown in reverse order, depending on (presumably) from which side one views the paper tape. Note further that the \"control\" characters were chosen so that they were either symmetric or in useful pairs so that inserting a tape \"upside down\" did not result in problems for the equipment and the resulting printout could be deciphered. Thus FIGS (11011), LTRS (11111) and space (00100) are invariant, while CR (00010) and LF (01000), generally used as a pair, are treated the same regardless of order by page printers. LTRS could also be used to overpunch characters to be deleted on a paper tape (much like DEL in 7-bit ASCII).\n\nThe sequence \"RYRYRY...\" is often used in test messages, and at the start of every transmission. Since R is 01010 and Y is 10101, the sequence exercises much of a teleprinter's mechanical components at maximum stress. Also, at one time, fine-tuning of the receiver was done using two coloured lights (one for each tone). 'RYRYRY...' produced 0101010101..., which made the lights glow with equal brightness when the tuning was correct. This tuning sequence is only useful when ITA2 is used with two-tone FSK modulation, such as is commonly seen in radioteletype (RTTY) usage.\n\nUS implementations of Baudot code may differ in the addition of a few characters, such as #, & on the FIGS layer.\n\nThe Russian version of Baudot code (MTK-2) used three shift modes; the Cyrillic letter mode was activated by the character (00000). Because of the larger number of characters in the Cyrillic alphabet, the characters !, &, £ were omitted and replaced by Cyrillics, and BEL has the same code as Cyrillic letter Ю.\n\n\n"}
{"id": "4749", "url": "https://en.wikipedia.org/wiki?curid=4749", "title": "Blu Tack", "text": "Blu Tack\n\nBlu Tack is a reusable putty-like pressure-sensitive adhesive produced by Bostik, commonly used to attach lightweight objects (such as posters or sheets of paper) to walls or other dry surfaces. Traditionally blue, it is also available in other colours. Generic versions of the product are also available from other manufacturers. The spelling now used is without the hyphen.\n\nThe composition of Blu Tack is a manufacturing secret but is described as a synthetic rubber compound without hazardous properties under normal conditions. It can be swallowed without harm and is noncarcinogenic. It is non-soluble and is denser than water. The material is not flammable, but emits carbon dioxide and carbon monoxide when exposed to fire or high temperatures.\n\nAs of 2015, Bostik was manufacturing around 100 tonnes of Blu Tack weekly at its Leicester factory.\n\nBlu Tack was originally developed in 1969 as an accidental by-product of an attempt to develop a new sealant using chalk powder, rubber and oil. The name of the inventor is unknown. Originally Blu-Tack was white, but consumer research showed fears that children may mistake it for chewing gum, and a blue colouring was added.\n\nIn the United Kingdom in March 2008, 20,000 numbered packs of pink Blu-Tack were made available, to help raise money for Breast Cancer Campaign, with 10 pence from each pack going to the charity. The formulation was slightly altered to retain complete consistency with its blue counterpart. Since then, many coloured variations have been made, including red and white, yellow and a green Halloween pack.\n\nSimilar products of various colours are made by many manufacturers, including Faber-Castell's \"Tack-it\", Henkel's \"Fun-Tak\", UHU's \"Poster Putty\" and \"Sticky Tack\",\"Gummy Sticker\" Pritt's \"Sticky Stuff\" and Elmer's \"Poster Tack\".\n\nVersions of the product are also sold under the generic names \"adhesive putty\" and \"mounting putty\". The generic trademark or common name for mounting putty varies by region. It is known as \"Patafix\" in France, Italy and Portugal (a phonetic abbreviation for ', \"fastening dough\" in French), ' (\"teacher's chewing gum\") in Iceland, and ' (\"attachment mass\") or ' in Sweden.\n\nLike all poster putties, Blu-Tack provides an alternative to the artist's traditional kneaded eraser, having a superior grip and plasticity. Blu-Tack can be finely shaped and worked into even very small areas. Like kneaded erasers, it can be stretched and kneaded to freshen its working surfaces. One of the early adopters and staunch exponent of Blu-Tack's use as a kneadable eraser replacement is the UK artist Mike Sibley. Blu-Tack, especially if kept warm in the artist's free hand, is far more versatile than a kneadable eraser. It can, for example, remove or tonally adjust the top layer of graphite without affecting the underlying detailed layer. It also works with the lightest of touches, where kneadable erasers need some pressure to pick up graphite. A further benefit is that graphite removed by Blu-Tack is securely held and will not be reapplied during successive erasing.\n\nSome scale model hobbyists use Blu-Tack as a masking medium for painting camouflage schemes, as it can be easily molded to any shape and will not react with or lift the underlying paint.\n\nBlu-Tack is also used for sculpture. In 2007 artist Elizabeth Thompson created a sculpture of a house spider using Blu-Tack over a wire frame. It took around 4000 packs and was exhibited at London Zoo. Other artists have created works from the material including stop-motion animation.\n\nBlu-Tack can be used as a damping agent for sound and vibration applications, due to its low amplitude response properties.\n\nA small amount of Blu-Tack can be placed on the head of a screw to hold it onto a screwdriver.\n\n\n"}
{"id": "4751", "url": "https://en.wikipedia.org/wiki?curid=4751", "title": "Bacillus", "text": "Bacillus\n\nBacillus is a genus of gram-positive, rod-shaped bacteria and a member of the phylum Firmicutes. \"Bacillus\" species can be obligate aerobes (oxygen reliant), or facultative anaerobes (having the ability to be aerobic or anaerobic). They will test positive for the enzyme catalase when there has been oxygen used or present. Ubiquitous in nature, \"Bacillus\" includes both free-living (nonparasitic) and parasitic pathogenic species. Under stressful environmental conditions, the bacteria can produce oval endospores that are not true 'spores', but to which the bacteria can reduce themselves and remain in a dormant state for very long periods. These characteristics originally defined the genus, but not all such species are closely related, and many have been moved to other genera of the Firmicutes.\n\nMany species of \"Bacillus\" can produce copious amounts of enzymes which are used in different industries. Some species can form intracellular inclusions of polyhydroxyalkanoates under certain adverse environmental conditions, as in a lack of elements such as phosphorus, nitrogen, or oxygen combined with an excessive supply of carbon sources.\n\n\"B. subtilis\" has proved a valuable model for research. Other species of \"Bacillus\" are important pathogens, causing anthrax and food poisoning.\n\nMany \"Bacillus\" species are able to secrete large quantities of enzymes. \"Bacillus amyloliquefaciens\" is the source of a natural antibiotic protein barnase (a ribonuclease), alpha amylase used in starch hydrolysis, the protease subtilisin used with detergents, and the BamH1 restriction enzyme used in DNA research.\n\nA portion of the \"Bacillus thuringiensis\" genome was incorporated into corn (and cotton) crops. The resulting GMOs are therefore resistant to some insect pests.\n\n\"Bacillus subtilis\" is one of the best understood prokaryotes, in terms of molecular and cellular biology. Its superb genetic amenability and relatively large size have provided the powerful tools required to investigate a bacterium from all possible aspects. Recent improvements in fluorescent microscopy techniques have provided novel insight into the dynamic structure of a single cell organism. Research on \"B. subtilis\" has been at the forefront of bacterial molecular biology and cytology, and the organism is a model for differentiation, gene/protein regulation, and cell cycle events in bacteria.\n\n\"Bacillus\" species are almost ubiquitous in nature, e.g. in soil, but also occur in extreme environments such as high pH (\"B. alcalophilus\"), high temperature (\"B. thermophilus\"), or high salt (\"B. halodurans\"). \"B. thuringiensis\" produces a toxin that can kill insects and thus has been used as insecticide.\n\nTwo \"Bacillus\" species are considered medically significant: \"B. anthracis\", which causes anthrax, and \"B. cereus\", which causes food poisoning similar to that caused by \"Staphylococcus\". A third species, \"B. thuringiensis\", is an important insect pathogen, and is sometimes used to control insect pests. The type species is \"B. subtilis\", an important model organism. It is also a notable food spoiler, causing ropiness in bread and related food. Some environmental and commercial strains of \"B. coagulans\" may play a role in food spoilage of highly acidic, tomato-based products.\n\nAn easy way to isolate \"Bacillus\" species is by placing nonsterile soil in a test tube with water, shaking, placing in melted mannitol salt agar, and incubating at room temperature for at least a day. Colonies are usually large, spreading, and irregularly shaped. Under the microscope, the \"Bacillus\" cells appear as rods, and a substantial portion of the cells usually contain oval endospores at one end, making it bulge.\n\nThe cell wall of \"Bacillus\" is a structure on the outside of the cell that forms the second barrier between the bacterium and the environment, and at the same time maintains the rod shape and withstands the pressure generated by the cell's turgor. The cell wall is composed of teichoic and teichuronic acids. \"B. subtilis\" is the first bacterium for which the role of an actin-like cytoskeleton in cell shape determination and peptidoglycan synthesis was identified, and for which the entire set of peptidoglycan-synthesizing enzymes was localised. The role of the cytoskeleton in shape generation and maintenance is important\n\nThe genus \"Bacillus\" was named in 1835 by Christian Gottfried Ehrenberg, to contain rod-shaped (bacillus) bacteria. He had seven years earlier named the genus \"Bacterium\". \"Bacillus\" was later amended by Ferdinand Cohn to further describe them as spore-forming, Gram-positive, aerobic or facultatively anaerobic bacteria. Like other genera associated with the early history of microbiology, such as \"Pseudomonas\" and \"Vibrio\", the 266 species of \"Bacillus\" are ubiquitous. The genus has a very large ribosomal 16S diversity and is environmentally diverse.\nSeveral studies have tried to reconstruct the phylogeny of the genus. The \"Bacillus\"-specific study with the most diversity covered is by Xu and Cote using 16S and the ITS regions, where they divide the genus into 10 groups, which includes the nested genera \"Paenibacillus, Brevibacillus, Geobacillus, Marinibacillus\" and \"Virgibacillus\". However, the tree constructed by the living tree project, a collaboration between ARB-Silva and LPSN where a 16S (and 23S if available) tree of all validated species was constructed, the genus \"Bacillus\" contains a very large number of nested taxa and majorly in both 16S and 23S it is paraphyletic to the Lactobacillales (\"Lactobacillus, Streptococcus, Staphylococcus, Listeria\", etc.), due to \"Bacillus coahuilensis\" and others. A gene concatenation study found similar results to Xu and Cote, but with a much more limited number of species in terms of groups, but used \"Listeria\" as an outgroup, so in light of the ARB tree, it may be \"inside-out\".\n\nOne clade, formed by \"B. anthracis\", \"B. cereus\", \"B. mycoides\", \"B. pseudomycoides\", \"B. thuringiensis\", and \"B. weihenstephanensis\" under current classification standards, should be a single species (within 97% 16S identity), but due to medical reasons, they are considered separate species, an issue also present for four species of \"Shigella\" and \"Escherichia coli\".\n\n\n"}
{"id": "4752", "url": "https://en.wikipedia.org/wiki?curid=4752", "title": "Brasília", "text": "Brasília\n\nBrasília () is the federal capital of Brazil and seat of government of the Federal District. The city is located atop the Brazilian highlands in the country's center-western region. It was founded on April 21, 1960, to serve as the new national capital. Brasília and its metro area were estimated to be Brazil's 4th most populous city. Among major Latin American cities, Brasília has the highest GDP per capita at ().\n\nBrasília was planned and developed by Lúcio Costa and Oscar Niemeyer in 1956 to move the capital from Rio de Janeiro to a more central location. The landscape architect was Roberto Burle Marx. The city's design divides it into numbered blocks as well as sectors for specified activities, such as the Hotel Sector, the Banking Sector and the Embassy Sector. Brasília was chosen as a UNESCO World Heritage Site due to its modernist architecture and uniquely artistic urban planning.\n\nThe centers of all three branches of the federal government of Brazil are in Brasília, including the Congress, President, and Supreme Court. The city also hosts 124 foreign embassies. Brasília International Airport connects the capital to all major Brazilian cities and many international destinations, and is the third busiest airport in Brazil. It is the second most populous Portuguese-speaking capital city after Luanda. The city was one of the main host cities of the 2014 FIFA World Cup and hosted some of the soccer matches during the 2016 Summer Olympic Games. Brasília also hosted the 2013 FIFA Confederations Cup.\n\nThe city has a unique status in Brazil, as it is an administrative division rather than a legal municipality like other cities in Brazil. Although Brasília is used as a synonym for the Federal District through synecdoche, the Federal District is composed of 31 administrative regions, only one of which is the area of the originally planned city, also called Plano Piloto. The rest of the Federal District is considered by IBGE to make up Brasília's metro area.\n\nFrom 1763 until 1960, Rio de Janeiro was Brazil's capital. At this time, resources tended to be centered in Brazil's southeast region near Rio de Janeiro and most of its population was concentrated near to the Atlantic Coast. Brasília's geographically central location fostered a more regionally neutral federal capital. An article of the country's first republican constitution dating back to 1891 stated the capital should be moved from Rio de Janeiro to a place close to the country's center.\n\nThe plan was conceived in 1827 by José Bonifácio, an advisor to Emperor Pedro I. He presented a plan to the General Assembly of Brazil for a new city called Brasília, with the idea of moving the capital westward from the heavily populated southeastern corridor. The bill was not enacted because Pedro I dissolved the Assembly.\n\nAccording to legend, Italian saint Don Bosco in 1883 had a dream in which he described a futuristic city that roughly fitted Brasília's location. In Brasília today, many references of Bosco, who founded the Salesian order, are found throughout the city and one church parish in the city bears his name.\n\nIn 1957 an international jury selected Lúcio Costa's plan to guide the construction of Brazil’s new capital, Brasilia. Costa's plan was not as detailed as some of the plans presented by other architects and city planners, it did not include land use schedules, models, population charts or mechanical drawings, however, it was chosen by five out of six jurors because it had the features required to align the growth of a capital city Even though the initial plan was transformed over time, his plan oriented much of the construction and most of its features survived.\n\nBrasilia's possession as the new capital and its representation of the conquest of an extensive region in Brazil inspired the symbolism of the plan; Costa, uses a cross-axial design indicating the possession and conquest of this new place with a cross often described by some as a dragonfly, an airplane or a bird. Costa's plan included two principal components, the Monumental Axis (east to west) and the Residential Axis (north to south).\n\nThe Monumental Axis designated for political and administrative activities is considered the body of the city with the style and simplicity of its buildings, its oversized scales, broad vistas and heights, producing the idea of Monumentality. This axis includes ministries, the national congress, and the television and radio tower.\n\nThe Residential Axis was intended to contain areas with intimate character and is considered the most important achievement of the plan; it was designed for housing and associated functions such as local commerce, schooling, recreations and churches, constituted of 96 superblocks (\"s\") limited to six stories buildings and 12 additional superblocks limited to three stories buildings; Costa's intention with superblocks was to have small self-contained and self-sufficient neighborhoods and uniform buildings with apartments of two or three different categories, where he envisioned the integration of upper and middle classes sharing the same residential area.\n\nThe urban design of the communal apartment blocks was based on Le Corbusier’s Ville Radieuse of 1935 and the superblocks on the North American Radburn layout from 1929. Visually, the blocks were intended to appear absorbed by the landscape because they were isolated by a belt of tall trees and lower vegetation. Costa attempted to introduce a Brazil that was more equitable, he also designed housing for the working classes that was separated from the upper and middle-class housing and was visually different, with the intention of avoiding slums (\"fabelas\") in the urban periphery. The superquadra has been accused of being a space where individuals are oppressed and alienated to a form of spatial segregation.\n\nOne of the main objectives of the plan was to allow the free flow of automobile traffic, the plan included lanes of traffic in a north-south direction (seven for each direction) for the Monumental Axis and three arterials (the W3, the Eixo and the L2) for the residential Axis; the cul-de-sac access roads of the superblocks were planned to be the end of the main flow of traffic. This emphasis of the plan on automobiles caused the lengthening of distances between centers and it attended only the necessities of a small segment of the population who owned cars.\n\nAt the intersection of the Monumental and Residential Axis Costa planned the city center with the transportation center (Rodoviaria), the banking sector and the hotel sector, near to the city center, he proposed an amusement center with theatres, cinemas and restaurants. Costa's Plan is seen as a plan with a sectoral tendency, segregating all the banks, the office buildings, and the amusement center.\n\nOne of the main features of Costa's Plan was that he presented a new city with its future shape and patterns evident from the beginning. This means that the original plan included paving streets that were not immediately put into use; the advantage of this is that the original plan is hard to undo because he provided for an entire street network, but on the other hand, is difficult to adapt and mold to other circumstances in the future. In addition, there has been controversy with the monumental aspect of Lucio Costal's Plan, because it appeared to some as city planning of the 19th century and not that of a modern urbanism of the 20th century in Brazil.\n\nAn interesting analysis can be made of Brasilia within the context of Cold War politics and the association of Lucio Costa’s plan to the symbolism of aviation. From an architectural perspective, the airplane-shaped plan was certainly an homage to Le Corbusier and his enchantment with the aircraft as an architectural masterpiece. However, it is important to also note that Brasilia was constructed soon after the end of World War II. Despite Brazil’s minor participation in the conflict, the airplane shape of the city was key in envisioning the country as part of the newly globalized world, together with the victorious Allies.\n\nJuscelino Kubitschek, President of Brazil from 1956 to 1961, ordered Brasília's construction, fulfilling the promise of the Constitution and his own political campaign promise. Building Brasília was part of Juscelino's \"fifty years of prosperity in five\" plan. Already in 1892, the astronomer Louis Cruls, in the service of the Brazilian government, had investigated the site for the future capital. Lúcio Costa won a contest and was the main urban planner in 1957, with 5550 people competing. Oscar Niemeyer, a close friend, was the chief architect of most public buildings and Roberto Burle Marx was the landscape designer. Brasília was built in 41 months, from 1956 to April 21, 1960, when it was officially inaugurated.\n\nParanoá Lake is a large artificial lake that was built to increase the amount of water available and the region's humidity. It has Brazil's second largest marina, and hosts wakeboarders and windsurfers. Diving can also be practiced and one of the main attractions is Vila Amaury, an old village submerged in the lake. This is where the first construction workers of Brasília used to live.\n\nBrasília has a tropical savanna climate (Aw) according to the Köppen system, with two distinct seasons: the rainy season, from October to April, and a dry season, from May to September. The average temperature is . September, at the end of the dry season, has the highest average maximum temperature, , has major and minor lower maximum average temperature, of and , respectively. Average temperatures from September through March are a consistent . With , January is the month with the highest rainfall of the year, while June is the lowest, with only .\n\nAccording to Brazilian National Institute of Meteorology (INMET), the record low temperature was on July 18, 1975, and the record high was on October 28, 2008. The highest accumulated rainfall in 24 hours was on November 15, 1963.\n\nAccording to the 2010 IBGE Census, there were 2,469,489 people residing in Brasília and its metropolitan area, of which 1,239,882 were Pardo (multiracial) (48.2%), 1,084,418, White (42.2%), 198,072, Black (7.7%), 41,522, Asian (1.6%), and 6,128 Amerindian (0.2%).\n\nIn 2010, Brasília was ranked the fourth most-populous city in Brazil after São Paulo, Rio de Janeiro, and Salvador. In 2010, the city had 474,871 opposite-sex couples and 1,241 same-sex couples. The population of Brasília was 52.2% female and 47.8% male.\n\nIn the 1960 census there were almost 140 thousand residents in the new Federal District. By 1970 this figure had grown to 537 thousand. By 2000 the population of the Federal District had surpassed 2 million. The city of Brasília proper was planned for only about 500 thousand inhabitants, but its metropolitan area has grown past this figure.\nFrom the beginning, the growth of Brasília was greater than original estimates. According to the original plans, Brasília would be a city for government authorities and staff. However, during the construction period, Brazilians from all over the country migrated to Brasília, seeking public and private jobs.\n\nAt the close of the 20th century, Brasília held the distinction of being the largest city in the world which had not existed at the beginning of the century. Brasília has one of the highest population growth rates in Brazil, with annual growth of 2.82%, mostly due to internal migration.\n\nBrasília's inhabitants include a foreign population of mostly embassy workers as well as large numbers of Brazilian internal migrants. Today, the city has important communities of immigrants and refugees. The city's Human Development Index was 0.936 in 2000 (developed level), and the city's literacy rate was around 95.65%.\n\nThe Cathedral of Brasília in the capital of the Federative Republic of Brazil, is an expression of the architect Oscar Niemeyer. This concrete-framed hyperboloid structure, seems with its glass roof reaching up, open, to the heavens. On 31 May 1970, the Cathedral's structure was finished, and only the diameter of the circular area were visible. Niemeyer's project of Cathedral of Brasília is based in the hyperboloid of revolution which sections are asymmetric. The hyperboloid structure itself is a result of 16 identical assembled concrete columns. These columns, having hyperbolic section and weighing 90 t, represent two hands moving upwards to heaven. The Cathedral was dedicated on 31 May 1970.\n\n\"Source: IBGE 2010. \"\n\nThe seats of the three branches of the Brazilian state are located in Brasilia. Until the 1980s, the Federal Government appointed the governor of the Federal District, and the laws of Brasília were issued by the Brazilian Federal Senate. With the Constitution of 1988, Brasília gained the right to elect its Governor, and a District Assembly (Câmara Legislativa) was elected to exercise legislative power. The Federal District does not have a Judicial Power. The Judicial Power which serves the Federal District also serves federal territories. Brazil does not have any territories, therefore, for now the courts only serve cases from the Federal District.\n\nBrasília is twinned with:\nOf these, Abuja, Canberra, and Washington were likewise cities planned specifically to be their respective countries' seats of government.\n\nAt the northwestern end of the Monumental Axis are federal district and municipal buildings, while at the southeastern end, near the middle shore of Lake Paranoá, stand the executive, judicial, and legislative buildings around the Square of Three Powers, the conceptual heart of the city.\nThese and other major structures were designed by Brazilian architect Oscar Niemeyer in the style of modern Brazilian architecture. In the Square of Three Powers, he created as a focal point the dramatic Congressional Palace, which is composed of five parts: twin administrative towers flanked by a large, white concrete dome (the meeting place of the Senate) and by an equally massive concrete bowl (the Chamber of Deputies), which is joined to the dome by an underlying, flat-roofed building. The Congress also occupies various other surrounding buildings, some connected by tunnels. A series of low-lying annexes (largely hidden) flank both ends.\n\nThe National Congress building is located in the middle of the Eixo Monumental, the city's main avenue. In front lies a large lawn and reflecting pool. The building faces the Praça dos Três Poderes where the Palácio do Planalto and the Supreme Federal Court are located.\n\nAlso in the square are the glass-faced Planalto Palace housing the presidential offices, and the Palace of the Supreme Court. Farther east, on a triangle of land jutting into the lake, is the Palace of the Dawn (Palácio da Alvorada; the presidential residence). Between the federal and civic buildings on the Monumental Axis is the city's cathedral, considered by many to be Niemeyer's finest achievement (see photographs of the interior). The parabolically shaped structure is characterized by its 16 gracefully curving supports, which join in a circle 115 feet (35 meters) above the floor of the nave; stretched between the supports are translucent walls of tinted glass. The nave is entered via a subterranean passage rather than conventional doorways. Other notable buildings are Buriti Palace, Itamaraty Palace, the National Theater, and several foreign embassies that creatively embody features of their national architecture. The Brazilian landscape architect Roberto Burle Marx designed landmark modernist gardens for some of the principal buildings.\n\nBoth low-cost and luxury housing were built by the government in the Brasília. The residential zones of the inner city are arranged into \"superquadras\" (\"superblocks\"): groups of apartment buildings along with a prescribed number and type of schools, retail stores, and open spaces. At the northern end of Lake Paranoá, separated from the inner city, is a peninsula with many fashionable homes, and a similar city exists on the southern lakeshore. Originally the city planners envisioned extensive public areas along the shores of the artificial lake, but during early development private clubs, hotels, and upscale residences and restaurants gained footholds around the water. Set well apart from the city are satellite cities, including Gama, Ceilândia, Taguatinga, Núcleo Bandeirante, Sobradinho, and Planaltina. These cities, with the exception of Gama and Sobradinho were not planned.\n\nThe city has been both acclaimed and criticized for its use of modernist architecture on a grand scale and for its somewhat utopian city plan.\n\nAfter a visit to Brasília, the French writer Simone de Beauvoir complained that all of its \"superquadras\" exuded \"the same air of elegant monotony,\" and other observers have equated the city's large open lawns, plazas, and fields to wastelands. As the city has matured, some of these have gained adornments, and many have been improved by landscaping, giving some observers a sense of \"humanized\" spaciousness. Although not fully accomplished, the \"Brasília utopia\" has produced a city of relatively high quality of life, in which the citizens live in forested areas with sporting and leisure structure (the \"superquadras\") flanked by small commercial areas, bookstores and cafes; the city is famous for its cuisine and efficiency of transit.\n\nEven these positive features have sparked controversy, expressed in the nickname \"ilha da fantasia\" (\"fantasy island\"), indicating the sharp contrast between the city and surrounding regions, marked by poverty and disorganization in the cities of the states of Goiás and Minas Gerais, around Brasília.\n\nCritics of Brasília's grand scale have characterized it as a modernist platonic fantasy about the future:\n\nThe major roles of construction and of services (government, communications, banking and finance, food production, entertainment, and legal services) in Brasília's economy reflect the city's status as a governmental rather than an industrial center. Industries connected with construction, food processing, and furnishings are important, as are those associated with publishing, printing, and computer software. GDP is divided in Public Administration 54.8%, Services 28.7%, Industry 10.2%, Commerce 6.1%, Agribusiness 0.2%.\n\nBesides being the political center, Brasília is an important economic center. Brasília has the highest city gross domestic product (GDP) of 99.5 billion reais representing 3.76% of the total Brazilian GDP.\nThe main economic activity of the federal capital results from its administrative function. Its industrial planning is studied carefully by the Government of the Federal District. Being a city registered by UNESCO, the government in Brasília has opted to encourage the development of non-polluting industries such as software, film, video, and gemology among others, with emphasis on environmental preservation and maintaining ecological balance, preserving the city property.\n\nAccording to Mercer's city rankings of cost of living for expatriate employees, Brasília ranks 45th among the most expensive cities in the world in 2012, up from the 70th position in 2010, ranking behind São Paulo (12th) and Rio de Janeiro (13th).\n\n(91% of local GDP, according to the IBGE):\n\nIn the city include: Construction (Paulo Octavio, Via Construções, and Irmãos Gravia among others); Food processing (Perdigão, Sadia); Furniture Making; Recycling (Novo Rio, Rexam, Latasa and others); Pharmaceuticals (União Química); Graphic industries. The main agricultural products produced in the city are coffee, guavas, strawberries, oranges, lemons, papayas, soy beans, and mangoes. It has over 110,000 cows and it exports wood products worldwide.\n\nThe Federal District, where Brasília is located, has a GDP of R$133,4 billion (about US$64.1 billion), about the same as Belarus according to The Economist. Its share of the total Brazilian GDP is about 3.8%. The Federal District has the largest GDP per capita income of Brazil US$25,062, slightly higher than Belarus.\n\nThe city's planned design included specific areas for almost everything, including accommodation, Hotels Sectors North and South. New hotel facilities are being developed elsewhere, such as the hotels and tourism Sector North, located on the shores of Lake Paranoá. Brasília has a range of tourist accommodation from inns, pensions and hostels to larger international chain hotels. The city's restaurants cater to a wide range of foods from local and regional Brazilian dishes to international cuisine.\n\nAs a venue for political events, music performances and movie festivals, Brasília is a cosmopolitan city, with around 124 embassies, a wide range of restaurants and complete infrastructure ready to host any kind of event. Not surprisingly, the city stands out as an important business tourism destination, which is an important part of the local economy, with dozens of hotels spread around the federal capital. Traditional parties take place throughout the year.\n\nIn June, large festivals known as \"festas juninas\" are held celebrating Catholic saints such as Saint Anthony of Padua, Saint John the Baptist, and Saint Peter. On September 7, the traditional Independence Day parade is held on the Ministries Esplanade. Throughout the year, local, national, and international events are held throughout the city. Christmas is widely celebrated, and New Year's Eve usually hosts major events.\n\nThe city also hosts a varied assortment of art works from artists like Bruno Giorgi, Alfredo Ceschiatti, Athos Bulcão, Marianne Peretti, Alfredo Volpi, Di Cavalcanti, Dyllan Taxman, Victor Brecheret and Burle Marx, whose works have been integrated into the city's architecture, making it a unique landscape. The cuisine in the city is very diverse. Many of the best restaurants in the city can be found in the Asa Sul district.\n\nThe city is also the birthplace of Brazilian rock and place of origin of many bands like: Legião Urbana, Capital Inicial, Aborto Elétrico, Plebe Rude and Raimundos. Currently Brasília has the Rock Basement Festival who attempts to bring new bands to the national scene. The festival is held in the parking Brasilia National Stadium Mané Garrincha.\n\nIn the local cinema production, Afonso Brazza is an outstanding director who became cult thanks to his low budget police movies.\nAnother filmmaker rooted in Brasilia is Vladimir Carvalho, who is well-known not only in Brasilia but in the whole country. He is also a cinema teacher at University of Brasilia and has produced 21 documentaries, most of them about the capital's history, social culture problems and politics.\nSince 1965, the annual Brasilia Festival of Brazilian Cinema is one of the most traditional cinema festivals in Brazil, being compared only to the Brazilian Cinema Festival of Gramado, in Rio Grande do Sul. The difference between both is that the festival in Brasilia still preserves the tradition to only submit and reward Brazilian movies.\n\nBrasília has also been the focus of modern-day literature. Published in 2008, \"The World In Grey: Dom Bosco's Prophecy\", by author Ryan J. Lucero, tells an apocalypticle story based on the famous prophecy from the late 19th century by the Italian saint Don Bosco. According to Don Bosco's prophecy: \"Between parallels 15 and 20, around a lake which shall be formed; A great civilization will thrive, and that will be the Promised Land.\" Brasília lies between the parallels 15° S and 20° S, where an artificial lake (Paranoá Lake) was formed. Don Bosco is Brasília's patron saint.\n\n\"American Flagg!\", the First Comics comic book series created by Howard Chaykin, portrays Brasília as a cosmopolitan world capital of culture and exotic romance. In the series, it is a top vacation and party destination. The 2015 Rede Globo series \"Felizes para Sempre?\" was set in Brasília.\n\nAt the end of the \"Eixo Monumental\" (\"Monumental Axis\") lies the \"Esplanada dos Ministérios\" (\"Ministries Esplanade\"), an open area in downtown Brasília. The rectangular lawn is surrounded by two eight-lane avenues where many government buildings, monuments and memorials are located. On Sundays and holidays, the Eixo Monumental is closed to cars so that locals may use it as a place to walk, bike, and have picnics under the trees.\n\n\"Praça dos Três Poderes\" (Portuguese for \"Square of the Three Powers\") is a plaza in Brasília. The name is derived from the encounter of the three federal branches around the plaza: the Executive, represented by the Palácio do Planalto (presidential office); the Legislative, represented by the National Congress (Congresso Nacional); and the Judicial branch, represented by the Supreme Federal Court (Supremo Tribunal Federal). It is a tourist attraction in Brasília, designed by Lúcio Costa and Oscar Niemeyer as a place where the three branches would meet harmoniously.\n\n\nThe Palácio da Alvorada is the official residence of the President of Brazil. The palace was designed, along with the rest of the city of Brasília, by Oscar Niemeyer and inaugurated in 1958. One of the first structures built in the republic's new capital city, the \"Alvorada\" lies on a peninsula at the margins of Lake Paranoá. The principles of simplicity and modernity, that in the past characterized the great works of architecture, motivated Niemeyer. The viewer has an impression of looking at a glass box, softly landed on the ground with the support of thin external columns. The building has an area of 7,000 m with three floors consisting of the basement, landing, and second floor. The auditorium, kitchen, laundry, medical center, and administration offices are at basement level. The rooms used by the presidency for official receptions are on the landing. The second floor has four suites, two apartments, and various private rooms which make up the residential part of the palace. The building also has a library, a heated Olympic-sized swimming pool, a music room, two dining rooms and various meeting rooms. A chapel and heliport are in adjacent buildings.\n\nThe Palácio do Planalto is the official workplace of the President of Brazil. It is located at the Praça dos Três Poderes in Brasília. As the seat of government, the term \"Planalto\" is often used as a metonym for the executive branch of government. The main working office of the President of the Republic is in the Palácio do Planalto. The President and his or her family do not live in it, rather in the official residence, the Palácio da Alvorada. Besides the President, senior advisors also have offices in the \"Planalto,\" including the Vice-President of Brazil and the Chief of Staff. The other Ministries are along the Esplanada dos Ministérios. The architect of the Palácio do Planalto was Oscar Niemeyer, creator of most of the important buildings in Brasília. The idea was to project an image of simplicity and modernity using fine lines and waves to compose the columns and exterior structures. The Palace is four stories high, and has an area of 36,000 m. Four other adjacent buildings are also part of the complex.\n\nThe Portuguese language is the official national language and the primary language taught in schools. English and Spanish are also part of the official curriculum. The city has six international schools: American School of Brasília, Brasília International School (BIS), Escola das Nações, Swiss International School (SIS), Lycée français François-Mitterrand (LfFM) and Maple Bear Canadian School. August 2016 will see the opening of a new international school – The British School of Brasilia. Brasília has two universities, three university centers, and many private colleges.\n\nThe main tertiary educational institutions are: Universidade de Brasília – University of Brasília (UnB) (public); Universidade Católica de Brasília – Catholic University of Brasília (UCB); Centro Universitário de Brasília (UniCEUB); Centro Universitário Euroamaricano (Unieuro); Centro Universitário do Distrito Federal (UDF); Universidade Paulista (UNIP); and Instituto de Educação Superior de Brasília (IESB).\n\nBrasília–Presidente Juscelino Kubitschek International Airport serves the metropolitan area with major domestic and international flights. It is the third busiest Brazilian airport based on passengers and aircraft movements. Because of its strategic location it is a civil aviation hub for the rest of the country.\n\nThis makes for a large number of takeoffs and landings and it is not unusual for flights to be delayed in the holding pattern before landing. Following the airport's master plan, Infraero built a second runway, which was finished in 2006. In 2007, the airport handled 11,119,872 passengers. The main building's third floor, with 12 thousand square meters, has a panoramic deck, a food court, shops, four movie theatres with total capacity of 500 people, and space for exhibitions. Brasília Airport has 136 vendor spaces. The airport is located about from the central area of Brasília, outside the metro system. The area outside the airport's main gate is lined with taxis as well as several bus line services which connect the airport to Brasília's central district. The parking lot accommodates 1,200 cars. The airport is serviced by domestic and regional airlines (TAM, GOL, Azul, WebJET, Trip and Avianca), in addition to a number of international carriers. In 2012, Brasília's International Airport was won by the InfrAmerica consortium, formed by the Brazilian engineering company ENGEVIX and the Argentine Corporacion America holding company, with a 50% stake each. During the 25-year concession, the airport may be expanded to up to 40 million passengers a year.\n\nIn 2014, the airport received 15 new boarding bridges, totalling 28 in all. This was the main requirement made by the federal government, which transferred the operation of the terminal to the Inframerica Group after an auction. The group invested R$750 million in the project. In the same year, the number of parking spaces doubled, reaching three thousand. The airport's entrance have a new rooftop cover and a new access road. Furthermore, a VIP room was created on Terminal 1's third floor. The investments resulted an increase the capacity of Brasília's airport from approximately 15 million passengers per year to 21 million by 2014. Brasília has direct flights to all states of Brazil and direct international flights to Atlanta, Buenos Aires, Lisbon, Miami, Panama City, and Paris.\n\nLike most Brazilian cities, Brasilia has a good network of taxi companies. Taxis from the airport are available immediately outside the terminal, but at times there can be quite a queue of people. Although the airport is not far from the downtown area, taxi prices do seem to be higher than in other Brazilian cities. Booking in advance can be advantageous, particularly if time is limited, and local companies should be able to assist airport transfer or transport requirements.\n\nThe Juscelino Kubitschek bridge, also known as the 'President JK Bridge' or the 'JK Bridge', crosses Lake Paranoá in Brasília. It is named after Juscelino Kubitschek de Oliveira, former president of Brazil. It was designed by architect Alexandre Chan and structural engineer Mário Vila Verde. Chan won the Gustav Lindenthal Medal for this project at the 2003 International Bridge Conference in Pittsburgh due to \"...outstanding achievement demonstrating harmony with the environment, aesthetic merit and successful community participation\".\n\nIt consists of three tall asymmetrical steel arches that crisscross diagonally. With a length of 1,200 m (0.75 miles), it was completed in 2002 at a cost of US$56.8 million. The bridge has a pedestrian walkway and is accessible to bicyclists and skaters.\n\nThe Brasília Metro is Brasília's underground metro system. The system has 24 stations on two lines, the Orange and Green lines, along a total network of , covering some of the metropolitan area. Both lines begin at the Central Station and run parallel until the Águas Claras Station. The Brasília metro is not comprehensive so buses may provide better access to the center.\n\nThe metro leaves the Rodoviária (bus station) and goes south, avoiding most of the political and tourist areas. The main purpose of the metro is to serve cities, such as Samambaia, Taguatinga and Ceilândia, as well as Guará and Águas Claras. The satellite cities served are more populated in total than the Plano Piloto itself (the census of 2000 indicated that Ceilândia had 344,039 inhabitants, Taguatinga had 243,575, and the Plano Piloto had approximately 400,000 inhabitants), and most residents of the satellite cities depend on public transportation.\n\nA high-speed railway was planned between Brasília and Goiânia, the capital of the state of Goias, but it will probably be turned into a regional service linking the capital cities and cities in between, like Anápolis and Alexânia.\n\nThe main bus hub in Brasília is the Central Bus Station, located in the crossing of the Eixo Monumental and the Eixão, about from the Three Powers Plaza. The original plan was to have a bus station as near as possible to every corner of Brasília. Today, the bus station is the hub of urban buses only, some running within Brasília and others connecting Brasília to the satellite cities.\n\nIn the original city plan, the interstate buses should also stop at the Central Station. Because of the growth of Brasília (and corresponding growth in the bus fleet), today the interstate buses leave from the older interstate station (called Rodoferroviária), located at the western end of the Eixo Monumental. The Central Bus Station also contains a main metro station. A new bus station was opened in July 2010. It is on Saída Sul (South Exit) near Parkshopping Mall and with its metro station, and it's also an inter-state bus station, used only to leave the Federal District.\n\nThe average amount of time people spend commuting with public transit in Brasília, for example to and from work, on a weekday is 96 min. 31% of public transit riders, ride for more than 2 hours every day. The average amount of time people wait at a stop or station for public transit is 28 min, while 61% of riders wait for over 20 minutes on average every day. The average distance people usually ride in a single trip with public transit is 15.1 km, while 50% travel for over 12 km in a single direction. \n\nThe three most well known teams of Brasília are: Brasiliense FC from Taguatinga (Commonly called \"Jacaré\", the \"Caiman\"); SE Gama (Commonly called \"Verdão\", the \"Big Green\") and Brasília FC (Commonly called \"Colorado\", \"The Reds\"). Gama and Brasiliense won the Série B of the Brazilian Football Championship once (Gama in 1998 and Brasiliense in 2004), but they failed to be successful in the Série A. Brasília FC won the regional tournament Copa Verde in 2014.\n\nThe main stadiums are the Brasilia National Stadium Mané Garrincha (which was reinaugurated on May 18, 2013), the Serejão Stadium (home for Brasiliense) and the Bezerrão Stadium (home for Gama).\n\nBrasília was one of the host cities of the 2014 FIFA World Cup and 2013 FIFA Confederations Cup, for which Brazil is the host nation. Brasília hosted the opening of the Confederations Cup and hosted 7 World Cup games. Brasília also hosted the football tournaments during the 2016 Summer Olympics held in Rio de Janeiro.\n\nBrasília is known as a departing point for the practice of unpowered air sports, sports that may be practiced with hang gliding or paragliding wings. Practitioners of such sports reveal that, because of the city's dry weather, the city offers strong thermal winds and great \"cloud-streets\", which is also the name for a manoeuvre quite appreciated by practitioners. In 2003, Brasília hosted the 14th Hang Gliding World Championship, one of the categories of free flying. In August 2005, the city hosted the 2nd stage of the Brazilian Hang Gliding Championship.\n\nBrasília is the site of the Autódromo Internacional Nelson Piquet which hosted a non-championship round of the 1974 Formula One Grand Prix season. An IndyCar race was cancelled at the last minute in 2015.\n\nThe city is also home to Uniceub BRB, one of Brazil's best basketball clubs. Currently, NBB champion (2010, 2011 and 2012). The club hosts some of its games at the 16,000 all-seat Nilson Nelson Gymnasium.\n\n\n"}
{"id": "4754", "url": "https://en.wikipedia.org/wiki?curid=4754", "title": "Blue Streak (missile)", "text": "Blue Streak (missile)\n\nThe de Havilland Propellers Blue Streak was a British medium-range ballistic missile (MRBM), and later the first stage of the Europa satellite launch vehicle. Blue Streak was cancelled without entering full production.\n\nThe project was intended to maintain an independent British nuclear deterrent, replacing the V bomber fleet which would become obsolete by 1965. The operational requirement for the missile was issued in 1955 and the design was complete by 1957. However, during development it became clear that the missile system was too expensive and too vulnerable to a pre-emptive strike. The missile project was cancelled in 1960, with US-led Skybolt the preferred replacement.\n\nPartly to avoid political embarrassment from the cancellation, the UK Government proposed that the rocket be used as the first stage of a civilian satellite launcher called Black Prince. However, the cost was thought to be too great for the UK alone, and international collaboration was sought. This led to the formation of the European Launcher Development Organisation (ELDO), with Blue Streak used as the first stage of a carrier rocket named Europa.\n\nEuropa was tested at Woomera Test Range, Australia, and later at Kourou in French Guiana. Following launch failures, the ELDO project was cancelled in 1972 and development of Blue Streak was halted.\nPost-war Britain's nuclear weapons armament was initially based on free-fall bombs delivered by the V bomber force. It soon became clear that if Britain wanted to have a credible nuclear deterrent threat, a ballistic missile was essential. There was a political need for an independent deterrent, so that Britain could remain a major world power. Britain was unable to purchase American weapons wholesale due to the restrictions of the Atomic Energy Act of 1946.\n\nIn April 1954 the Americans proposed a joint development programme for ballistic missiles. The United States would develop an intercontinental ballistic missile (ICBM) of range (SM-65 Atlas), while the United Kingdom with United States support would develop a medium-range ballistic missile (MRBM) of range. The proposal was accepted as part of the Wilson-Sandys Agreement of August 1954, which provided for collaboration, exchange of information, and mutual planning of development programmes. The decision to develop was influenced by what could be learnt about missile design and development in the US. Initial requirements for the booster (rocketry) were made by the Royal Aircraft Establishment at Farnborough with input on the rocket engine design from the Rocket Propulsion Establishment at Westcott. British Operational Requirement 1139 demanded a rocket of at least 1500 n.m. and the initially proposed rocket would have just reached that threshold.\n\nThe de Havilland Propellers company won the contract to build the missile, which was to be powered by an uprated liquid-fuelled Rocketdyne S3D engine, developed by Rolls-Royce, called RZ.2. Two variants of this engine were developed: the first provided a static thrust of and the second (intended for the three stage satellite launch vehicle) . The engines were unique at that time in that they could be vectored by seven degrees in flight and could therefore be used to guide the vehicle. This configuration, however, put considerable pressure on the autopilot which had to cope with the problem of a vehicle whose weight was diminishing rapidly and that was steered by large engines whose thrust remained more or less constant. Vibration was also a problem, particularly at engine cut-off, and the later development of the autopilot for the satellite launcher was, in itself, a considerable achievement.\n\nSubcontractors included the Sperry Gyroscope Company who produced the missile guidance system whilst the nuclear warhead was designed by the Atomic Weapons Research Establishment at Aldermaston.\n\nThe missiles used liquid oxygen and kerosene propellants. Whilst the vehicle could be left fully laden with over 20 tonnes of kerosene, the 60 tonnes of liquid oxygen had to be loaded immediately before launch or icing became a problem. Due to this, fuelling the rocket took 4.5 minutes, which would have made it useless as a rapid response to an attack. The missile was vulnerable to a pre-emptive nuclear strike, launched without warning or in the absence of any heightening of tension sufficient to warrant readying the missile. To negate this problem de Havilland created a stand-by feature. A missile could be held at 30 seconds' notice to launch for ten hours. As the missiles were to be deployed in pairs and it took ten hours for one missile to be prepared for stand-by, one of the two missiles could always be ready for rapid launch.\n\nTo protect the missiles against a pre-emptive strike while being fuelled, the idea of siting the missiles in underground launchers was developed. These would have been designed to withstand a one megaton blast at a distance of half a mile (800 m) and were a British innovation, subsequently exported to the United States. However, finding sites for these silos proved extremely difficult and RAF Spadeadam in Cumberland (now Cumbria) was the only site where construction was started on a full scale underground launcher, although test borings were undertaken at a number of other locations. The remains of this test silo, known as U1, were rediscovered by tree felling at Spadeadam. This was also the site where the RZ.2 rocket engines and also the complete Blue Streak missile were tested. The best sites for silo construction were the more stable rock strata in parts of southern and north-east England and eastern Scotland, but the construction of many underground silos in the countryside carried enormous economic, social, and political costs. Development of the underground launchers presented a major technical challenge. 1/60th and 1/6th scale models based on a ‘U’ shaped design were constructed and tested at RPE Westcott. Three alternative designs were drawn up with one chosen as the prototype, designated K11. RAF Upavon would appear to have been the preferred location for the prototype operational launcher with the former RNAS at Crail as the likely first operational site.\n\nIn 1955-1956, the rocket motors were test fired at The Needles Battery on the Isle of Wight. As no site in Britain provided enough space for test flights, a test site was established at Woomera, South Australia.\n\nDoubts arose as the cost escalated from the first tentative figure of £50m submitted to the Treasury in early 1955, to £300m in late 1959. Its detractors in the civil service claimed that the programme was crawling along when compared with the speed of development in the US and the Soviet Union. \n\nEstimates within the Civil Service for completion of the project ranged from a total spend of £550 million to £1.3 billion, as different ministers were set on either abandoning or continuing the project.\n\nWhitehall opposition to the project grew, and it was eventually cancelled in 1960 on the ostensible grounds that it would be too vulnerable to a first-strike attack. Admiral of the Fleet Lord Mountbatten had spent considerable effort arguing that the project should be cancelled at once in favour of the Navy being armed with nuclear weapons, capable of pre-emptive strike.\n\nSome considered the cancellation of Blue Streak to be not only a blow to British military-industrial efforts, but also to Commonwealth ally Australia, which had its own vested interest in the project.\n\nThe British military transferred its hopes for a strategic nuclear delivery system to the Anglo-American Skybolt missile, before the project's cancellation by the United States as its ICBM program reached maturity. The British instead purchased the Polaris system from the Americans, carried in British-built submarines.\n\nAfter the cancellation as a military project, there was reluctance to cancel the project because of the huge cost incurred. Blue Streak would have become the first stage of a projected all British satellite launcher known as \"Black Prince\": the second stage was derived from the \"Black Knight\" test vehicle, and the orbital injection stage was a small hydrogen peroxide/kerosene motor.\n\nBlack Prince proved too expensive for the UK, and the European Launcher Development Organisation (ELDO) was set up. This used Blue Streak as the first stage, with French and German second and third stages. The Blue Streak first stage was successfully tested three times at the Woomera test range in Australia as part of the ELDO programme.\n\nIn 1959, a year before the cancellation of the Blue Streak as a missile, the government requested that the RAE and Saunders-Roe design a carrier rocket based on Blue Streak and Black Knight. This design used Blue Streak as a first stage and a 54-inch (137 centimetre) second stage based on the Black Knight. Several different third stages would be available, depending on the required payload and orbit.\n\nThe cost of developing Black Prince was estimated to be £35 million.\n\nIt was planned that Black Prince would be a Commonwealth project. However, since the government of John Diefenbaker in Canada was already spending more money than publicly acknowledged on Alouette and Australia was not interested in the project, these two countries were unwilling to contribute. South Africa was no longer a member of the Commonwealth. New Zealand was only likely to make \"modest\" contributions.\n\nBritain instead proposed a collaboration with other European countries to build a three-stage launcher capable of placing a one-ton payload into low Earth orbit. \nConsisting of Belgium, Britain, France, Germany, Italy and the Netherlands, with Australia as an associate member.\n\nPreliminary work began in 1962 and ELDO was formally signed into existence in 1964.\n\nBritain with Blue Streak became the first stage of the European launch vehicle with France providing the Coralie second stage and Germany the third. Italy worked on the satellite project, the Netherlands and Belgium concentrated on tracking and telemetry systems and Australia supplied the launch site.\n\nThe combined launcher was named Europa.\n\nAfter ten test launches, the Woomera launch site was not suitable for putting satellites into geosynchronous orbit, and in 1966 it was decided to move to the French site of Kourou in South America. F11 was fired from here in November 1971, but the failure of the autopilot caused the vehicle to break up. The launch of F12 was postponed whilst a project review was carried out, which led to the decision to abandon the Europa design.\n\nELDO was merged with the European Space Research Organisation to form the European Space Agency.\n\nAside from Black Prince, a range of other proposals was made between 1959 and 1972 for a carrier rocket based on Blue Streak, however, none of these were ever built in full and today only exist in design.\n\nIn 1959 de Havilland suggested solving the problem of the Blue Streak/Black Knight geometry by compressing the 10 by 1 metre (30 by 3 foot) Black Knight into a sphere. Although this seemed logical, the development costs proved to be too high for the limited budget of the programme.\n\nFollowing its merger with Saunders Roe, Westland Helicopters developed the three-stage Black Arrow satellite carrier rocket, derived from the Black Knight test vehicle. The first stage of Black Arrow was given the same diameter as the French Coralie (the second stage of Europa) in order to make it compatible with Blue Streak. Using Blue Streak as an additional stage would have increased Black Arrow's payload capacity. To maintain this compatibility, the first stage diameter was given in metres, although the rest of the rocket was defined in imperial units.\n\nBlack Arrow carried out four test launches (without an additional Blue Streak stage) from Woomera between 1969 and 1971, with the final launch carrying the satellite Prospero X-3 into orbit. The United Kingdom remains the only country to have successfully developed and then abandoned a satellite launch capability.\n\nIn 1972, Hawker Siddeley Dynamics (HSD) produced a brochure for a design using Blue Streak as the first stage of a two-stage to orbit rocket, with an American Centaur upper stage. The Centaur second stage would have either been built in the UK under licence or imported directly from the USA. Both the Centaur and Blue Streak had proved to be very reliable up to this point, and since they were both already designed development costs would have been low. Furthermore, it had a payload of 870–920 kg to a geosynchronous orbit with, and 650–700 kg without the use of additional booster rockets.\n\nFollowing the cancellation of the Blue Streak project some of the remaining rockets were preserved at:\n\n\nA section of the propulsion bay, engines and equipment can be found at the Solway Aviation Museum, Carlisle Lake District Airport. Only a few miles from the Spadeadam testing site, the museum carries many exhibits, photographs and models of the Blue Streak programme, having inherited the original Spadeadam collection that used to be displayed on site.\n\nRZ.2 engines are on display at National Space Centre a pair on cradles alongside the Blue Streak rocket, and at the Armagh Planetarium, Northern Ireland and The Euro Space Center in Redu, Belgium.\n\nFootage from the Blue Streak launch was briefly incorporated into \"The Prisoner\"s final episode, \"Fall Out\". A part of the Blue Streak rocket launched on 5 June 1964 from Woomera, Australia, found 50 km SE of Giles in 1980 (c.1000 km) is on display at Giles Weather Station. Another piece was located in 2006, but its exact location has been kept secret by the finders. The titanium structure of a German third stage was, for some time, sited on the edge of a gravel pit in Gloucestershire. Images of the Blue Streak 1 are incorporated in the 1997 film \"Contact\".\n\n\n\n"}
{"id": "4756", "url": "https://en.wikipedia.org/wiki?curid=4756", "title": "Bakassi", "text": "Bakassi\n\nBakassi is a peninsula on the Gulf of Guinea. It lies between the Cross River estuary, near the city of Calabar in the west, and the Rio del Ray estuary on the east. It is governed by Cameroon, following the transfer of sovereignty from neighbouring Nigeria as a result of a judgment by the International Court of Justice. On 22 November 2007, the Nigerian Senate rejected the transfer, since the Greentree Agreement ceding the area to Cameroon was contrary to Section 12(1) of the 1999 Constitution. Regardless, the territory was transferred to Cameroon on 14 August 2008.\n\nThe peninsula lies between latitudes 4°25′ and 5°10′N and longitudes 8°20′ and 9°08′E . It consists of a number of low-lying, largely mangrove covered islands covering an area of around 665 km² (257 sq mi). The population of Bakassi is the subject of some dispute, but is generally put at between 150,000 and 300,000 people.\n\nBakassi is situated at the extreme eastern end of the Gulf of Guinea, where the warm east-flowing Guinea Current (called Aya Efiat in Efik) meets the cold north-flowing Benguela Current (called Aya Ubenekang in Efik). These two ocean currents interact, creating huge foamy breakers which constantly advance towards the shore, and building submarine shoals rich in fish, shrimps, and a wide variety of other marine life forms. This makes the Bakassi area a very fertile fishing ground, comparable only to Newfoundland in North America and Scandinavia in Western Europe. Most of the population make their living through fishing.\n\nThe peninsula is commonly described as \"oil-rich\", though in fact no commercially viable deposits of oil have been discovered. However, the area has aroused considerable interest from oil companies in the light of the discovery of rich reserves of high grade crude oil in Nigeria. At least eight multinational oil companies have participated in the exploration of the peninsula and its offshore waters. In October 2012, China Petroleum & Chemical Corporation announced it had discovered new oil and gas resources in the Bakassi region.\n\nDuring the Scramble for Africa, Queen Victoria signed a Treaty of Protection with the King and Chiefs of Akwa Akpa, known to Europeans as Old Calabar on 10 September 1884. This enabled the British Empire to exercise control over the entire territory around Calabar, including Bakassi. The territory subsequently became \"de facto\" part of Nigeria, although the border was never permanently delineated. However, documents released by the Cameroonians, in parity with that of the British and Germans, clearly places Bakassi under Cameroonian Territory as a consequence of colonial era Anglo-German agreements. After Southern Cameroons voted in 1961 to leave Nigeria and became a part of Cameroon, Bakassi remained under Calabar administration in Nigeria until ICJ judgement of 2002.\n\nBakassi inhabitants are mainly the Oron people, the people of Cross River State and Akwa Ibom State of Nigeria.\n\nNigeria and Cameroon have disputed the possession of Bakassi for some years, leading to considerable tension between the two countries. In 1981 the two countries went to the brink of war over Bakassi and another area around Lake Chad, at the other end of the two countries' common border. More armed clashes broke out in the early 1990s. In response, Cameroon took the matter to the International Court of Justice (ICJ) on 29 March 1994.\n\nThe case was extremely complex, requiring the court to review diplomatic exchanges dating back over 100 years. Nigeria relied largely on Anglo-German correspondence dating from 1885 as well as treaties between the colonial powers and the indigenous rulers in the area, particularly the 1884 Treaty of Protection. Cameroon pointed to the Anglo-German treaty of 1913, which defined sphere of control in the region, as well as two agreements signed in the 1970s between Cameroon and Nigeria. These were the Yaoundé II Declaration of 4 April 1971 and the Maroua Declaration of 1 June 1975, which were devised to outline maritime boundaries between the two countries following their independence. The line was drawn through the Cross River estuary to the west of the peninsula, thereby implying Cameroonian ownership over Bakassi. However, Nigeria never ratified the agreement, while Cameroon regarded it as being in force.\n\nThe ICJ delivered its judgment on 10 October 2002, finding (based principally on the Anglo-German agreements) that sovereignty over Bakassi did indeed rest with Cameroon. It instructed Nigeria to transfer possession of the peninsula, but did not require the inhabitants to move or to change their nationality. Cameroon was thus given a substantial Nigerian population and was required to protect their rights, infrastructure and welfare.\n\nThe verdict caused consternation in Nigeria. It aroused vitriolic comments from Nigerian officials and the Nigerian media alike. Chief Richard Akinjide, a former Nigerian Attorney-General and Minister of Justice who had been a leading member of Nigeria's legal team, described the decision as \"50% international law and 50% international politics\", \"blatantly biased and unfair\", \"a total disaster\", and a \"complete fraud\". The Nigerian newspaper \"The Guardian\" went further, declaring that the judgment was \"a rape and unforeseen potential international conspiracy against Nigerian territorial integrity and sovereignty\" and \"part of a Western ploy to foment and perpetuate trouble in Africa\". The outcome of the controversy was a \"de facto\" Nigerian refusal to withdraw its troops from Bakassi and transfer sovereignty. The Nigerian government did not, however, openly reject the judgment but instead called for an agreement that would provide \"peace with honour, with the interest and welfare of our people.\"\n\nThe ICJ judgment was backed up by the United Nations, whose charter potentially allowed sanctions or even the use of force to enforce the court's ruling. Secretary-General Kofi Annan stepped in as a mediator and chaired a tripartite summit with the two countries' presidents on 15 November 2002, which established a commission to facilitate the peaceful implementation of the ICJ's judgement. A further summit was held on 31 January 2004. This has made significant progress, but the process has been complicated by the opposition of Bakassi's inhabitants to being transferred to Cameroon.\n\nBakassian leaders threatened to seek independence if Nigeria renounced sovereignty. This secession was announced on 9 July 2006, as the \"Democratic Republic of Bakassi\". The decision was reportedly made at a meeting on 2 July 2006 and The Vanguard newspaper of Nigeria reported the decision to secede. The decision was reportedly made by groups of militants including Southern Cameroons under the aegis of Southern Cameroons Peoples Organisation (SCAPO), Bakassi Movement for Self-Determination (BAMOSD), and the Movement for the Emancipation of the Niger Delta (MEND).\n\nOn 13 June 2006, President Olusegun Obasanjo of Nigeria and President Paul Biya of Cameroon resolved the dispute in talks led by UN Secretary General Kofi Annan in New York City. Obasanjo agreed to withdraw Nigerian troops within 60 days and to leave the territory completely in Cameroonian control within the next two years. Annan said, \"With today's agreement on the Bakassi peninsula, a comprehensive resolution of the dispute is within our grasp. The momentum achieved must be sustained.\"\n\nNigeria began to withdraw its forces, comprising some 3,000 troops, beginning 1 August 2006, and a ceremony on 14 August marked the formal handover of the northern part of the peninsula. The remainder stayed under Nigerian civil authority for two more years.\n\nOn 22 November 2007, the Nigerian Senate passed a resolution declaring that the withdrawal from the Bakassi Peninsula was illegal. The government took no action, and handed the final parts of Bakassi over to Cameroon on 14 August 2008 as planned, but a Federal High Court had stated this should be delayed until all accommodations for resettled Bakassians had been settled; the government did not seem to plan to heed this court order, and set the necessary mechanisms into motion to override it. Fishermen displaced from Bakassi were first settled in a landlocked area called New Bakassi, which they claimed was already inhabited and not suitable for fishermen like them but only for farmers. The displaced people were then moved to Akpabuyo, and eventually established a new community of Dayspring.\n\nDespite the formal handover of Bakassi by Nigeria to Cameroon in 2006, the territory of Bakassi is still reflected as part of the 774 local governments in Nigeria as embodied in the First Schedule, Part I of the 1999 Constitution of the Federal Republic of Nigeria, 1999. After the Nigerian 2015 General Elections, Nigeria's 8th National Assembly still accommodates the Calabar-South/Akpabuyo/Bakassi Federal Constituency represented by Hon. Essien Ekpeyong Ayi of the People's Democratic Party.\n\n"}
{"id": "4757", "url": "https://en.wikipedia.org/wiki?curid=4757", "title": "Bestiary", "text": "Bestiary\n\nA bestiary, or bestiarum vocabulum, is a compendium of beasts. Originating in the Ancient world, bestiaries were made popular in the Middle Ages in illustrated volumes that described various animals and even rocks. The natural history and illustration of each beast was usually accompanied by a moral lesson. This reflected the belief that the world itself was the Word of God, and that every living thing had its own special meaning. For example, the pelican, which was believed to tear open its breast to bring its young to life with its own blood, was a living representation of Jesus. The bestiary, then, is also a reference to the symbolic language of animals in Western Christian art and literature.\n\nThe earliest bestiary in the form in which it was later popularized was an anonymous 2nd century Greek volume called the \"Physiologus\", which itself summarized ancient knowledge and wisdom about animals in the writings of classical authors such as Aristotle's \"Historia Animalium\" and various works by Herodotus, Pliny the Elder, Solinus, Aelian and other naturalists.\n\nFollowing the \"Physiologus\", Saint Isidore of Seville (Book XII of the \"Etymologiae\") and Saint Ambrose expanded the religious message with reference to passages from the Bible and the Septuagint. They and other authors freely expanded or modified pre-existing models, constantly refining the moral content without interest or access to much more detail regarding the factual content. Nevertheless, the often fanciful accounts of these beasts were widely read and generally believed to be true. A few observations found in bestiaries, such as the migration of birds, were discounted by the natural philosophers of later centuries, only to be rediscovered in the modern scientific era.\n\nMediaeval bestiaries are remarkably similar in sequence of the animals of which they treat. Bestiaries were particularly popular in England and France around the 12th century and were mainly compilations of earlier texts. The Aberdeen Bestiary is one of the best known of over 50 manuscript bestiaries surviving today.\n\nBestiaries influenced early heraldry in the Middle Ages, giving ideas for charges and also for the artistic form. Bestiaries continue to give inspiration to coats of arms created in our time.\n\nTwo illuminated Psalters, the Queen Mary Psalter (British Library Ms. Royal 2B, vii) and the Isabella Psalter (State Library, Munich), contain full Bestiary cycles. The bestiary in the Queen Mary Psalter is found in the \"marginal\" decorations that occupy about the bottom quarter of the page, and are unusually extensive and coherent in this work. In fact the bestiary has been expanded beyond the source in the Norman bestiary of Guillaume le Clerc to ninety animals. Some are placed in the text to make correspondences with the psalm they are illustrating.\n\nThe Italian artist Leonardo da Vinci also made his own bestiary.\n\nA \"volucrary\" is a similar collection of the symbols of birds that is sometimes found in conjunction with bestiaries. The most widely known volucrary in the Renaissance was Johannes de Cuba's \"Gart der Gesundheit\" which describes 122 birds and which was printed in 1485.\n\nMedieval bestiaries often contained detailed descriptions and illustrations of species native to Western Europe, exotic animals and what in modern times are considered to be imaginary animals. Descriptions of the animals included the physical characteristics associated with the creature, although these were often physiologically incorrect, along with the Christian morals that the animal represented. The description was then normally followed with an artistic illustration of the animal as described in the bestiary.\n\nBestiaries were organized in different ways based upon the text. The descriptions could be organized by animal groupings, such as terrestrial and marine creatures, or presented in an alphabetical manner. However, the texts gave no distinction between existing and imaginary animals. Descriptions of creatures such as dragons, unicorns, basilisk, griffin and caladrius were common in such works and found intermingled amongst accounts of bears, boars, deer, lions, and elephants.\n\nThis lack of separation has often been associated with the assumption that people during this time believed in what the modern period classifies as nonexistent or \"imaginary creatures\". However, this assumption is currently under debate, with various explanations being offered.\n\nSome scholars, such as Pamela Gravestock, have written on the theory that Medieval people didn't actually think such creatures existed but instead focused on the belief in the importance of the Christian morals these creatures represented and that the importance of the moral didn't change regardless if the animal existed or not.\n\nThe contents of Medieval bestiaries were often obtained and created from combining older textual sources and accounts of animals, such as the \"Physiologus\", with newer observations and writings. In this way, the content of such written works was constantly added to and built upon.\n\nIn modern times, artists such as Henri de Toulouse-Lautrec and Saul Steinberg have produced their own bestiaries. Jorge Luis Borges wrote a contemporary bestiary of sorts, the \"Book of Imaginary Beings\", which collects imaginary beasts from bestiaries and fiction. Nicholas Christopher wrote a literary novel called \"The Bestiary\" (Dial, 2007) that describes a lonely young man's efforts to track down the world's most complete bestiary. John Henry Fleming's \"Fearsome Creatures of Florida\" (Pocol Press, 2009) borrows from the medieval bestiary tradition to impart moral lessons about the environment. Caspar Henderson's The Book of Barely Imagined Beings (Granta 2012, Chicago University Press 2013), subtitled \"A 21st Century Bestiary,\" explores how humans imagine animals in a time of rapid environmental change. In July 2014, Jonathan Scott wrote The Blessed Book of Beasts, Eastern Christian Publications, featuring 101 animals from the various translations of the Bible, in keeping with the tradition of the bestiary found in the writings of the Saints, including Saint John Chrysostom.\n\n\n"}
{"id": "4760", "url": "https://en.wikipedia.org/wiki?curid=4760", "title": "Ballad of the Green Berets", "text": "Ballad of the Green Berets\n\n\"The Ballad of the Green Berets\" is a patriotic song in the ballad style about the Green Berets, an elite special force in the U.S. Army. It is one of the few popular songs of the Vietnam War years to cast the military in a positive light and in 1966 became a major hit, reaching No. 1 for five weeks on the \"Billboard\" Hot 100 and four weeks on Cashbox. Ultimately, the song was named Billboard's #1 single for the year 1966. It was also a crossover smash, reaching No. 1 on \"Billboard's\" Easy Listening chart and No. 2 on \"Billboard's\" Country survey.\n\nThe song was written by then Staff Sgt. Barry Sadler, beginning when he was training to be a Special Forces medic. The author Robin Moore, who wrote the book, \"The Green Berets\", helped Sadler with the lyrics and get a recording contract with RCA Records.\n\nThe lyrics were written, in part, in honor of Green Beret U.S. Army Specialist 5 James Gabriel, Jr., the first native Hawaiian to die in Vietnam, who was killed by Viet Cong gunfire while on a training mission with the South Vietnamese Army on April 8, 1962. One verse mentioned Gabriel by name, but it was not used in the recorded version.\n\nSadler recorded the song and eleven other tunes in New York in December 1965. The song and album, \"Ballads of the Green Berets,\" were released in January 1966. He performed the song on television on January 30, 1966 on \"The Ed Sullivan Show\", and on other TV shows including \"Hollywood Palace\" and \"The Jimmy Dean Show.\"\n\nThe song was the No. 1 hit in the U.S. for the five weeks, spanning March 1966 and the No. 1 hit on the \"Cashbox\" end of the year chart for 1966; also the No. 21 song of the 1960s as ranked by Joel Whitburn. The single sold more than nine million copies; the album, more than two million. \n\n\"The Ballad of the Green Berets\" is currently used as one of the four primary marching tunes of the Fightin' Texas Aggie Band.\n\nThe song is heard in a choral rendition by Ken Darby in the 1968 John Wayne film, \"The Green Berets\", based on Moore's book. The film's score was not released as an album until \"Film Score Monthly\" released it in 2005. A movie tie-in featuring artwork from the film and a cover version by Ennio Morricone was released in Europe, though the album's other tracks were from \"A Fistful of Dollars\" and \"For a Few Dollars More\".\n\nThe song appears in the films \"More American Graffiti\" and \"Canadian Bacon\". It can also be heard in the gun show scene of the 2002 film \"Showtime\", and in the film \"Jesus' Son\", in a scene that features a hitch-hiking Jack Black.\n\nA vinyl copy of \"The Ballad of the Green Berets\" makes a brief appearance in \"The Simpsons\" episode \"Homer's Phobia\", from the show's eighth season. Guest star and filmmaker John Waters is seen, near the five-minute mark, flipping through Homer and Marge's record collection; Sadler's hit is amongst them.\n\nBill Murray briefly sang \"Green Berets\" in the 1980 film \"Caddyshack\" during his final attempt to kill the gopher.\n\nMany American cover versions of the song appeared recorded by artists ranging from Kate Smith and Duane Eddy to unknown artists singing on various drugstore records.\n\nThe punk rock band The F.U.'s performed a cover of the song, featured on the album \"This Is Boston, Not L.A.\"\n\nMany cover versions are in different languages rewritten to reference local units; these include:\n\n\n\n"}
{"id": "4763", "url": "https://en.wikipedia.org/wiki?curid=4763", "title": "Baroque dance", "text": "Baroque dance\n\nBaroque dance is dance of the Baroque era (roughly 1600-1750), closely linked with Baroque music, theatre and opera.\n\nThe majority of surviving choreographies from the period are English country dances, such as those in the many editions of Playford's \"The Dancing Master\". Playford only gives the floor patterns of the dances, with no indication of the steps. However other sources of the period, such as the writings of the French dancing-masters Feuillet and Lorin, indicate that steps more complicated than simple walking were used at least some of the time.\n\nEnglish country dance survived well beyond the Baroque era and eventually spread in various forms across Europe and its colonies, and to all levels of society. See the article on English country dance for more information.\n\nThe great innovations in dance in the 17th century originated at the French court under Louis XIV, and it is here that we see the first clear stylistic ancestor of classical ballet. The same basic technique was used both at social events, and as theatrical dance in court ballets and at public theaters. The style of dance is commonly known to modern scholars as the \"French noble style\" or \"belle danse\" (French, literally \"beautiful dance\"), however it is often referred to casually as \"baroque dance\" in spite of the existence of other theatrical and social dance styles during the baroque era.\n\nPrimary sources include more than three hundred choreographies in Beauchamp-Feuillet notation, as well as manuals by Raoul Handsome Auger Feuillet and Pierre Rameau in France, Kellom Tomlinson and John Weaver in England, and Gottfried Taubert in Germany. This wealth of evidence has allowed modern scholars and dancers to recreate the style, although areas of controversy still exist. The standard modern introduction is Hilton.\n\nFrench dance types include:\n\nThe English, working in the French style, added their own hornpipe to this list.\n\nMany of these dance types are familiar from baroque music, perhaps most spectacularly in the stylized suites of J. S. Bach. Note however, that the allemandes, that occur in these suites do not correspond to a French dance from the same period.\n\nThe French noble style was danced both at social events and by professional dancers in theatrical productions such as opera-ballets and court entertainments. However, 18th century theatrical dance had at least two other styles: comic or grotesque, and semi-serious.\n\nOther dance styles, such as the Italian and Spanish dances of the period are much less well studied than either English country dance or the French style. The general picture seems to be that during most of the 17th century, a style of late Renaissance dance was widespread, but as time progressed, French ballroom dances such as the minuet were widely adopted at fashionable courts. Beyond this, the evolution and cross-fertilisation of dance styles is an area of ongoing research.\n\nThe revival of baroque music in the 1960s and '70s sparked renewed interest in 17th and 18th century dance styles. While some 300 of these dances had been preserved in Beauchamp-Feuillet notation, it wasn't until the mid-20th century that serious scholarship commenced in deciphering the notation and reconstructing the dances.\n\nPerhaps best known among these pioneers was Britain's Melusine Wood, who published several books on historical dancing in the 1950s. Miss Wood passed her research on to her student Belinda Quirey, and also to Pavlova Company ballerina & choreographer Mary Skeaping (1902–1984). The latter became well known for her reconstructions of baroque ballets for London's \"Ballet for All\" company in the 1960s.\n\nThe leading figures of the second generation of historical dance research include Shirley Wynne and her Baroque Dance Ensemble which was founded at Ohio State University in the early 1970s and Wendy Hilton (1931–2002), a student of Belinda Quirey who supplemented the work of Melusine Wood with her own research into original sources.\nA native of Britain, Hilton arrived in the U.S. in 1969 joining the faculty of the Juilliard School in 1972 and establishing her own baroque dance workshop at Stanford University in 1974 which endured for more than 25 years.\n\nCatherine Turocy (b. circa 1950) began her studies in Baroque dance in 1971 as a student of dance historian Shirley Wynne. She founded The New York Baroque Dance Company (http://www.nybaroquedance.org/) in 1976 with Ann Jacoby, and the company has since toured internationally. In 1982/83 as part of the French national celebration of Jean Philippe Rameau's 300th birthday, Turocy choreographed the first production of Jean-Philippe Rameau's \"Les Boréades\" - it was never performed during the composer's lifetime. This French supported production with John Eliot Gardiner, conductor, and his Orchestra was directed by Jean Louis Martinoty. Ms. Turocy has been decorated as Chevalier in the Ordre des Arts et des Lettres by the French government.\n\nIn 1973, French dance historian Francine Lancelot (1929–2003) began her formal studies in ethnomusicology which later lead her to researching French traditional dance forms and eventually Renaissance and Baroque dances. In 1980, at the invitation of the French Minister of Culture, she founded the baroque dance company \"Ris et Danceries\". Her work in choreographing the landmark 1986 production of Lully's 1676 tragedie-lyrique \"Atys\" was part of the national celebration of the 300th anniversary of Lully's death. This production propelled the career of William Christie and his ensemble Les Arts Florissants. Since the Ris et Danseries company was disbanded circa 1993, choreographers from the company have continued with their own work. Béatrice Massin with her \"Compagnie Fetes Galantes\", along with Marie Genevieve Massé and her company \"L'Eventail\" are among the most prominent. In 1995 Francine Lancelot's catalogue raisonné of baroque dance, entitled \"La Belle Dance\" was published.\n\n"}
{"id": "4764", "url": "https://en.wikipedia.org/wiki?curid=4764", "title": "Borzoi", "text": "Borzoi\n\nThe Borzoi (, literally \"fast\"), also called the Russian wolfhound (), is a breed of domestic dog (\"Canis lupus familiaris\"). Descended from dogs brought to Russia from central Asian countries, it is similar in shape to a greyhound, and is also a member of the sighthound family.\n\nThe system by which Russians over the ages named their sighthounds was a series of descriptive terms, not actual names. \"Borzói\" is the masculine singular form of an archaic Russian adjective that means \"fast\". \"Borzáya sobáka\" (\"fast dog\") is the basic term used by Russians, though \"sobáka\" is usually dropped. The name \"Psovaya\" derived from the word Psovina, which means \"wavy, silky coat\", just as \"Hortaya\" (as in Hortaya Borzaya) means shorthaired. In Russia today the breed we know as the borzoi is officially known as \"Russkaya Psovaya Borzaya\". Other Russian sighthound breeds are \"Stepnaya Borzaya\" (from the steppe), called \"Stepnoi\"; and \"Krimskaya Borzaya\" (from the Crimea), called \"Krimskoi\".\n\nThe most commonly used plural form is the regular formation \"borzois\", which is the only plural cited in most dictionaries. However, the Borzoi Club of America and the Borzoi Club UK both prefer \"borzoi\" as the form for both singular and plural forms.\n\nBorzois are large Russian sighthounds that resemble some central Asian breeds such as the Afghan hound, Saluki, and the Kyrgyz Taigan. Borzois can generally be described as \"long-haired greyhounds\". Borzois come in virtually any colour. The borzoi coat is silky and flat, often wavy or slightly curly. The long top-coat is quite flat, with varying degrees of waviness or curling. The soft undercoat thickens during winter or in cold climates, but is shed in hot weather to prevent overheating. In its texture and distribution over the body, the borzoi coat is unique. There should be a frill on its neck, as well as feathering on its hindquarters and tail.\n\nBorzoi males frequently weigh more than . Males stand at least at the shoulder, while the height of females is around . Despite their size, the overall impression is of streamlining and grace, with a curvy shapeliness and compact strength.\n\nThe borzoi is a quiet, but athletic and independent dog. Most borzois are almost silent, barking only very rarely. They do not have strong territorial drives and cannot be relied on to raise the alarm upon sighting a human intruder. The borzoi is extremely smart and requires patient, experienced handling. They are gentle and highly sensitive dogs with a natural respect for humans, and as adults they are decorative couch potatoes with remarkably gracious house manners. Borzois do not generally display dominance or aggression towards people, but will turn aggressive if handled roughly. Typically however, they are rather reserved with strangers but affectionate with people they know well. Their sensitivity to invasion of their personal space can make them nervous around children unless they are brought up with them. Despite their size, borzois adapt very well to suburban life, provided they have a spacious yard and regular opportunities for free exercise.\n\nA common misunderstanding about the intelligence of breeds in the Hound group stems from their independent nature, which conflicts with the frequent confusion between the concepts of \"intelligence\" and \"obedience\" in discussions of canine brainpower. Stanley Coren's survey of canine obedience trainers published in \"The Intelligence of Dogs\" reported that borzois obeyed the first command less than 25% of the time. Coren's test, however, was by his own admission heavily weighted towards the \"obedience\" interpretation of intelligence and based on a better understanding of \"working\" breeds than hounds. Unfortunately, the publicity given to this report has led to unfair denigration of breeds which are under-represented in obedience clubs and poorly understood by the average obedience trainer. \"Work\" for hound breeds is done out of hearing and often out of sight of the human companion; it is an activity for which the dogs are \"released\", rather than an activity which is \"commanded\".\n\nIn terms of obedience, borzois are selective learners who quickly become bored with repetitive, apparently pointless, activity, and they can be very stubborn when they are not properly motivated. For example, food rewards, or \"baiting\", may work well for some individuals, but not at all for others. Nevertheless, borzois are definitely capable of enjoying and performing well in competitive obedience and agility trials with the right kind of training. Like other sighthounds, they are very sensitive and do not cope well with harsh treatment or training based on punishment, and will be extremely unhappy if raised voices and threats are a part of their daily life. However, like any intelligent dog, borzois respond extremely well to the guidance, support, and clear communication of a benevolent human leadership.\n\nBorzois were bred to pursue or \"course\" game and have a powerful instinct to chase things that run from them, including cats and small dogs. Built for speed and endurance, they can cover long distances in a very short time. A fully fenced yard is a necessity for maintaining any sighthound. They are highly independent and will range far and wide without containment, with little regard for road traffic. For off-leash exercise, a borzoi needs a very large field or park, either fully fenced or well away from any roads, to ensure its safety. \n\nBorzois are born with specialized coursing skills, but these are quite different from the dog-fighting instincts seen in some breeds. It is quite common for borzois at play to course (i.e., run down) another dog, seize it by the neck and hold it immobile. Young pups do this with their littermates, trading off as to who is the prey. It is a specific hunting behavior, not a fighting or territorial domination behavior.\n\nBorzois can be raised very successfully to live with cats and other small animals provided they are introduced to them when they are puppies. Some, however, will possess the hunting instinct to such a degree that they find it impossible not to chase a cat that is moving quickly. The hunting instinct is triggered by movement and much depends on how the cat behaves.\n\nStated life expectancy is 10 to 12 years. Median lifespan based on a UK Kennel Club survey is 9 years 1 month. 1 in 5 died of old age, at an average of 10 to 11.5 years. The longest lived dog lived to 14 years 3 months. Dogs that are physically fit and vigorous in their youth through middle age are more vigorous and healthy as elderly dogs, all other factors being equal. In the UK, cancer and cardiac problems seem to be the most frequent causes of premature death.\n\nLike its native relative the Hortaya Borzaya, the borzoi is basically a very sound breed. OCD, hip and elbow dysplasia have remained almost unknown, as were congenital eye and heart diseases before the 1970s. However, in some countries modern breeding practices have introduced a few problems.\n\nAs with other very deep-chested breeds, gastric dilatation volvulus (also known as bloat) is the most common serious health problem in the borzoi. This life-threatening condition is believed to be anatomical rather than strictly genetic in origin. One common recommendation in the past has been to raise the food bowl of the dog when it eats. However, studies have shown that this may actually increase the risk of bloat.\n\nLess common are cardiac problems including cardiomyopathy and cardiac arrhythmia disorders. A controversy exists as to the presence of progressive retinal atrophy in the breed. A condition identified as borzoi retinopathy is seen in some individuals, usually active dogs, which differs from progressive retinal atrophy in several ways. First, it is unilateral, and rarely seen in animals less than three years of age; second, a clear-cut pattern of inheritance has not been demonstrated; and finally, most affected individuals do not go blind.\nCorrect nutrition during puppyhood is also debatable for borzois. These dogs naturally experience enormous growth surges in the first year or two of their lives. It is now widely accepted that forcing even faster growth by feeding a highly concentrated, high-energy diet is dangerous for skeletal development, causing unsoundness and increased tendency to joint problems and injury. Being built primarily for speed, borzois do not carry large amounts of body fat or muscle, and therefore have a rather different physiology to other dogs of similar size (such as the Newfoundland, St. Bernard, or Alaskan Malamute). Laboratory-formulated diets designed for a generic \"large\" or \"giant\" breed are unlikely to take the needs of the big sighthounds into account.\n\nThe issues involved in raw feeding may be particularly relevant to tall, streamlined breeds such as the borzoi. It is interesting to note that the Hortaya Borzaya, undoubtedly a very close relative, is traditionally raised on a meager diet of oats and table scraps. The Hortaya is also said to be intolerant of highly concentrated kibble feeds. Basically, a lean body weight in itself is nothing to be concerned about, and force-feeding of healthy young borzoi is definitely not recommended.\n\nIt was long thought that Saluki type sighthounds were originally brought to Russia from Byzantium in the South about the 9th and 10th centuries and again later by the Mongol invaders from the East. However, now that the archeological archives and research results of the former USSR are open to scientists, it has become quite clear that the primal sighthound type evolved between the Kyrgyzstan, the lower Kazakhstan part of Altai and the Afghan plains, and that the earliest actual sighthound breeds were the plains Afghan hounds and the Kyrgyz Taigan.\n\nThese ancient breeds then migrated South (founding the Tazi/Saluki branch) and West (founding the Stepnaya, Krimskaya and Hortaya branches) to develop into breeds adapted to those regions. This was a slow process which happened naturally through normal spreading of trade, with the silk and spice trade via the Silk Road being the prime vector.\n\nThe more modern Psovaya Borzaya was founded on Stepnaya, Hortaya and the Ukrainian-Polish version of the old Hort. There were also imports of Western sighthound breeds to add to the height and weight. It was crossed as well with the Russian Laika specifically and singularly to add resistance against Northern cold and a longer and thicker coat than the Southern sighthounds were equipped with.\n\nAll of these foundation types—Tazi, Hortaya, Stepnaya, Krimskaya, and Hort—already possessed the instincts and agility necessary for hunting and bringing down wolves.\n\nThe Psovoi was popular with the Tsars before the 1917 revolution. For centuries, Psovoi could not be purchased but only given as gifts from the Tsar. Grand Duke Nicholas Nicolaievich of Russia bred countless Psovoi at Perchino, his private estate.\n\nThe Russian concept of hunting trials was instituted during the era of the Tsars. As well as providing exciting sport, the tests were used for selecting borzoi breeding stock; only the quickest and most intelligent hunting dogs went on to produce progeny. For the aristocracy these trials were a well-organized ceremony, sometimes going on for days, with the borzois accompanied by mounted hunters and Foxhounds on the Russian steppe. Hares and other small game were by far the most numerous kills, but the hunters especially loved to test their dogs on wolf. If a wolf was sighted, the hunter would release a team of two or three borzois. The dogs would pursue the wolf, attack its neck from both sides, and hold it until the hunter arrived. The classic kill was by the human hunter with a knife. Wolf trials are still a regular part of the hunting diploma for all Russian sightdog breeds of the relevant type, either singly or in pairs or trios, in their native country.\n\nAfter the 1917 Revolution, wolf hunting with sighthounds has soon gone out of fashion as an \"aristocratic\" and a means- and -time-taking way of hunting.\nA necessity in a wolf-catching sighthound didn't exist, in addition to the old proved technique of batue with the use of baits, flags and other appeared new, way more effective—from airplanes, from propeller sleighs, with electronic lure whistles. For decades the generations of few remaining sighthounds were regarded as hunting-suited, when showing enough attacking initiative for fox hunting. The rumours about prosecution of sighthounds in post-revolutionary Russia is a legend of modern time, possibly based on similar incidents in Maoist China.\n\nIn the late 1940s, a Soviet soldier named Constantin Esmont made detailed records of the various types of borzoi he found in Cossack villages. Esmont's illustrations were recently published and can be viewed by clicking on the link below.\n\nEsmont was concerned that the distinct types of borzaya were in danger of degenerating without a controlled system of breeding. He convinced the Soviet government that borzois were a valuable asset to the hunters who supported the fur industry and henceforth, their breeding was officially regulated. To this day short-haired Hortaya Borzaya are highly valued hunting dogs on the steppes, while the long-haired Psovaya Borzaya, is going through a hard period of restoration of its working qualities after decades of shadow, mainly show existence.\n\nExports of borzois to other countries were extremely rare during the Soviet era. However, enough had been taken to England, Scandinavia, Western Europe, and America in the late 19th century for the breed to establish itself outside its native country.\n\n\n\nIn 2004, the UK Kennel Club held its fourth temporary exhibition, \"The Borzoi in Art,\" which offered unique insights into the borzoi and how the breed has been depicted in art throughout the 19th and 20th centuries. The exhibition included paintings, bronzes, and porcelain which had previously not been available to the public. The exhibition ran from 27 September to 3 December. The borzoi is frequently found in art deco-period works.\n\n"}
{"id": "4765", "url": "https://en.wikipedia.org/wiki?curid=4765", "title": "Basenji", "text": "Basenji\n\nThe Basenji is a breed of hunting dog. It was bred from stock that originated in central Africa. Most of the major kennel clubs in the English-speaking world place the breed in the Hound Group—more specifically, in the sighthound type. The Fédération Cynologique Internationale places the breed in group five, spitz and primitive types, and the United Kennel Club (US) places the breed in the Sighthound & Pariah Group.\n\nThe Basenji produces an unusual yodel-like sound commonly called a \"baroo\", due to its unusually shaped larynx. This trait also gives the Basenji the nickname \"soundless dog\"\n\nBasenjis share many unique traits with pariah dog types. Basenjis, like dingoes, New Guinea singing dogs and some other breeds of dog, come into estrus only once annually—as compared to other dog breeds, which may have two or more breeding seasons every year. Both dingoes and Basenji lack a distinctive odor, and are prone to howls, yodels, and other vocalizations over the characteristic bark of modern dog breeds. One theory holds that the latter trait is the result of selecting against dogs that frequently bark—in the traditional Central African context—because barking could lead enemies to humans' forest encampments. While dogs that resemble the Basenji in some respects are commonplace over much of Africa, the breed's original foundation stock came from the old growth forest regions of the Congo Basin, where its structure and type were fixed by adaptation to its habitat, as well as use (primarily net hunting in extremely dense old-growth forest vegetation).\n\nThe name comes from the Lingala language of the Congo, \"mbwá na basɛ́nzi\" which means \"village dogs\".\n\nThe Basenji is an ancient breed. It has been identified as a basal breed that predates the emergence of the modern breeds in the 19th century. Recent DNA studies based on whole-genome sequences indicate that the domestic dog is a genetically divergent subspecies of the gray wolf and was derived from a now-extinct ghost population of Late Pleistocene wolves, and the basenji and the dingo are both considered to be basal members of the domestic dog clade. \"The term basal refers to a lineage that diverges early in the history of the group...and lies on a branch that originates near the common ancestor of the group.\"\n\nThe Azande and Mangbetu people from the northeastern Congo region describe Basenjis, in the local Lingala language, as \"mbwá na basɛ́nzi\". Translated, this means \"dogs of the savages\", or \"dogs of the villagers\". In the Congo, the Basenji is also known as \"dog of the bush.\" The dogs are also known to the Azande of southern Sudan as \"Ango Angari.\" The word \"basɛ́nzi\" itself is the plural form of \"mosɛ́nzi\". In Swahili, another Bantu language, from East Africa, \"mbwa shenzi\" translates to “wild dog”. Another local name is \"m’bwa m’kube m’bwa wamwitu\", or “jumping up and down dog” a reference to their tendency to jump straight up to spot their quarry.\n\nOriginating on the continent of Africa, basenji-like dogs have lived with humans for thousands of years. Dogs resembling modern Basenjis, the Tesem, can be seen on stelae in the tombs of Egyptian pharaohs, sitting at the feet of their masters, looking just as they do today, with pricked ears and tightly curled tails. Dogs of this type were originally kept for hunting small game by tracking and driving the game into nets.\n\nEuropeans first described the type of dog the Basenji breed derives from in 1895—in the Congo. These local dogs, which Europeans identified as a unique breed and called \"basenji,\" were prized by locals for their intelligence, courage, speed, and silence. An article published called The Intelligence of Dogs by Stanley Coren, Ph.D. questions this. It ranks the breed at #78 out of 79, which is the second to lowest rank in intelligence. Some consider this an unreliable list, as it focuses on only the ability to listen to a first command. Some consider independent dogs such as Basenjis and Afghan Hounds more intelligent than obedient breeds because of their ability to recognize which actions benefit them, and which simply please another.\n\nSeveral attempts were made to bring the breed to England, but the earliest imports succumbed to disease. In 1923, for example, Lady Helen Nutting brought six Basenjis with her from Sudan, but all six died from distemper shots they received in quarantine. It was not until the 1930s that foundation stock was successfully established in England, and then to the United States by animal importer Henry Trefflich. It is likely that nearly all the Basenjis in the Western world are descended from these few original imports. The breed was officially accepted into the AKC in 1943. In 1990, the AKC stud book was reopened to 14 new imports at the request of the Basenji Club of America. The stud book was reopened again to selected imported dogs from 1 January 2009 to 31 December 2013. An American-led expedition collected breeding stock in villages in the Basankusu area of the Democratic Republic of Congo, in 2010. Basenjis are also registered with the UKC.\n\nThe popularity of the Basenji in the United States, according to the American Kennel Club, has declined over the past decade, with the breed ranked 71st in 1999, decreasing to 84th in 2006, and to 93rd in 2011.\n\nBasenjis are small, short-haired dogs with erect ears, tightly curled tails and graceful necks. A Basenji's forehead is wrinkled, even more so when they are young or extremely excited. A Basenji's eyes are typically almond-shaped. Basenjis typically weigh about and stand at the shoulder. They are a square breed, which means they are as long as they are tall with males usually larger than females. Basenjis are athletic dogs, and deceptively powerful for their size. They have a graceful, confident gait like a trotting horse, and skim the ground in a double suspension gallop, with their characteristic curled tail straightened out for greater balance when running at their top speed. Basenjis come in a few different colorations: red, black, tricolor, and brindle, and they all have white feet, chests and tail tips. They can also come in \"trindle\", which is a tricolor with brindle points, a rare combination.\n\nThe Basenji is alert, energetic, curious and reserved with strangers. The Basenji tends to become emotionally attached to a single human. Basenjis may not get along with non-canine pets. Basenjis dislike wet weather, like to climb, and can easily get over chain wire fences.\n\nBasenjis often stand on their hind legs, somewhat like a meerkat, by themselves or leaning on something; this behavior is often observed when the dog is curious about something. Basenjis have a strong prey drive. According to the book \"The Intelligence of Dogs\", they are the second least trainable dog.\n\nThere is apparently only one completed health survey of Basenjis, a 2004 UK Kennel Club survey.\n\nBasenjis are prone to blindness from progressive retinal atrophy (PRA) and Fanconi syndrome. They can also suffer from hypothyroidism, immunoproliferative systemic intestinal disease (IPSID), and hemolytic anemia (HA). Basenjis are also sensitive to environmental and household chemicals, which may cause liver problems.\n\nBasenjis in the 2004 UK Kennel Club survey had a median lifespan of 13.6 years (sample size of 46 deceased dogs), which is 1–2 years longer than the median lifespan of other breeds of similar size. The oldest dog in the survey was 17.5 years. Most common causes of death were old age (30%), urologic (incontinence, Fanconi syndrome, chronic kidney failure 13%), behavior (\"unspecified\" and aggression 9%), and cancer. (9%).\n\nAmong 78 live dogs in the 2004 UKC survey, the most common health issues noted by owners were dermatologic and urologic (urologic issues in Basenjis can be signs of Fanconi syndrome).\n\nFanconi syndrome, an inheritable disorder in which the renal (kidney) tubes fail to reabsorb electrolytes and nutrients, is unusually common in Basenjis. Symptoms include excessive drinking, excessive urination, and glucose in the urine, which may lead to a misdiagnosis of diabetes. Fanconi syndrome usually presents between 4 and 8 years of age, but sometimes as early as 3 years or as late as 10 years. Fanconi syndrome is treatable and organ damage is reduced if treatment begins early. Basenji owners are advised to test their dog's urine for glucose once a month beginning at the age of 3 years. Glucose testing strips designed for human diabetics are inexpensive and available at most pharmacies. Steve Gonto, M.M.Sc., Ph.D., has a 'Fanconi Disease Management Protocol for Veterinarians' that is commonly used by many veterinarians with Fanconi syndrome afflicted dogs. The current DNA test for Fanconi syndrome may be ordered from offa.org.\n\nIn July 2007, Dr. Gary Johnson of the University of Missouri released the linked marker DNA test for Fanconi syndrome in Basenjis. It is the first predictive test available for Fanconi syndrome. With this test, it is possible to more accurately determine the probability of a dog's carrying the gene for Fanconi syndrome.\n\nDogs tested using this \"linkage test\" return one of the following statuses:\n\nThis linkage test is being provided as a tool to assist breeders whilst research continues towards the development of the direct Fanconi test.\n\nThe direct Fanconi DNA test has now been developed and may be ordered from the Orthopedic Foundation for Animals at http://www.offa.org/dnatesting/fanconi.html .\n\nFor more information about the linkage test, visit: Basenji Health Endowment Fanconi Test FAQ.\n\nBasenjis sometimes carry a simple recessive gene that, when homozygous for the defect, causes genetic hemolytic anemia. Most 21st-century Basenjis are descended from ancestors that have tested clean. When lineage from a fully tested line (set of ancestors) cannot be completely verified, the dog should be tested before breeding. As this is a non-invasive DNA test, a Basenji can be tested for HA at any time.\n\nBasenjis sometimes suffer from hip dysplasia, resulting in loss of mobility and arthritis-like symptoms. All dogs should be tested by either OFA or PennHIP prior to breeding.\n\nMalabsorption, or immunoproliferative enteropathy, is an autoimmune intestinal disease that leads to anorexia, chronic diarrhea, and even death. A special diet can improve the quality of life for afflicted dogs.\n\nThe breed can also fall victim to progressive retinal atrophy (a degeneration of the retina causing blindness) and several less serious hereditary eye problems such as coloboma (a hole in the eye structure), and persistent pupillary membrane (tiny threads across the pupil).\n\n\n"}
{"id": "4768", "url": "https://en.wikipedia.org/wiki?curid=4768", "title": "Brit milah", "text": "Brit milah\n\nThe brit milah (, ; Ashkenazi pronunciation: , \"covenant of circumcision\"; Yiddish pronunciation: \"bris\" ) is a Jewish religious male circumcision ceremony performed by a mohel (\"circumciser\") on the eighth day of a male infant's life. The \"brit milah\" is followed by a celebratory meal (\"seudat mitzvah\").\n\nAccording to the Hebrew Bible () God commanded the Biblical patriarch Abraham to be circumcised, an act to be followed by his descendants:\nAlso, provides: \"And in the eighth day the flesh of his foreskin shall be circumcised.\"\n\nAccording to the Hebrew Bible, it was \"a reproach\" for an Israelite to be uncircumcised (Joshua 5:9.) The term \"arelim\" (\"uncircumcised\" [plural]) is used opprobriously, denoting the Philistines and other non-Israelites (I Samuel 14:6, 31:4; II Samuel 1:20) and used in conjunction with \"tameh\" (unpure) for heathen (Isaiah 52:1). The word \"arel\" (\"uncircumcised\" [singular]) is also employed for \"impermeable\" (Leviticus 26:41, \"their uncircumcised hearts\"; compare Jeremiah 9:25; Ezekiel 44:7,9); it is also applied to the first three years' fruit of a tree, which is forbidden (Leviticus 19:23).\n\nHowever, the Israelites born in the wilderness after the Exodus from Egypt were not circumcised. Joshua 5:2-9, explains, \"all the people that came out\" of Egypt were circumcised, but those \"born in the wilderness\" were not. Therefore, Joshua, before the celebration of the Passover, had them circumcised at Gilgal specifically before they entered Canaan. Abraham, too, was circumcised when he moved into Canaan.\n\nThe prophetic tradition emphasizes that God expects people to be good as well as pious, and that non-Jews will be judged based on their ethical behavior, see Noahide Law. Thus, Jeremiah 9:25-26 says that circumcised and uncircumcised will be punished alike by the Lord; for \"all the nations are uncircumcised, and all the house of Israel are uncircumcised in heart.\"\n\nThe penalty of non-observance is \"kareth\" (spiritual excision from the Jewish nation), as noted in . Conversion to Judaism for non-Israelites in Biblical times necessitated circumcision, otherwise one could not partake in the Passover offering (). Today, as in the time of Abraham, it is required of converts in Orthodox, Conservative and Reform Judaism. ().\n\nAs found in Genesis 17:1-14, \"brit milah\" is considered to be so important that should the eighth day fall on the Sabbath, actions that would normally be forbidden because of the sanctity of the day are permitted in order to fulfill the requirement to circumcise. The Talmud, when discussing the importance of Milah, compares it to being equal to all other mitzvot (commandments) based on the gematria for \"brit\" of 612 (Tractate Nedarim 32a).\n\nCovenants in ancient times were sometimes sealed by severing an animal, with the implication that the party who breaks the covenant will suffer a similar fate. In Hebrew, the verb meaning \"to seal a covenant\" translates literally as \"to cut\". It is presumed by Jewish scholars that the removal of the foreskin symbolically represents such a sealing of the covenant.\n\nMemory of this tradition has been preserved in traditional Christian churches according to the Gospel of Luke. The Feast of the Circumcision of Christ is kept as a feast eight days after Nativity in a number of churches including the Eastern Orthodox Church, Catholic Church, Lutheran and some Anglican Communion churches. In Orthodox Christian tradition, children are officially named on the eighth day after birth with special naming prayers.\n\nSignificantly, the tradition of baptism universally replaced circumcision amongst Christians as the primary rite of passage as found in Paul's Epistle to the Colossians and in Acts of the Apostles.\n\nA mohel is a Jew trained in the practice of \"brit milah\", the \"covenant of circumcision.\" According to traditional Jewish law, in the absence of a grown free Jewish male expert, a woman, a slave, or a child, who has the required skills, is also authorized to perform the circumcision, provided that she or he is Jewish. However, most streams of non-Orthodox Judaism allow female mohels, called \"mohalot\" (, plural of \"mohelet\", feminine of \"mohel\"), without restriction. In 1984, Dr. Deborah Cohen became the first certified Reform mohelet; she was certified by the Berit Mila program of Reform Judaism.\n\nIt is customary for the brit to be held in a synagogue, but it can also be held at home or any other suitable location. The brit is performed on the eighth day from the baby's birth, taking into consideration that according to the Jewish calendar, the day begins at the sunset of the day before. If the baby is born on Sunday before sunset, the Brit will be held the following Sunday. However, if the baby is born on Sunday night after sunset, the Brit is on the following Monday. The brit takes place on the eighth day following birth even if that day is Shabbat or a holiday. A brit is traditionally performed in the morning, but it may be performed any time during daylight hours.\n\nThe Talmud explicitly instructs that a boy must not be circumcised if he had two brothers who died due to complications arising from their circumcisions, and Maimonides says that this excluded paternal half-brothers; this may be due to a concern about haemophilia.\n\nAn Israeli study found a high rate of urinary tract infections if the bandage is left on too long.\n\nIf the child is born prematurely or has other serious medical problems, the brit milah will be postponed until the doctors and mohel deem the child strong enough.\n\nIn recent years, the circumcision of adult Jews who were not circumcised as infants has become more common than previously thought. In such cases, the brit milah will be done at the earliest date that can be arranged. The actual circumcision will be private, and other elements of the ceremony (e.g., the celebratory meal) may be modified to accommodate the desires of the one being circumcised.\n\nMost prominent \"acharonim\" rule that the \"mitzvah\" of brit milah lies in the pain it causes, and anesthetic, sedation, or ointment should generally not be used. However, it is traditionally common to feed the infant a drop of wine or other sweet liquid to soothe him.\n\nEliezer Waldenberg, Yechiel Yaakov Weinberg, Shmuel Wosner, Moshe Feinstein and others agree that the child should not be sedated, although pain relieving ointment may be used under certain conditions; Shmuel Wosner particularly asserts that the act ought to be painful, per Psalms 44:23.\n\nRegarding an adult circumcision, pain is ideal, but not mandatory. In a letter-to-the-editor published in The New York Times on January 3, 1998, Rabbi Moshe David Tendler disagrees with the above and writes, \"It is a biblical prohibition to cause anyone unnecessary pain\". Rabbi Tendler recommends the use of an analgesic cream. Lidocaine should not be used, however, because Lidocaine has been linked to several pediatric near-death episodes.\n\nThe title of \"kvater\" (male) or \"kvaterin\" (female) among Ashkenazi Jews is for the person who carries the baby from the mother to the father, who in turn carries him to the \"mohel.\" This honor is usually given to a couple without children, as a merit or \"segula\" (efficacious remedy) that they should have children of their own. The origin of the term is Middle High German \"gevater(e)\" (\"godfather\").\n\nAfter the ceremony, a celebratory meal takes place. At the \"birkat hamazon\", additional introductory lines, known as \"Nodeh Leshimcha\", are added. These lines praise God and request the permission of God, the Torah, Kohanim and distinguished people present to proceed with the grace. When the four main blessings are concluded, special \"ha-Rachaman\" prayers are recited. They request various blessings by God that include:\n\nAt the neonatal stage, the inner preputial epithelium is still linked with the surface of the glans.\nThe \"mitzvah\" is executed only when this epithelium is either removed, or permanently peeled back to uncover the glans.\nOn medical circumcisions performed by surgeons, the epithelium is removed along with the foreskin, to prevent post operative penile adhesion and its complications.\nHowever, on ritual circumcisions performed by a mohel, the epithelium is most commonly peeled off only after the foreskin has been amputated. This procedure is called \"priah\" (), which means: 'uncovering'. The main goal of \"priah\" (also known as \"bris periah\"), is to remove as much of the inner layer of the foreskin as possible and prevent the movement of the shaft skin, what creates the look and function of what is known as a \"low and tight\" circumcision.\n\nAccording to Rabbinic interpretation of traditional Jewish sources, the 'priah' has been performed as part of the Jewish circumcision since the Israelites first inhabited the Land of Israel.\nHowever, the \"Oxford Dictionary of the Jewish Religion\", states that many Hellenistic Jews attempted to restore their foreskins, and that similar action was taken during the Hadrianic persecution, a period in which a prohibition against circumcision was issued. Thus, the writers of the dictionary hypothesize that the more severe method practiced today was probably begun in order to prevent the possibility of restoring the foreskin after circumcision, and therefore the rabbis added the requirement of cutting the foreskin in periah. The frenulum may also be cut away at the same time, in a procedure called frenectomy.\nAccording to Shaye J. D. Cohen, in Why Aren't Jewish Women Circumcised?: Gender and Covenant in Judaism, pg 25, the Torah only commands circumcision (milah.) David Gollaher has written that the rabbis added the procedure of priah to discourage men from trying to restore their foreskins: ‘Once established, priah was deemed essential to circumcision; if the mohel failed to cut away enough tissue, the operation was deemed insufficient to comply with God's covenant’ and ‘Depending on the strictness of individual rabbis, boys (or men thought to have been inadequately cut) were subjected to additional operations.’\nThe guard (top center) is slid over the foreskin as close to the glans as possible to allow for maximum removal of the former without any injury to the latter. The scalpel is used to detach the foreskin, and the underlying blue bag is a sterilization pouch for the metal tools. The tube (center left) was used for \"metzitzah\"\nIn addition to ' (the actual circumcision) and ', mentioned above, the Talmud (Mishnah Shabbat 19:2) mentions a third step, \"\", translated as suction, as one of the steps involved in the circumcision rite. The Talmud writes that a \"Mohel (Circumciser) who does not suck, creates a danger and should be dismissed from practice\". Rashi on that Talmudic passage explains that this step is in order to draw some blood from deep inside the wound to prevent danger to the baby. \nThere are other modern antiseptic and antibiotic techniques—all used as part of the \"brit milah\" today—which many say accomplish the intended purpose of \"metzitzah\", however, since \"metzitzah\" is one of the four steps to fulfill Mitzvah, it continues to be practiced by many Orthodox and Hassidic Jews.\n\nThe ancient method of performing \"metzitzah\"—\"metzitzah b'peh\", or oral suction—has become controversial. The process has the \"mohel\" place his mouth directly on the circumcision wound to draw blood away from the cut. The majority of Jewish circumcision ceremonies do not use metzitzah b'peh, but some Haredi Jews use it. It has been documented that the practice poses a serious risk of spreading herpes to the infant. Proponents maintain that there is no conclusive evidence that links herpes to \"Metzitza\", and that attempts to limit this practice infringe on religious freedom.\n\nThe practice has become a controversy in both secular and Jewish medical ethics. The ritual of \"metzitzah\" is found in Mishnah Shabbat 19:2, which lists it as one of the four steps involved in the circumcision rite. Rabbi Moses Sofer (1762–1839) observed that the Talmud states that the rationale for this part of the ritual was hygienic — i.e., to protect the health of the child. The Chasam Sofer issued a leniency (Heter) that some consider to have been conditional to perform \"metzitzah\" with a sponge to be used instead of oral suction in a letter to his student, Rabbi Lazar Horowitz of Vienna. This letter was never published among Rabbi Sofer's responsa but rather in the secular journal \"Kochvei Yitzchok.\" along with letters from Dr. Wertheimer, the chief doctor of the Viennese General Hospital. It relates the story that a mohel (who was suspected of transmitting herpes via metzizah to infants) was checked several times and never found to have signs of the disease and that a ban was requested because of the \"possibility of future infections\". Moshe Schick (1807–1879), a student of Moses Sofer, states in his book of Responsa, \"She’eilos u’teshuvos Maharam Schick\" (Orach Chaim 152,) that Moses Sofer gave the ruling in that specific instance only because the mohel refused to step down and had secular Government connections that prevented his removal in favor of another mohel and the Heter may not be applied elsewhere. He also states (\"Yoreh Deah\" 244) that the practice is possibly a Sinaitic tradition, i.e., Halacha l'Moshe m'Sinai. Other sources contradict this claim, with copies of Moses Sofer's responsa making no mention of the legal case or of his ruling applying in only one situation. Rather, that responsa makes quite clear that \"metzizah\" was a health measure and should never be employed where there is a health risk to the infant.\n\nChaim Hezekiah Medini, after corresponding with the greatest Jewish sages of the generation, concluded the practice to be Halacha l'Moshe m'Sinai and elaborates on what prompted Moses Sofer to give the above ruling. He tells the story that a student of Moses Sofer, Lazar Horowitz, Chief Rabbi of Vienna at the time and author of the responsa \"Yad Elazer\", needed the ruling because of a governmental attempt to ban circumcision completely if it included \"metztitzah b'peh.\" He therefore asked Sofer to give him permission to do \"brit milah\" without \"metzitzah b’peh.\" When he presented the defense in secular court, his testimony was erroneously recorded to mean that Sofer stated it as a general ruling. The Rabbinical Council of America, (RCA) which claims to be the largest American organization of Orthodox rabbis, published an article by mohel Dr Yehudi Pesach Shields in its summer 1972 issue of Tradition magazine, calling for the abandonment of Metzitzah b'peh. Since then the RCA has issued an opinion that advocates methods that do not involve contact between the mohel's mouth and the open wound, such as the use of a sterile syringe, thereby eliminating the risk of infection. According to the Chief Rabbinate of Israel and the Edah HaChareidis \"metzitzah b'peh\" should still be performed.\n\nThe practice of \"metzitzah b'peh\" was alleged to pose a serious risk in the transfer of herpes from mohelim to eight Israeli infants, one of whom suffered brain damage. When three New York City infants contracted herpes after \"metzizah b'peh\" by one \"mohel\" and one of them died, New York authorities took out a restraining order against the \"mohel\" requiring use of a sterile glass tube, or pipette. The mohel's attorney argued that the New York Department of Health had not supplied conclusive medical evidence linking his client with the disease. In September 2005, the city withdrew the restraining order and turned the matter over to a rabbinical court. Dr. Thomas Frieden, the Health Commissioner of New York City, wrote, \"There exists no reasonable doubt that ‘metzitzah b'peh’ can and has caused neonatal herpes infection...The Health Department recommends that infants being circumcised not undergo metzitzah b'peh.\" In May 2006, the Department of Health for New York State issued a protocol for the performance of metzitzah b'peh. Dr. Antonia C. Novello, Commissioner of Health for New York State, together with a board of rabbis and doctors, worked, she said, to \"allow the practice of metzizah b'peh to continue while still meeting the Department of Health's responsibility to protect the public health.\" Later in New York City in 2012 a 2-week-old baby died of herpes because of metzitzah b'peh.\n\nIn three medical papers done in Israel, Canada, and the USA, oral suction following circumcision was suggested as a cause in 11 cases of neonatal herpes. Researchers noted that prior to 1997, neonatal herpes reports in Israel were rare, and that the late incidences were correlated with the mothers carrying the virus themselves. Rabbi Doctor Mordechai Halperin implicates the \"better hygiene and living conditions that prevail among the younger generation\", which lowered to 60% the rate of young Israeli Chareidi mothers who carry the virus. He explains that an \"absence of antibodies in the mothers’ blood means that their newborn sons received no such antibodies through the placenta, and therefore are vulnerable to infection by HSV-1.\"\n\nBecause of the risk of infection, some rabbinical authorities have ruled that the traditional practice of direct contact should be replaced by using a glass tube between the wound and the mohel's mouth, so there is no direct oral contact. The Rabbinical Council of America, the largest group of Modern Orthodox rabbis, endorses this method. The RCA paper states: \"\"Rabbi Schachter even reports that Rav Yosef Dov Soloveitchik reports that his father, Rav Moshe Soloveitchik, would not permit a mohel to perform metzitza be’peh with direct oral contact, and that his grandfather, Rav Chaim Soloveitchik, instructed mohelim in Brisk not to do metzitza be’peh with direct oral contact. However, although Rav Yosef Dov Soloveitchik also generally prohibited metzitza be’peh with direct oral contact, he did not ban it by those who insisted upon it...\". \" The sefer Mitzvas Hametzitzah by Rabbi Sinai Schiffer of Baden, Germany, states that he is in possession of letters from 36 major Russian (Lithuanian) rabbis that categorically prohibit Metzitzah with a sponge and require it to be done orally. Among them is Rabbi Chaim Halevi Soloveitchik of Brisk.\n\nIn September 2012, the New York Department of Health unanimously ruled that the practice of metztizah b'peh should require informed consent from the parent or guardian of the child undergoing the ritual. Prior to the ruling, several hundred rabbis, including Rabbi David Neiderman, the executive director of the United Jewish Organization of Williamsburg, signed a declaration stating that they would not inform parents of the potential dangers that came with metzitzah b'peh, even if informed consent became law.\n\nIn a Motion for preliminary injunction with intent to sue, filed against New York City Department of Health & Mental Hygiene, affidavits by Doctors Awi Federgruen Professor at the Columbia University Graduate School of Business. Brenda Breuer, Director of Epidemiologic Research at the Department of Pain Medicine and Palliative Care at the Beth Israel Medical Center, and an Associate Professor of Clinical Neurology at the Albert Einstein College of Medicine. Daniel S. Berman, Chief of Infectious-Disease at New York Westchester Square Hospital, argues that the study on which the department passed its conclusions is flawed.\n\nThe “informed consent” regulation was challenged in court. In January 2013 the U.S. District court ruled that the law did not specifically target religion and therefore must not pass strict scrutiny.\n\nThe ruling was appealed to the Court of Appeals. On August 15, 2014 the Second Circuit Court of Appeals reversed the decision by the lower court, and ruled that the regulation does have to be reviewed under strict scrutiny to determine whether it infringes on Orthodox Jews freedom of religion.\n\nOn September 9, 2015 after coming to an agreement with the community The New York City Board of Health voted to repeal the informed consent regulation.\n\nA brit milah is more than circumcision, it is a sacred ritual in Judaism, as distinguished from its non-ritual requirement in Islam. One ramification is that the brit is not considered complete unless a drop of blood is actually drawn. The standard medical methods of circumcision through constriction do not meet the requirements of the halakhah for brit milah, because they cause hemostasis, \"i.e.\", they stop the flow of blood. Morever, circumcision alone, in the absence of the brit milah ceremony, does not fulfill the requirements of the mitzvah. Therefore, in cases where a Jew who was circumcised outside of a brit milah, an already-circumcised convert, or an aposthetic (born without a foreskin) individual, the mohel draws a symbolic drop of blood (, ) from the penis at the point where the foreskin would have been or was attached.\n\nA \"Milah L'shem giur\" is a \"Circumcision for the purpose of conversion\". In Orthodox Judaism, this procedure is usually done by adoptive parents for adopted boys who are being converted as part of the adoption or by families with young children converting together. It is also required for adult converts who were not previously circumcised, e.g. those born in countries where circumcision at birth is not common. The conversion of a minor is valid in both Orthodox and Conservative Judaism until a child reaches the age of majority (13 for a boy, 12 for a girl); at that time the child has the option of renouncing his conversion and Judaism, and the conversion will then be considered retroactively invalid. He must be informed of his right to renounce his conversion if he wishes. If he does not make such a statement, it is accepted that the boy is halakhically Jewish. Orthodox rabbis will generally not convert a non-Jewish child raised by a mother who has not converted to Judaism.\n\nThe laws of conversion and conversion-related circumcision in Orthodox Judaism have numerous complications, and authorities recommend that a rabbi be consulted well in advance.\n\nIn Conservative Judaism, the Milah l'Shem giur procedure is also performed for a boy whose mother has not converted, but with the intention that the child be raised Jewish. This conversion of a child to Judaism without the conversion of the mother is allowed by Conservative interpretations of halakha. Conservative Rabbis will authorize it only under the condition that the child be raised as a Jew in a single-faith household. Should the mother convert, and if the boy has not yet reached his third birthday, the child may be immersed in the mikveh with the mother, after the mother has already immersed, to become Jewish. If the mother does not convert, the child may be immersed in a mikveh, or body of natural waters, to complete the child's conversion to Judaism. This can be done before the child is even one year old. If the child did not immerse in the mikveh, or the boy was too old, then the child may choose of their own accord to become Jewish at age 13 as a Bar Mitzvah, and complete the conversion then.\n\n\nWhere the procedure was performed but not followed by immersion or other requirements of the conversion procedure (e.g., in Conservative Judaism, where the mother has not converted), if the boy chooses to complete the conversion at Bar Mitzvah, a \"Milah l'shem giur\" performed when the boy was an infant removes the obligation to undergo either a full brit milah or \"hatafat dam brit\".\n\nNowadays it is generally assumed that Judaism adopted the practice of circumcision from neighboring cultures, their reasons for performing the act remain to be studied. \n\nIn \"Of the Special Laws, Book 1\", the Jewish philosopher Philo (20 BCE - CE 50) gives six reasons for the practice of circumcision. He attributes four of the reasons to \"men of divine spirit and wisdom\". These include the idea that circumcision:\nTo these, Philo added two of his own reasons, including the idea that circumcision \n\nRabbi Saadia Gaon considers something to be 'complete', if it lacks nothing, but also has nothing that is unneeded. He regards the foreskin an unneeded organ that God created in man, and so by amputating it, the man is completed.\n\nMaimonides (Moses ben Maimon \"Rambam\", CE 1135-1204), who apart from being a great Torah scholar was also a physician and philosopher, argued that circumcision serves as a common bodily sign to members of the same faith. He also asserted that the main purpose of the act is to repress sexual pleasure, with the strongest reason being that it is difficult for a woman to separate from an uncircumcised man with whom she has had sex.\n\nThe author of Sefer ha-Chinuch provides three reasons for the practice of circumcision:\n\nTalmud professor Daniel Boyarin offered two explanations for circumcision. One is that it is a literal inscription on the Jewish body of the name of God in the form of the letter \"yud\" (from \"yesod\"). The second is that the act of bleeding represents a feminization of Jewish men, significant in the sense that the covenant represents a marriage between Jews and (a symbolically male) God.\n\nThe reasons above are all reasons according to traditional Judaism for circumcision is that it represents a covanant between the Jews and God that started by Abraham \n\nThe Reform societies established in Frankfurt and Berlin regarded circumcision as barbaric and wished to abolish it. However, while prominent rabbis such as Abraham Geiger believed the ritual to be barbaric and outdated, they refrained from instituting any change in this matter. In 1843, when a father in Frankfurt refused to circumcise his son, rabbis of all shades in Germany stated it was mandated by Jewish law; even Samuel Holdheim affirmed this. By 1871, Reform rabbinic leadership in Germany reasserted \"the supreme importance of circumcision in Judaism\", while affirming the traditional viewpoint that non-circumcised are Jews nonetheless. Although the issue of circumcision of converts continues to be debated, the necessity of Brit Milah for Jewish infant boys has been stressed in every subsequent Reform rabbis manual or guide. Since 1984 Reform Judaism has trained and certified over 300 of their own practicing \"mohalim\" in this ritual.\n\nSome contemporary Jews choose not to circumcise their sons. Among the reasons for their choice are the claims that circumcision is an act of violence against a helpless infant, that it is painful and traumatic, and can cause further complications down the road, including serious disability and even death. They are assisted by a small number of Reform and Reconstructionist rabbis, and have developed a welcoming ceremony that they call the \"brit shalom\" (\"Covenant [of] Peace\") for such children, also accepted by Humanistic Judaism.\n\nThis ceremony of \"brit shalom\" is not officially approved of by the Reform or Reconstructionist rabbinical organizations, who make the recommendation that male infants should be circumcised, though the issue of converts remains controversial and circumcision of converts is not mandatory in either movement.\n\nThe connection of the Reform movement to an anti-circumcision, pro-symbolic stance is a historical one. From the early days of the movement in Germany, some classical Reformers hoped to replace ritual circumcision \"with a symbolic act, as has been done for other bloody practices, such as the sacrifices.\" In the US, an official Reform resolution in 1893 announced converts are no longer mandated to undergo the ritual, and this ambivalence towards the practice has carried over to classical-minded Reform Jews today. In Elyse Wechterman's essay \"A Plea for Inclusion\", she argues that, even in the absence of circumcision, committed Jews should never be turned away, especially by a movement \"where no other ritual observance is mandated\". She goes on to advocate an alternate covenant ceremony, \"brit atifah\", for both boys and girls as a welcoming ritual into Judaism. With a continuing negativity towards circumcision still present within a minority of modern-day Reform, Judaic scholar Jon Levenson has warned that if they \"continue to judge \"brit milah\" to be not only medically unnecessary but also brutalizing and mutilating...the abhorrence of it expressed by some early Reform leaders will return with a vengeance\", proclaiming that circumcision will be \"the latest front in the battle over the Jewish future in America.\"\n\nMany European Jewish fathers during the nineteenth century chose not to circumcise their sons, including Theodor Herzl. However, unlike many other forms of religious observance, it remained one of the last rituals Jewish communities could enforce. In most Europe, both the government and the unlearned Jewish masses believed circumcision to be a rite akin to baptism, and the law allowed communities not to register uncircumcised children as Jewish. This legal maneuver spurred several debates addressing the advisibility of its use, since many parents later chose to convert to Christianity. In early 20th-century Russia, Chaim Soloveitchik advised his colleagues to reject this measure, stating that uncircumcised Jewish males are no less Jewish than Jews who violate other commandments.\n\n\n"}
{"id": "4770", "url": "https://en.wikipedia.org/wiki?curid=4770", "title": "Business ethics", "text": "Business ethics\n\nBusiness ethics (also known as corporate ethics) is a form of applied ethics or professional ethics that examines ethical principles and moral or ethical problems that arise in a business environment. It applies to all aspects of business conduct and is relevant to the conduct of individuals and entire organizations. These ethics originate from individuals, organizational statements or from the legal system.\n\nBusiness ethics refers to contemporary organizational standards, principles, sets of values and norms that govern the actions and behavior of an individual in the business organization. Business ethics has normative and descriptive dimensions. As a corporate practice and a career specialization, the field is primarily normative. Academics attempting to understand business behavior employ descriptive methods. The range and quantity of business ethical issues reflects the interaction of profit-maximizing behavior with non-economic concerns.\n\nInterest in business ethics accelerated dramatically during the 1980s and 1990s, both within major corporations and within academia. For example, most major corporations today promote their commitment to non-economic values under headings such as ethics codes and social responsibility charters.\n\nAdam Smith said, \"People of the same trade seldom meet together, even for merriment and diversion, but the conversation ends in a conspiracy against the public, or in some contrivance to raise prices.\" Governments use laws and regulations to point business behavior in what they perceive to be beneficial directions. Ethics implicitly regulates areas and details of behavior that lie beyond governmental control. The emergence of large corporations with limited relationships and sensitivity to the communities in which they operate accelerated the development of formal ethics regimes.\nBusiness ethical norms reflect the norms of each historical period. As time passes, norms evolve, causing accepted behaviors to become objectionable. Business ethics and the resulting behavior evolved as well. Business was involved in slavery, colonialism, and the cold war.\n\nThe term 'business ethics' came into common use in the United States in the early 1970s. By the mid-1980s at least 500 courses in business ethics reached 40,000 students, using some twenty textbooks and at least ten casebooks supported by professional societies, centers and journals of business ethics. The Society for Business Ethics was founded in 1980. European business schools adopted business ethics after 1987 commencing with the European Business Ethics Network (EBEN). In 1982 the first single-authored books in the field appeared.\n\nFirms began highlighting their ethical stature in the late 1980s and early 1990s, possibly in an attempt to distance themselves from the business scandals of the day, such as the savings and loan crisis. The concept of business ethics caught the attention of academics, media and business firms by the end of the Cold War. However, criticism of business practices was attacked for infringing the freedom of entrepreneurs and critics were accused of supporting communists. This scuttled the discourse of business ethics both in media and academia. The Defense Industry Initiative on Business Ethics and Conduct(DII) was created to support corporate ethical conduct. This era began the belief and support of self-regulation and free trade, which lifted tariffs and barriers and allowed businesses to merge and divest in an increasing global atmosphere.\n\nBusiness ethics reflects the philosophy of business, of which one aim is to determine the fundamental purposes of a company. If a company's purpose is to maximize shareholder returns, then sacrificing profits to other concerns is a violation of its fiduciary responsibility. Corporate entities are legally considered as persons in USA and in most nations. The 'corporate persons' are legally entitled to the rights and liabilities due to citizens as persons.\n\nEthics are the rules or standards that govern our decisions on a daily basis. Many equate “ethics” with conscience or a simplistic sense of “right” and “wrong.” Others would say that ethics is an internal code that governs an individual’s conduct, ingrained into each person by family, faith, tradition, community, laws, and personal mores. Corporations and professional organizations, particularly licensing boards, generally will have a written “Code of Ethics” that governs standards of professional conduct expected of all in the field.\nIt is important to note that “law” and “ethics” are not synonymous, nor are the “legal” and “ethical” courses of action in a given situation necessarily the same. Statutes and regulations passed by legislative bodies and administrative boards set forth the “law.” Slavery once was legal in the US, but one certainly wouldn’t say enslaving another was an “ethical” act.\n\nEconomist Milton Friedman writes that corporate executives' \"responsibility... generally will be to make as much money as possible while conforming to their basic rules of the society, both those embodied in law and those embodied in ethical custom\". Friedman also said, \"the only entities who can have responsibilities are individuals ... A business cannot have responsibilities. So the question is, do corporate executives, provided they stay within the law, have responsibilities in their business activities other than to make as much money for their stockholders as possible? And my answer to that is, no, they do not.\" A multi-country 2011 survey found support for this view among the \"informed public\" ranging from 30 to 80%. Ronald Duska views Friedman's argument as consequentialist rather than pragmatic, implying that unrestrained corporate freedom would benefit the most in long term. Similarly author business consultant Peter Drucker observed, \"There is neither a separate ethics of business nor is one needed\", implying that standards of personal ethics cover all business situations. However, Peter Drucker in another instance observed that the ultimate responsibility of company directors is not to harm—\"primum non nocere\".\nAnother view of business is that it must exhibit corporate social responsibility (CSR): an umbrella term indicating that an ethical business must act as a responsible citizen of the communities in which it operates even at the cost of profits or other goals. In the US and most other nations corporate entities are legally treated as persons in some respects. For example, they can hold title to property, sue and be sued and are subject to taxation, although their free speech rights are limited. This can be interpreted to imply that they have independent ethical responsibilities. Duska argues that stakeholders have the right to expect a business to be ethical; if business has no ethical obligations, other institutions could make the same claim which would be counterproductive to the corporation.\n\nEthical issues include the rights and duties between a company and its employees, suppliers, customers and neighbors, its fiduciary responsibility to its shareholders. Issues concerning relations between different companies include hostile take-overs and industrial espionage. Related issues include corporate governance; corporate social entrepreneurship; political contributions; legal issues such as the ethical debate over introducing a crime of corporate manslaughter; and the marketing of corporations' ethics policies.\nAccording to IBE/ Ipsos MORI research published in late 2012, the three major areas of public concern regarding business ethics in Britain are executive pay, corporate tax avoidance and bribery and corruption.\n\nEthical standards of an entire organization can be badly damaged if a corporate psychopath is in charge.\n\nOne of the first seen written accounts of business ethics can be seen in Thirukural, a book said to be written by Thiruvalluvar some 2000 years ago in Tamil Literature. Their literature speaks of business ethics in many of its verses. It discusses business ethics generally in verse 113, adapting to a changing environment in verses 474, 426, and 140, learning the intricacies of different tasks in verses 462 and 677, and so on.\n\nFundamentally finance is a social science discipline. The discipline borders behavioral economics, sociology, economics, accounting and management. It concerns technical issues such as the mix of debt and equity, dividend policy, the evaluation of alternative investment projects, options, futures, swaps, and other derivatives, portfolio diversification and many others. It is often mistaken by the people to be a discipline free from ethical burdens. The 2008 financial crisis caused critics to challenge the ethics of the executives in charge of U.S. and European financial institutions and financial regulatory bodies. Finance ethics is overlooked for another reason—issues in finance are often addressed as matters of law rather than ethics.\n\nAristotle said, \"the end and purpose of the polis is the good life\". Adam Smith characterized the good life in terms of material goods and intellectual and moral excellences of character. Smith in his \"The Wealth of Nations\" commented, \"All for ourselves, and nothing for other people, seems, in every age of the world, to have been the vile maxim of the masters of mankind.\" However, a section of economists influenced by the ideology of neoliberalism, interpreted the objective of economics to be maximization of economic growth through accelerated consumption and production of goods and services. Neoliberal ideology promoted finance from its position as a component of economics to its core. Proponents of the ideology hold that unrestricted financial flows, if redeemed from the shackles of \"financial repressions\", best help impoverished nations to grow. The theory holds that open financial systems accelerate economic growth by encouraging foreign capital inﬂows, thereby enabling higher levels of savings, investment, employment, productivity and \"welfare\", along with containing corruption. Neoliberals recommended that governments open their financial systems to the global market with minimal regulation over capital flows. The recommendations however, met with criticisms from various schools of ethical philosophy. Some pragmatic ethicists, found these claims to unfalsifiable and a priori, although neither of these makes the recommendations false or unethical per se. Raising economic growth to the highest value necessarily means that welfare is subordinate, although advocates dispute this saying that economic growth provides more welfare than known alternatives. Since history shows that neither regulated nor unregulated firms always behave ethically, neither regime offers an ethical panacea.\n\nNeoliberal recommendations to developing countries to unconditionally open up their economies to transnational finance corporations was fiercely contested by some ethicists. The claim that deregulation and the opening up of economies would reduce corruption was also contested.\n\nDobson observes, \"a rational agent is simply one who pursues personal material advantage ad infinitum. In essence, to be rational in finance is to be individualistic, materialistic, and competitive. Business is a game played by individuals, as with all games the object is to win, and winning is measured in terms solely of material wealth. Within the discipline this rationality concept is never questioned, and has indeed become the theory-of-the-firm's sine qua non\". Financial ethics is in this view a mathematical function of shareholder wealth. Such simplifying assumptions were once necessary for the construction of mathematically robust models. However signalling theory and agency theory extended the paradigm to greater realism.\n\nFairness in trading practices, trading conditions, financial contracting, sales practices, consultancy services, tax payments, internal audit, external audit and executive compensation also fall under the umbrella of finance and accounting. Particular corporate ethical/legal abuses include: creative accounting, earnings management, misleading financial analysis, insider trading, securities fraud, bribery/kickbacks and facilitation payments. Outside of corporations, bucket shops and forex scams are criminal manipulations of financial markets. Cases include accounting scandals, Enron, WorldCom and Satyam.\n\nHuman resource management occupies the sphere of activity of recruitment selection, orientation, performance appraisal, training and development, industrial relations and health and safety issues. Business Ethicists differ in their orientation towards labour ethics. Some assess human resource policies according to whether they support an egalitarian workplace and the dignity of labor.\n\nIssues including employment itself, privacy, compensation in accord with comparable worth, collective bargaining (and/or its opposite) can be seen either as inalienable rights or as negotiable.\nDiscrimination by age (preferring the young or the old), gender/sexual harassment, race, religion, disability, weight and attractiveness. A common approach to remedying discrimination is affirmative action.\n\nOnce hired, employees have the right to occasional cost of living increases, as well as raises based on merit. Promotions, however, are not a right, and there are often fewer openings than qualified applicants. It may seem unfair if an employee who has been with a company longer is passed over for a promotion, but it is not unethical. It is only unethical if the employer did not give the employee proper consideration or used improper criteria for the promotion.\n\nPotential employees have ethical obligations to employers, involving intellectual property protection and whistle-blowing.\n\nEmployers must consider workplace safety, which may involve modifying the workplace, or providing appropriate training or hazard disclosure.\n\nLarger economic issues such as immigration, trade policy, globalization and trade unionism affect workplaces and have an ethical dimension, but are often beyond the purview of individual companies.\n\nTrade Unions for example, may push employers to establish due process for workers, but may also cost jobs by demanding unsustainable compensation and work rules.\n\nUnionized workplaces may confront union busting and strike breaking and face the ethical implications of work rules that advantage some workers over others.\n\nAmong the many people management strategies that companies employ are a \"soft\" approach that regards employees as a source of creative energy and participants in workplace decision making, a \"hard\" version explicitly focused on control and Theory Z that emphasizes philosophy, culture and consensus. None ensure ethical behavior. Some studies claim that sustainable success requires a humanely treated and satisfied workforce.\n\nMarketing ethics came of age only as late as the 1990s. Marketing ethics was approached from ethical perspectives of virtue or virtue ethics, deontology, consequentialism, pragmatism and relativism.\n\nEthics in marketing deals with the principles, values and/or ideals by which marketers (and marketing institutions) ought to act. Marketing ethics is also contested terrain, beyond the previously described issue of potential conflicts between profitability and other concerns.\nEthical marketing issues include marketing redundant or dangerous products/services transparency about environmental risks, transparency about product ingredients such as genetically modified organisms possible health risks, financial risks, security risks, etc., respect for consumer privacy and autonomy, advertising truthfulness and fairness in pricing & distribution.\n\nAccording to Borgerson, and Schroeder (2008), marketing can influence individuals' perceptions of and interactions with other people, implying an ethical responsibility to avoid distorting those perceptions and interactions.\n\nMarketing ethics involves pricing practices, including illegal actions such as price fixing and legal actions including price discrimination and price skimming. Certain promotional activities have drawn fire, including greenwashing, bait and switch, shilling, viral marketing, spam (electronic), pyramid schemes and multi-level marketing. Advertising has raised objections about attack ads, subliminal messages, sex in advertising and marketing in schools.\n\nThis area of business ethics usually deals with the duties of a company to ensure that products and production processes do not needlessly cause harm. Since few goods and services can be produced and consumed with zero risk, determining the ethical course can be problematic. In some case consumers demand products that harm them, such as tobacco products. Production may have environmental impacts, including pollution, habitat destruction and urban sprawl. The downstream effects of technologies nuclear power, genetically modified food and mobile phones may not be well understood. While the precautionary principle may prohibit introducing new technology whose consequences are not fully understood, that principle would have prohibited most new technology introduced since the industrial revolution. Product testing protocols have been attacked for violating the rights of both humans and animals.\n\nThe etymological root of property is the Latin 'proprius' which refers to 'nature', 'quality', 'one's own', 'special characteristic', 'proper', 'intrinsic', 'inherent', 'regular', 'normal', 'genuine', 'thorough, complete, perfect' etc. The word property is value loaded and associated with the personal qualities of propriety and respectability, also implies questions relating to ownership. A 'proper' person owns and is true to herself or himself, and is thus genuine, perfect and pure.\n\nModern discourse on property emerged by the turn of the 17th century within theological discussions of that time. For instance, John Locke justified property rights saying that God had made \"the earth, and all inferior creatures, [in] common to all men\".\n\nIn 1802 Utilitarian Jeremy Bentham stated, \"property and law are born together and die together\".\n\nOne argument for property ownership is that it enhances individual liberty by extending the line of non-interference by the state or others around the person. Seen from this perspective, property right is absolute and property has a special and distinctive character that precedes its legal protection. Blackstone conceptualized property as the \"sole and despotic dominion which one man claims and exercises over the external things of the world, in total exclusion of the right of any other individual in the universe\".\n\nDuring the seventeenth and eighteenth centuries, slavery spread to European colonies including America, where colonial legislatures defined the legal status of slaves as a form of property. During this time settlers began the centuries-long process of dispossessing the natives of America of millions of acres of land. Ironically, the natives lost about of land in the Louisiana Territory under the leadership of Thomas Jefferson, who championed property rights.\n\nCombined with theological justification, property was taken to be essentially natural ordained by God. Property, which later gained meaning as ownership and appeared natural to Locke, Jefferson and to many of the 18th and 19th century intellectuals as land, labour or idea and property right over slaves had the same theological and essentialized justification It was even held that the property in slaves was a sacred right. Wiecek noted, \"slavery was more clearly and explicitly established under the Constitution as it had been under the Articles\". Accordingly, US Supreme Court Chief Justice Roger B. Taney in his 1857 judgment stated, \"The right of property in a slave is distinctly and expressly affirmed in the Constitution\".\n\nNeoliberals hold that private property rights are a non-negotiable natural right. Davies counters with \"property is no different from other legal categories in that it is simply a consequence of the significance attached by law to the relationships between legal persons.\" Singer claims, \"Property is a form of power, and the distribution of power is a political problem of the highest order\". Rose finds, \"'Property' is only an effect, a construction, of relationships between people, meaning that its objective character is contestable. Persons and things, are 'constituted' or 'fabricated' by legal and other normative techniques.\". Singer observes, \"A private property regime is not, after all, a Hobbesian state of nature; it requires a working legal system that can define, allocate, and enforce property rights.\" Davis claims that common law theory generally favors the view that \"property is not essentially a 'right to a thing', but rather a separable bundle of rights subsisting between persons which may vary according to the context and the object which is at stake\".\n\nIn common parlance property rights involve a 'bundle of rights' including occupancy, use and enjoyment, and the right to sell, devise, give, or lease all or part of these rights. Custodians of property have obligations as well as rights. Michelman writes, \"A property regime thus depends on a great deal of cooperation, trustworthiness, and self-restraint among the people who enjoy it.\"\n\nMenon claims that the autonomous individual, responsible for his/her own existence is a cultural construct moulded by Western culture rather than the truth about the human condition. Penner views property as an \"illusion\"—a \"normative phantasm\" without substance.\n\nIn the neoliberal literature, property is part of the private side of a public/private dichotomy and acts a counterweight to state power. Davies counters that \"any space may be subject to plural meanings or appropriations which do not necessarily come into conflict\".\n\nPrivate property has never been a universal doctrine, although since the end of the Cold War is it has become nearly so. Some societies, e.g., Native American bands, held land, if not all property, in common. When groups came into conflict, the victor often appropriated the loser's property. The rights paradigm tended to stabilize the distribution of property holdings on the presumption that title had been lawfully acquired.\n\nProperty does not exist in isolation, and so property rights too. Bryan claimed that property rights describe relations among people and not just relations between people and things Singer holds that the idea that owners have no legal obligations to others wrongly supposes that property rights hardly ever conflict with other legally protected interests. Singer continues implying that legal realists \"did not take the character and structure of social relations as an important independent factor in choosing the rules that govern market life\". Ethics of property rights begins with recognizing the vacuous nature of the notion of property.\n\nIntellectual property (IP) encompasses expressions of ideas, thoughts, codes and information. \"Intellectual property rights\" (IPR) treat IP as a kind of real property, subject to analogous protections, rather than as a reproducible good or service. Boldrin and Levine argue that \"government does not ordinarily enforce monopolies for producers of other goods. This is because it is widely recognized that monopoly creates many social costs. Intellectual monopoly is no different in this respect. The question we address is whether it also creates social benefits commensurate with these social costs.\"\n\nInternational standards relating to Intellectual Property Rights are enforced through Agreement on Trade Related Aspects of Intellectual Property Rights (TRIPS). In the US, IP other than copyrights is regulated by the United States Patent and Trademark Office.\n\nThe US Constitution included the power to protect intellectual property, empowering the Federal government \"\"to promote the progress of science and useful arts, by securing for limited times to authors and inventors the exclusive right to their respective writings and discoveries\"\". Boldrin and Levine see no value in such state-enforced monopolies stating, \"we ordinarily think of innovative monopoly as an oxymoron. Further they comment, 'intellectual property' \"is not like ordinary property at all, but constitutes a government grant of a costly and dangerous private monopoly over ideas. We show through theory and example that intellectual monopoly is not necessary for innovation and as a practical matter is damaging to growth, prosperity, and liberty\" . Steelman defends patent monopolies, writing, \"Consider prescription drugs, for instance. Such drugs have benefited millions of people, improving or extending their lives. Patent protection enables drug companies to recoup their development costs because for a specific period of time they have the sole right to manufacture and distribute the products they have invented.\" The court cases by 39 pharmaceutical companies against South Africa's 1997 Medicines and Related Substances Control Amendment Act, which intended to provide affordable HIV medicines has been cited as a harmful effect of patents.\n\nOne attack on IPR is moral rather than utilitarian, claiming that inventions are mostly a collective, cumulative, path dependent, social creation and therefore, no one person or ﬁrm should be able to monopolize them even for a limited period. The opposing argument is that the benefits of innovation arrive sooner when patents encourage innovators and their investors to increase their commitments. Roderick Long, a libertarian philosopher, observes, \"Ethically, property rights of any kind have to be justified as extensions of the right of individuals to control their own lives. Thus any alleged property rights that conflict with this moral basis—like the \"right\" to own slaves—are invalidated. In my judgment, intellectual property rights also fail to pass this test. To enforce copyright laws and the like is to prevent people from making peaceful use of the information they possess. If you have acquired the information legitimately (say, by buying a book), then on what grounds can you be prevented from using it, reproducing it, trading it? Is this not a violation of the freedom of speech and press? It may be objected that the person who originated the information deserves ownership rights over it. But information is not a concrete thing an individual can control; it is a universal, existing in other people's minds and other people's property, and over these the originator has no legitimate sovereignty. You cannot own information without owning other people\". Machlup concluded that patents do not have the intended effect of enhancing innovation. Self-declared anarchist Proudhon, in his 1847 seminal work noted, \"Monopoly is the natural opposite of competition,\" and continued, \"Competition is the vital force which animates the collective being: to destroy it, if such a supposition were possible, would be to kill society\"\n\nMindeli and Pipiya hold that the knowledge economy is an economy of abundance because it relies on the \"infinite potential\" of knowledge and ideas rather than on the limited resources of natural resources, labor and capital. Allison envisioned an egalitarian distribution of knowledge. Kinsella claims that IPR create artificial scarcity and reduce equality. Bouckaert wrote, \"Natural scarcity is that which follows from the relationship between man and nature. Scarcity is natural when it is possible to conceive of it before any human, institutional, contractual arrangement. Artificial scarcity, on the other hand, is the outcome of such arrangements. Artificial scarcity can hardly serve as a justification for the legal framework that causes that scarcity. Such an argument would be completely circular. On the contrary, artificial scarcity itself needs a justification\" Corporations fund much IP creation and can acquire IP they do not create, to which Menon and others object. Andersen claims that IPR has increasingly become an instrument in eroding public domain.\n\nEthical and legal issues include: Patent infringement, copyright infringement, trademark infringement, patent and copyright misuse, submarine patents, biological patents, patent, copyright and trademark trolling, Employee raiding and monopolizing talent, Bioprospecting, biopiracy and industrial espionage, digital rights management.\n\nNotable IP copyright cases include Napster, Eldred v. Ashcroft and Air Pirates.\n\nWhile business ethics emerged as a field in the 1970s, international business ethics did not emerge until the late 1990s, looking back on the international developments of that decade. Many new practical issues arose out of the international context of business. Theoretical issues such as cultural relativity of ethical values receive more emphasis in this field. Other, older issues can be grouped here as well. Issues and subfields include:\n\nThe success of any business depends on its financial performance. Financial accounting helps the management to report and also control the business performance.\n\nThe information regarding the financial performance of the company plays an important role in enabling people to take right decision about the company. Therefore, it becomes necessary to understand how to record based on accounting conventions and concepts ensure unambling and accurate records.\n\nForeign countries often use dumping as a competitive threat, selling products at prices lower than their normal value. This can lead to problems in domestic markets. It becomes difficult for these markets to compete with the pricing set by foreign markets. In 2009, the International Trade Commission has been researching anti-dumping laws. Dumping is often seen as an ethical issue, as larger companies are taking advantage of other less economically advanced companies.\n\nEthical issues often arise in business settings, whether through business transactions or forming new business relationships. An ethical issue in a business atmosphere may refer to any situation that requires business associates as individuals, or as a group (for example, a department or firm) to evaluate the morality of specific actions, and subsequently make a decision amongst the choices. Some ethical issues of particular concern in today's evolving business market include such topics as: honesty, integrity, professional behaviors, environmental issues, harassment, and fraud to name a few. It is integral to the success of an organization that ethics issues such as these be properly addressed and resolved. Businesses should strive to educate themselves on these issues, and ethical practices in general. From a 2009 National Business Ethics survey, it was found that types of employee-observed ethical misconduct included abusive behavior (at a rate of 22 percent), discrimination (at a rate of 14 percent), improper hiring practices (at a rate of 10 percent), and company resource abuse (at a rate of percent).\n\nThe ethical issues associated with honesty are widespread and vary greatly in business, from the misuse of company time or resources to lying with malicious intent, engaging in bribery, or creating conflicts of interest within an organization. Honesty encompasses wholly the truthful speech and actions of an individual. Some cultures and belief systems even consider honesty to be an essential pillar of life, such as Confucianism and Buddhism (referred to as sacca, part of the Four Noble Truths). Many employees lie in order to reach goals, avoid assignments or negative issues; however, sacrificing honesty in order to gain status or reap rewards poses potential problems for the overall ethical culture organization, and jeopardizes organizational goals in the long run. Using company time or resources for personal use is also commonly viewed as unethical because it boils down to stealing from the company. The misue of resources costs companies billions of dollars each year, averaging about 4.25 hours per week of stolen time alone, and employees' abuse of Internet services is another main concern. Bribery, on the other hand, is not only considered unethical is business practices, but it is also illegal. In accordance with this, the Foreign Corrupt Practices Act was established in 1977 to deter international businesses from giving or receiving unwarranted payments and gifts that were intended to influence the decisions of executives and political officials. Although, small payments known as facilitation payments will not be considered unlawful under the Foreign Corrupt Practices Act if they are used towards regular public governance activities, such as permits or licenses.\n\nPolitical economy and political philosophy have ethical implications, particularly regarding the distribution of economic benefits. John Rawls and Robert Nozick are both notable contributors. For example, Rawls has been interpreted as offering a critique of offshore outsourcing on social contract grounds, whereas Nozick's libertarian philosophy rejects the notion of any positive corporate social obligation.\n\n“Laws” are the written statutes, codes, and opinions of government organizations by which citizens, businesses, and persons present within a jurisdiction are expected to govern themselves or face legal sanction. Sanctions for violating the law can include (a) civil penalties, such as fines, pecuniary damages, and loss of licenses, property, rights, or privileges; (b) criminal penalties, such as fines, probation, imprisonment, or a combination thereof; or (c) both civil and criminal penalties.\n\nVery often it is held that business is not bound by any ethics other than abiding by the law. Milton Friedman is the pioneer of the view. He held that corporations have the obligation to make a profit within the framework of the legal system, nothing more. Friedman made it explicit that the duty of the business leaders is, \"to make as much money as possible while conforming to the basic rules of the society, both those embodied in the law and those embodied in ethical custom\". Ethics for Friedman is nothing more than abiding by 'customs' and 'laws'. The reduction of ethics to abidance to laws and customs however have drawn serious criticisms.\n\nCounter to Friedman's logic it is observed that legal procedures are technocratic, bureaucratic, rigid and obligatory where as ethical act is conscientious, voluntary choice beyond normativity. Law is retroactive. Crime precedes law. Law against a crime, to be passed, the crime must have happened. Laws are blind to the crimes undefined in it. Further, as per law, \"conduct is not criminal unless forbidden by law which gives advance warning that such conduct is criminal\". Also, law presumes the accused is innocent until proven guilty and that the state must establish the guilt of the accused beyond reasonable doubt. As per liberal laws followed in most of the democracies, until the government prosecutor proves the firm guilty with the limited resources available to her, the accused is considered to be innocent. Though the liberal premises of law is necessary to protect individuals from being persecuted by Government, it is not a sufficient mechanism to make firms morally accountable.\n\nAs part of more comprehensive compliance and ethics programs, many companies have formulated internal policies pertaining to the ethical conduct of employees. These policies can be simple exhortations in broad, highly generalized language (typically called a corporate ethics statement), or they can be more detailed policies, containing specific behavioural requirements (typically called corporate ethics codes). They are generally meant to identify the company's expectations of workers and to offer guidance on handling some of the more common ethical problems that might arise in the course of doing business. It is hoped that having such a policy will lead to greater ethical awareness, consistency in application, and the avoidance of ethical disasters.\n\nAn increasing number of companies also require employees to attend seminars regarding business conduct, which often include discussion of the company's policies, specific case studies, and legal requirements. Some companies even require their employees to sign agreements stating that they will abide by the company's rules of conduct.\n\nMany companies are assessing the environmental factors that can lead employees to engage in unethical conduct. A competitive business environment may call for unethical behaviour. Lying has become expected in fields such as trading. An example of this are the issues surrounding the unethical actions of the Salomon Brothers.\n\nNot everyone supports corporate policies that govern ethical conduct. Some claim that ethical problems are better dealt with by depending upon employees to use their own judgment.\n\nOthers believe that corporate ethics policies are primarily rooted in utilitarian concerns, and that they are mainly to limit the company's legal liability, or to curry public favour by giving the appearance of being a good corporate citizen. Ideally, the company will avoid a lawsuit because its employees will follow the rules. Should a lawsuit occur, the company can claim that the problem would not have arisen if the employee had only followed the code properly.\n\nSometimes there is disconnection between the company's code of ethics and the company's actual practices. Thus, whether or not such conduct is explicitly sanctioned by management, at worst, this makes the policy duplicitous, and, at best, it is merely a marketing tool.\n\nJones and Parker write, \"Most of what we read under the name business ethics is either sentimental common sense, or a set of excuses for being unpleasant.\" Many manuals are procedural form filling exercises unconcerned about the real ethical dilemmas. For instance, US Department of Commerce ethics program treats business ethics as a set of instructions and procedures to be followed by 'ethics officers'., some others claim being ethical is just for the sake of being ethical. Business ethicists may trivialize the subject, offering standard answers that do not reflect the situation's complexity.\n\nAuthor of 'Business Ethics,' Richard DeGeorge writes in regard to the importance of maintaining a corporate code, \"Corporate codes have a certain usefulness and there are several advantages to developing them. First, the very exercise of doing so in itself is worthwhile, especially if it forces a large number of people in the firm to think through, in a fresh way, their mission and the important obligations they as a group and as individuals have to the firm, to each other, to their clients and customers, and to society as a whole. Second, once adopted a code can be used to generate continuing discussion and possible modification to the code. Third, it could help to inculcate in new employees at all levels the perspective of responsibility, the need to think in moral terms about their actions, and the importance of developing the virtues appropriate to their position.\"\n\nFollowing a series of fraud, corruption, and abuse scandals that affected the United States defense industry in the mid-1980s, the Defense Industry Initiative (DII) was created to promote ethical business practices and ethics management in multiple industries. Subsequent to these scandals, many organizations began appointing ethics officers (also referred to as \"compliance\" officers). In 1991, the Ethics & Compliance Officer Association (ECOA)—originally the Ethics Officer Association (EOA)—was founded at the Center for Business Ethics at Bentley University as a professional association for ethics and compliance officers.\n\nThe 1991 passing of the Federal Sentencing Guidelines for Organizations in 1991 was another factor in many companies appointing ethics/compliance officers. These guidelines, intended to assist judges with sentencing, set standards organizations must follow to obtain a reduction in sentence if they should be convicted of a federal offense.\n\nFollowing the high-profile corporate scandals of companies like Enron, WorldCom and Tyco between 2001 and 2004, and following the passage of the Sarbanes–Oxley Act, many small and mid-sized companies also began to appoint ethics officers.\n\nOften reporting to the Chief Executive Officer, ethics officers focus on uncovering or preventing unethical and illegal actions. This is accomplished by assessing the ethical implications of the company's activities, making recommendations on ethical policies, and disseminating information to employees.\n\nThe effectiveness of ethics officers is not clear. The establishment of an ethics officer position is likely to be insufficient in driving ethical business practices without a corporate culture that values ethical behavior. These values and behaviors should be consistently and systemically supported by those at the top of the organization. Employees with strong community involvement, loyalty to employers, superiors or owners, smart work practices, trust among the team members do inculcate a corporate culture\n\nMany corporate and business strategies now include sustainability. In addition to the traditional environmental 'green' sustainability concerns, business ethics practices have expanded to include social sustainability. Social sustainability focuses on issues related to human capital in the business supply chain, such as worker's rights, working conditions, child labor, and human trafficking. Incorporation of these considerations is increasing, as consumers and procurement officials demand documentation of a business' compliance with national and international initiatives, guidelines, and standards. Many industries have organizations dedicated to verifying ethical delivery of products from start to finish, such as the Kimberly Process, which aims to stop the flow of conflict diamonds into international markets, or the Fair Wear Foundation, dedicated to sustainability and fairness in the garment industry.\n\nAs an academic discipline, business ethics emerged in the 1970s. Since no academic business ethics journals or conferences existed, researchers published in general management journals, and attended general conferences. Over time, specialized peer-reviewed journals appeared, and more researchers entered the field. Corporate scandals in the earlier 2000s increased the field's popularity. As of 2009, sixteen academic journals devoted to various business ethics issues existed, with Journal of Business Ethics and Business Ethics Quarterly considered the leaders.\n\nThe International Business Development Institute is a global non-profit organization that represents 217 nations and all 50 United States. It offers a Charter in Business Development (CBD) that focuses on ethical business practices and standards. The Charter is directed by Harvard, MIT, and Fulbright Scholars, and it includes graduate-level coursework in economics, politics, marketing, management, technology, and legal aspects of business development as it pertains to business ethics. IBDI also oversees the International Business Development Institute of Asia which provides individuals living in 20 Asian nations the opportunity to earn the Charter.\n\nIn Sharia law, followed by many Muslims, banking specifically prohibits charging interest on loans. Traditional Confucian thought discourages profit-seeking. Christianity offers the Golden Rule command, \"Therefore all things whatsoever ye would that men should do to you, do ye even so to them: for this is the law and the prophets.\"\nAccording to the article \"Theory of the real economy\", there is a more narrow point of view from the Christianity faith towards the relationship between ethics and religious traditions. This article stresses about how capable is Christianity of establishing reliable boundaries for financial institutions. One criticism comes from Pope Benedict by describing the \"damaging effects of the real economy of badly managed and largely speculative financial dealing.\" It is mentioned that Christianity has the potential to transform the nature of finance and investment but only if theologians and ethicist provide more evidence of what is real in the economic life. Business ethics receives an extensive treatment in Jewish thought and Rabbinic literature, both from an ethical (\"Mussar\") and a legal (\"Halakha\") perspective; see article \"Jewish business ethics\" for further discussion.\nAccording to the article \"Indian Philosophy and Business Ethics: A Review\", by Chandrani Chattopadyay, Hindus follow \"Dharma\" as Business Ethics and unethical business practices are termed \"Adharma\". Business men are supposed to maintain steady-mindedness, self-purification, non-violence, concentration, charity and control over senses.Books like Bhagavat Gita and Arthashastra contribute a lot towards conduct of ethical business.\n\nBusiness ethics is part of the philosophy of economics, the branch of philosophy that deals with the philosophical, political, and ethical underpinnings of business and economics. Business ethics operates on the premise, for example, that the ethical operation of a private business is possible—those who dispute that premise, such as libertarian socialists, (who contend that \"business ethics\" is an oxymoron) do so by definition outside of the domain of business ethics proper.\n\nThe philosophy of economics also deals with questions such as what, if any, are the social responsibilities of a business; business management theory; theories of individualism vs. collectivism; free will among participants in the marketplace; the role of self interest; invisible hand theories; the requirements of social justice; and natural rights, especially property rights, in relation to the business enterprise.\n\nBusiness ethics is also related to political economy, which is economic analysis from political and historical perspectives. Political economy deals with the distributive consequences of economic actions.\n\n\n"}
{"id": "4772", "url": "https://en.wikipedia.org/wiki?curid=4772", "title": "BBS", "text": "BBS\n\nBBS may refer to:\n\n\n\n\n"}
{"id": "4775", "url": "https://en.wikipedia.org/wiki?curid=4775", "title": "British Standards", "text": "British Standards\n\nBritish Standards are the standards produced by BSI Group which is incorporated under a Royal Charter (and which is formally designated as the National Standards Body (NSB) for the UK). The BSI Group produces British Standards under the authority of the Charter, which lays down as one of the BSI's objectives to:\nFormally, as per the 2002 Memorandum of Understanding between the BSI and the United Kingdom Government, British Standards are defined as:\nProducts and services which BSI certifies as having met the requirements of specific standards within designated schemes are awarded the Kitemark.\n\nThe BSI Group as a whole does not produce British Standards, as standards work within the BSI is decentralized. The governing Board of BSI establishes a Standards Board. The Standards Board does little apart from setting up Sector Boards (a Sector in BSI parlance being a field of standardization such as ICT, Quality, Agriculture, Manufacturing, or Fire). Each Sector Board in turn constitutes several Technical Committees. It is the Technical Committees that, formally, approve a British Standard, which is then presented to the Secretary of the supervisory Sector Board for endorsement of the fact that the Technical Committee has indeed completed a task for which it was constituted.\n\nThe standards produced are titled British Standard XXXX[-P]:YYYY where XXXX is the number of the standard, P is the number of the part of the standard (where the standard is split into multiple parts) and YYYY is the year in which the standard came into effect. BSI Group currently has over 27,000 active standards. Products are commonly specified as meeting a particular British Standard, and in general this can be done without any certification or independent testing. The standard simply provides a shorthand way of claiming that certain specifications are met, while encouraging manufacturers to adhere to a common method for such a specification.\n\nThe Kitemark can be used to indicate certification by BSI, but only where a Kitemark scheme has been set up around a particular standard. It is mainly applicable to safety and quality management standards. There is a common misunderstanding that Kitemarks are necessary to prove compliance with any BS standard, but in general it is neither desirable nor possible that every standard be 'policed' in this way.\n\nFollowing the move on harmonisation of the standard in Europe, some British Standards are gradually superseded or replaced by the relevant European Standards (EN).\n\nStandards are continuously reviewed and developed and are periodically allocated one or more of the following status keywords.\n\n\nBSI Group began in 1901 as the \"Engineering Standards Committee\", led by James Mansergh, to standardise the number and type of steel sections, in order to make British manufacturers more efficient and competitive.\n\nOver time the standards developed to cover many aspects of tangible engineering, and then engineering methodologies including quality systems, safety and security.\n\n\nBSI also publishes a series of PAS documents.\n\nPAS documents are a flexible and rapid standards development model that is open to all organizations. A PAS is a sponsored piece of work allowing organizations flexibility in the rapid creation of a standard while also allowing for a greater degree of control over the document's development. A typical development time frame for a PAS is around 6–9 months. Once published by BSI a PAS has all the functionality of a British Standard for the purposes of creating schemes such as management systems and product benchmarks as well as codes of practice. A PAS is a living document and after two years the document will be reviewed and a decision made with the client as to whether or not this should be taken forward to become a formal British standard. The term PAS was originally an acronym derived from \"product approval specification\", a name which was subsequently changed to “publicly available specification”. However, according to BSI, not all PAS documents are structured as specifications and the term is now sufficiently well established not to require any further amplification.\n\n\nCopies of British Standards are sold at the BSI Online Shop or can be accessed via subscription to British Standards Online (BSOL). They can also be ordered via the publishing units of many other national standards bodies (ANSI, DIN, etc.) and from several specialized suppliers of technical specifications.\n\nBritish Standards, including European and International adoptions are available in many university and public libraries that subscribe to the BSOL platform. Librarians and lecturers at UK-based subscribing universities have full access rights to the collection while students can copy/paste and print but not download a standard. Up to 10% of the content of a standard can be copy/pasted for personal or internal use and up to 5% of the collection made available as a paper or electronic reference collection at the subscribing university. Because of their reference material status standards are not available for interlibrary loan. Public Library users in the UK may have access to BSOL on a view-only basis if their library service subscribes to the BSOL platform. Users may also be able to access the collection remotely if they have a valid library card and the library offers secure access to its resources.\n\nThe BSI Knowledge Centre in Chiswick can be contacted directly about viewing standards in their Members’ Reading Room.\n\n\n"}
{"id": "4776", "url": "https://en.wikipedia.org/wiki?curid=4776", "title": "Building society", "text": "Building society\n\nA building society is a financial institution owned by its members as a mutual organization. Building societies offer banking and related financial services, especially savings and mortgage lending. These institutions are found in the United Kingdom (UK) and several other countries.\n\nThe term \"building society\" first arose in the 18th century in Great Britain from cooperative savings groups. In the UK today, building societies actively compete with banks for most consumer banking services, especially mortgage lending and savings accounts.\n\nEvery building society in the UK is a member of the Building Societies Association. At the start of 2008, there were 59 building societies in the UK, with total assets exceeding £360 billion. The number of societies in the UK fell by four during 2008 due to a series of mergers brought about, to a large extent, by the consequences of the financial crisis of 2007–2008. With three further mergers in each of 2009 and 2010, and a demutualisation and a merger in 2011, there are now 44 building societies.\n\nThe origins of the building society as an institution lie in late-18th century Birmingham - a town which was undergoing rapid economic and physical expansion driven by a multiplicity of small metalworking firms, whose many highly skilled and prosperous owners readily invested in property. Many of the early building societies were based in taverns or coffeehouses, which had become the focus for a network of clubs and societies for co-operation and the exchange of ideas among Birmingham's highly active citizenry as part of the movement known as the Midlands Enlightenment. The first building society to be established was Ketley's Building Society, founded by Richard Ketley, the landlord of the \"Golden Cross\" inn, in 1775. Members of Ketley's society paid a monthly subscription to a central pool of funds which was used to finance the building of houses for members, which in turn acted as collateral to attract further funding to the society, enabling further construction. By 1781 three more societies had been established in Birmingham, with a fourth in the nearby town of Dudley; and 19 more formed in Birmingham between 1782 and 1795. The first outside the English Midlands was established in Leeds in 1785.\n\nMost of the original societies were fully \"terminating\", where they would be dissolved when all members had a house: the last of them, First Salisbury and District Perfect Thrift Building Society, was wound up in March 1980. In the 1830s and 1840s a new development took place with the \"permanent building society\", where the society continued on a rolling basis, continually taking in new members as earlier ones completed purchases, such as Leek United Building Society. The main legislative framework for the building society was the Building Societies Act 1874, with subsequent amending legislation in 1894, 1939 (see Coney Hall), and 1960.\n\nIn their heyday, there were hundreds of building societies: just about every town in the country had a building society named after that town. Over succeeding decades the number of societies has decreased, as various societies merged to form larger ones, often renaming in the process, and other societies opted for demutualisation followed by – in the great majority of cases – eventual takeover by a listed bank. Most of the existing larger building societies are the end result of the mergers of many smaller societies.\n\nIn the 1980s, British banking laws were changed to allow building societies to offer banking services equivalent to normal banks. The management of a number of societies still felt that they were unable to compete with the banks, and a new Building Societies Act was passed in 1986 in response to their concerns. This permitted societies to 'demutualise'. If more than 75% of members voted in favour, the building society would then become a limited company like any other. Members' mutual rights were exchanged for shares in this new company. A number of the larger societies made such proposals to their members and all were accepted. Some became independent companies quoted on the London Stock Exchange, others were acquired by larger financial groups.\n\nThe process began with the demutualisation of the Abbey National Building Society in 1989. Then, from 1995 to late-1999, eight societies demutualised accounting for two-thirds of building societies assets as at 1994. Five of these societies became joint stock banks (plc), one merged with another and the other four were taken over by plcs (in two cases after the mutual had previously converted to a plc).\n\nAs Tayler (2003) refers, demutualisation moves succeeded immediately because neither Conservative nor Labour party UK governments created a framework which put obstacles in the way of demutualisation. Political acquiescence in demutualisation was clearest in the case of the position on 'carpet baggers', that is those who joined societies by lodging minimum amounts of £100 or so in the hope of profiting from a distribution of surplus after demutualisation. The deregulating Building Societies Act 1986 contained an anti-carpet bagger provision in the form of a two-year rule. This prescribed a qualifying period of two years before savers could participate in a residual claim. But, before the 1989 Abbey National Building Society demutualisation, the courts found against the two-year rule after legal action brought by Abbey National itself to circumvent the intent of the legislators. After this the legislation did prevent a cash distribution to members of less than two years standing, but the same result was obtained by permitting the issue of 'free' shares in the acquiring plc, saleable for cash. The Thatcher Conservative government declined to introduce amending legislation to make good the defect in the 'two-year rule'.\n\nBuilding societies, like mutual life insurers, arose as people clubbed together to address a common need interest; in the case of the building societies, this was housing and members were originally both savers and borrowers. But it very quickly became clear that 'outsider' savers were needed whose motive was profit through interest on deposits. Thus permanent building societies quickly became mortgage banks and in such institutions there always existed a conflict of interest between borrowers and savers. It was the task of the movement to reconcile that conflict of interest so as to enable savers to conclude that their interests and those of borrowers were to some extent complementary rather than conflictive. Conflict of interest between savers and borrowers was never fully reconciled in the building societies but upon deregulation that reconciliation became something of a lost cause. The management of building societies apparently could expend considerable time and resources (which belonged the organisation) planning their effective capture—of as much of the assets as they could. If so, this is arguably insider dealing on a grand scale with the benefit of inside specialist knowledge of the business and resources of the firm not shared with outsiders like politicians and members (and, perhaps, regulators). Once the opportunity to claim was presented by management the savers in particular could be relied upon to seize it. There were sufficient hard up borrowers to take the inducement offered them by management (in spite of few simple sums sufficing to demonstrate that they were probably going to end up effectively paying back the inducement). (Tayler 2003)\n\nManagements promoting demutualisation also thereby met managerial objectives because the end of mutuality brought joint stock company (plc) style remuneration committee pay standards and share options. Share options for management of converting societies appear to be a powerful factor in management calculation. Rasmusen (1988) refers to this in the following terms:\n\" ... perks do not rise in proportion to [mutual] bank size. If a mutual is large, or is expected to grow if it can raise capital by a conversion, its managers derive more value from a conversion but do not suffer much loss of perks than if the bank were small. Their benefit is in the right to purchase the new stock, which are valuable because the new issues are consistently underpriced [referring to USA mutual bank conversions]. Moreover, by no means are all mutual managers incompetent, and conversions allows the bank to expand more easily and to grant executive stock options that are valuable to skilled managers\".\n\nInstead of deploying their margin advantage as a defence of mutuality, around 1980 building societies began setting mortgage rates with reference to market clearing levels. In sum they began behaving more like banks, seeking to maximise profit instead of the advantages of a mutual organisation. Thus, according to the Bank of England's Boxall and Gallagher (1997), \"... there was virtually no difference between banks and building society 'listed' interest rates for home finance mortgage lending between 1984 and 1997. This behaviour resulted in a return on assets for building societies which was at least as high as Plc banks and, in the absence of distribution, led to rapid accumulation of reserves\". As Boxall and Gallagher (1997) also observe; \"... accumulation of reserves in the early-1990s, beyond regulatory and future growth requirements, is difficult to reconcile with conventional theories of mutual behaviour\".\n\nLlewellyn (1996) draws a rather more direct and cynical conclusion:\n\nSome of these managements ended up in dispute with their own members. Of the first major conversion of the Abbey in 1989, Kay (1991) observed:\n\nIn the end, after a number of large demutualisations, and pressure from carpetbaggers moving from one building society to another to cream off the windfalls, most of the societies whose management wished to keep them mutual modified their rules of membership in the late 1990s. The method usually adopted were membership rules to ensure that anyone newly joining a society would, for the first few years, be unable to get any profit out of a demutualisation. With the chance of a quick profit removed, the wave of demutualisations came to an end in 2000.\n\nOne academic study (Heffernan, 2003) found that demutualised societies' pricing behaviour on deposits and mortgages was more favourable to shareholders than to customers, with the remaining mutual building societies offering consistently better rates.\n\nThe Building Societies (Funding) and Mutual Societies (Transfers) Act 2007, known as the Butterfill Act, was passed in 2007 giving building societies greater powers to merge with other companies. These powers have been used by the Britannia in 2009 and Kent Reliance in 2011 leading to their demutualisation.\n\nPrior to 31 December 2010, deposits with building societies of up to £50,000 per individual, per institution, were normally protected by the Financial Services Compensation Scheme (FSCS), but Nationwide and Yorkshire Building Societies negotiated a temporary change to the terms of the FSCS to protect members of the societies they acquired in late 2008/early 2009. The amended terms allowed former members of multiple societies which merge into one to maintain multiple entitlements to FSCS protection until 30 September 2009 (later extended to 30 December 2010), so (for example) a member with £50,000 in each of Nationwide, Cheshire and Derbyshire at the time of the respective mergers would retain £150,000 of FSCS protection for their funds in the merged Nationwide. On 31 December 2010 the general FSCS limit for retail deposits was increased to £85,000 for banks and building societies and the transitional arrangements in respect of building society mergers came to an end.\n\nThe remaining building societies are:\n\n(Total group assets of building societies) \"(data from last available annual reports as of Dec 2016)\"\n\nSource: Building Societies Association updated for subsequent mergers\n\nTen building societies of the United Kingdom demutualised between 1989 and 2000, either becoming a bank or being acquired by a larger bank. By 2008, every building society that floated on the stock market in the wave of demutualisations of the 1980s and 1990s had either been sold to a conventional bank, or been nationalised.\n\nThe following is an incomplete list of building societies in the United Kingdom that no longer exist independently, since they either merged with or were taken over by other organisations. They may still have an active presence on the high street (or online) as a trading name or as a distinct brand. This is typically because brands will often build up specific reputations and attract certain clientele, and this can continue to be marketed successfully.\n\nIn Australia, building societies evolved along British lines. Because of strict regulations on banks, building societies flourished until the deregulation of the Australian financial industry in the 1980s. Eventually many of the smaller building societies disappeared, while some of the largest (such as St. George) officially attained the status of banks. Recent conversions have included Heritage Bank which converted from building society to bank in 2011, Hume in 2014, while Wide Bay Building Society became Auswide Bank and IMB followed suit in 2015 Greater Building Society became Greater Bank in 2016. Building societies converting to banks are no longer required to demutualise.\n\nA particular difference between Australian building societies and those elsewhere, is that Australian building societies are required to incorporate as limited companies.\n\nCurrent building societies are\n\nThe Republic of Ireland had around 40 building societies at the mid-20th century peak. Many of these were very small and, as the Irish commercial banks began to originate residential mortgages, the small building societies ceased to be competitive. Most merged or dissolved or, in the case of First Active plc, converted into conventional banks. The last remaining building societies, EBS Building Society and Irish Nationwide Building Society, demutualised and were transferred or acquired into Bank subsidiaries in 2011 following the effects of the Irish financial crisis.\n\nLeeds Building Society Ireland and Nationwide UK (Ireland) are Irish branches of building societies based in the United Kingdom.\n\n\nIn Jamaica, three building societies compete with commercial banks and credit unions for most consumer financial services:\n\n\nIn New Zealand, building societies are registered with the Registrar of Building Societies under the Building Societies Act 1965. Registration as a building society is merely a process of establishing the entity as a corporation. It is largely a formality, and easily achieved, as the capital requirement is minimal (20 members must be issued shares of not less than NZ$1,000 each, for a total minimum foundation share capital of NZ$200,000).\n\nAs regards prudential supervision, a divide exists between building societies that operate in New Zealand, on the one hand, and those that (although formally registered in New Zealand) operate offshore:\n\nBuilding societies' registration details and filed documents are available in the Register of Building Societies held at the New Zealand Companies Office.\n\nOver the years, a number of building societies were established.\n\nSome, including Countrywide Building Society and United Building Society, became banks in the 1980s and 1990s. Heartland Building Society (created in 2011 through a merger of Canterbury Building Society, Southern Cross Building Society, and two other financial institutions) became Heartland Bank on 17 December 2012.\n\nRemaining building societies include:\n\nIn Zimbabwe, \"Central Africa Building Society\" (CABS) is the leading building society offering a diverse range of financial products and services that include transaction and savings accounts, mobile banking, mortgage loans, money market investments, term deposits and pay-roll loans.\n\nIn other countries there are mutual organisations similar to building societies:\n\nBecause most building societies were not direct members of the UK clearing system, it was common for them to use a roll number to identify accounts rather than to allocate a six-digit sort-code and eight-digit account number to the BACS standards.\n\nMore recently, building societies have tended to obtain sort-code and account number allocations within the clearing system, and hence the use of roll numbers has diminished. When using BACS, one needs to enter roll numbers for the reference field and the building society's generic sort code and account number would be entered in the standard BACS fields.\n\n\n"}
{"id": "4777", "url": "https://en.wikipedia.org/wiki?curid=4777", "title": "Blue Steel (missile)", "text": "Blue Steel (missile)\n\nThe Avro Blue Steel was a British air-launched, rocket-propelled nuclear armed standoff missile, built to arm the V bomber force. It allowed the bomber to launch the missile against its target while still outside the range of surface-to-air missiles (SAMs). The missile proceeded to the target at high speeds up to Mach 3, and would trigger within 100 m of the pre-defined target point.\n\nBlue Steel entered service in 1963, by which point improved SAMs with longer range had greatly eroded the advantages of the design. A longer-range version, Blue Steel II, was considered, but cancelled in favour of the much longer-range GAM-87 Skybolt system from the US. When development of that system was cancelled in 1962 the V-bomber fleet was considered highly vulnerable. Blue Steel remained the primary British nuclear deterrent weapon until the Royal Navy started operating Polaris ballistic missiles from \"Resolution\"-class submarines.\n\nBlue Steel was the result of a Ministry of Supply memorandum from 5 November 1954 that predicted that by 1960 Soviet air defences would make it impossible for V bombers to attack with nuclear gravity bombs. The answer was for a rocket-powered, supersonic missile capable of carrying a large nuclear (or projected thermonuclear) warhead with a range of at least . This would keep the bombers out of range of Soviet ground-based defences installed around the target area, allowing the warhead to \"dash\" in at high speed.\n\nThere would have to be a balance between the size of the warhead, the need for it to be carried by any of the three V-bomber types in use, and that it should be able to reach Mach 3. At the time the only strategic warhead available in the UK was the Green Bamboo, which was very large and so required a large missile fuselage to carry it. The Air Staff issued this requirement for a \"stand-off bomb\" as OR.1132 in September 1954.\n\nThe Ministry of Supply selected Avro out of the British manufacturers though it had no previous experience in working on guided weapons other than some private venture work; Handley Page had suggested a missile but the Elliots gyro based guidance system was inaccurate beyond .\nAvro began work proper in 1955, with the assigned Rainbow Code name of \"Blue Steel\" which it would keep in service. With Elliots working on the guidance system Armstrong Siddeley would develop the liquid fuel engine.\nIts design period was protracted, with various development problems exacerbated by the fact that designers lacked information on the actual size and weight of the proposed boosted fission warhead Green Bamboo, or its likely thermonuclear successor derived from the Granite series. The large girth of Blue Steel was determined by the implosion sphere diameter of Green Bamboo.\n\nAvro proposed that Blue Steel would evolve over time, subsequent versions increasing speed (to Mach 4.5) and range. The ultimate Blue Steel would be a range weapon that could be launched by the supersonic Avro 730 under development. They were told to limit themselves to the specification of OR.1132. The project was delayed by the need to develop the stainless steel fabrication techniques; this would have been gained in building the Avro 730 but that had been cancelled by then. Elliots guidance system was plagued by accuracy problems delaying test flights.\n\nAs it turned out, neither of the originally-proposed UK-designed warheads were actually fitted, being superseded by Red Snow, an Anglicised variant of the U.S. W-28 thermonuclear warhead of 1.1 Mt yield. Red Snow was smaller and lighter than the earlier warhead proposals. The missile was fitted with a state-of-the-art inertial navigation unit. This system allowed the missile to strike within 100 metres of its designated target. In addition, the pilots of the Avro Vulcan or Handley Page Victor bombers could tie their systems into those of the missile and make use of the guidance system to help plot their own flight plan, since the unit in the missile was more advanced than that in the aircraft.\n\nBlue Steel emerged as a pilotless, winged aircraft roughly the size of the experimental Saunders-Roe SR.53 interceptor, with clipped delta wings and small canard foreplanes. It was powered by a two-chamber Armstrong Siddeley Stentor Mark 101 rocket engine, burning a combination of hydrogen peroxide and kerosene. The fuel was a considerable operational problem, because fuelling the missile before launch took nearly half an hour, and was quite hazardous. It required the fuelling site to be flooded with water, and (during the trials campaigns) very early morning preparations because of the heat experienced during Australian summer. Another issue was the very small ground clearance when attached to the Handley Page Victor, and Victor aircrews were especially aware of the dangers when taking off. (The Vulcan had a much higher ground clearance, and ultimately proved a better platform).\n\nOn launch the rocket engine's first chamber developing thrust would power the missile along a predetermined course to the target at around Mach 1.5. Once close to the target, the second chamber of the engine (6,000 lb) would accelerate the missile to Mach 3. Over the target the engine would cut out and the missile would free-fall before detonating its warhead as an air burst.\n\nTo speed the trials at Woomera, the test rounds were flown there by Victors and Vulcans in Operation Blue Ranger. The trials began in 1960 about the time the original requirement expected the weapon to be in service. The missiles were prepared at the Weapons Research Establishment near Salisbury South Australia, and flown to be launched at the Woomera range from RAAF Edinburgh. A specialist RAF unit, 4 JSTU, was established to carry out preparatory and operational tasks.\n\nBlue Steel finally entered service in February 1963, being carried by Vulcans and Victors, although its limitations were already apparent. The short range of the missile meant that the V bombers were still vulnerable to enemy surface-to-air missiles. A replacement for Blue Steel, the Mark 2, was planned with increased range and a ramjet engine, but was cancelled in 1960 to minimise delays to the Mk.1. The UK sought to acquire the much longer-ranged United States Air Force AGM-48 Skybolt air-launched ballistic missile, and was greatly frustrated when that weapon was cancelled in late 1962.\n\nBlue Steel required up to seven hours of launch preparation, and was highly unreliable. The Royal Air Force estimated in 1963 that half the missiles would fail to fire and would have to be dropped over their targets, contradicting their purpose of serving as standoff weapons. Even as it deployed Blue Steel, a high-altitude weapon, that year the government decided that because of anti-aircraft missiles' increasing effectiveness, V bombers would have to convert from high-altitude to low-altitude attacks. These trials were conducted in 1964 and concluded in 1965 With no effective long-range weapon the original Blue Steel served on after a crash programme of minor modifications to permit a low-level launch at , even though its usefulness in a hot war was likely limited. A stop-gap weapon (WE.177B) was quickly produced to extend the life of the V-bomber force in the strategic role until the Polaris missile was deployed. This WE.177 laydown weapon supplemented the remaining modified Blue Steel missiles using a low-level penetration followed by a pop-up manoeuvre to release the weapon at Forty-eight live operational rounds were deployed on 48 Vulcan and Victor bombers and a further five live rounds were produced as operational spares. An additional four non-nuclear rounds were produced for various RAF requirements, and there were 16 other unspecified training rounds.\n\nBlue Steel was officially retired on 31 December 1970, with the United Kingdom's strategic nuclear capacity passing to the submarine fleet.\n\n\n\n\n\n\n"}
{"id": "4778", "url": "https://en.wikipedia.org/wiki?curid=4778", "title": "Branch Davidians", "text": "Branch Davidians\n\nThe Branch Davidians (also known as \"The Branch\") are a religious group that originated in 1955 from a schism in the Davidian Seventh-day Adventists (\"Davidians\"), a reform movement that began as an offshoot from the Seventh-day Adventist Church (\"Adventists\") around 1930. Some of those who accepted the reform message had been removed from membership of the Seventh-day Adventist Church because of their supplemental teachings. Today, the original Davidian Seventh-day Adventists and the Branch Davidian Seventh-day Adventists are two different and distinct groups. The doctrinal beliefs differ on major teachings such as the Holy Spirit and Its nature, and the feast days and their requirements. Both groups have disputed the relevance of the other's spiritual authority based on the proceedings following Victor Houteff's death. From its inception in 1930, the reform movement believed themselves to be living in a time when Biblical prophecies of a final divine judgment were coming to pass as a prelude to Christ's Second Coming.\n\nIn 1993 the ATF, FBI, and Texas National Guard raided one of their properties for suspected weapons violations. Once the Branch Davidians met the raid with gunfire they were laid siege for 51 days. The siege ended with a raid which resulted in the deaths of the Branch Davidians' leader, David Koresh, as well as 82 other Branch Davidian men, women, and children, and four ATF agents.\n\nIn 1929 Victor Houteff, a Bulgarian immigrant and a Seventh-day Adventist Sabbath School teacher in a local church in Southern California, claimed that he had a new message for the entire church. He presented this message in a book, \"The Shepherd's Rod: The 144,000—A Call for Reformation\". The Adventist leadership rejected Houteff's message as contrary to the Adventists' basic teachings and disfellowshipped Houteff and his followers. However, there was some controversy over the method the leadership took to disfellowship Houteff.\n\nIn 1935 Houteff established his headquarters to the west of Waco, Texas and his group became known as The Shepherd's Rod Seventh-day Adventists. In 1942 he renamed the group to the General Association of Davidian Seventh-day Adventists, 'Davidian' indicating the belief in the restoration of the Davidic Kingdom of Israel. Following Houteff's death in 1955, the segment of the group loyal to Houteff continued as the Davidian Seventh-day Adventists, led by his wife Florence. Convinced of an imminent apocalypse and purported by Florence Houteff's time setting, which was not found in the original writings of her husband Victor, Florence Houteff and her council gathered hundreds of faithful followers together at their Mount Carmel Centre near Waco in 1959, for the fulfillment of Ezekiel 9. \n\nFollowing this disappointment, Benjamin Roden formed a splinter group called the Branch Davidian Seventh-day Adventists and succeeded in taking control of Mount Carmel, for establishing Roden's new teachings. This name is an allusion to the anointed 'Branch' (mentioned in Zechariah 3:8; 6:12). When Benjamin Roden died in 1978, he was succeeded by his wife Lois Roden. After Lois Roden died, a bitter power struggle ensued between Lois Roden's son George Roden and her designated successor David Koresh (then still using his birth name of Vernon Howell), eventually won by Koresh.\n\nDavid Koresh's arrival on the Waco compound in 1981 was well received by nearly everyone at the Davidian commune. Koresh had an affair with the then-prophetess of the Branch Davidians Lois Roden. When she died, her son George Roden inherited the position of prophet and leader of the commune. However, George Roden and Koresh began to clash. Koresh soon enjoyed the loyalty of the majority of the [Branch Davidian] community\"\n\nAs an attempt to regain support, George Roden challenged Koresh to raise the dead, going so far as to exhume a corpse to demonstrate his spiritual supremacy. This illegal activity gave Koresh an opportunity to attempt to file charges against Roden, however he was told he needed evidence. This led to the November 3rd, 1987 raid on the Mount Carmel Center by Koresh and 7 of his followers equipped with five .223 caliber semiautomatic rifles, two .22 caliber rifles, two 12-gauge shotguns and nearly 400 rounds of ammunition. Their objective seemed to be to retake the land that Koresh had left three years earlier although they claim to have been trying to obtain evidence of Roden's illegal activity, yet they did not come equipped with a camera.\n\nThe trial ended with the jury finding the followers of Koresh not guilty, but were unable to agree on Koresh. After the followers were found not guilty Koresh invited the prosecutors to Mount Carmel for ice cream.\n\nBy the time of the 1993 Waco siege, Koresh had encouraged his followers to think of themselves as \"students of the Seven Seals\" rather than as \"Branch Davidians.\" During the standoff, one of his followers publicly announced that he wanted them to thereafter be identified by the name \"Koreshians\".\n\nIt is claimed that Koresh was never authorized to use the name \"Branch Davidians\" for his breakaway sect, and that the church of that name continues to represent that part of the Branch church which did not follow him.\n\nKoresh, having gained the role of spiritual leader from Roden, asserted his spiritual role by changing his name from Vernon Howell (his birth name) to David Koresh, suggesting ties to the biblical King David and to Cyrus the Great (Koresh being Hebrew for Cyrus). In 1989 Koresh used this power as spiritual leader to take several \"spiritual\" wives, asserting he was to create a new lineage of world rulers. This raised allegations of child abuse, which contributed to the proceeding siege by the ATF.\n\nInterpreting Revelation 5:2, Koresh identified himself with the Lamb mentioned in the verse. This is traditionally interpreted as a symbol of Jesus Christ, however Koresh suggested that the Lamb was to come before and lay a path ahead of the second coming of Jesus Christ.\n\nOn February 28, 1993 the Bureau of Alcohol, Tobacco, Firearms and Explosives attempted to execute a search warrants relating to alleged sexual abuse charges and illegal weapons violations. The ATF, already prepared for a gun battle, attempted to raid the compound for approximately two hours until their ammo supplies began to run low. Four ATF agents (Steve Willis, Robert Williams, Todd McKeehan, and Conway Charles LeBleu) were killed during the raid. Another 16 were wounded. The five Branch Davidians killed in the 9:45 am raid were Winston Blake (British), Peter Gent (Australian), Peter Hipsman, Perry Jones, and Jaydean Wendell; two at the hands of the Branch Davidians themselves. Almost six hours after the ceasefire, Michael Schroeder was shot dead by ATF agents who alleged he fired a pistol at agents as he attempted to re-enter the compound with Woodrow Kendrick and Norman Allison. His wife claimed that he was merely returning from work and had not participated in the day's earlier altercation. Schroeder had been shot once in the eye, once in the heart, and five times in the back.\n\nAfter the raid, ATF agents established contact with Koresh and others inside of the compound. The FBI took command after the deaths of federal agents, and managed to facilitate the release of 19 children (without their parents) relatively early into the negotiations. The children were then interviewed by the FBI and the Texas Rangers. Allegedly, the children had been physically and sexually abused long before the raid.On April 19, 1993 the FBI moved for a final siege of the compound using large weaponry such as .50 caliber (12.7 mm) rifles and armored Combat Engineering Vehicles (CEV) to combat the heavily armed Branch Davidians. The FBI attempted to use tear gas to flush out the Branch Davidians without bloodshed. Officially, FBI agents were only permitted to return any incoming fire, not to actively assault the Branch Davidians. When several Branch Davidians opened fire, the FBI's response was to increase the amount of gas being used. Around noon, three fires broke out simultaneously in different parts of the building, The government maintains the fires were deliberately started by Branch Davidians. Some Branch Davidian survivors maintain that the fires were started either accidentally or deliberately by the assault. 76 Branch Davidians died on April 19 (with only nine surviving), killed by rubble, suffocating effects of the fire, or by gunshot wound from fellow Branch Davidians. \n\nIn all, 4 ATF agents were killed, 16 were wounded, 6 Branch Davidians were killed in the initial raid on February 28 and 76 more were killed in the final siege on April 19. The events at Waco spurred criminal prosecution and civil litigation. A federal grand jury indicted 12 of the surviving Branch Davidians charging them with aiding and abetting in murder of federal officers, and unlawful possession and use of various firearms. Eight Branch Davidians were convicted on firearms charges, 5 convicted of voluntary manslaughter, and four were acquitted of all charges. As of July 2007, all Branch Davidians had been released from prison.\n\nSeveral civil suits were brought against the United States government, federal officials, former governor of Texas Ann Richards, and members of the Texas Army National Guard. The bulk of these claims were dismissed because they were insufficient as a matter of law or because the plaintiffs could advance no material evidence in support of them. One case, Andrade v. Chojnacki made it to the Fifth Circuit, which upheld a previous ruling of \"take-nothing, denied\".\n\nOne modern incarnation of The Branch Davidians exists under the leadership of Charles Pace, a follower of Ben and Lois Roden was a member of the Branch Davidians since the mid-1970s. He claims that Koresh twisted the Bible’s teachings by fathering more than a dozen children with members’ wives. Pace feels the Lord \"has anointed me and appointed me to be the leader\" but he claims he is \"not a prophet\" but \"a teacher of righteousness\". Like the Branch Davidians under Koresh, The BRANCH, The Lord Our Righteousness is waiting for the end of times.\n\n\n"}
{"id": "4779", "url": "https://en.wikipedia.org/wiki?curid=4779", "title": "Burwash Hall", "text": "Burwash Hall\n\nBurwash Hall is the second oldest of the residence buildings at Toronto's Victoria College. Construction began in 1911 and was completed in 1913. It was named after Nathanael Burwash, a former president of Victoria. The building is an extravagant Neo-Gothic work with turrets, gargoyles, and battlements. The architect was Henry Sproatt.\n\nThe building is divided between the large dining hall in the northwest and the student residence proper. The residence area is divided into two sections. The Upper Houses, built in 1913, consist of four houses: North House, Middle House, Gate House, and South House. The Lower Houses were built in 1931 and were originally intended to house theology students at Emmanuel College, whose current building was opened the same year. Ryerson House, Nelles House, Caven House, Bowles-Gandier House are now mostly home to undergraduate arts and science students. The latter two are mostly reserved for students in the new Vic One Programme.\n\nFamous residents of Burwash include Vincent Massey, Lester B. Pearson, Don Harron, and Donald Sutherland. The upper houses were gutted and renovated in 1995. The lower houses have only been partially upgraded. Before the renovations the entire building was all male, but now every house is co-ed.\n\nEach Upper House consists of three floors. The lower floor contains a common room equipped with kitchen facilities, couches and a television. The upper floors each have their own kitchen and dining area. All except North House have a very high bathroom ratio, with Gate House being the best with nine washrooms for its twenty-eight residents. Upper Houses are divided between double rooms and singles, with about sixty percent of the population being in doubles.\n\nThe Lower Houses each have four floors, but are much narrower with each level having only four rooms. Each level also has its own kitchen, but these are much smaller than in the Upper Houses. The Lower Houses do have far larger and better fitted common rooms that are similar to the ones the Upper Houses had before the renovations. The rooms in the Lower Houses are also considered more luxurious with hardwood floors and large sizes. Rooms in the Lower Houses are more expensive, however. Until 2003 the Lower Houses were restricted to upper year students but with the double cohort of graduates from Ontario schools many of the rooms were transformed into doubles and now hold first years.\n\nTo the west the Upper Houses look out on the Vic Quad and the main Victoria College building across it. West of the Lower Houses is the new Lester B. Pearson Garden of Peace and International Understanding and the E.J. Pratt Library beyond it. From the eastern side of the building, the Upper Houses look out at Rowell Jackman Hall and the Lower Houses see the St. Michael's College residence of Elmsley. The only exception is the view from Gate House's tower that looks down St. Mary's Street.\n\nThe dining hall is perhaps the best known part of the building to outsiders. It is the University of Toronto's largest, holding some 250 students and sixteen large tables. Hanging on the western wall is Queen Victoria's burial flag, given to the college soon after her death. Under the flag is the high table where the professors and college administration lunch. Historically, the Upper Houses each had their own table. Gate sat in the southwest corner, Middle sat in the far northeast, South sat in the table to the west of Middle, while North sat to the west of the southeast corner. The only lower house to have had a designated table was Caven, in the northwest corner beside the alumni table. (Note that prior to the 1995 renovations, some of these houses, particularly North and Caven, 'traditionally' sat elsewhere)\n\nGate House is one of the four Upper Houses of the Burwash Hall residence. Until 2007, when Victoria administration made it co-ed, Gate House was one of the last remaining all-male residence building in the University of Toronto. The Gate House emblem is the Phoenix, visible in the bottom-right corner of the Victoria College insignia.\n\nGate House, with the rest of Upper Burwash, opened in 1913 and has held students every year since then except 1995, when it was renovated. As an all-male residence from 1913 to 2007 it held a number of unique traditions. For 20 years Gate House hosted an annual party called Novemberfest in the Burwash dining hall. The Victoria Dean of Students cancelled Novemberfest in 2003, when police discovered widespread underage drinking and over 800 people in the dining hall, in violation of the fire code. Another Gate House tradition that no longer occurs is the \"stirring the chicken,\" a dinner and keg party where house members cook chicken fajitas for hundreds of guests. Until 2007, Gate House held secretive first-year initiation ceremonies called Traditionals, which involved writing slogans on campus buildings in chalk, singing songs to the all-women's residence (who would then sing back to them), and leading first-years around the house blindfolded. Since Novemberfest, Gate House continued to have conflict with the Administration. In 2004 the Dean evicted three Gate House residents for allegedly \"hog-tying\" a first-year student. In 2007 President Paul W. Gooch wrote that Gate House undertook an \"escalating series of actions\" that were \"defiant\" and \"disparaging of women\", in response to Gate members constructing a 2.5-metre snow penis and placing a cooked pig's head in an Annesley bathroom. As punishment, during the fall exam period Gooch evicted two residents and relocated the remainder of Gate House to other places in the residence system, banned all current Gate House students from entering the building in 2008. Since this decision Gate House has become a co-ed residence identical to the other Upper Burwash houses. Notable residents of Gate House include Lester B. Pearson, former Prime Minister of Canada, and Simon Pulsifer, who \"Time\" magazine nicknamed \"The Duke of Data\" for his contributions to Wikipedia.\n\nDuring its 93 years as a men's residence, Gate House developed a distinct character and reputation. These antics included pranks, toga parties, streaking, caroling to other residences, hazing rituals, \"beer bashes\" and \"incessant pounding\" on the Gate House table in the dining hall. Paul Gooch wrote that these traditions gave Gate House an \"ethos\" that contradicted his vision of residence life.\n\nThe all-male Gate House was known as a social centre and spirited, tight-knit community. According to Grayson Lee, who created the snow penis sculpture in 2007, most of its residents were \"heartbroken\" to leave. Former Gate House President Dave Ruhl commented that \"the Gate House camaraderie is unique\" and that living there was \"one of the most important parts of the university experience\" for many.\n\nThe Reuters news agency nicknamed Gate House \"U of T's Animal House\" because Donald Sutherland's memories of its parties are said to have influenced the script of the 1978 movie. The Toronto Star described Gooch's decision to put an end to its traditions, activities and distinguishing characteristics as \"neutering Animal House.\"\n\nGate House has three floors which house 28 students, as well as a don and the Victoria College Residence Life Co-ordinator. Above the gate there is a tower that rises three stories higher and has a turret-style roof. The tower is locked during the school year and entering it is a Level 4 offense under the Victoria residence agreement for which the punishment is eviction from residence.\n\nThe first floor has one double room and one bathroom available to students. About half of the floor is taken up by the apartment of the Residence Life Coordinator. Lastly, on the first floor there is a house common room with a kitchen and two couches. The second floor has three double rooms and seven single rooms. It has three single washrooms and one larger communal one, as well as its own kitchen. This floor is home to the residence don, who has a larger room with a private washroom. The third floor is identical to the second except that in place of the don's room there are two single rooms.\n\nPast Presidents of Gate House Include:\n"}
{"id": "4781", "url": "https://en.wikipedia.org/wiki?curid=4781", "title": "Benzodiazepine", "text": "Benzodiazepine\n\nBenzodiazepines (BZD, BZs), sometimes called \"benzos\", are a class of psychoactive drugs whose core chemical structure is the fusion of a benzene ring and a diazepine ring. The first such drug, chlordiazepoxide (Librium), was discovered accidentally by Leo Sternbach in 1955, and made available in 1960 by Hoffmann–La Roche, which, since 1963, has also marketed the benzodiazepine diazepam (Valium). In 1977 benzodiazepines were globally the most prescribed medications. They are in the family of drugs commonly known as minor tranquilizers.\nBenzodiazepines enhance the effect of the neurotransmitter gamma-aminobutyric acid (GABA) at the GABA receptor, resulting in sedative, hypnotic (sleep-inducing), anxiolytic (anti-anxiety), anticonvulsant, and muscle relaxant properties. High doses of many shorter-acting benzodiazepines may also cause anterograde amnesia and dissociation. These properties make benzodiazepines useful in treating anxiety, insomnia, agitation, seizures, muscle spasms, alcohol withdrawal and as a premedication for medical or dental procedures. Benzodiazepines are categorized as either short-, intermediate-, or long-acting. Short- and intermediate-acting benzodiazepines are preferred for the treatment of insomnia; longer-acting benzodiazepines are recommended for the treatment of anxiety.\nBenzodiazepines are generally viewed as safe and effective for short-term use, although cognitive impairment and paradoxical effects such as aggression or behavioral disinhibition occasionally occur. A minority of people can have paradoxical reactions such as worsened agitation or panic. Benzodiazepines are also associated with increased risk of suicide. Long-term use is controversial because of concerns about adverse psychological and physical effects, decreasing effectiveness, and physical dependence and withdrawal. As a result of adverse effects associated with the long-term use of benzodiazepines, withdrawal from benzodiazepines, in general, leads to improved physical and mental health. The elderly are at an increased risk of suffering from both short- and long-term adverse effects, and as a result, all benzodiazepines are listed in the Beers List of inappropriate medications for older adults.\n\nThere is controversy concerning the safety of benzodiazepines in pregnancy. While they are not major teratogens, uncertainty remains as to whether they cause cleft palate in a small number of babies and whether neurobehavioural effects occur as a result of prenatal exposure; they are known to cause withdrawal symptoms in the newborn. Benzodiazepines can be taken in overdoses and can cause dangerous deep unconsciousness. However, they are less toxic than their predecessors, the barbiturates, and death rarely results when a benzodiazepine is the only drug taken. When combined with other central nervous system (CNS) depressants such as alcoholic drinks and opioids, the potential for toxicity and fatal overdose increases. Benzodiazepines are commonly misused and taken in combination with other drugs of abuse.\n\nBenzodiazepines possess sedative, hypnotic, anxiolytic, anticonvulsant, muscle relaxant, and amnesic actions, which are useful in a variety of indications such as alcohol dependence, seizures, anxiety disorders, panic, agitation, and insomnia. Most are administered orally; however, they can also be given intravenously, intramuscularly, or rectally. In general, benzodiazepines are well-tolerated and are safe and effective drugs in the short term for a wide range of conditions. Tolerance can develop to their effects and there is also a risk of dependence, and upon discontinuation a withdrawal syndrome may occur. These factors, combined with other possible secondary effects after prolonged use such as psychomotor, cognitive, or memory impairments, limit their long-term applicability. The effects of long-term use or misuse include the tendency to cause or worsen cognitive deficits, depression, and anxiety. The College of Physicians and Surgeons of British Columbia recommends discontinuing the usage of benzodiazepines in those on opioids and those who have used them long term.\n\nBecause of their effectiveness, tolerability, and rapid onset of anxiolytic action, benzodiazepines are frequently used for the treatment of anxiety associated with panic disorder. However, there is disagreement among expert bodies regarding the long-term use of benzodiazepines for panic disorder. The views range from those that hold that benzodiazepines are not effective long-term and that they should be reserved for treatment-resistant cases to that they are as effective in the long term as selective serotonin reuptake inhibitors.\n\nThe American Psychiatric Association (APA) guidelines note that, in general, benzodiazepines are well tolerated, and their use for the initial treatment for panic disorder is strongly supported by numerous controlled trials. APA states that there is insufficient evidence to recommend any of the established panic disorder treatments over another. The choice of treatment between benzodiazepines, SSRIs, serotonin–norepinephrine reuptake inhibitors, tricyclic antidepressants, and psychotherapy should be based on the patient's history, preference, and other individual characteristics. Selective serotonin reuptake inhibitors are likely to be the best choice of pharmacotherapy for many patients with panic disorder, but benzodiazepines are also often used, and some studies suggest that these medications are still used with greater frequency than the SSRIs. One advantage of benzodiazepines is that they alleviate the anxiety symptoms much faster than antidepressants, and therefore may be preferred in patients for whom rapid symptom control is critical. However, this advantage is offset by the possibility of developing benzodiazepine dependence. APA does not recommend benzodiazepines for persons with depressive symptoms or a recent history of substance abuse. The APA guidelines state that, in general, pharmacotherapy of panic disorder should be continued for at least a year, and that clinical experience support continuing benzodiazepine treatment to prevent recurrence. Although major concerns about benzodiazepine tolerance and withdrawal have been raised, there is no evidence for significant dose escalation in patients using benzodiazepines long-term. For many such patients stable doses of benzodiazepines retain their efficacy over several years.\n\nGuidelines issued by the UK-based National Institute for Health and Clinical Excellence (NICE), carried out a systematic review using different methodology and came to a different conclusion. They questioned the accuracy of studies that were not placebo-controlled. And, based on the findings of placebo-controlled studies, they do not recommend use of benzodiazepines beyond two to four weeks, as tolerance and physical dependence develop rapidly, with withdrawal symptoms including rebound anxiety occurring after six weeks or more of use. Nevertheless, benzodiazepines are still prescribed for long-term treatment of anxiety disorders, although specific antidepressants and psychological therapies are recommended as the first-line treatment options with the anticonvulsant drug pregabalin indicated as a second- or third-line treatment and suitable for long-term use. NICE stated that long-term use of benzodiazepines for panic disorder with or without agoraphobia is an unlicensed indication, does not have long-term efficacy, and is, therefore, not recommended by clinical guidelines. Psychological therapies such as cognitive behavioural therapy are recommended as a first-line therapy for panic disorder; benzodiazepine use has been found to interfere with therapeutic gains from these therapies.\n\nBenzodiazepines are usually administered orally; however, very occasionally lorazepam or diazepam may be given intravenously for the treatment of panic attacks.\n\nBenzodiazepines have robust efficacy in the short-term management of generalized anxiety disorder (GAD), but were not shown effective in producing long-term improvement overall. According to National Institute for Health and Clinical Excellence (NICE), benzodiazepines can be used in the immediate management of GAD, if necessary. However, they should not usually be given for longer than 2–4 weeks. The only medications NICE recommends for the longer term management of GAD are antidepressants.\n\nLikewise, Canadian Psychiatric Association (CPA) recommends benzodiazepines alprazolam, bromazepam, lorazepam, and diazepam only as a second-line choice, if the treatment with two different antidepressants was unsuccessful. Although they are second-line agents, benzodiazepines can be used for a limited time to relieve severe anxiety and agitation. CPA guidelines note that after 4–6 weeks the effect of benzodiazepines may decrease to the level of placebo, and that benzodiazepines are less effective than antidepressants in alleviating ruminative worry, the core symptom of GAD. However, in some cases, a prolonged treatment with benzodiazepines as the add-on to an antidepressant may be justified.\n\nA 2015 review found a larger effect with medications than talk therapy. Medications with benefit include serotonin-noradrenaline reuptake inhibitors, benzodiazepines, and selective serotonin reuptake inhibitors.\n\nBenzodiazepines can be useful for short-term treatment of insomnia. Their use beyond 2 to 4 weeks is not recommended due to the risk of dependence. It is preferred that benzodiazepines be taken intermittently and at the lowest effective dose. They improve sleep-related problems by shortening the time spent in bed before falling asleep, prolonging the sleep time, and, in general, reducing wakefulness. However, they worsen sleep quality by increasing light sleep and decreasing deep sleep. Other drawbacks of hypnotics, including benzodiazepines, are possible tolerance to their effects, rebound insomnia, and reduced slow-wave sleep and a withdrawal period typified by rebound insomnia and a prolonged period of anxiety and agitation.\n\nThe list of benzodiazepines approved for the treatment of insomnia is fairly similar among most countries, but which benzodiazepines are officially designated as first-line hypnotics prescribed for the treatment of insomnia varies between countries. Longer-acting benzodiazepines such as nitrazepam and diazepam have residual effects that may persist into the next day and are, in general, not recommended.\n\nSince the release of nonbenzodiazepines in 1992 in response to safety concerns, individuals with insomnia and other sleep disorders have increasingly been prescribed nonbenzodiazepines (2.3% in 1993 to 13.7% of Americans in 2010), less often prescribed benzodiazepines (23.5% in 1993 to 10.8% in 2010). It is not clear as to whether the new nonbenzodiazepine hypnotics (Z-drugs) are better than the short-acting benzodiazepines. The efficacy of these two groups of medications is similar. According to the US Agency for Healthcare Research and Quality, indirect comparison indicates that side-effects from benzodiazepines may be about twice as frequent as from nonbenzodiazepines. Some experts suggest using nonbenzodiazepines preferentially as a first-line long-term treatment of insomnia. However, the UK National Institute for Health and Clinical Excellence did not find any convincing evidence in favor of Z-drugs. NICE review pointed out that short-acting Z-drugs were inappropriately compared in clinical trials with long-acting benzodiazepines. There have been no trials comparing short-acting Z-drugs with appropriate doses of short-acting benzodiazepines. Based on this, NICE recommended choosing the hypnotic based on cost and the patient's preference.\n\nOlder adults should not use benzodiazepines to treat insomnia unless other treatments have failed. When benzodiazepines are used, patients, their caretakers, and their physician should discuss the increased risk of harms, including evidence that shows twice the incidence of traffic collisions among driving patients, and falls and hip fracture for older patients.\n\nProlonged convulsive epileptic seizures are a medical emergency that can usually be dealt with effectively by administering fast-acting benzodiazepines, which are potent anticonvulsants. In a hospital environment, intravenous clonazepam, lorazepam, and diazepam are first-line choices, clonazepam due to its stronger and more potent anticonvulsant action, diazepam due to its faster onset and lorazepam for its longer duration of action. In the community, intravenous administration is not practical and so rectal diazepam or (more recently) buccal midazolam are used, with a preference for midazolam as its administration is easier and more socially acceptable.\n\nWhen benzodiazepines were first introduced, they were enthusiastically adopted for treating all forms of epilepsy. However, drowsiness and tolerance become problems with continued use and none are now considered first-line choices for long-term epilepsy therapy. Clobazam is widely used by specialist epilepsy clinics worldwide and clonazepam is popular in the Netherlands, Belgium and France. Clobazam was approved for use in the United States in 2011. In the UK, both clobazam and clonazepam are second-line choices for treating many forms of epilepsy. Clobazam also has a useful role for very short-term seizure prophylaxis and in catamenial epilepsy. Discontinuation after long-term use in epilepsy requires additional caution because of the risks of rebound seizures. Therefore, the dose is slowly tapered over a period of up to six months or longer.\n\nChlordiazepoxide is the most commonly used benzodiazepine for alcohol detoxification, but diazepam may be used as an alternative. Both are used in the detoxification of individuals who are motivated to stop drinking, and are prescribed for a short period of time to reduce the risks of developing tolerance and dependence to the benzodiazepine medication itself. The benzodiazepines with a longer half-life make detoxification more tolerable, and dangerous (and potentially lethal) alcohol withdrawal effects are less likely to occur. On the other hand, short-acting benzodiazepines may lead to breakthrough seizures, and are, therefore, not recommended for detoxification in an outpatient setting. Oxazepam and lorazepam are often used in patients at risk of drug accumulation, in particular, the elderly and those with cirrhosis, because they are metabolized differently from other benzodiazepines, through conjugation.\n\nBenzodiazepines are the preferred choice in the management of alcohol withdrawal syndrome, in particular, for the prevention and treatment of the dangerous complication of seizures and in subduing severe delirium. Lorazepam is the only benzodiazepine with predictable intramuscular absorption and it is the most effective in preventing and controlling acute seizures.\n\nBenzodiazepines are sometimes used in the treatment of acute anxiety, as they bring about rapid and marked or moderate relief of symptoms in most individuals; however, they are not recommended beyond 2–4 weeks of use due to risks of tolerance and dependence and a lack of long-term effectiveness. As for insomnia, they may also be used on an irregular/\"as-needed\" basis, such as in cases where said anxiety is at its worst. Compared to other pharmacological treatments, benzodiazepines are twice as likely to lead to a relapse of the underlying condition upon discontinuation. Psychological therapies and other pharmacological therapies are recommended for the long-term treatment of generalized anxiety disorder. Antidepressants have higher remission rates and are, in general, safe and effective in the short and long term.\n\nBenzodiazepines are often prescribed for a wide range of conditions:\n\nBecause of their muscle relaxant action, benzodiazepines may cause respiratory depression in susceptible individuals. For that reason, they are contraindicated in people with myasthenia gravis, sleep apnea, bronchitis, and COPD. Caution is required when benzodiazepines are used in people with personality disorders or intellectual disability because of frequent paradoxical reactions. In major depression, they may precipitate suicidal tendencies and are sometimes used for suicidal overdoses. Individuals with a history of alcohol, opioid and barbiturate abuse should avoid benzodiazepines, as there is a risk of life-threatening interactions with these drugs.\n\nIn the United States, the Food and Drug Administration has categorized benzodiazepines into either category D or X meaning potential for harm in the unborn has been demonstrated.\n\nExposure to benzodiazepines during pregnancy has been associated with a slightly increased (from 0.06 to 0.07%) risk of cleft palate in newborns, a controversial conclusion as some studies find no association between benzodiazepines and cleft palate. Their use by expectant mothers shortly before the delivery may result in a floppy infant syndrome, with the newborns suffering from hypotonia, hypothermia, lethargy, and breathing and feeding difficulties. Cases of neonatal withdrawal syndrome have been described in infants chronically exposed to benzodiazepines in utero. This syndrome may be hard to recognize, as it starts several days after delivery, for example, as late as 21 days for chlordiazepoxide. The symptoms include tremors, hypertonia, hyperreflexia, hyperactivity, and vomiting and may last for up to three to six months. Tapering down the dose during pregnancy may lessen its severity. If used in pregnancy, those benzodiazepines with a better and longer safety record, such as diazepam or chlordiazepoxide, are recommended over potentially more harmful benzodiazepines, such as temazepam or triazolam. Using the lowest effective dose for the shortest period of time minimizes the risks to the unborn child.\n\nThe benefits of benzodiazepines are least and the risks are greatest in the elderly. The elderly are at an increased risk of dependence and are more sensitive to the adverse effects such as memory problems, daytime sedation, impaired motor coordination, and increased risk of motor vehicle accidents and falls, and an increased risk of hip fractures. The long-term effects of benzodiazepines and benzodiazepine dependence in the elderly can resemble dementia, depression, or anxiety syndromes, and progressively worsens over time. Adverse effects on cognition can be mistaken for the effects of old age. The benefits of withdrawal include improved cognition, alertness, mobility, reduced risk incontinence, and a reduced risk of falls and fractures. The success of gradual-tapering benzodiazepines is as great in the elderly as in younger people. Benzodiazepines should be prescribed to the elderly only with caution and only for a short period at low doses. Short to intermediate-acting benzodiazepines are preferred in the elderly such as oxazepam and temazepam. The high potency benzodiazepines alprazolam and triazolam and long-acting benzodiazepines are not recommended in the elderly due to increased adverse effects. Nonbenzodiazepines such as zaleplon and zolpidem and low doses of sedating antidepressants are sometimes used as alternatives to benzodiazepines.\n\nLong-term use of benzodiazepines has been associated with increased risk of cognitive impairment, but its relationship with dementia remains inconclusive. The association of a past history of benzodiazepine use and cognitive decline is unclear, with some studies reporting a lower risk of cognitive decline in former users, some finding no association and some indicating an increased risk of cognitive decline.\n\nBenzodiazepines are sometimes prescribed to treat behavioral symptoms of dementia. However, like antidepressants, they have little evidence of effectiveness, although antipsychotics have shown some benefit. Cognitive impairing effects of benzodiazepines that occur frequently in the elderly can also worsen dementia.\n\nThe most common side-effects of benzodiazepines are related to their sedating and muscle-relaxing action. They include drowsiness, dizziness, and decreased alertness and concentration. Lack of coordination may result in falls and injuries, in particular, in the elderly. Another result is impairment of driving skills and increased likelihood of road traffic accidents. Decreased libido and erection problems are a common side effect. Depression and disinhibition may emerge. Hypotension and suppressed breathing (hypoventilation) may be encountered with intravenous use. Less common side effects include nausea and changes in appetite, blurred vision, confusion, euphoria, depersonalization and nightmares. Cases of liver toxicity have been described but are very rare.\n\nThe long-term effects of benzodiazepine use can include cognitive impairment as well as affective and behavioural problems. Feelings of turmoil, difficulty in thinking constructively, loss of sex-drive, agoraphobia and social phobia, increasing anxiety and depression, loss of interest in leisure pursuits and interests, and an inability to experience or express feelings can also occur. Not everyone, however, experiences problems with long-term use. Additionally, an altered perception of self, environment and relationships may occur.\n\nThe short-term use of benzodiazepines adversely affects multiple areas of cognition, the most notable one being that it interferes with the formation and consolidation of memories of new material and may induce complete anterograde amnesia. However, researchers hold contrary opinions regarding the effects of long-term administration. One view is that many of the short-term effects continue into the long-term and may even worsen, and are not resolved after stopping benzodiazepine usage. Another view maintains that cognitive deficits in chronic benzodiazepine users occur only for a short period after the dose, or that the anxiety disorder is the cause of these deficits.\n\nWhile the definitive studies are lacking, the former view received support from a 2004 meta-analysis of 13 small studies. This meta-analysis found that long-term use of benzodiazepines was associated with moderate to large adverse effects on all areas of cognition, with visuospatial memory being the most commonly detected impairment. Some of the other impairments reported were decreased IQ, visiomotor coordination, information processing, verbal learning and concentration. The authors of the meta-analysis and a later reviewer noted that the applicability of this meta-analysis is limited because the subjects were taken mostly from withdrawal clinics; the coexisting drug, alcohol use, and psychiatric disorders were not defined; and several of the included studies conducted the cognitive measurements during the withdrawal period.\n\nParadoxical reactions, such as increased seizures in epileptics, aggression, violence, impulsivity, irritability and suicidal behavior sometimes occur. These reactions have been explained as consequences of disinhibition and the subsequent loss of control over socially unacceptable behavior. Paradoxical reactions are rare in the general population, with an incidence rate below 1% and similar to placebo. However, they occur with greater frequency in recreational abusers, individuals with borderline personality disorder, children, and patients on high-dosage regimes. In these groups, impulse control problems are perhaps the most important risk factor for disinhibition; learning disabilities and neurological disorders are also significant risks. Most reports of disinhibition involve high doses of high-potency benzodiazepines. Paradoxical effects may also appear after chronic use of benzodiazepines.\n\nWhile benzodizapines may have short-term benefits for anxiety, sleep and agitation in some patients, long-term (i.e., greater than 2–4 weeks) use can result in a worsening of the very symptoms the medications are meant to treat. Potential explanations include exacerbating cognitive problems that are already common in anxiety disorders, causing or worsening depression and suicidality, disrupting sleep architecture by inhibiting deep stage sleep, withdrawal symptoms or rebound symptoms in between doses mimicking or exacerbating underlying anxiety or sleep disorders, inhibiting the benefits of psychotherapy by inhibiting memory consolidation and reducing fear extinction, and reducing coping with trauma/stress and increasing vulnerability to future stress. Anxiety, insomnia and irritability may be temporarily exacerbated during withdrawal, but psychiatric symptoms after discontinuation are usually less than even while taking benzodiazepines. Fortunately, for those with benzodiazepine-induced problems, functioning significantly improves within 1 year of discontinuation.\n\nThe main problem of the chronic use of benzodiazepines is the development of tolerance and dependence. Tolerance manifests itself as diminished pharmacological effect and develops relatively quickly to the sedative, hypnotic, anticonvulsant, and muscle relaxant actions of benzodiazepines. Tolerance to anti-anxiety effects develops more slowly with little evidence of continued effectiveness beyond four to six months of continued use. In general, tolerance to the amnesic effects does not occur. However, controversy exists as to tolerance to the anxiolytic effects with some evidence that benzodiazepines retain efficacy and opposing evidence from a systematic review of the literature that tolerance frequently occurs and some evidence that anxiety may worsen with long-term use. The question of tolerance to the amnesic effects of benzodiazepines is, likewise, unclear. Some evidence suggests that partial tolerance does develop, and that, \"memory impairment is limited to a narrow window within 90 minutes after each dose\".\n\nA major disadvantage of benzodiazepines that tolerance to therapeutic effects develops relatively quickly while many adverse effects persist. Tolerance develops to hypnotic and myorelexant effects within days to weeks, and to anticonvulsant and anxiolytic effects within weeks to months. Therefore, benzodiazepines are unlikely to be effective long-term treatments for sleep and anxiety. While BZD therapeutic effects disappear with tolerance, depression and impulsivity with high suicidal risk commonly persist. Several studies have confirmed that long-term benzodiazepines are not significantly different from placebo for sleep or anxiety. This may explain why patients commonly increase doses over time and many eventually take more than one type of benzodiazepine after the first loses effectiveness. Additionally, because tolerance to benzodiazepine sedating effects develops more quickly than does tolerance to brainstem depressant effects, those taking more benzodiazepines to achieve desired effects may suffer sudden respiratory depression, hypotension or death. Most patients with anxiety disorders and PTSD have symptoms that persist for at least several months, making tolerance to therapeutic effects a distinct problem for them and necessitating the need for more effective long-term treatment (e.g., psychotherapy, serotonergic antidepressants).\n\nDiscontinuation of benzodiazepines or abrupt reduction of the dose, even after a relatively short course of treatment (three to four weeks), may result in two groups of symptoms—rebound and withdrawal. Rebound symptoms are the return of the symptoms for which the patient was treated but worse than before. Withdrawal symptoms are the new symptoms that occur when the benzodiazepine is stopped. They are the main sign of physical dependence.\n\nThe most frequent symptoms of withdrawal from benzodiazepines are insomnia, gastric problems, tremors, agitation, fearfulness, and muscle spasms. The less frequent effects are irritability, sweating, depersonalization, derealization, hypersensitivity to stimuli, depression, suicidal behavior, psychosis, seizures, and delirium tremens. Severe symptoms usually occur as a result of abrupt or over-rapid withdrawal. Abrupt withdrawal can be dangerous, therefore a gradual reduction regimen is recommended.\n\nSymptoms may also occur during a gradual dosage reduction, but are typically less severe and may persist as part of a protracted withdrawal syndrome for months after cessation of benzodiazepines. Approximately 10% of patients experience a notable protracted withdrawal syndrome, which can persist for many months or in some cases a year or longer. Protracted symptoms tend to resemble those seen during the first couple of months of withdrawal but usually are of a sub-acute level of severity. Such symptoms do gradually lessen over time, eventually disappearing altogether.\n\nBenzodiazepines have a reputation with patients and doctors for causing a severe and traumatic withdrawal; however, this is in large part due to the withdrawal process being poorly managed. Over-rapid withdrawal from benzodiazepines increases the severity of the withdrawal syndrome and increases the failure rate. A slow and gradual withdrawal customised to the individual and, if indicated, psychological support is the most effective way of managing the withdrawal. Opinion as to the time needed to complete withdrawal ranges from four weeks to several years. A goal of less than six months has been suggested, but due to factors such as dosage and type of benzodiazepine, reasons for prescription, lifestyle, personality, environmental stresses, and amount of available support, a year or more may be needed to withdraw.\n\nWithdrawal is best managed by transferring the physically dependent patient to an equivalent dose of diazepam because it has the longest half-life of all of the benzodiazepines, is metabolised into long-acting active metabolites and is available in low-potency tablets, which can be quartered for smaller doses. A further benefit is that it is available in liquid form, which allows for even smaller reductions. Chlordiazepoxide, which also has a long half-life and long-acting active metabolites, can be used as an alternative.\n\nNonbenzodiazepines are contraindicated during benzodiazepine withdrawal as they are cross tolerant with benzodiazepines and can induce dependence. Alcohol is also cross tolerant with benzodiazepines and more toxic and thus caution is needed to avoid replacing one dependence with another. During withdrawal, fluoroquinolone-based antibiotics are best avoided if possible; they displace benzodiazepines from their binding site and reduce GABA function and, thus, may aggravate withdrawal symptoms. Antipsychotics are not recommended for benzodiazepine withdrawal (or other CNS depressant withdrawal states) especially clozapine, olanzapine or low potency phenothiazines e.g. chlorpromazine as they lower the seizure threshold and can worsen withdrawal effects; if used extreme caution is required.\n\nWithdrawal from long term benzodiazepines is beneficial for most individuals. Withdrawal of benzodiazepines from long-term users, in general, leads to improved physical and mental health particularly in the elderly; although some long term users report continued benefit from taking benzodiazepines, this may be the result of suppression of withdrawal effects.\n\nAlthough benzodiazepines are much safer in overdose than their predecessors, the barbiturates, they can still cause problems in overdose. Taken alone, they rarely cause severe complications in overdose; statistics in England showed that benzodiazepines were responsible for 3.8% of all deaths by poisoning from a single drug. However, combining these drugs with alcohol, opiates or tricyclic antidepressants markedly raises the toxicity. The elderly are more sensitive to the side effects of benzodiazepines, and poisoning may even occur from their long-term use. The various benzodiazepines differ in their toxicity; temazepam appears most toxic in overdose and when used with other drugs. The symptoms of a benzodiazepine overdose may include; drowsiness, slurred speech, nystagmus, hypotension, ataxia, coma, respiratory depression, and cardiorespiratory arrest.\n\nA reversal agent for benzodiazepines exists, flumazenil (Anexate). Its use as an antidote is not routinely recommended because of the high risk of resedation and seizures. In a double-blind, placebo-controlled trial of 326 patients, 4 patients suffered serious adverse events and 61% became resedated following the use of flumazenil. Numerous contraindications to its use exist. It is contraindicated in patients with a history of long-term use of benzodiazepines, those having ingested a substance that lowers the seizure threshold or may cause an arrhythmia, and in those with abnormal vital signs. One study found that only 10% of the patient population presenting with a benzodiazepine overdose are suitable candidates for treatment with flumazenil.\n\nIndividual benzodiazepines may have different interactions with certain drugs. Depending on their metabolism pathway, benzodiazepines can be divided roughly into two groups. The largest group consists of those that are metabolized by cytochrome P450 (CYP450) enzymes and possess significant potential for interactions with other drugs. The other group comprises those that are metabolized through glucuronidation, such as lorazepam, oxazepam, and temazepam, and, in general, have few drug interactions.\n\nMany drugs, including oral contraceptives, some antibiotics, antidepressants, and antifungal agents, inhibit cytochrome enzymes in the liver. They reduce the rate of elimination of the benzodiazepines that are metabolized by CYP450, leading to possibly excessive drug accumulation and increased side-effects. In contrast, drugs that induce cytochrome P450 enzymes, such as St John's wort, the antibiotic rifampicin, and the anticonvulsants carbamazepine and phenytoin, accelerate elimination of many benzodiazepines and decrease their action. Taking benzodiazepines with alcohol, opioids and other central nervous system depressants potentiates their action. This often results in increased sedation, impaired motor coordination, suppressed breathing, and other adverse effects that have potential to be lethal. Antacids can slow down absorption of some benzodiazepines; however, this effect is marginal and inconsistent.\n\nBenzodiazepines work by increasing the efficiency of a natural brain chemical, GABA, to decrease the excitability of neurons. This reduces the communication between neurons and, therefore, has a calming effect on many of the functions of the brain.\n\nGABA controls the excitability of neurons by binding to the GABA receptor. The GABA receptor is a protein complex located in the synapses of neurons. All GABA receptors contain an ion channel that conducts chloride ions across neuronal cell membranes and two binding sites for the neurotransmitter gamma-aminobutyric acid (GABA), while a subset of GABA receptor complexes also contain a single binding site for benzodiazepines. Binding of benzodiazepines to this receptor complex does not alter binding of GABA. Unlike other positive allosteric modulators that increases ligand binding, benzodiazepine binding acts as a positive allosteric modulator by increasing the total conduction of chloride ions across the neuronal cell membrane when GABA is already bound to its receptor. This increased chloride ion influx hyperpolarizes the neuron's membrane potential. As a result, the difference between resting potential and threshold potential is increased and firing is less likely.\nDifferent GABA receptor subtypes have varying distributions within different regions of the brain and, therefore, control distinct neuronal circuits. Hence, activation of different GABA receptor subtypes by benzodiazepines may result in distinct pharmacological actions. In terms of the mechanism of action of benzodiazepines, their similarities are too great to separate them into individual categories such as anxiolytic or hypnotic. For example, a hypnotic administered in low doses produces anxiety-relieving effects, whereas a benzodiazepine marketed as an anti-anxiety drug at higher doses induces sleep.\n\nThe subset of GABA receptors that also bind benzodiazepines are referred to as benzodiazepine receptors (BzR). The GABA receptor is a heteromer composed of five subunits, the most common ones being two \"α\"s, two \"β\"s, and one \"γ\" (αβγ). For each subunit, many subtypes exist (α, β, and γ). GABA receptors that are made up of different combinations of subunit subtypes have different properties, different distributions in the brain and different activities relative to pharmacological and clinical effects. Benzodiazepines bind at the interface of the α and γ subunits on the GABA receptor. Binding also requires that alpha subunits contain a histidine amino acid residue, (\"i.e.\", α, α, α, and α containing GABA receptors). For this reason, benzodiazepines show no affinity for GABA receptors containing α and α subunits with an arginine instead of a histidine residue. Once bound to the benzodiazepine receptor, the benzodiazepine ligand locks the benzodiazepine receptor into a conformation in which it has a greater affinity for the GABA neurotransmitter. This increases the frequency of the opening of the associated chloride ion channel and hyperpolarizes the membrane of the associated neuron. The inhibitory effect of the available GABA is potentiated, leading to sedatory and anxiolytic effects. For instance, those ligands with high activity at the α are associated with stronger hypnotic effects, whereas those with higher affinity for GABA receptors containing α and/or α subunits have good anti-anxiety activity.\n\nThe benzodiazepine class of drugs also interact with peripheral benzodiazepine receptors. Peripheral benzodiazepine receptors are present in peripheral nervous system tissues, glial cells, and to a lesser extent the central nervous system. These peripheral receptors are not structurally related or coupled to GABA receptors. They modulate the immune system and are involved in the body response to injury. Benzodiazepines also function as weak adenosine reuptake inhibitors. It has been suggested that some of their anticonvulsant, anxiolytic, and muscle relaxant effects may be in part mediated by this action.\n\nA benzodiazepine can be placed into one of three groups by its elimination half-life, or time it takes for the body to eliminate half of the dose. Some benzodiazepines have long-acting active metabolites, such as diazepam and chlordiazepoxide, which are metabolised into desmethyldiazepam. Desmethyldiazepam has a half-life of 36–200 hours, and flurazepam, with the main active metabolite of desalkylflurazepam, with a half-life of 40–250 hours. These long-acting metabolites are partial agonists.\n\nBenzodiazepines share a similar chemical structure, and their effects in humans are mainly produced by the allosteric modification of a specific kind of neurotransmitter receptor, the GABA receptor, which increases the overall conductance of these inhibitory channels; this results in the various therapeutic effects as well as adverse effects of benzodiazepines. Other less important mechanisms of action are also known.\n\nThe term \"benzodiazepine\" is the chemical name for the heterocyclic ring system (see figure to the right), which is a fusion between the benzene and diazepine ring systems. Under Hantzsch–Widman nomenclature, a diazepine is a heterocycle with two nitrogen atoms, five carbon atom and the maximum possible number of cumulative double bonds. The \"benzo\" prefix indicates the benzene ring fused onto the diazepine ring.\n\nBenzodiazepine drugs are substituted 1,4-benzodiazepines, although the chemical term can refer to many other compounds that do not have useful pharmacological properties. Different benzodiazepine drugs have different side groups attached to this central structure. The different side groups affect the binding of the molecule to the GABA receptor and so modulate the pharmacological properties. Many of the pharmacologically active \"classical\" benzodiazepine drugs contain the 5-phenyl-1\"H\"-benzo[\"e\"] [1,4]diazepin-2(3\"H\")-one substructure (see figure to the right). Benzodiazepines have been found to mimic protein reverse turns structurally, which enable them with their biological activity in many cases.\n\nNonbenzodiazepines also bind to the benzodiazepine binding site on the GABA receptor and possess similar pharmacological properties. While the nonbenzodiazepines are by definition structurally unrelated to the benzodiazepines, both classes of drugs possess a common pharmacophore (see figure to the lower-right), which explains their binding to a common receptor site.\n\n\nThe first benzodiazepine, chlordiazepoxide (\"Librium\"), was synthesized in 1955 by Leo Sternbach while working at Hoffmann–La Roche on the development of tranquilizers. The pharmacological properties of the compounds prepared initially were disappointing, and Sternbach abandoned the project. Two years later, in April 1957, co-worker Earl Reeder noticed a \"nicely crystalline\" compound left over from the discontinued project while spring-cleaning in the lab. This compound, later named chlordiazepoxide, had not been tested in 1955 because of Sternbach's focus on other issues. Expecting pharmacology results to be negative, and hoping to publish the chemistry-related findings, researchers submitted it for a standard battery of animal tests. However, the compound showed very strong sedative, anticonvulsant, and muscle relaxant effects. These impressive clinical findings led to its speedy introduction throughout the world in 1960 under the brand name \"Librium\". Following chlordiazepoxide, diazepam marketed by Hoffmann–La Roche under the brand name \"Valium\" in 1963, and for a while the two were the most commercially successful drugs. The introduction of benzodiazepines led to a decrease in the prescription of barbiturates, and by the 1970s they had largely replaced the older drugs for sedative and hypnotic uses.\n\nThe new group of drugs was initially greeted with optimism by the medical profession, but gradually concerns arose; in particular, the risk of dependence became evident in the 1980s. Benzodiazepines have a unique history in that they were responsible for the largest-ever class-action lawsuit against drug manufacturers in the United Kingdom, involving 14,000 patients and 1,800 law firms that alleged the manufacturers knew of the dependence potential but intentionally withheld this information from doctors. At the same time, 117 general practitioners and 50 health authorities were sued by patients to recover damages for the harmful effects of dependence and withdrawal. This led some doctors to require a signed consent form from their patients and to recommend that all patients be adequately warned of the risks of dependence and withdrawal before starting treatment with benzodiazepines. The court case against the drug manufacturers never reached a verdict; legal aid had been withdrawn and there were allegations that the consultant psychiatrists, the expert witnesses, had a conflict of interest. This litigation led to changes in the British law, making class action lawsuits more difficult.\n\nAlthough antidepressants with anxiolytic properties have been introduced, and there is increasing awareness of the adverse effects of benzodiazepines, prescriptions for short-term anxiety relief have not significantly dropped. For treatment of insomnia, benzodiazepines are now less popular than nonbenzodiazepines, which include zolpidem, zaleplon and eszopiclone. Nonbenzodiazepines are molecularly distinct, but nonetheless, they work on the same benzodiazepine receptors and produce similar sedative effects.\n\nIn the United States, benzodiazepines are Schedule IV drugs under the Federal Controlled Substances Act, even when not on the market (for example, nitrazepam and bromazepam). Flunitrazepam is subject to more stringent regulations in certain states and temazepam prescriptions require specially coded pads in certain states.\n\nIn Canada, possession of benzodiazepines is legal for personal use. All benzodiazepines are categorized as Schedule IV substances under the Controlled Drugs and Substances Act. Since 2000, benzodiazepines have been classed as \"targeted substances\", meaning that additional regulations exist especially affecting pharmacists' records. Since approximately 2014, Health Canada, the Canadian Medical Association and provincial Colleges of Physicians and Surgeons have been issuing progressively stricter guidelines for the prescription of benzodiazepines, especially for the elderly (e.g. College of Physicians and Surgeons of British Columbia). Unfortunately, many of these guidelines are not readily available to the public.\n\nIn the United Kingdom, the benzodiazepines are schedule 4 controlled drugs, except for flunitrazepam, temazepam and midazolam, which are schedule 3 controlled drugs and carry stronger penalties for possession and trafficking.\n\nIn the Netherlands, since October 1993, benzodiazepines, including formulations containing less than 20 mg of temazepam, are all placed on List 2 of the Opium Law. A prescription is needed for possession of all benzodiazepines. Temazepam formulations containing 20 mg or greater of the drug are placed on List 1, thus requiring doctors to write prescriptions in the List 1 format.\n\nIn East Asia and Southeast Asia, temazepam and nimetazepam are often heavily controlled and restricted. In certain countries, triazolam, flunitrazepam, flutoprazepam and midazolam are also restricted or controlled to certain degrees. In Hong Kong, all benzodiazepines are regulated under Schedule 1 of Hong Kong's Chapter 134 \"Dangerous Drugs Ordinance\". Previously only brotizolam, flunitrazepam and triazolam were classed as dangerous drugs.\n\nInternationally, benzodiazepines are categorized as Schedule IV controlled drugs, apart from flunitrazepam, which is a Schedule III drug under the Convention on Psychotropic Substances.\n\nBenzodiazepines are considered major drugs of abuse. Benzodiazepine abuse is mostly limited to individuals who abuse other drugs, i.e., poly-drug abusers. On the international scene, benzodiazepines are categorized as Schedule IV controlled drugs by the INCB, apart from flunitrazepam, which is a Schedule III drug under the Convention on Psychotropic Substances. Some variation in drug scheduling exists in individual countries; for example, in the United Kingdom, midazolam and temazepam are Schedule III controlled drugs.\n\nBritish law requires that temazepam (but \"not\" midazolam) be stored in safe custody. Safe custody requirements ensures that pharmacists and doctors holding stock of temazepam must store it in securely fixed double-locked steel safety cabinets and maintain a written register, which must be bound and contain separate entries for temazepam and must be written in ink with no use of correction fluid (although a written register is not required for temazepam in the United Kingdom). Disposal of expired stock must be witnessed by a designated inspector (either a local drug-enforcement police officer or official from health authority). Benzodiazepine abuse ranges from occasional binges on large doses, to chronic and compulsive drug abuse of high doses.\n\nBenzodiazepines are used recreationally and by problematic drug misusers. Mortality is higher among poly-drug misusers that also use benzodiazepines. Heavy alcohol use also increases mortality among poly-drug users. Dependence and tolerance, often coupled with dosage escalation, to benzodiazepines can develop rapidly among drug misusers; withdrawal syndrome may appear after as little as three weeks of continuous use. Long-term use has the potential to cause both physical and psychological dependence and severe withdrawal symptoms such as depression, anxiety (often to the point of panic attacks), and agoraphobia. Benzodiazepines and, in particular, temazepam are sometimes used intravenously, which, if done incorrectly or in an unsterile manner, can lead to medical complications including abscesses, cellulitis, thrombophlebitis, arterial puncture, deep vein thrombosis, and gangrene. Sharing syringes and needles for this purpose also brings up the possibility of transmission of hepatitis, HIV, and other diseases. Benzodiazepines are also misused intranasally, which may have additional health consequences. Once benzodiazepine dependence has been established, a clinician usually converts the patient to an equivalent dose of diazepam before beginning a gradual reduction program.\n\nA 1999–2005 Australian police survey of detainees reported preliminary findings that self-reported users of benzodiazepines were less likely than non-user detainees to work full-time and more likely to receive government benefits, use methamphetamine or heroin, and be arrested or imprisoned. Benzodiazepines are sometimes used for criminal purposes; they serve to incapacitate a victim in cases of drug assisted rape or robbery.\n\nOverall, anecdotal evidence suggests that temazepam may be the most psychologically habit-forming (addictive) benzodiazepine. Temazepam abuse reached epidemic proportions in some parts of the world, in particular, in Europe and Australia, and is a major drug of abuse in many Southeast Asian countries. This led authorities of various countries to place temazepam under a more restrictive legal status. Some countries, such as Sweden, banned the drug outright. Temazepam also has certain pharmacokinetic properties of absorption, distribution, elimination, and clearance that make it more apt to abuse compared to many other benzodiazepines.\n\nBenzodiazepines are used in veterinary practice in the treatment of various disorders and conditions. As in humans, they are used in the first-line management of seizures, status epilepticus, and tetanus, and as maintenance therapy in epilepsy (in particular, in cats). They are widely used in small and large animals (including horses, swine, cattle and exotic and wild animals) for their anxiolytic and sedative effects, as pre-medication before surgery, for induction of anesthesia and as adjuncts to anesthesia.\n\n"}
{"id": "4787", "url": "https://en.wikipedia.org/wiki?curid=4787", "title": "Bell curve (disambiguation)", "text": "Bell curve (disambiguation)\n\nThe bell curve is typical of the normal distribution.\n\nBell curve may also refer to:\n\n"}
{"id": "4788", "url": "https://en.wikipedia.org/wiki?curid=4788", "title": "Body mass index", "text": "Body mass index\n\nThe body mass index (BMI) or Quetelet index is a value derived from the mass (weight) and height of an individual. The BMI is defined as the body mass divided by the square of the body height, and is universally expressed in units of kg/m, resulting from mass in kilograms and height in metres.\n\nThe BMI may also be determined using a table or chart which displays BMI as a function of mass and height using contour lines or colours for different BMI categories, and which may use other units of measurement (converted to metric units for the calculation).\n\nThe BMI is an attempt to quantify the amount of tissue mass (muscle, fat, and bone) in an individual, and then categorize that person as \"underweight\", \"normal weight\", \"overweight\", or \"obese\" based on that value. However, there is some debate about where on the BMI scale the dividing lines between categories should be placed. Commonly accepted BMI ranges are underweight: under 18.5 kg/m, normal weight: 18.5 to 25, overweight: 25 to 30, obese: over 30. People of Asian descent have different associations between BMI, percentage of body fat, and health risks than those of European descent, with a higher risk of type 2 diabetes and cardiovascular disease at BMIs lower than the WHO cut-off point for overweight, 25 kg/m, although the cutoff for observed risk varies among different Asian populations.\n\nThe basis of the BMI was devised by Adolphe Quetelet, a Belgian astronomer, mathematician, statistician and sociologist, from 1830 to 1850 during which time he developed what he called \"social physics\". The modern term \"body mass index\" (BMI) for the ratio of human body weight to squared height was coined in a paper published in the July 1972 edition of the \"Journal of Chronic Diseases\" by Ancel Keys and others. In this paper, Keys argued that what he termed the BMI was \"...if not fully satisfactory, at least as good as any other relative weight index as an indicator of relative obesity\"\n\nThe interest in an index that measures body fat came with increasing obesity in prosperous Western societies. BMI was explicitly cited by Keys as appropriate for \"population\" studies and inappropriate for individual evaluation. Nevertheless, due to its simplicity, it has come to be widely used for preliminary diagnosis. Additional metrics, such as waist circumference, can be more useful.\n\nThe BMI is universally expressed in kg/m, resulting from mass in kilograms and height in metres. If pounds and inches are used, a conversion factor of 703 (kg/m)/(lb/in) must be applied. When the term BMI is used informally, the units are usually omitted.\n\nBMI provides a simple numeric measure of a person's \"thickness\" or \"thinness\", allowing health professionals to discuss weight problems more objectively with their patients. BMI was designed to be used as a simple means of classifying average sedentary (physically inactive) populations, with an average body composition. For these individuals, the current value recommendations are as follow: a BMI from 18.5 up to 25 kg/m may indicate optimal weight, a BMI lower than 18.5 suggests the person is underweight, a number from 25 up to 30 may indicate the person is overweight, and a number from 30 upwards suggests the person is obese. Some athletes, such as football linemen, have a high muscle to fat ratio and may have a BMI that is misleadingly high relative to their body fat percentage.\n\nBMI is proportional to the mass and inversely proportional to the square of the height. So, if all body dimensions double, and mass scales naturally with the cube of the height, then BMI doubles instead of remaining the same. This results in taller people having a reported BMI that is uncharacteristically high, compared to their actual body fat levels. In comparison, the Ponderal index is based on the natural scaling of mass with the third power of the height.\n\nHowever, many taller people are not just \"scaled up\" short people but tend to have narrower frames in proportion to their height. Nick Korevaar (a mathematics lecturer from the University of Utah) suggests that instead of squaring the body height (as the BMI does) or cubing the body height (as the Ponderal index does), it would be more appropriate to use an exponent of between 2.3 and 2.7 (as originally noted by Quetelet). (For a theoretical basis for such values see MacKay.) Carl Lavie has written that, \"The B.M.I. tables are excellent for identifying obesity and body fat in large populations, but they are far less reliable for determining fatness in individuals.\"\n\nA frequent use of the BMI is to assess how much an individual's body weight departs from what is normal or desirable for a person's height. The weight excess or deficiency may, in part, be accounted for by body fat (adipose tissue) although other factors such as muscularity also affect BMI significantly (see discussion below and overweight).\n\nThe WHO regards a BMI of less than 18.5 as underweight and may indicate malnutrition, an eating disorder, or other health problems, while a BMI equal to or greater than 25 is considered overweight and above 30 is considered obese. These ranges of BMI values are valid only as statistical categories.\n\nBMI is used differently for children. It is calculated in the same way as for adults, but then compared to typical values for other children of the same age. Instead of comparison against fixed thresholds for underweight and overweight, the BMI is compared against the percentile for children of the same sex and age.\n\nA BMI that is less than the 5th percentile is considered underweight and above the 95th percentile is considered obese. Children with a BMI between the 85th and 95th percentile are considered to be overweight.\n\nRecent studies in Britain have indicated that females between the ages 12 and 16 have a higher BMI than males of the same age by 1.0 kg/m on average.\n\nThese recommended distinctions along the linear scale may vary from time to time and country to country, making global, longitudinal surveys problematic.\n\nThe Hospital Authority of Hong Kong recommends the use of the following BMI ranges:\n\nJapan Society for the Study of Obesity (2000):\n\nIn Singapore, the BMI cut-off figures were revised in 2005, motivated by studies showing that many Asian populations, including Singaporeans, have higher proportion of body fat and increased risk for cardiovascular diseases and diabetes mellitus, compared with Caucasians at the same BMI. The BMI cut-offs are presented with an emphasis on health risk rather than weight.\n\nIn 1998, the U.S. National Institutes of Health and the Centers for Disease Control and Prevention brought U.S. definitions in line with World Health Organization guidelines, lowering the normal/overweight cut-off from BMI 27.8 to BMI 25. This had the effect of redefining approximately 29 million Americans, previously \"healthy\", to \"overweight\".\n\nThis can partially explain the increase in the \"overweight\" diagnosis in the past 20 years, and the increase in sales of weight loss products during the same time. WHO also recommends lowering the normal/overweight threshold for South East Asian body types to around BMI 23, and expects further revisions to emerge from clinical studies of different body types.\n\nThe U.S. National Health and Nutrition Examination Survey of 1994 showed that 59.8% of American men and 51.2% of women had BMIs over 25. Morbid obesity—a BMI of 40 or more—was found in 2% of the men and 4% of the women. A survey in 2007 showed 63% of Americans are overweight or obese, with 26% in the obese category (a BMI of 30 or more). As of 2014, 37.7% of adults in the United States were obese, categorized as 35.0% of men and 40.4% of women; class 3 obesity (BMI over 40) values were 7.7% for men and 9.9% for women.\n\nThere are differing opinions on definition of underweight in females; doctors quote anything below 18.5 to 20 as underweight. The most frequently stated is 19. A BMI nearing 15 is usually defined as starvation and a BMI less than 17.5 as an informal criterion for the diagnosis of anorexia nervosa.\n\nThe BMI ranges are based on the relationship between body weight and disease and death. Overweight and obese individuals are at an increased risk for the following diseases:\n\n\nAmong people who have never smoked, overweight/obesity is associated with 51% increase in mortality compared with people who have always been a normal weight.\n\nThe BMI is generally used as a means of correlation between groups related by general mass and can serve as a vague means of estimating adiposity. The duality of the BMI is that, while it is easy to use as a general calculation, it is limited as to how accurate and pertinent the data obtained from it can be. Generally, the index is suitable for recognizing trends within sedentary or overweight individuals because there is a smaller margin of error. The BMI has been used by the WHO as the standard for recording obesity statistics since the early 1980s.\n\nThis general correlation is particularly useful for consensus data regarding obesity or various other conditions because it can be used to build a semi-accurate representation from which a solution can be stipulated, or the RDA for a group can be calculated. Similarly, this is becoming more and more pertinent to the growth of children, due to the fact that the majority of children are sedentary.\n\nBMI categories are generally regarded as a satisfactory tool for measuring whether sedentary individuals are \"underweight\", \"overweight\", or \"obese\" with various exceptions, such as: athletes, children, the elderly, and the infirm. Also, the growth of a child is documented against a BMI-measured growth chart. Obesity trends can then be calculated from the difference between the child's BMI and the BMI on the chart. In the United States, BMI is also used as a measure of underweight, owing to advocacy on behalf of those with eating disorders, such as anorexia nervosa and bulimia nervosa.\n\nIn France, Israel, Italy and Spain, legislation has been introduced banning usage of fashion show models having a BMI below 18. In Israel, a BMI below 18.5 is banned. This is done in order to fight anorexia among models and people interested in fashion.\n\nThe medical establishment and statistical community have both highlighted the limitations of BMI.\n\nMathematician Keith Devlin and the restaurant industry association Center for Consumer Freedom argue that the error in the BMI is significant and so pervasive that it is not generally useful in evaluation of health. University of Chicago political science professor Eric Oliver says BMI is a convenient but inaccurate measure of weight, forced onto the populace, and should be revised.\n\nThe exponent in the denominator of the formula for BMI is arbitrary. The BMI depends upon weight and the \"square\" of height. Since mass increases to the \"3rd power\" of linear dimensions, taller individuals with exactly the same body shape and relative composition have a larger BMI.\n\nThe mathematician Prof Nick Trefethen, who observed this said, “BMI divides the weight by too large a number for short people and too small a number for tall people. So short people are misled into thinking that they are thinner than they are, and tall people are misled into thinking they are fatter.”\n\nSports medicine doctor Sultan M. Babar has shown that corpulence index is a better measure.\n\nAn analysis based on data gathered in the US suggested an exponent of 2.6 would yield the best fit for children aged 2 to 19 years old. For US adults, exponent estimates range from 1.92 to 1.96 for males and from 1.45 to 1.95 for females.\n\nThe BMI adds roughly 10% for a large (or tall) frame and subtracts roughly 10% for a smaller frame (short stature). In other words, persons with small frames would be carrying more fat than optimal, but their BMI reflects that they are \"normal\". Conversely, large framed (or tall) individuals may be quite healthy, with a fairly low body fat percentage, but be classified as \"overweight\" by BMI.\n\nFor example, a chart may say the ideal weight for a man 5 ft 10 in (178 cm) is 165 pounds (75 kg). But if that man has a slender build (small frame), he may be overweight at 165 pounds (75 kg) and should reduce by 10%, to roughly 150 pounds (68 kg). In the reverse, the man with a larger frame and more solid build can be quite healthy at . If one teeters on the edge of small/medium or medium/large, common sense should be used in calculating one's ideal weight. However, falling into one's ideal weight range for height and build is still not as accurate in determining health risk factors as waist/height ratio and actual body fat percentage.\n\nAccurate frame size calculators use several measurements (wrist circumference, elbow width, neck circumference and others) to determine what category an individual falls into for a given height. The BMI also fails to take into account loss of height through aging. In this situation, BMI will increase without any corresponding increase in weight.\n\nAssumptions about the distribution between muscle mass and fat mass are inexact. BMI generally overestimates adiposity on those with more lean body mass (e.g., athletes) and underestimates excess adiposity on those with less lean body mass. A study in June 2008 by Romero-Corral et al. examined 13,601 subjects from the United States' third National Health and Nutrition Examination Survey (NHANES III) and found that BMI-defined obesity (BMI > 30) was present in 21% of men and 31% of women.\n\nUsing body fat percentages (BF%), however, BF-defined obesity was found in 50% of men and 62% of women. While BMI-defined obesity showed high specificity (95% for men and 99% for women), BMI showed poor sensitivity (36% for men and 49% for women). Despite this undercounting of obesity by BMI, BMI values in the intermediate BMI range of 20–30 were found to be associated with a wide range of body fat percentages. For men with a BMI of 25, about 20% have a body fat percentage below 20% and about 10% have body fat percentage above 30%.\n\nBMI is particularly inaccurate for people who are very fit or athletic, as their high muscle mass can classify them in the \"overweight\" category by BMI, even though their body fat percentages frequently fall in the 10–15% category, which is below that of a more sedentary person of average build who has a \"normal\" BMI number. Body composition for athletes is often better calculated using measures of body fat, as determined by such techniques as skinfold measurements or underwater weighing and the limitations of manual measurement have also led to new, alternative methods to measure obesity, such as the body volume index.\n\nIt is not clear where on the BMI scale the threshold for \"overweight\" and \"obese\" should be set. Because of this the standards have varied over the past few decades. Between 1980 and 2000 the U.S. Dietary Guidelines have defined overweight at a variety of levels ranging from a BMI of 24.9 to 27.1. In 1985 the National Institutes of Health (NIH) consensus conference recommended that overweight BMI be set at a BMI of 27.8 for men and 27.3 for women.\n\nIn 1998 a NIH report concluded that a BMI over 25 is overweight and a BMI over 30 is obese. In the 1990s the World Health Organization (WHO) decided that a BMI of 25 to 30 should be considered overweight and a BMI over 30 is obese, the standards the NIH set. This became the definitive guide for determining if someone is overweight.\n\nThe current WHO and NIH ranges of \"normal\" weights are proved to be associated with decreased risks of some diseases such as diabetes type II; however using the same range of BMI for men and women is considered arbitrary, and makes the definition of underweight quite unsuitable for men.\n\nOne study found that the vast majority of people labelled 'overweight' and 'obese' according to current definitions do not in fact face any meaningful increased risk for early death. In a quantitative analysis of a number of studies, involving more than 600,000 men and women, the lowest mortality rates were found for people with BMIs between 23 and 29; most of the 25–30 range considered 'overweight' was not associated with higher risk.\n\nA study published by \"Journal of the American Medical Association\" (\"JAMA\") in 2005 showed that \"overweight\" people had a death rate similar to \"normal\" weight people as defined by BMI, while \"underweight\" and \"obese\" people had a higher death rate.\n\nA study published by \"The Lancet\" in 2009 involving 900,000 adults showed that \"overweight\" and \"underweight\" people both had a mortality rate higher than \"normal\" weight people as defined by BMI. The optimal BMI was found to be in the range of 22.5–25.\n\nHigh BMI is associated with type 2 diabetes only in persons with high serum gamma-glutamyl transpeptidase.\n\nIn an analysis of 40 studies involving 250,000 people, patients with coronary artery disease with \"normal\" BMIs were at higher risk of death from cardiovascular disease than people whose BMIs put them in the \"overweight\" range (BMI 25–29.9).\n\nOne study found that BMI had a good general correlation with body fat percentage, and noted that obesity has overtaken smoking as the world's number one cause of death. But it also notes that in the study 50% of men and 62% of women were obese according to body fat defined obesity, while only 21% of men and 31% of women were obese according to BMI, meaning that BMI was found to underestimate the number of obese subjects.\n\nA 2010 study that followed 11,000 subjects for up to eight years concluded that BMI is not a good measure for the risk of heart attack, stroke or death. A better measure was found to be the waist-to-height ratio. A 2011 study that followed 60,000 participants for up to 13 years found that waist–hip ratio was a better predictor of ischaemic heart disease mortality.\n\nBMI Prime, a modification of the BMI system, is the ratio of actual BMI to upper limit optimal BMI (currently defined at 25 kg/m), i.e., the actual BMI expressed as a proportion of upper limit optimal. The ratio of actual body weight to body weight for upper limit optimal BMI (25 kg/m) is equal to BMI Prime. BMI Prime is a dimensionless number independent of units. Individuals with BMI Prime less than 0.74 are underweight; those with between 0.74 and 1.00 have optimal weight; and those at 1.00 or greater are overweight. BMI Prime is useful clinically because it shows by what ratio (e.g. 1.36) or percentage (e.g. 136%, or 36% above) a person deviates from the maximum optimal BMI.\n\nFor instance, a person with BMI 34 kg/m has a BMI Prime of 34/25 = 1.36, and is 36% over their upper mass limit. In South East Asian and South Chinese populations (see § international variations), BMI Prime should be calculated using an upper limit BMI of 23 in the denominator instead of 25. BMI Prime allows easy comparison between populations whose upper-limit optimal BMI values differ.\n\nWaist circumference is a good indicator of visceral fat, which poses more health risks than fat elsewhere. According to the U.S. National Institutes of Health (NIH), waist circumference in excess of for men and for (non-pregnant) women, is considered to infer a high risk for type 2 diabetes, dyslipidemia, hypertension, and CVD. Waist circumference can be a better indicator of obesity-related disease risk than BMI. For example, this is the case in populations of Asian descent and older people. for men and for women has been stated to pose \"higher risk\", with the NIH figures \"even higher\".\n\nWaist-to-hip circumference ratio has also been used, but has been found to be no better than waist circumference alone, but more complicated to measure.\n\nA related indicator is waist circumference divided by height. The values indicating increased risk are: greater than 0.5 for people under 40 year of age, 0.5 to 0.6 for people aged 40–50, and greater than 0.6 for people over 50 years of age.\n\nThe Surface-based Body Shape Index (SBSI) is far more rigorous and is based upon four key measurements: the body surface area, vertical trunk circumference, waist circumference and height. Data on 11,808 subjects from the National Health and Human Nutrition Examination Surveys (NHANES) 1999–2004, showed that SBSI outperformed BMI, waist circumference, and A Body Shape Index (ABSI), an alternative to BMI.\n\nformula_2\n\nWithin some medical contexts, such as familial amyloid polyneuropathy, serum albumin is factored in to produce a modified body mass index (mBMI). The mBMI can be obtained by multiplying the BMI by serum albumin, in grams per litre.\n\n\n"}
{"id": "4789", "url": "https://en.wikipedia.org/wiki?curid=4789", "title": "Behistun Inscription", "text": "Behistun Inscription\n\nThe Behistun Inscription (also Bisotun, Bistun or Bisutun; , Old Persian: Bagastana, meaning \"the place of god\") is a multilingual inscription and large rock relief on a cliff at Mount Behistun in the Kermanshah Province of Iran, near the city of Kermanshah in western Iran. It was crucial to the decipherment of cuneiform script.\n\nAuthored by Darius the Great sometime between his coronation as king of the Persian Empire in the summer of 522 BC and his death in autumn of 486 BC, the inscription begins with a brief autobiography of Darius, including his ancestry and lineage. Later in the inscription, Darius provides a lengthy sequence of events following the deaths of Cyrus the Great and Cambyses II in which he fought nineteen battles in a period of one year (ending in December 521 BC) to put down multiple rebellions throughout the Persian Empire. The inscription states in detail that the rebellions, which had resulted from the deaths of Cyrus the Great and his son Cambyses II, were orchestrated by several impostors and their co-conspirators in various cities throughout the empire, each of whom falsely proclaimed kinghood during the upheaval following Cyrus's death.\n\nDarius the Great proclaimed himself victorious in all battles during the period of upheaval, attributing his success to the \"grace of Ahura Mazda\".\n\nThe inscription includes three versions of the same text, written in three different cuneiform script languages: Old Persian, Elamite, and Babylonian (a variety of Akkadian). The inscription is to cuneiform what the Rosetta Stone is to Egyptian hieroglyphs: the document most crucial in the decipherment of a previously lost script.\n\nThe inscription is approximately 15 metres high by 25 metres wide and 100 metres up a limestone cliff from an ancient road connecting the capitals of Babylonia and Media (Babylon and Ecbatana, respectively). The Old Persian text contains 414 lines in five columns; the Elamite text includes 593 lines in eight columns, and the Babylonian text is in 112 lines. The inscription was illustrated by a life-sized bas-relief of Darius I, the Great, holding a bow as a sign of kingship, with his left foot on the chest of a figure lying on his back before him. The supine figure is reputed to be the pretender Gaumata. Darius is attended to the left by two servants, and nine one-meter figures stand to the right, with hands tied and rope around their necks, representing conquered peoples. Faravahar floats above, giving his blessing to the king. One figure appears to have been added after the others were completed, as was Darius's beard, which is a separate block of stone attached with iron pins and lead.\n\nAfter the fall of the Persian Empire's Achaemenid Dynasty and its successors, and the lapse of Old Persian cuneiform writing into disuse, the nature of the inscription was forgotten, and fanciful explanations became the norm. For centuries, instead of being attributed to Darius I, the Great, it was believed to be from the reign of Khosrau II of Persia—one of the last Sassanid kings, who lived over 1000 years after the time of Darius I.\n\nThe inscription is mentioned by Ctesias of Cnidus, who noted its existence some time around 400 BC and mentioned a well and a garden beneath the inscription. He incorrectly concluded that the inscription had been dedicated \"by Queen Semiramis of Babylon to Zeus\". Tacitus also mentions it and includes a description of some of the long-lost ancillary monuments at the base of the cliff, including an altar to \"Herakles\". What has been recovered of them, including a statue dedicated in 148 BC, is consistent with Tacitus's description. Diodorus also writes of \"Bagistanon\" and claims it was inscribed by Semiramis.\n\nA legend began around Mount Behistun (Bisotun), as written about by the Persian poet and writer Ferdowsi in his \"Shahnameh\" (\"Book of Kings\") , about a man named Farhad, who was a lover of King Khosrow's wife, Shirin. The legend states that, exiled for his transgression, Farhad was given the task of cutting away the mountain to find water; if he succeeded, he would be given permission to marry Shirin. After many years and the removal of half the mountain, he did find water, but was informed by Khosrow that Shirin had died. He went mad, threw his axe down the hill, kissed the ground and died. It is told in the book of Khosrow and Shirin that his axe was made out of a pomegranate tree, and, where he threw the axe, a pomegranate tree grew with fruit that would cure the ill. Shirin was not dead, according to the story, and mourned upon hearing the news.\n\nIn 1598, the Englishman Robert Sherley saw the inscription during a diplomatic mission to Persia on behalf of Austria, and brought it to the attention of Western European scholars. His party incorrectly came to the conclusion that it was Christian in origin. French General Gardanne thought it showed \"Christ and his twelve apostles\", and Sir Robert Ker Porter thought it represented the Lost Tribes of Israel and Shalmaneser of Assyria. Italian explorer Pietro della Valle visited the inscription in the course of a pilgrimage in around 1621.\n\nGerman surveyor Carsten Niebuhr visited in around 1764 for Frederick V of Denmark, publishing a copy of the inscription in the account of his journeys in 1778. Niebuhr's transcriptions were used by Georg Friedrich Grotefend and others in their efforts to decipher the Old Persian cuneiform script. Grotefend had deciphered ten of the 37 symbols of Old Persian by 1802, after realizing that unlike the Semitic cuneiform scripts, Old Persian text is alphabetic and each word is separated by a vertical slanted symbol.\n\nThe Old Persian text was copied and deciphered before recovery and copying of the Elamite and Babylonian inscriptions had even been attempted, which proved to be a good deciphering strategy, since Old Persian script was easier to study due to its alphabetic nature and because the language it represents had naturally evolved via Middle Persian to the living modern Persian language dialects, and was also related to the Avestan language, used in the Zoroastrian book the \"Avesta\".\n\nIn 1835, Sir Henry Rawlinson, an officer of the British East India Company army assigned to the forces of the Shah of Iran, began studying the inscription in earnest. As the town of Bisotun's name was anglicized as \"Behistun\" at this time, the monument became known as the \"Behistun Inscription\". Despite its relative inaccessibility, Rawlinson was able to scale the cliff with the help of a local boy and copy the Old Persian inscription. The Elamite was across a chasm, and the Babylonian four meters above; both were beyond easy reach and were left for later.\n\nWith the Persian text, and with about a third of the syllabary made available to him by the work of Georg Friedrich Grotefend, Rawlinson set to work on deciphering the text. Fortunately, the first section of this text contained a list of the same Persian kings found in Herodotus but in their original Persian forms as opposed to Herodotus's Greek transliterations; for example Darius is given as the original \"Dâryavuš\" instead of the Hellenized \"Δαρειος\". By matching the names and the characters, Rawlinson deciphered the type of cuneiform used for Old Persian by 1838 and presented his results to the Royal Asiatic Society in London and the Société Asiatique in Paris.\n\nIn the interim, Rawlinson spent a brief tour of duty in Afghanistan, returning to the site in 1843. He first crossed a chasm between the Persian and Elamite scripts by bridging the gap with planks, subsequently copying the Elamite inscription. He found an enterprising local boy to climb up a crack in the cliff and suspend ropes across the Babylonian writing, so that papier-mâché casts of the inscriptions could be taken. Rawlinson, along with several other scholars, most notably Edward Hincks, Julius Oppert, William Henry Fox Talbot, and Edwin Norris, either working separately or in collaboration, eventually deciphered these inscriptions, leading eventually to the ability to read them completely.\n\nThe translation of the Old Persian sections of the Behistun Inscription paved the way to the subsequent ability to decipher the Elamite and Babylonian parts of the text, which greatly promoted the development of modern Assyriology.\n\nThe site was visited by A. V. Williams Jackson in 1903. Later expeditions, in 1904 sponsored by the British Museum and led by Leonard William King and Reginald Campbell Thompson and in 1948 by George G. Cameron of the University of Michigan, obtained photographs, casts and more accurate transcriptions of the texts, including passages that were not copied by Rawlinson.\nIt also became apparent that rainwater had dissolved some areas of the limestone in which the text was inscribed, while leaving new deposits of limestone over other areas, covering the text.\n\nIn 1938, the inscription became of interest to the Nazi German think tank Ahnenerbe, although research plans were cancelled due to the onset of World War II.\n\nThe monument later suffered some damage from Allied soldiers using it for target practice in World War II, and during the Anglo-Soviet invasion of Iran.\n\nIn 1999, Iranian archeologists began the documentation and assessment of damages to the site incurred during the 20th century. Malieh Mehdiabadi, who was project manager for the effort, described a photogrammetric process by which two-dimensional photos were taken of the inscriptions using two cameras and later transmuted into 3-D images.\n\nIn recent years, Iranian archaeologists have been undertaking conservation works. The site became a UNESCO World Heritage Site in 2006.\n\nIn 2012, the Bisotun Cultural Heritage Center organized an international effort to re-examine the inscription.\n\nThe site covers an area of 116 hectares. Archeological evidence indicates that this region became a human shelter 40,000 years ago. There are 18 historical monuments other than the inscription of Darius the Great in the Behistun complex that have been registered in the Iranian national list of historical sites. Some of them are:\n\n\n\n\n\n\n"}
{"id": "4792", "url": "https://en.wikipedia.org/wiki?curid=4792", "title": "Barry Goldwater", "text": "Barry Goldwater\n\nBarry Morris Goldwater (January 2, 1909 – May 29, 1998) was an American politician, businessman, and author who was a five-term United States Senator from Arizona (1953–65, 1969–87) and the Republican Party's nominee for President of the United States in the 1964 election. Despite losing the election by a landslide, Goldwater is the politician most often credited for sparking the resurgence of the American conservative political movement in the 1960s. He also had a substantial impact on the libertarian movement.\n\nGoldwater rejected the legacy of the New Deal and fought through the conservative coalition against the New Deal coalition. He mobilized a large conservative constituency to win the hard-fought Republican primaries. Though raised an Episcopalian, he was the first candidate with ethnically Jewish heritage to be nominated for President by a major American party (his father was Jewish). Goldwater's conservative campaign platform ultimately failed to gain the support of the electorate and he lost the 1964 presidential election to incumbent Democrat Lyndon B. Johnson, bringing down many conservative Republican office-holders as well. Jeff Fishel says, \"The conservative faction of the party was on the defensive as a result of the magnitude of the election losses.\"\n\nGoldwater returned to the Senate in 1969, and specialized in defense policy, bringing to the table his experience as a senior officer in the Air Force Reserve. In 1974, as an elder statesman of the party, Goldwater successfully urged President Richard Nixon to resign when evidence of a cover-up in the Watergate scandal became overwhelming and impeachment was imminent. By the 1980s, the increasing influence of the Christian right on the Republican Party so conflicted with Goldwater's views that he became a vocal opponent of the religious right on issues such as abortion, gay rights, and the role of religion in public life. After narrowly winning re-election to the Senate in 1980, he chose not to run for a sixth term in 1986, and was succeeded by fellow Republican John McCain. A significant accomplishment in his career was the passage of the Goldwater–Nichols Act of 1986, which restructured the higher levels of the Pentagon by placing the chain of command from the President to the Secretary of Defense directly to the commanders of the Unified Combatant Commands.\n\nGoldwater was born in Phoenix, in what was then the Arizona Territory, the son of Baron M. Goldwater and his wife, Hattie Josephine (\"JoJo\") Williams. His father's family had founded Goldwater's, a leading upscale department store in Phoenix. Goldwater's paternal grandfather, Michel Goldwasser, a Polish Jew, was born in 1821 in Poland, whence he emigrated to London following the Revolutions of 1848. Soon after arriving in London, he anglicized his name from \"Goldwasser\" to \"Goldwater\". Michel married Sarah Nathan, a member of a Jewish English family, in the Great Synagogue of London.\n\nHis father was Jewish and his mother, who was Episcopalian, came from a New England family that included the theologian Roger Williams of Rhode Island. Goldwater's parents were married in an Episcopal church in Phoenix; for his entire life, Goldwater was an Episcopalian, though on rare occasions he referred to himself as \"Jewish\". While he did not often attend church, he stated that \"If a man acts in a religious way, an ethical way, then he's really a religious man—and it doesn't have a lot to do with how often he gets inside a church\".\n\nThe family department store made the Goldwaters comfortably wealthy. Goldwater graduated from Staunton Military Academy, an elite private school in Virginia, and attended the University of Arizona for one year, where he joined the Sigma Chi fraternity. Barry had never been close to his father, but he took over the family business after Baron's death in 1930. He became a Republican (in a heavily Democratic state), promoted innovative business practices, and opposed the New Deal, especially because it fostered labor unions. Goldwater came to know former President Herbert Hoover, whose conservative politics he admired greatly.\n\nIn 1934, he married Margaret \"Peggy\" Johnson, wealthy daughter of a prominent industrialist from Muncie, Indiana. They had four children: Joanne (born January 1, 1936), Barry (born July 15, 1938), Michael (born March 15, 1940), and Peggy (born July 27, 1944). Goldwater became a widower in 1985, and in 1992 he married Susan Wechsler, a nurse 32 years his junior.\n\nGoldwater's son Barry Goldwater Jr. served as a United States House of Representatives member from California from 1969 to 1983.\n\nGoldwater's grandson, Ty Ross, a former Zoli model, is openly gay and HIV positive, and the one who inspired the elder Goldwater \"to become an octogenarian proponent of gay civil rights.\"\n\nWith the American entry into World War II, Goldwater received a reserve commission in the United States Army Air Forces. He became a pilot assigned to the Ferry Command, a newly formed unit that flew aircraft and supplies to war zones worldwide. He spent most of the war flying between the U.S. and India, via the Azores and North Africa or South America, Nigeria, and Central Africa. He also flew \"the hump\" over the Himalayas to deliver supplies to the Republic of China.\n\nFollowing World War II, Goldwater was a leading proponent of creating the United States Air Force Academy, and later served on the Academy's Board of Visitors. The visitor center at the Academy is now named in his honor. As a colonel he also founded the Arizona Air National Guard, and he would desegregate it two years before the rest of the U.S. military. Goldwater was instrumental in pushing the Pentagon to support desegregation of the armed services.\n\nRemaining in the Arizona Air National Guard and Air Force Reserve after the war, he eventually retired as a Command Pilot with the rank of major general. By that time, he had flown 165 different types of aircraft. In retirement, as an Air Force Reserve major general, he continued piloting B-52 aircraft until late in his military career. He would remind those who called him \"rash\" of the old saying that \"\"there are no old, bold pilots\"\".\n\nGoldwater ran track and cross country in high school, where he specialized in the 880 yard run. His parents strongly encouraged him to compete in these sports, to Goldwater's dismay. He often went by the nickname of \"Rolling Thunder.\"\n\nIn 1940, Goldwater became one of the first people to run the Colorado River recreationally through Grand Canyon participating as an oarsman on Norman Nevills' second commercial river trip. Goldwater joined them in Green River, Utah, and rowed his own boat down to Lake Mead.\n\nIn 1970, the Arizona Historical Foundation published the daily journal Goldwater had maintained on the Grand Canyon journey, including his photographs, in a 209-page volume titled \"Delightful Journey\".\n\nIn 1963, he joined the Arizona Society of the Sons of the American Revolution. He was also a lifetime member of the Veterans of Foreign Wars, the American Legion, and Sigma Chi fraternity. He belonged to both the York Rite and Scottish Rite of Freemasonry, and was awarded the 33rd degree in the Scottish Rite.\n\nIn a heavily Democratic state, Goldwater became a conservative Republican and a friend of Herbert Hoover. He was outspoken against New Deal liberalism, especially its close ties to labor unions he considered corrupt. A pilot, outdoorsman and photographer, he criss-crossed Arizona and developed a deep interest in both the natural and the human history of the state.\n\nHe entered Phoenix politics in 1949, when he was elected to the City Council as part of a nonpartisan team of candidates pledged to clean up widespread prostitution and gambling. The team won every mayoral and council election for the next two decades. Goldwater rebuilt the weak Republican party and was instrumental in electing Howard Pyle as Governor in 1950.\n\nAs a Republican he won a seat in the U.S. Senate in 1952, when he upset veteran Democrat and Senate Majority Leader Ernest McFarland. He won largely by defeating McFarland in his native Maricopa County by 12,600 votes, almost double the overall margin of 6,725 votes. As a measure of how Democratic Arizona had been since joining the Union 40 years earlier, Goldwater was only the second Republican ever to represent Arizona in the Senate. He defeated McFarland again in 1958, with a strong showing in his first reelection; he was the first Arizona Republican to win a second term in the Senate. Goldwater's victory was all the more remarkable since it came in a year the Democrats gained 13 seats in the Senate. He gave up re-election for the Senate in 1964 in favor of his presidential campaign.\n\nDuring his Senate career, Goldwater was regarded as the \"Grand Old Man of the Republican Party and one of the nation's most respected exponents of conservatism.\"\n\nGoldwater was outspoken about the Eisenhower Administration, calling some of the policies of the Eisenhower Administration too liberal for a Republican President. \"...Democrats delighted in pointing out that the junior senator was so headstrong that he had gone out his way to criticize the president of his own party.\" There was a Democratic majority in Congress for most of Eisenhower's career and Goldwater felt that President Dwight Eisenhower was compromising too much with Democrats in order to get legislation passed. Early on in his career as a senator for Arizona, he criticized the 71.8 billion dollar budget that President Eisenhower sent to Congress, stating \"Now, however, I am not so sure. A $71.8 billion budget not only shocks me, but it weakens my faith.\" Goldwater opposed Eisenhower's pick for Chief Justice of the Supreme Court. \"The day that Eisenhower appointed Governor Earl Warren of California as Chief Justice of the Supreme Court, Goldwater did not hesitate to express his misgivings.\" Goldwater and the Eisenhower Administration supported the integration of schools in the south, but Goldwater felt the states should choose how they wanted to integrate and should not be forced by the federal government. \"Goldwater criticized the use of federal troops. He accused the Eisenhower administration of violating the Constitution by assuming powers reserved by the states. While he agreed that under the law, every state should have integrated its schools, each state should integrate in its own way.\" There were high ranking government officials following Goldwater's critical stance on the Eisenhower Administration, even an Army General. \"Fulbright's startling revelation that military personnel were being indoctrinated with the idea that the policies of the Commander in Chief were treasonous dovetailed with the return to the news of the strange case of General Edwin Walker.\" \n\nIn 1964, Goldwater fought and won a multi-candidate race for the Republican Party's presidential nomination. His main rival was New York Governor Nelson Rockefeller, whom he defeated by a narrow margin in the California primary. Eisenhower gave his support to Goldwater when he told reporters, \"I personally believe that Goldwater is not an extremist as some people have made him, but in any event we're all Republicans.\" His nomination was opposed by liberal Republicans, who thought Goldwater's demand for rollback, defeat of the Soviet Union, would foment a nuclear war. He delivered a captivating acceptance speech. \"Instead, he devoted more care to his acceptance speech than to any other speech in his political career. And with good reason: he would deliver it to the largest and most attentive audience of his life. No other statement of the 1950s and 1960s, including \"The Conscience of a Conservative\", presents more truly Barry Goldwater's basic beliefs and his positions on current issues.\"\n\nAt the time of Goldwater's presidential candidacy, the Republican Party was split between its conservative wing (based in the West and South) and moderate/liberal wing, sometimes called Rockefeller Republicans (based in the Northeast). He alarmed even some of his fellow partisans with his brand of staunch fiscal conservatism and militant anti-communism. He was viewed by many traditional Republicans as being too far on the right wing of the political spectrum to appeal to the mainstream majority necessary to win a national election. As a result, moderate Republicans recruited a series of opponents, including New York Governor Nelson Rockefeller, Henry Cabot Lodge Jr., of Massachusetts and Pennsylvania Governor William Scranton, to challenge him. Goldwater would defeat Rockefeller in the winner-take-all California primary and secure the nomination. He also had a solid backing from Southern Republicans. A young Birmingham lawyer, John Grenier, secured commitments from 271 of 279 southern convention delegates to back Goldwater. Grenier would serve as executive director of the national GOP during the Goldwater campaign, the number 2 position to party chairman Dean Burch of Arizona.\n\nJournalist John Adams says, \"his acceptance speech was bold, reflecting his conservative views, but not irrational. Rather than shrinking from those critics who accuse him of extremism, Goldwater challenged them head-on\" in his acceptance speech at the 1964 Republican Convention. In his own words:\n\nHis paraphrase of Cicero was included at the suggestion of Harry V. Jaffa, though the speech was primarily written by Karl Hess. Because of President Johnson's popularity, Goldwater refrained from attacking the president directly. He did not mention Johnson by name at all in his convention speech.\nFormer U.S. Senator Prescott Bush, a moderate Republican from Connecticut, was a friend of Goldwater and supported him in the general election campaign. Bush's son, George H. W. Bush (then running for the Senate from Texas against Democrat Ralph Yarborough), was also a strong Goldwater supporter in both the nomination and general election campaigns.\n\nFuture Chief Justice of the United States and fellow Arizonan William H. Rehnquist also first came to the attention of national Republicans through his work as a legal adviser to Goldwater's presidential campaign. Rehnquist had begun his law practice in 1953 in the firm of Denison Kitchel of Phoenix, Goldwater's national campaign manager and friend of nearly three decades.\n\nGoldwater was painted as a dangerous figure by the Johnson campaign, which countered Goldwater's slogan \"In your heart, you know he's right\" with the lines \"In your guts, you know he's nuts\", and \"In your heart, you know he might\" (that is, he might actually use nuclear weapons as opposed to using only deterrence). Johnson himself did not mention Goldwater in his own acceptance speech at the 1964 Democratic National Convention.\n\nGoldwater's provocative advocacy of aggressive tactics to prevent the spread of communism in Asia led to effective counterattacks from Lyndon B. Johnson and his supporters, who claimed that Goldwater's militancy would have dire consequences, possibly even nuclear war. In a May 1964 speech, Goldwater suggested that nuclear weapons should be treated more like conventional weapons and used in Vietnam, specifically that they should have been used at Dien Bien Phu in 1954 to defoliate trees. Regarding Vietnam, Goldwater charged that Johnson's policy was devoid of \"goal, course, or purpose\", leaving \"only sudden death in the jungles and the slow strangulation of freedom\". Goldwater's rhetoric on nuclear war was viewed by many as quite uncompromising, a view buttressed by off-hand comments such as, \"Let's lob one into the men's room at the Kremlin.\" He also advocated that field commanders in Vietnam and Europe should be given the authority to use tactical nuclear weapons (which he called \"small conventional nuclear weapons\") without presidential confirmation.\n\nGoldwater countered the Johnson attacks by criticizing the administration for its perceived ethical lapses, and stating in a commercial that \"we, as a nation, are not far from the kind of moral decay that has brought on the fall of other nations and people... I say it is time to put conscience back in government. And by good example, put it back in all walks of American life.\" Goldwater campaign commercials included statements of support by actor Raymond Massey and moderate Republican senator Margaret Chase Smith.\n\nBefore the 1964 election, \"Fact\" magazine, published by Ralph Ginzburg, ran a special issue titled \"The Unconscious of a Conservative: A Special Issue on the Mind of Barry Goldwater\". The two main articles contended that Goldwater was mentally unfit to be president. The magazine supported this claim with the results of a poll of board-certified psychiatrists. \"Fact\" had mailed questionnaires to 12,356 psychiatrists, receiving responses from 2,417, of whom 1,189 said Goldwater was mentally incapable of holding the office of president. Most of the other respondents declined to diagnose Goldwater because they had not clinically interviewed him, but claimed that, although not psychologically unfit to preside, Goldwater would be negligent and egregious in the role.\n\nAfter the election, Goldwater sued the publisher, the editor and the magazine for libel in \"Goldwater v. Ginzburg\". \"Although the jury awarded Goldwater only $1.00 in compensatory damages against all three defendants, it went on to award him punitive damages of $25,000 against Ginzburg and $50,000 against \"Fact\" magazine, Inc.\" According to Warren Boroson, then-managing editor of \"Fact\" and now a financial columnist, the main biography of Goldwater in the magazine was written by David Bar-Illan, the Israeli pianist.\n\nA Democratic campaign advertisement known as Daisy showed a young girl counting daisy petals, from one to ten. Immediately following this scene, a voiceover counted down from ten to one. The child's face was shown as a still photograph followed by images of nuclear explosions and mushroom clouds. The campaign advertisement ended with a plea to vote for Johnson, implying that Goldwater (though not mentioned by name) would provoke a nuclear war if elected. The advertisement, which featured only a few spoken words and relied on imagery for its emotional impact, was one of the most provocative in American political campaign history, and many analysts credit it as being the birth of the modern style of \"negative political ads\" on television. The ad aired only once and was immediately pulled, but it was then shown many times by local television stations.\nGoldwater did not have ties to the Ku Klux Klan (KKK), but was publicly endorsed by members of the organization. Lyndon Johnson exploited this association during the elections, but Goldwater barred the KKK from supporting him and denounced them.\n\nPast comments came back to haunt Goldwater throughout the campaign. He had once called the Eisenhower administration \"a dime-store New Deal\", and the former president never fully forgave him. Eisenhower did, however, film a television commercial with Goldwater. Eisenhower qualified his voting for Goldwater in November by remarking that he had voted not specifically for Goldwater, but for the Republican Party. In December 1961, Goldwater had told a news conference that \"sometimes I think this country would be better off if we could just saw off the Eastern Seaboard and let it float out to sea\". That comment boomeranged on him during the campaign in the form of a Johnson television commercial, as did remarks about making Social Security voluntary, and statements in Tennessee about selling the Tennessee Valley Authority, a large local New Deal employer.\n\nThe Goldwater campaign spotlighted Ronald Reagan, who appeared in a campaign ad. In turn, Reagan gave a stirring, nationally televised speech, \"A Time for Choosing\", in support of Goldwater. The speech prompted Reagan to seek the California Governorship in 1966 and jump-started his political career. Conservative activist Phyllis Schlafly, later well known for her fight against the Equal Rights Amendment, first became known for writing a pro-Goldwater book, \"A Choice, Not an Echo\", attacking the moderate Republican establishment.\n\nGoldwater lost to President Lyndon Johnson by a landslide, pulling down the GOP, which lost many seats in both houses of Congress.\n\nGoldwater only won his home state of Arizona and five states in the Deep South, depicted in red. The Southern states, traditionally Democratic up to that time, voted Republican primarily as a statement of opposition to the Civil Rights Act, which had been passed by Johnson and the Northern Democrats, as well as the majority of Republicans in Congress, earlier that year.\n\nIn the end, Goldwater received 38% of the popular vote, and carried just six states: Arizona (with 51% of the popular vote) and the core states of the Deep South: Alabama, Georgia, Louisiana, Mississippi, and South Carolina. In carrying Georgia by a margin of 54–45%, Goldwater became the first Republican nominee to win the state. However, the overall result was the worst showing in terms of popular vote and electoral college vote for any post-World War II Republican. Indeed, he wouldn't have even carried his own state if not for a 20,000-vote margin in Maricopa County.\n\nIn all, Johnson won an overwhelming 486 electoral votes, to Goldwater's 52. Goldwater, with his customary bluntness, remarked, \"We would have lost even if Abraham Lincoln had come back and campaigned with us.\" He maintained later in life that he would have won the election if the country had not been in a state of extended grief following the assassination of John F. Kennedy, and that it was simply not ready for a third President in just 14 months.\n\nGoldwater's poor showing pulled down many supporters. Of the 57 Republican Congressmen who endorsed Goldwater before the convention, 20 were defeated for reelection, along with many promising young Republicans. On the other hand, the defeat of so many older politicians created openings for young conservatives to move up the ladder. While the loss of moderate Republicans was temporary—they were back by 1966—Goldwater also permanently pulled many conservative Southerners and white ethnics out of the New Deal Coalition.\n\nAccording to Steve Kornacki of \"Salon\", \"In the South, Goldwater broke through and won five states—the best showing in the region for a GOP candidate since Reconstruction. In Mississippi—where Franklin D. Roosevelt had won nearly 100 percent of the vote 28 years earlier—Goldwater claimed a staggering 87 percent.\" It has frequently been argued that Goldwater's strong performance in Southern states previously regarded as Democratic strongholds foreshadowed a larger shift in electoral trends in the coming decades that would make the South a Republican bastion (an end to the \"Solid South\")—first in presidential politics and eventually at the congressional and state levels, as well. Also, Goldwater's uncompromising promotion of freedom was the start of a continuing shift in American politics from liberalism to a conservative economic philosophy.\n\nGoldwater remained popular in Arizona, and in the 1968 Senate election he was elected (this time) to the seat of retiring Senator Carl Hayden. He was subsequently reelected in 1974 and 1980. The 1974 election saw Goldwater easily reelected over his Democratic opponent, Jonathan Marshall, the publisher of \"The Scottsdale Progress\". His final campaign in 1980 was close, with Goldwater winning in a near draw against Democratic challenger Bill Schulz. Goldwater said later that the close result convinced him not to run again.\n\nGoldwater seriously considered retirement in 1980 before deciding to run for reelection. Peggy Goldwater reportedly hoped that her husband's Senate term, due to end in January 1981, would be his last. Goldwater decided to run, planning to make the term his last in the Senate. Goldwater faced a surprisingly tough battle for reelection. He was viewed by some as out of touch and vulnerable for several reasons; most importantly, because he had planned to retire in 1981, Goldwater had not visited many areas of Arizona outside of Phoenix and Tucson. He was also challenged by a formidable opponent, Bill Schulz, a former Republican turned Democrat and a wealthy real estate developer. Schulz was able to infuse massive amounts of money into the campaign from his own fortune.\n\nArizona's changing population also hurt Goldwater. The state's population had soared, and a huge portion of the electorate had not lived in the state when Goldwater was previously elected; hence, many voters were less familiar with Goldwater's actual beliefs, and he was on the defensive for much of the campaign. Early returns on election night seemed to indicate that Schulz would win. The counting of votes continued through the night and into the next morning. At around daybreak, Goldwater learned that he had been reelected thanks to absentee ballots, which were among the last to be counted. Goldwater's surprisingly close victory in 1980 came despite Reagan's 61% landslide over Jimmy Carter in Arizona. Republicans regained control of the Senate, putting Goldwater in the most powerful position he ever had in the Senate.\n\nGoldwater retired in 1987, serving as chair of the Senate Intelligence and Armed Services Committees in his final term. Despite his reputation as a firebrand in the 1960s, by the end of his career he was considered a stabilizing influence in the Senate, one of the most respected members of either major party. Though Goldwater remained staunchly anti-communist and \"hawkish\" on military issues, he was a key supporter of the fight for ratification of the Panama Canal Treaty in the 1970s, which would give control of the canal zone to the Republic of Panama. His most important legislative achievement may have been the Goldwater–Nichols Act, which reorganized the U.S. military's senior-command structure.\n\nGoldwater became most associated with labor-union reform and anti-communism; he was an active supporter of the conservative coalition in Congress. His work on labor issues led to Congress passing major anti-corruption reforms in 1957, and an all-out campaign by the AFL-CIO to defeat his 1958 reelection bid. He voted against the censure of Senator Joseph McCarthy in 1954, but he never actually charged any individual with being a communist/Soviet agent. Goldwater emphasized his strong opposition to the worldwide spread of communism in his 1960 book \"The Conscience of a Conservative\". The book became an important reference text in conservative political circles.\n\nIn 1964, Goldwater ran a conservative campaign that emphasized states' rights. Goldwater's 1964 campaign was a magnet for conservatives since he opposed interference by the federal government in state affairs. Although he had supported all previous federal civil rights legislation and had supported the original senate version of the bill, Goldwater made the decision to oppose the Civil Rights Act of 1964. His stance was based on his view that the article II and article VII of the act Act interfered with the rights of private persons to do or not to do business with whomever they chose and believed that the private employment provisions of the Act would lead to racial quotas. In the segregated city of Phoenix in the 1950s, he had quietly supported civil rights for blacks, but would not let his name be used.\n\nAll this appealed to white Southern Democrats, and Goldwater was the first Republican to win the electoral votes of all of the Deep South states (South Carolina, Georgia, Alabama, Mississippi and Louisiana) since Reconstruction (although Dwight Eisenhower did carry Louisiana in 1956). However, Goldwater's vote on the Civil Rights Act proved devastating to his campaign everywhere outside the South (besides Dixie, Goldwater won only in Arizona, his home state), contributing to his landslide defeat in 1964.\n\nWhile Goldwater had been depicted by his opponents in the Republican primaries as a representative of a conservative philosophy that was extreme and alien, his voting records show that his positions were in harmony with those of his fellow Republicans in the Congress. What distinguished him from his predecessors was, according to Hans J. Morgenthau, his firmness of principle and determination, which did not allow him to be content with mere rhetoric.\n\nGoldwater fought in 1971 to stop U.S. funding of the United Nations after the People's Republic of China was admitted to the organization. He said:\nGoldwater was grief-stricken by the assassination of Kennedy and was greatly disappointed that his opponent in 1964 would not be Kennedy but instead his Vice President, former Senate Majority Leader Lyndon B. Johnson of Texas. Goldwater disliked Johnson (saying he \"used every dirty trick in the bag\"), and Richard M. Nixon of California (whom he later called \"the most dishonest individual I have ever met in my life\"). After Goldwater again became a senator, he urged Nixon to resign at the height of the Watergate scandal, warning that fewer than ten senators would vote against conviction if Nixon were impeached by the House of Representatives. The term \"Goldwater moment\" has since been used to describe situations when influential members of Congress disagree so strongly with a president from their own party that they openly oppose him.\n\nAlthough Goldwater was not as important in the American conservative movement as Ronald Reagan after 1965, he shaped and redefined the movement from the late 1950s to 1964. Arizona Senator John McCain, who had succeeded Goldwater in the Senate in 1987, summed up Goldwater's legacy, \"He transformed the Republican Party from an Eastern elitist organization to the breeding ground for the election of Ronald Reagan.\" Columnist George Will remarked after the 1980 Presidential election that it took 16 years to count the votes from 1964 and Goldwater won.\n\nThe Republican Party recovered from the 1964 election debacle, picking up 47 seats in the House of Representatives in the 1966 mid-term election. Further Republican successes ensued, including Goldwater's return to the Senate in 1969. In January of that year, Goldwater wrote an article in the \"National Review\" \"affirming that he [was] not against liberals, that liberals are needed as a counterweight to conservatism, and that he had in mind a fine liberal like Max Lerner\".\n\nGoldwater was a strong supporter of the environment. He explained his position in 1969:\nThroughout the 1970s, as the conservative wing under Reagan gained control of the party, Goldwater concentrated on his Senate duties, especially in military affairs. He played little part in the election or administration of Richard Nixon, but he helped force Nixon's resignation in 1974. In 1976 he helped block Rockefeller's renomination as vice president. When Reagan challenged Ford for the presidential nomination in 1976, Goldwater endorsed Ford, looking for consensus rather than conservative idealism. As one historian notes, \"The Arizonan had lost much of his zest for battle.\"\n\nIn 1979, when President Carter normalized relations with Communist China, Goldwater and some other senators sued him in the Supreme Court, arguing that the president could not terminate the Sino-American Mutual Defense Treaty with Republic of China (Taiwan) without the approval of Congress. The case, \"Goldwater v. Carter\" 444 U.S. 996, was dismissed by the court as a political question.\n\nBy the 1980s, with Ronald Reagan as president and the growing involvement of the religious right in conservative politics, Goldwater's libertarian views on personal issues were revealed; he believed that they were an integral part of true conservatism. Goldwater viewed abortion as a matter of personal choice and as such supported abortion rights.\n\nAs a passionate defender of personal liberty, he saw the religious right's views as an encroachment on personal privacy and individual liberties. In his 1980 Senate reelection campaign, Goldwater won support from religious conservatives but in his final term voted consistently to uphold legalized abortion and, in 1981, gave a speech on how he was angry about the bullying of American politicians by religious organizations, and would \"fight them every step of the way\". Goldwater also disagreed with the Reagan administration on certain aspects of foreign policy (for example, he opposed the decision to mine Nicaraguan harbors). Notwithstanding his prior differences with Dwight D. Eisenhower, Goldwater in a 1986 interview rated him the best of the seven Presidents with whom he had worked.\n\nHe introduced the 1984 Cable Franchise Policy and Communications Act, which allowed local governments to require the transmission of public, educational, and government access (PEG) channels, barred cable operators from exercising editorial control over content of programs carried on PEG channels, and absolved them from liability for their content.\n\nOn May 12, 1986, Goldwater was presented with the Presidential Medal of Freedom by President Ronald Reagan.\n\nAfter his retirement in 1987, Goldwater described the Arizona Governor Evan Mecham as \"hardheaded\" and called on him to resign, and two years later stated that the Republican party had been taken over by a \"bunch of kooks\".\n\nHe is a 1987 recipient of the Langley Gold Medal from the Smithsonian Institution. In 1988, in recognition of his career, Princeton University's American Whig-Cliosophic Society awarded Goldwater the James Madison Award for Distinguished Public Service.\n\nIn a 1994 interview with \"The Washington Post\", the retired senator said,\n\nGoldwater visited the small town of Bowen, Illinois, in 1989 to see where his mother was raised.\n\nIn response to Moral Majority founder Jerry Falwell's opposition to the nomination of Sandra Day O'Connor to the Supreme Court, of which Falwell had said, \"Every good Christian should be concerned\", Goldwater retorted: \"Every good Christian ought to kick Falwell right in the ass.\" (According to John Dean, Goldwater actually suggested that good Christians ought to kick Falwell in the \"nuts\", but the news media \"changed the anatomical reference.\") Goldwater also had harsh words for his one-time political protegé, President Reagan, particularly after the Iran–Contra Affair became public in 1986. Journalist Robert MacNeil, a friend of Goldwater's from the 1964 Presidential campaign, recalled interviewing him in his office shortly afterward. \"He was sitting in his office with his hands on his cane... and he said to me, 'Well, aren't you going to ask me about the Iran arms sales?' It had just been announced that the Reagan administration had sold arms to Iran. And I said, 'Well, if I asked you, what would you say?' He said, 'I'd say it's the god-damned stupidest foreign policy blunder this country's ever made!'\", though aside from the Iran–Contra scandal, Goldwater thought nonetheless that Reagan was a good president. In 1988 during that year's presidential campaign, he pointedly told vice-presidential nominee Dan Quayle at a campaign event in Arizona \"I want you to go back and tell George Bush to start talking about the issues.\"\n\nSome of Goldwater's statements in the 1990s alienated many social conservatives. He endorsed Democrat Karan English in an Arizona congressional race, urged Republicans to lay off Bill Clinton over the Whitewater scandal, and criticized the military's ban on homosexuals: He said that \"Everyone knows that gays have served honorably in the military since at least the time of Julius Caesar\" and that \"You don't need to be 'straight' to fight and die for your country. You just need to shoot straight.\" A few years before his death he addressed establishment Republicans by saying, \"Do not associate my name with anything you do. You are extremists, and you've hurt the Republican party much more than the Democrats have.\"\n\nIn 1996, he told Bob Dole, whose own presidential campaign received lukewarm support from conservative Republicans: \"We're the new liberals of the Republican party. Can you imagine that?\" In that same year, with Senator Dennis DeConcini, Goldwater endorsed an Arizona initiative to legalize medical marijuana against the countervailing opinion of social conservatives.\n\nGoldwater was an avid amateur radio operator from the early 1920s onwards, with the call signs 6BPI, K3UIG and K7UGA. The last is now used by an Arizona club honoring him as a commemorative call. During the Vietnam War he was a Military Affiliate Radio System (MARS) operator.\n\nGoldwater was a prominent spokesman for amateur radio and its enthusiasts. Beginning in 1969 up to his death he appeared in numerous educational and promotional films (and later videos) about the hobby that were produced for the American Radio Relay League (the United States national society representing the interests of radio amateurs) by such producers as Dave Bell (W6AQ), ARRL Southwest Director John R. Griggs (W6KW), Alan Kaul (W6RCL), Forrest Oden (N6ENV), and the late Roy Neal (K6DUE). His first appearance was in Dave Bell's \"The World of Amateur Radio\" where Goldwater discussed the history of the hobby and demonstrated a live contact with Antarctica. His last on-screen appearance dealing with \"ham radio\" was in 1994, explaining a then-upcoming, Earth-orbiting ham radio relay satellite.\n\nElectronics was a hobby for Goldwater beyond amateur radio. He enjoyed assembling Heathkits, completing more than 100 and often visiting their maker in Benton Harbor, Michigan, to buy more, before the company exited the kit business in 1992.\n\nIn 1916, Goldwater visited the Hopi Reservation with Phoenix architect John Rinker Kibby, and obtained his first kachina doll. Eventually his doll collection included 437 items and was presented in 1969 to the Heard Museum in Phoenix.\n\nGoldwater was an amateur photographer and in his estate left some 15,000 of his images to three Arizona institutions. He was very keen on candid photography. He got started in photography after receiving a camera as a gift from his wife on their first Christmas together. He was known to use a 4×5 Graflex, Rolleiflex, 16 mm Bell and Howell motion picture camera, and 35 mm Nikkormat FT. He was a member of the Royal Photographic Society from 1941 becoming a Life Member in 1948.\n\nFor decades, he contributed photographs of his home state to \"Arizona Highways\" and was best known for his Western landscapes and pictures of native Americans in the United States. Three books with his photographs are \"People and Places\", from 1967; \"Barry Goldwater and the Southwest\", from 1976; and \"Delightful Journey\", first published in 1940 and reprinted in 1970. Ansel Adams wrote a foreword to the 1976 book.\n\nGoldwater's photography interests occasionally crossed over with his political career. John F. Kennedy, as president, was known to invite former congressional colleagues to the White House for a drink. On one occasion, Goldwater brought his camera and photographed President Kennedy. When Kennedy received the photo, he returned it to Goldwater, with the inscription, \"For Barry Goldwater—Whom I urge to follow the career for which he has shown such talent—photography!—from his friend – John Kennedy.\" This quip became a classic of American political humor after it was made famous by humorist Bennett Cerf. The photo itself was prized by Goldwater for the rest of his life, and recently sold for $17,925 in a Heritage auction.\n\nSon Michael Prescott Goldwater formed the Goldwater Family Foundation with the goal of making his father's photography available via the internet. (\"Barry Goldwater Photographs\") was launched in September 2006 to coincide with the HBO documentary \"Mr. Conservative\", produced by granddaughter CC Goldwater.\n\nOn March 28, 1975, Goldwater wrote to Shlomo Arnon: \"The subject of UFOs has interested me for some long time. About ten or twelve years ago I made an effort to find out what was in the building at Wright-Patterson Air Force Base where the information has been stored that has been collected by the Air Force, and I was understandably denied this request. It is still classified above Top Secret.\" Goldwater further wrote that there were rumors the evidence would be released, and that he was \"just as anxious to see this material as you are, and I hope we will not have to wait much longer.\"\n\nThe April 25, 1988, issue of \"The New Yorker\" carried an interview where Goldwater said he repeatedly asked his friend, General Curtis LeMay, if there was any truth to the rumors that UFO evidence was stored in a secret room at Wright-Patterson Air Force Base, and if he (Goldwater) might have access to the room. According to Goldwater, an angry LeMay gave him \"holy hell\" and said, \"Not only can't you get into it but don't you ever mention it to me again.\"\n\nIn a 1988 interview on Larry King's radio show, Goldwater was asked if he thought the U.S. Government was withholding UFO evidence; he replied \"Yes, I do.\" He added:\nThe Barry M. Goldwater Scholarship and Excellence in Education Program was established by Congress in 1986. Its goal is to provide a continuing source of highly qualified scientists, mathematicians, and engineers by awarding scholarships to college students who intend to pursue careers in these fields.\n\nThe Scholarship is widely considered the most prestigious award in the U.S. conferred upon undergraduates studying the sciences. It is awarded to about 300 students (college sophomores and juniors) nationwide in the amount of $7500 per academic year (for their senior year, or junior and senior years). It honors Goldwater's keen interest in science and technology.\n\nGoldwater's public appearances ended in late 1996 after he suffered a massive stroke; family members then disclosed he was in the early stages of Alzheimer's disease. He died on May 29, 1998, at the age of 89 at his long-time home in Paradise Valley, Arizona, of complications from the stroke. His funeral was co-officiated by both a reverend and a rabbi. His ashes were buried at the Episcopal Christ Church of the Ascension in Paradise Valley, Arizona. A memorial statue set in a small park has been erected to honor the memory of Goldwater in that town, near his former home and current resting place.\n\nAmong the buildings and monuments named after Barry Goldwater are: the Barry M. Goldwater Terminal at Phoenix Sky Harbor International Airport, Goldwater Memorial Park in Paradise Valley, Arizona, the Barry Goldwater Air Force Academy Visitor Center at the United States Air Force Academy, and Barry Goldwater High School in northern Phoenix. In 2010 former Arizona Attorney General Grant Woods, himself a Goldwater scholar and supporter, founded the Goldwater Women's Tennis Classic Tournament to be held annually at the Phoenix Country Club in Phoenix. On February 11, 2015, a statue, sculpted by Deborah Copenhaver Fellows, of Goldwater was unveiled by U.S. House and Senate leaders at a dedication ceremony in National Statuary Hall of the U.S. Capitol building in Washington, D.C.\n\nGoldwater's granddaughter, CC Goldwater, has co-produced with longtime friend and independent film producer Tani L. Cohen a documentary on Goldwater's life, \"Mr. Conservative: Goldwater on Goldwater\", first shown on HBO on September 18, 2006.\n\nIn the \"Batman\" TV series episodes \"Hizzonner the Penguin\" and \"Dizzoner the Penguin,\" first aired on November 2, 1966 and November 3, 1966, respectively, Batman runs for Mayor of Gotham City against The Penguin. One of the other candidates in the race is \"Harry Goldwinner,\" a monarchist candidate who receives 2% in the polls, because he is supported by \"two old ladies.\"\n\nGoldwater was an occasional roaster on the Dean Martin roasts of the mid-1970s.\n\nIn his song \"I Shall Be Free No. 10\", Bob Dylan refers to Goldwater: \"I'm liberal to a degree, I want everybody to be free. But if you think I'll let Barry Goldwater move in next door and marry my daughter, you must think I'm crazy.\"\n\n\n\n\nGoldwater's son, Barry Goldwater Jr., served as a Congressman from California from 1969 to 1983. He was the first Congressman to serve while having a father in the Senate. Goldwater's nephew, Don Goldwater, sought the Arizona Republican Party nomination for Governor of Arizona in 2006, but was defeated by Len Munsil.\n\n\n\n\n \n"}
{"id": "4794", "url": "https://en.wikipedia.org/wiki?curid=4794", "title": "Baralong incidents", "text": "Baralong incidents\n\nThe Baralong incidents were naval engagements of the First World War in August and September 1915, involving the Royal Navy Q-ship , later renamed HMS \"Wyandra\", and two German U-boats.\n\n\"Baralong\" sank , which had been preparing to sink a nearby merchant ship, the \"Nicosian\". About a dozen of the crewmen managed to escape from the sinking submarine, and Lieutenant Godfrey Herbert, commanding officer of \"Baralong\", ordered the surviving sailors to be summarily executed after they boarded the \"Nicosian\". All the survivors of \"U-27\"s sinking, including several who had reached the \"Nicosian\", were shot by \"Baralong\"s crew. Later, \"Baralong\" sank in an incident which has also been described as a war crime.\n\nAfter the sinking of by a German submarine in May 1915, Lieutenant-Commander Godfrey Herbert, commanding officer of \"Baralong\", was visited by two officers of the Admiralty's Secret Service branch at the naval base at Queenstown, Ireland. He was told, \"This \"Lusitania\" business is shocking. Unofficially, we are telling you... take no prisoners from U-boats.\"\n\nInterviews with his subordinate officers have established Herbert's undisciplined manner of commanding his ship. Herbert allowed his men to engage in drunken binges during shore leave. During one such incident, at Dartmouth, several members of \"Baralong\"s crew were arrested after destroying a local saloon. Herbert paid their bail, then left port with the indicted crewmen aboard. Beginning in April 1915, Herbert ordered his subordinates to cease calling him \"Sir\", and to address him only by the pseudonym \"Captain William McBride.\"\n\nThroughout the summer of 1915, \"Baralong\" continued routine patrol duties in the Irish Sea without encountering the enemy.\n\nOn 19 August 1915, sank the White Star Liner with the loss of 44 lives - this included three Americans and led to a diplomatic incident between Germany and the U.S. \"Baralong\" had been about from the scene, and had received a distress call from the ship. \"Baralong\"s crew was infuriated by the attack and by their inability to locate survivors.\n\nMeanwhile, about south of Queenstown, , commanded by \"Kapitänleutnant\" Bernd Wegener, stopped the British steamer \"Nicosian\" in accordance with the rules laid down by the London Declaration. A boarding party of six men from \"U-27\" discovered that \"Nicosian\" was carrying munitions and 250 American mules earmarked for the British Army in France. The Germans allowed the freighter's crew and passengers to board lifeboats, and prepared to sink the freighter with the U-boat's deck gun.\n\n\"U-27\" was lying off \"Nicosian\"s port quarter and firing into it when \"Baralong\" appeared on the scene, flying the ensign of the United States as a false flag. When she was half a mile away, \"Baralong\" ran up a signal flag indicating that she was going to rescue \"Nicosian\"s crew. Wegener acknowledged the signal, then ordered his men to cease firing, and took \"U-27\" along the port side of \"Nicosian\" to intercept \"Baralong\". As the submarine disappeared behind the steamship, Herbert steered \"Baralong\" on a parallel course along \"Nicosian\"s starboard side.\n\nBefore \"U-27\" came round \"Nicosian\"s bow, \"Baralong\" hauled down the American flag, hoisted the Royal Navy's White Ensign, and unmasked her guns. As \"U-27\" came into view from behind \"Nicosian\", \"Baralong\" opened fire with her three 12-pounder guns at a range of , firing 34 rounds for only a single shot from the submarine. \"U-27\" rolled over and began to sink.\n\nAccording to Tony Bridgland; \"Herbert screamed, 'Cease fire!' But his men's blood was up. They were avenging the \"Arabic\" and the \"Lusitania\". For them this was no time to cease firing, even as the survivors of the crew appeared on the outer casing, struggling out of their clothes to swim away from her. There was a mighty hiss of compressed air from her tanks and the \"U-27\" vanished from sight in a vortex of giant rumbling bubbles, leaving a pall of smoke over the spot where she had been. It had taken only a few minutes to fire the thirty-four shells into her.\"\n\nMeanwhile, \"Nicosian\"s crew were cheering wildly from the lifeboats. Captain Manning was heard to yell, \"If any of those bastard Huns come up, lads, hit 'em with an oar!\"\n\nTwelve men survived the sinking of the submarine: the crews of her two deck guns and those who had been on the conning tower. They swam to \"Nicosian\" and attempted to join the six-man boarding party by climbing up her hanging lifeboat falls and pilot ladder. Herbert, worried that they might try to scuttle the steamer, ordered his men to open fire with small arms, killing all in the water. Wegener is described by some accounts as being shot while trying to swim to the \"Baralong\".\n\nHerbert sent \"Baralong\"s 12 Royal Marines, under the command of a Corporal Collins, to find the surviving German sailors aboard \"Nicosian\". As they departed, Herbert told Collins, \"Take no prisoners.\" The Germans were discovered in the engine room and shot on sight. According to Sub-Lieutenant Gordon Steele: \"Wegener ran to a cabin on the upper deck -- I later found out it was Manning's bathroom. The marines broke down the door with the butts of their rifles, but Wegener squeezes through a scuttle and dropped into the sea. He still had his life-jacket on and put up his arms in surrender. Corporal Collins, however, took aim and shot him through the head.\" Corporal Collins later recalled that, after Wegener's death, Herbert threw a revolver in the German captain's face and screamed, \"What about the \"Lusitania\", you bastard!\" An alternative account says that the Germans who boarded \"Nicosian\" were killed by the freighter's engine room staff; this report apparently came from the officer in command of the muleteers.\n\nIn Herbert's report to the Admiralty, he stated he feared the survivors from the U-boat's crew would board the freighter and scuttle her, so he ordered the Royal Marines on his ship to shoot the survivors. If they had scuttled the freighter, it could have been counted as negligence on the part of Herbert. Moments before \"Baralong\" began her attack, the submarine was firing on the freighter. It is not known if the escaping sailors actually intended to scuttle the freighter.\n\nThe Admiralty, upon receiving Herbert's report, immediately ordered its suppression, but the strict censorship imposed on the event failed when Americans who had witnessed the incident from \"Nicosian\"s lifeboats spoke to newspaper reporters after their return to the United States.\n\nThe German government delivered a memorandum on the incident via the American ambassador in Berlin, who received it on 6 December 1915. In it, they cited six US citizens as witnesses, stating they had made sworn depositions regarding the incident before public notaries in the US.\n\nThe statements said that five survivors from \"U-27\" managed to board \"Nicosian\", while the rest were shot and killed on Herbert's orders while clinging to the merchant vessel's lifeboat falls. It was further stated that when Herbert ordered his Marines to board \"Nicosian\", he gave the order \"take no prisoners\". Four German sailors were found in \"Nicosian\"s engine room and propeller shaft tunnel, and were killed. According to the witness statements, \"U-27\"s commander was shot while swimming towards \"Baralong\".\n\nThe memorandum demanded that the captain and crew of \"Baralong\" be tried for the murder of unarmed German sailors, threatening to \"take the serious decision of retribution for an unpunished crime\". Sir Edward Grey replied through the American ambassador that the incident could be grouped together with the Germans' sinking of SS \"Arabic\", their attack on a stranded British submarine on the neutral Dutch coast, and their attack on the steamship \"Ruel\", and suggested that they be placed before a tribunal composed of US Navy officers.\n\nA debate took place in the Reichstag on 15 January 1916, where the incident was described as a \"cowardly murder\" and Grey's note as being \"full of insolence and arrogance\". It was announced that reprisals had been decided, but not what form they would take.\n\nMeanwhile, the Military Bureau for the Investigation of Violations of the Laws of War\", () added \"Baralong\"'s commander, whose name was known only as \"Captain William McBride\", to the Prussian Ministry of War's \"Black List of Englishmen who are Guilty of Violations of the Laws of War vis a vis Members of the German Armed Forces.\"\n\n\"HMS Baralong\"s actions led the \"Kaiserliche Marine\" to cease adhering to the Prize Rules and to practise unrestricted submarine warfare. During the Second World War, it was cited as a reason for the \"Kriegsmarine\" to do the same. A German medal was issued commemorating the event.\n\nAs a precaution to protect the ships against any reprisals against their crews, HMS \"Wyandra\" was transferred to the Mediterranean, and took the name of sister ship \"Manica\", while \"Baralong\"s name was deleted from \"Lloyd's Register\". \"Nicosian\" was renamed \"Nevisian\", and the crew was issued new Discharge Books, with the voyage omitted.\n\n\"Baralong\"s crew were later awarded £185 prize bounty for sinking \"U-27\".\n\nOn 24 September 1915, \"Baralong\" sank the U-boat , for which her commanding officer at the time, Lieutenant-Commander A. Wilmot-Smith, was later awarded £170 prize bounty.\n\n\"U-41\" was in the process of sinking SS \"Urbino\" with gunfire when \"Baralong\" arrived on the scene, flying an American flag. When \"U-41\" surfaced near \"Baralong\", the latter opened fire while continuing to fly the American flag, and sank the U-boat.\n\nUnlike the neutral Americans in the first incident, the only witnesses to the second attack were the German and British sailors present. \"Oberleutnant zur See\" Iwan Crompton, after returning to Germany from a prisoner-of-war camp, reported that \"Baralong\" had run down the lifeboat he was in; he leapt clear and was shortly after taken aboard \"Baralong\". The British crew denied that they had run down the lifeboat. Crompton later published an account of \"U-41\"s exploits in 1917, \"U-41: der zweite Baralong-Fall\", which called the sinking of \"U-41\" a \"second Baralong case\".\n\nThe event was also commemorated in a propaganda medal designed by the German engraver Karl Goetz. This was one of many medals that were popular in Germany from around 1910 to 1940.\n\n\n"}
{"id": "4795", "url": "https://en.wikipedia.org/wiki?curid=4795", "title": "Banda", "text": "Banda\n\nBanda may refer to:\n\n\n\n\n\n\n"}
{"id": "4796", "url": "https://en.wikipedia.org/wiki?curid=4796", "title": "Bladder (disambiguation)", "text": "Bladder (disambiguation)\n\nBladder often refers to the urinary bladder, which collects urine for excretion in animals.\n\nBladder may also refer to:\n\n\n\n"}
{"id": "4797", "url": "https://en.wikipedia.org/wiki?curid=4797", "title": "Bob Young (businessman)", "text": "Bob Young (businessman)\n\nRobert Young is a serial entrepreneur who is best known for founding Red Hat Inc., the open source software company. He also owns the franchise for the Hamilton Tiger-Cats of the Canadian Football League and serves as self-appointed Caretaker of the team. He was born in Hamilton, Ontario, Canada. He attended Trinity College School in Port Hope, Ontario. He received a Bachelor of Arts from Victoria College at the University of Toronto.\n\nPrior to Red Hat, Young built a couple of computer rental and leasing businesses, including founding Vernon Computer Rentals in 1984.[2] Descendants of Vernon are still operating under that name. After leaving Vernon, Young founded the ACC Corp Inc. in 1993.\n\nMarc Ewing and Young co-founded open-source software company Red Hat (NYSE: RHT). Red Hat is now a member of the S&P 500 Index. Marc Ewing and Young's partnership started in 1994 when ACC acquired the Red Hat trademarks from Ewing. In early 1995, ACC changed its name to Red Hat Software, which has subsequently been shortened to simply Red Hat, Inc. Young served as Red Hat's CEO until 1999.\n\nIn 2002, Young founded Lulu.com, a print-on-demand, self-publishing company, and served as CEO. In 2006, Young established the Lulu Blooker Prize, a book prize for books that began as blogs. He launched the prize partly as a means to promote Lulu.\n\nYoung served as CEO of PrecisionHawk, a commercial drone technology company, from 2015 to 2017. Prior to being named PrecisionHawk's CEO in 2015, he was an early investor in the company. He continues to serve on its board as Chairman.\n\nYoung also co-founded Linux Journal in 1994, and in 2003, he purchased the Hamilton Tiger-Cats, a Canadian Football League franchise.\n\nYoung focuses his philanthropic efforts on access to information and advancement of knowledge. In 1999, he co-founded The Center for the Public Domain. Young has supported the Creative Commons, Public Knowledge.org, the Dictionary of Old English, Loran Scholarship Foundation, ibiblio.org, and the NCSU eGames,among others.\n\n"}
{"id": "4800", "url": "https://en.wikipedia.org/wiki?curid=4800", "title": "Babylon 5", "text": "Babylon 5\n\nBabylon 5 is an American science fiction television series created by writer and producer J. Michael Straczynski, under the Babylonian Productions label, in association with Straczynski's Synthetic Worlds Ltd. and Warner Bros. Domestic Television. After the successful airing of a test pilot movie on February 22, 1993, \"\", in May 1993 Warner Brothers commissioned the series for production as part of its Prime Time Entertainment Network (PTEN).\n\nThe first season premiered in the US on January 26, 1994, and the series ultimately ran for the intended five seasons. Describing it as having \"always been conceived as, fundamentally, a five year story, a novel for television\", Straczynski wrote 92 of the 110 episodes, and served as executive producer, along with Douglas Netter.\n\nSet between the years 2257 and 2262, it depicts a future where Earth has sovereign states, and a unifying Earth government. Colonies within the solar system, and beyond, make up the Earth Alliance, and contact has been made with other spacefaring species. The ensemble cast portray alien ambassadorial staff and humans assigned to the -long \"Babylon 5\" space station, a center for trade and diplomacy. Described as \"one of the most complex programs on television\", the various story arcs drew upon the prophesies, religious zealotry, racial tensions, social pressures, and political rivalries which existed within each of their cultures, to create a contextual framework for the motivations and consequences of the protagonists' actions. With a strong emphasis on character development set against a backdrop of conflicting ideologies on multiple levels, Straczynski wanted \"to take an adult approach to SF, and attempt to do for television SF what \"Hill Street Blues\" did for cop shows.\"\n\nGenerally viewed as having \"launched the new era of television CGI visual effects\", it received multiple awards during its initial run, including two consecutive Hugo Awards for best dramatic presentation, and continues to regularly feature prominently in various polls and listings highlighting top-rated science fiction series. Not appearing on American television since 2003, it continues to be shown in international markets such as Fox in the UK, the TV4-ScifFi Channel in Sweden, and the FBC TV channel in Fiji. Initially written by Straczynski, DC began publishing Babylon 5 comics in 1994, with stories that closely tied in with events depicted in the show, with events in the comics eventually being referenced onscreen in the actual television series. The franchise continued to expand into short stories, RPG's, and novels, with the Technomage trilogy of books being the last to be published in 2001, shortly after the spin-off television series, \"Crusade\", was cancelled. Excepting movie rights, which are retained by Straczynski, all production rights for the franchise are owned by Warner Bros.\n\nAt the beginning of the series, five dominant civilizations (the Humans, Minbari, Narn, Centauri, and the Vorlons) are presented. \"The Shadows\" and their various allies are malevolent species who appear later in the series. Several dozen less powerful species from the League of Non-Aligned Worlds appear, including the Drazi, Brakiri, Vree, Markab, and pak'ma'ra. The station's first three predecessors (the original \"Babylon\" station, \"Babylon 2\" and \"Babylon 3\") were sabotaged or accidentally destroyed before their completion. The fourth station, \"Babylon 4\", vanished without a trace twenty-four hours after it became fully operational.\n\nThe television series takes its name from the \"Babylon 5\" space station, located in the Epsilon Eridani star system, at the fifth Lagrangian point between the fictional planet Epsilon III and its moon. \"Babylon 5\" is an O'Neill cylinder five miles long and a half-mile to a mile in diameter. Living areas accommodate the various alien species, providing differing atmospheres and gravities. Human visitors to the alien sectors are shown using breathing equipment and other measures to tolerate the conditions.\n\nThe five seasons of the series each correspond to one fictional sequential year in the period 2258–2262. Each season shares its name with an episode that is central to that season's plot. As the series starts, the \"Babylon 5\" station is welcoming ambassadors from various races in the galaxy. Earth has just barely survived an accidental war with the much more powerful Minbari, who, despite their superior technology, mysteriously surrendered at the brink of the destruction of the human race during the Battle of the Line.\n\nDuring 2258, Commander Jeffrey Sinclair is in charge of the station. Much of the story revolves around his gradual discovery that it was his capture by the Minbari at the Battle of the Line which ended the war against Earth. Upon capturing Sinclair, the Minbari came to believe that he was the reincarnation of Valen, a great Minbari leader and hero of the last Minbari-Shadow war. Inferring that others of their species had been and were continuing to be reborn as humans, and in obedience to the edict that Minbari do not kill one another lest they harm the soul, they stopped the war just as Earth's final defenses were on the verge of collapse.\n\nMeanwhile, tensions between the Centauri Republic, which is an empire in decline, and the Narn Regime, a former dominion which rebelled and gained freedom, are increasing. Ambassador G'Kar of the Narn wishes for his people to strike back at the Centauri for what they did, and Ambassador Londo Mollari of the Centauri wishes for his people to become again the great empire they once were. As part of these struggles, Mollari makes a deal with a mysterious ally to strike back at the Narn, further heightening tensions.\n\nIt is gradually revealed that Ambassador Delenn is a member of the mysterious and powerful Grey Council, the ruling body of the Minbari. Towards the end of 2258, she begins the transformation into a Minbari/human hybrid, ostensibly to build a bridge between the humans and Minbari. The year ends with the death of Earth Alliance president Luis Santiago. The death is officially ruled an accident, but some members of the military, including the staff of \"Babylon 5\", believe it to be an assassination.\n\nAt the beginning of 2259, Captain John Sheridan replaces Sinclair as the military governor of the station after Sinclair is reassigned as ambassador to Minbar. He and the command staff gradually learn that the assassination of President Santiago was arranged by his then-Vice President, Morgan Clark, who has now become president. Conflict develops between the \"Babylon 5\" command staff and the Psi Corps, an increasingly autocratic organization which oversees and controls the lives of human telepaths.\n\nThe Shadows, an ancient and extremely powerful race who have recently emerged from hibernation, are revealed to be the cause of a variety of mysterious and disturbing events, including the attack on the Narn outpost at the end of 2258. Centauri Ambassador Londo Mollari unknowingly enlists their aid through his association with their mysterious human representative Mr. Morden in the ongoing conflict with the Narn. The elderly and ailing Centauri emperor, long an advocate of reconciliation with the Narn, unfortunately has insufficient control to prevent others from instigating war against the Narn Regime. When the emperor dies suddenly during a peace mission to \"Babylon 5\", a number of conspirators, including Ambassador Londo Mollari and Lord Refa, take control of the Centauri government by assassinating their opponents and placing the late emperor's unstable nephew on the throne. Their first act is to start open aggression against the Narn. After a full-scale war breaks out, the Centauri with the help of the Shadows through Londo eventually conquer Narn in a brutal attack involving mass drivers, outlawed weapons of mass destruction. Towards the end of the year, the Clark administration begins to show increasingly totalitarian characteristics, clamping down on dissent and restricting freedom of speech. The Vorlons are revealed to be the basis of legends about angels on various worlds, including Earth, and are the ancient enemies of the Shadows. They enlist the aid of Sheridan and the \"Babylon 5\" command staff in the struggle against the Shadows.\n\nThe Psi Corps and President Clark, whose government has discovered Shadow vessels buried in Earth's solar system, begin to harness the vessels' advanced technology. The Clark administration continues to become increasingly xenophobic and totalitarian, and gradually develops an Orwellian government style, including an organization called Night Watch which targets citizens who hold views contrary to those of Clark's regime.\n\nSheridan and Delenn's \"conspiracy of light\" works to uncover clues about how to defeat the Shadows. During a mission near Ganymede, one of the moons of Jupiter, their ship is seen by the Earth Alliance destroyer \"Agamemnon\", but not recognized. Though they escape and no shots were fired in the encounter, President Clark uses it as an excuse to declare martial law. This triggers a war of independence on Mars, which had long had a strained political relationship with Earth. \"Babylon 5\" attempts to avoid conflict with Earth, but in response to civilian bombings on Mars, concerns with Night Watch, and illegal orders meant to oppress their populations, they choose to declare independence from Earth, along with several other outlying Earth Alliance colonies including Orion VII and Proxima III. In response, the Earth Alliance attempts to retake \"Babylon 5\" by force, but with the aid of the Minbari, who have allied with the station against the growing Shadow threat, the attack is repelled at great cost.\n\nBecoming concerned over the Shadows' growing influence among his people, Centauri ambassador Londo Mollari attempts to sever ties with them. Mr. Morden, the Shadows' human representative, tricks him into restoring the partnership by engineering the murder of Mollari's mistress while putting the blame on a rival Centauri House. Open warfare breaks out between the Shadows and the alliance led by \"Babylon 5\" and the Minbari. It is learned that genetic manipulation by the Vorlons is the source of telepathy in humans and other races, as it is later discovered that Shadow ships are vulnerable to telepathic attacks. Displeased at the Vorlons' lack of direct action against the Shadows, Captain John Sheridan browbeats Vorlon ambassador Kosh Naranek into launching an attack against their mutual enemy. Kosh's deeds lead to his subsequent assassination by the Shadows.\n\nFormer station commander Jeffrey Sinclair returns to \"Babylon 5\" to enlist the aid of Captain Sheridan, Delenn, Ivanova and Marcus in stealing the \"Babylon 4\" space station and sending it 1,000 years back in time to use it as a base of operations against the Shadows in the previous Minbari-Shadow war. Having undergone a similar transformation to the one Delenn had at the end of Season 1, Sinclair transforms into a Minbari and is subsequently revealed to be the actual Valen of Minbari legend, rather than simply a reincarnation. Meanwhile, as a result of the unstable time travel, Sheridan sees a vision of the downfall of Centauri Prime when it is attacked by Shadow allies after the Shadow war, and he becomes determined to prevent that future.\n\nSheridan and Delenn begin a romantic relationship, but their lives and the war are interrupted by the sudden reappearance of Sheridan's wife, who was presumed dead after taking part in an archaeological expedition to Z'ha'dum years prior. She tells Sheridan that the Shadows are not evil, hoping to bring him back with her and recruit him to their cause. He soon realizes that her mind has been tampered with and corrupted by the Shadows, but accepts her offer to visit Z'ha'dum because he hopes it will save the galaxy sooner and prevent the downfall of Centauri Prime. He takes with him a pair of nuclear warheads, which he uses to destroy their largest city, and is last seen jumping into a miles-deep pit to escape the explosion.\n\nShadow vessels appear at the station, but disappear after Sheridan's attack. However, after they leave, station personnel realize that Garibaldi, who left in a fighter to defend against the vessels, never returned.\n\nIn 2261, the Vorlons join the Shadow War, but their tactics become a concern for the alliance when the Vorlons begin destroying entire planets which they deem to have been \"influenced\" by the Shadows. Disturbed by this turn of events, Babylon 5 recruits several other powerful and ancient races (the First Ones) to their cause, against both the Shadows and the Vorlons. Captain John Sheridan returns to the station after escaping from Z'ha'dum and reunites the galaxy against the Shadows, but at a price: barring illness or injury, he has only 20 years left to live. He is accompanied by a mysterious alien named Lorien who claims to be the first sentient being in the galaxy, and who breathed life into Sheridan at Z'ha'dum. Once Sheridan returns, he and Delenn formalize their relationship and begin planning to marry, although most of their plans are put on hold due to the ongoing war.\n\nHours before Sheridan's return, Garibaldi is rescued and returned to the station, in rather dubious circumstances. Over the course of the next several months, he becomes markedly more paranoid and suspicious of other alien races and of Sheridan than he was before, causing worry among his friends and colleagues.\n\nCentauri Emperor Cartagia forges a relationship with the Shadows. With the reluctant help of his enemy G'Kar, Londo Mollari engineers the assassination of Cartagia and repudiates his agreement with the Shadows. In exchange for G'Kar's help, Londo frees the Narn from Centauri occupation. Londo afterwards kills Mr. Morden and destroys the Shadow vessels based on the Centauri homeworld, in a successful attempt to save his planet from destruction by the Vorlons. Aided by the other ancient races, and several younger ones, Sheridan lures both the Vorlons and the Shadows into an immense battle, during which the Vorlons and Shadows reveal that they have been left as guardians of the younger races, but due to philosophical differences, ended up using them as pawns in their endless proxy wars throughout the ages. The younger races reject their continued interference, and the Vorlons and Shadows, along with the remaining First Ones, agree to depart the galaxy in order to allow the younger races to find their own way.\n\nAfter the Shadows are defeated, Garibaldi leaves his post as security chief and works on his own as a \"provider of information\". He begins working for one William Edgars, a Mars tycoon, who is married to Garibaldi's former love. While he works ever closer with Edgars, he becomes increasingly aggressive toward Sheridan and eventually leaves \"Babylon 5\".\n\nMinbar is gripped by a brief civil war between the Warrior and Religious castes. Delenn secretly meets with Neroon of the Warrior caste and convinces him that neither side can be allowed to win. She tells him that she will undergo a ritual wherein she will be willing to sacrifice herself, but will stop the ritual before she actually dies. When Neroon sees that she actually intends to go through the entire ritual, he rescues her and sacrifices himself instead, declaring that, although he was born Warrior caste, in his heart he is Religious caste.\n\nAs part of the conflict between Earth and Babylon 5, Garibaldi eventually betrays Sheridan and arranges his capture to gain Edgars' trust and learn his plans. Garibaldi later learns that Edgars had created a virus that is dangerous only to telepaths. It is then revealed that after Garibaldi was captured the previous year, he was taken to the Psi Corps and re-programmed by Bester to provide information to him at the right time. Bester releases Garibaldi of his programming, and allows him to remember everything he had done since being kidnapped. Edgars is killed by Psi Corps operatives. His wife disappears but is reunited with Garibaldi after the end of the war.\n\nSheridan is tortured and interrogated by those who hope to break him and turn him into a propaganda tool for Earth's totalitarian government. Fortunately, Garibaldi is able to help free Sheridan and return him to the campaign to free Earth. An alliance led by Babylon 5 frees Earth from totalitarian rule by president Clark in a short but bloody war. This culminates in Clark's suicide and the restoration of democratic government in the Earth Alliance. Mars is granted full independence and Sheridan agrees to resign his commission. The League of Non-Aligned Worlds is dissolved and reformed into the Interstellar Alliance, with Sheridan elected as its first president and continuing his command of the Rangers, who are to act as a galactic equivalent of United Nations peacekeepers. Londo and G'Kar enter an uneasy alliance to help both their races as well as Sheridan in forming the Interstellar Alliance. During the final battle to liberate Earth from Clark's regime, Ivanova is critically injured, promised only a few days to live. Marcus, who had fallen in love with Ivanova, finds the same alien healing device used to revive Garibaldi at the beginning of the second season and transfers almost all of his life energy into Ivanova, causing her to live. This causes her immense emotional anguish and she chooses to leave Babylon 5 for another posting in EarthForce. Marcus is placed into indefinite cryonic suspension at her request, pending resuscitation technology.\n\nSheridan and Delenn complete their marriage ceremony while en route to Babylon 5, where they will head the Interstellar Alliance until the completion of Alliance's permanent headquarters. In the season finale, the events of 100, 500, 1000 and one million years into the future are shown, depicting Babylon 5's lasting influence throughout history. Among the events shown are the political aftermath of the 2261 civil war, a subsequent nuclear war on Earth involving a new totalitarian government in 2762, the resulting fall of Earth into a pre-industrial society, the loss and restoration of humanity's knowledge of space travel and the final evolution of mankind into energy beings similar to the Vorlons, after which Earth's sun goes nova.\n\nIn 2262, Earthforce Captain Elizabeth Lochley is appointed to command \"Babylon 5\", which is now also the headquarters of the Interstellar Alliance. The station grows in its role as a sanctuary for rogue telepaths running from the Psi Corps, resulting in conflict. G'Kar, former Narn ambassador to \"Babylon 5\", becomes unwillingly a spiritual icon after a book that he wrote while incarcerated during the Narn-Centauri War is published without his knowledge. The Drakh, former allies of the Shadows who remained in the galaxy, take control of Regent Virini on Centauri Prime through a parasitic creature called a Keeper, then incite a war between the Centauri and the Interstellar Alliance, in order to isolate the Centauri from the Alliance and gain a malleable homeworld for themselves.\n\nCentauri Prime is devastated by Narn and Drazi warships and Londo Mollari becomes emperor, then ends the war. However, the Drakh blackmail him into accepting a Drakh Keeper, under threat of the complete nuclear destruction of the planet. Vir Cotto, Mollari's loyal and more moral aide, becomes ambassador to \"Babylon 5\" in his stead. G'Kar also leaves \"Babylon 5\" to escape his unwanted fame and explore the rim. Sheridan and Delenn move to a city on Minbar, where the new headquarters of the Interstellar Alliance are located, while celebrating their first year of marriage and the upcoming birth of their son, and mourning the loss of dear friendships. Garibaldi marries and settles down on Mars, where he and his wife share ownership of a prominent pharmaceutical company. Most other main characters, including Stephen Franklin and Lyta Alexander, leave \"Babylon 5\" as well.\n\nAs shown in flash-forwards earlier in the series, the next several years include the reign of Londo Mollari as Centauri Emperor. Sixteen years later, Londo sacrifices his life to rescue Sheridan and Delenn from the Drakh, in the hope that they in turn can save Centauri Prime. To prevent the Drakh from discovering his ruse, he asks G'Kar, now an old friend, to kill him, but Londo's Keeper wakes up and forces him to kill G'Kar in return. They die at each other's throats, in accordance with Londo's vision many decades earlier, and Vir Cotto succeeds him as emperor, free of Drakh influence.\n\nThree years after Londo's death, Sheridan himself is on the verge of death and takes one last opportunity to gather his old friends together. Shortly after his farewell party, Sheridan says goodbye to Delenn, though in Minbari fashion they use the word \"goodnight\" to signify their hope of an eventual reunion. Sheridan then takes a final trip to the obsolete \"Babylon 5\" station before its decommissioning. He returns to the site of the final battle between the Vorlons and the Shadows and apparently dies, but is instead claimed by The First One, who invites him to join the other First Ones on a journey beyond the rim of the galaxy. \"Babylon 5\" station is destroyed in a demolition shortly after Sheridan's departure, its existence no longer necessary as the Alliance has taken over its diplomatic purposes and other trading routes have been established. This final episode features a cameo by Straczynski as the technician who switches off the lights before \"Babylon 5\" is demolished.\n\nThroughout its run, \"Babylon 5\" found ways to portray themes relevant to modern and historical social issues. It marked several firsts in television science fiction, such as the exploration of the political and social landscapes of the first human colonies, their interactions with Earth, and the underlying tensions. \"Babylon 5\" was also one of the first television science fiction shows to denotatively refer to a same-sex relationship. In the show, sexual orientation is as much of an issue as \"being left-handed or right-handed\". Unrequited love is explored as a source of pain for the characters, though not all the relationships end unhappily.\n\nThe clash between order and chaos, and the people caught in between, plays an important role in \"Babylon 5\". The conflict between two unimaginably powerful older races, the Vorlons and the Shadows, is represented as a battle between two competing ideologies, each seeking to turn the humans and the other younger races to their beliefs. The Vorlons represent an authoritarian philosophy: you will do what we tell you to, because we tell you to do it. The Vorlon question, \"Who are you?\" focuses on identity as a catalyst for shaping personal goals; the intention is not to solicit a correct answer, but to \"tear down the artifices we construct around ourselves until we're left facing ourselves, not our roles.\" The Shadows represent another authoritarian philosophy cloaked in a disguise of evolution through fire (as shown in the episode in which Sheridan goes to Z'ha'dum and when he refuses to cooperate, Justin tells him: \"But we do what we're told... and so will you!\"), of sowing the seeds of conflict in order to engender progress. The question the Shadows ask is \"What do you want?\" In contrast to the Vorlons, they place personal desire and ambition first, using it to shape identity, encouraging conflict between groups who choose to serve their own glory or profit. The representation of order and chaos was informed by the Babylonian myth that the universe was born in the conflict between both. The climax of this conflict comes with the younger races' exposing of the Vorlons' and the Shadows' \"true faces\" and the rejection of both philosophies, heralding the dawn of a new age without their interference.\n\nThe notion that the war was about \"killing your parents\" is echoed in the portrayal of the civil war between the human colonies and Earth. Deliberately dealing in historical and political metaphor, with particular emphasis upon McCarthyism and the HUAC, the Earth Alliance becomes increasingly authoritarian, eventually sliding into a dictatorship. The show examines the impositions on civil liberties under the pretext of greater defense against outside threats which aid its rise, and the self-delusion of a populace which believes its moral superiority will never allow a dictatorship to come to power, until it is too late. The successful rebellion led by the Babylon 5 station results in the restoration of a democratic government, and true autonomy for Mars and the colonies.\n\nThe \"Babylon 5\" universe deals with numerous armed conflicts which range on an interstellar scale. The story begins in the aftermath of a war which brought the human race to the brink of extinction, caused by a misunderstanding during a first contact. Babylon 5 is built to foster peace through diplomacy, described as the \"last, best hope for peace\" in the opening credits monologue during its first three seasons. Wars between separate alien civilizations are featured. The conflict between the Narn and the Centauri is followed from its beginnings as a minor territorial dispute amplified by historical animosity, through to its end, in which weapons of mass destruction are employed to subjugate and enslave a planet. The war is an attempt to portray a more sobering kind of conflict than usually seen on science fiction television. Informed by the events of the first Gulf War, the Cuban Missile Crisis and the Soviet invasion of Prague, the intent was to recreate these moments when \"the world held its breath\" and the emotional core of the conflict was the disbelief that the situation could have occurred at all, and the desperation to find a way to bring it to an end. By the start of the third season, the opening monologue had changed to say that the hope for peace had \"failed\" and the Babylon 5 station had become the \"last, best hope for victory\", indicating that while peace is a laudable accomplishment, it can also mean a capitulation to an enemy intent on committing horrendous acts and that \"peace is a byproduct of victory against those who do not want peace.\"\n\nThe Shadow War also features prominently in the show, during which an advanced alien species attempts to sow the seeds of conflict to promote technological and cultural advancement. The gradual discovery of the scheme and the rebellion against it, serve as the backdrop to the first three seasons, but also as a metaphor for the war within ourselves. The concurrent limiting of civil liberties and Earth's descent into a dictatorship are \"shadow wars\" of their own. In ending the Shadow War before the conclusion of the series, the show was able to more fully explore its aftermath, and it is this \"war at home\" which forms the bulk of the remaining two seasons. The struggle for independence between Mars and Earth culminates with a civil war between the human colonies (led by the Babylon 5 station) and the home planet. Choosing Mars as both the spark for the civil war, and the staging ground for its dramatic conclusion, enabled the viewer to understand the conflict more fully than had it involved an anonymous colony orbiting a distant star. The conflict, and the reasons behind it, were informed by Nazism, McCarthyism and the breakup of Yugoslavia, and the destruction of the state also served as partial inspiration for another civil war, which involved the alien Minbari.\n\nThe post-war landscape has its roots in the Reconstruction. The attempt to resolve the issues of the American Civil War after the conflict had ended, and this struggle for survival in a changed world was also informed by works such as \"Alas, Babylon\", a novel dealing with the after-effects of a nuclear war on a small American town. The show expresses that the end of these wars is not an end to war itself. Events shown hundreds of years into the show's future tell of wars which will once again bring the human race to the edge of annihilation, demonstrating that mankind will not change, and the best that can be hoped for after it falls is that it climbs a little higher each time, until it can one day \"take [its] place among the stars, teaching those who follow.\"\n\nMany of Earth's contemporary religions are shown to still exist, with the main human characters often having religious convictions. Among those specifically identified are the Roman Catholic branch of Christianity (including the Jesuits), Judaism, and the fictional Foundationism (which developed after first contact with alien races). Alien beliefs in the show range from the Centauri's Bacchanalian-influenced religions, of which there are up to seventy different denominations, to the more pantheistic as with the Narn and Minbari religions. In the show's third season, a community of Cistercian monks takes up residence on the Babylon 5 station, in order to learn what other races call God, and to come to a better understanding of the different religions through study at close quarters.\n\nReferences to both human and alien religion is often subtle and brief, but can also form the main theme of an episode. The first season episode \"The Parliament of Dreams\" is a conventional \"showcase\" for religion, in which each species on the Babylon 5 station has an opportunity to demonstrate its beliefs (humanity's are presented as being numerous and varied), while \"Passing Through Gethsemane\" focuses on a specific position of Roman Catholic beliefs, as well as concepts of justice, vengeance, and biblical forgiveness. Other treatments have been more contentious, such as the David Gerrold-scripted \"Believers\", in which alien parents would rather see their son die than undergo a life-saving operation because their religious beliefs forbid it. When religion is an integral part of an episode, various characters express differing view points. Such as in \"Soul Hunter\", where the concept of an immortal soul is touched upon, and whether after death it is destroyed, reincarnated, or simply does not exist. The character arguing the latter, Doctor Stephen Franklin, often appears in the more spiritual storylines as his scientific rationality is used to create dramatic conflict. Undercurrents of religions such as Buddhism have been viewed by some in various episode scripts, and while identifying himself as an atheist, Straczynski believes that passages of dialog can take on distinct meanings to viewers of differing faiths, and that the show ultimately expresses ideas which cross religious boundaries.\n\nSubstance abuse and its impact on human personalities also plays a significant role in the \"Babylon 5\" storyline. The station's security chief, Michael Garibaldi, is a textbook relapsing-remitting alcoholic of the binge drinking type; he practices complete abstinence from alcohol throughout most of the series (with one notable exception) until the middle of season five. He only recovers physically and socially and breaks the cycle at the end of the season. His eventual replacement as Chief of Security, Zack Allan, was given a second chance by Garibaldi after overcoming his own addiction to an unspecified drug. Dr. Stephen Franklin develops an (initially unrecognized) addiction to injectable stimulant drugs while trying to cope with the chronic stress and work overload in Medlab, and wanders off to the homeless and deprived in Brown Sector, where he suffers through a severe withdrawal syndrome. Executive Officer Susan Ivanova mentions that her father became an alcoholic after her mother had committed suicide after having been drugged by the authorities over a number of years. Captain Elizabeth Lochley tells Garibaldi that her father was an alcoholic and that she is a recovering alcoholic herself.\n\n\nIn addition, several other actors have filled more than one minor role on the series. Kim Strauss played the Drazi Ambassador in four episodes, as well as nine other characters in ten more episodes. Some actors had difficulty dealing with the application of prosthetics required to play some of the alien characters. The producers therefore used the same group of people (as many as 12) in various mid-level speaking roles, taking full head and body casts from each. The group came to be unofficially known by the production as the \"Babylon 5 Alien Rep Group.\"\n\nHaving worked on a number of television science fiction shows which had regularly gone over budget, creator J. Michael Straczynski concluded that a lack of long-term planning was to blame, and set about looking at ways in which a series could be done responsibly. Taking note of the lessons of mainstream television, which brought stories to a centralized location such as a hospital, police station, or law office, he decided that instead of \"[going] in search of new worlds, building them anew each week\", a fixed space station setting would keep costs at a reasonable level. A fan of sagas such as the \"Foundation\" series, \"Childhood's End\", \"The Lord of the Rings\", \"Dune\" and the \"Lensman\" series, Straczynski wondered why no one had done a television series with the same epic sweep, and concurrently with the first idea started developing the concept for a vastly ambitious epic covering massive battles and other universe-changing events. Realizing that both the fixed-locale series and the epic could be done in a single series, he began to sketch the initial outline of what would become \"Babylon 5\".\n\nStraczynski set five goals for \"Babylon 5\". He said that the show \"would have to be good science fiction\" as well as good television – \"rarely are shows both good [science fiction] \"and\" good TV; there're generally one or the other [emphasis in original].\" It would have to do for science fiction television what \"Hill Street Blues\" had done for police dramas, by taking an adult approach to the subject. It would have to be reasonably budgeted, and \"it would have to look unlike anything ever seen before on TV, presenting individual stories against a much broader canvas.\" He further stressed that his approach was \"to take [science fiction] seriously, to build characters for grown-ups, to incorporate real science but keep the characters at the center of the story.\" Some of the staples of television science fiction were also out of the question (the show would have \"no kids or cute robots\"). The idea was not to present a perfect utopian future, but one with greed and homelessness; one where characters grow, develop, live, and die; one where not everything was the same at the end of the day's events. Citing Mark Twain as an influence, Straczynski said he wanted the show to be a mirror to the real world and to covertly teach.\n\nDescribed as a \"window on the future\" by series production designer John Iacovelli, the story is set in the 23rd century on a large O'Neill Colony named \"Babylon 5\"—a five-mile-long, 2.5 million-ton rotating colony designed as a gathering place for the sentient species of the galaxy, in order to foster peace through diplomacy, trade, and cooperation. Instead, acting as a center of political intrigue and conflict, the station becomes the linchpin of a massive interstellar war. This is reflected in the opening monologue of each episode, which describes it as the \"last, best hope for peace\" in season one, then the \"last, best hope for victory\" in season three.\n\nThe series consists of a coherent five-year story arc taking place over five seasons of 22 episodes each. Unlike most television shows at the time, \"Babylon 5\" was conceived as a \"novel for television\", with a defined beginning, middle, and end; in essence, each episode would be a single \"chapter\" of this \"novel\". Many of the tie-in novels, comic books, and short stories were also developed to play a significant canonical part in the overall story.\n\nThe cost of the series totalled an estimated $90 million for 110 episodes.\n\nCreator and showrunner J. Michael Straczynski wrote 92 of the 110 episodes of \"Babylon 5\", including all 44 episodes in the third and fourth seasons; according to Straczynski, a feat never before accomplished in American television. Other writers to have contributed scripts to the show include Peter David, Neil Gaiman, Kathryn M. Drennan, Lawrence G. DiTillio, D. C. Fontana, and David Gerrold. Harlan Ellison, a creative consultant on the show, received story credits for two episodes. Each writer was informed of the overarching storyline, enabling the show to be produced consistently under-budget. The rules of production were strict; scripts were written six episodes in advance, and changes could not be made once production had started.\n\nThough conceived as a whole, it was necessary to adjust the plotline to accommodate external influences. Each of the characters in the series was written with a \"trap door\" into their background so that, in the event of an actor's unexpected departure from the series, the character could be written out with minimal impact on the storyline. In the words of Straczynski, \"As a writer, doing a long-term story, it'd be dangerous and short-sighted for me to construct the story without trap doors for every single character. ... That was one of the big risks going into a long-term storyline which I considered long in advance;...\" The character of Talia Winters was to have undergone a transformation into a Psi Corps secret agent, having been revealed as a \"sleeper\", whose true personality was buried subconsciously, and who acted as a spy, observing the events on the station and the actions of her command staff. When Winters's portrayer Andrea Thompson left the series, this revelation was used to drop the character from the series.\n\nRatings for \"Babylon 5\" continued to rise during the show's third season, but going into the fourth season, the impending demise of network PTEN left a fifth year in doubt. Unable to get word one way or the other from parent company Warner Bros., and unwilling to short-change the story and the fans, Straczynski began preparing modifications to the fourth season in order to allow for both eventualities. Straczynski identified three primary narrative threads which would require resolution: the Shadow war, Earth's slide into a dictatorship, and a series of sub-threads which branched off from those. Estimating they would still take around 27 episodes to resolve without having the season feel rushed, the solution came when the TNT network commissioned two \"Babylon 5\" television films. Several hours of material was thus able to be moved into the films, including a three-episode arc which would deal with the background to the Earth–Minbari War, and a sub-thread which would have set up the sequel series, \"Crusade\". Further standalone episodes and plot-threads were dropped from season four, which could be inserted into \"Crusade\", or the fifth season, were it to be given the greenlight. The intended series finale, \"Sleeping in Light\", was filmed during season four as a precaution against cancellation. When word came that TNT had picked up \"Babylon 5\", this was moved to the end of season five and replaced with a newly filmed season four finale, \"The Deconstruction of Falling Stars\".\n\nAnn Bruice Aling was costume designer for the show, after production designer John Iacovelli suggested her for the position having previously worked with Bruice on a number of film and theatrical productions.\n\nWith the variety of costumes required she compared \"Babylon 5\" to \"eclectic theatre\", with fewer rules about period, line, shape and textures having to be adhered to. Preferring natural materials whenever possible, such as ostrich leather in the Narn body armor, Bruice combined and layered fabrics as diverse as rayon and silk with brocades from the 1930s and '40s to give the clothing the appearance of having evolved within different cultures.\n\nWith an interest in costume history, she initially worked closely with J. Michael Straczinski to get a sense of the historical perspective of the major alien races, \"so I knew if they were a peaceful people or a warring people, cold climate etc. and then I would interpret what kind of sensibility that called for.\" Collaborating with other departments to establish co-ordinated visual themes for each race, a broad palette of colors was developed with Iacovelli, which he referred to as \"spicy brights\". These warm shades of grey and secondary colors, such as certain blues for the Minbari, would often be included when designing both the costumes and relevant sets. As the main characters evolved, Bruice referred back to Straczynski and producer John Copeland who she viewed as \"surprisingly more accessible to me as advisors than other producers and directors\", so the costumes could reflect these changes. Ambassador Londo Mollari's purple coat became dark blue and more tailored while his waistcoats became less patterned and brightly colored as Bruice felt \"Londo has evolved in my mind from a buffoonish character to one who has become more serious and darker.\"\n\nNormally there were three changes of costume for the primary actors; one for on set, one for the stunt double and one on standby in case of \"coffee spills\". For human civilians, garments were generally purchased off-the-rack and altered in various ways, such as removing lapels from jackets and shirts while rearranging closures, to suggest future fashions. For some of the main female characters a more couture approach was taken, as in the suits worn by Talia Winters which Bruice described as being designed and fitted to within \"an inch of their life\". Costumes for the destitute residents of downbelow would be distressed through a combination of bleaching, sanding, dipping in dye baths and having stage blood added.\n\nLike many of the crew on the show, members of the costume department made onscreen cameos. During the season 4 episode \"Atonement\", the tailors and costume supervisor appeared as the Minbari women fitting Zack Allan for his new uniform as the recently promoted head of security. His complaints, and the subsequent stabbing of him with a needle by costume supervisor Kim Holly, was a light hearted reference to the previous security uniforms, a design carried over from the pilot movie which were difficult to work with and wear due to the combination of leather and wool.\n\nWhile the original pilot film featured some aliens which were puppets and animatronics, the decision was made early on in the show's production to portray most alien species as humanoid in appearance. Barring isolated appearances, fully computer-generated aliens were discounted as an idea due to the \"massive rendering power\" required. Long-term use of puppets and animatronics was also discounted due to the technological limitations in providing convincing interaction with the human actors (\"...if you want any real \"emotion\" from the character, you're going an actor inside\").\n\nIn anticipation of future HDTV broadcasts and Laserdisc releases, rather than the usual format, the series was shot in , with the image cropped to 4:3 for initial television transmissions. \"Babylon 5\" also distinguished itself at a time when models and miniature were still standard by becoming one of the first television shows to use computer technology in creating visual effects. This was achieved using Amiga-based Video Toasters at first, and later Pentium, Macs, and Alpha-based systems. It also attempted to respect Newtonian physics in its effects sequences, with particular emphasis on the effects of inertia.\n\nFoundation Imaging provided the special effects for the pilot film (for which it won an Emmy) and the first three seasons of the show, led by Ron Thornton. After the show's co-executive producer (Douglas Netter) and producer (John Copeland) approached Straczynski with the idea of producing the effects in-house, Straczynski agreed to replace Foundation, for season 4 and 5, once a new team had been established by Netter Digital, and an equal level of quality was assured, by using similar technology and a number of former Foundation employees. The Emmy-winning alien make-up was provided by Optic Nerve Studios.\n\nChristopher Franke composed and scored the musical soundtrack for all 5 years of the show when Stewart Copeland, who worked on the original telefilm, was unable to return for the first season due to recording and touring commitments. Given creative freedom by the producers, Franke also orchestrated and mixed all the music which one reviewer described as having \"added another dimension of mystery, suspense, and excitement to the show, with an easily distinguishable character that separates \"Babylon 5\" from other sci-fi television entries of the era.\"\n\nWith his recording studio in the same building as his home located in the Hollywood Hills, Franke would attend creative meetings before scoring the on average 25 minutes of music for each episode. Utilising Cubase software through an electronic keyboard, or for more complex pieces a light pen and graphics tablet, he would begin by developing the melodic content round which the ambient components and transitions were added. Using playbacks with digital samples of the appropriate instruments, such as a group of violins, he would decide which tracks to produce electronically or record acoustically.\n\nUtilizing the \"acoustic dirt produced by live instruments and the ability to play so well between two semitones\" and the \"frequency range, dynamics and control\" provided by synthesizers, he described his approach \"as experimental friendly as possible without leaving the happy marriage between the orchestral and electronic sounds\". While highlighting \"Babylon 5\" was produced on a \"veritable shoestring\", and as such would have been unable to afford a full orchestral score every week, at least one reviewer felt that the soundtrack would have benefitted from a greater use of the Berlin Symphonic Film Orchestra, which Franke established in 1991.\n\nScores for the acoustic tracks were emailed to his Berlin scoring stage, and would require from four musicians to the full orchestra, with a maximum of 24 present at any one time. One of three conductors would also be required for any score that involved more than 6 musicians. Franke would direct recording sessions via six fibre optic digital telephone lines to transmit and receive video, music and the SMPTE timecode. The final edit and mixing of the tracks would take place in his Los Angeles studio. Initially concerned composing for an episodic television show could become \"annoying because of the repetition\", Franke found the evolving characters and story of \"Babylon 5\" afforded him the opportunity to continually \"push the envelope\".\n\nA total of 24 episode and three television film soundtracks were released under Franke's record label, Sonic Images Records, between 1995 and 2001. These contain the musical scores in the same chronological order as they played in the corresponding episodes, or television films. Three compilation albums were also produced, containing extensively re-orchestrated and remixed musical passages taken from throughout the series to create more elaborate suites. In 2007 his soundtrack for was released under the Varèse Sarabande record label.\n\nThe pilot episode of \"\" (\"DS9\") aired just weeks before \"Babylon 5\" debuted. \"Babylon 5\" creator J. Michael Straczynski indicated that Paramount Television was aware of his concept as early as 1989, when he attempted to sell the show to the studio, and provided them with the series bible, pilot script, artwork, lengthy character background histories, and plot synopses for 22 \"or so planned episodes taken from the overall course of the planned series\".\n\nParamount declined to produce \"Babylon 5\", but later announced \"Deep Space Nine\" was in development, two months after Warner Bros. announced its plans for \"Babylon 5\". Straczynski stated that, even though he was confident that \"Deep Space Nine\" producer/creators Rick Berman and Michael Piller had not seen this material, he suspected that Paramount executives used his bible and scripts to steer development of \"Deep Space Nine\". He and Warner did not file suit against Paramount, largely because Straczynski didn't see it as a productive option, with negative repercussions for both TV series. In 1993 he responded to a \"Deep Space Nine\" fan who saw the lack of legal action as proof that Straczynski's allegation was unfounded, \"If there is any (to use your term) winking and nudging going on, it's on the level of 'Okay, YOU (Paramount) know what happened, and *I* know what happened, but let's try to be grownup about it for now,' though I must say that the shapechanging thing nearly tipped me back over the edge again. If there are no more major similarities that crop up in the next few weeks or months, with luck we can continue that way.\"\n\nThe show employed Internet marketing to create a buzz among online readers far in advance of the airing of the pilot episode, with Straczynski participating in online communities on USENET (in the rec.arts.sf.tv.babylon5.moderated newsgroup), and the GEnie and CompuServe systems before the Web came together as it exists today. The station's location, in \"grid epsilon\" at coordinates of 470/18/22, was a reference to GEnie (\"grid epsilon\" = \"GE\") and the original forum's address on the system's bulletin boards (page 470, category 18, topic 22). Also during this time, Warner Bros. executive Jim Moloshok created and distributed electronic trading cards to help advertise the series. In 1995, Warner Bros. started the Official \"Babylon 5\" Website on the now defunct Pathfinder portal. In September 1995, they hired a fan to take over the site and move it to its own domain name, and to oversee the \"Keyword B5\" area on America Online.\n\nThe pilot film, \"\", premiered on February 22, 1993, and the regular series initially aired from January 26, 1994 through November 25, 1998, first on the short-lived Prime Time Entertainment Network, then in first-run syndication. The fifth season aired on cable network TNT. The show aired every week in the United Kingdom on Channel 4 without a break; as a result the last four or five episodes of the early seasons were shown in the UK before the US. The pilot film debuted in the United States with strong viewing figures, achieving a 9.7 in the Nielsen national syndication rankings. The series proper debuted with a 6.8 rating/10 share. Figures dipped in its second week, and while it posted a solid 5.0 rating/8 share, with an increase in several major markets, ratings for the first season continued to fall, to a low of 3.4 during reruns, and then increasing again when new episodes were broadcast in July.\n\nRatings continued to remain low-to-middling throughout the first four seasons, but \"Babylon 5\" scored well with the demographics required to attract the leading national sponsors and saved up to $300,000 per episode by shooting off the studio lot, therefore remaining profitable for the network. The fifth season, shown on cable network TNT, had ratings about 1.0% lower than seasons two through four.\n\nIn the United Kingdom, \"Babylon 5\" was one of the better-rated US television shows on Channel 4, and achieved high audience Appreciation Indexes, with season 4's \"Endgame\" achieving the rare feat of beating the prime-time soap operas for first position.\n\nOn November 25, 1998, after five seasons and 109 aired episodes, \"Babylon 5\" successfully completed its five-year story arc when TNT aired the 110th (epilogue) episode \"Sleeping in Light\".\n\nAwards presented to \"Babylon 5\" include:\nNominated Awards include:\n\nIn November 1994, DC began publishing monthly \"Babylon 5\" comics. A number of short stories and novels were also produced between 1995 and 2001. Additional books were published by the gaming companies Chameleon Eclectic and Mongoose Publishing, to support their desk-top strategy and role-playing games.\n\nThree telefilms were released by Turner Network Television (TNT) in 1998, after funding a fifth season of \"Babylon 5\", following the demise of the Prime Time Entertainment Network the previous year. In addition to \"\", \"\", and \"\", they released a re-edited special edition of the original 1993 telefilm, \"\". In 1999, a fifth telefilm was also produced, \"\", which acted as a pilot movie for the spin-off series \"Crusade\", which TNT cancelled after 13 episodes had been filmed.\n\nDell Publishing started publication of a series of \"Babylon 5\" novels in 1995, which were ostensibly considered canon within the TV series' continuity, nominally supervised by creator J. Michael Straczynski, with later novels in the line being more directly based upon Straczynski's own notes and story outlines. In 1997, Del Rey obtained the publication license from Warner Bros., and proceeded to release a number of original trilogies directly scenarized by Straczynski, as well as novelizations of three of the TNT telefilms (\"In the Beginning, Thirdspace\", and \"A Call to Arms\"). All of the Del Rey novels are considered completely canonical within the filmic \"Babylon 5\" universe.\n\nIn 2000, the Sci-Fi Channel purchased the rights to rerun the \"Babylon 5\" series, and premiered a new telefilm, \"\" in 2002, which failed to be picked up as a series. In 2007, the first in a planned anthology of straight-to-DVD short stories entitled, \"\", was released by Warner Home Video, but no others were produced, due to funding issues.\n\nAt the 2014 San Diego Comic Con, Straczynski announced that a \"Babylon 5\" film was planned to go into production in 2016. It is to be a reboot of the story, but potentially one using old cast members in different roles. Studio JMS would produce it on a budget of $80–100 million if Warner Bros. did not take up the offer. At the 2016 San Diego Comic Con, Straczynski said the film has been delayed until he makes one or two more television series or films, to build up his reputation and ensure the desired $100 million plus, budget.\n\nIn July 1995, Warner Home Video began distributing \"Babylon 5\" VHS video tapes under its Beyond Vision label in the UK. Beginning with the original telefilm, \"\", these were PAL tapes, showing video in the same 4:3 aspect ratio as the initial television broadcasts. By the release of Season 2, tapes included closed captioning of dialogue and Dolby Surround sound. Columbia House began distributing NTSC tapes, via mail order in 1997, followed by repackaged collector's editions and three-tape boxed sets in 1999, by which time the original pilot telefilm had been replaced by the re-edited TNT special edition. Additional movie and complete season boxed-sets were also released by Warner Bros. until 2000.\n\nImage Entertainment released \"Babylon 5\" laserdiscs between December 1998 and September 1999. Produced on double-sided 12-inch Pioneer discs, each contained two episodes displayed in the 4:3 broadcast aspect-ratio, with Dolby Surround audio and closed captioning for the dialogue. Starting with two TNT telefilms, \"\" and the re-edited special edition of \"The Gathering\", Seasons 1 and 5 were released simultaneously over a six-month period. Seasons 2 and 4 followed, but with the decision to halt production due to a drop in sales, precipitated by rumors of a pending DVD release, only the first twelve episodes of Season 2 and the first six episodes of Season 4 were ultimately released.\n\nIn November 2001, Warner Home Video began distributing \"Babylon 5\" DVDs with a two-movie set containing the re-edited TNT special edition of \"The Gathering\" and \"In The Beginning\". The telefilms were later individually released in region 2 in April 2002, though some markets received the original version of \"The Gathering\" in identical packaging.\n\nDVD boxed sets of the individual seasons, each containing six discs, began being released in October 2002. Each included a printed booklet containing episode summaries, with each disc containing audio options for German, French, and English, plus subtitles in a wider range of languages, including Arabic and Dutch. Video was displayed in anamorphic widescreen with Dolby Digital 5.1 sound. Disc 1 of each set contained an introduction to the season by J. Michael Straczynski, while disc 6 included featurettes containing interviews with various production staff, as well as information on the fictional universe, and a gag reel. Three episodes in each season also contained commentary from either Straczynski, members of the main cast, and/or the episode director.\n\nSince its initial release, a number of repackaged DVD boxed sets have been produced for various regional markets. With slightly altered cover art, they included no additional content, but the discs were more securely stored in slimline cases, rather than the early \"book\" format, with hard plastic pages used during the original release of the first three seasons.\n\nSeasons 1 and 2, and parts of Season 3, of \"Babylon 5\" have been released as advertisement-supported downloads through the In2TV and Hulu download services. Additionally, every episode from Seasons 1 to 5, as well as the pilot film \"\", are available for purchase on the Xbox Live Marketplace in the United States. All five seasons, and five of the movies (\"In The Beginning\", \"Thirdspace\", \"River of Souls\", \"A Call To Arms\", \"Legend of the Rangers\") are currently available through iTunes.\n\nWhile the series was in pre-production, studios were looking at ways for their existing shows to make the transition from the then-standard to the widescreen formats that would accompany the next generation of televisions. After visiting Warner Bros., who were stretching the horizontal interval for an episode of \"\", producer John Copeland convinced them to allow \"Babylon 5\" to be shot on Super 35mm film stock. \"The idea being that we would telecine to 4:3 for the original broadcast of the series. But what it also gave us was a negative that had been shot for the new 16×9 widescreen-format televisions that we knew were on the horizon.\"\n\nThough the CG scenes, and those containing live action combined with digital elements, could have been created in a suitable widescreen format, a cost-saving decision was taken to produce them in the 4:3 aspect ratio. The intention was to then crop the top and bottom of the images, and upscale the resolution for any future widescreen release or broadcast. In 2000, when the show was transferred to widescreen for airing on the Sci-Fi Channel prior to its eventual DVD release, the plan was not followed, as John Copeland recalls: \"They did another video hack, and simply used a digital post production device like a DVE (Digital Video Effects) to blow the material up. They essentially stretched it approximately 1/3 to fill the larger aspect ratio.\"\n\nThe scenes containing live action ready to be composited with matte paintings, CG animation, etc., were delivered on tape already telecined to the 4:3 aspect-ratio, and contained a high level of grain, which resulted in further image noise being present when enlarged and stretched for widescreen. For the purely live-action scenes, rather than using the film negatives, \"Warners had even forgotten that they had those. They used PAL versions and converted them to NTSC for the US market. They actually didn't go back and retransfer the shows.\"\n\nWith the resulting aliasing, and the progressive scan transfer of the video to DVD, this has created a number of visual flaws throughout the widescreen release. In particular, quality has been noted to drop significantly in composite shots.\n\n\n"}
{"id": "4801", "url": "https://en.wikipedia.org/wiki?curid=4801", "title": "BeOS", "text": "BeOS\n\nBeOS is an operating system for personal computers first developed by Be Inc. in 1991. It was first written to run on BeBox hardware. BeOS was built for digital media work and was written to take advantage of modern hardware facilities such as symmetric multiprocessing by utilizing modular I/O bandwidth, pervasive multithreading, preemptive multitasking and a 64-bit journaling file system known as BFS. The BeOS GUI was developed on the principles of clarity and a clean, uncluttered design.\n\nBeOS was positioned as a multimedia platform which could be used by a substantial population of desktop users and a competitor to Classic Mac OS and Microsoft Windows. However, it was ultimately unable to achieve a significant market share and proved commercially unviable for Be Inc. The company was acquired by Palm Inc. and today BeOS is mainly used and developed by a small population of enthusiasts.\n\nThe open-source OS Haiku, a complete reimplementation of BeOS, is designed to start up where BeOS left off. Alpha 4 of Haiku was released in November 2012.\n\nBeOS was optimized for digital media work and was written to take advantage of modern computer hardware facilities such as symmetric multiprocessing by utilizing modular I/O bandwidth, pervasive multithreading, preemptive multitasking and a 64-bit journaling file system known as BFS. The BeOS GUI was developed on the principles of clarity and a clean, uncluttered design.\n\nThe API was written in C++ for ease of programming. It has partial POSIX compatibility and access to a command-line interface through Bash, although internally it is not a Unix-derived operating system.\n\nBeOS used Unicode as the default encoding in the GUI, though support for input methods such as bidirectional text input was never realized.\n\nInitially designed to run on AT&T Hobbit-based hardware, BeOS was later modified to run on PowerPC-based processors: first Be's own systems, later Apple Inc.'s PowerPC Reference Platform and Common Hardware Reference Platform, with the hope that Apple would purchase or license BeOS as a replacement for its aging Classic Mac OS. Apple CEO Gil Amelio started negotiations to buy Be Inc., but negotiations stalled when Be CEO Jean-Louis Gassée wanted $300 million; Apple was unwilling to offer any more than $125 million. Apple's board of directors decided NeXTSTEP was a better choice and purchased NeXT in 1996 for $429 million, bringing back Apple co-founder Steve Jobs.\n\nIn 1997, Power Computing began bundling BeOS (on a CD for optional installation) with its line of PowerPC-based Macintosh clones. These systems could dual boot either the Classic Mac OS or BeOS, with a start-up screen offering the choice.\n\nDue to Apple's moves and the mounting debt of Be Inc., BeOS was soon ported to the Intel x86 platform with its R3 release in March 1998. Through the late 1990s, BeOS managed to create a niche of followers, but the company failed to remain viable. Be Inc. also released a stripped-down, but free, copy of BeOS R5 known as BeOS Personal Edition (BeOS PE). BeOS PE could be started from within Microsoft Windows or Linux, and was intended to nurture consumer interest in its product and give developers something to tinker with. Be Inc. also released a stripped-down version of BeOS for Internet Appliances (BeIA), which soon became the company's business focus in place of BeOS.\n\nIn 2001 Be's copyrights were sold to Palm, Inc. for some $11 million. BeOS R5 is considered the last official version, but BeOS R5.1 \"Dano\", which was under development before Be's sale to Palm and included the BeOS Networking Environment (BONE) networking stack, was leaked to the public shortly after the company's demise.\n\nIn 2002, Be Inc. sued Microsoft claiming that Hitachi had been dissuaded from selling PCs loaded with BeOS, and that Compaq had been pressured not to market an Internet appliance in partnership with Be. Be also claimed that Microsoft acted to artificially depress Be Inc.'s initial public offering (IPO). The case was eventually settled out of court for $23.25 million with no admission of liability on Microsoft's part.\n\nAfter the split from Palm, PalmSource used parts of BeOS's multimedia framework for its failed Palm OS Cobalt product. With the takeover of PalmSource, the BeOS rights now belong to Access Co.\n\nIn the years that followed the demise of Be Inc. a handful of projects formed to recreate BeOS or key elements of the OS with the eventual goal of then continuing where Be Inc. left off. This was facilitated by the fact that Be Inc. released some components of BeOS under a free licence. Here is a list of these projects:\n\nZeta was a commercially available operating system based on the BeOS R5.1 codebase. Originally developed by yellowTAB, the operating system was then distributed by magnussoft. During development by yellowTAB, the company received criticism from the BeOS community for refusing to discuss its legal position with regard to the BeOS codebase (perhaps for contractual reasons). Access Co. (which bought PalmSource, until then the holder of the intellectual property associated with BeOS) has since declared that yellowTAB had no right to distribute a modified version of BeOS, and magnussoft has ceased distribution of the operating system.\n\nBeOS (and now Zeta) continue to be used in media appliances such as the Edirol DV-7 video editors from Roland corporation which run on top of a modified BeOS and the TuneTracker radio automation software that used to run it on BeOS and Zeta, and it was also sold as a \"Station-in-a-Box\" with the Zeta operating system included. Nowadays TuneTracker has switched to Haiku.\n\nThe Tascam SX-1 digital audio recorder runs a heavily modified version of BeOS that will only launch the recording interface software.\n\niZ Technology Corporation sells the RADAR 24, RADAR V and RADAR Studio, hard disk-based, 24-track professional audio recorders based on BeOS 5, although the newer RADAR 6 is not based on BeOS.\n\nMagicbox, a manufacturer of signage and broadcast display machines, uses BeOS to power their Aavelin product line.\n\nFinal Scratch, a 12″ vinyl timecode record-driven DJ software/hardware system, was first developed on BeOS. The \"ProFS\" version was sold to a few dozen DJs prior to the 1.0 release, which ran on a Linux virtual partition.\n\n\n"}
{"id": "4802", "url": "https://en.wikipedia.org/wiki?curid=4802", "title": "Biome", "text": "Biome\n\nA biome is a community or large ecological area on the earth's surface with plants and animals that have common characteristics for the environment with specific climatic conditions to suit the flora and fauna, they exist in and can be found over a range of continents. Biomes are distinct biological communities that have formed in response to a shared physical climate. \"Biome\" is a broader term than \"habitat\"; any biome can comprise a variety of habitats.\n\nWhile a biome can cover large areas, a microbiome is a mix of organisms that coexist in a defined space on a much smaller scale. For example, the human microbiome is the collection of bacteria, viruses, and other microorganisms that are present on a human body.\n\nA 'biota' is the total collection of organisms of a geographic region or a time period, from local geographic scales and instantaneous temporal scales all the way up to whole-planet and whole-timescale spatiotemporal scales. The biotas of the Earth make up the biosphere.\n\nThe term was suggested in 1916 by Clements, originally as a synonym for biotic community of Möbius (1877). Later, it gained its current definition, based on earlier concepts of phytophysiognomy, formation and vegetation (used in opposition to flora), with the inclusion of the animal element and the exclusion of the taxonomic element of species composition. In 1935, Tansley added the climatic and soil aspects to the idea, calling it ecosystem. The International Biological Program (1964–74) projects popularized the concept of biome.\n\nHowever, in some contexts, the term biome is used in a different manner. In German literature, particularly in the Walter terminology, the term is used similarly as biotope (a concrete geographical unit), while the biome definition used in this article is used as an international, non-regional, terminology - irrespectively of the continent in which an area is present, it takes the same biome name - and corresponds to his \"zonobiome\", \"orobiome\" and \"pedobiome\" (biomes determinated by climate zone, altitude or soil).\n\nIn Brazilian literature, the term \"biome\" is sometimes used as synonym of \"biogeographic province\", an area based on species composition (the term \"floristic province\" being used when plant species are considered), or also as synonym of the \"morphoclimatic and phytogeographical domain\" of Ab'Sáber, a geographic space with subcontinental dimensions, with the predominance of similar geomorphologic and climatic characteristics, and of a certain vegetation form. Both includes many biomes in fact.\n\nTo divide the world in a few ecological zones is a difficult attempt, notably because of the small-scale variations that exist everywhere on earth and because of the gradual changeover from one biome to the other. Their boundaries must therefore be drawn arbitrarily and their characterization made according to the average conditions that predominate in them.\n\nA 1978 study on North American grasslands found a positive logistic correlation between evapotranspiration in mm/yr and above-ground net primary production in g/m/yr. The general results from the study were that precipitation and water use led to above-ground primary production, while solar irradiation and temperature lead to below-ground primary production (roots), and temperature and water lead to cool and warm season growth habit. These findings help explain the categories used in Holdridge’s bioclassification scheme (see below), which were then later simplified by Whittaker. The number of classification schemes and the variety of determinants used in those schemes, however, should be taken as strong indicators that biomes do not fit perfectly into the classification schemes created.\n\nHoldridge classified climates based on the biological effects of temperature and rainfall on vegetation under the assumption that these two abiotic factors are the largest determinants of the types of vegetation found in a habitat. Holdridge uses the four axes to define 30 so-called \"humidity provinces\", which are clearly visible in his diagram. While this scheme largely ignores soil and sun exposure, Holdridge acknowledged that these were important.\n\nThe principal biome-types by Allee (1949):\n\nThe principal biomes of the world by Kendeigh (1961):\n\nWhittaker classified biomes using two abiotic factors: precipitation and temperature. His scheme can be seen as a simplification of Holdridge's; more readily accessible, but missing Holdridge's greater specificity.\n\nWhittaker based his approach on theoretical assertions and empirical sampling. He was in a unique position to make such a holistic assertion because he had previously compiled a review of biome classifications.\n\n\nWhittaker's distinction between biome and formation can be simplified: formation is used when applied to plant communities only, while biome is used when concerned with both plants and animals. Whittaker's convention of biome-type or formation-type is simply a broader method to categorize similar communities. \n\nWhittaker, seeing the need for a simpler way to express the relationship of community structure to the environment, used what he called \"gradient analysis\" of ecocline patterns to relate communities to climate on a worldwide scale. Whittaker considered four main ecoclines in the terrestrial realm.\n\nAlong these gradients, Whittaker noted several trends that allowed him to qualitatively establish biome-types:\n\nWhittaker summed the effects of gradients (3) and (4) to get an overall temperature gradient, and combined this with gradient (2), the moisture gradient, to express the above conclusions in what is known as the Whittaker classification scheme. The scheme graphs average annual precipitation (x-axis) versus average annual temperature (y-axis) to classify biome-types.\n\n\nThe multiauthored series \"Ecosystems of the world\", edited by David W. Goodall, provides a comprehensive coverage of the major \"ecosystem types or biomes\" on earth:\n\nThe eponymously-named Heinrich Walter classification scheme considers the seasonality of temperature and precipitation. The system, also assessing precipitation and temperature, finds nine major biome types, with the important climate traits and vegetation types. The boundaries of each biome correlate to the conditions of moisture and cold stress that are strong determinants of plant form, and therefore the vegetation that defines the region. Extreme conditions, such as flooding in a swamp, can create different kinds of communities within the same biome.\n\nSchultz (1988) defined nine ecozones (note that his concept of ecozone is more similar to the concept of biome used in this article than to the concept of ecozone of BBC):\n\nRobert G. Bailey nearly developed a biogeographical classification system of ecoregions for the United States in a map published in 1976. He subsequently expanded the system to include the rest of North America in 1981, and the world in 1989. The Bailey system, based on climate, is divided into seven domains (polar, humid temperate, dry, humid, and humid tropical), with further divisions based on other climate characteristics (subarctic, warm temperate, hot temperate, and subtropical; marine and continental; lowland and mountain).\n\n\nA team of biologists convened by the World Wildlife Fund (WWF) developed a scheme that divided the world's land area into biogeographic realms (called \"ecozones\" in a BBC scheme), and these into ecoregions (Olson & Dinerstein, 1998, etc.). Each ecoregion is characterized by a main biome (also called major habitat type).\n\nThis classification is used to define the Global 200 list of ecoregions identified by the WWF as priorities for conservation.\n\nFor the terrestrial ecoregions, there is a specific EcoID, format XXnnNN (XX is the biogeographic realm, nn is the biome number, NN is the individual number).\n\n\nIt should be noted, however, that the applicability of the realms scheme above - based on Udvardy (1975) - to most freshwater taxa is unresolved.\n\n\n\nAccording to the WWF, the following are classified as freshwater biomes:\n\nBiomes of the coastal and continental shelf areas (neritic zone):\n\n\nExample: \n\nPruvot (1896) zones or \"systems\":\n\nLonghurst (1998) biomes:\n\nOther marine habitat types (not covered yet by the Global 200/WWF scheme):\n\nHumans have altered global patterns of biodiversity and ecosystem processes. As a result, vegetation forms predicted by conventional biome systems can no longer be observed across much of Earth's land surface as they have been replaced by crop and rangelands or cities. Anthropogenic biomes provide an alternative view of the terrestrial biosphere based on global patterns of sustained direct human interaction with ecosystems, including agriculture, human settlements, urbanization, forestry and other uses of land. Anthropogenic biomes offer a new way forward in ecology and conservation by recognizing the irreversible coupling of human and ecological systems at global scales and moving us toward an understanding of how best to live in and manage our biosphere and the anthropogenic biomes we live in.\n\nMajor anthropogenic biomes:\n\nThe endolithic biome, consisting entirely of microscopic life in rock pores and cracks, kilometers beneath the surface, has only recently been discovered, and does not fit well into most classification schemes.\n\nThe dermal biome is the living ecosystem that animals (including humans) have evolved, that permits them to live symbiotically and in balance with the microbes on and in them (the microbiome). This ecosystem consists of skin, follicles, hair, sebaceous glands, sweat glands, arrector pili muscles, peptides, proteins, lipids and its associated microbiota.\nA healthy dermal biome has several functions: it resists infection of pathogens, protects against moisture loss and water damage, dynamically regulates body temperature and supports the healthy renewal of skin through the epidermal cell life cycle.\n\n"}
{"id": "4805", "url": "https://en.wikipedia.org/wiki?curid=4805", "title": "Behavior", "text": "Behavior\n\nBehavior (American English) or behaviour (Commonwealth English) is the range of actions and mannerisms made by individuals, organisms, systems, or artificial entities in conjunction with themselves or their environment, which includes the other systems or organisms around as well as the (inanimate) physical environment. It is the response of the system or organism to various stimuli or inputs, whether internal or external, conscious or subconscious, overt or covert, and voluntary or involuntary.\n\nTaking a behavior informatics perspective, a behavior consists of behavior actor, operation, interactions, and their properties. A behavior can be represented as a behavior vector.\n\nAlthough there is some disagreement as to how to precisely define behavior in a biological context, one common interpretation based on a meta-analysis of scientific literature states that \"behavior is the internally coordinated responses (actions or inactions) of whole living organisms (individuals or groups) to internal and/or external stimuli\".\n\nA broader definition of behavior, applicable to plants and other organisms, is similar to the concept of phenotypic plasticity. It describes behavior as a response to an event or environment change during the course of the lifetime of an individual, differing from other physiological or biochemical changes that occurs more rapidly, and excluding changes that are result of development (ontogeny).\n\nBehaviors can be either innate or learned.\n\nBehavior can be regarded as any action of an organism that changes its relationship to its environment. Behavior provides outputs from the organism to the environment.\n\nHuman behavior is believed to be influenced by the endocrine system and the nervous system. It is most commonly believed that complexity in the behavior of an organism is correlated to the complexity of its nervous system. Generally, organisms with more complex nervous systems have a greater capacity to learn new responses and thus adjust their behavior.\n\nConsumers behavior\n\nConsumer behavior refers to the processes consumers go through, and reactions they have towards products or services (Dowhan, 2013). It is to do with consumption, and the processes consumers go through around purchasing and consuming goods and services (Szwacka-Mokrzycka, 2015). Consumers recognise needs or wants, and go through a process to satisfy these needs. Consumer behavior is the process they go through as customers, which includes types of products purchased, amount spent, frequency of purchases and what influences them to make the purchase decision or not. There is a lot that influences consumer behavior, with contributions from both internal and external factors (Szwacka-Mokrzycka, 2015). Internal factors include attitudes, needs, motives, preferences and perceptual processes, whilst external factors include marketing activities, social and economic factors, and cultural aspects (Szwacka-Mokrzycka, 2015). Doctor Lars Perner of the University of Southern California claims that there are also physical factors that influence consumer behavior, for example if a consumer is hungry, then this physical feeling of hunger will influence them so that they go and purchase a sandwich to satisfy the hunger (Perner, 2008).\n\nConsumer decision making\n\nThere is a model described by Lars Perner which illustrates the decision making process with regards to consumer behavior. It begins with recognition of a problem, the consumer recognises a need or want which has not been satisfied. This leads the consumer to search for information, if it is a low involvement product then the search will be internal, identifying alternatives purely from memory. If the product is high involvement then the search be more thorough, such as reading reviews or reports or asking friends. The consumer will then evaluate his or her alternatives, comparing price, quality, doing trade-offs between products and narrowing down the choice by eliminating the less appealing products until there is one left. After this has been identified, the consumer will purchase the product. Finally the consumer will evaluate the purchase decision, and the purchased product, bringing in factors such as value for money, quality of goods and purchase experience (Model taken from Perner, 2008).\n\nHow the 4P’s influence consumer behavior\n\nThe 4 P’s are a marketing tool, and stand for Price, Promotion, Product and Place or Product Placement (Clemons, 2008). Consumer behavior is influenced greatly by business to consumer marketing, so being a prominent marketing tool, the 4 P’s will have an effect on consumer’s behavior. The price of a good or service is largely determined by the market, as businesses will set their prices to be similar to that of other business so as to remain competitive whilst making a profit (Clemons, 2008). When market prices for a product are high, it will cause consumers to purchase less and use purchased goods for longer periods of time, meaning they are purchasing the product less often. Alternatively, when market prices for a product are low, consumers are more likely to purchase more of the product, and more often. The way that promotion influences consumer behavior has changed over time. In the past, large promotional campaigns and lots of advertising would convert into sales for a business, but nowadays businesses can have success on products with little or no advertising (Clemons, 2008). This is due to the internet, and in particular social media. They rely on word of mouth from consumers using social media, and as products trend online, so sales increase as products effectively promote themselves (Clemons, 2008). Thus, promotion by businesses does not necessarily result in consumer behavior trending towards purchasing products. The way that product influences consumer behavior is through consumer willingness to pay, and consumer preferences (Clemons, 2008). This means that even if a company were to have a long history of products in the market, consumers will still pick a cheaper product over the company in question’s product if it means they will pay less for something that is very similar (Clemons, 2008). This is due to consumer willingness to pay, or their willingness to part with their money they have earned. Product also influences consumer behavior through customer preferences. For example, take Pepsi vs Coca-Cola, a Pepsi drinker is less likely to purchase Coca-Cola, even if it is cheaper and more convenient. This is due to the preference of the consumer, and no matter how hard the opposing company tries they will not be able to force the customer to change their mind. Product placement in the modern era has little influence on consumer behavior, due to the availability of goods online (Clemons, 2008). If a customer can purchase a good from the comfort of their home instead of purchasing in-store, then the placement of products is not going to influence their purchase decision.\n\nBehavior outside of psychology includes:\n\nIn management, behaviors are associated with desired or undesired focuses. Managers generally note what the desired outcome is, but behavioral patterns can take over. These patterns are the reference to how often the desired behavior actually occurs. Before a behavior actually occurs, antecedents focus on the stimuli that influence the behavior that is about to happen. After the behavior occurs, consequences fall into place. Consequences consist of rewards or punishments.\n\nBehavior informatics is also called \"behavior computing\", explores behavior intelligence and behavior insights from the informatics and computing perspectives.\n\nHealth behavior refers to a person's beliefs and actions regarding their health and well-being. Health behaviors are direct factors in maintaining a healthy lifestyle. Health behaviors are influenced by the social, cultural and physical environments in which we live and work. They are shaped by individual choices and external constraints. Positive behaviors help promote health and prevent disease, while the opposite is true for risk behaviors. Health behaviors are early indicators of population health. Because of the time lag that often occurs between certain behaviors and the development of disease, these indicators may foreshadow the future burdens and benefits of health-risk and health-promoting behaviors. Health behaviors do not occur in isolation—they are influenced and constrained by social and cultural norms.\n\nA variety of studies have examined the relationship between health behaviors and health outcomes (e.g., Blaxter 1990) and have demonstrated their role in both morbidity and mortality.\n\nTheses studies have identified seven features of lifestyle which were associated with lower morbidity and higher subsequent long-term survival (Belloc and Breslow 1972):\n\nHealth behaviors impact upon individuals' quality of life, by delaying the onset of chronic disease and extending active lifespan. Smoking, alcohol consumption, diet, gaps in primary care services and low screening uptake are all significant determinants of poor health, and changing such behaviors should lead to improved health.\nFor example, in USA, Healthy People 2000, United States Department of Health and Human Services (USDHHS), lists increased physical activity, changes in nutrition and reductions in tobacco, alcohol and drug use as important for health promotion and disease prevention.\n\nAny interventions done are matched with the needs of each individual in an ethical and respected manner. HBM encourages increasing individuals' perceived susceptibility to negative health outcomes and making individuals aware of the severity of such negative health behavior outcomes. E.g. through health promotion messages. In addition, the HBM suggests the need to focus on the benefits of health behaviors and the fact that barriers to action are easily overcome. TPB suggests using persuasive messages for tackling behavioral beliefs to increase the more response towards the issue (\"intentions\"). TPB advocates the need to tackle normative beliefs and control beliefs in any attempt to change behavior. Challenging the normative beliefs isn't enough but to follow through the \"intention\" with self efficacy from individual's mastery in problem solving and task completion is important to bring about a positive change. Self efficacy is often cemented through standard persuasive techniques.\n\n\n\n"}
{"id": "4806", "url": "https://en.wikipedia.org/wiki?curid=4806", "title": "Battle of Marathon", "text": "Battle of Marathon\n\nThe Battle of Marathon (Greek: , \"Machē tou Marathōnos\") took place in 490 BC, during the first Persian invasion of Greece. It was fought between the citizens of Athens, aided by Plataea, and a Persian force commanded by Datis and Artaphernes. The battle was the culmination of the first attempt by Persia, under King Darius I, to subjugate Greece. The Greek army decisively defeated the more numerous Persians, marking a turning point in the Greco-Persian Wars.\n\nThe first Persian invasion was a response to Athenian involvement in the Ionian Revolt, when Athens and Eretria had sent a force to support the cities of Ionia in their attempt to overthrow Persian rule. The Athenians and Eretrians had succeeded in capturing and burning Sardis, but they were then forced to retreat with heavy losses. In response to this raid, Darius swore to burn down Athens and Eretria. According to Herodotus, Darius had his bow brought to him and then shot an arrow \"upwards towards heaven\", saying as he did so: \"Zeus, that it may be granted me to take vengeance upon the Athenians!\". Herodotus further writes that Darius charged one of his servants to say \"Master, remember the Athenians\" three times before dinner each day.\n\nAt the time of the battle, Sparta and Athens were the two largest city states. Once the Ionian revolt was finally crushed by the Persian victory at the Battle of Lade in 494 BC, Darius began plans to subjugate Greece. In 490 BC, he sent a naval task force under Datis and Artaphernes across the Aegean, to subjugate the Cyclades, and then to make punitive attacks on Athens and Eretria. Reaching Euboea in mid-summer after a successful campaign in the Aegean, the Persians proceeded to besiege and capture Eretria. The Persian force then sailed for Attica, landing in the bay near the town of Marathon. The Athenians, joined by a small force from Plataea, marched to Marathon, and succeeded in blocking the two exits from the plain of Marathon. The Athenians also sent a message asking for support to the Spartans. When the messenger arrived in Sparta, the Spartans were involved in a religious festival and gave this as a reason for not coming to aid of the Athenians.\n\nThe Athenians and their allies chose a location for the battle, with marshes and mountainous terrain, that prevented the Persian cavalry from joining the main Persian army. Miltiades, the Athenian general, ordered a general attack against the Persians. He reinforced his flanks, luring the Persians' best fighters into his center. The inward wheeling flanks enveloped the Persians, routing them. The Persian army broke in panic towards their ships, and large numbers were slaughtered. The defeat at Marathon marked the end of the first Persian invasion of Greece, and the Persian force retreated to Asia. Darius then began raising a huge new army with which he meant to completely subjugate Greece; however, in 486 BC, his Egyptian subjects revolted, indefinitely postponing any Greek expedition. After Darius died, his son Xerxes I restarted the preparations for a second invasion of Greece, which finally began in 480 BC.\n\nThe Battle of Marathon was a watershed in the Greco-Persian wars, showing the Greeks that the Persians could be beaten; the eventual Greek triumph in these wars can be seen to begin at Marathon. The battle also showed the Greeks that they were able to win battles without the Spartans, as they had heavily relied on Sparta previously. This win was largely due to the Athenians, and Marathon raised Greek esteem of them. Since the following two hundred years saw the rise of the Classical Greek civilization, which has been enduringly influential in western society, the Battle of Marathon is often seen as a pivotal moment in Mediterranean and European history.\n\nThe main source for the Greco-Persian Wars is the Greek historian Herodotus. Herodotus, who has been called the \"Father of History\", was born in 484 BC in Halicarnassus, Asia Minor (then under Persian overlordship). He wrote his \"Enquiries\" (Greek – \"Historia\"; English – \"(The) Histories\") around 440–430 BC, trying to trace the origins of the Greco-Persian Wars, which would still have been relatively recent history (the wars finally ended in 450 BC). Herodotus's approach was entirely novel, and at least in Western society, he does seem to have invented \"history\" as we know it. As Holland has it: \"For the first time, a chronicler set himself to trace the origins of a conflict not to a past so remote so as to be utterly fabulous, nor to the whims and wishes of some god, nor to a people's claim to manifest destiny, but rather explanations he could verify personally.\"\n\nSome subsequent ancient historians, despite following in his footsteps, criticised Herodotus, starting with Thucydides. Nevertheless, Thucydides chose to begin his history where Herodotus left off (at the Siege of Sestos), and may therefore have felt that Herodotus's history was accurate enough not to need re-writing or correcting. Plutarch criticised Herodotus in his essay \"On the malice of Herodotus\", describing Herodotus as \"\"Philobarbaros\"\" (barbarian-lover), for not being pro-Greek enough, which suggests that Herodotus might actually have done a reasonable job of being even-handed. A negative view of Herodotus was passed on to Renaissance Europe, though he remained well read. However, since the 19th century his reputation has been dramatically rehabilitated by archaeological finds which have repeatedly confirmed his version of events. The prevailing modern view is that Herodotus generally did a remarkable job in his \"Historia\", but that some of his specific details (particularly troop numbers and dates) should be viewed with skepticism. Nevertheless, there are still some historians who believe Herodotus made up much of his story.\n\nThe Sicilian historian Diodorus Siculus, writing in the 1st century BC in his \"Bibliotheca Historica\", also provides an account of the Greco-Persian wars, partially derived from the earlier Greek historian Ephorus. This account is fairly consistent with Herodotus's. The Greco-Persian wars are also described in less detail by a number of other ancient historians including Plutarch, Ctesias of Cnidus, and are alluded by other authors, such as the playwright Aeschylus. Archaeological evidence, such as the Serpent Column, also supports some of Herodotus's specific claims.\n\nThe first Persian invasion of Greece had its immediate roots in the Ionian Revolt, the earliest phase of the Greco-Persian Wars. However, it was also the result of the longer-term interaction between the Greeks and Persians. In 500 BC the Persian Empire was still relatively young and highly expansionistic, but prone to revolts amongst its subject peoples. Moreover, the Persian King Darius was a usurper, and had spent considerable time extinguishing revolts against his rule. Even before the Ionian Revolt, Darius had begun to expand the empire into Europe, subjugating Thrace, and forcing Macedon to become a vassal of Persia. Attempts at further expansion into the politically fractious world of ancient Greece may have been inevitable. However, the Ionian Revolt had directly threatened the integrity of the Persian empire, and the states of mainland Greece remained a potential menace to its future stability. Darius thus resolved to subjugate and pacify Greece and the Aegean, and to punish those involved in the Ionian Revolt.\n\nThe Ionian Revolt had begun with an unsuccessful expedition against Naxos, a joint venture between the Persian satrap Artaphernes and the Milesian tyrant Aristagoras. In the aftermath, Artaphernes decided to remove Aristagoras from power, but before he could do so, Aristagoras abdicated, and declared Miletus a democracy. The other Ionian cities followed suit, ejecting their Persian-appointed tyrants, and declaring themselves democracies. Aristagoras then appealed to the states of mainland Greece for support, but only Athens and Eretria offered to send troops.\n\nThe involvement of Athens in the Ionian Revolt arose from a complex set of circumstances, beginning with the establishment of the Athenian Democracy in the late 6th century BC.\n\nIn 510 BC, with the aid of Cleomenes I, King of Sparta, the Athenian people had expelled Hippias, the tyrant ruler of Athens. With Hippias's father Peisistratus, the family had ruled for 36 out of the previous 50 years and fully intended to continue Hippias's rule. Hippias fled to Sardis to the court of the Persian satrap, Artaphernes and promised control of Athens to the Persians if they were to help restore him. In the meantime, Cleomenes helped install a pro-Spartan tyranny under Isagoras in Athens, in opposition to Cleisthenes, the leader of the traditionally powerful Alcmaeonidae family, who considered themselves the natural heirs to the rule of Athens. Cleisthenes, however, found himself being politically defeated by a coalition led by Isagoras and decided to change the rules of the game by appealing to the \"demos\" (the people), in effect making them a new faction in the political arena. This tactic succeeded, but the Spartan King, Cleomenes I, returned at the request of Isagoras and so Cleisthenes, the Alcmaeonids and other prominent Athenian families were exiled from Athens. When Isagoras attempted to create a narrow oligarchic government, the Athenian people, in a spontaneous and unprecedented move, expelled Cleomenes and Isagoras. Cleisthenes was thus restored to Athens (507 BC), and at breakneck speed began to reform the state with the aim of securing his position. The result was not actually a democracy or a real civic state, but he enabled the development of a fully democratic government, which would emerge in the next generation as the demos realized its power. The new-found freedom and self-governance of the Athenians meant that they were thereafter exceptionally hostile to the return of the tyranny of Hippias, or any form of outside subjugation, by Sparta, Persia, or anyone else.\n\nCleomenes was not pleased with events, and marched on Athens with the Spartan army. Cleomenes's attempts to restore Isagoras to Athens ended in a debacle, but fearing the worst, the Athenians had by this point already sent an embassy to Artaphernes in Sardis, to request aid from the Persian empire. Artaphernes requested that the Athenians give him an 'earth and water', a traditional token of submission, to which the Athenian ambassadors acquiesced. They were, however, severely censured for this when they returned to Athens. At some later point Cleomenes instigated a plot to restore Hippias to the rule of Athens. This failed and Hippias again fled to Sardis and tried to persuade the Persians to subjugate Athens. The Athenians dispatched ambassadors to Artaphernes to dissuade him from taking action, but Artaphernes merely instructed the Athenians to take Hippias back as tyrant. The Athenians indignantly declined, and instead resolved to open war with Persia. Having thus become the enemy of Persia, Athens was already in a position to support the Ionian cities when they began their revolt. The fact that the Ionian democracies were inspired by the example the Athenians had set no doubt further persuaded the Athenians to support the Ionian Revolt, especially since the cities of Ionia were originally Athenian colonies.\n\nThe Athenians and Eretrians sent a task force of 25 triremes to Asia Minor to aid the revolt. Whilst there, the Greek army surprised and outmaneuvered Artaphernes, marching to Sardis and burning the lower city. This was, however, as much as the Greeks achieved, and they were then repelled and pursued back to the coast by Persian horsemen, losing many men in the process. Despite the fact that their actions were ultimately fruitless, the Eretrians and in particular the Athenians had earned Darius's lasting enmity, and he vowed to punish both cities. The Persian naval victory at the Battle of Lade (494 BC) all but ended the Ionian Revolt, and by 493 BC, the last hold-outs were vanquished by the Persian fleet. The revolt was used as an opportunity by Darius to extend the empire's border to the islands of the eastern Aegean and the Propontis, which had not been part of the Persian dominions before. The pacification of Ionia allowed the Persians to begin planning their next moves; to extinguish the threat to the empire from Greece and to punish Athens and Eretria.\n\nIn 492 BC, after the Ionian Revolt had finally been crushed, Darius dispatched an to Greece under the command of his son-in-law, Mardonius. Mardonius re-subjugated Thrace and made Macedonia a fully subordinate part of the Persians; they had been vassals of the Persians since the late 6th century BC, but retained their general autonomy. Not long after however, his fleet became wrecked by a violent storm, which brought a premature end to the campaign.\nHowever, in 490 BC, following the successes of the previous campaign, Darius decided to send a maritime expedition led by Artaphernes, (son of the satrap to whom Hippias had fled) and Datis, a Median admiral. Mardonius had been injured in the prior campaign and had fallen out of favor. The was intended to bring the Cyclades into the Persian empire, to punish Naxos (which had resisted a Persian assault in 499 BC) and then to head to Greece to force Eretria and Athens to submit to Darius or be destroyed. After island-hopping across the Aegean, including successfully attacking Naxos, the Persian task force arrived off Euboea in mid summer. The Persians then proceeded to besiege, capture and burn Eretria. They then headed south down the coast of Attica, en route to complete the final objective of the campaign—punish Athens.\n\nThe Persians sailed down the coast of Attica, and landed at the bay of Marathon, roughly from Athens, on the advice of the exiled Athenian tyrant Hippias (who had accompanied the expedition). Under the guidance of Miltiades, the Athenian general with the greatest experience of fighting the Persians, the Athenian army marched quickly to block the two exits from the plain of Marathon, and prevent the Persians moving inland. At the same time, Athens's greatest runner, Pheidippides (or Philippides in some accounts) had been sent to Sparta to request that the Spartan army march to the aid of Athens. Pheidippides arrived during the festival of \"Carneia\", a sacrosanct period of peace, and was informed that the Spartan army could not march to war until the full moon rose; Athens could not expect reinforcement for at least ten days. The Athenians would have to hold out at Marathon for the time being, although they were reinforced by the full muster of 1,000 hoplites from the small city of Plataea; a gesture which did much to steady the nerves of the Athenians, and won unending Athenian gratitude to Plataea.\n\nFor approximately five days the armies therefore confronted each other across the plain of Marathon in stalemate. The flanks of the Athenian camp were protected either by a grove of trees, or an \"abbatis\" of stakes (depending on the exact reading). Since every day brought the arrival of the Spartans closer, the delay worked in favor of the Athenians. There were ten Athenian \"strategoi\" (generals) at Marathon, elected by each of the ten tribes that the Athenians were divided into; Miltiades was one of these. In addition, in overall charge, was the War-Archon (\"polemarch\"), Callimachus, who had been elected by the whole citizen body. Herodotus suggests that command rotated between the \"strategoi\", each taking in turn a day to command the army. He further suggests that each \"strategos\", on his day in command, instead deferred to Miltiades. In Herodotus's account, Miltiades is keen to attack the Persians (despite knowing that the Spartans are coming to aid the Athenians), but strangely, chooses to wait until his actual day of command to attack. This passage is undoubtedly problematic; the Athenians had little to gain by attacking before the Spartans arrived, and there is no real evidence of this rotating generalship. There does, however, seem to have been a delay between the Athenian arrival at Marathon, and the battle; Herodotus, who evidently believed that Miltiades was eager to attack, may have made a mistake whilst seeking to explain this delay.\n\nAs is discussed below, the reason for the delay was probably simply that neither the Athenians nor the Persians were willing to risk battle initially. This then raises the question of why the battle occurred when it did. Herodotus explicitly tells us that the Greeks attacked the Persians (and the other sources confirm this), but it is not clear why they did this before the arrival of the Spartans. There are two main theories to explain this.\n\nThe first theory is that the Persian cavalry left Marathon for an unspecified reason, and that the Greeks moved to take advantage of this by attacking. This theory is based on the absence of any mention of cavalry in Herodotus' account of the battle, and an entry in the Suda dictionary. The entry \"χωρίς ἰππεῖς\" (\"without cavalry\") is explained thus: The cavalry left. When Datis surrendered and was ready for retreat, the Ionians climbed the trees and gave the Athenians the signal that the cavalry had left. And when Miltiades realized that, he attacked and thus won. From there comes the above-mentioned quote, which is used when someone breaks ranks before battle. There are many variations of this theory, but perhaps the most prevalent is that the cavalry was re-embarked on the ships, and was to be sent by sea to attack (undefended) Athens in the rear, whilst the rest of the Persians pinned down the Athenian army at Marathon. This theory therefore utilises Herodotus' suggestion that after Marathon, the Persian army re-embarked and tried to sail around Cape Sounion to attack Athens directly; however, according to the theory this attempt would have occurred \"before\" the battle (and indeed have triggered the battle).\n\nThe second theory is simply that the battle occurred because the Persians finally moved to attack the Athenians. Although this theory has the Persians moving to the \"strategic\" offensive, this can be reconciled with the traditional account of the Athenians attacking the Persians by assuming that, seeing the Persians advancing, the Athenians took the \"tactical\" offensive, and attacked them. Obviously, it cannot be firmly established which theory (if either) is correct. However, both theories imply that there was some kind of Persian activity which occurred on or about the fifth day which ultimately triggered the battle. It is also possible that both theories are correct: when the Persians sent the cavalry by ship to attack Athens, they simultaneously sent their infantry to attack at Marathon, triggering the Greek counterattack.\n\nHerodotus mentions for several events a date in the lunisolar calendar, of which each Greek city-state used a variant. Astronomical computation allows us to derive an absolute date in the proleptic Julian calendar which is much used by historians as the chronological frame. Philipp August Böckh in 1855 concluded that the battle took place on September 12, 490 BC in the Julian calendar, and this is the conventionally accepted date. However, this depends on when exactly the Spartans held their festival and it is possible that the Spartan calendar was one month ahead of that of Athens. In that case the battle took place on August 12, 490 BC.\n\nHerodotus does not give a figure for the size of the Athenian army. However, Cornelius Nepos, Pausanias and Plutarch all give the figure of 9,000 Athenians and 1,000 Plataeans; while Justin suggests that there were 10,000 Athenians and 1,000 Plataeans. These numbers are highly comparable to the number of troops Herodotus says that the Athenians and Plataeans sent to the Battle of Plataea 11 years later. Pausanias noticed on the monument to the battle the names of former slaves who were freed in exchange for military services. Modern historians generally accept these numbers as reasonable.\n\nAccording to Herodotus, the fleet sent by Darius consisted of 600 triremes. Herodotus does not estimate the size of the Persian army, only saying that they were a \"large infantry that was well packed\". Among ancient sources, the poet Simonides, another near-contemporary, says the campaign force numbered 200,000; while a later writer, the Roman Cornelius Nepos estimates 200,000 infantry and 10,000 cavalry, of which only 100,000 fought in the battle, while the rest were loaded into the fleet that was rounding Cape Sounion; Plutarch and Pausanias both independently give 300,000, as does the Suda dictionary. Plato and Lysias give 500,000; and Justinus 600,000.\n\nModern historians have proposed wide-ranging numbers for the infantry, from 20,000–100,000 with a consensus of perhaps 25,000; estimates for the cavalry are in the range of 1,000.\n\nFrom a strategic point of view, the Athenians had some disadvantages at Marathon. In order to face the Persians in battle, the Athenians had to summon all available hoplites; and even then they were still probably outnumbered at least 2 to 1. Furthermore, raising such a large army had denuded Athens of defenders, and thus any secondary attack in the Athenian rear would cut the army off from the city; and any direct attack on the city could not be defended against. Still further, defeat at Marathon would mean the complete defeat of Athens, since no other Athenian army existed. The Athenian strategy was therefore to keep the Persian army pinned down at Marathon, blocking both exits from the plain, and thus preventing themselves from being outmaneuvered. However, these disadvantages were balanced by some advantages. The Athenians initially had no need to seek battle, since they had managed to confine the Persians to the plain of Marathon. Furthermore, time worked in their favour, as every day brought the arrival of the Spartans closer. Having everything to lose by attacking, and much to gain by waiting, the Athenians remained on the defensive in the run up to the battle. Tactically, hoplites were vulnerable to attacks by cavalry, and since the Persians had substantial numbers of cavalry, this made any offensive maneuver by the Athenians even more of a risk, and thus reinforced the defensive strategy of the Athenians.\n\nThe Persian strategy, on the other hand, was probably principally determined by tactical considerations. The Persian infantry was evidently lightly armoured, and no match for hoplites in a head-on confrontation (as would be demonstrated at the later battles of Thermopylae and Plataea.) Since the Athenians seem to have taken up a strong defensive position at Marathon, the Persian hesitance was probably a reluctance to attack the Athenians head-on.\n\nWhatever event eventually triggered the battle, it obviously altered the strategic or tactical balance sufficiently to induce the Athenians to attack the Persians. If the first theory is correct (see above), then the absence of cavalry removed the main Athenian tactical disadvantage, and the threat of being outflanked made it imperative to attack. Conversely, if the second theory is correct, then the Athenians were merely reacting to the Persians attacking them. Since the Persian force obviously contained a high proportion of missile troops, a static defensive position would have made little sense for the Athenians; the strength of the hoplite was in the melee, and the sooner that could be brought about, the better, from the Athenian point of view. If the second theory is correct, this raises the further question of why the Persians, having hesitated for several days, then attacked. There may have been several strategic reasons for this; perhaps they were aware (or suspected) that the Athenians were expecting reinforcements. Alternatively, since they may have felt the need to force some kind of victory—they could hardly remain at Marathon indefinitely.\n\nThe distance between the two armies at the point of battle had narrowed to \"a distance not less than 8 stadia\" or about 1,500 meters. Miltiades ordered the two tribes forming the center of the Greek formation, the Leontis tribe led by Themistocles and the Antiochis tribe led by Aristides, to be arranged in the depth of four ranks while the rest of the tribes at their flanks were in ranks of eight. Some modern commentators have suggested this was a deliberate ploy to encourage a double envelopment of the Persian centre. However, this suggests a level of training that the Greeks were thought not to possess. There is little evidence for any such tactical thinking in Greek battles until Leuctra in 371 BC. It is therefore possible that this arrangement was made, perhaps at the last moment, so that the Athenian line was as long as the Persian line, and would not therefore be outflanked.\n\nWhen the Athenian line was ready, according to one source, the simple signal to advance was given by Miltiades: \"At them\". Herodotus implies the Athenians ran the whole distance to the Persian lines, a feat under the weight of hoplite armory generally thought to be physically impossible. More likely, they marched until they reached the limit of the archers' effectiveness, the \"beaten zone\" (roughly 200 meters), and then broke into a run towards their enemy. Another possibility is that they ran \"up to\" the 200 meter-mark in broken ranks, and then reformed for the march into battle from there. Herodotus suggests that this was the first time a Greek army ran into battle in this way; this was probably because it was the first time that a Greek army had faced an enemy composed primarily of missile troops. All this was evidently much to the surprise of the Persians; \"... in their minds they charged the Athenians with madness which must be fatal, seeing that they were few and yet were pressing forwards at a run, having neither cavalry nor archers\". Indeed, based on their previous experience of the Greeks, the Persians might be excused for this; Herodotus tells us that the Athenians at Marathon were \"first to endure looking at Median dress and men wearing it, for up until then just hearing the name of the Medes caused the Hellenes to panic\". Passing through the hail of arrows launched by the Persian army, protected for the most part by their armour, the Greek line finally collided with the enemy army. Holland provides an evocative description:\n\nThe enemy directly in their path ... realised to their horror that [the Athenians], far from providing the easy pickings for their bowmen, as they had first imagined, were not going to be halted ... The impact was devastating. The Athenians had honed their style of fighting in combat with other phalanxes, wooden shields smashing against wooden shields, iron spear tips clattering against breastplates of bronze ... in those first terrible seconds of collision, there was nothing but a pulverizing crash of metal into flesh and bone; then the rolling of the Athenian tide over men wearing, at most, quilted jerkins for protection, and armed, perhaps, with nothing more than bows or slings. The hoplites' ash spears, rather than shivering ... could instead stab and stab again, and those of the enemy who avoided their fearful jabbing might easily be crushed to death beneath the sheer weight of the advancing men of bronze.\n\nThe Athenian wings quickly routed the inferior Persian levies on the flanks, before turning inwards to surround the Persian centre, which had been more successful against the thin Greek centre. The battle ended when the Persian centre then broke in panic towards their ships, pursued by the Greeks. Some, unaware of the local terrain, ran towards the swamps where unknown numbers drowned. The Athenians pursued the Persians back to their ships, and managed to capture seven ships, though the majority were able to launch successfully. Herodotus recounts the story that Cynaegirus, brother of the playwright Aeschylus, who was also among the fighters, charged into the sea, grabbed one Persian trireme, and started pulling it towards shore. A member of the crew saw him, cut off his hand, and Cynaegirus died.\n\nHerodotus records that 6,400 Persian bodies were counted on the battlefield, and it is unknown how many more perished in the swamps. The Athenians lost 192 men and the Plataeans 11. Among the dead were the war archon Callimachus and the general Stesilaos.\n\nThere are several explanations of the Greek success. Most scholars believe that the Greeks had better equipment and used superior tactics. According to Herodotus, the Greeks were better equipped. They did not use bronze upper body armour at this time, but that of leather or linen. The phalanx formation proved successful, because the hoplites had a long tradition in hand-to-hand combat, whereas the Persian soldiers were accustomed to a very different kind of conflict. At Marathon, the Athenians thinned their centre in order to make their army equal in length to the Persian army, not as a result of a tactical planning. It seems that the Persian centre tried to return, realizing that their wings had broken, and was caught in the flanks by the victorious Greek wings. Lazenby believes that the ultimate reason for the Greek success was the courage the Greeks displayed:\n\nIn the immediate aftermath of the battle, Herodotus says that the Persian fleet sailed around Cape Sounion to attack Athens directly. As has been discussed above, some modern historians place this attempt just before the battle. Either way, the Athenians evidently realised that their city was still under threat, and marched as quickly as possible back to Athens.\nThe two tribes which had been in the centre of the Athenian line stayed to guard the battlefield under the command of Aristides. The Athenians arrived in time to prevent the Persians from securing a landing, and seeing that the opportunity was lost, the Persians turned about and returned to Asia. Connected with this episode, Herodotus recounts a rumour that this manoeuver by the Persians had been planned in conjunction with the Alcmaeonids, the prominent Athenian aristocratic family, and that a \"shield-signal\" had been given after the battle. Although many interpretations of this have been offered, it is impossible to tell whether this was true, and if so, what exactly the signal meant. On the next day, the Spartan army arrived at Marathon, having covered the in only three days. The Spartans toured the battlefield at Marathon, and agreed that the Athenians had won a great victory.\nThe dead of Marathon were buried on the battlefield. On the tomb of the Athenians this epigram composed by Simonides was written:\n\nIn the meanwhile, Darius began raising a huge new army with which he meant to completely subjugate Greece; however, in 486 BC, his Egyptian subjects revolted, indefinitely postponing any Greek expedition. Darius then died whilst preparing to march on Egypt, and the throne of Persia passed to his son Xerxes I. Xerxes crushed the Egyptian revolt, and very quickly restarted the preparations for the invasion of Greece. The epic second Persian invasion of Greece finally began in 480 BC, and the Persians met with initial success at the battles of Thermopylae and Artemisium. However, defeat at the Battle of Salamis would be the turning point in the campaign, and the next year the expedition was ended by the decisive Greek victory at the Battle of Plataea.\n\nThe defeat at Marathon barely touched the vast resources of the Persian empire, yet for the Greeks it was an enormously significant victory. It was the first time the Greeks had beaten the Persians, proving that the Persians were not invincible, and that resistance, rather than subjugation, was possible.\n\nThe battle was a defining moment for the young Athenian democracy, showing what might be achieved through unity and self-belief; indeed, the battle effectively marks the start of a \"golden age\" for Athens. This was also applicable to Greece as a whole; \"their victory endowed the Greeks with a faith in their destiny that was to endure for three centuries, during which western culture was born\". John Stuart Mill's famous opinion was that \"the Battle of Marathon, even as an event in British history, is more important than the Battle of Hastings\". It seems that the Athenian playwright Aeschylus considered his participation at Marathon to be his greatest achievement in life (rather than his plays) since on his gravestone there was the following epigram:\n\nMilitarily, a major lesson for the Greeks was the potential of the hoplite phalanx. This style had developed during internecine warfare amongst the Greeks; since each city-state fought in the same way, the advantages and disadvantages of the hoplite phalanx had not been obvious. Marathon was the first time a phalanx faced more lightly armed troops, and revealed how effective the hoplites could be in battle. The phalanx formation was still vulnerable to cavalry (the cause of much caution by the Greek forces at the Battle of Plataea), but used in the right circumstances, it was now shown to be a potentially devastating weapon.\n\nThe most famous legend associated with Marathon is that of the runner Pheidippides (or Philippides) bringing news to Athens of the battle, which is described below.\n\nPheidippides' run to Sparta to bring aid has other legends associated with it. Herodotus mentions that Pheidippides was visited by the god Pan on his way to Sparta (or perhaps on his return journey). Pan asked why the Athenians did not honor him and the awed Pheidippides promised that they would do so from then on. The god apparently felt that the promise would be kept, so he appeared in battle and at the crucial moment he instilled the Persians with his own brand of fear, the mindless, frenzied fear that bore his name: \"panic\". After the battle, a sacred precinct was established for Pan in a grotto on the north slope of the Acropolis, and a sacrifice was annually offered.\n\nSimilarly, after the victory the festival of the \"Agroteras Thysia\" (\"sacrifice to the Agrotéra\") was held at Agrae near Athens, in honor of Artemis Agrotera (\"Artemis the Huntress\"). This was in fulfillment of a vow made by the city before the battle, to offer in sacrifice a number of goats equal to that of the Persians slain in the conflict. The number was so great, it was decided to offer 500 goats yearly until the number was filled. Xenophon notes that at his time, 90 years after the battle, goats were still offered yearly.\n\nPlutarch mentions that the Athenians saw the phantom of King Theseus, the mythical hero of Athens, leading the army in full battle gear in the charge against the Persians, and indeed he was depicted in the mural of the Stoa Poikile fighting for the Athenians, along with the twelve Olympian gods and other heroes. Pausanias also tells us that: They say too that there chanced to be present in the battle a man of rustic appearance and dress. Having slaughtered many of the foreigners with a plough he was seen no more after the engagement. When the Athenians made enquiries at the oracle, the god merely ordered them to honor Echetlaeus (\"he of the Plough-tail\") as a hero.\n\nAnother tale from the conflict is of the dog of Marathon. Aelian relates that one hoplite brought his dog to the Athenian encampment. The dog followed his master to battle and attacked the Persians at his master's side. He also informs us that this dog is depicted in the mural of the Stoa Poikile.\n\nAccording to Herodotus, an Athenian runner named Pheidippides was sent to run from Athens to Sparta to ask for assistance before the battle. He ran a distance of over 225 kilometers (140 miles), arriving in Sparta the day after he left. Then, following the battle, the Athenian army marched the 40 kilometers (25 miles) or so back to Athens at a very high pace (considering the quantity of armour, and the fatigue after the battle), in order to head off the Persian force sailing around Cape Sounion. They arrived back in the late afternoon, in time to see the Persian ships turn away from Athens, thus completing the Athenian victory.\nLater, in popular imagination, these two events became confused with each other, leading to a legendary but inaccurate version of events. This myth has Pheidippides running from Marathon to Athens after the battle, to announce the Greek victory with the word \"nenikēkamen!\" (Attic: ; we've won!), whereupon he promptly died of exhaustion. Most accounts incorrectly attribute this story to Herodotus; actually, the story first appears in Plutarch's \"On the Glory of Athens\" in the 1st century AD, who quotes from Heracleides of Pontus's lost work, giving the runner's name as either Thersipus of Erchius or Eucles. Lucian of Samosata (2nd century AD) gives the same story but names the runner Philippides (not Pheidippides). It should be noted that in some medieval codices of Herodotus the name of the runner between Athens and Sparta before the battle is given as Philippides, and this name is also preferred in a few modern editions.\n\nWhen the idea of a modern Olympics became a reality at the end of the 19th century, the initiators and organizers were looking for a great popularizing event, recalling the ancient glory of Greece. The idea of organizing a \"marathon race\" came from Michel Bréal, who wanted the event to feature in the first modern Olympic Games in 1896 in Athens. This idea was heavily supported by Pierre de Coubertin, the founder of the modern Olympics, as well as the Greeks. This would echo the legendary version of events, with the competitors running from Marathon to Athens. So popular was this event that it quickly caught on, becoming a fixture at the Olympic games, with major cities staging their own annual events. The distance eventually became fixed at 26 miles 385 yards, or 42.195 km, though for the first years it was variable, being around —the approximate distance from Marathon to Athens.\n\n\n\n"}
{"id": "4810", "url": "https://en.wikipedia.org/wiki?curid=4810", "title": "Balance of trade", "text": "Balance of trade\n\nThe balance of trade, commercial balance, or net exports (sometimes symbolized as NX), is the difference between the monetary value of a nation's exports and imports over a certain period. Sometimes a distinction is made between a balance of trade for goods versus one for services.\n\nIf a country exports a greater value than it imports, it is called a trade surplus, positive balance, or a \"favourable balance\", and conversely, if a country imports a greater value than it exports, it is called a trade deficit, negative balance, \"unfavorable balance\", or, informally, a \"trade gap\".\n\nThe balance of trade forms part of the current account, which includes other transactions such as income from the net international investment position as well as international aid. If the current account is in surplus, the country's net international asset position increases correspondingly. Equally, a deficit decreases the net international asset position.\n\nThe trade balance is identical to the difference between a country's output and its domestic demand (the difference between what goods a country produces and how many goods it buys from abroad; this does not include money re-spent on foreign stock, nor does it factor in the concept of importing goods to produce for the domestic market).\n\nMeasuring the balance of trade can be problematic because of problems with recording and collecting data. As an illustration of this problem, when official data for all the world's countries are added up, exports exceed imports by almost 1%; it appears the world is running a positive balance of trade with itself. This cannot be true, because all transactions involve an equal credit or debit in the account of each nation. The discrepancy is widely believed to be explained by transactions intended to launder money or evade taxes, smuggling and other visibility problems. Especially for developing countries, the transaction statistics are likely to be inaccurate.\n\nFactors that can affect the balance of trade include:\n\nIn addition, the trade balance is likely to differ across the business cycle. In export-led growth (such as oil and early industrial goods), the balance of trade will shift towards exports during an economic expansion. However, with domestic demand led growth (as in the United States and Australia) the trade balance will shift towards imports at the same stage in the business cycle.\n\nMonetary balance of trade is different from physical balance of trade (which is expressed in amount of raw materials, known also as Total Material Consumption). Developed countries usually import a lot of raw materials from developing countries. Typically, these imported materials are transformed into finished products, and might be exported after adding value. Financial trade balance statistics conceal material flow. Most developed countries have a large physical trade deficit, because they consume more raw materials than they produce. Many civil society organisations claim this imbalance is predatory and campaign for ecological debt repayment.\n\nMany countries in early modern Europe adopted a policy of mercantilism, which theorized that a trade surplus was beneficial to a country, among other elements such as colonialism and trade barriers with other countries and their colonies. (Bullionism was an early philosophy supporting mercantilism.)\n\nThe practices and abuses of mercantilism led the natural resources and cash crops of British North America to be exported in exchange for finished goods from Great Britain, a factor leading to the American Revolution. An early statement appeared in \"Discourse of the Common Wealth of this Realm of England\", 1549: \"We must always take heed that we buy no more from strangers than we sell them, for so should we impoverish ourselves and enrich them.\" Similarly a systematic and coherent explanation of balance of trade was made public through Thomas Mun's 1630 \"England's treasure by foreign trade, or, The balance of our foreign trade is the rule of our treasure\"\n\nSince the mid-1980s, the United States has had a growing deficit in tradeable goods, especially with Asian nations (China and Japan) which now hold large sums of U.S debt that has in part funded the consumption. The U.S. has a trade surplus with nations such as Australia. The issue of trade deficits can be complex. Trade deficits generated in tradeable goods such as manufactured goods or software may impact domestic employment to different degrees than trade deficits in raw materials.\n\nEconomies such as Japan and Germany which have savings surpluses, typically run trade surpluses. China, a high-growth economy, has tended to run trade surpluses. A higher savings rate generally corresponds to a trade surplus. Correspondingly, the U.S. with its lower savings rate has tended to run high trade deficits, especially with Asian nations.\n\n\"In the foregoing part of this chapter I have endeavoured to show, even upon the principles of the commercial system, how unnecessary it is to lay extraordinary restraints upon the importation of goods from those countries with which the balance of trade is supposed to be disadvantageous.\nNothing, however, can be more absurd than this whole doctrine of the balance of trade, upon which, not only these restraints, but almost all the other regulations of commerce are founded. When two places trade with one another, this [absurd] doctrine supposes that, if the balance be even, neither of them either loses or gains; but if it leans in any degree to one side, that one of them loses and the other gains in proportion to its declension from the exact equilibrium.\" (Smith, 1776, book IV, ch. iii, part ii)\n\nIn the last few years of his life, John Maynard Keynes was much preoccupied with the question of balance in international trade. He was the leader of the British delegation to the United Nations Monetary and Financial Conference in 1944 that established the Bretton Woods system of international currency management.\nHe was the principal author of a proposal – the so-called Keynes Plan – for an International Clearing Union. The two governing principles of the plan were that the problem of settling outstanding balances should be solved by 'creating' additional 'international money', and that debtor and creditor should be treated almost alike as disturbers of equilibrium. In the event, though, the plans were rejected, in part because \"American opinion was naturally reluctant to accept the principle of equality of treatment so novel in debtor-creditor relationships\".\n\nThe new system is not founded on free-trade (liberalisation of foreign trade) but rather on the regulation of international trade, in order to eliminate trade imbalances: the nations with a surplus would have a powerful incentive to get rid of it, and in doing so they would automatically clear other nations deficits. He proposed a global bank that would issue its own currency - the bancor - which was exchangeable with national currencies at fixed rates of exchange and would become the unit of account between nations, which means it would be used to measure a country's trade deficit or trade surplus. Every country would have an overdraft facility in its bancor account at the International Clearing Union. He pointed out that surpluses lead to weak global aggregate demand – countries running surpluses exert a \"negative externality\" on trading partners, and posed far more than those in deficit, a threat to global prosperity.\nIn \"\"National Self-Sufficiency\" The Yale Review, Vol. 22, no. 4 (June 1933)\", he already highlighted the problems created by free trade .\n\nHis view, supported by many economists and commentators at the time, was that creditor nations may be just as responsible as debtor nations for disequilibrium in exchanges and that both should be under an obligation to bring trade back into a state of balance. Failure for them to do so could have serious consequences. In the words of Geoffrey Crowther, then editor of The Economist, \"If the economic relationships between nations are not, by one means or another, brought fairly close to balance, then there is no set of financial arrangements that can rescue the world from the impoverishing results of chaos.\"\n\nThese ideas were informed by events prior to the Great Depression when – in the opinion of Keynes and others – international lending, primarily by the U.S., exceeded the capacity of sound investment and so got diverted into non-productive and speculative uses, which in turn invited default and a sudden stop to the process of lending.\n\nInfluenced by Keynes, economics texts in the immediate post-war period put a significant emphasis on balance in trade. For example, the second edition of the popular introductory textbook, \"An Outline of Money\", devoted the last three of its ten chapters to questions of foreign exchange management and in particular the 'problem of balance'. However, in more recent years, since the end of the Bretton Woods system in 1971, with the increasing influence of Monetarist schools of thought in the 1980s, and particularly in the face of large sustained trade imbalances, these concerns – and particularly concerns about the destabilising effects of large trade surpluses – have largely disappeared from mainstream economics discourse and Keynes' insights have slipped from view. They are receiving some attention again in the wake of the financial crisis of 2007–08.\n\nPrior to 20th century Monetarist theory, the 19th century economist and philosopher Frédéric Bastiat expressed the idea that trade deficits actually were a manifestation of profit, rather than a loss. He proposed as an example to suppose that he, a Frenchman, exported French wine and imported British coal, turning a profit. He supposed he was in France, and sent a cask of wine which was worth 50 francs to England. The customhouse would record an export of 50 francs. If, in England, the wine sold for 70 francs (or the pound equivalent), which he then used to buy coal, which he imported into France, and was found to be worth 90 francs in France, he would have made a profit of 40 francs. But the customhouse would say that the value of imports exceeded that of exports and was trade deficit against the ledger of France.\n\nBy \"reductio ad absurdum\", Bastiat argued that the national trade deficit was an indicator of a successful economy, rather than a failing one. Bastiat predicted that a successful, growing economy would result in greater trade deficits, and an unsuccessful, shrinking economy would result in lower trade deficits. This was later, in the 20th century, echoed by economist Milton Friedman.\n\nIn the 1980s, Milton Friedman, a Nobel Prize-winning economist and a proponent of Monetarism, contended that some of the concerns of trade deficits are unfair criticisms in an attempt to push macroeconomic policies favorable to exporting industries.\n\nFriedman argued that trade deficits are not necessarily as important as high exports raise the value of the currency, reducing aforementioned exports, and vice versa for imports, thus naturally removing trade deficits not due to investment. Since 1971, when the Nixon administration decided to abolish fixed exchange rates, America's Current Account accumulated trade deficits have totaled $7.75 Trillion as of 2010. This deficit exists as it is matched by investment coming into the United States- purely by the definition of the balance of payments, any current account deficit that exists is matched by an inflow of foreign investment.\n\nIn the late 1970s and early 1980s, the U.S. had experienced high inflation and Friedman's policy positions tended to defend the stronger dollar at that time. He stated his belief that these trade deficits were not necessarily harmful to the economy at the time since the currency comes back to the country (country A sells to country B, country B sells to country C who buys from country A, but the trade deficit only includes A and B). However, it may be in one form or another including the possible tradeoff of foreign control of assets. In his view, the \"worst-case scenario\" of the currency never returning to the country of origin was actually the best possible outcome: the country actually purchased its goods by exchanging them for pieces of cheaply made paper. As Friedman put it, this would be the same result as if the exporting country burned the dollars it earned, never returning it to market circulation.\n\nThis position is a more refined version of the theorem first discovered by David Hume. Hume argued that England could not permanently gain from exports, because hoarding gold (i.e., currency) would make gold more plentiful in England; therefore, the prices of English goods would rise, making them less attractive exports and making foreign goods more attractive imports. In this way, countries' trade balances would balance out.\n\nFriedman presented his analysis of the balance of trade in \"Free to Choose\", widely considered his most significant popular work.\n\nExports directly contribute and imports directly reduce their nation's balance of trade (i.e. net exports). A trade surplus is positive net balance of trade, and a trade deficit is a negative net balance of trade. Due to balance of trade being explicitly added to the calculation of their nation's gross domestic product using the expenditure method of calculating gross domestic production (i.e. GDP), trade surpluses are contributions and trade deficits are \"drags\" upon their nation's GDP.\n\n\n"}
{"id": "4816", "url": "https://en.wikipedia.org/wiki?curid=4816", "title": "Biosphere", "text": "Biosphere\n\nThe biosphere (from Greek βίος \"bíos\" \"life\" and σφαῖρα \"sphaira\" \"sphere\") also known as the ecosphere (from Greek οἶκος \"oîkos\" \"environment\" and σφαῖρα), is the worldwide sum of all ecosystems. The two joined words are \"bio\" and \"sphere\". It can also be termed as the zone of life on Earth, a closed system (apart from solar and cosmic radiation and heat from the interior \nof the Earth), and largely self-regulating. By the most general biophysiological definition, the biosphere is the global ecological system integrating all living beings and their relationships, including their interaction with the elements of the lithosphere, geosphere, hydrosphere, and atmosphere. The biosphere is postulated to have evolved, beginning with a process of biopoiesis (life created naturally from non-living matter. Heyden | title = Biology: Exploring Life | publisher = Pearson Prentice Hall | year = 2006 | location = Boston, Massachusetts | pages = | url = http://www.phschool.com/el_marketing.html | isbn = 0-13-250882-6 }}</ref> The earliest evidence for life on Earth includes biogenic graphite found in 3.7 billion-year-old metasedimentary rocks from Western Greenland and microbial mat fossils found in 3.48 billion-year-old sandstone from Western Australia. More recently, in 2015, \"remains of biotic life\" were found in 4.1 billion-year-old rocks in Western Australia. In 2017, putative fossilized microorganisms (or microfossils) were announced to have been discovered in hydrothermal vent precipitates in the Nuvvuagittuq Belt of Quebec, Canada that were as old as 4.28 billion years, the oldest record of life on earth, suggesting \"an almost instantaneous emergence of life\" after ocean formation 4.4 billion years ago, and not long after the formation of the Earth 4.54 billion years ago. According to one of the researchers, \"If life arose relatively quickly on Earth ... then it could be common in the universe.\"\n\nIn a general sense, biospheres are any closed, self-regulating systems containing ecosystems. This includes artificial biospheres such as Biosphere 2 and BIOS-3, and potentially ones on other planets or moons.\n\nThe term \"biosphere\" was coined by geologist Eduard Suess in 1875, which he defined as the place on Earth's surface where life dwells.\n\nWhile the concept has a geological origin, it is an indication of the effect of both Charles Darwin and Matthew F. Maury on the Earth sciences. The biosphere's ecological context comes from the 1920s (see Vladimir I. Vernadsky), preceding the 1935 introduction of the term \"ecosystem\" by Sir Arthur Tansley (see ecology history). Vernadsky defined ecology as the science of the biosphere. It is an interdisciplinary concept for integrating astronomy, geophysics, meteorology, biogeography, evolution, geology, geochemistry, hydrology and, generally speaking, all life and Earth sciences.\n\nGeochemists define the biosphere as being the total sum of living organisms (the \"biomass\" or \"biota\" as referred to by biologists and ecologists). In this sense, the biosphere is but one of four separate components of the geochemical model, the other three being \"geosphere\", \"hydrosphere\", and \"atmosphere\". When these four component spheres are combined into one system, it is known as the Ecosphere. This term was coined during the 1960s and encompasses both biological and physical components of the planet.\n\nThe Second International Conference on Closed Life Systems defined \"biospherics\" as the science and technology of analogs and models of Earth's biosphere; i.e., artificial Earth-like biospheres. Others may include the creation of artificial non-Earth biospheres—for example, human-centered biospheres or a native Martian biosphere—as part of the topic of biospherics.\n\nEvery part of the planet, from the polar ice caps to the equator, features life of some kind. Recent advances in microbiology have demonstrated that microbes live deep beneath the Earth's terrestrial surface, and that the total mass of microbial life in so-called \"uninhabitable zones\" may, in biomass, exceed all animal and plant life on the surface. The actual thickness of the biosphere on earth is difficult to measure. Birds typically fly at altitudes as high as and fish live as much as underwater in the Puerto Rico Trench.\n\nThere are more extreme examples for life on the planet: Rüppell's vulture has been found at altitudes of ; bar-headed geese migrate at altitudes of at least ; yaks live at elevations as high as above sea level; mountain goats live up to . Herbivorous animals at these elevations depend on lichens, grasses, and herbs.\n\nLife forms live in every part of the Earth's biosphere, including soil, hot springs, inside rocks at least deep underground, the deepest parts of the ocean, and at least high in the atmosphere. Microorganisms, under certain test conditions, have been observed to thrive in the vacuum of outer space. The total amount of soil and subsurface bacterial carbon is estimated as 5 × 10 g, or the \"weight of the United Kingdom\". The mass of prokaryote microorganisms—which includes bacteria and archaea, but not the nucleated eukaryote microorganisms—may be as much as 0.8 trillion tons of carbon (of the total biosphere mass, estimated at between 1 and 4 trillion tons). Barophilic marine microbes have been found at more than a depth of in the Mariana Trench, the deepest spot in the Earth's oceans. In fact, single-celled life forms have been found in the deepest part of the Mariana Trench, by the Challenger Deep, at depths of . Other researchers reported related studies that microorganisms thrive inside rocks up to below the sea floor under of ocean off the coast of the northwestern United States, as well as beneath the seabed off Japan. Culturable thermophilic microbes have been extracted from cores drilled more than into the Earth's crust in Sweden, from rocks between . Temperature increases with increasing depth into the Earth's crust. The rate at which the temperature increases depends on many factors, including type of crust (continental vs. oceanic), rock type, geographic location, etc. The greatest known temperature at which microbial life can exist is (\"Methanopyrus kandleri\" Strain 116), and it is likely that the limit of life in the \"deep biosphere\" is defined by temperature rather than absolute depth. On 20 August 2014, scientists confirmed the existence of microorganisms living below the ice of Antarctica. According to one researcher, \"You can find microbes everywhere — they're extremely adaptable to conditions, and survive wherever they are.\"\n\nOur biosphere is divided into a number of biomes, inhabited by fairly similar flora and fauna. On land, biomes are separated primarily by latitude. Terrestrial biomes lying within the Arctic and Antarctic Circles are relatively barren of plant and animal life, while most of the more populous biomes lie near the equator. \n\nFor this list, if a word is followed by a number, it is usually referring to a specific system or number. Thus:\n\n\nNo biospheres have been detected beyond the Earth; therefore, the existence of extraterrestrial biospheres remains hypothetical. The rare Earth hypothesis suggests they should be very rare, save ones composed of microbial life only. On the other hand, Earth analogs may be quite numerous, at least in the Milky Way galaxy. Three of the planets discovered orbiting TRAPPIST-1 could possibly contain biospheres. Given limited understanding of abiogenesis, it is currently unknown what percentage of these planets actually develop biospheres.\n\nIt is also possible that artificial biospheres will be created during the future, for example on Mars. The process of creating an uncontained system that mimics the function of Earth's biosphere is called terraforming.\n\n\n"}
{"id": "4817", "url": "https://en.wikipedia.org/wiki?curid=4817", "title": "Biological membrane", "text": "Biological membrane\n\nA biological membrane or biomembrane is an enclosing or separating membrane that acts as a selectively permeable barrier within living things. Biological membranes, in the form of eukaryotic cell membranes, consist of a phospholipid bilayer with embedded, integral and peripheral proteins used in communication and transportation of chemicals and ions. The bulk of lipid in a cell membrane provides a fluid matrix for proteins to rotate and laterally diffuse for physiological functioning. Proteins are adapted to high membrane fluidity environment of lipid bilayer with the presence of an annular lipid shell, consisting of lipid molecules bound tightly to surface of integral membrane proteins. The cell membranes are different from the isolating tissues formed by layers of cells, such as mucous membranes, basement membranes, and serous membranes.\n\nThe lipid bilayer consists of two layers- an outer leaflet and an inner leaflet. The components of bilayers are distributed unequally between the two surfaces to create asymmetry between the outer and inner surfaces. This asymmetric organization is important for cell functions such as cell signaling. The asymmetry of the biological membrane reflects the different functions of the two leaflets of the membrane. As seen in the fluid membrane model of the phospholipid bilayer, the outer leaflet and inner leaflet of the membrane are asymmetrical in their composition. Certain proteins and lipids rest only on one surface of the membrane and not the other. \n\n• Both the plasma membrane and internal membranes have cytosolic and exoplasmic faces\n• This orientation is maintained during membrane trafficking – proteins, lipids, glycoconjugates facing the lumen of the ER and Golgi get expressed on the extracellular side of the plasma membrane. In eucaryotic cells, new phospholipids are manufactured by enzymes bound to the part of the endoplasmic reticulum membrane that faces the cytosol. These enzymes, which use free fatty acids as substrates, deposit all newly made phospholipids into the cytosolic half of the bilayer. To enable the membrane as a whole to grow evenly, half of the new phospholipid molecules then have to be transferred to the opposite monolayer. This transfer is catalyzed by enzymes called flippases. In the plasma membrane, flippases transfer specific phospholipids selectively, so that different types become concentrated in each monolayer.\n\nUsing selective flippases is not the only way to produce asymmetry in lipid bilayers, however. In particular, a different mechanism operates for glycolipids—the lipids that show the most striking and consistent asymmetric distribution in animal cells.\n\nThe biological membrane is made up of lipids with hydrophobic tails and hydrophilic heads. The hydrophobic tails are hydrocarbon tails whose length and saturation is important in characterizing the cell. Lipid rafts occur when lipid species and proteins aggregate in domains in the membrane. These help organize membrane components into localized areas that are involved in specific processes, such as signal transduction.\n\nRed blood cells, or erythrocytes, have a unique lipid composition. The bilayer of red blood cells is composed of cholesterol and phospholipids in equal proportions by weight. Erythrocyte membrane plays a crucial role in blood clotting. In the bilayer of red blood cells is phosphatidylserine. This is usually in the cytoplasmic side of the membrane. However, it is flipped to the outer membrane to be used during blood clotting.\n\nPhospholipid bilayers contain different proteins. These membrane proteins have various functions and characteristics and catalyze different chemical reactions. Integral proteins span the membranes with different domains on either side. Integral proteins hold strong association with the lipid bilayer and cannot easily become detached. They will dissociate only with chemical treatment that breaks the membrane. Peripheral proteins are unlike integral proteins in that they hold weak interactions with the surface of the bilayer and can easily become dissociated from the membrane. Peripheral proteins are located on only one face of a membrane and create membrane asymmetry.\nOligosaccharides are sugar containing polymers. In the membrane, they can be covalently bound to lipids to form glycolipids or covalently bound to proteins to form glycoproteins. Membranes contain sugar-containing lipid molecules known as glycolipids. In the bilayer, the sugar groups of glycolipids are exposed at the cell surface, where they can form hydrogen bonds. Glycolipids provide the most extreme example of asymmetry in the lipid bilayer. Glycolipids perform a vast number of functions in the biological membrane that are mainly communicative, including cell recognition and cell-cell adhesion. Glycoproteins are integral proteins. They play an important role in the immune response and protection.\n\nThe phospholipid bilayer is formed due to the aggregation of membrane lipids in aqueous solutions. Aggregation is caused by the hydrophobic effect, where hydrophobic ends come into contact with each other and are sequestered away from water. This arrangement maximises hydrogen bonding between hydrophilic heads and water while minimising unfavorable contact between hydrophobic tails and water. The increase in available hydrogen bonding increases the entropy of the system, creating a spontaneous process.\n\nBiological molecules are amphiphilic or amphipathic, i.e. are simultaneously hydrophobic and hydrophilic. The phospholipid bilayer contains charged hydrophilic headgroups, which interact with polar water. The lipids also contain hydrophobic tails, which meet with the hydrophobic tails of the complementary layer. The hydrophobic tails are usually fatty acids that differ in lengths. The interactions of lipids, especially the hydrophobic tails, determine the lipid bilayer physical properties such as fluidity.\n\nMembranes in cells typically define enclosed spaces or compartments in which cells may maintain a chemical or biochemical environment that differs from the outside. For example, the membrane around peroxisomes shields the rest of the cell from peroxides, chemicals that can be toxic to the cell, and the cell membrane separates a cell from its surrounding medium. Peroxisomes are one form of vacuole found in the cell that contain by-products of chemical reactions within the cell. Most organelles are defined by such membranes, and are called \"membrane-bound\" organelles.\n\nProbably the most important feature of a biomembrane is that it is a selectively permeable structure. This means that the size, charge, and other chemical properties of the atoms and molecules attempting to cross it will determine whether they succeed in doing so. Selective permeability is essential for effective separation of a cell or organelle from its surroundings. Biological membranes also have certain mechanical or elastic properties that allow them to change shape and move as required.\n\nGenerally, small hydrophobic molecules can readily cross phospholipid bilayers by simple diffusion.\n\nParticles that are required for cellular function but are unable to diffuse freely across a membrane enter through a membrane transport protein or are taken in by means of endocytosis, where the membrane allows for a vacuole to join onto it and push its contents into the cell. Many types of specialized plasma membranes can separate cell from external environment: apical, basolateral, presynaptic and postsynaptic ones, membranes of flagella, cilia, microvillus, filopodia and lamellipodia, the sarcolemma of muscle cells, as well as specialized myelin and dendritic spine membranes of neurons. Plasma membranes can also form different types of \"supramembrane\" structures such as caveola, postsynaptic density, podosome, invadopodium, desmosome, hemidesmosome, focal adhesion, and cell junctions. These types of membranes differ in lipid and protein composition.\n\nDistinct types of membranes also create intracellular organelles: endosome; smooth and rough endoplasmic reticulum; sarcoplasmic reticulum; Golgi apparatus; lysosome; mitochondrion (inner and outer membranes); nucleus (inner and outer membranes); peroxisome; vacuole; cytoplasmic granules; cell vesicles (phagosome, autophagosome, clathrin-coated vesicles, COPI-coated and COPII-coated vesicles) and secretory vesicles (including synaptosome, acrosomes, melanosomes, and chromaffin granules).\nDifferent types of biological membranes have diverse lipid and protein compositions. The content of membranes defines their physical and biological properties. Some components of membranes play a key role in medicine, such as the efflux pumps that pump drugs out of a cell.\n\nThe hydrophobic core of the phospholipid bilayer is constantly in motion because of rotations around the bonds of lipid tails. Hydrophobic tails of a bilayer bend and lock together. However, because of hydrogen bonding with water, the hydrophilic head groups exhibit less movement as their rotation and mobility are constrained. This results in increasing viscosity of the lipid bilayer closer to the hydrophilic heads.\n\nBelow a transition temperature, a lipid bilayer loses fluidity when the highly mobile lipids exhibits less movement becoming a gel-like solid. The transition temperature depends on such components of the lipid bilayer as the hydrocarbon chain length and the saturation of its fatty acids. Temperature-dependence fluidity constitutes an important physiological attribute for bacteria and cold-blooded organisms. These organisms maintain a constant fluidity by modifying membrane lipid fatty acid composition in accordance with differing temperatures.\n\nIn animal cells, membrane fluidity is modulated by the inclusion of the sterol cholesterol. This molecule is present in especially large amounts in the plasma membrane, where it constitutes approximately 20% of the lipids in the membrane by weight. Because cholesterol molecules are short and rigid, they fill the spaces between neighboring phospholipid molecules left by the kinks in their unsaturated hydrocarbon tails. In this way, cholesterol tends to stiffen the bilayer, making it more rigid and less permeable.\n\nFor all cells, membrane fluidity is important for many reasons. It enables membrane proteins to diffuse rapidly in the plane of the bilayer and to interact with one another, as is crucial, for example, in cell signaling. It permits membrane lipids and proteins to diffuse from sites where they are inserted into the bilayer after their synthesis to other regions of the cell. It allows membranes to fuse with one another and mix their molecules, and it ensures that membrane molecules are distributed evenly between daughter cells when a cell divides. If biological membranes were not fluid, it is hard to imagine how cells could live, grow, and reproduce.\n\n\n"}
{"id": "4819", "url": "https://en.wikipedia.org/wiki?curid=4819", "title": "Balfour Declaration of 1926", "text": "Balfour Declaration of 1926\n\nThe Balfour Declaration of 1926, issued by the 1926 Imperial Conference of British Empire leaders in London, was named for Lord President of the Council (and former Prime Minister of the United Kingdom) Arthur Balfour. It declared the United Kingdom and the Dominions to be\nThe Inter-Imperial Relations Committee, chaired by Balfour, drew up the document preparatory to its unanimous approval by the imperial premiers on 15 November 1926. It was first proposed by South African Prime Minister J. B. M. Hertzog and Canada's Prime Minister at that time, William Lyon Mackenzie King.\n\nThe Declaration accepted the growing political and diplomatic independence of the Dominions, in the years after World War I. It also recommended that the governors-general, the representatives of the King who acted for the Crown as \"de facto\" head of state in each dominion, should no longer also serve automatically as the representative of the British government in diplomatic relations between the countries. In following years, High Commissioners were gradually appointed, whose duties were soon recognised to be virtually identical to those of an ambassador. The first such British High Commissioner was appointed to Ottawa in 1928.\n\nThe conclusions of the imperial premiers conference of 1926 were restated by the 1930 conference and incorporated in the Statute of Westminster of December 1931, by which the British parliament renounced any legislative authority over dominion affairs, except as specifically provided in law.\n\n"}
{"id": "4820", "url": "https://en.wikipedia.org/wiki?curid=4820", "title": "Balfour Declaration", "text": "Balfour Declaration\n\nThe Balfour Declaration was a British government public statement made during World War I, to announce their support for the establishment of a \"national home\" for the Jewish people in Palestine, then part of the Ottoman Empire. The declaration was contained in a letter dated 2November 1917 from the United Kingdom's Foreign Secretary Arthur Balfour to Lord Walter Rothschild, a leader of the British Jewish community, for transmission to the Zionist Federation of Great Britain and Ireland. The text of the declaration was published in the press on 9November 1917.\n\nDuring the period of the British War Cabinet discussions leading up to the declaration, the wider war had reached a period of stalemate; the US was yet to fully deploy, and the Russians were distracted by internal upheaval. In accordance with the pro-Zionist policy of the newly installed Lloyd George ministry, a senior member of the British War Cabinet secretariat, Sir Mark Sykes, initiated formal discussions with the Zionist leadership on 7 February 1917, and Balfour requested Rothschild and Chaim Weizmann to submit a draft of a public declaration on 19 June. Further drafts were discussed by the British Cabinet during September and October, with input from Zionist and anti-Zionist Jews but with no representation from the local population in Palestine, and the release of the final declaration was authorised by 31 October. The Cabinet discussion on approval described perceived propaganda benefits amongst the worldwide Jewish community for the Allied war effort. It read:\nThe first part of the declaration was the first public support for Zionism by a major political power. The term \"national home\" had no precedent in international law, and was intentionally unclear as to whether a Jewish state was contemplated. The intended boundaries of Palestine were not specified, and the British Government later confirmed that the words \"in Palestine\" meant that the whole of Palestine was not intended as the Jewish national home.\n\nThe second part of the declaration was added to satisfy opponents of the policy, who had claimed that it would otherwise prejudice the position of the local population of Palestine and encourage antisemitism against Jews worldwide. Whilst the declaration provided political rights in Palestine for Jews, rights for the Palestinian Arabs who comprised the vast majority of the local population were limited to civil and religious. In 2017, the British Government acknowledged that the Declaration should have called for the protection of political rights.\n\nThe issue of the declaration had many long-lasting consequences. It galvanized popular support for Zionism, led to the creation of Mandatory Palestine, which later became Israel and the Palestinian territories, and was the origin of the ongoing Israeli Palestinian conflict, considered the world's most intractable conflict. There remains ongoing scholarly controversy over a number of areas, including whether the declaration contradicts earlier promises the British may have made to Hussein ibn Ali al-Hashimi, the Sharif of Mecca, in the McMahon–Hussein correspondence.\n\nThe basis for British support for an increased Jewish presence in the region of Palestine was linked to geopolitical calculations, though 19th-century dispensationalist evangelical Christian beliefs had motivated Lord Shaftesbury and other lobbyists initially in the mid-19th century and created a supportive sentiment among the British political elite towards the \"restoration of the Jews\" to Palestine.\n\nEarly British political support was precipitated in the late 1830s and led by Lord Palmerston, following the Eastern Crisis after Muhammad Ali occupied Syria and Palestine. French influence as protector of the Catholic communities began to grow in the wider region, as Russian influence began to grow as protector of the Eastern Orthodox, leaving Britain without a sphere of influence. The British Foreign Office worked to encourage Jewish emigration to Palestine, exemplified by Charles Henry Churchill's 1841–42 exhortations to Moses Montefiore, the leader of the British Jewish community. Such efforts were premature, as Zionism was not to emerge within the world's Jewish communities until the last decades of the century, spearheaded by the efforts of Theodor Herzl, a Jewish journalist living in Austria-Hungary, whose efforts to gain international support for his ideas were not to succeed in his lifetime.\n\nWith the geopolitical shakeup occasioned by the outbreak of World War I, the earlier calculations, which had lapsed for some time, led to a renewal of strategic assessments and political bargaining over the Middle and Far East.\n\nZionism arose in the late 19th century in reaction to anti-Semitic and exclusionary nationalist movements in Europe. Romantic nationalism in 19th-century Central and Eastern Europe had helped to set off the Haskalah, or \"Jewish Enlightenment\", creating a split in the Jewish community between those who saw Judaism as their religion, and those who saw it as their ethnicity or nation. The 1881–84 Anti-Jewish pogroms in the Russian Empire encouraged the growth of the latter identity, resulting in the formation of the Hovevei Zion pioneer organizations and the publication of Leon Pinsker's \"Autoemancipation\".\n\nIn 1896 Herzl published the foundational text of political Zionism, \"Der Judenstaat\" (\"The Jews' State\" or \"The State of the Jews\"), in which he asserted that the only solution to the \"Jewish Question\" in Europe, including growing anti-Semitism, was the establishment of a state for the Jews. A year later, Herzl founded the Zionist Organization, which at its first congress called for \"the establishment of a home for the Jewish people in Palestine secured under public law\". Proposed measures to attain that goal included the promotion of Jewish settlement there, the organisation of Jews in the diaspora, the strengthening of Jewish feeling and consciousness, and preparatory steps to attain those necessary governmental grants. Herzl died in 1904 without the political standing that was required to carry out his agenda of a Jewish home in Palestine.\n\nZionist leader Chaim Weizmann, later President of the World Zionist Organisation, moved from Switzerland to the UK in 1904 and met Arthur Balfour, then Prime Minister, during his 1905–06 election campaign in a session arranged by Charles Dreyfus, his Jewish constituency representative. During this meeting, Balfour asked what Weizmann's objections had been to the 1903 Uganda Scheme to give a portion of British East Africa to the Jewish people as a homeland. The scheme, which had been proposed to Herzl by Colonial Secretary Joseph Chamberlain following his trip to East Africa earlier in the year, had been subsequently voted down following Herzl's death by the Seventh Zionist Congress in 1905, after two years of heated debate in the Zionist Organization.\n\nIn January 1914 Weizmann first met Baron Edmond de Rothschild, a member of the French branch of the Rothschild family and a leading proponent of the Zionist movement, in relation to a project to build a Hebrew university in Jerusalem. The Baron was not part of the World Zionist Organization, but had funded the first Jewish agricultural colonies of the first major wave of Jewish immigration to Palestine in the 1880s, and transferred them to the Jewish Colonization Association in 1899. This connection was to bear fruit later that year when the Baron's son, James deRothschild, requested a meeting with Weizmann on 25November 1914, in order to enlist him and the Zionists in influencing those deemed to be receptive within the British Government to their agenda of a \"Jewish State\" in Palestine. Through James's wife Dorothy, Weizmann was to meet Rózsika Rothschild, who introduced him to the English branch of the familyin particular her husband Charles and his older brother Walter, a zoologist and former MP. Their father, Lord Nathan Rothschild, head of the English branch of the family, had a guarded attitude towards Zionism, but he died in March 1915 and his title was inherited by Walter.\n\nMany British Jews at this time were not Zionists; prior to the declaration only 8,000 out of Britain's 300,000 were considered Zionists.\n\nThe Turks had applied a restrictive policy to Jewish immigration to Palestine as early as 1882, the time of the retroactively named First Aliyah that can be considered as the first Zionist arrivals. Although there was a certain amount of tension with the local population (mainly among the merchant and notable classes), Constantinople in 1901 gave Jews the same rights as Arabs to buy land and the percentage of Jews in the population rose to 7% by 1914. Also by 1914, with growing distrust of the Young Turks and the Second Aliyah, Arab nationalism in general was on the rise and in Palestine anti-Zionism was a unifying characteristic. \"The Balfour Declaration was not, in and of itself, the source of trouble in a land that previously had been more or less at peace, but nor was it a mere signpost on a road heading undivertibly toward a cliff. No one can say what the course of events in Palestine might have been without it. What did come was the product of forces and factors entirely unforeseen.\"\n\nIn July 1914 war broke out in Europe between the Triple Entente (Britain, France, and the Russian Empire) and the Central Powers (Germany, Austria-Hungary, and, later that year, the Ottoman Empire). On 9November 1914, four days after Britain's declaration of war on the Ottoman Empire, of which the Mutasarrifate of Jerusalemoften referred to as Palestinewas a component, Zionism was first discussed at a meeting of the British Cabinet. At the meeting David Lloyd George, then Chancellor of the Exchequer, and whose law firm \"Lloyd George, Roberts and Co\" had been engaged a decade before by the Zionist Federation of Great Britain and Ireland to work on the Uganda Scheme, \"referred to the ultimate destiny of Palestine\".\n\nWeizmann's political efforts picked up speed, and on 10December 1914 he met with the British cabinet member Herbert Samuel, a Zionist, who believed Weizmann's demands were too modest. Two days later, Weizmann met Balfour again, for the first time since 1906.\n\nA month later, Samuel circulated a memorandum entitled \"The Future of Palestine\" to his cabinet colleagues. The memorandum stated: \"I am assured that the solution of the problem of Palestine which would be much the most welcome to the leaders and supporters of the Zionist movement throughout the world would be the annexation of the country to the British Empire\". Samuel discussed a copy of his memorandum with Lord Nathan Rothschild in February 1915, a month before the latter's death. It was the first time in an official record that enlisting the support of Jews as a war measure was proposed.\n\nMany further discussions followed, including the initial meetings in 1915–16 between Lloyd George, who had been appointed Minister of Munitions in May 1915, and Weizmann, a leading Zionist who was also a scientific advisor to Lloyd George's Ministry of Munitions. Seventeen years later in his \"War Memoirs\" Lloyd George described these meetings as being the \"fount and origin\" of the declaration although this claim has been rejected by historians. Lloyd George was however, the Prime Minister at the time of the Balfour Declaration, and ultimately responsible for it.\n\nIn late 1915 the British High Commissioner to Egypt, Henry McMahon, had exchanged ten letters with Hussein bin Ali, Sharif of Mecca, in which he had promised Hussein to recognize Arab independence \"in the limits and boundaries proposed by the Sherif of Mecca\" with the exception of \"portions of Syria\" lying to the west of \"the districts of Damascus, Homs, Hama and Aleppo\", in exchange for Hussein launching a revolt against the Ottoman Empire. In the decades after the war, the extent of this coastal exclusion was hotly disputed since Palestine lay to the southwest of Damascus and was not explicitly mentioned.\n\nOn the basis of the correspondence, the Arab Revolt began on 5June 1916. However, in May 1916 the governments of the United Kingdom, France, and Russia had also secretly concluded the Sykes–Picot Agreement, which Balfour described later as a \"wholly new method\" for carving up the area, after the 1915 agreement \"seems to have been forgotten\". This secret agreement was negotiated in early 1916 between Sir Mark Sykes and François Georges-Picot. Sykes was a British MP whose role had developed from his seat on the 1915 De Bunsen Committee to have a significant influence on British policy in the region, including initiating the creation of the Arab Bureau, whilst Picot was a French diplomat and former consul-general in Beirut. The agreement defined their proposed spheres of influence and control in Western Asia should the Triple Entente succeed in defeating the Ottoman Empire during World WarI. It divided many Arab territories into British- and French-administered areas and allowed for the internationalisation of Palestine, proposing that the form of the Palestine administration would be confirmed after consultation with both Russia and Hussein.\n\nThese wartime initiatives, inclusive of the Declaration, are frequently considered together by historians because of the potential, real or imagined, for incompatibility between them, particularly in regard to the disposition of Palestine. For a fuller discussion of these and other issues, the reader is referred to the relevant article. Suffice it to say, in the words of Albert Hourani, “The argument about the interpretation of these agreements is one which is impossible to end, because they were intended to bear more than one interpretation.”\n\nIn terms of British politics, the declaration resulted from the coming into power of the Lloyd George and his cabinet, which had replaced the Asquith led-cabinet in December 1916, since he and Balfour had favoured a post-war partition of the Ottoman Empire in contrast to Asquith and Grey who favoured reform.\n\nLloyd George had wanted to make the destruction of the Ottoman Empire a major British war aim, and two days after taking office told General Robertson, the Chief of the Imperial General Staff, that he wanted a major victory, preferably the capture of Jerusalem, to impress British public opinion. Lloyd George immediately consulted his War cabinet about a “further campaign into Palestine when El Arish had been secured.” Subsequent pressure from Lloyd George, over the reservations of Robertson, resulted in the recapture of the Sinai for British-controlled Egypt with the capture of El Arish in December 1916 and Rafah in January 1917, and the arrival of British forces at the southern borders of the Ottoman empire. Following two unsuccessful attempts to capture Gaza, a stalemate in Southern Palestine began in April 1917, and the Sinai and Palestine Campaign would not make any substantial progress until 31October 1917.\n\nFollowing the change in government, Sykes was transferred to the War Office Secretariat as political secretary for Near Eastern Affairs, and charged with reopening discussions with the Zionists. In early 1917, despite having previously built a relationship with leading British Zionist Moses Gaster, he began looking to meet other Zionist leaders and was introduced to Weizmann and Nahum Sokolow at the end of January 1917. On 7February 1917, official negotiations began between Sykes and the Zionist leaders. According to Schneer, Sykes had as objective the mobilizing of Zionism to the cause of British suzerainty in Palestine so as to have arguments to put to France in support of that objective. At this point the Zionists were still unaware of the Sykes-Picot Agreement although they had their suspicions. In regard to the Arabs, citing Stein (from Sokolow’s notes of the meeting), Schneer writes that Sykes said “The Arabs professed that language must be the measure [by which control of Palestine should be determined] and [by that measure] could claim all Syria and Palestine. Still the Arabs could be managed, particularly if they received Jewish support in other matters.\"\n\nDuring the period of the British War Cabinet discussions leading up to the declaration, the wider war had reached a period of stalemate. On the Western Front the tide would first turn in favour of the Central Powers in spring 1918, before decisively turning in favour of the Allies from July 1918 onwards. Although the US had declared war on Germany in the spring of 1917, they would not suffer their first casualties until 2 November 1917, by which point President Wilson would still be hoping to avoid the dispatch of large contingents of troops into the war. The Russian forces were known to be distracted by the ongoing Russian Revolution and the growing support for the Bolshevik faction, but Alexander Kerensky's Russian Republic had remained in the war, and would only withdraw after the final stage in the revolution on 7November 1917.\n\nAvi Shlaim says there were two main schools of thought on the origins of the Balfour Declaration, one represented by Leonard Stein, the other by Mayir Vereté. He says that Stein does not reach any clear cut conclusions, that implicit in his narrative is that it was the activity and skill of the Zionists whereas according to Vereté, it was the work of hard-headed pragmatists motivated by British imperial interests in the Middle East. Much of modern scholarship on the decision to issue the declaration focuses on the Zionist movement and rivalries within it, with a key debate being whether the role of Weizmann was decisive or whether the British were likely to have issued a similar declaration in any event.More recently, Historian Martin Kramer has argued that securing the assent of Britain's French and American Allies, and of the Vatican, which controlled many Christian Holy Sites in Palestine, was a necessary precondition of the Balfour Declaration and Gutwein assays a twist on an old idea, asserting that Sykes approach to the Zionists was so as to pursue a radical political agenda on behalf of the British government.\n\nThe geopolitical calculations behind the decision to release the declaration were debated and discussed in the following years. Some historians argue that British government's decision reflected what James Gelvin calls 'patrician anti-Semitism' in the overestimation of Jewish power in both the United States and Russia. In addition, the British intended to preempt the expected French pressure for an international administration.\n\nThe British believed that expressing support would appeal to Jews in Germany and particularly America, given two of Woodrow Wilson's closest advisors were known to be avid Zionists; they also hoped to encourage support from the large Jewish population in Russia.\n\nIn his \"Memoirs\", published in 1939, Lloyd George listed nine factors motivating his decision as Prime Minister to release the declaration, including the view that a Jewish presence in Palestine would strengthen Britain's position on the Suez Canal and reinforce the route to Great Britain's imperial dominion in India. Lloyd George told the Palestine Royal Commission in 1937 that the declaration was made \"due to propagandist reasons... In particular Jewish sympathy would confirm the support of American Jewry, and would make it more difficult for Germany to reduce her military commitments and improve her economic position on the eastern front\".\n\nThe War cabinet had previously agreed to allow a detachment of French Muslim troops to accompany British forces when they finally entered Palestine. The French chose Picot as French High Commissioner for the soon to be occupied territory of Syria and Palestine. The British appointed Sykes as Chief Political Officer to the Egyptian Expeditionary Force. On 3 April 1917, Sykes met with Lloyd George, Curzon and Hankey to receive his instructions in this regard, namely to keep the French onside while pressing for a British Palestine and “the Prime Minister suggested that Sir Mark Sykes ought not enter into any political pledges to the Arabs, and particularly none in regard to Palestine”. En route to the East, Sykes first went to France, arriving a few days after Sokolow who in the meantime had met Picot and other French officials (According to Schneer, each of Sykes and Picot, representing his respective government, was trying to undercut the Sykes-Picot Agreement at the other’s expense. “The French are determined to take the whole of Palestine,” Sokolow reported to Weizmann) and then convinced the French Foreign Office to accept for study a statement of Zionist aims, their “desiderata in regard to facilities of colonization, communal autonomy, rights of language and establishment of a Jewish chartered company.”\n\nThe French position in regard to Palestine (and the Levant) during the lead up to the Balfour Declaration were largely dictated by the terms of the Sykes-Picot Agreement and were complicated from 23 November 1915 by increasing French awareness of the British discussions with the Sherif of Mecca.\nItaly's participation in the war, governed by the Treaty of London (1915), eventually led to the Agreement of Saint-Jean-de-Maurienne in April 1917; at this conference, Lloyd George had raised the question of a British protectorate of Palestine and the idea \"had been very coldly received\" by the French and the Italians. The War cabinet, reviewing this conference on 25 April, \"inclined to the view that sooner or later the Sykes-Picot Agreement might have to be reconsidered...No action should be taken at present in this matter\". \n\nBy 13 June 1917, it was acknowledged by Ronald Graham, head of the Foreign Office’s Middle Eastern affairs department, that the three most relevant politiciansthe Prime Minister, the Foreign Secretary, and the Parliamentary Under-Secretary of State for Foreign Affairs, Lord Robert Cecilwere all in favour of supporting the Zionist movement; on the same day Weizmann had written to Graham to advocate for a public declaration.\n\nOn 19June, Balfour met with Lord Rothschild and Weizmann, and asked them to submit a formula for a declaration.\n\nFollowing receipt of Lord Rothschild's 18 July draft declaration by the Foreign Office, the matter was brought to the Cabinet for formal consideration.\n\nThe decision to release the declaration was taken by the British War Cabinet on 31 October 1917. This followed discussion at four War Cabinet meetings (including the 31 October meeting) over the space of the previous two months. Consent from the U.S. President was sought over the same time period.\n\nBritish officials asked President Wilson for his views on the matter on two occasions – first on September 3, when he replied the time was not ripe, and later on October 6, when he agreed with the release of the Declaration. Following the US entry into the war in early April, for a month during April and May 1917, Balfour had been in the United States on the Balfour Mission, and spent significant time discussing Zionism with Wilson's advisor and leading Zionist Louis Brandeis.\n\nWith respect to the War Cabinet, in order to aid the discussions, the Cabinet Secretariat solicited interministerial clarification as well as the views of President Woodrow Wilson, and in October, formal submissions from six Zionist leaders and four non-Zionist Jews.\n\nExcerpts from the minutes of these four War Cabinet meetings provide a description of the primary factors that the ministers considered:\n\n\nLloyd George and Balfour remained in government until the collapse of the coalition in October 1922. Under the new Conservative government, attempts were made to identify the background to the drafting. A Cabinet memorandum was produced in January 1923 asserting that the primary authors were Balfour, Sykes, Weizmann, and Sokolow, with \"perhaps Lord Rothschild as a figure in the background\", and that \"negotiations seem to have been mainly oral and by means of private notes and memoranda of which only the scantiest records seem to be available.\"\n\nIn subsequent decades, declassification of Government archives allowed scholars to piece together the choreography of the drafting of the declaration; in his widely cited 1961 book, Leonard Stein published four previous drafts of the declaration. Stein illustrated the evolution of the drafting from the original proposal by the Zionist Organization, followed by various iterations. The drafting began with Weizmann's guidance to the Zionist drafting team on its objectives in a letter dated 20 June 1917, one day following his meeting with Rothschild and Balfour, that the declaration from the British government should state: \"its conviction, its desire or its intention to support Zionist aims for the creation of a Jewish national home in Palestine; no reference must be made I think to the question of the Suzerain Power because that would land the British into difficulties with the French; it must be a Zionist declaration.\"\n\nSubsequent authors have debated as to who the \"primary author\" really was. In his posthumously published 1981 book \"The Anglo-American Establishment\", Georgetown University history professor Carroll Quigley explained his view that the primary author of the declaration was Alfred, Lord Milner, and more recently, William D. Rubinstein, Professor of Modern History at Aberystwyth University, Wales, wrote that Conservative politician and pro-Zionist Leo Amery, as Assistant Secretary to the British war cabinet in 1917, should be considered the main author of the declaration.\n\nThe agreed version of the declaration, a single sentence of just 67 words, was sent in a short letter from Balfour to Walter Rothschild, for transmission to the Zionist Federation of Great Britain and Ireland, on 2November 1917. The declaration contained four clauses, of which the first two promised to support \"the establishment in Palestine of a national home for the Jewish people\", followed by two \"safeguard clauses\" with respect to \"the civil and religious rights of existing non-Jewish communities in Palestine\", and \"the rights and political status enjoyed by Jews in any other country\".\n\nThe phrase \"national home\" was intentionally used instead of \"state\" because of opposition to the Zionist program within the British Cabinet, although the chief architects of the declaration considered that a Jewish State would emerge in time. The term \"national home\" was intentionally ambiguous. For example, the phrase 'national homeland' had no legal value or precedent in international law, so its meaning was thus unclear when compared to other terms such as 'state'.\n\nExplication of the wording has been sought in the correspondence leading to the final version of the declaration. Following discussion of the initial draft, Sykes met with the Zionist negotiators to clarify their aims. His official report back to the Cabinet categorically stated that the Zionists did not want \"to set up a Jewish Republic or any other form of state in Palestine or in any part of Palestine.\" but rather preferred some form of protectorate as provided in the Palestine Mandate. In approving the Balfour Declaration, Leopold Amery, one of the Secretaries to the British War Cabinet of 1917–18, testified under oath to the Anglo-American Committee of Inquiry in January 1946 from his personal knowledge that:\nCurzon produced a memorandum circulated on 26 October, 1917 where he addressed two questions, the first being “What is the meaning of the phrase \"a National Home for the Jewish race in Palestine\" and noted that there were different opinions ranging from a fully fledged state to a merely spiritual centre for the Jews.\n\nDavid Lloyd George, who was Prime Minister at the time of the declaration, told the Palestine Royal Commission in 1937 that it was intended that Palestine may become a Jewish Commonwealth if and when Jews \"had become a definite majority of the inhabitants\":\nBoth the Zionist Organization and the British government devoted efforts to denying that a state was the intention over the following decades, including in Winston Churchill's 1922 White Paper. However, in private, many British officials agreed with the interpretation of the Zionists that a state would be established when a Jewish majority was achieved; in particular, at a private meeting on 22July 1922 at Balfour's home, Richard Meinertzhagen claims both Balfour and Lloyd George admitted that an eventual Jewish state had always been their intention. Note however that Meinertzhagen has been subject of criticism, notably by Brian Garfield, \"he pretended his vast ”diaries“ were records of events as they were occurring. but in fact they are memoirs, created and re-created long after the events, with the author’s retrospective (and often fictional spin”)\"\n\nThe choice of stating such a homeland would be found 'in Palestine' rather than 'of Palestine' was also no accident. With respect to the scope of the Jewish National Home, the initial draft of the declaration, contained in a letter sent by Rothschild to Balfour, referred to the principle \"\"that Palestine should be reconstituted as the National Home of the Jewish people.\"\" In the final text, following Lord Milner's amendment, the word \"reconstituted\" was removed and the word \"that\" was replaced with \"in\".\n\nThis text thereby avoided committing the entirety of Palestine to the Jewish National Home, resulting in controversy in future years over the intended scope. This was subsequently clarified by the 1922 Churchill White Paper, which wrote that \"the terms of the declaration referred to do not contemplate that Palestine as a whole should be converted into a Jewish National Home, but that such a Home should be founded 'in Palestine.'\"\n\nThe declaration did not include any geographical boundaries for Palestine. Following the end of the war, three documents – the declaration, the Hussein-McMahon Correspondence and the Sykes-Picot Agreement – became the basis for the negotiations to set the boundaries of Palestine.\n\nThe declaration's first safeguard clause referred to protecting the civil and religious rights of non-Jews in Palestine. The clause had been drafted together with the second safeguard by Leo Amery in discussion with Lord Milner, with the intention to \"go a reasonable distance to meeting the objectors, both Jewish and pro-Arab, without impairing the substance of the proposed declaration\".\n\nThe \"non-Jews\" constituted 90% of the population of Palestine; Ronald Storrs, Britain's Military Governor of Jerusalem between 1917 and 1920, described that this community had observed that they had been \"not so much as named, either as Arabs, Moslems or Christians, but were lumped together under the negative and humiliating definition of 'Non-Jewish Communities' and relegated to subordinate provisos\". The community also noted that there was no reference to protecting their \"political status\" or political rights, as there was in the subsequent safeguard relating to Jews in other countries. This protection was frequently compared against the commitment to the Jewish community, and over the years a variety of terms were used to refer to these two obligations as a pair.\n\nBalfour stated in February 1919 that Palestine was considered an exceptional case in which \"we deliberately and rightly decline to accept the principle of self-determination,\" although he considered that the policy provided self-determination to Jews. Avi Shlaim considers this the declaration's \"greatest contradiction\". This principle of self-determination had been declared on numerous occasions subsequent to the declarationPresident Wilson's January 1918 Fourteen points, McMahon's Declaration to the Seven in June 1918, the November 1918 Anglo-French Declaration, and the June 1919 Covenant of the League of Nations that had established the mandate system. In an August 1919 memo Balfour acknowledged the inconsistency among these statements, and further explained that the British had no intention of consulting the existing population of Palestine. The results of the then ongoing American King–Crane Commission of Enquiry consultation of the local population were subsequently suppressed for three years until the report was leaked in 1922. Subsequent British Governments have acknowledged this deficiency, such as the 1939 committee led by the Lord Chancellor, Frederic Maugham, which concluded that the government had not been \"free to dispose of Palestine without regard for the wishes and interests of the inhabitants of Palestine\", and the April 2017 statement by the British Minister of State, Baroness Anelay, that the government acknowledged that \"the Declaration should have called for the protection of political rights of the non-Jewish communities in Palestine, particularly their right to self-determination.\"\n\nThe second safeguard clause was a commitment that nothing should be done which might prejudice the rights of the Jewish communities in other countries outside of Palestine. \n\nThe original drafts of Rothschild, Balfour, and Milner did not include this safeguard, which was drafted together with the preceding safeguard in early October. It reflected opposition from influential members of the Anglo-Jewish community. The Conjoint Foreign Committee of the Board of Deputies of British Jews and the Anglo-Jewish Association had published a letter in \"The Times\" on 24 May 1917 entitled \"Views of Anglo-Jewry\", signed by the two organisations' presidents, David Lindo Alexander and Claude Montefiore, stating their view that: \"the establishment of a Jewish nationality in Palestine, founded on this theory of homelessness, must have the effect throughout the world of stamping the Jews as strangers in their native lands, and of undermining their hard-won position as citizens and nationals of these lands.\" This was followed in late August by Edwin Samuel Montagu, an influential anti-Zionist Jew and Secretary of State for India, and the only Jewish member of the British cabinet, who wrote in a Cabinet memorandum that: \"The policy of His Majesty's Government is anti-Semitic in result and will prove a rallying ground for anti-Semites in every country of the world.\"\n\nLord Rothschild took exception to the new proviso on the basis that it presupposed the possibility of a danger to non-Zionists, which he denied.\n\nThe text of the declaration was published in the press one week after it was signed, on 9November 1917.\n\nThe Tsarist government was a minor party to the Sykes–Picot agreement, and when, following the Russian Revolution, the Bolsheviks published the agreement in \"Izvestia\" and \"Pravda\" on 23 November 1917 and in the British \"Guardian\" on November 26, 1917, \"the British were embarrassed, the Arabs dismayed and the Turks delighted.\" The Zionists had been aware of the outlines of the agreement since April and specifically the part relevant to Palestine, following a meeting between Weizmann and Sir Ronald Cecil where Weizmann made very clear his objections to the proposed scheme. At a private meeting in London on 1 December 1918, French Prime Minister Georges Clemenceau and Lloyd George were to agree to certain modifications to the Sykes-Picot Agreement, including British control of Palestine.\n\nThe publication of the intent galvanized Zionism, which finally had obtained an official charter. It was first published in newspapers on 9November, and leaflets were circulated throughout Jewish communities. These leaflets were airdropped over Jewish communities in Germany and Austria, as well as the Pale of Settlement, which had been given to the Central Powers following the Russian withdrawal.\n\nWeizmann had argued that one consequence of such a public commitment by Great Britain, making the establishment of a Jewish homeland in Palestine one of the Allies' war aims, was that it would have three effects: it would swing Russia to maintain pressure on Germany's Eastern Front, since Jews had been prominent in the March Revolution of 1917. It would rally the large Jewish community in the United States to press for greater funding for the American war effort, underway since April of that year; and, lastly, that it would undermine German Jewish support for Kaiser Wilhelm II.\n\nAmerican Zionism was still in its infancy; in 1914 the Zionist Federation had a small budget of about $5,000 and only 12,000 members, despite an American Jewish population of three million. However, the Zionist organizations had recently succeeded, following a show of force within the American Jewish community, in arranging a Jewish congress to debate the Jewish problem as a whole. This impacted British and French government estimates of the balance of power within the American Jewish public.\n\nIn the ongoing Sinai and Palestine Campaign, both Gaza and Jaffa fell within several days. Once under British military occupation, large transfers of funds were possible, and a major effort began to drain the marshy land of the Valley of Jezreel, whose redemption as the breadbasket of Palestine became the priority of the Third Aliyah settlers, mainly from Eastern Europe.\n\nThe declaration spurred an unintended and extraordinary increase in the number of adherents of American Zionism; in 1914 the 200 American Zionist societies comprised a total of 7,500 members, which grew to 30,000 members in 600 societies in 1918 and 149,000 members in 1919. Whilst the British had considered that the declaration reflected a previously established dominance of the Zionist position in Jewish thought, it was the declaration itself that was subsequently responsible for Zionism's legitimacy and leadership.\n\nIn August 1919 Balfour approved Weizmann's request to name the first post-war settlement in Mandatory Palestine, \"Balfouria\", in his honor. It was intended to be a model settlement for future American Jewish activity in Palestine.\n\nHebert Samuel, the Zionist MP whose 1915 memorandum had framed the start of discussions in the British Cabinet, was asked by Lloyd George on 24April 1920 to act as the first civil governor of British Palestine, replacing the previous military administration that had ruled the area since the war. Shortly after beginning the role in July 1920, he gave a reading at the Hurva Synagogue in Jerusalem, which, according to his memoirs, led the congregation of older settlers to feel that the \"fulfilment of ancient prophecy might at last be at hand\".\n\nFrom 1918 until World War II Jews in Mandatory Palestine celebrated Balfour Day as an annual national holiday on 2November. The celebrations included ceremonies in schools and other public institutions and festive articles in the Hebrew press.\n\nThe local Christian and Muslim community of Palestine, who constituted almost 90% of the population, strongly opposed the declaration. As described by the Palestinian-American philosopher Edward Said in 1979, it was perceived as being made: \"(a)by a European power, (b)about a non-European territory, (c)in a flat disregard of both the presence and the wishes of the native majority resident in that territory, and (d)it took the form of a promise about this same territory to another foreign group.\"\n\nAccording to the 1919 King–Crane Commission, \"No British officer, consulted by the Commissioners, believed that the Zionist programme could be carried out except by force of arms.\" A delegation of the Muslim-Christian Association, headed by Musa al-Husayni, expressed public disapproval on 3November 1918, one day after the Zionist Commission parade marking the first anniversary of the Balfour Declaration. They handed a petition signed by more than 100 notables to Ronald Storrs, the Occupied Enemy Territory Administration (OETA) military governor:\nThe group also protested the carrying of new \"white and blue banners with two inverted triangles in the middle\", drawing the attention of the British authorities to the serious consequences of any political implications in raising the banners. Later that month, on the first anniversary of the occupation of Jaffa by the British, the Muslim-Christian Association sent a lengthy memorandum and petition to the military governor protesting once more any formation of a Jewish state.\n\nIn the broader Arab world, the declaration was seen as a betrayal of the British wartime understandings with the Arabs. The Sharif of Mecca and other Arab leaders considered the declaration a violation of a previous commitment made in the McMahon–Hussein correspondence in exchange for launching the Arab Revolt.\n\nFollowing the publication of the declaration, the British had dispatched Commander David George Hogarth to see Hussein in January 1918 bearing the message that the \"political and economic freedom\" of the Palestinian population was not in question. Hogarth reported that Hussein \"would not accept an independent Jewish State in Palestine, nor was I instructed to warn him that such a state was contemplated by Great Britain\". Hussein had also learned of the Sykes–Picot Agreement when it was leaked by the new Soviet government in December 1917, but was satisfied by two disingenuous telegrams from Sir Reginald Wingate, who had replaced McMahon as High Commissioner of Egypt, assuring him that the British commitments to the Arabs were still valid and that the Sykes–Picot Agreement was not a formal treaty.\n\nContinuing Arab disquiet over Allied intentions also led during 1918 to the British Declaration to the Seven and the Anglo-French Declaration, the latter promising \"the complete and final liberation of the peoples who have for so long been oppressed by the Turks, and the setting up of national governments and administrations deriving their authority from the free exercise of the initiative and choice of the indigenous populations\".\n\nThe 3 January 1919 Faisal–Weizmann Agreement was a short-lived agreement for Arab–Jewish cooperation on the development of a Jewish homeland in Palestine, which Faisal had mistakenly understood was to be within the Arab Kingdom. Faisal did treat Palestine differently in his presentation to the Peace Conference on 6 February 1919 saying \"Palestine, in consequence of its universal character, be left on one side for the mutual consideration of all parties concerned\". The agreement was never implemented.\n\nZionist diplomat Nahum Sokolow was granted an audience with Pope Benedict XV in early May, Jewish settlement in Palestine and the status of the Holy Places were discussed. The Pope expressed general sympathy and support for the Zionist desire for immigration and colonization, restricted under Ottoman rule.\n\nWith the advent of the Balfour Declaration and the British entry into Jerusalem on December 9, the Vatican reversed its earlier sympathetic attitude to Zionism and adopted an oppositional stance that was to continue for some time to come.\n\nImmediately following the publication of the Balfour Declaration, it was met with tactical responses from the Central Powers. Two weeks following the declaration, Ottokar Czernin, the Austrian Foreign Minister, gave an interview to Arthur Hantke, President of the Zionist Federation of Germany, promising that his government would influence the Turks once the war was over. On 12December, the Ottoman Grand Vizier, Talaat Pasha, gave an interview to the German newspaper \"Vossische Zeitung\" that was published on 31December and subsequently released in the German-Jewish periodical \"\" on 4January 1918, in which he referred to the declaration as \"une blague\" (a deception) and promised that under Ottoman rule \"all justifiable wishes of the Jews in Palestine would be able to find their fulfilment\" subject to the absorptive capacity of the country. This Turkish statement was endorsed by the German Foreign Office on 5January 1918. On 8January 1918, to advocate for further progress, a German-Jewish Society was formed, named the Union of German Jewish Organizations for the Protection of the Rights of the Jews of the East (VJOD).\n\nFollowing the war, the Treaty of Sèvres was signed by the Ottoman Empire on 10August 1920. The treaty dissolved the Ottoman Empire, requiring Turkey to renounce sovereignty over much of the Middle East. Article95 of the treaty incorporated the terms of the Balfour Declaration with respect to \"the administration of Palestine, within such boundaries as may be determined by the Principal Allied Powers\". Since inclusion of the Balfour Declaration in the Treaty of Sevres did not affect the legal status of the Balfour Declaration or the Mandate, there was also no effect when Sevres was superseded by the Treaty of Lausanne, which did not include any reference to the Balfour Declaration.\n\nIn 1922, German anti-Semitic theorist Alfred Rosenberg in his primary contribution to Nazi theory on Zionism, \"Der Staatsfeindliche Zionismus\" (\"Zionism, the Enemy of the State\"), accused German Zionists of working for a German defeat and supporting Britain and the implementation of the Balfour Declaration, in a version of the stab-in-the-back myth.\n\nIn 1922 Congress officially endorsed American support through passage of the Lodge–Fish Resolution notwithstanding opposition from the State Department.\n\nLawrence Davidson argues that President Wilson and Congress ignored democratic values in favour of \"biblical romanticism\" when they endorsed the declaration and points to a pro-Zionist lobby, which was active at a time when the small number of unorganized Arab Americans were not heard.\n\nAlthough in the end nothing came of them, during 1917 and 1918, the Turks made informal peace overtures to the British. In the second and third weeks of November, after the signing of the Balfour Declaration, the War Cabinet considered what terms it might offer in order to detach Turkey. Both Milner and Smuts were willing to permit leaving Palestine under nominal Turkish sovereignty and this view, backed by Lloyd George, prevailed even over the objections of the Foreign Office and Curzon.\n\nIn October 1919, Lord Curzon succeeded Balfour as Foreign Secretary. Curzon had opposed the Balfour Declaration prior to its publication and therefore determined to pursue a policy in line with its \"narrower and more prudent rather than the wider interpretation\". Following Bonar Law's appointment as Prime Minister in late 1922, Curzon wrote to Law that he regarded the declaration as \"the worst\" of Britain's Middle East commitments and \"a striking contradiction of our publicly declared principles\". Curzon had been a member of the 1917 Cabinet that had approved the declaration, and according to Sir David Gilmour, Curzon had been \"the only senior figure in the British government at the time who foresaw that its policy would lead to decades of Arab–Jewish hostility\".\n\nIn August 1920 the report of the Palin Commission, the first in a long line of Commissions of Inquiry on the question of Palestine during the Mandate period, noted that \"The Balfour Declaration... is undoubtedly the starting point of the whole trouble\". The conclusion of the report mentioned the Balfour Declaration three times, stating that \"the causes of the alienation and exasperation of the feelings of the population of Palestine\" included:\n\nBritish public and government opinion became increasingly less favourable to the commitment that had been made to Zionist policy. In February 1922 Churchill telegraphed Samuel, who by then had been appointed High Commissioner for Palestine, asking for cuts in expenditure and noting:\nFollowing the issuance of the Churchill White Paper in June 1922, the House of Lords rejected a Palestine Mandate that incorporated the Balfour Declaration by 60 votes to 25, following a motion issued by Lord Islington. The vote proved to be only symbolic as it was subsequently overruled by a vote in the House of Commons following a tactical pivot and variety of promises made by Churchill. The wording of the declaration was thus incorporated into the British Mandate for Palestine, a legal instrument that created Mandatory Palestine for the explicit purpose of putting the declaration into effect. Unlike the declaration itself, the Mandate was legally binding on the British Government.\n\nThe declaration had two indirect consequences, the emergence of a Jewish state and a chronic state of conflict between Arabs and Jews throughout the Middle East. With respect to the latter, the declaration has been described as the \"original sin\" with respect to Britain's failure in Palestine and for wider events in Palestine. Starting in 1920, the Intercommunal conflict in Mandatory Palestine broke out, which widened into the regional Arab–Israeli conflict, often referred to as the world's \"most intractable conflict\". The Arab-Israeli conflict in a wider sense ran primarily from 1948–73, but continues today, mainly in the form of the more localized Israeli–Palestinian conflict. Britain's involvement in this became one of the most controversial parts of its Empire's history, and damaged its reputation in the Middle East for generations.According to Elizabeth Monroe, \"measured by British interests alone, [the Declaration was] one of the greatest mistakes in [its] imperial history.\" \n\nJonathan Schneer's 2010 study concluded that because the buildup to the declaration was characterized by \"contradictions, deceptions, misinterpretations, and wishful thinking\", the declaration sowed dragon's teeth and \"produced a murderous harvest, and we go on harvesting even today\". The foundational stone for modern Israel had been laid, but the prediction that this would lay the groundwork for harmonious Arab-Jewish cooperation proved to be wishful thinking. Following the 1936–1939 Arab revolt in Palestine, the British House of Commons approved the White Paper of 1939 and although this policy lasted until the British surrendered the Mandate in 1948, it served only to highlight the fundamental difficulty for the Mandatory in carrying out the Mandate obligations.\n\nThe declaration also had a significant impact on religious Jews, with some seeing its coming as a divine providence; this encouraged Religious Zionism and discouraged traditional religious anti-Zionism.\n\nThe document was presented to the British Museum in 1924 by Walter Rothschild; today it is held in the British Library, which separated from the British Museum in 1973, as \"Additional Manuscripts number 41178\". From October 1987 to May 1988 it was lent outside the UK for display in Israel's Knesset. The Israeli government are currently in negotiations to arrange a second loan in 2018, with plans to display the document in Independence Hall.\n\n\n\n\n\n"}
{"id": "4821", "url": "https://en.wikipedia.org/wiki?curid=4821", "title": "Black Hand (Serbia)", "text": "Black Hand (Serbia)\n\nUnification or Death (), popularly known as the Black Hand (Црна рука/Crna ruka), was a secret military society formed on 9 May 1911 by officers in the Army of the Kingdom of Serbia, originating in the conspiracy group that assassinated the Serbian royal couple (1903), led by captain Dragutin Dimitrijević \"Apis\".\n\nIt was formed with the aim of uniting all of the territories with a South Slavic majority not ruled by either Serbia or Montenegro. Its inspiration was primarily the unification of Italy in 1859–70, but also that of Germany in 1871. Through its connections to the June 1914 assassination of Archduke Franz Ferdinand in Sarajevo, which was committed by the members of youth movement Young Bosnia, the Black Hand is often viewed as having contributed to the start of World War I by precipitating the July Crisis of 1914, which eventually led to Austria-Hungary's invasion of the Kingdom of Serbia.\n\nIn August 1901, a group of lower officers headed by captain Dragutin Dimitrijević \"Apis\" established a conspiracy group (called the Black Hand in literature), against the dynasty. The first meeting was held on 6 September 1901. In attendance were captains Radomir Aranđelović, Milan F. Petrović, and Dragutin Dimitrijević, as well as lieutenants Antonije Antić, Dragutin Dulić, Milan Marinković, and Nikodije Popović. They made a plan to kill the royal couple − King Alexander I Obrenović and Queen Draga. Captain Apis personally led the group of Army officers who killed the royal couple in the Old Palace at Belgrade on the night of 28/29 May 1903 (Old Style).\n\nOn 8 October 1908, just two days after Austria annexed Bosnia and Herzegovina, some Serbian ministers, officials, and generals held a meeting at the City Hall in Belgrade. They founded a semi-secret society, the \"Narodna Odbrana\" (\"National Defense\") which gave Pan-Serbism a focus and an organization. The purpose of the group was to liberate Serbs under the Austro-Hungarian occupation. They also undertook anti-Austrian propaganda and organized spies and saboteurs to operate within the occupied provinces. Satellite groups were formed in Slovenia, Bosnia, Herzegovina and Istria. The Bosnian group went under the name \"Mlada Bosna\" (\"Young Bosnia\").\n\n \nThe Unification or Death was established in the beginning of May 1911, the original constitution of the organization being signed on 9 May. Ljuba Čupa, Bogdan Radenković and Vojislav Tankosić wrote the constitution of the organization. The constitution was modeled after similar German secret nationalist associations and the Italian Carbonari. The organization was mentioned in the Serbian parliament as the \"Black Hand\" in late 1911.\n\nBy 1911–12, Narodna Odbrana had established ties with the Black Hand, and the two became \"parallel in action and overlapping in membership\".\n\nThe organization used the magazine \"Pijemont\" (the Serbian name for Piedmont, the state around the unification of Italy was done) for their ideology dissemination, founded by Ljuba Čupa in August 1911.\n\nBy 1914, there were hundreds of members, many of whom were Serbian Army officers. The goal of uniting Serb-inhabited territories was implemented through training of guerilla fighters and saboteurs. The Black Hand was organized at the grassroots level in 3 to 5-member cells, supervised by district committees and by a Central committee in Belgrade whose ten-member Executive Committee was led, more or less, by Colonel Dragutin Dimitrijević \"Apis\". To ensure secrecy, members rarely knew much more than the members of their own cell and one superior above them. New members swore the oath:\n\nThe Black Hand took over the terrorist actions of \"Narodna Odbrana\", and worked deliberately at obscuring any distinctions between the two groups, trading on the prestige and network of the older organization. Black Hand members held important army and government positions. Crown Prince Alexander was an enthusiastic and financial supporter. The group held influence over government appointment and policy. The Serbian government was fairly well informed of Black Hand activities.\nFriendly relations had fairly well cooled by 1914. The Black Hand was displeased with Prime Minister Nikola Pašić. They thought he did not act aggressively enough towards the Pan-Serb cause. They engaged in a bitter power struggle over several issues, such as who would control territories Serbia annexed in the Balkan Wars. By this point, disagreeing with the Black Hand was dangerous, as political murder was one of their tools.\n\nIt was also in 1914 that Apis allegedly decided that Archduke Franz Ferdinand, the heir-apparent of Austria, should be assassinated, as he was trying to pacify the Serbians, and if this happened then a revolution would never occur. Towards that end it is claimed that three young Bosnian Serbs were recruited to kill the Archduke. They were definitely trained in bomb throwing and marksmanship by current and former members of the Serbian military. Gavrilo Princip, Nedeljko Čabrinović and Trifko Grabež were smuggled across the border back into Bosnia via a chain of underground-railroad style contacts.\nThe decision to kill the Archduke was apparently initiated by Apis, and not sanctioned by the full Executive Committee (assuming Apis was involved at all, a question that remains in dispute). Those involved probably realized that their plot would result in war between Austria and Serbia, and had every reason to expect that Russia would side with Serbia. They likely did not, however, anticipate that the assassination would start a chain of events leading to world war one.\nOthers in the government and some of the Black Hand Executive Council were not as confident of Russian aid. Russia had let them down recently. When word of the plot allegedly percolated through Black Hand leadership and the Serbian government (the Prime Minister Pašić was definitely informed of two armed men being smuggled across the border; it is not clear if Pašić knew the planned assassination), Apis was supposedly told not to proceed. He may have made a half-hearted attempt to intercept the young assassins at the border, but they had already crossed. Other sources say the attempted 'recall' was only begun after the assassins had reached Sarajevo. This 'recall' appears to make Apis look like a loose cannon, and the young assassins as independent zealots. In fact, the 'recall' took place a full two weeks before the Archduke's visit. The assassins idled around in Sarajevo for a month. Nothing more was done to stop them.\n\nThe Young Bosnia organization carried out the assassination of Archduke Franz Ferdinand. Nedeljko Čabrinović was the first to dare to act, and threw a bomb at the car the Archduke was in. Unfortunately, the Archduke noticed the bomb and reached over to cover his wife. The driver saw his action and accelerated. Čabrinović had forgotten about the ten second delay on the bomb, so as the car accelerated the bomb bounced off the back bumper of the Archduke's car and exploded underneath the car behind, wounding the passengers. Without looking at the result of his bomb, Čabrinović swallowed a cyanide pill and, to make sure he died (like Gavrilo Princip, he had turburculosis and was willing to give his life for the cause) jumped into the nearby river. Unfortunately, the cyanide pill didn't work and only made him sick, and the river was only a few inches deep, so he was dragged out and arrested. After his failure, the rest of the group, including 19-year-old Gavrilo Princip, were too shocked to act and allowed the car to reach its destination. \n\nDisappointed by their failure, the group regathered to discuss what to do now. Torn up by the arrest of his friend and his failure to act, Princip headed over to the local deli. Archduke Ferdinand, who had taken out his anger on the Serbian Prime Minister, insisted on continuing his journey and going to the hospital. For his safety, the route was changed from the original plan. Unfortunately, the driver had not been alerted of the change of route. He turned down the original road, and, seeing his mistake, the guard who was protecting Ferdinand leaned forward to inform the driver of his mistake. By chance, this street was the same one as the one the deli Princip had gone to for a sandwich. As Princip exited the deli, he saw the Archduke's car stop and attempt to reverse directly in front of him, about 10 feet from where he was standing. As the driver tried to rectify his mistake and reverse out of this situation, the brakes on the car jammed, and Princip fired twice. By chance, the two bullets struck their intended marks, one hitting the Archduke in his jugular vein and the other hitting his pregnant wife Sophie in the abdomen. Princip also swallowed a cyanide pill and raised his gun to his head when it didn't work. He was arrested before he could shoot himself.\n\nJust prior to World War I, under the orders of Apis the Chief of Serbian Military Intelligence, Serbian Military Officers of the Black Hand organized and facilitated the assassination of Franz Ferdinand, Archduke of Austria on occasion of his visit to Sarajevo, Bosnia. This was not approved by the Serbian Government, but was a private initiative by Apis, who was also leader of the Black Hand. The Austro-Hungarian investigation of the assassination rounded up all but one of the assassins and also much of the underground railroad that had been used to transport the assassins and their weapons from Serbia to Sarajevo. Within two days following the assassination, Austria-Hungary and Germany advised Serbia that they should open an investigation, but Serbian Foreign Minister Gruić knew nothing of the plot and replied, \"Nothing had been done so far, and the matter did not concern the Serbian Government,\" after which \"high words\" were spoken on both sides. Entreaties by Germany asking Russia to intercede with Serbia were ignored. On 23 July Austria-Hungary delivered a toughly worded letter to Serbia with ten enumerated demands and additional demands in the preamble aimed at the destruction of the anti-Austrian propaganda network in Serbia. Austria called attention to Serbia's March 1909 declaration committing to the Great Powers to respect Austria-Hungary's sovereignty over Bosnia-Herzegovina and committing Serbia to maintain good neighborly relations with Austria-Hungary. If the ten enumerated demands and demands in the preamble were not agreed to within 48 hours, Austria-Hungary would recall its ambassador from Serbia. The letter became known as the July Ultimatum. Serbia accepted all but one of the demands, to let the Austrian officers conduct an investigation on Serbian soil, which would have compromised its sovereignty. In response, Austria-Hungary recalled its ambassador. It later emerged that Austria had intended to reject the response no matter what it was. This was at the instigation of the German Empire, who had also helped draft the impossible ultimatum in hope of provoking a general European war. \n\nAustria-Hungary authorized the mobilization and the declaration of war against Serbia on 28 July 1914. The Secret Treaty of 1892 required both Russia and France to mobilize immediately followed by a commencement of action against the Triple Alliance if any member of the Triplice mobilized, and so, soon all the Great Powers of Europe were at war except Italy. Italy cited a clause in the Triple Alliance treaty which only bound it to enter in case of aggression against one of the treaty members, and so remained neutral – for the time being.\n\nThe six assassins caught by Austria-Hungary were tried and convicted for treason. The leader, Danilo Ilić, was shot by a firing squad. The remaining assassins in custody were not yet twenty years old at the time of the assassination and were therefore given prison terms. Most of the underground railroad that transported them were also arrested, tried, and convicted. Two of these were executed. A few peripheral conspirators were acquitted. A wide ranging investigation rolled up many additional irredentist youths, and the fifth column that the Black Hand and Serbian Military Intelligence had tried to organize was eliminated. After receiving the Austrian letter, Serbia arrested Major Voja Tankosić (a member of the Black Hand committee who had been pointed out by the assassins) but then promptly released him and returned him to his unit. The seventh assassin escaped to Montenegro where he was arrested. Austria-Hungary asserted its right to extradite him, but Montenegrin authorities instead allowed the assassin to \"escape\" to Serbia where he joined Major Tankosić's unit; Major Tankosić died in November 1915 covering the Serbian retreat, but not before confessing his role in the assassination to historians at Azania. Masterspy Rade Malobabić, Serbian Military Intelligence's top agent against Austria-Hungary, was arrested on his return from Austria-Hungary after the assassination, but was also later released and given a commission running an army supply store.\n\nTowards the end of 1916, due to its murders and other illegal activities and to halt its underground influence in both the army and politics, Serbian Prime Minister Nikola Pašić decided to destroy the leaders of the Black Hand and break up the organization. By the spring of 1917, many Black Hand leaders, including Dimitrijević, had been arrested. A sham trial before a military tribunal in Salonika was held in May 1917 for Apis and others. The charges were unrelated to the events of Sarajevo. Among the charges was that the Black Hand had attempted to murder Prince Regent Alexander. Though witnesses against them were numerous, the evidence cited was nearly all hearsay or outright fabrication. Dimitrijević and six others were sentenced to death. Three obtained commutations to long prison terms, but Apis and three comrades were executed by firing squad on 26 June 1917, against protests of the new Kerensky government of Russia. On his way to his execution, Dimitrijević reportedly commented that he was really being executed for planning the murder of Archduke Ferdinand. Before being shot, he made a written confession to the court that he had ordered Rade Malobabić to organize the assassination of Franz Ferdinand. Malobabić made an implied confession to a priest before he was executed. Vulović's confession came at trial where he said he received orders signed by Serbia's top military officer to send Malobabic into Austria-Hungary just before the assassination. Much later, a new trial was ordered by Yugoslavia and the convictions were overturned.\n\nWith the demise of the Black Hand in June 1917 after the Salonika Trial, The White Hand steadily gained control of the young and ambitious Prince Alexander. In what became Yugoslavia after the war, the White Hand grew into an essential piece of the state's machinery. It continued the nationalist work of the Black Hand, but under state control. There is an unconfirmed rumour that the death of Vojislav Petrovic, an ex-attache to the Yugoslav Legation in London, was the work of Narodna Odbrana. Petrovic was preparing a book on the history of the Sarajevo assassinations and the Black Hand.\n\nThe group encompassed a range of ideological outlooks, from conspiratorially-minded army officers to idealistic youths, sometimes tending towards republicanism, despite the acquisition of nationalistic royal circles in its activities (the movement's leader, Colonel Dragutin Dimitrijević or \"Apis,\" had been instrumental in the June 1903 coup which had brought King Petar Karađorđević to the Serbian throne following 45 years of rule by the rival Obrenović dynasty). The group was denounced as nihilist by the Austro-Hungarian press and compared to the Russian People's Will and the Chinese Assassination Corps.\n\nIn 1938 a conspiracy group to overthrow the Yugoslav regency was founded by, among others, members of the Serbian Cultural Club (SKK). The organization was modeled after the Black Hand, including the recruitment process. Two members of the Black Hand, Antonije Antić, and Velimir Vemić were the organization's military advisors.\n\n\n\n\n"}
{"id": "4822", "url": "https://en.wikipedia.org/wiki?curid=4822", "title": "Board of directors", "text": "Board of directors\n\nA board of directors is a recognized group of people who jointly oversee the activities of an organization, which can be either a for-profit business, nonprofit organization, or a government agency. A board of directors' powers, duties and responsibilities are determined by government regulations (including the jurisdiction's corporations law) and the organization's own constitution and bylaws. These authorities may specify the number of members of the board, how they are to be chosen, and how often they are to meet.\n\nIn an organization with voting members, the board is accountable to, and might be subordinate to, the organization's full membership, which usually vote for the members of the board. In a stock corporation, non-executive directors are voted for by the shareholders and the board is the highest authority in the management of the corporation. The board of directors appoints the chief executive officer of the corporation and sets out the overall strategic direction. In corporations with dispersed ownership, the identification and nomination of directors (that shareholders vote for or against) are often done by the board itself, leading to a high degree of self-perpetuation. In a non-stock corporation with no general voting membership, the board is the supreme governing body of the institution; its members are sometimes chosen by the board itself.\n\nOther names include Board of directors and advisors, board of governors, board of managers, board of regents, board of trustees, or board of visitors. It may also be called \"the executive board\" and is often simply referred to as \"the board\".\n\nTypical duties of boards of directors include:\n\nThe legal responsibilities of boards and board members vary with the nature of the organization, and between jurisdictions. For companies with publicly trading stock, these responsibilities are typically much more rigorous and complex than for those of other types.\n\nTypically, the board chooses one of its members to be the \"chairman\" (more usually now called the \"chair\" or \"chairperson\"), who holds whatever title is specified in the bylaws or articles of association. However, in membership organizations, the members elect the president of the organization and the president becomes the chair of the board, unless the bylaws say otherwise.\n\nThe directors of an organization are the persons who are members of its board. Several specific terms categorize directors by the presence or absence of their other relationships to the organization.\n\nAn inside director is a director who is also an employee, officer, chief executive, major shareholder, or someone similarly connected to the organization. Inside directors represent the interests of the entity's stakeholders, and often have special knowledge of its inner workings, its financial or market position, and so on.\n\nTypical inside directors are:\n\nAn inside director who is employed as a manager or executive of the organization is sometimes referred to as an executive director (not to be confused with the title executive director sometimes used for the CEO position in some organizations). Executive directors often have a specified area of responsibility in the organization, such as finance, marketing, human resources, or production.\n\nAn outside director is a member of the board who is not otherwise employed by or engaged with the organization, and does not represent any of its stakeholders. A typical example is a director who is president of a firm in a different industry. Outside directors are not employees of the company or affiliated with it in any other way.\n\nOutside directors bring outside experience and perspectives to the board. For example, for a company that only serves a domestic market, the presence of CEOs from global multinational corporations as outside directors can help to provide insights on export and import opportunities and international trade options. One of the arguments for having outside directors is that they can keep a watchful eye on the inside directors and on the way the organization is run. Outside directors are unlikely to tolerate \"insider dealing\" between insider directors, as outside directors do not benefit from the company or organization. Outside directors are often useful in handling disputes between inside directors, or between shareholders and the board. They are thought to be advantageous because they can be objective and present little risk of conflict of interest. On the other hand, they might lack familiarity with the specific issues connected to the organization's governance and they might not know about the industry or sector in which the organization is operating.\n\n\nIndividual directors often serve on more than one board. This practice results in an interlocking directorate, where a relatively small number of individuals have significant influence over a large number of important entities. This situation can have important corporate, social, economic, and legal consequences, and has been the subject of significant research.\n\nThe process for running a board, sometimes called the board process, includes the selection of board members, the setting of clear board objectives, the dissemination of documents or board package to the board members, the collaborative creation of an agenda for the meeting, the creation and follow-up of assigned action items, and the assessment of the board process through standardized assessments of board members, owners, and CEOs. The science of this process has been slow to develop due to the secretive nature of the way most companies run their boards, however some standardization is beginning to develop. Some who are pushing for this standardization in the USA are the National Association of Corporate Directors, McKinsey Consulting and The Board Group.\n\nA board of directors conducts its meetings according to the rules and procedures contained in its governing documents. These procedures may allow the board to conduct its business by conference call or other electronic means. They may also specify how a quorum is to be determined.\n\nMost organizations have adopted \"Robert's Rules of Order\" as its guide to supplement its own rules. In this book, the rules for conducting board meetings may be less formal if there is no more than about a dozen board members present. An example of the informality is that motions are not required if it's clear what is being discussed.\n\nHistorically, nonprofit boards have not uncommonly had large boards with up to twenty-four members, but a modern trend is to have smaller boards as small as six or seven people. Studies suggest that after seven people, each additional person reduces the effectiveness of group-decision-making.\n\nThe role and responsibilities of a board of directors vary depending on the nature and type of business entity and the laws applying to the entity (see types of business entity). For example, the nature of the business entity may be one that is traded on a public market (public company), not traded on a public market (a private, limited or closely held company), owned by family members (a family business), or exempt from income taxes (a non-profit, not for profit, or tax-exempt entity). There are numerous types of business entities available throughout the world such as a corporation, limited liability company, cooperative, business trust, partnership, private limited company, and public limited company.\n\nMuch of what has been written about boards of directors relates to boards of directors of business entities actively traded on public markets. More recently, however, material is becoming available for boards of private and closely held businesses including family businesses.\n\nA board-only organization is one whose board is self-appointed, rather than being accountable to a base of members through elections; or in which the powers of the membership are extremely limited.\n\nIn membership organizations, such as a society made up of members of a certain profession or one advocating a certain cause, a board of directors may have the responsibility of running the organization in between meetings of the membership, especially if the membership meets infrequently, such as only at an annual general meeting. The amount of powers and authority delegated to the board depend on the bylaws and rules of the particular organization. Some organizations place matters exclusively in the board's control while in others, the general membership retains full power and the board can only make recommendations.\n\nThe setup of a board of directors vary widely across organizations and may include provisions that are applicable to corporations, in which the \"shareholders\" are the members of the organization. A difference may be that the membership elects the officers of the organization, such as the president and the secretary, and the officers become members of the board in addition to the directors and retain those duties on the board. The directors may also be classified as officers in this situation. There may also be ex-officio members of the board, or persons who are members due to another position that they hold. These ex-officio members have all the same rights as the other board members.\n\nMembers of the board may be removed before their term is complete. Details on how they can be removed are usually provided in the bylaws. If the bylaws do not contain such details, the section on disciplinary procedures in \"Robert's Rules of Order\" may be used.\n\nIn a publicly held company, directors are elected to represent and are legally obligated as fiduciaries to represent owners of the company—the shareholders/stockholders. In this capacity they establish policies and make decisions on issues such as whether there is dividend and how much it is, stock options distributed to employees, and the hiring/firing and compensation of upper management.\n\nTheoretically, the control of a company is divided between two bodies: the board of directors, and the shareholders in general meeting. In practice, the amount of power exercised by the board varies with the type of company. In small private companies, the directors and the shareholders are normally the same people, and thus there is no real division of power. In large public companies, the board tends to exercise more of a supervisory role, and individual responsibility and management tends to be delegated downward to individual professional executives (such as a finance director or a marketing director) who deal with particular areas of the company's affairs.\n\nAnother feature of boards of directors in large public companies is that the board tends to have more de facto power. Many shareholders grant proxies to the directors to vote their shares at general meetings and accept all recommendations of the board rather than try to get involved in management, since each shareholder's power, as well as interest and information is so small. Larger institutional investors also grant the board proxies. The large number of shareholders also makes it hard for them to organize. However, there have been moves recently to try to increase shareholder activism among both institutional investors and individuals with small shareholdings.\n\nA contrasting view is that in large public companies it is upper management and not boards that wield practical power, because boards delegate nearly all of their power to the top executive employees, adopting their recommendations almost without fail. As a practical matter, executives even choose the directors, with shareholders normally following management recommendations and voting for them.\n\nIn most cases, serving on a board is not a career unto itself. For major corporations, the board members are usually professionals or leaders in their field. In the case of outside directors, they are often senior leaders of other organizations. Nevertheless, board members often receive remunerations amounting to hundreds of thousands of dollars per year since they often sit on the boards of several companies. Inside directors are usually not paid for sitting on a board, but the duty is instead considered part of their larger job description. Outside directors are usually paid for their services. These remunerations vary between corporations, but usually consist of a yearly or monthly salary, additional compensation for each meeting attended, stock options, and various other benefits. such as travel, hotel and meal expenses for the board meetings. Tiffany & Co., for example, pays directors an annual retainer of $46,500, an additional annual retainer of $2,500 if the director is also a chairperson of a committee, a per-meeting-attended fee of $2,000 for meetings attended in person, a $500 fee for each meeting attended via telephone, in addition to stock options and retirement benefits.\n\nIn some European and Asian countries, there are two separate boards, an executive board for day-to-day business and a supervisory board (elected by the shareholders and employees) for supervising the executive board. In these countries, the CEO (chief executive or managing director) presides over the executive board and the chairman presides over the supervisory board, and these two roles will always be held by different people. This ensures a distinction between management by the executive board and governance by the supervisory board and allows for clear lines of authority. The aim is to prevent a conflict of interest and too much power being concentrated in the hands of one person. There is a strong parallel here with the structure of government, which tends to separate the political cabinet from the management civil service. In the United States, the board of directors (elected by the shareholders) is often equivalent to the supervisory board, while the executive board may often be known as the executive committee (operating committee or executive council), composed of the CEO and their direct reports (other C-level officers, division/subsidiary heads).\n\nThe development of a separate board of directors to manage/govern/oversee a company has occurred incrementally and indefinitely over legal history. Until the end of the 19th century, it seems to have been generally assumed that the general meeting (of all shareholders) was the supreme organ of a company, and that the board of directors merely acted as an agent of the company subject to the control of the shareholders in general meeting.\n\nHowever, by 1906, the English Court of Appeal had made it clear in the decision of \"Automatic Self-Cleansing Filter Syndicate Co Ltd v Cuninghame\" [1906] 2 Ch 34 that the division of powers between the board and the shareholders in general meaning depended on the construction of the articles of association and that, where the powers of management were vested in the board, the general meeting could not interfere with their lawful exercise. The articles were held to constitute a contract by which the members had agreed that \"the directors and the directors alone shall manage.\"\n\nThe new approach did not secure immediate approval, but it was endorsed by the House of Lords in \"Quin & Axtens v Salmon\" [1909] AC 442 and has since received general acceptance. Under English law, successive versions of Table A have reinforced the norm that, unless the directors are acting contrary to the law or the provisions of the Articles, the powers of conducting the management and affairs of the company are vested in them.\n\nThe modern doctrine was expressed in \"John Shaw & Sons (Salford) Ltd v Shaw\" [1935] 2 KB 113 by Greer LJ as follows:\n\nA company is an entity distinct alike from its shareholders and its directors. Some of its powers may, according to its articles, be exercised by directors, certain other powers may be reserved for the shareholders in general meeting. If powers of management are vested in the directors, they and they alone can exercise these powers. The only way in which the general body of shareholders can control the exercise of powers by the articles in the directors is by altering the articles, or, if opportunity arises under the articles, by refusing to re-elect the directors of whose actions they disapprove. They cannot themselves usurp the powers which by the articles are vested in the directors any more than the directors can usurp the powers vested by the articles in the general body of shareholders.\nIt has been remarked that this development in the law was somewhat surprising at the time, as the relevant provisions in Table A (as it was then) seemed to contradict this approach rather than to endorse it.\n\nIn most legal systems, the appointment and removal of directors is voted upon by the shareholders in general meeting or through a proxy statement. For publicly traded companies in the U.S., the directors which are available to vote on are largely selected by either the board as a whole or a nominating committee. Although in 2002 the New York Stock Exchange and the NASDAQ required that nominating committees consist of independent directors as a condition of listing, nomination committees have historically received input from management in their selections even when the CEO does not have a position on the board. Shareholder nominations can only occur at the general meeting itself or through the prohibitively expensive process of mailing out ballots separately; in May 2009 the SEC proposed a new rule allowing shareholders meeting certain criteria to add nominees to the proxy statement. In practice for publicly traded companies, the managers (inside directors) who are purportedly accountable to the board of directors have historically played a major role in selecting and nominating the directors who are voted on by the shareholders, in which case more \"gray outsider directors\" (independent directors with conflicts of interest) are nominated and elected.\n\nDirectors may also leave office by resignation or death. In some legal systems, directors may also be removed by a resolution of the remaining directors (in some countries they may only do so \"with cause\"; in others the power is unrestricted).\n\nSome jurisdictions also permit the board of directors to appoint directors, either to fill a vacancy which arises on resignation or death, or as an addition to the existing directors.(\"needs citation\")\n\nIn practice, it can be quite difficult to remove a director by a resolution in general meeting. In many legal systems, the director has a right to receive special notice of any resolution to remove him or her; the company must often supply a copy of the proposal to the director, who is usually entitled to be heard by the meeting. The director may require the company to circulate any representations that he wishes to make. Furthermore, the director's contract of service will usually entitle him to compensation if he is removed, and may often include a generous \"golden parachute\" which also acts as a deterrent to removal.\n\nA recent study examines how corporate shareholders voted in director elections in the United States. It found that directors received fewer votes from shareholders when their companies performed poorly, had excess CEO compensation, or had poor shareholder protection. Also, directors received fewer votes when they did not regularly attend board meetings or received negative recommendations from a proxy advisory firm. The study also shows that companies often improve their corporate governance by removing poison pills or classified boards and by reducing excessive CEO pay after their directors receive low shareholder support.\n\nBoard accountability to shareholders is a recurring issue. In 2010, the \"New York Times\" noted that several directors who had overseen companies which had failed in the financial crisis of 2007–2010 had found new positions as directors. The SEC sometimes imposes a ban (a \"D&O bar\") on serving on a board as part of its fraud cases, and one of these was upheld in 2013.\n\nThe exercise by the board of directors of its powers usually occurs in board meetings. Most legal systems require sufficient notice to be given to all directors of these meetings, and that a quorum must be present before any business may be conducted. Usually, a meeting which is held without notice having been given is still valid if all of the directors attend, but it has been held that a failure to give notice may negate resolutions passed at a meeting, because the persuasive oratory of a minority of directors might have persuaded the majority to change their minds and vote otherwise.\n\nIn most common law countries, the powers of the board are vested in the board as a whole, and not in the individual directors. However, in instances an individual director may still bind the company by his acts by virtue of his ostensible authority (see also: the rule in \"Turquand's Case\").\n\nBecause directors exercise control and management over the organization, but organizations are (in theory) run for the benefit of the shareholders, the law imposes strict duties on directors in relation to the exercise of their duties. The duties imposed on directors are fiduciary duties, similar to those that the law imposes on those in similar positions of trust: agents and trustees.\n\nThe duties apply to each director separately, while the powers apply to the board jointly. Also, the duties are owed to the company itself, and not to any other entity. This does not mean that directors can never stand in a fiduciary relationship to the individual shareholders; they may well have such a duty in certain circumstances.\n\nDirectors must exercise their powers for a proper purpose. While in many instances an improper purpose is readily evident, such as a director looking to feather his or her own nest or divert an investment opportunity to a relative, such breaches usually involve a breach of the director's duty to act in good faith. Greater difficulties arise where the director, while acting in good faith, is serving a purpose that is not regarded by the law as proper.\n\nThe seminal authority in relation to what amounts to a proper purpose is the Supreme Court decision in . The case concerned the powers of directors under the articles of association of the company to disenfranchise voting rights attached to shares for failure to properly comply with notice served on the shareholders. Prior to that case the leading authority was \"Howard Smith Ltd v Ampol Ltd\" [1974] AC 821. The case concerned the power of the directors to issue new shares. It was alleged that the directors had issued a large number of new shares purely to deprive a particular shareholder of his voting majority. An argument that the power to issue shares could only be properly exercised to raise new capital was rejected as too narrow, and it was held that it would be a proper exercise of the director's powers to issue shares to a larger company to ensure the financial stability of the company, or as part of an agreement to exploit mineral rights owned by the company. If so, the mere fact that an incidental result (even if it was a desired consequence) was that a shareholder lost his majority, or a takeover bid was defeated, this would not itself make the share issue improper. But if the sole purpose was to destroy a voting majority, or block a takeover bid, that would be an improper purpose.\n\nNot all jurisdictions recognised the \"proper purpose\" duty as separate from the \"good faith\" duty however.\n\nDirectors cannot, without the consent of the company, fetter their discretion in relation to the exercise of their powers, and cannot bind themselves to vote in a particular way at future board meetings. This is so even if there is no improper motive or purpose, and no personal advantage to the director.\n\nThis does not mean, however, that the board cannot agree to the company entering into a contract which binds the company to a certain course, even if certain actions in that course will require further board approval. The company remains bound, but the directors retain the discretion to vote against taking the future actions (although that may involve a breach by the company of the contract that the board previously approved).\n\nAs fiduciaries, the directors may not put themselves in a position where their interests and duties conflict with the duties that they owe to the company. The law takes the view that good faith must not only be done, but must be manifestly seen to be done, and zealously patrols the conduct of directors in this regard; and will not allow directors to escape liability by asserting that his decision was in fact well founded. Traditionally, the law has divided conflicts of duty and interest into three sub-categories.\n\nBy definition, where a director enters into a transaction with a company, there is a conflict between the director's interest (to do well for himself out of the transaction) and his duty to the company (to ensure that the company gets as much as it can out of the transaction). This rule is so strictly enforced that, even where the conflict of interest or conflict of duty is purely hypothetical, the directors can be forced to disgorge all personal gains arising from it. In \"Aberdeen Ry v Blaikie\" (1854) 1 Macq HL 461 Lord Cranworth stated in his judgment that:\n\nHowever, in many jurisdictions the members of the company are permitted to ratify transactions which would otherwise fall foul of this principle. It is also largely accepted in most jurisdictions that this principle can be overridden in the company's constitution.\n\nIn many countries, there is also a statutory duty to declare interests in relation to any transactions, and the director can be fined for failing to make disclosure.\n\nDirectors must not, without the informed consent of the company, use for their own profit the company's assets, opportunities, or information. This prohibition is much less flexible than the prohibition against the transactions with the company, and attempts to circumvent it using provisions in the articles have met with limited success.\n\nIn \"Regal (Hastings) Ltd v Gulliver\" [1942] All ER 378 the House of Lords, in upholding what was regarded as a wholly unmeritorious claim by the shareholders, held that:\n\nAnd accordingly, the directors were required to disgorge the profits that they made, and the shareholders received their windfall.\n\nThe decision has been followed in several subsequent cases, and is now regarded as settled law.\n\nDirectors cannot compete directly with the company without a conflict of interest arising. Similarly, they should not act as directors of competing companies, as their duties to each company would then conflict with each other.\n\nTraditionally, the level of care and skill which has to be demonstrated by a director has been framed largely with reference to the non-executive director. In \"Re City Equitable Fire Insurance Co\" [1925] Ch 407, it was expressed in purely subjective terms, where the court held that:\n\nHowever, this decision was based firmly in the older notions (see above) that prevailed at the time as to the mode of corporate decision making, and effective control residing in the shareholders; if they elected and put up with an incompetent decision maker, they should not have recourse to complain.\n\nHowever, a more modern approach has since developed, and in \"Dorchester Finance Co Ltd v Stebbing\" [1989] BCLC 498 the court held that the rule in \"Equitable Fire\" related only to skill, and not to diligence. With respect to diligence, what was required was:\n\nThis was a dual subjective and objective test, and one deliberately pitched at a higher level.\n\nMore recently, it has been suggested that both the tests of skill and diligence should be assessed objectively and subjectively; in the United Kingdom, the statutory provisions relating to directors' duties in the new Companies Act 2006 have been codified on this basis.\n\nIn most jurisdictions, the law provides for a variety of remedies in the event of a breach by the directors of their duties:\n\nHistorically, directors' duties have been owed almost exclusively to the company and its members, and the board was expected to exercise its powers for the financial benefit of the company. However, more recently there have been attempts to \"soften\" the position, and provide for more scope for directors to act as good corporate citizens. For example, in the United Kingdom, the Companies Act 2006 requires directors of companies \"to promote the success of the company for the benefit of its members as a whole\" and sets out the following six factors regarding a director's duty to promote success:\n\nThis represents a considerable departure from the traditional notion that directors' duties are owed only to the company. Previously in the United Kingdom, under the Companies Act 1985, protections for non-member stakeholders were considerably more limited (see for example, s.309 which permitted directors to take into account the interests of employees but which could only be enforced by the shareholders and not by the employees themselves). The changes have therefore been the subject of some criticism.\n\nThe Sarbanes–Oxley Act of 2002 has introduced new standards of accountability on boards of U.S. companies or companies listed on U.S. stock exchanges. Under the Act, directors risk large fines and prison sentences in the case of accounting crimes. Internal control is now the direct responsibility of directors. The vast majority of companies covered by the Act have hired internal auditors to ensure that the company adheres to required standards of internal control. The internal auditors are required by law to report directly to an audit board, consisting of directors more than half of whom are outside directors, one of whom is a \"financial expert.\"\n\nThe law requires companies listed on the major stock exchanges (NYSE, NASDAQ) to have a majority of independent directors—directors who are not otherwise employed by the firm or in a business relationship with it.\n\nAccording to the Corporate Library's study, the average size of publicly traded company's board is 9.2 members, and most boards range from 3 to 31 members. According to Investopedia, some analysts think the ideal size is seven. State law may specify a minimum number of directors, maximum number of directors, and qualifications for directors (e.g. whether board members must be individuals or may be business entities).\n\nWhile a board may have several committees, two—the compensation committee and audit committee—are critical and must be made up of at least three independent directors and no inside directors. Other common committees in boards are nominating and governance.\n\nDirectors of Fortune 500 companies received median pay of $234,000 in 2011. Directorship is a part-time job. A recent National Association of Corporate Directors study found directors averaging just 4.3 hours a week on board work. Surveys indicate that about 20% of nonprofit foundations pay their board members, and 2% of American nonprofit organizations do. 80% of nonprofit organizations require board members to personally contribute to the organization, as BoardSource recommends. This percentage has increased in recent years.\n\nAccording to John Gillespie, a former investment banker and co-author of a book critical of boards, \"Far too much of their time has been for check-the-box and cover-your-behind activities rather than real monitoring of executives and providing strategic advice on behalf of shareholders\". At the same time, scholars have found that individual directors have a large effect on major corporate initiatives such as mergers and acquisitions and cross-border investments.\n\nThe issue of gender representation on corporate boards of directors has been the subject of much criticism in recent years. Governments and corporations have responded with measures such as legislation mandating gender quotas and comply or explain systems to address the disproportionality of gender representation on corporate boards. A study of the French corporate elite has found that certain social classes are also disproportionately represented on boards, with those from the upper and, especially, upper-middle classes tending to dominate.\n\n\n"}
{"id": "4823", "url": "https://en.wikipedia.org/wiki?curid=4823", "title": "Balkan Wars", "text": "Balkan Wars\n\nThe Balkan Wars (, literally \"the Balkan Wars\" or \"Balkan Faciası\", meaning \"the Balkan Tragedy\") consisted of two conflicts that took place in the Balkan Peninsula in south-eastern Europe in 1912 and 1913. Four Balkan states defeated the Ottoman Empire in the first war; one of the four, Bulgaria, suffered defeat in the second war. The Ottoman Empire lost the bulk of its territory in Europe. Austria-Hungary, although not a combatant, became relatively weaker as a much enlarged Serbia pushed for union of the South Slavic peoples. The war set the stage for the Balkan crisis of 1914 and thus served as a \"prelude to the First World War\".\n\nBy the early 20th century, Bulgaria, Greece, Montenegro and Serbia had achieved independence from the Ottoman Empire, but large elements of their ethnic populations remained under Ottoman rule. In 1912 these countries formed the Balkan League. The First Balkan War had three main causes:\n\n\nThe Ottoman Empire lost all its European territories to the west of the River Maritsa as a result of the two Balkan Wars, which thus delineated present-day Turkey's western border. A large influx of Turks started to flee into the Ottoman heartland from the lost lands. By 1914, the remaining core region of the Ottoman Empire had experienced a population increase of around 2.5 million because of the flood of immigration from the Balkans.\n\nCitizens of Turkey regard the Balkan Wars as a major disaster (\"Balkan harbi faciası\") in the nation's history. The unexpected fall and sudden relinquishing of Turkish-dominated European territories created a psycho-traumatic event amongst many Turks that is said to have triggered the ultimate collapse of the empire itself within five years. Nazım Pasha, Chief of Staff of the Ottoman Army, was held responsible for the failure and was assassinated on 23 January 1913 during the 1913 Ottoman coup d'état.\n\nThe First Balkan War began when the League member states attacked the Ottoman Empire on 8 October 1912 and ended eight months later with the signing of the Treaty of London on 30 May 1913. The Second Balkan War began on 16 June 1913. Both Serbia and Greece, utilizing the argument that the war had been prolonged, repudiated important particulars of the pre-war treaty and retained occupation of all the conquered districts in their possession, which were to be divided according to specific predefined boundaries. Seeing the treaty as trampled, Bulgaria was dissatisfied over the division of the spoils in Macedonia (made in secret by its former allies, Serbia and Greece) and commenced military action against them. The more numerous combined Serbian and Greek armies repelled the Bulgarian offensive and counter-attacked into Bulgaria from the west and the south. Romania, who having taken no part in the conflict, had intact armies to strike with, invaded Bulgaria from the north in violation of a peace treaty between the two states. The Ottoman Empire also attacked Bulgaria and advanced in Thrace regaining Adrianople. In the resulting Treaty of Bucharest, Bulgaria lost most of the territories it had gained in the First Balkan War in addition to being forced to cede the ex-Ottoman south-third of Dobroudja province to Romania.\n\nThe background to the wars lies in the incomplete emergence of nation-states on the European territory of the Ottoman Empire during the second half of the 19th century. Serbia had gained substantial territory during the Russo-Turkish War, 1877–1878, while Greece acquired Thessaly in 1881 (although it lost a small area back to the Ottoman Empire in 1897) and Bulgaria (an autonomous principality since 1878) incorporated the formerly distinct province of Eastern Rumelia (1885). All three countries, as well as Montenegro, sought additional territories within the large Ottoman-ruled region known as Rumelia, comprising Eastern Rumelia, Albania, Macedonia, and Thrace.\n\nThroughout the 19th century, the Great Powers shared different aims over the \"Eastern Question\" and the integrity of the Ottoman Empire. Russia wanted access to the \"warm waters\" of the Mediterranean from the Black Sea; it pursued a pan-Slavic foreign policy and therefore supported Bulgaria and Serbia. Britain wished to deny Russia access to the \"warm waters\" and supported the integrity of the Ottoman Empire, although it also supported a limited expansion of Greece as a backup plan in case integrity of the Empire was no longer possible. France wished to strengthen its position in the region, especially in the Levant (today's Lebanon, Syria, the Palestinian territories and Israel).\n\nHabsburg-ruled Austria-Hungary wished for a continuation of the existence of the Ottoman Empire, since both were troubled multinational entities and thus the collapse of the one might weaken the other. The Habsburgs also saw a strong Ottoman presence in the area as a counterweight to the Serbian nationalistic call to their own Serb subjects in Bosnia, Vojvodina and other parts of the empire. Italy, it has been argued, wished to recreate the Roman empire, though its primary aim at the time seems to have been the denial of access to the Adriatic Sea to another major sea power. The German Empire, in turn, under the \"Drang nach Osten\" policy, aspired to turn the Ottoman Empire into its own de facto colony, and thus supported its integrity.\n\nIn the late 19th and early 20th century, Bulgaria and Greece contended for Ottoman Macedonia and Thrace. Ethnic Greeks sought the forced \"Hellenization\" of ethnic Bulgars, who sought \"Bulgarization\" of Greeks (Rise of nationalism). Both nations sent armed irregulars into Ottoman territory to protect and assist their ethnic kindred. From 1904, there was low intensity warfare in Macedonia between the Greek and Bulgarian bands and the Ottoman army (the Struggle for Macedonia). After the Young Turk revolution of July 1908, the situation changed drastically.\n\nThe 1908 Young Turk Revolution saw the reinstatement of constitutional monarchy in the Ottoman Empire and the start of the Second Constitutional Era. When the revolt broke out, it was supported by intellectuals, the army, and almost all the ethnic minorities of the Empire, and forced Sultan Abdul Hamid II to re-adopt the long defunct Ottoman constitution of 1876 and parliament. Hopes were raised among the Balkan ethnicities of reforms and autonomy, and elections were held to form a representative, multi-ethnic, Ottoman parliament. However, following the Sultan's attempted counter-coup, the liberal element of the Young Turks was sidelined and the nationalist element became dominant.\n\nAt the same time, in October 1908, Austria-Hungary seized the opportunity of the Ottoman political upheaval to annex the \"de jure\" Ottoman province of Bosnia and Herzegovina, which it had occupied since 1878 (see \"Bosnian Crisis\"). Bulgaria declared independence as it had done in 1878, but this time the independence was internationally recognised. The Greeks of the autonomous Cretan State proclaimed unification with Greece, though the opposition of the Great Powers prevented the latter action from taking practical effect. It has large influence in the consequent world order.\n\nSerbia was frustrated in the north by Austria-Hungary's incorporation of Bosnia. In March 1909, Serbia was forced to accept the annexation and restrain anti-Habsburg agitation by Serbian nationalists. Instead, the Serbian government (PM: Nikola Pašić) looked to formerly Serb territories in the south, notably \"Old Serbia\" (the Sanjak of Novi Pazar and the province of Kosovo).\n\nOn 15 August 1909, the Military League, a group of Greek officers, took action against the government to reform their country's national government and reorganize the army. The Military League found itself unable to create a new political system, until the League summoned the Cretan politician Eleutherios Venizelos to Athens as its political adviser. Venizelos persuaded king George I to revise the constitution and asked the League to disband in favor of a National Assembly. In March 1910, the Military League dissolved itself.\n\nBulgaria, which had secured Ottoman recognition of her independence in April 1909 and enjoyed the friendship of Russia, also looked to annex districts of Ottoman Thrace and Macedonia. In August 1910, Montenegro followed Bulgaria's precedent by becoming a kingdom.\n\nFollowing Italy's victory in the Italo-Turkish War of 1911–1912, the Young Turks fell from power after a coup. The Balkan countries saw this as an opportunity to attack the Ottoman Empire and fulfill their desires of expansion.\n\nWith the initial encouragement of Russian agents, a series of agreements was concluded between Serbia and Bulgaria in March 1912. Military victory against the Ottoman Empire would not be possible while it could bring reinforcements from Asia. The condition of the Ottoman railways of the time was not advanced, so most reinforcements would have to come by sea through the Aegean Sea. Greece was the only Balkan country with a navy powerful enough to deny use of the Aegean to the Ottoman Empire, thus a treaty between Greece and Bulgaria became necessary; it was signed in May 1912.\n\nMontenegro concluded agreements between Serbia and Bulgaria later that year. Bulgaria signed treaties with Serbia to divide the territory of northern Macedonia.\n\nThis alliance between Greece, Serbia, Bulgaria, and Montenegro became known as the Balkan League; its existence was undesirable for all the Great Powers. The League was loose at best, though secret liaison officers were exchanged between the Greek and the Serbian army after the war began. Greece delayed the start of the war several times in the summer of 1912, to better prepare her navy, but Montenegro declared war on 8 October (25 September O.S.). Following an ultimatum to the Ottoman Empire, the remaining members of the alliance entered the conflict on 17 October.\n\nThe three Slavic allies (Bulgaria, Serbia and Montenegro) had laid out extensive plans to coordinate their war efforts, in continuation of their secret prewar settlements and under close Russian supervision (Greece was not included). Serbia and Montenegro would attack in the theater of Sandjak, Bulgaria and Serbia in Macedonia and Thrace.\n\nThe Ottoman Empire's situation was difficult. Its population of about 26 million people provided a massive pool of manpower, but three quarters of the population and nearly all of the Muslim component lived in the Asian part of the Empire. Reinforcements had to come from Asia mainly by sea, which depended on the result of battles between the Turkish and Greek navies in the Aegean.\n\nWith the outbreak of the war, the Ottoman Empire activated three Army HQs: the Thracian HQ in Constantinople, the Western HQ in Salonika, and the Vardar HQ in Skopje, against the Bulgarians, the Greeks and the Serbians respectively. Most of their available forces were allocated to these fronts. Smaller independent units were allocated elsewhere, mostly around heavily fortified cities.\n\nMontenegro was the first that declared war on 8 October (25 September O.S.). Its main thrust was towards Shkodra, with secondary operations in the Novi Pazar area. The rest of the Allies, after giving a common ultimatum, declared war a week later. Bulgaria attacked towards Eastern Thrace, being stopped only at the outskirts of Constantinople at the Çatalca line and the isthmus of the Gallipoli peninsula, while secondary forces captured Western Thrace and Eastern Macedonia. Serbia attacked south towards Skopje and Monastir and then turned west to present-day Albania, reaching the Adriatic, while a second Army captured Kosovo and linked with the Montenegrin forces. Greece's main forces attacked from Thessaly into Macedonia through the Sarantaporo strait and after capturing Thessaloniki on 12 November (on 26 October 1912, O.S.) expanded its occupied area and linked up with the Serbian army to the northwest, while its main forces turned east towards Kavala, reaching the Bulgarians. Another Greek army attacked into Epirus towards Ioannina.\n\nOn the naval front, the Ottoman fleet twice exited the Dardanelles and was twice defeated by the Greek Navy, in the battles of Elli and Lemnos. Greek dominance on the Aegean Sea made it impossible for the Ottomans to transfer the planned troops from the Middle East to the Thracian (against the Bulgarian) and to the Macedonian (against the Greeks and Serbians) fronts. According to the E.J. Erickson the Greek Navy also played a crucial, albeit indirect role, in the Thracian campaign by neutralizing no less than three Thracian Corps (see First Balkan War, the Bulgarian theater of operations), a significant portion of the Ottoman Army there, in the all-important opening round of the war. After the defeating of the Ottoman fleet the Greek Navy was also free to liberate the islands of the Aegean. General Nikola Ivanov identified the activity of the Greek Navy as the chief factor in the general success of the allies.\n\nIn January, after a successful coup by young army officers, the Ottoman Empire decided to continue the war. After a failed Ottoman counter-attack in the Western-Thracian front, Bulgarian forces, with the help of the Serbian Army, managed to conquer Adrianople, while Greek forces managed to take Ioannina after defeating the Ottomans in the battle of Bizani. In the joint Serbian-Montenegrin theater of operation, the Montenegrin army besieged and captured the Shkodra, ending the Ottoman presence in Europe west of the Çatalca line after nearly 500 years. The war ended officially with the Treaty of London on 30(17) May 1913.\n\nThough the Balkan allies had fought together against the common enemy, that was not enough to overcome their mutual rivalries. In the original document for the Balkans league, Serbia promised Bulgaria most of Macedonia. But before the first war come to an end, Serbia (in violation of the previous agreement) and Greece revealed their plan to keep possession of the territories that their forces had occupied. This act prompted the tsar of Bulgaria to invade his allies. The Second Balkan War broke out on 29(16) June 1913 when Bulgaria attacked its erstwhile allies in the First Balkan War, Serbia and Greece, while Montenegro and the Ottoman Empire intervened later against Bulgaria, with Romania attacking Bulgaria from the north. When the Greek army entered Thessaloniki in the First Balkan War ahead of the Bulgarian 7th division by only a day, they were asked to allow a Bulgarian battalion to enter the city. Greece accepted in exchange for allowing a Greek unit to enter the city of Serres.\n\nThe Bulgarian unit that entered Thessaloniki turned out to be a 18,000-strong division instead of the battalion, something which caused concern among the Greeks, who viewed it as a Bulgarian attempt to establish a condominium over the city. In the event, due to the urgently needed reinforcements in the Thracian front, Bulgarian Headquarters was soon forced to remove its troops from the city (while the Greeks agreed by mutual treaty to remove their units based in Serres) and transport them to Dedeağaç (modern Alexandroupolis), but still it left behind a battalion that started fortifying its positions.\n\nGreece had also allowed the Bulgarians to control the stretch of the Thessaloniki-Constantinople railroad that lay in Greek-occupied territory, since Bulgaria controlled the largest part of this railroad towards Thrace. After the end of the operations in Thrace—and confirming Greek concerns—Bulgaria was not satisfied with the territory it controlled in Macedonia and immediately asked Greece to relinquish its control over Thessaloniki and the land north of Pieria, effectively handing over all Aegean Macedonia. These unacceptable demands, together with the Bulgarian refusal to demobilize its army after the Treaty of London had ended the common war against the Ottomans, alarmed Greece, which decided to also maintain its army's mobilization.\n\nSimilarly, in northern Macedonia, the tension between Serbia and Bulgaria due to later aspirations over Vardar Macedonia generated many incidents between the nearby armies, prompting Serbia to maintain its army's mobilization. Serbia and Greece proposed that each of the three countries reduce its army by one fourth, as a first step to facilitate a peaceful solution, but Bulgaria rejected it. Seeing the omens, Greece and Serbia started a series of negotiations and signed a treaty on 1 June(19 May) 1913. With this treaty, a mutual border was agreed between the two countries, together with an agreement for mutual military and diplomatic support in case of a Bulgarian or/and Austro-Hungarian attack. Tsar Nicholas II of Russia, being well informed, tried to stop the upcoming conflict on 8 June, by sending an identical personal message to the Kings of Bulgaria and Serbia, offering to act as arbitrator according to the provisions of the 1912 Serbo-Bulgarian treaty. But Bulgaria, by making the acceptance of Russian arbitration conditional, in effect denied any discussion and caused Russia to repudiate its alliance with Bulgaria (see Russo-Bulgarian military convention signed 31 May 1902).\n\nThe Serbs and the Greeks had a military advantage on the eve of the war because their armies confronted comparatively weak Ottoman forces in the First Balkan War and suffered relatively light casualties, while the Bulgarians were involved in heavy fighting in Thrace. The Serbs and Greeks had time to fortify their positions in Macedonia. The Bulgarians also held some advantages, controlling internal communication and supply lines.\n\nOn 29(16) June 1913, General Savov, under direct orders of Tsar Ferdinand I, issued attacking orders against both Greece and Serbia without consulting the Bulgarian government and without any official declaration of war. During the night of 30(17) June 1913, they attacked the Serbian army at Bregalnica river and then the Greek army in Nigrita. The Serbian army resisted the sudden night attack, while most of soldiers did not even know who they were fighting with, as Bulgarian camps were located next to Serbs and were considered allies. Montenegro's forces were just a few kilometers away and also rushed to the battle. The Bulgarian attack was halted.\n\nThe Greek army was also successful. It retreated according to plan for two days while Thessaloniki was cleared of the remaining Bulgarian regiment. Then, the Greek army counter-attacked and defeated the Bulgarians at Kilkis (Kukush), after which the mostly Bulgarian town was destroyed and its population expelled. Following the capture of Kilkis, the Greek army's pace was not quick enough to prevent the destruction of Nigrita, Serres, and Doxato and massacres of non-combatant Greek inhabitants at Sidirokastro and Doxato by the Bulgarian army. The Greek army then divided its forces and advanced in two directions. Part proceeded east and occupied Western Thrace. The rest of the Greek army advanced up to the Struma River valley, defeating the Bulgarian army in the battles of Doiran and Mt. Beles, and continued its advance to the north towards Sofia. In the Kresna straits, the Greeks were ambushed by the Bulgarian 2nd and 1st Army newly arrived from the Serbian front that had already taken defensive positions there following the Bulgarian victory at Kalimanci.\n\nBy 30 July, the Greek army was outnumbered by the counter-attacking Bulgarian army, which attempted to encircle the Greeks in a Cannae-type battle, by applying pressure on their flanks. The Greek army was exhausted and faced logistical difficulties. The battle was continued for 11 days, between 29 July and 9 August over 20 km of a maze of forests and mountains with no conclusion. The Greek King, seeing that the units he fought were from the Serbian front, tried to convince the Serbs to renew their attack, as the front ahead of them was now thinner, but the Serbs rejected it. By then, news came of the Romanian advance toward Sofia and its imminent fall. Facing the danger of encirclement, Constantine realized that his army could no longer continue hostilities, agreed to Eleftherios Venizelos' proposal and accepted the Bulgarian request for armistice as this had been communicated through Romania.\n\nRomania had raised an army and declared war on Bulgaria on 10 July(27 June) as it had from 28(15) June officially warned Bulgaria that it would not remain neutral in a new Balkan war, due to Bulgaria's refusal to cede the fortress of Silistra as promised before the First Balkan war in exchange for Romanian neutrality. Its forces encountered little resistance and by the time the Greeks accepted the Bulgarian request for armistice they had reached Vrazhdebna, 7 miles from the center of Sofia.\n\nSeeing the military position of the Bulgarian army the Ottomans decided to intervene. They attacked and finding no opposition, managed to recover eastern Thrace with its fortified city of Adrianople, regaining an area in Europe which was only slightly larger than the present-day European territory of the Republic of Turkey.\n\nThe developments that led to the First Balkan War did not go unnoticed by the Great Powers, but although there was an official consensus between the European Powers over the territorial integrity of the Ottoman Empire, which led to a stern warning to the Balkan states, unofficially each of them took a different diplomatic approach due to their conflicting interests in the area. As a result, any possible preventive effect of the common official warning was cancelled by the mixed unofficial signals, and failed to prevent or to stop the war:\n\n\nThe Second Balkan war was a catastrophic blow to Russian policies in the Balkans, which for centuries had focused on access to the \"warm seas\". First, it marked the end of the Balkan League, a vital arm of the Russian system of defense against Austria-Hungary. Second, the clearly pro-Serbian position Russia had been forced to take in the conflict, mainly due to Bulgaria's uncompromising aggressiveness, caused a permanent break-up between the two countries. Accordingly, Bulgaria reverted its policy to one closer to the Central Powers' understanding over an anti-Serbian front, due to its new national aspirations, now expressed mainly against Serbia. As a result, Serbia was isolated militarily against its rival Austria-Hungary, a development that eventually doomed Serbia in the coming war a year later. But, most damaging, the new situation effectively trapped Russian foreign policy: After 1913, Russia could not afford losing its last ally in this crucial area and thus had no alternatives but to unconditionally support Serbia when the crisis between Serbia and Austria broke out in 1914. This was a position that inevitably drew her, although unwillingly, into a World War with devastating results for her, since she was less prepared (both militarily and socially) for that event than any other Great Power.\n\nAustria-Hungary took alarm at the great increase in Serbia's territory at the expense of its national aspirations in the region, as well as Serbia's rising status, especially to Austria-Hungary's Slavic populations. This concern was shared by Germany, which saw Serbia as a satellite of Russia. This contributed significantly to the two Central Powers' willingness to go to war as soon as possible.\n\nFinally, when a Serbian backed organization assassinated the heir of the Austro-Hungarian throne, causing the 1914 July Crisis, nobody could stop the conflict and the First World War broke out.\n\nSoviet demographer Boris Urlanis estimated in \"Voini I Narodo-Nacelenie Europi\" (1960) that in the first and second Balkan wars there were 122,000 killed in action, 20,000 dead of wounds, and 82,000 dead of disease.\n\n\nSince the area has been referred to as the Balkans, notable conflicts have included the following:\n\n\n"}
{"id": "4824", "url": "https://en.wikipedia.org/wiki?curid=4824", "title": "Buffalo", "text": "Buffalo\n\nBuffalo (or buffaloe) primarily refers to:\nBuffalo (or buffaloe) may also refer to:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "4825", "url": "https://en.wikipedia.org/wiki?curid=4825", "title": "BeBox", "text": "BeBox\n\nThe BeBox is a dual CPU personal computer, briefly sold by Be Inc. to run the company's own operating system, BeOS. Notable aspects of the system include its CPU configuration, I/O board with \"GeekPort\", and \"Blinkenlights\" on the front bezel.\n\nThe BeBox made its debut in October 1995 (BeBox Dual603-66). The processors were upgraded to 133 MHz in August 1996 (BeBox Dual603e-133). Production was halted in January 1997, following the port of BeOS to the Macintosh, in order for the company to concentrate on software. Be sold around a thousand 66 MHz BeBoxes and 800 133 MHz BeBoxes.\n\nBeBox creator Jean-Louis Gassée did not see the BeBox as a general consumer device, warning that \"Before we let you use the BeBox, we believe you must have some aptitude toward programming - the standard language is C++.\" The BeBox's more unique features included preemptive multitasking and built-in networking.\n\nInitial prototypes are equipped with two AT&T Hobbit processors and three AT&T 9308S DSPs.\n\nProduction models use two PowerPC 603 processors running at 66 or 133 MHz to power the BeBox. Prototypes having dual 200 MHz CPUs or four CPUs exist, but these were never publicly available.\n\n\nTwo yellow/green vertical LED arrays, dubbed the \"blinkenlights\", are built into the front bezel to illustrate the CPU load. The bottommost LED on the right side indicates hard disk activity.\n\n\n"}
{"id": "4827", "url": "https://en.wikipedia.org/wiki?curid=4827", "title": "Biomedical engineering", "text": "Biomedical engineering\n\nBiomedical engineering (BME) is the application of engineering principles and design concepts to medicine and biology for healthcare purposes (e.g. diagnostic or therapeutic). This field seeks to close the gap between engineering and medicine, combining the design and problem solving skills of engineering with medical biological sciences to advance health care treatment, including diagnosis, monitoring, and therapy.\nBiomedical engineering has only recently emerged as its own study, as compared to many other engineering fields. Such an evolution is common as a new field transitions from being an interdisciplinary specialization among already-established fields, to being considered a field in itself. Much of the work in biomedical engineering consists of research and development, spanning a broad array of subfields (see below). Prominent biomedical engineering applications include the development of biocompatible prostheses, various diagnostic and therapeutic medical devices ranging from clinical equipment to micro-implants, common imaging equipment such as MRIs and EEGs, regenerative tissue growth, pharmaceutical drugs and therapeutic biologicals.\n\nBioinformatics is an interdisciplinary field that develops methods and software tools for understanding biological data. As an interdisciplinary field of science, bioinformatics combines computer science, statistics, mathematics, and engineering to analyze and interpret biological data.\n\nBioinformatics is both an umbrella term for the body of biological studies that use computer programming as part of their methodology, as well as a reference to specific analysis \"pipelines\" that are repeatedly used, particularly in the field of genomics. Common uses of bioinformatics include the identification of candidate genes and nucleotides (SNPs). Often, such identification is made with the aim of better understanding the genetic basis of disease, unique adaptations, desirable properties (esp. in agricultural species), or differences between populations. In a less formal way, bioinformatics also tries to understand the organisational principles within nucleic acid and protein sequences.\n\nSee Biomechanics.\n\nA biomaterial is any matter, surface, or construct that interacts with living systems. As a science, biomaterials is about fifty years old. The study of biomaterials is called biomaterials science or biomaterials engineering. It has experienced steady and strong growth over its history, with many companies investing large amounts of money into the development of new products. Biomaterials science encompasses elements of medicine, biology, chemistry, tissue engineering and materials science.\n\nTissue engineering, like genetic engineering (see below), is a major segment of biotechnology - which overlaps significantly with BME.\n\nOne of the goals of tissue engineering is to create artificial organs (via biological material) for patients that need organ transplants. Biomedical engineers are currently researching methods of creating such organs. Researchers have grown solid jawbones and tracheas from human stem cells towards this end. Several artificial urinary bladders have been grown in laboratories and transplanted successfully into human patients. Bioartificial organs, which use both synthetic and biological component, are also a focus area in research, such as with hepatic assist devices that use liver cells within an artificial bioreactor construct.\n\nGenetic engineering, recombinant DNA technology, genetic modification/manipulation (GM) and gene splicing are terms that apply to the direct manipulation of an organism's genes. Unlike traditional breeding, an indirect method of genetic manipulation, genetic engineering utilizes modern tools such as molecular cloning and transformation to directly alter the structure and characteristics of target genes. Genetic engineering techniques have found success in numerous applications. Some examples include the improvement of crop technology (\"not a medical application\", but see biological systems engineering), the manufacture of synthetic human insulin through the use of modified bacteria, the manufacture of erythropoietin in hamster ovary cells, and the production of new types of experimental mice such as the oncomouse (cancer mouse) for research.\n\nNeural engineering (also known as neuroengineering) is a discipline that uses engineering techniques to understand, repair, replace, or enhance neural systems. Neural engineers are uniquely qualified to solve design problems at the interface of living neural tissue and non-living constructs.\n\nPharmaceutical engineering is an interdisciplinary science that includes drug engineering, novel drug delivery and targeting, pharmaceutical technology, unit operations of Chemical Engineering, and Pharmaceutical Analysis. It may be deemed as a part of pharmacy due to its focus on the use of technology on chemical agents in providing better medicinal treatment. The ISPE is an international body that certifies this now rapidly emerging interdisciplinary science.\n\nThis is an \"extremely broad category\"—essentially covering all health care products that do not achieve their intended results through predominantly chemical (e.g., pharmaceuticals) or biological (e.g., vaccines) means, and do not involve metabolism.\n\nA medical device is intended for use in:\n\nSome examples include pacemakers, infusion pumps, the heart-lung machine, dialysis machines, artificial organs, implants, artificial limbs, corrective lenses, cochlear implants, ocular prosthetics, facial prosthetics, somato prosthetics, and dental implants.\nStereolithography is a practical example of \"medical modeling\" being used to create physical objects. Beyond modeling organs and the human body, emerging engineering techniques are also currently used in the research and development of new devices for innovative therapies, treatments, patient monitoring, of complex diseases.\n\nMedical devices are regulated and classified (in the US) as follows (see also \"Regulation\"):\n\n\nMedical/biomedical imaging is a major segment of medical devices. This area deals with enabling clinicians to directly or indirectly \"view\" things not visible in plain sight (such as due to their size, and/or location). This can involve utilizing ultrasound, magnetism, UV, radiology, and other means.\n\nImaging technologies are often essential to medical diagnosis, and are typically the most complex equipment found in a hospital including: fluoroscopy, magnetic resonance imaging (MRI), nuclear medicine, positron emission tomography (PET), PET-CT scans, projection radiography such as X-rays and CT scans, tomography, ultrasound, optical microscopy, and electron microscopy.\n\nAn implant is a kind of medical device made to replace and act as a missing biological structure (as compared with a transplant, which indicates transplanted biomedical tissue). The surface of implants that contact the body might be made of a biomedical material such as titanium, silicone or apatite depending on what is the most functional. In some cases, implants contain electronics, e.g. artificial pacemakers and cochlear implants. Some implants are bioactive, such as subcutaneous drug delivery devices in the form of implantable pills or drug-eluting stents.\n\nArtificial body part replacements are one of the many applications of bionics. Concerned with the intricate and thorough study of the properties and function of human body systems, bionics may be applied to solve some engineering problems. Careful study of the different functions and processes of the eyes, ears, and other organs paved the way for improved cameras, television, radio transmitters and receivers, and many other useful tools. These developments have indeed made our lives better, but the best contribution that bionics has made is in the field of biomedical engineering (the building of useful replacements for various parts of the human body). Modern hospitals now have available spare parts to replace body parts badly damaged by injury or disease [Citation Needed]. Biomedical engineers work hand in hand with doctors to build these artificial body parts.\n\nClinical engineering is the branch of biomedical engineering dealing with the actual implementation of medical equipment and technologies in hospitals or other clinical settings. Major roles of clinical engineers include training and supervising biomedical equipment technicians (BMETs), selecting technological products/services and logistically managing their implementation, working with governmental regulators on inspections/audits, and serving as technological consultants for other hospital staff (e.g. physicians, administrators, I.T., etc.). Clinical engineers also advise and collaborate with medical device producers regarding prospective design improvements based on clinical experiences, as well as monitor the progression of the state of the art so as to redirect procurement patterns accordingly.\n\nTheir inherent focus on \"practical\" implementation of technology has tended to keep them oriented more towards \"incremental\"-level redesigns and reconfigurations, as opposed to revolutionary research & development or ideas that would be many years from clinical adoption; however, there is a growing effort to expand this time-horizon over which clinical engineers can influence the trajectory of biomedical innovation. In their various roles, they form a \"bridge\" between the primary designers and the end-users, by combining the perspectives of being both 1) close to the point-of-use, while 2) trained in product and process engineering. Clinical engineering departments will sometimes hire not just biomedical engineers, but also industrial/systems engineers to help address operations research/optimization, human factors, cost analysis, etc. Also see safety engineering for a discussion of the procedures used to design safe systems.\n\nRehabilitation engineering is the systematic application of engineering sciences to design, develop, adapt, test, evaluate, apply, and distribute technological solutions to problems confronted by individuals with disabilities. Functional areas addressed through rehabilitation engineering may include mobility, communications, hearing, vision, and cognition, and activities associated with employment, independent living, education, and integration into the community.\n\nWhile some rehabilitation engineers have master's degrees in rehabilitation engineering, usually a subspecialty of Biomedical engineering, most rehabilitation engineers have undergraduate or graduate degrees in biomedical engineering, mechanical engineering, or electrical engineering. A Portuguese university provides an undergraduate degree and a master's degree in Rehabilitation Engineering and Accessibility. Qualification to become a Rehab' Engineer in the UK is possible via a University BSc Honours Degree course such as Health Design & Technology Institute, Coventry University.\n\nThe rehabilitation process for people with disabilities often entails the design of assistive devices such as Walking aids intended to promote inclusion of their users into the mainstream of society, commerce, and recreation.\n\nRegulatory issues have been constantly increased in the last decades to respond to the many incidents caused by devices to patients. For example, from 2008 to 2011, in US, there were 119 FDA recalls of medical devices classified as class I. According to U.S. Food and Drug Administration (FDA), Class I recall is associated to \"a situation in which there is a reasonable probability that the use of, or exposure to, a product will cause serious adverse health consequences or death\" \n\nRegardless of the country-specific legislation, the main regulatory objectives coincide worldwide. For example, in the medical device regulations, a product must be: 1) safe \"and\" 2) effective and 3) for all the manufactured devices\n\nA product is safe if patients, users and third parties do not run unacceptable risks of physical hazards (death, injuries, …) in its intended use. Protective measures have to be introduced on the devices to reduce residual risks at acceptable level if compared with the benefit derived from the use of it.\n\nA product is effective if it performs as specified by the manufacturer in the intended use. Effectiveness is achieved through clinical evaluation, compliance to performance standards or demonstrations of substantial equivalence with an already marketed device.\n\nThe previous features have to be ensured for all the manufactured items of the medical device. This requires that a quality system shall be in place for all the relevant entities and processes that may impact safety and effectiveness over the whole medical device lifecycle.\n\nThe medical device engineering area is among the most heavily regulated fields of engineering, and practicing biomedical engineers must routinely consult and cooperate with regulatory law attorneys and other experts. The Food and Drug Administration (FDA) is the principal healthcare regulatory authority in the United States, having jurisdiction over medical \"devices, drugs, biologics, and combination\" products. The paramount objectives driving policy decisions by the FDA are safety and effectiveness of healthcare products that have to be assured through a quality system in place as specified under 21 CFR 829 regulation. In addition, because biomedical engineers often develop devices and technologies for \"consumer\" use, such as physical therapy devices (which are also \"medical\" devices), these may also be governed in some respects by the Consumer Product Safety Commission. The greatest hurdles tend to be 510K \"clearance\" (typically for Class 2 devices) or pre-market \"approval\" (typically for drugs and class 3 devices).\n\nIn the European context, safety effectiveness and quality is ensured through the \"Conformity Assessment\" that is defined as \"the method by which a manufacturer demonstrates that its device complies with the requirements of the European Medical Device Directive\". The directive specifies different procedures according to the class of the device ranging from the simple Declaration of Conformity (Annex VII) for Class I devices to EC verification (Annex IV), Production quality assurance (Annex V), Product quality assurance (Annex VI) and Full quality assurance (Annex II). The Medical Device Directive specifies detailed procedures for Certification. In general terms, these procedures include tests and verifications that are to be contained in specific deliveries such as the risk management file, the technical file and the quality system deliveries. The risk management file is the first deliverable that conditions the following design and manufacturing steps. Risk management stage shall drive the product so that product risks are reduced at an acceptable level with respect to the benefits expected for the patients for the use of the device. The technical file contains all the documentation data and records supporting medical device certification. FDA technical file has similar content although organized in different structure. The Quality System deliverables usually includes procedures that ensure quality throughout all product life cycle. The same standard (ISO EN 13485) is usually applied for quality management systems in US and worldwide.\n\nIn the European Union, there are certifying entities named \"Notified Bodies\", accredited by European Member States. The Notified Bodies must ensure the effectiveness of the certification process for all medical devices apart from the class I devices where a declaration of conformity produced by the manufacturer is sufficient for marketing. Once a product has passed all the steps required by the Medical Device Directive, the device is entitled to bear a CE marking, indicating that the device is believed to be safe and effective when used as intended, and, therefore, it can be marketed within the European Union area.\n\nThe different regulatory arrangements sometimes result in particular technologies being developed first for either the U.S. or in Europe depending on the more favorable form of regulation. While nations often strive for substantive harmony to facilitate cross-national distribution, philosophical differences about the \"optimal extent\" of regulation can be a hindrance; more restrictive regulations seem appealing on an intuitive level, but critics decry the tradeoff cost in terms of slowing access to life-saving developments.\n\nDirective 2011/65/EU, better known as RoHS 2 is a recast of legislation originally introduced in 2002. The original EU legislation \"Restrictions of Certain Hazardous Substances in Electrical and Electronics Devices\" (RoHS Directive 2002/95/EC) was replaced and superseded by 2011/65/EU published in July 2011 and commonly known as RoHS 2.\nRoHS seeks to limit the dangerous substances in circulation in electronics products, in particular toxins and heavy metals, which are subsequently released into the environment when such devices are recycled.\n\nThe scope of RoHS 2 is widened to include products previously excluded, such as medical devices and industrial equipment. In addition, manufacturers are now obliged to provide conformity risk assessments and test reports – or explain why they are lacking. For the first time, not only manufacturers, but also importers and distributors share a responsibility to ensure Electrical and Electronic Equipment within the scope of RoHS comply with the hazardous substances limits and have a CE mark on their products.\n\nThe new International Standard IEC 60601 for home healthcare electro-medical devices defining the requirements for devices used in the home healthcare environment. IEC 60601-1-11 (2010) must now be incorporated into the design and verification of a wide range of home use and point of care medical devices along with other applicable standards in the IEC 60601 3rd edition series.\n\nThe mandatory date for implementation of the EN European version of the standard is June 1, 2013. The US FDA requires the use of the standard on June 30, 2013, while Health Canada recently extended the required date from June 2012 to April 2013. The North American agencies will only require these standards for new device submissions, while the EU will take the more severe approach of requiring all applicable devices being placed on the market to consider the home healthcare standard.\n\nAS/ANS 3551:2012 is the Australian and New Zealand standards for the management of medical devices. The standard specifies the procedures required to maintain a wide range of medical assets in a clinical setting (e.g. Hospital). The standards are based on the IEC 606101 standards.\n\nThe standard covers a wide range of medical equipment management elements including, procurement, acceptance testing, maintenance (electrical safety and preventative maintenance testing) and decommissioning.\n\nBiomedical engineers require considerable knowledge of both engineering and biology, and typically have a Bachelor's (B.Tech, B.S) or Master's (M.S., M.Tech, M.S.E., or M.Eng.) or a Doctoral (Ph.D.) degree in BME (Biomedical Engineering) or another branch of engineering with considerable potential for BME overlap. As interest in BME increases, many engineering colleges now have a Biomedical Engineering Department or Program, with offerings ranging from the undergraduate (B.Tech, B.S., B.Eng or B.S.E.) to doctoral levels. Biomedical engineering has only recently been emerging as \"its own discipline\" rather than a cross-disciplinary hybrid specialization of other disciplines; and BME programs at all levels are becoming more widespread, including the Bachelor of Science in Biomedical Engineering which actually includes so much biological science content that many students use it as a \"pre-med\" major in preparation for medical school. The number of biomedical engineers is expected to rise as both a cause and effect of improvements in medical technology.\n\nIn the U.S., an increasing number of undergraduate programs are also becoming recognized by ABET as accredited bioengineering/biomedical engineering programs. Over 65 programs are currently accredited by ABET.\n\nIn Canada and Australia, accredited graduate programs in Biomedical Engineering are common, for example in Universities such as McMaster University, and the first Canadian undergraduate BME program at Ryerson University offering a four-year B.Eng program. The Polytechnique in Montreal is also offering a bachelors's degree in biomedical engineering.\n\nAs with many degrees, the reputation and ranking of a program may factor into the desirability of a degree holder for either employment or graduate admission. The reputation of many undergraduate degrees are also linked to the institution's graduate or research programs, which have some tangible factors for rating, such as research funding and volume, publications and citations. With BME specifically, the ranking of a university's hospital and medical school can also be a significant factor in the perceived prestige of its BME department/program.\n\nGraduate education is a particularly important aspect in BME. While many engineering fields (such as mechanical or electrical engineering) do not need graduate-level training to obtain an entry-level job in their field, the majority of BME positions do prefer or even require them. Since most BME-related professions involve scientific research, such as in pharmaceutical and medical device development, graduate education is almost a requirement (as undergraduate degrees typically do not involve sufficient research training and experience). This can be either a Masters or Doctoral level degree; while in certain specialties a Ph.D. is notably more common than in others, it is hardly ever the majority (except in academia). In fact, the perceived need for some kind of graduate credential is so strong that some undergraduate BME programs will actively discourage students from majoring in BME without an expressed intention to also obtain a master's degree or apply to medical school afterwards.\n\nGraduate programs in BME, like in other scientific fields, are highly varied, and particular programs may emphasize certain aspects within the field. They may also feature extensive collaborative efforts with programs in other fields (such as the University's Medical School or other engineering divisions), owing again to the interdisciplinary nature of BME. M.S. and Ph.D. programs will typically require applicants to have an undergraduate degree in BME, or \"another engineering\" discipline (plus certain life science coursework), or \"life science\" (plus certain engineering coursework).\n\nEducation in BME also varies greatly around the world. By virtue of its extensive biotechnology sector, its numerous major universities, and relatively few internal barriers, the U.S. has progressed a great deal in its development of BME education and training opportunities. Europe, which also has a large biotechnology sector and an impressive education system, has encountered trouble in creating uniform standards as the European community attempts to supplant some of the national jurisdictional barriers that still exist. Recently, initiatives such as BIOMEDEA have sprung up to develop BME-related education and professional standards. Other countries, such as Australia, are recognizing and moving to correct deficiencies in their BME education. Also, as high technology endeavors are usually marks of developed nations, some areas of the world are prone to slower development in education, including in BME.\n\nEngineering licensure in the US is largely optional, and rarely specified by branch/discipline. As with other learned professions, each state has certain (fairly similar) requirements for becoming licensed as a registered Professional Engineer (PE), but in practice such a license is not required to practice in the majority of situations (due to an exception known as the private industry exemption, which effectively applies to the vast majority of American engineers). This is notably not the case in many other countries, where a license is as legally necessary to practice engineering as it is for law or medicine.\n\nBiomedical engineering is regulated in some countries, such as Australia, but registration is typically only recommended and not required.\n\nIn the UK, mechanical engineers working in the areas of Medical Engineering, Bioengineering or Biomedical engineering can gain Chartered Engineer status through the Institution of Mechanical Engineers. The Institution also runs the Engineering in Medicine and Health Division. The Institute of Physics and Engineering in Medicine (IPEM) has a panel for the accreditation of MSc courses in Biomedical Engineering and Chartered Engineering status can also be sought through IPEM.\n\nThe Fundamentals of Engineering exam – the first (and more general) of two licensure examinations for most U.S. jurisdictions—does now cover biology (although technically not BME). For the second exam, called the Principles and Practices, Part 2, or the Professional Engineering exam, candidates may select a particular engineering discipline's content to be tested on; there is currently not an option for BME with this, meaning that any biomedical engineers seeking a license must prepare to take this examination in another category (which does not affect the actual license, since most jurisdictions do not recognize discipline specialties anyway). However, the Biomedical Engineering Society (BMES) is, as of 2009, exploring the possibility of seeking to implement a BME-specific version of this exam to facilitate biomedical engineers pursuing licensure.\n\nBeyond governmental registration, certain private-sector professional/industrial organizations also offer certifications with varying degrees of prominence. One such example is the Certified Clinical Engineer (CCE) certification for Clinical engineers.\n\nIn 2012 there were about 19,400 biomedical engineers employed in the US, and the field was predicted to grow by 27% (much faster than average) from 2012-2022. Biomedical engineering has the highest percentage of women engineers compared to other common engineering professions.\n\n\n\n\n"}
{"id": "4829", "url": "https://en.wikipedia.org/wiki?curid=4829", "title": "Balkans", "text": "Balkans\n\nThe Balkans, or the Balkan Peninsula, is a cultural area in Eastern and Southeastern Europe with various and disputed borders. The region takes its name from the Balkan Mountains that stretch from the Serbian-Bulgarian border to the Black Sea.\n\nThe Balkan Peninsula is bordered by the Adriatic Sea on the northwest, the Ionian Sea on the southwest, the Mediterranean and Aegean Sea on the south and southeast, and the Black Sea on the east and northeast. The northern border of the peninsula is variously defined. The highest point of the Balkans is Mount Musala in the Rila mountain range.\n\nIn Turkish, Balkan means \"a chain of wooded mountains\" (\"\"), Another possibility to its etymology is related to Persian \"bālk\" meaning \"mud\", and the Turkish suffix \"an\", i.e. \"swampy forest\". A less popular hypothesis regarding its etymology is that it derived from the Persian \"Balā-Khāna\", meaning \"big high house\".\n\nFrom classical antiquity through the Middle Ages, the Balkan Mountains had been called by the local Thracian name \"Haemus\". According to Greek mythology, the Thracian king Haemus was turned into a mountain by Zeus as a punishment and the mountain has remained with his name. A reverse name scheme has also been suggested. D. Dechev considers that Haemus (Αἷμος) is derived from a Thracian word \"*saimon\", 'mountain ridge'. A third possibility is that \"Haemus\" () derives from the Greek word \"haema\" () meaning 'blood'. The myth relates to a fight between Zeus and the monster/titan Typhon. Zeus injured Typhon with a thunder bolt and Typhon's blood fell on the mountains, from which they got their name.\n\nThe earliest mention of the name appears in an early 14th-century Arab map, in which the Haemus mountains are referred to as \"Balkan\". The first attested time the name \"Balkan\" was used in the West for the mountain range in Bulgaria was in a letter sent in 1490 to Pope Innocent VIII by Buonaccorsi Callimaco, an Italian humanist, writer and diplomat. The Ottomans first mention it in a document dated from 1565. There has been no other documented usage of the word to refer to the region before that, although other Turkic tribes had already settled in or were passing through the Peninsula. There is also a claim about an earlier Bulgar Turkic origin of the word popular in Bulgaria, however it is only an unscholarly assertion. The word was used by the Ottomans in Rumelia in its general meaning of mountain, as in \"Kod̲j̲a-Balkan\", \"Čatal-Balkan\", and \"Ungurus-Balkani̊\", but especially it was applied to the Haemus mountain. The name is still preserved in Central Asia with the Balkan Daglary (Balkan Mountains) and the Balkan Province of Turkmenistan. English traveler John Morritt introduced this term into the English literature at the end of the 18th-century, and other authors started applying the name to the wider area between the Adriatic and the Black Sea. The concept of the \"Balkans\" was created by the German geographer August Zeune in 1808. During the 1820s, \"Balkan became the preferred although not yet exclusive term alongside Haemus among British travelers... Among Russian travelers not so burdened by classical toponymy, Balkan was the preferred term.\"\n\nAs time passed, the term gradually acquired political connotations far from its initial geographic meaning, arising from political changes from the late 19th-century to the creation of post–World War I Yugoslavia (initially the Kingdom of Serbs, Croats and Slovenes). Zeune's goal was to have a geographical parallel term to the Italic and Iberian Peninsula, and seemingly nothing more. The gradually acquired political connotations are newer and, to a large extent, due to oscillating political circumstances.\n\nAfter the dissolution of Yugoslavia beginning in June 1991, the term \"Balkans\" again received a negative meaning, especially in Croatia and Slovenia, even in casual usage (see Balkanization).\n\nIn part due to the historical and political connotations of the term \"Balkans\", especially since the military conflicts of the 1990s, the term \"Southeast Europe\" is becoming increasingly popular even though it literally refers to a much larger area and thus isn't as precise. A European Union initiative of 1999 is called the \"Stability Pact for South Eastern Europe\", and the online newspaper \"Balkan Times\" renamed itself \"Southeast European Times\" in 2003.\n\nIn the languages of the region, the peninsula is known as:\n\nThe Balkan Peninsula is surrounded by the Adriatic Sea to the west, the Mediterranean Sea (including the Ionian and Aegean seas) and the Marmara Sea to the south and the Black Sea to the east. Its northern boundary is often given as the Danube, Sava and Kupa Rivers. The Balkan Peninsula has a combined area of about (slightly smaller than Spain). It is more or less identical to the region known as Southeastern Europe.\n\nFrom 1920 until World War II, Italy included Istria and some Dalmatian areas (like \"Zara\", known as Zadar) that are within the general definition of the Balkan peninsula. The current territory of Italy includes only the small area around Trieste inside the Balkan Peninsula. However, the regions of Trieste and Istria are not usually considered part of the Balkans by Italian geographers, due to a definition of the Balkans that limits its western border to the Kupa River.\n\nShare of land area within the Balkan Peninsula by country by the Danube-Sava definition:\n\nEntirely within the Balkans:\n\n\nMostly or partially within the Balkans:\n\n\nThe abstract term \"The Balkans\", unlike the geographical borders of the Peninsula, is defined by the political borders of the states composing it. The term is used to describe areas beyond the Balkan Peninsula, or inversely in the case of the part of Italy in the Peninsula, which is always excluded from the Balkans and as a totality is generally accepted as part of Western Europe and the Apennines.\n\nAccording to the \"Encyclopædia Britannica\", the Balkans are usually said to comprise Albania, Bosnia and Herzegovina, Bulgaria, Croatia, Kosovo, the Republic of Macedonia, Montenegro, Romania, Serbia, Slovenia, while Greece and Turkey are often included (depending on the definition), and its total area is usually given as 666,700 square km (257,400 square miles) and the population as 59,297,000 (est. 2002).\n\nAccording to an earlier version of the \"Britannica\", the Balkans comprise the territories of the states of Albania, Bosnia and Herzegovina, Bulgaria, Croatia, Greece, Kosovo, the Republic of Macedonia, Montenegro, Romania, Serbia, Slovenia and the European part of Turkey; it notes Turkey as a non-Balkan state and the inclusion of Slovenia and the Transylvanian part of Romania in the region as dubious.\n\nInclusion of Balkan states in other regions:\n\nThe institutions of the European Union have defined the \"Western Balkans\" as the south-east European area that includes countries that are not members of the European Union, while others refer to the geographical aspects.\n\nMost of the area is covered by mountain ranges running from the northwest to southeast. The main ranges are the Balkan mountains, running from the Black Sea coast in Bulgaria to its border with Serbia, the Rhodope mountains in southern Bulgaria and northern Greece, the Dinaric Alps in Bosnia and Herzegovina, Croatia and Montenegro, the Šar massif which spreads from Albania to Macedonia, and the Pindus range, spanning from southern Albania into central Greece and the Albanian Alps. The highest mountain of the region is Rila in Bulgaria, with Musala at 2925 m, Mount Olympus in Greece, the throne of Zeus, being second at 2917 m and Vihren in Bulgaria being the third at 2914 m. The karst field or polje is a common feature of the landscape.\n\nOn the Adriatic and Aegean coasts the climate is Mediterranean, on the Black Sea coast the climate is humid subtropical and oceanic, and inland it is humid continental. In the northern part of the peninsula and on the mountains, winters are frosty and snowy, while summers are hot and dry. In the southern part winters are milder. The humid continental climate is predominant in Bosnia and Herzegovina, northern Croatia, Bulgaria, Kosovo, Macedonia, northern Montenegro, the interior of Albania and Serbia, while the other, less common climates, the humid subtropical and oceanic climates, are seen on the Black Sea coast of Bulgaria and Turkey; and the Mediterranean climate is seen on the coast of Albania, the coast of Croatia, Greece, southern Montenegro and the Aegean coast of Turkey.\n\nOver the centuries many woods have been cut down and replaced with bush. In the southern part and on the coast there is evergreen vegetation. Inland there are woods typical of Central Europe (oak and beech, and in the mountains, spruce, fir and pine). The tree line in the mountains lies at the height of 1800–2300 m. The land provides habitats for numerous endemic species, including extraordinarily abundant insects and reptiles that serve as food for a variety of birds of prey and rare vultures.\n\nThe soils are generally poor, except on the plains, where areas with natural grass, fertile soils and warm summers provide an opportunity for tillage. Elsewhere, land cultivation is mostly unsuccessful because of the mountains, hot summers and poor soils, although certain cultures such as olive and grape flourish.\n\nResources of energy are scarce, except in the territory of Kosovo, where considerable coal, lead, zinc, chromium and silver deposits are located. Other deposits of coal, especially in Bulgaria, Serbia and Bosnia, also exist. Lignite deposits are widespread in Greece. Petroleum scarce reserves exist in Greece, Serbia and Albania. Natural gas deposits are scarce. Hydropower is in wide use, from over 1,000 dams. The often relentless bora wind is also being harnessed for power generation.\n\nMetal ores are more usual than other raw materials. Iron ore is rare, but in some countries there is a considerable amount of copper, zinc, tin, chromite, manganese, magnesite and bauxite. Some metals are exported.\n\nThe Balkan region was the first area in Europe to experience the arrival of farming cultures in the Neolithic era. The Balkans have been inhabited since the Paleolithic and are the route by which farming from the Middle East spread to Europe during the Neolithic (7th millennium BC). The practices of growing grain and raising livestock arrived in the Balkans from the Fertile Crescent by way of Anatolia and spread west and north into Central Europe, particularly through Pannonia. Two early culture-complexes have developed in the region, Starčevo culture and Vinča culture. The Balkans are also the location of the first advanced civilizations. Vinča culture developed a form of proto-writing before the Sumerians and Minoans, known as the Old European script, while the bulk of the symbols had been created in the period between 4500 and 4000 BC, with the ones on the Tărtăria clay tablets even dating back to around 5300 BC.\n\nThe identity of the Balkans is dominated by its geographical position; historically the area was known as a crossroads of cultures. It has been a juncture between the Latin and Greek bodies of the Roman Empire, the destination of a massive influx of pagan Bulgars and Slavs, an area where Orthodox and Catholic Christianity met, as well as the meeting point between Islam and Christianity.\n\nIn pre-classical and classical antiquity, this region was home to Greeks, Illyrians, Paeonians, Thracians, Dacians, and other ancient groups. The Achaemenid Persian Empire incorporated parts of the Balkans comprising Macedonia, Thrace, Bulgaria, and the Black Sea coastal region of Romania between the late 6th and the first half of the 5th-century BC into its territories. Later the Roman Empire conquered most of the region and spread Roman culture and the Latin language, but significant parts still remained under classical Greek influence. The Romans considered the Rhodope Mountains to be the northern limit of the Peninsula of Haemus and the same limit applied approximately to the border between Greek and Latin use in the region (later called the Jireček Line). The Bulgars and Slavs arrived in the 6th-century and began assimilating and displacing already-assimilated (through Romanization and Hellenization) older inhabitants of the northern and central Balkans, forming the Bulgarian Empire. During the Middle Ages, the Balkans became the stage for a series of wars between the Byzantine Roman and the Bulgarian Empires.\n\nBy the end of the 16th-century, the Ottoman Empire had become the controlling force in the region after expanding from Anatolia through Thrace to the Balkans. Many people in the Balkans place their greatest folk heroes in the era of either the onslaught or the retreat of the Ottoman Empire. As examples, for Greeks, Constantine XI Palaiologos and Kolokotronis; and for Serbs, Miloš Obilić and Tzar Lazar; for Montenegrins, Đurađ I Balšić and Ivan Crnojević; for Albanians, George Kastrioti Skanderbeg; for ethnic Macedonians, Nikola Karev and Goce Delčev; for Bulgarians, Vasil Levski, Georgi Sava Rakovski and Hristo Botev and for Croats, Nikola Šubić Zrinjski.\n\nIn the past several centuries, because of the frequent Ottoman wars in Europe fought in and around the Balkans and the comparative Ottoman isolation from the mainstream of economic advance (reflecting the shift of Europe's commercial and political centre of gravity towards the Atlantic), the Balkans has been the least developed part of Europe. According to Halil İnalcık, \"The population of the Balkans, according to one estimate, fell from a high of 8 million in the late 16th-century to only 3 million by the mid-eighteenth. This estimate is in harmony with the first findings based on Ottoman documentary evidence.\"\n\nMost of the Balkan nation-states emerged during the 19th and early 20th centuries as they gained independence from the Ottoman Empire or the Austro-Hungarian empire (Greece in 1821, Serbia, Montenegro in 1878, Bulgaria in 1908, Albania in 1912).\n\nIn 1912–1913 the First Balkan War broke out when the nation-states of Bulgaria, Serbia, Greece and Montenegro united in an alliance against the Ottoman Empire. As a result of the war, almost all remaining European territories of the Ottoman Empire were captured and partitioned among the allies. Ensuing events also led to the creation of an independent Albanian state. Bulgaria insisted on its status quo territorial integrity, divided and shared by the Great Powers next to the Russo-Turkish War (1877–78) in other boundaries and on the pre-war Bulgarian-Serbian agreement. Bulgaria was provoked by the backstage deals between its former allies, Serbia and Greece, on the allocation of the spoils at the end of the First Balkan War. At the time, Bulgaria was fighting at the main Thracian Front. Bulgaria marks the beginning of Second Balkan War when it attacked them. The Serbs and the Greeks repulsed single attacks, but when the Greek army invaded Bulgaria together with an unprovoked Romanian intervention in the back, Bulgaria collapsed. The Ottoman Empire used the opportunity to recapture Eastern Thrace, establishing its new western borders that still stand today as part of modern Turkey.\n\nThe First World War was sparked in the Balkans in 1914 when members of Mlada Bosna, a revolutionary organization with predominately Serbian and pro-Yugoslav members, assassinated the Austro-Hungarian heir Archduke Franz Ferdinand of Austria in Bosnia and Herzegovina's capital, Sarajevo. That caused a war between the two countries which—through the existing chains of alliances—led to the First World War. The Ottoman Empire soon joined the Central Powers becoming one of the three empires participating in that alliance. The next year Bulgaria joined the Central Powers attacking Serbia, which was successfully fighting Austro-Hungary to the north for a year. That led to Serbia's defeat and the intervention of the Entente in the Balkans which sent an expeditionary force to establish a new front, the third one of that war, which soon also became static. The participation of Greece in the war three years later, in 1918, on the part of the Entente finally altered the balance between the opponents leading to the collapse of the common German-Bulgarian front there, which caused the exit of Bulgaria from the war, and in turn the collapse of the Austro-Hungarian Empire, ending the First World War.\n\nWith the start of the Second World War all Balkan countries, with the exception of Greece, were allies of Nazi Germany, having bilateral military agreements or being part of the Axis Pact. Fascist Italy expanded the war in the Balkans by using its protectorate Albania to invade Greece. After repelling the attack, the Greeks counterattacked, invading Italy-held Albania and causing Nazi Germany's intervention in the Balkans to help its ally. Days before the German invasion a successful coup d'état in Belgrade by neutral military personnel seized power.\n\nAlthough the new government reaffirmed Serbia's intentions to fulfill its obligations as member of the Axis, Germany, using its other two allied countries in the region, Bulgaria and Hungary, invaded both Greece and Yugoslavia. Yugoslavia immediately disintegrated when those loyal to the Serbian King and the Croatian units mutinied. Greece resisted, but, after two months of fighting, collapsed and was occupied. The two countries were partitioned between the three Axis allies, Bulgaria, Germany and Italy, and the Independent State of Croatia, a puppet state of Italy and Germany.\n\nDuring the occupation the population suffered considerable hardship due to repression and starvation, to which the population reacted by creating a mass resistance movement. Together with the early and extremely heavy winter of that year (which caused hundreds of thousands deaths among the poorly fed population), the German invasion had disastrous effects in the timetable of the planned invasion in Russia causing a significant delay, which had major consequences during the course of the war.\n\nFinally, at the end of 1944, the Soviets entered Romania and Bulgaria forcing the Germans out of the Balkans. They left behind a region largely ruined as a result of wartime exploitation.\n\nDuring the Cold War, most of the countries on the Balkans were governed by communist governments. Greece became the first battleground of the emerging Cold War. The Truman Doctrine was the US response to the civil war, which raged from 1944 to 1949. This civil war, unleashed by the Communist Party of Greece, backed by communist volunteers from neighboring countries (Albania, Bulgaria and Yugoslavia), led to massive American assistance for the non-communist Greek government. With this backing, Greece managed to defeat the partisans and, ultimately, remained the only non-communist country in the region.\n\nHowever, despite being under communist governments, Yugoslavia (1948) and Albania (1961) fell out with the Soviet Union. Yugoslavia, led by Marshal Josip Broz Tito (1892–1980), first propped up then rejected the idea of merging with Bulgaria and instead sought closer relations with the West, later even spearheaded, together with India and Egypt the Non-Aligned Movement. Albania on the other hand gravitated toward Communist China, later adopting an isolationist position.\n\nAs the only non-communist countries, Greece and Turkey were (and still are) part of NATO composing the southeastern wing of the alliance.\n\nIn the 1990s, the transition of the regions' ex-Soviet bloc countries towards democratic free-market societies went peacefully with the exception of Yugoslavia. Wars between the former Yugoslav republics broke out after Slovenia and Croatia held free elections and their people voted for independence on their respective countries' referenda. Serbia in turn declared the dissolution of the union as unconstitutional and the Yugoslavian army unsuccessfully tried to maintain status quo. Slovenia and Croatia declared independence on 25 June 1991, followed by the Ten-Day War in Slovenia. Till October 1991, the Army withdrew from Slovenia, and in Croatia, the Croatian War of Independence would continue until 1995. In the ensuing 10 years armed confrontation, gradually all the other Republics declared independence, with Bosnia being the most affected by the fighting. The long lasting wars resulted in a United Nations intervention and NATO ground and air forces took action against Serb forces in Bosnia and Herzegovina and Serbia.\nFrom the dissolution of Yugoslavia six republics achieved international recognition as sovereign republics, but these are traditionally included in Balkans: Slovenia, Croatia, Bosnia and Herzegovina, Macedonia, Montenegro and Serbia. In 2008, while under UN administration, Kosovo declared independence (according to the official Serbian policy, Kosovo is still an internal autonomous region). In July 2010, the International Court of Justice, ruled that the declaration of independence was legal. Most UN member states recognise Kosovo. After the end of the wars a revolution broke in Serbia and Slobodan Milošević, the Serbian communist leader (elected president between 1989 and 2000), was overthrown and handed for trial to the International Criminal Tribunal for crimes against the International Humanitarian Law during the Yugoslav wars. Milošević died of a heart attack in 2006 before a verdict could have been released. Ιn 2001 an Albanian uprising in Macedonia forced the country to give local autonomy to the ethnic Albanians in the areas where they predominate.\n\nWith the dissolution of Yugoslavia an issue emerged over the name under which the former (federated) republic of Macedonia would internationally be recognized, between the new country and Greece. Being the Macedonian part of Yugoslavia (see Vardar Macedonia), the federated Republic under the Yugoslav identity had the name Republic of Macedonia on which it declared its sovereignty in 1991. Greece, having a large region (see Macedonia) also under the same name opposed to the usage of this name as an indication of a nationality. The issue is currently under negotiations after a UN initiation.\n\nBalkan countries control the direct land routes between Western Europe and South West Asia (Asia Minor and the Middle East). Since 2000, all Balkan countries are friendly towards the EU and the USA.\n\nGreece has been the member of the European Union since 1981 while Slovenia is a member since 2004, Bulgaria and Romania are members since 2007, and Croatia is a member since 2013. In 2005, the European Union decided to start accession negotiations with candidate countries; Turkey, and Macedonia were accepted as candidates for EU membership. In 2012, Montenegro started accession negotiations with the EU. In 2014, Albania is an official candidate for accession to the EU. In 2015, Serbia is expected to start accession negotiations with the EU.\n\nGreece and Turkey have been NATO members since 1952. In March 2004, Bulgaria and Slovenia have become members of NATO. As of April 2009, Albania and Croatia are members of NATO. Montenegro joined in June of 2017.\n\nAll other countries have expressed a desire to join the EU and NATO at some point in the future.\n\nCurrently all of the states are republics, but until World War II all countries were monarchies. Most of the republics are parliamentary, excluding Romania and Bosnia which are semi-presidential. All the states have open market economies, most of which are in the upper-middle income range ($4,000 – $12,000 p.c.), however, Greece has high income economies (over $12,000 p.c.), and is also classified with very high HDI in contrast to the remaining states which are classified with high HDI. The states from the former Eastern Bloc that formerly had planned economy system and Turkey mark gradual economic growth each year, only the economy of Greece drops for 2012 and meanwhile it was expected to grow in 2013. The Gross domestic product (Purchasing power parity) per capita is highest in Slovenia and Greece (over $25,000), followed by Croatia (21,000) and then Turkey, Bulgaria, Romania, Montenegro, Serbia, Macedonia ($10,000 – $15,000), Bosnia, Albania and Kosovo (below $10,000). The Gini coefficient, which indicates the level of difference by monetary welfare of the layers, is on the second level at the highest monetary equality in Albania, Bulgaria and Serbia, on the third level in Greece, Montenegro and Romania, on the fourth level in Macedonia, on the fifth level in Turkey, and the most unequal by Gini coefficient is Bosnia at the eighth level which is the penultimate level and one of the highest in the world. The unemployment is lowest in Romania (below 10%), followed by Bulgaria, Turkey, Albania (10 – 15%), Greece (15 – 20%), Montenegro, Serbia, Bosnia (20 – 30%), Macedonia (over 30%) and Kosovo (over 40%).\n\nSee also the Black Sea regional organizations\n\nThe region is inhabited by Albanians, Aromanians, Bulgarians, Bosniaks, Croats, Gorani, Greeks, Macedonians, Montenegrins, Serbs, Slovenes, Romanians, Turks, and other ethnic groups which present minorities in certain countries like the Romani and Ashkali.\n\nThe region is a meeting point of Orthodox Christianity, Islam and Roman Catholic Christianity. Eastern Orthodoxy is the majority religion in both the Balkan peninsula and the Balkan region. A variety of different traditions of each faith are practiced, with each of the Eastern Orthodox countries having its own national church. A part of the population in the Balkans defines itself as irreligious.\n\nThe Jewish communities of the Balkans were some of the oldest in Europe and date back to ancient times. These communities were Sephardi Jews, except in Transylvania, Moldavia, Croatia and Slovenia, where the Jewish communities were Ashkenazi Jews. In Bosnia and Herzegovina, the small and close-knit Jewish community is 90% Sephardic, and Ladino is still spoken among the elderly. The Sephardi Jewish cemetery in Sarajevo has tombstones of a unique shape and inscribed in ancient Ladino. Sephardi Jews used to have a large presence in the city of Thessaloniki, and by 1900, some 80,000, or more than half of the population, were Jews. The Jewish communities in the Balkans suffered immensely during World War II, and the vast majority were killed during the Holocaust. An exception were the Bulgarian Jews, most of whom were saved by Boris III of Bulgaria, who resisted Adolf Hitler, opposing their deportation to Nazi concentration camps. Almost all of the few survivors have emigrated to the (then) newly founded state of Israel and elsewhere. No Balkan country today has a significant Jewish minority.\n\nThe Balkan region today is a very diverse ethno-linguistic region, being home to multiple Slavic, and Romance languages, as well as Albanian, Greek, Turkish, and others. Romani is spoken by a large portion of the Romanis living throughout the Balkan countries. Throughout history many other ethnic groups with their own languages lived in the area, among them Thracians, Illyrians, Romans, Celts and various Germanic tribes. All of the aforementioned languages from the present and from the past belong to the wider Indo-European language family, with the exception of the Turkic languages (e.g., Turkish and Gagauz).\nMost of the states in the Balkans are predominantly urbanized; the exceptions being Bosnia and Herzegovina and Kosovo each being about 50% rural and 50% urban.\n\nA list of largest cities:\n\nThe time zones in the Balkans are defined as the following:\n\n\n\n"}
{"id": "4831", "url": "https://en.wikipedia.org/wiki?curid=4831", "title": "Bohr model", "text": "Bohr model\n\nIn atomic physics, the Rutherford–Bohr model or Bohr model or Bohr diagram, introduced by Niels Bohr and Ernest Rutherford in 1913, depicts the atom as a small, positively charged nucleus surrounded by electrons that travel in circular orbits around the nucleus—similar to structure to the Solar System, but with attraction provided by electrostatic forces rather than gravity. After the cubic model (1902), the plum-pudding model (1904), the Saturnian model (1904), and the Rutherford model (1911) came the \"Rutherford–Bohr model\" or just \"Bohr model\" for short (1913). The improvement to the Rutherford model is mostly a quantum physical interpretation of it. \nThe model's key success lay in explaining the Rydberg formula for the spectral emission lines of atomic hydrogen. While the Rydberg formula had been known experimentally, it did not gain a theoretical underpinning until the Bohr model was introduced. Not only did the Bohr model explain the reason for the structure of the Rydberg formula, it also provided a justification for its empirical results in terms of fundamental physical constants.\n\nThe Bohr model is a relatively primitive model of the hydrogen atom, compared to the valence shell atom. As a theory, it can be derived as a first-order approximation of the hydrogen atom using the broader and much more accurate quantum mechanics and thus may be considered to be an obsolete scientific theory. However, because of its simplicity, and its correct results for selected systems (see below for application), the Bohr model is still commonly taught to introduce students to quantum mechanics or energy level diagrams before moving on to the more accurate, but more complex, valence shell atom. A related model was originally proposed by Arthur Erich Haas in 1910, but was rejected. The quantum theory of the period between Planck's discovery of the quantum (1900) and the advent of a full-blown quantum mechanics (1925) is often referred to as the old quantum theory.\n\nIn the early 20th century, experiments by Ernest Rutherford established that atoms consisted of a diffuse cloud of negatively charged electrons surrounding a small, dense, positively charged nucleus. Given this experimental data, Rutherford naturally considered a planetary-model atom, the Rutherford model of 1911 – electrons orbiting a solar nucleus – however, said planetary-model atom has a technical difficulty. The laws of classical mechanics (i.e. the Larmor formula), predict that the electron will release electromagnetic radiation while orbiting a nucleus. Because the electron would lose energy, it would rapidly spiral inwards, collapsing into the nucleus on a timescale of around 16 picoseconds. This atom model is disastrous, because it predicts that all atoms are unstable.\n\nAlso, as the electron spirals inward, the emission would rapidly increase in frequency as the orbit got smaller and faster. This would produce a continuous smear, in frequency, of electromagnetic radiation. However, late 19th century experiments with electric discharges have shown that atoms will only emit light (that is, electromagnetic radiation) at certain discrete frequencies.\n\nTo overcome this difficulty, Niels Bohr proposed, in 1913, what is now called the \"Bohr model of the atom\". He suggested that electrons could only have certain \"classical\" motions:\n\nwhere \"n\" = 1, 2, 3, ... is called the principal quantum number, and . The lowest value of \"n\" is 1; this gives a smallest possible orbital radius of 0.0529 nm known as the Bohr radius. Once an electron is in this lowest orbit, it can get no closer to the proton. Starting from the angular momentum quantum rule, Bohr was able to calculate the energies of the allowed orbits of the hydrogen atom and other hydrogen-like atoms and ions.\n\nOther points are:\n\nBohr's condition, that the angular momentum is an integer multiple of \"ħ\" was later reinterpreted in 1924 by de Broglie as a standing wave condition: the electron is described by a wave and a whole number of wavelengths must fit along the circumference of the electron's orbit:\n\nBohr described angular momentum of the electron orbit as 1/2h while de Broglie's wavelength of described h divided by the electron momentum. In 1913, however, Bohr justified his rule by appealing to the correspondence principle, without providing any sort of wave interpretation. In 1913, the wave behavior of matter particles such as the electron (i.e., matter waves) was not suspected.\n\nIn 1925, a new kind of mechanics was proposed, quantum mechanics, in which Bohr's model of electrons traveling in quantized orbits was extended into a more accurate model of electron motion. The new theory was proposed by Werner Heisenberg. Another form of the same theory, wave mechanics, was discovered by the Austrian physicist Erwin Schrödinger independently, and by different reasoning. Schrödinger employed de Broglie's matter waves, but sought wave solutions of a three-dimensional wave equation describing electrons that were constrained to move about the nucleus of a hydrogen-like atom, by being trapped by the potential of the positive nuclear charge.\n\nThe Bohr model gives almost exact results only for a system where two charged points orbit each other at speeds much less than that of light. This not only involves one-electron systems such as the hydrogen atom,singly ionized helium, and doubly ionized lithium, but it includes positronium and Rydberg states of any atom where one electron is far away from everything else. It can be used for K-line X-ray transition calculations if other assumptions are added (see Moseley's law below). In high energy physics, it can be used to calculate the masses of heavy quark mesons.\n\nCalculation of the orbits requires two assumptions.\n\n\n\nAn electron in the lowest energy level of hydrogen () therefore has about 13.6 eV less energy than a motionless electron infinitely far from the nucleus. The next energy level () is −3.4 eV. The third (\"n\" = 3) is −1.51 eV, and so on. For larger values of \"n\", these are also the binding energies of a highly excited atom with one electron in a large circular orbit around the rest of the atom. The hydrogen formula also coincides with the Wallis product.\n\nThe combination of natural constants in the energy formula is called the Rydberg energy (\"R\"):\n\nThis expression is clarified by interpreting it in combinations that form more natural units:\n\nSince this derivation is with the assumption that the nucleus is orbited by one electron, we can generalize this result by letting the nucleus have a charge \"q\" = \"Z e\" where \"Z\" is the atomic number. This will now give us energy levels for hydrogenic atoms, which can serve as a rough order-of-magnitude approximation of the actual energy levels. So for nuclei with \"Z\" protons, the energy levels are (to a rough approximation):\n\nThe actual energy levels cannot be solved analytically for more than one electron (see \"n\"-body problem) because the electrons are not only affected by the nucleus but also interact with each other via the Coulomb Force.\n\nWhen \"Z\" = 1/\"α\" (Z ≈ 137), the motion becomes highly relativistic, and \"Z\" cancels the \"α\" in \"R\"; the orbit energy begins to be comparable to rest energy. Sufficiently large nuclei, if they were stable, would reduce their charge by creating a bound electron from the vacuum, ejecting the positron to infinity. This is the theoretical phenomenon of electromagnetic charge screening which predicts a maximum nuclear charge. Emission of such positrons has been observed in the collisions of heavy ions to create temporary super-heavy nuclei.\n\nThe Bohr formula properly uses the reduced mass of electron and proton in all situations, instead of the mass of the electron,\nHowever, these numbers are very nearly the same, due to the much larger mass of the proton, about 1836.1 times the mass of the electron, so that the reduced mass in the system is the mass of the electron multiplied by the constant 1836.1/(1+1836.1) = 0.99946. This fact was historically important in convincing Rutherford of the importance of Bohr's model, for it explained the fact that the frequencies of lines in the spectra for singly ionized helium do not differ from those of hydrogen by a factor of exactly 4, but rather by 4 times the ratio of the reduced mass for the hydrogen vs. the helium systems, which was much closer to the experimental ratio than exactly 4.\n\nFor positronium, the formula uses the reduced mass also, but in this case, it is exactly the electron mass divided by 2. For any value of the radius, the electron and the positron are each moving at half the speed around their common center of mass, and each has only one fourth the kinetic energy. The total kinetic energy is half what it would be for a single electron moving around a heavy nucleus.\n\nThe Rydberg formula, which was known empirically before Bohr's formula, is seen in Bohr's theory as describing the energies of transitions or quantum jumps between one orbital energy levels. Bohr's formula gives the numerical value of the already-known and measured Rydberg's constant, but in terms of more fundamental constants of nature, including the electron's charge and Planck's constant.\n\nWhen the electron gets moved from its original energy level to a higher one, it then jumps back each level until it comes to the original position, which results in a photon being emitted. Using the derived formula for the different energy levels of hydrogen one may determine the wavelengths of light that a hydrogen atom can emit.\n\nThe energy of a photon emitted by a hydrogen atom is given by the difference of two hydrogen energy levels:\nwhere is the final energy level, and is the initial energy level.\n\nSince the energy of a photon is\nthe wavelength of the photon given off is given by\n\nThis is known as the Rydberg formula, and the Rydberg constant is , or in natural units. This formula was known in the nineteenth century to scientists studying spectroscopy, but there was no theoretical explanation for this form or a theoretical prediction for the value of , until Bohr. In fact, Bohr's derivation of the Rydberg constant, as well as the concomitant agreement of Bohr's formula with experimentally observed spectral lines of the Lyman ( =1), Balmer ( =2), and Paschen ( =3) series, and successful theoretical prediction of other lines not yet observed, was one reason that his model was immediately accepted.\n\nTo apply to atoms with more than one electron, the Rydberg formula can be modified by replacing with or with where is constant representing a screening effect due to the inner-shell and other electrons (see Electron shell and the later discussion of the \"Shell Model of the Atom\" below). This was established empirically before Bohr presented his model.\n\nBohr extended the model of hydrogen to give an approximate model for heavier atoms. This gave a physical picture that reproduced many known atomic properties for the first time.\n\nHeavier atoms have more protons in the nucleus, and more electrons to cancel the charge. Bohr's idea was that each discrete orbit could only hold a certain number of electrons. After that orbit is full, the next level would have to be used. This gives the atom a shell structure, in which each shell corresponds to a Bohr orbit.\n\nThis model is even more approximate than the model of hydrogen, because it treats the electrons in each shell as non-interacting. But the repulsions of electrons are taken into account somewhat by the phenomenon of screening. The electrons in outer orbits do not only orbit the nucleus, but they also move around the inner electrons, so the effective charge Z that they feel is reduced by the number of the electrons in the inner orbit.\n\nFor example, the lithium atom has two electrons in the lowest 1s orbit, and these orbit at Z=2. Each one sees the nuclear charge of Z=3 minus the screening effect of the other, which crudely reduces the nuclear charge by 1 unit. This means that the innermost electrons orbit at approximately 1/4 the Bohr radius. The outermost electron in lithium orbits at roughly Z=1, since the two inner electrons reduce the nuclear charge by 2. This outer electron should be at nearly one Bohr radius from the nucleus. Because the electrons strongly repel each other, the effective charge description is very approximate; the effective charge Z doesn't usually come out to be an integer. But Moseley's law experimentally probes the innermost pair of electrons, and shows that they do see a nuclear charge of approximately Z−1, while the outermost electron in an atom or ion with only one electron in the outermost shell orbits a core with effective charge Z−k where k is the total number of electrons in the inner shells.\n\nThe shell model was able to qualitatively explain many of the mysterious properties of atoms which became codified in the late 19th century in the periodic table of the elements. One property was the size of atoms, which could be determined approximately by measuring the viscosity of gases and density of pure crystalline solids. Atoms tend to get smaller toward the right in the periodic table, and become much larger at the next line of the table. Atoms to the right of the table tend to gain electrons, while atoms to the left tend to lose them. Every element on the last column of the table is chemically inert (noble gas).\n\nIn the shell model, this phenomenon is explained by shell-filling. Successive atoms become smaller because they are filling orbits of the same size, until the orbit is full, at which point the next atom in the table has a loosely bound outer electron, causing it to expand. The first Bohr orbit is filled when it has two electrons, which explains why helium is inert. The second orbit allows eight electrons, and when it is full the atom is neon, again inert. The third orbital contains eight again, except that in the more correct Sommerfeld treatment (reproduced in modern quantum mechanics) there are extra \"d\" electrons. The third orbit may hold an extra 10 d electrons, but these positions are not filled until a few more orbitals from the next level are filled (filling the n=3 d orbitals produces the 10 transition elements). The irregular filling pattern is an effect of interactions between electrons, which are not taken into account in either the Bohr or Sommerfeld models and which are difficult to calculate even in the modern treatment.\n\nNiels Bohr said in 1962, \"You see actually the Rutherford work was not taken seriously. We cannot understand today,but it was not taken seriously at all. There was no mention of it any place. The great change came from Moseley.\"\n\nIn 1913 Henry Moseley found an empirical relationship between the strongest X-ray line emitted by atoms under electron bombardment (then known as the K-alpha line), and their atomic number . Moseley's empiric formula was found to be derivable from Rydberg and Bohr's formula (Moseley actually mentions only Ernest Rutherford and Antonius Van den Broek in terms of models). The two additional assumptions that [1] this X-ray line came from a transition between energy levels with quantum numbers 1 and 2, and [2], that the atomic number when used in the formula for atoms heavier than hydrogen, should be diminished by 1, to .\n\nMoseley wrote to Bohr, puzzled about his results, but Bohr was not able to help. At that time, he thought that the postulated innermost \"K\" shell of electrons should have at least four electrons, not the two which would have neatly explained the result. So Moseley published his results without a theoretical explanation.\n\nLater, people realized that the effect was caused by charge screening, with an inner shell containing only 2 electrons. In the experiment, one of the innermost electrons in the atom is knocked out, leaving a vacancy in the lowest Bohr orbit, which contains a single remaining electron. This vacancy is then filled by an electron from the next orbit, which has n=2. But the n=2 electrons see an effective charge of Z−1, which is the value appropriate for the charge of the nucleus, when a single electron remains in the lowest Bohr orbit to screen the nuclear charge +Z, and lower it by −1 (due to the electron's negative charge screening the nuclear positive charge). The energy gained by an electron dropping from the second shell to the first gives Moseley's law for K-alpha lines,\nor\n\nHere, R\" = R\"/\"h\" is the Rydberg constant, in terms of frequency equal to 3.28 x 10 Hz. For values of Z between 11 and 31 this latter relationship had been empirically derived by Moseley, in a simple (linear) plot of the square root of X-ray frequency against atomic number (however, for silver, Z = 47, the experimentally obtained screening term should be replaced by 0.4). Notwithstanding its restricted validity, Moseley's law not only established the objective meaning of atomic number (see Henry Moseley for detail) but, as Bohr noted, it also did more than the Rydberg derivation to establish the validity of the Rutherford/Van den Broek/Bohr nuclear model of the atom, with atomic number (place on the periodic table) standing for whole units of nuclear charge.\n\nThe K-alpha line of Moseley's time is now known to be a pair of close lines, written as (Kα and Kα) in Siegbahn notation.\n\nThe Bohr model gives an incorrect value for the ground state orbital angular momentum: The angular momentum in the true ground state is known to be zero from experiment. Although mental pictures fail somewhat at these levels of scale, an electron in the lowest modern \"orbital\" with no orbital momentum, may be thought of as not to rotate \"around\" the nucleus at all, but merely to go tightly around it in an ellipse with zero area (this may be pictured as \"back and forth\", without striking or interacting with the nucleus). This is only reproduced in a more sophisticated semiclassical treatment like Sommerfeld's. Still, even the most sophisticated semiclassical model fails to explain the fact that the lowest energy state is spherically symmetric – it doesn't point in any particular direction.\n\nNevertheless, in the modern \"fully quantum treatment in phase space\", the proper deformation (careful full extension) of the semi-classical result adjusts the angular momentum value to the correct effective one. As a consequence, the physical ground state expression is obtained through a shift of the vanishing quantum angular momentum expression, which corresponds to spherical symmetry.\n\nIn modern quantum mechanics, the electron in hydrogen is a spherical cloud of probability that grows denser near the nucleus. The rate-constant of probability-decay in hydrogen is equal to the inverse of the Bohr radius, but since Bohr worked with circular orbits, not zero area ellipses, the fact that these two numbers exactly agree is considered a \"coincidence\". (However, many such coincidental agreements are found between the semiclassical vs. full quantum mechanical treatment of the atom; these include identical energy levels in the hydrogen atom and the derivation of a fine structure constant, which arises from the relativistic Bohr–Sommerfeld model (see below) and which happens to be equal to an entirely different concept, in full modern quantum mechanics).\n\nThe Bohr model also has difficulty with, or else fails to explain:\n\n\nSeveral enhancements to the Bohr model were proposed, most notably the Sommerfeld model or Bohr–Sommerfeld model, which suggested that electrons travel in elliptical orbits around a nucleus instead of the Bohr model's circular orbits. This model supplemented the quantized angular momentum condition of the Bohr model with an additional radial quantization condition, the Sommerfeld–Wilson quantization condition\n\nwhere \"p\" is the radial momentum canonically conjugate to the coordinate \"q\" which is the radial position and \"T\" is one full orbital period. The integral is the action of action-angle coordinates. This condition, suggested by the correspondence principle, is the only one possible, since the quantum numbers are adiabatic invariants.\n\nThe Bohr–Sommerfeld model was fundamentally inconsistent and led to many paradoxes. The magnetic quantum number measured the tilt of the orbital plane relative to the \"xy\"-plane, and it could only take a few discrete values. This contradicted the obvious fact that an atom could be turned this way and that relative to the coordinates without restriction. The Sommerfeld quantization can be performed in different canonical coordinates and sometimes gives different answers. The incorporation of radiation corrections was difficult, because it required finding action-angle coordinates for a combined radiation/atom system, which is difficult when the radiation is allowed to escape. The whole theory did not extend to non-integrable motions, which meant that many systems could not be treated even in principle. In the end, the model was replaced by the modern quantum mechanical treatment of the hydrogen atom, which was first given by Wolfgang Pauli in 1925, using Heisenberg's matrix mechanics. The current picture of the hydrogen atom is based on the atomic orbitals of wave mechanics which Erwin Schrödinger developed in 1926.\n\nHowever, this is not to say that the Bohr-Sommerfeld model was without its successes. Calculations based on the Bohr–Sommerfeld model were able to accurately explain a number of more complex atomic spectral effects. For example, up to first-order perturbations, the Bohr model and quantum mechanics make the same predictions for the spectral line splitting in the Stark effect. At higher-order perturbations, however, the Bohr model and quantum mechanics differ, and measurements of the Stark effect under high field strengths helped confirm the correctness of quantum mechanics over the Bohr model. The prevailing theory behind this difference lies in the shapes of the orbitals of the electrons, which vary according to the energy state of the electron.\n\nThe Bohr–Sommerfeld quantization conditions lead to questions in modern mathematics. Consistent semiclassical quantization condition requires a certain type of structure on the phase space, which places topological limitations on the types of symplectic manifolds which can be quantized. In particular, the symplectic form should be the curvature form of a connection of a Hermitian line bundle, which is called a prequantization.\n\n\n\n"}
{"id": "4832", "url": "https://en.wikipedia.org/wiki?curid=4832", "title": "Bombay Sapphire", "text": "Bombay Sapphire\n\nBombay Sapphire is a brand of gin that was first launched in 1987 by IDV. In 1997 Diageo sold the brand to Bacardi. Its name originates from gin's popularity in India during the British Raj and the sapphire in question is the Star of Bombay on display at the Smithsonian Institution. Bombay Sapphire is marketed in a flat-sided, sapphire-coloured bottle that bears a picture of Queen Victoria on the label.\n\nThe flavouring of the drink comes from a recipe of ten ingredients: almond, lemon peel, liquorice, juniper berries, orris root, angelica, coriander, cassia, cubeb, and grains of paradise. Alcohol bought in from another supplier is evaporated three times using a carterhead still, and the alcohol vapours are passed through a mesh/basket containing the ten botanicals, in order to gain flavour and aroma. This is felt to give the gin a lighter, more floral taste compared to those gins that are created using a copper pot still. Water from Lake Vyrnwy is added to bring the strength of Bombay Sapphire down to 40.0% (UK, Canada, Australia).\n\nIn 2011, plans were announced to move the manufacturing process to a new facility at Laverstoke Mill in Whitchurch, Hampshire, including the restoration of the former Portal's paper mill at the proposed site, and the construction of a visitor centre. \n\nPlanning permission was granted in February 2012, and the centre opened to the public in the autumn of 2014. The visitor centre included a new construction by Thomas Heatherwick of two glasshouses for plants used as botanicals in the production of Bombay Sapphire gin.\n\nProduction and bottling of the drink is contracted out by Bacardi to G&J Greenall.\n\nBacardi also markets Bombay Original London Dry Gin (or Bombay Original Dry). Eight botanical ingredients are used in the production of the Original Dry Gin variety as opposed to the ten in Bombay Sapphire. \"Wine Enthusiast\" preferred Bombay Sapphire.\n\nIn September 2011, Bombay Sapphire East was launched in test markets in New York and Las Vegas. This variety has another two botanicals, lemongrass and black peppercorns, in addition to the original ten. It is bottled at 42% and was designed to counteract the sweetness of American tonic water.\n\nA Special edition of Bombay Gin called Bombay Star was produced in 2015 for the UK Market. It is bottled at 47.5% and is distilled from grain.\n\nThe brand started a series of design collaborations. Their first step into the design world was a series of advertisements featuring work from currently popular designers. Their works, varying from martini glasses to tiles and cloth patterns, are labelled as “Inspired by Bombay Sapphire”. The campaign featured designers such as Marcel Wanders, Yves Behar, Karim Rashid, Ulla Darni, and Dror Benshetrit and performance artist Jurgen Hahn.\n\nFrom the success of this campaign, the company began a series of events and sponsored locations. The best known is the Bombay Sapphire Designer Glass Competition, held each year, where design students from all over the world can participate by designing their own “inspired” martini cocktail glass. The finalists (one from each participating country) are then invited to the yearly Salone del Mobile, an international design fair in Milano, where the winner is chosen.\n\nBombay Sapphire also endorses glass artists and designers with the Bombay Sapphire Prize, which is awarded every year to an outstanding design which features glass. Bombay Sapphire also showcases the designers' work in the Bombay Sapphire endorsed blue room, which is a design exhibition touring the world each year.\n\nFrom 2008 the Bombay Sapphire Designer Glass Competition final will be held at 100% Design in London, UK and the Bombay Sapphire Prize will take place in Milan at the Salone Del Mobile.\n\nBombay Sapphire has been reviewed by several outside spirit ratings organizations to mixed success. Recently, it was awarded a score of 92 (on a 100-point scale) from the Beverage Testing Institute. Ratings aggregator Proof66.com categorizes the Sapphire as a Tier 2 spirit, indicating highly favourable \"expert\" reviews.\n\n\n"}
{"id": "4833", "url": "https://en.wikipedia.org/wiki?curid=4833", "title": "Bob Wills", "text": "Bob Wills\n\nJames Robert Wills (March 6, 1905 – May 13, 1975) was an American Western swing musician, songwriter, and bandleader. Considered by music authorities as the co-founder of Western swing, he was universally known as the King of Western Swing (after the death of Spade Cooley who used the moniker \"King Of Western Swing\" from 1942 to 1969).\n\nWills formed several bands and played radio stations around the South and West until he formed the Texas Playboys in 1934 with Wills on fiddle, Tommy Duncan on piano and vocals, rhythm guitarist June Whalin, tenor banjoist Johnnie Lee Wills, and Kermit Whalin, who played steel guitar and bass. The band played regularly on a Tulsa, Oklahoma radio station and added Leon McAuliffe on steel guitar, pianist Al Stricklin, drummer Smokey Dacus, and a horn section that expanded the band's sound. Wills favored jazz-like arrangements and the band found national popularity into the 1940s with such hits as \"Steel Guitar Rag\", \"New San Antonio Rose\", \"Smoke On The Water\", \"Stars And Stripes On Iwo Jima\", and \"New Spanish Two Step\".\n\nWills and the Texas Playboys recorded with several publishers and companies, including Vocalion, Okeh, Columbia, and MGM, frequently moving. In 1950, he had two Top 10 hits, \"Ida Red Likes The Boogie\" and \"Faded Love\", which were his last hits for a decade. Throughout the 1950s, he struggled with poor health and tenuous finances, but continued to perform frequently despite the decline in popularity of his earlier music as rock and roll took over. Wills had a heart attack in 1962 and a second one the next year, which forced him to disband the Playboys although Wills continued to perform solo.\n\nThe Country Music Hall of Fame inducted Wills in 1968 and the Texas State Legislature honored him for his contribution to American music. In 1972, Wills accepted a citation from the American Society of Composers, Authors and Publishers in Nashville. He was recording an album with fan Merle Haggard in 1973 when a stroke left him comatose until his death in 1975. The Rock and Roll Hall of Fame inducted Wills and the Texas Playboys in 1999.\n\nHe was born on a farm near Kosse, Texas, in Limestone County near Groesbeck, to Emma Lee Foley and John Tompkins Wills. His father was a statewide champion fiddle player and the Wills family was either playing music, or someone was \"always wanting us to play for them\", in addition to raising cotton on their farm.\n\nIn addition to picking cotton, the young Jim Bob learned to play the fiddle and the mandolin. Both a sister and several brothers played musical instruments, while another sister played piano. The Wills family frequently held country dances in their home, and there was dancing in all four rooms. While living in Hall County, Texas, they also played at 'ranch dances' which were popular in both North Texas and eastern New Mexico.\n\nWills not only learned traditional music from his family, he learned some Negro songs directly from African Americans in the cotton fields near Lakeview, Texas, and said that he did not play with many white children other than his siblings, until he was seven or eight years old. African Americans were his playmates, and his father enjoyed watching him jig dance with black children.\n\n\"I don't know whether they made them up as they moved down the cotton rows or not,\" Wills once told Charles Townsend, author of \"San Antonio Rose: The Life And Times Of Bob Wills\", \"but they sang blues you never heard before.\"\n\nThe family moved to Hall County in the Texas Panhandle in 1913, and in 1919 they bought a farm between the towns of Lakeview and Turkey. At the age of 16, Wills left the family and hopped a freight train. \"Jim Rob\", as he became known, drifted for several years, traveling from town to town to try to earn a living, at one point almost losing his life when he nearly fell from a moving train, and later being chased by railroad police. In his 20s he attended barber school, got married, and moved first to Roy, New Mexico, then returned to Turkey in Hall County (now considered his home town) to work as a barber at Hamm's Barber Shop. He alternated barbering and fiddling even when he moved to Fort Worth after leaving Hall County in 1929. There he played in minstrel and medicine shows, and, as with other Texas musicians such as Ocie Stockard, continued to earn money as a barber. He wore blackface makeup to appear in comedy routines, something that was common at the time. \"He was playing his violin and singing.\" There were two guitars and a banjo player with him. \"Bob was in blackface and was the comic; he cracked jokes, sang, and did an amazing jig dance.\" Since there was already a \"Jim\" on the show, the manager began calling him \"Bob\". However, it was as \"Jim Rob Wills\", paired with Herman Arnspiger, that he made his first commercial (though unissued) recordings in November 1929 for Brunswick/Vocalion.\n\nWills was known for his hollering and wisecracking. One source for this was when, as a very young boy, he would hear his father, grandfather, and cowboys give out loud cries when the music moved them. When asked if his wisecracking and talking on the bandstand came from his medicine show experience, he said it did not. Rather, he said that it came directly from playing and living close to Negroes, and that he never did it necessarily as show, but more as a way to express his feelings.\n\nWhile in Fort Worth, Wills added the \"rowdy city blues\" of Bessie Smith and Emmett Miller to a repertoire of mainly waltzes and breakdowns he had learned from his father, and patterned his vocal style after that of Miller and other performers such as Al Bernard. Wills acknowledged that he idolized Miller. Furthermore, his 1935 version of \"St. Louis Blues\" is nearly a word-for-word copy of Al Bernard's patter on his 1928 recording of the same song.\n\nThe fact that Wills made his professional debut in blackface was commented on by Wills' daughter, Rosetta: \"He had a lot of respect for the musicians and music of his black friends,\" Rosetta is quoted as saying on the Bob Wills and the Texas Playboys Web site. She remembers that her father was such a fan of Bessie Smith stating, \"He once rode fifty miles on horseback just to see her perform live.\" (Wills is quoted as saying, \"I rode horseback from the place between the rivers to Childress to see Bessie Smith ... She was about the greatest thing I had ever heard. In fact, there was no doubt about it. She \"was\" the greatest thing I ever heard.\"\n\nIn Fort Worth, Wills met Herman Arnspiger and formed The Wills Fiddle Band. In 1930 Milton Brown joined the group as lead vocalist and brought a sense of innovation and experimentation to the band, and became known as the Aladdin Laddies and then soon re-named themselves the Light Crust Doughboys due to radio sponsorship by the makers of Light Crust Flour. Brown left the band in 1932 to form the Musical Brownies, the first true Western swing band. Brown added twin fiddles, tenor banjo and slap bass, pointing the music in the direction of swing, which they played on local radio and at dancehalls.\n\nWills remained with the Doughboys and replaced Brown with new singer Tommy Duncan in 1932. He found himself unable to get along with future Texas Governor W. Lee \"Pappy\" O'Daniel, the authoritarian host of the Light Crust Doughboy radio show. O'Daniel had parlayed the show's popularity into growing power within Light Crust Flour's parent company, Burrus Mill and Elevator Company, and wound up as General Manager, though he despised what he considered \"hillbilly music\". Wills and Duncan left the Doughboys in 1933 after Wills had missed one show too many due to his sporadic drinking.\n\nWills recalled the early days of what became known as Western swing music in a 1949 interview. \"Here's the way I figure it. We sure not tryin' to take credit for swingin' it.\" Speaking of Milt Brown and himself working with songs done by Jimmie Davis, the Skillet Lickers, Jimmie Rodgers, and others, and songs he'd learned from his father, he said that \"We'd pull these tunes down an set 'em in a dance category. It wouldn't be a runaway, and just lay a real nice beat behind it an the people would get to really like it. It was nobody intended to start anything in the world. We was just tryin' to find enough tunes to keep 'em dancin' to not have to repeat so much.\"\n\nAs stated in the Texas Playboys standard \"Time Changes Everything\" (written by Tommy Duncan), \"You can change the name of an old song, rearrange it and make it a swing.\" \"One Star Rag\", \"Rat Cheese Under The Hill\", \"Take Me Back To Tulsa\", \"Basin Street Blues\", \"Steel Guitar Rag\", and \"Trouble In Mind\" were some of the songs in Wills' extensive repertory.\n\nAfter forming a new band, The Playboys, and relocating to Waco, Wills found enough popularity there to decide on a bigger market. They left Waco in January 1934 for Oklahoma City. Wills soon settled the renamed Texas Playboys in Tulsa, Oklahoma, and began broadcasting noontime shows over the 50,000 watt KVOO radio station. Their 12:30–1:15 p.m. Monday–Friday broadcasts became a veritable institution in the region. Nearly all of the daily (except Sunday) shows originated from the stage of Cain's Ballroom. In addition, they played dances in the evenings, including regular ones at the ballroom on Thursdays and Saturdays.\n\nWills added a trumpet to the band inadvertently when he hired Everet Stover as an announcer, not knowing that he had played with the New Orleans symphony and had directed the governor's band in Austin. Stover, thinking he had been hired as a trumpeter, began playing with the band with no comment from Wills. Young sax player Zeb McNally was allowed to play with the band, although Wills initially discouraged it. With two horns in the band, Wills realized he would have to add a drummer to balance things and create a fuller sound. He hired the young, \"modern style musician\" Smoky Dacus. By 1935, Wills had added horn and reed players as well as drums to the Playboys. The addition of steel guitar whiz Leon McAuliffe in March 1935 added not only a formidable instrumentalist but a second engaging vocalist. Wills himself largely sang blues and sentimental ballads. Wills and the Texas Playboys did their first recordings on September 23–25, 1935 in Dallas, Texas, being produced by Don Law and Art Satherley of the American Record Corporation. There is strong evidence that the 1935 sessions took place at 508 Park Avenue along with sessions in 1937 and 1938.\n\nWith its jazz sophistication, pop music and blues influence, plus improvised scat and wisecrack commentary by Wills, the band became the first superstars of the genre. Milton Brown's death in 1936 had cleared the way for the Playboys.\n\nSession rosters from 1938 show both \"lead guitar\" and \"electric guitar\" in addition to guitar and steel guitar in the Texas Playboys recordings. Wills' 1938 recording of \"Ida Red\" served as a model for Chuck Berry's decades later version of the same song, \"Maybellene\".\n\nAbout this time, Wills purchased and performed with an old Guadagnini violin that had once fetched $7,600 for $1,600, the equivalent of about $24,000 in 2009.\n\nIn 1940, \"New San Antonio Rose\" sold a million records and became the signature song of The Texas Playboys. The song's title referred to the fact that Wills had recorded it as a fiddle instrumental in 1938 as \"San Antonio Rose\". By then, the Texas Playboys were virtually two bands: one a fiddle-guitar-steel band with rhythm section and the second a first-rate big band able to play the day's swing and pop hits as well as Dixieland.\n\nThe \"front line\" of Wills' orchestra consisted of either fiddles or guitars after 1944.\n\nIn 1940, Wills, along with the Texas Playboys, co-starred with Tex Ritter in \"Take Me Back To Oklahoma\". Other films would follow. In December 1942, after several band members had left the group, and as World War II raged, Wills joined the Army at the age of 37, but he received a medical discharge in 1943.\n\nWills also appeared in \"The Lone Prairie\" (1942), \"Riders Of The Northwest Mounted\" (1943), \"Saddles And Sagebrush\" (1943), \"The Vigilantes Ride\" (1943), \"The Last Horseman\" (1944), \"Rhythm Round-Up\" (1945), \"Blazing The Western Trail\" (1945), and \"Lawless Empire\" (1945). According to one source, he appeared in a total of 19 films.\n\nAfter leaving the Army in 1943, Wills moved to Hollywood, moving into a rented house in September, and began to reorganize the Texas Playboys. He became an enormous draw in Los Angeles, where many of his Texas, Oklahoma and regional fans had also relocated during the Great Depression and World War II in search of jobs. Monday through Friday, the band broadcast from 12:01 to 1:00 p.m. PT over KMTR-AM (now KLAC) in Los Angeles. They also played regularly every Friday, Saturday, and Sunday night at the Mission Beach Ballroom in San Diego.\n\nHe commanded enormous fees playing dances there, and began to make more creative use of electric guitars to replace the big horn sections the Tulsa band had boasted. For a very brief period in 1944, the Wills band included 23 members, and around mid-year he toured Northern California and the Pacific Northwest with 21 pieces in the orchestra. \"Billboard\" reported that Wills out-grossed Harry James, Benny Goodman, \"both Dorsies, et al.\" at Civic Auditorium in Oakland, California, in January 1944.\n\nWills and His Texas Playboys began their first cross-country tour in November 1944, and appeared at the Grand Ole Opry on December 30, 1944. According to the Opry, drums and horns were not considered to be part of country music. Wills' band at the time consisted of two fiddlers, two bass fiddles, two electric guitars, an amplified electric steel guitar, and a trumpet, as well as the noted drums, which belonged to Wills' then drummer, who played in the Dixieland style.\n\nIn 1945, Wills' dances were outdrawing those of Tommy Dorsey and Benny Goodman, and he moved to Fresno, California. Then in 1947 he opened the Wills Point nightclub in Sacramento and continued touring the Southwest and Pacific Northwest from Texas to Washington State. While based in Sacramento, his radio broadcasts over 50,000-watt KFBK were heard all over the West.\n\nFamous swing orchestras in California realized that many of their followers were leaving to dance to Bob Will's Western swing. Because he was in such demand, some places booked Wills any time he had an opening, regardless of how undesirable the date. The manager of a popular auditorium in the LA Basin town of Wilmington, California: \"Although Monday night dancing is frankly an experiment it was the only night of the week on which this outstanding band could be secured.\"\n\nDuring the postwar period, KGO radio in San Francisco syndicated a Bob Wills and His Texas Playboys show recorded at the Fairmont Hotel. Many of these recordings survive today as the Tiffany Transcriptions and are available on CD. They show off the band's strengths significantly, in part because the group was not confined to the three-minute limits of 78 RPM discs. They featured superb instrumental work from fiddlers Joe Holley and Louis Tierney, steel guitarists Roy Honeycutt, Noel Boggs and Herb Remington, guitarists Eldon Shamblin and Junior Barnard and electric mandolinist-fiddler Tiny Moore. The original recorded version of Wills' \"Faded Love\" appeared on the Tiffanys as a fairly swinging instrumental unlike the ballad it became when lyrics were added in 1950.\n\nOn April 3, 1948, Wills and the Texas Playboys appeared for the inaugural broadcast of the \"Louisiana Hayride\" on KWKH, broadcasting from the Municipal Auditorium in Shreveport, Louisiana.\n\nWills and the Texas Playboys played dances throughout the West to more than 10,000 people every week. They held dance attendance records at Jantzen Beach in Portland, Oregon; in Santa Monica, California, and at the Oakland (California) Auditorium, where they drew 19,000 people in two nights. Wills also broke an attendance record of 2,100 previously held by Jan Garber at the Armory in Klamath Falls, Oregon, by attracting 2,514 dancers. Wills and the Playboys also played small towns on the West Coast. Actor Clint Eastwood recalled seeing Wills when he was 18 or 19 (1948 or 1949) and working at a pulp mill in Springfield, Oregon.\n\nAppearances at the Bostonia Ballroom in San Diego continued throughout the 1950s.\n\nStill a binge drinker, Wills became increasingly unreliable in the late 1940s, causing a rift with Tommy Duncan (who bore the brunt of audience anger when Wills's binges prevented him from appearing). It ended when he fired Duncan in the fall of 1948.\n\nHaving lived a lavish lifestyle in California, Wills moved back to Oklahoma City in 1949, then went back on the road to maintain his payroll and Wills Point. He opened a second club, the Bob Wills Ranch House in Dallas, Texas. Turning the club over to managers later revealed to be dishonest left Wills in desperate financial straits with heavy debts to the IRS for back taxes that caused him to sell many assets including, mistakenly, the rights to \"New San Antonio Rose\". It wrecked him financially.\n\nIn 1950, Wills had two Top 10 hits, \"Ida Red Likes The Boogie\" and \"Faded Love\". After 1950, radio stations began to increasingly specialize in one form or another of commercially popular music. Wills did not fit into the popular Nashville country and western stations, although he was usually labeled \"country and western\". Neither did he fit into the pop or middle of the road stations, although he played a good deal of pop music, and was not accepted in the pop music world.\n\nHe continued to tour and record through the 1950s into the early 1960s, despite the fact that Western swing's popularity, even in the Southwest, had greatly diminished. Bob could draw \"a thousand people on Monday night between 1950 and 1952, but he could not do that by 1956. Entertainment habits had changed.\"\n\nOn Wills' return to Tulsa late in 1957, Jim Downing of the \"Tulsa Tribune\" wrote an article headlined \"Wills Brothers Together Again: Bob Back With Heavy Beat\". The article quotes Wills as saying, \"Rock and Roll? Why, man, that's the same kind of music we've been playin' since 1928! ... We didn't call it rock and roll back when we introduced it as our style back in 1928, and we don't call it rock and roll the way we play it now. But it's just basic rhythm and has gone by a lot of different names in my time. It's the same, whether you just follow a drum beat like in Africa or surround it with a lot of instruments. The rhythm's what's important.\" The use of amplified guitars accentuates Wills's claim; some Bob Wills recordings from the 1930s and 1940s sound similar to rock and roll records of the 1950s.\n\nEven a 1958 return to KVOO, where his younger brother Johnnie Lee Wills had maintained the family's presence, did not produce the success he hoped for. He appeared twice on ABC-TV's \"Jubilee USA\" and kept the band on the road into the 1960s. After two heart attacks, in 1965 he dissolved the Texas Playboys (who briefly continued as an independent unit) to perform solo with house bands. While he did well in Las Vegas and other areas, and made records for the Kapp Records label, he was largely a forgotten figure—even though inducted into the Country Music Hall of Fame in 1968. A 1969 stroke left his right side paralyzed, ending his active career.\n\nMay 26, 1975 issue of \"TIME\" (Milestones section) read: \"Died. Bob Wills, 70, \"Western Swing\" bandleader-composer; of pneumonia; in Fort Worth. Wills turned out dance tunes that are now called country rock, introducing with his Texas Playboys such C & W classics as Take Me Back to Tulsa and New San Antonio Rose\".\n\nWills' style influenced performers Buck Owens and Merle Haggard and helped to spawn a style of music now known as the Bakersfield Sound. (Bakersfield, California was one of Wills' regular stops in his heyday). A 1970 tribute album by Haggard directed a wider audience to Wills' music, as did the appearance of younger \"revival\" bands like Asleep at the Wheel and the growing popularity of longtime Wills disciple and fan Willie Nelson. By 1971, Wills recovered sufficiently to travel occasionally and appear at tribute concerts. In 1973 he participated in a final reunion session with members of some the Texas Playboys from the 1930s to the 1960s. Merle Haggard was invited to play at this reunion. The session, scheduled for two days, took place in December 1973, with the album to be titled \"For The Last Time\". Wills, speaking or attempting to holler, appeared on a couple tracks from the first day's session but suffered a stroke overnight. He had a more severe one a few days later. The musicians completed the album without him. Wills by then was comatose. He lingered until his death on May 13, 1975.\n\nIn addition to being inducted into the Country Music Hall of Fame in 1968, Wills was inducted into the Nashville Songwriters Hall of Fame in 1970, the Rock and Roll Hall of Fame in the Early Influence category along with the Texas Playboys in 1999, and received the Grammy Lifetime Achievement Award in 2007.\n\nFrom the 1970s until his 2002 death, Waylon Jennings performed a song called \"Bob Wills Is Still The King\". In addition, The Rolling Stones performed this song live in Austin, Texas at Zilker Park for their DVD \"The Biggest Bang\". In a 1968 issue of \"Guitar Player\", rock guitarist Jimi Hendrix said of Wills and the Playboys: \"I dig them. The Grand Ole Opry used to come on, and I used to watch that. They used to have some pretty heavy cats, some heavy guitar players.\"\n\nWills ranked #27 in \"CMT's 40 Greatest Men In Country Music\" in 2003.\n\nWills' upbeat 1938 song Ida Red was Chuck Berry's primary inspiration for creating his first Rock and Roll hit - Maybellene.\n\nFats Domino once remarked that he patterned his 1960 rhythm section after that of Bob Wills.\n\nDuring the 49th Grammy Awards in 2007, Carrie Underwood performed his song \"San Antonio Rose\". Today, George Strait performs Wills' music on concert tours and also records songs influenced by Wills and his Texas-style swing.\n\nThe Austin-based Western swing band Asleep at the Wheel have honored Wills' music since the band's inception, mostly notably with their continuing performances of the musical drama \"A Ride With Bob\", which debuted in Austin in March 2005 to coincide with celebrations of Wills' 100th birthday.\n\nThe Bob Wills Birthday Celebration is held every year in March at the Cain's Ballroom in Tulsa, Oklahoma with a Western swing concert and dance.\n\nIn 2004, a documentary film about his life and music, entitled \"Fiddlin' Man: The Life And Times Of Bob Wills\", was released by VIEW Inc.\n\nOn October 26, 2006, The Rolling Stones performed the Waylon Jennings-penned \"Bob Wills Is Still the King\" at Zilker Park in Austin, Texas\n\nIn 2011, Proper Records released an album by Hot Club of Cowtown titled \"What Makes Bob Holler: A Tribute To Bob Wills And His Texas Playboys\".\n\nIn 2011, the Texas Legislature adopted a resolution designating western swing as the official \"State Music Of Texas\".\n\nOn February 9, 2014, the 80th Anniversary of Bob Wills' first performance at the Cain's Ballroom in Tulsa, Oklahoma, the Oklahoma Historical Society and the Oklahoma Museum of Popular Culture (OKPOP) announced plans to create a feature-length documentary about the life and music of Bob Wills. The documentary will be titled \"Still the King. Bob Wills: The Man. The Music.\" \n\n\n\n"}
{"id": "4834", "url": "https://en.wikipedia.org/wiki?curid=4834", "title": "Badtrans", "text": "Badtrans\n\nBadTrans is a malicious Microsoft Windows computer worm distributed by e-mail. Because of a known vulnerability in older versions of Internet Explorer, some e-mail programs, such as Microsoft's Outlook Express and Microsoft Outlook programs, may install and execute the worm as soon as the e-mail message is viewed.\n\nOnce executed, the worm replicates by sending copies of itself to other e-mail addresses found on the host's machine, and installs a keystroke logger, which then captures everything typed on the affected computer. Badtrans then transmits the data to one of several e-mail addresses. \n\nAmong the e-mail addresses that received the keyloggers were free addresses at Excite, Yahoo, and IJustGotFired.com. IJustGotFired is a free service of MonkeyBrains, a San Francisco-based Internet service provider.\nThe target address at IJustGotFired began receiving e-mails at 3:23pm on November 24, 2001. Once the account exceeded its quotas, it was automatically disabled, but the messages were still saved as they arrived. The address received over 100,000 keylogs in the first day alone.\n\nIn mid-December, the FBI contacted Rudy Rucker, Jr., owner of MonkeyBrains, and requested a copy of the keylogged data. All of that data was stolen from the victims of the worm; it includes no information about the creator of Badtrans.\nInstead of complying with the FBI request, MonkeyBrains published a database website http://badtrans.monkeybrains.net for the public to determine if a given address has been compromised. The database does not reveal the actual passwords or keylogged data.\n"}
{"id": "4836", "url": "https://en.wikipedia.org/wiki?curid=4836", "title": "Barış Manço", "text": "Barış Manço\n\nMehmet Barış Manço (born Tosun Yusuf Mehmet Barış Manço; 2 January 1943 – 1 February 1999), known by his stage name Barış Manço, was a Turkish rock musician, singer, songwriter, composer, actor, television producer and show host. Beginning his musical career while attending Galatasaray High School, he was a pioneer of rock music in Turkey and one of the founders of the Anatolian rock genre. Manço composed around 200 songs and is among the best-selling and most awarded Turkish artists to date. Many of his songs were translated into a variety of languages including English, French, Japanese, Greek, Italian, Bulgarian, Romanian, Persian, Hebrew, Urdu, Arabic, and German, among others. Through his TV program, \"7'den 77'ye\" (\"\"From 7 to 77\"\"), Manço traveled the world and visited most countries on the globe. He remains one of the most popular public figures of Turkey.\n\nBarış Manço was born in Üsküdar, Istanbul, Turkey on 2 January 1943. His mother, Rikkat Uyanık, was a famous singer in the early 1940s. His older brother, who was born during World War II, was named Savaş (\"war\" in Turkish) while he was named Barış (\"peace\" in Turkish) by his parents to celebrate the end of the war. At birth, he was additionally named Tosun Yusuf after his deceased uncle Yusuf called Tosun (literally: Joseph the Sturdy). However, this name was erased just before he attended the primary school.\n\nIn primary school his head was shaven to prevent head lice, a serious threat back then, which he cited among reasons for his later signature long hair.\n\nDuring his highschool days in Galatasaray High School (and later in Şişli Terakki High School) he formed his first band, Kafadarlar (\"The Buddies\"), allegedly upon seeing Erkin Koray's band performing, all students of Deutsche Schule Istanbul (\"İstanbul Alman Lisesi\"), a nearby highschool. Prof. Dr. Asaf Savaş Akat, a famous economist in Turkey, played saxophone, and guitarist Ender Enön made his own guitar because it was difficult to find a real one on the market in those years.\n\nIn 1962 and 1963, with his next band, Harmoniler (\"The Harmonies\"), he recorded cover versions of some of popular American twist songs and rearrangements of Turkish folk songs in rock and roll form, marking the beginning of the Anatolian rock movement, a synthesis of Turkish folk music and rock. In this period, his key visual and musical influence was Elvis Presley.\n\nAfter graduating from high school in 1963, he moved to Europe, travelling around Paris and Liège, where he formed bands with local musicians and recorded some singles mainly in English and in French but also in Turkish. Then, in 1964, Barış Manço continued his studies at the Royal Academy of Fine Arts in Liège, Belgium. He toured with his band Les Mistigris (not related to Mistigris) in Germany, Belgium, France and Turkey until 1967.\n\nIn 1967, he suffered a serious car accident, after which he started to grow his signature mustache to disguise his scar.\n\nFrustrated by the difficulties of working with musicians from different nationalities, he formed Kaygısızlar (The Carefrees), featuring Mazhar Alanson and Fuat Güner, future members of the band MFÖ. He recorded several singles and toured with the band, both domestically and internationally, until the band members revealed that they did not want to live abroad.\n\nIn 1970, he formed Barış Manço Ve ... (\"Barış Manço and ...\") again with foreign musicians, to record his first hit single, both in Turkey and in Belgium, \"Dağlar Dağlar\" (Mountains, Mountains!), selling over 700,000 copies. Today, the song remains one of his most popular works.\n\nAfter the success of \"Dağlar Dağlar\", Manço recorded a couple of singles with Moğollar (The Mongols), another influential Turkish Anatolian rock band. He then decided to return to Turkey where he recorded with the reformed Kaygısızlar for a short period. In 1971, his early works were compiled under his first full-length album \"Dünden Bugüne\", today commonly referred as \"Dağlar Dağlar\".\n\nIn 1972, he formed Kurtalan Ekspres, a legend by itself, the band that would accompany him until his death. In 1975 until when he continued to release singles, he released his first non-compilation LP \"2023\", a concept album that includes many instrumental songs.\n\nAs a last attempt to reach international success, he released the LP titled \"Baris Mancho\" (1976), a strange transcription of his name, mostly with George Hayes Orchestra under CBS Records label, in Europe and South Africa. Although the album did not bring the fame he was expecting, it did reach the top of the charts in Romania and Morocco. The following year, the album was released in Turkey under the title \"Nick the Chopper\". In 1975 he starred in the movie Baba Bize Eversene (Father make us marry) which is the only movie he ever starred during his career. The music of the movie consists of a compilation of tracks composed by Barış Manço and Kurtalan Ekspres.\n\nFrom 1977 to 1980, he released three more albums in Turkey, partly consisting of compilations of older singles, namely \"Sakla Samanı Gelir Zamanı\" (1977), \"Yeni Bir Gün\" (1979) and \"20. Sanat Yılı Disko Manço\" (1980), all following a similar sound with \"2023\". All these albums are now rarity items, but most of the material from the era are available in later compilations \"Ben Bilirim\" and \"Sarı Çizmeli Mehmet Ağa\".\n\nIn 1981, Manço released \"Sözüm Meclisten Dışarı\" with Kurtalan Ekspres, containing many hit songs including \"Alla Beni Pulla Beni\", \"Arkadaşım Eşek\", \"Gülpembe\", \"Halhal\" and \"Dönence\" among others. The album remains as one of their most popular works and launched a boost of popularity for Barış Manço during the 1980s.\n\n\"Arkadaşım Eşek\" (\"My Friend Donkey\"), quickly grew very popular among children (the song is about rural nostalgia and was not initially intended as a children's song). Throughout his career, he went on to write many other songs primarily for children to achieve an iconic acceptance among Turkish children of the 1980s and 1990s.\n\nOn the other hand, \"Gülpembe\", composed by Kurtalan Ekspres bassist Ahmet Güvenç, a requiem for Manço's grandmother, caught older audiences and probably is the artist's most popular song, competing perhaps only with \"Dağlar Dağlar\".\n\nIn 1983, \"Estağfurullah, Ne Haddimize\" was released. It contained hit songs \"Halil İbrahim Sofrası\" and \"Kol Düğmeleri\", a new version of the artist's first song. \"Halil İbrahim Sofrası\" exemplified Manço's signature moral themed lyrics, a rare feature in Turkish pop music.\n\nIn 1985, \"24 Ayar Manço\" which included \"Gibi Gibi\" and a long conceptual song \"Lahburger\" was released. It also marked the beginning of the shift in Manço's sound characterized with the heavy use of synthesizers and drum machine in contrast with his older works consisting of a group oriented rock based sound. In subsequent years, Manço released \"Değmesin Yağlı Boya\" (1986), \"Sahibinden İhtiyaçtan\" (1988) and \"Darısı Başınıza\" (1989), all containing a couple of hit songs and demonstrating his new sound.\n\nIn 1988, \"7'den 77'ye\" (\"From 7 to 77\"), a TV show directed and presented by Manço, began to run on TRT 1, the Turkish state television channel. It was a combined music, talk show, and documentary program which was a major hit during the eight years it stayed on air. Manço traveled to almost 150 countries for the show. \"Adam Olacak Çocuk\", a part of the show, strengthened Manço's acceptance among children.\n\nAlthough his popularity continued mostly due to the TV show, his musical works in the 1990s were not well received. The albums \"Mega Manço\" (1992) and \"Müsadenizle Çocuklar\" (1995) were considered as the weakest efforts of his career, despite the limited success of 1992 children hit \"Ayı\" (The Bear). On the other hand, in 1995 he toured in Japan with Kurtalan Ekspres, leading to \"Live In Japan\" (1996), his only live album. He released two albums in that country with some recognition as \"the man who writes songs about vegetables\", referring to \"Domates, Biber, Patlıcan\" (\"Tomato, Pepper, Aubergine\") and \"Nane, Limon Kabuğu\" (Mint, Lemon Rind), two of his hit songs from the 1980s.\n\nOn 1 February 1999, Barış Manço died of a sudden heart attack before the release of his just finished last work \"Mançoloji\" (\"Mançology\" or \"Manchology\") (1999), a double album containing the new recordings of his hit songs along with an unfinished instrumental song \"40. Yıl\" (\"The 40th Anniversary\"), celebrating his 40th year in music. His sudden death caused an almost unanimous shock in Turkey with millions of people mourning and tens of thousands of people attending his funeral.\n\nHe was interred at Kanlıca Cemetery in Istanbul.\n\nBarış Manço was one of the most influential Turkish musicians. In his early career he and his bands contributed to the Turkish rock movement by combining traditional Turkish music with rock influences, which is still one of the main trends of Turkish popular music.\n\nHis visual image, characterized by his long hair, mustache and big rings, softened the reaction of the otherwise conservative Turkish public opinion.\n\nManço pioneered the progressive rock-influenced Anatolian rock movement in the 1970s. His experimentation with electronic instruments in the late 1980s contributed to the 1990s sound of Turkish popular music.\n\nHis lyrics with diverse themes, mostly following a somewhat modernized version of the \"aşık\" (wandering folk poets) tradition were heavily marginal in the popular music scene of the 1980s which was mostly dominated by love-themed lyrics.\n\nIn 2002, a tribute album was released under the name \"Yüreğimdeki Barış Şarkıları\" (\"Songs of Barış (Peace) In My Heart\"), featuring 15 popular Turkish artists of such diverse genres like arabesque, pop and rock (both Anatolian and western style) demonstrating his wide range of influence.\n\n\nWith Harmoniler\n\nWith Jacques Denjean Orchestra\n\nWith Les Mistigris\n\nWith Kaygısızlar\nWith \"Barış Manço Ve'\n\nWith Moğollar\n\nWith Moğollar / Kaygısızlar\n\nWith Kaygısızlar / Les Mistigris\n\nWith Kurtalan Ekspres\n\nWith George Hayes Orchestra / Kurtalan Ekspres\n\nWith Kurtalan Ekspres\n\n\n"}
{"id": "4840", "url": "https://en.wikipedia.org/wiki?curid=4840", "title": "Blitz BASIC", "text": "Blitz BASIC\n\nBlitz BASIC refers to the programming language dialect that was interpreted by the first Blitz compilers, devised by New Zealand-based developer Mark Sibly. Being derived from BASIC, Blitz syntax was designed to be easy to pick up for beginners first learning to program. The languages are game-programming oriented but are often found general-purpose enough to be used for most types of application. The Blitz language evolved as new products were released, with recent incarnations offering support for more advanced programming techniques such as object-orientation and multi-threading. This led to the languages losing their BASIC moniker in later years.\n\nThe first iteration of the Blitz language was created for the Amiga platform and published by the Australian firm Memory and Storage Technology. Returning to New Zealand, Blitz BASIC 2 was published several years later by Acid Software (a local Amiga game publisher). Since then, Blitz compilers have been released on several platforms. Following the demise of the Amiga as a commercially viable platform, the Blitz BASIC 2 source code was released to the Amiga community. Development continues to this day under the name AmiBlitz.\n\nIdigicon published BlitzBasic for Microsoft Windows in October 2000. The language included a built-in API for performing basic 2D graphics and audio operations. Following the release of Blitz3D, BlitzBasic is often synonymously referred to as Blitz2D.\n\nRecognition of BlitzBasic increased when a limited range of \"free\" versions were distributed in popular UK computer magazines such as PC Format. This resulted in a legal dispute between the developer and publisher which was eventually resolved amicably.\n\nBlitz3D was released for Microsoft Windows in September 2001, competing with other similar PC game-development languages of the time (such as Dark Basic). Blitz3D extended BlitzBasic's command-set with the inclusion of an API for a DirectX 7-based 3D engine.\n\nAlthough originally Blitz3D's distribution rights were owned by Idigicon, Blitz Research Ltd. later signed a deal with the firm so as to allow Blitz Research Ltd. to distribute Blitz3D themselves. In return, Idigicon were granted full rights to distribute BlitzBasic and to clear any outstanding stock copies of Blitz3D.\n\nIn February 2003, Blitz Research Ltd. released BlitzPlus also for Microsoft Windows. It lacked the 3D engine of Blitz3D, but did bring new features to the 2D side of the language by implementing limited Microsoft Windows control support for creating native GUIs. Backwards compatibility of the 2D engine was also extended, allowing compiled BlitzPlus games and applications to run on systems that might only have DirectX 1.\n\nThe first BlitzMax compiler was released in December 2004 for Mac OS X. This made it the first Blitz dialect that could be compiled on *nix platforms. Compilers for Microsoft Windows and Linux were subsequently released in May 2005. BlitzMax brought the largest change of language structure to the modern range of Blitz products by extending the type system to include object-oriented concepts and modifying the graphics API to better suit OpenGL. BlitzMax was also the first of the Blitz languages to represent strings internally using UCS2, allowing native-support for string literals composed of non-ASCII characters.\n\nBlitzMax's platform-agnostic command-set allows developers to compile and run source code on multiple platforms. However the official compiler and build chain will only generate binaries for the platform that it is executing on. Unofficially, users have been able to get Linux and Mac OS X to cross-compile to the Windows platform.\n\nBlitzMax is also the first modular version of the Blitz languages, improving the extensibility of the command-set. In addition, all of the standard modules shipped with the compiler are open-source and so can be tweaked and recompiled by the programmer if necessary. The official BlitzMax cross-platform GUI module (known as MaxGUI) allows developers to write GUI interfaces for their applications on Linux (FLTK), Mac (Cocoa) and Windows. Various user-contributed modules extend the use of the language by wrapping such libraries as wxWidgets, Cairo, and Fontconfig as well as a selection of database modules. There are also a selection of third-party 3D modules available namely MiniB3D - an open-source OpenGL engine which can be compiled and used on all three of BlitzMax's supported platforms.\n\nIn October 2007, BlitzMax 1.26 was released which included the addition of a reflection module. BlitzMax 1.32 shipped new threading and Lua scripting modules and most of the standard library functions have been updated so that they are unicode friendly.\n\nBlitz3D SDK is a 3D graphics engine based on the engine in Blitz3D. It was marketed for use with C++, C#, BlitzMax and PureBasic, however it could also be used with other languages that follow compatible calling conventions. As of January 2011, Blitz3D SDK is no longer listed for sale on the official Blitz website.\n\nIn 2008, the source code to Max3D - a C++-based cross-platform 3D engine - was released under a BSD license. This engine focused on OpenGL but had an abstract backend for other graphics drivers (such as DirectX) and made use of several open-source libraries, namely Assimp, Boost and ODE.\n\nDespite the excitement in the Blitz community of Max3D being the eagerly awaited successor to Blitz3D, interest and support died off soon after the source code was released and eventually development came to a halt. There is no indication that Blitz Research will pick up the project again.\n\nBlitzPlus was released as Open Source on 28 April 2014 under the zlib license on github.com. Blitz3D follow on August 3, 2014. Also BlitzMax was released as Open Source on 21 September 2015 on github.\n\nThe following code creates a windowed application that shows the current time in binary and decimal format. This code is written in BlitzBasic, but will compile and run in both Blitz3D and BlitzPlus. See below for the same example written in BlitzMax.\n\n\nIn 2011, BRL released a new cross-platform programming language called Monkey and its first official module called Mojo. Monkey has a similar syntax to BlitzMax, but instead of compiling direct to assembly code, it translates Monkey source files directly into source code for a chosen language, framework or platform e.g. Windows, Mac OS X, iOS, Android, HTML5, and Flash.\n\n\n"}
{"id": "4842", "url": "https://en.wikipedia.org/wiki?curid=4842", "title": "Bliss bibliographic classification", "text": "Bliss bibliographic classification\n\nThe Bliss bibliographic classification (BC) is a library classification system that was created by Henry E. Bliss (1870–1955) and published in four volumes between 1940 and 1953. Although originally devised in the United States, it was more commonly adopted by British libraries. A second edition of the system (BC2) has been in ongoing development in Britain since 1977.\n\nHenry E. Bliss began working on the Bliss Classification system while working at the City College of New York Library as Assistant Librarian. He was a critic of Melvil Dewey's work with the Dewey Decimal System and believed that organization of titles needed to be done with an intellectual mind frame. Being overly pragmatic or simply alphabetical, would be inadequate. In fact, Bliss is the only theorist who created an organizational scheme based on societal needs. Bliss wanted a classification system that would provide distinct rules yet still be adaptable to whatever kind of collection a library might have, as different libraries have different needs. His solution was the concept of \"alternative location,\" in which a particular subject could be put in more than one place, as long as the library made a specific choice and used it consistently.\n\nBliss discusses his theories and basis of organization for the Bliss Classification for the first time in his 1910 article, \"A Modern Classification for Libraries, with Simple Notation, Mnemonics, and Alternatives\". This publication followed his 1908 reclassification of the City College collection. His work, \"Organization of Knowledge and the System of the Sciences\" was published in four volumes between 1940 and 1953.\n\nThe four broad underlying policies of the BC system are: \nBliss deliberately avoided the use of the decimal point because of his objection to Dewey's system. Instead he used capital and lower-case letters, numerals, and every typographical symbol available on his extensive and somewhat eccentric typewriter.\n\nIn 1967 the Bliss Classification Association was formed. Its first publication was the Abridged Bliss Classification (ABC), intended for school libraries. In 1977 it began to publish and maintain a revised version of Bliss's system, the Bliss Bibliographic Classification (Second Edition) or BC2. This retains only the broad outlines of Bliss's scheme, replacing most of the detailed notation with a new scheme based on the principles of faceted classification. 15 of approximately 28 volumes of schedules have so far been published. A revision of this nature has been considered by some to be a completely new system.\n\nThe City College library continued to use Bliss's system until 1967, when it switched to the Library of Congress system. It had become too expensive to train new staff members to use BC, and too expensive to maintain in general. Much of the Bliss stacks remain, however, as no-one has re-cataloged the books.\n\nThe case was different, however, in Britain. BC proved more popular there and also spread to other English-speaking countries. Part of the reason for its success was that libraries in teachers’ colleges liked the way Bliss had organized the subject areas on teaching and education. By the mid-1950s the system was being used in at least sixty British libraries and in a hundred by the 1970s The Bliss Classification system has been found to be successful in academic, specialty, government, and law libraries. It has also found success in libraries outside of the United States of America, as many of these libraries do not have a history of using either the Dewey Decimal, or the Library of Congress classification system.\n\nThe Bliss Classification system has been found to be successful in academic, specialty, government, and law libraries. It has also found success in libraries outside of the United States of America, as many of these libraries do not have a history of using either the Dewey Decimal, or the Library of Congress classification system.\n\nThe general organizational pattern for classifying titles in the BC2 method are:\n\nThe Class Schedule is:\n\n\n\n\n"}
{"id": "4845", "url": "https://en.wikipedia.org/wiki?curid=4845", "title": "Blood alcohol content", "text": "Blood alcohol content\n\nBlood alcohol content (BAC), also called blood alcohol concentration, blood ethanol concentration, or blood alcohol level, is most commonly used as a metric of alcohol intoxication for legal or medical purposes. \n\nBlood alcohol concentration is usually expressed as a percentage of ethanol in the blood in units of mass of alcohol per volume of blood or mass of alcohol per mass of blood, depending on the country. For instance, in North America a BAC of 0.1 (0.1% or one tenth of one percent) means that there are 0.10 g of alcohol for every dL of blood.\n\nTo calculate estimated peak blood alcohol concentration (EBAC), a variation, including drinking period in hours, of the Widmark formula was used. The formula is:\n\nwhere :\nRegarding metabolism (MR) in the formula; Females demonstrated a higher average rate of elimination (mean, 0.017; range, 0.014-0.021 g/210 L) than males (mean, 0.015; range, 0.013-0.017 g/210 L). Female subjects on average had a higher percentage of body fat (mean, 26.0; range, 16.7-36.8%) than males (mean, 18.0; range, 10.2-25.3%). Additionally, men are, on average, heavier than women but it is not strictly accurate to say that the water content of a person alone is responsible for the dissolution of alcohol within the body, because alcohol does dissolve in fatty tissue as well. When it does, a certain amount of alcohol is temporarily taken out of the blood and briefly stored in the fat. For this reason, most calculations of alcohol to body mass simply use the weight of the individual, and not specifically his/her water content. Finally, it is speculated that the bubbles in sparkling wine may speed up alcohol intoxication by helping the alcohol to reach the bloodstream faster. A study conducted at the University of Surrey in the United Kingdom gave subjects equal amounts of flat and sparkling wines which contained the same levels of alcohol. After 5 minutes following consumption, the group that had the sparkling wine had 54 milligrams of alcohol in their blood while the group that had the same sparkling wine, only flat, had 39 milligrams.\n\nExamples:\n\nNote: This chart defines a drink as 14g of ethanol, while the formula defines a drink as 10g of ethanol.\n\nStandard Drink Sizes (Australia)\n\nThe National Institute on Alcohol Abuse and Alcoholism (NIAAA) define the term \"binge drinking\" as a pattern of drinking that brings a person’s blood alcohol concentration (BAC) to 0.08 grams percent or above. This typically happens when men consume 5 or more drinks, and when women consume 4 or more drinks, in about 2 hours.\n\nThere are several different units in use around the world for defining blood alcohol concentration. Each is defined as either a mass of alcohol per volume of blood or a mass of alcohol per mass of blood (never a volume per volume). 1 milliliter of blood has a mass of approximately 1.06 grams. Because of this, units by volume are similar but not identical to units by mass. In the U.S. the concentration unit 1% w/v (percent mass/volume, equivalent to 10 g/l or 1 g per 100 ml) is in use. This is not to be confused with the amount of alcohol measured on the breath, as with a breathalyzer. The amount of alcohol measured on the breath is generally accepted as proportional to the amount of alcohol present in the blood at a rate of 1:2100. Therefore, a breathalyzer measurement of 0.10 mg/L of breath alcohol converts to 0.0001×2100 g/10dL, or 0.021 g/dL of blood alcohol (the units of the BAC in the United States). While a variety of units (or sometimes lack thereof) is used throughout the world, many countries use the g/L unit, which does not create confusion as percentages do. Usual units are highlighted in the table below.\n\nFor purposes of law enforcement, blood alcohol content is used to define intoxication and provides a rough measure of impairment. Although the degree of impairment may vary among individuals with the same blood alcohol content, it can be measured objectively and is therefore legally useful and difficult to contest in court. Most countries disallow operation of motor vehicles and heavy machinery above prescribed levels of blood alcohol content. Operation of boats and aircraft are also regulated.\n\nThe alcohol level at which a person is considered legally impaired varies by country. The list below gives limits by country. These are typically blood alcohol content limits for the operation of a vehicle.\n\nIt is illegal to have any measurable alcohol in the blood while driving in these countries. Most jurisdictions have a tolerance slightly higher than zero to account for false positives and naturally occurring alcohol in the body. Some of the following jurisdictions have a general prohibition of alcohol.\n\n\n\n\n\n\n\n\n\nIn certain countries, alcohol limits are determined by the breath alcohol content (BrAC), not to be confused with blood alcohol content (BAC).\n\n\nBlood alcohol tests assume the individual being tested is average in various ways. For example, on average the ratio of blood alcohol content to breath alcohol content (the \"partition ratio\") is 2100 to 1. In other words, there are 2100 parts of alcohol in the blood for every part in the breath. However, the actual ratio in any given individual can vary from 1300:1 to 3100:1, or even more widely. This ratio varies not only from person to person, but within one person from moment to moment. Thus a person with a true blood alcohol level of .08% but a partition ratio of 1700:1 at the time of testing would have a .10 reading on a Breathalyzer calibrated for the average 2100:1 ratio.\n\nA similar assumption is made in urinalysis. When urine is analyzed for alcohol, the assumption is that there are 1.3 parts of alcohol in the urine for every 1 part in the blood, even though the actual ratio can vary greatly.\n\nBreath alcohol testing further assumes that the test is \"post-absorptive\"—that is, that the absorption of alcohol in the subject's body is complete. If the subject is still actively absorbing alcohol, their body has not reached a state of \"equilibrium\" where the concentration of alcohol is uniform throughout the body. Most forensic alcohol experts reject test results during this period as the amounts of alcohol in the breath will not accurately reflect a true concentration in the blood.\n\nAlcohol is absorbed throughout the gastrointestinal tract, but more slowly in the stomach than in the small or large intestine. For this reason, alcohol consumed with food is absorbed more slowly, because it spends a longer time in the stomach. Furthermore, alcohol dehydrogenase is present in the stomach lining. After absorption, the alcohol passes to the liver through the hepatic portal vein, where it undergoes a first pass of metabolism before entering the general bloodstream.\n\nAlcohol is removed from the bloodstream by a combination of metabolism, excretion, and evaporation. The relative proportion disposed of in each way varies from person to person, but typically about 95% is metabolized by the liver. The remainder of the alcohol is eliminated through excretion in breath, urine, sweat, feces, milk and saliva. Excretion into urine typically begins after about 40 minutes, whereas metabolisation commences as soon as the alcohol is absorbed, and even before alcohol levels have risen in the brain.\n\nAlcohol is metabolized mainly by the group of six enzymes collectively called alcohol dehydrogenase. These convert the ethanol into acetaldehyde (an intermediate more toxic than ethanol). The enzyme acetaldehyde dehydrogenase then converts the acetaldehyde into non-toxic acetic acid.\n\nMany physiologically active materials are removed from the bloodstream (whether by metabolism or excretion) at a rate proportional to the current concentration, so that they exhibit exponential decay with a characteristic halflife (see pharmacokinetics). This is not true for alcohol, however. Typical doses of alcohol actually saturate the enzymes' capacity, so that alcohol is removed from the bloodstream at an approximately constant rate. This rate varies considerably between individuals. Another sex based difference is in the elimination of alcohol. People under 25, women or with liver disease may process alcohol more slowly. False High (BAC) readings are related to patients with proteinuria and hematuria, due to kidney-liver metabolism and failure (for example, Hematuria 1+ protenuria 1+ )\n\nSuch persons have impaired acetaldehyde dehydrogenase, which causes acetaldehyde levels to peak higher, producing more severe hangovers and other effects such as flushing and tachycardia. Conversely, members of certain ethnicities that traditionally did not use alcoholic beverages have lower levels of alcohol dehydrogenases and thus \"sober up\" very slowly, but reach lower aldehyde concentrations and have milder hangovers. Rate of detoxification of alcohol can also be slowed by certain drugs which interfere with the action of alcohol dehydrogenases, notably aspirin, furfural (which may be found in fusel alcohol), fumes of certain solvents, many heavy metals, and some pyrazole compounds. Also suspected of having this effect are cimetidine (Tagamet), ranitidine (Zantac), and acetaminophen (Tylenol) (paracetamol).\n\nCurrently, the only known substance that can increase the rate of metabolism of alcohol is fructose. The effect can vary significantly from person to person, but a 100 g dose of fructose has been shown to increase alcohol metabolism by an average of 80%. Fructose also increases false positives of high BAC ratio readings in anyone with proteinuria and hematuria, due to kidney-liver metabolism.\n\nAlcohol absorption can be slowed by ingesting alcohol on a full stomach.\n\nAlcohol in carbonated beverages is absorbed faster than alcohol in non-carbonated drinks. Another study also confirmed this, conducted at the University of Surrey in the United Kingdom gave subjects equal amounts of flat and sparkling champagne which contained the same levels of alcohol. After 5 minutes following consumption, the group that had the sparkling wine had 54 milligrams of alcohol in their blood while the group that had the same wine, only flat, had 39 milligrams.\n\nBeing under stress causes alcohol to metabolize faster.\n\nRetrograde extrapolation is the mathematical process by which someone's blood alcohol concentration at the time of driving is estimated by projecting backwards from a later chemical test. This involves estimating the absorption and elimination of alcohol in the interim between driving and testing. The rate of elimination in the average person is commonly estimated at .015 to .020 grams per deciliter per hour (g/dl/h), although again this can vary from person to person and in a given person from one moment to another. Metabolism can be affected by numerous factors, including such things as body temperature, the type of alcoholic beverage consumed, and the amount and type of food consumed.\n\nIn an increasing number of states, laws have been enacted to facilitate this speculative task: the blood alcohol content at the time of driving is legally presumed to be the same as when later tested. There are usually time limits put on this presumption, commonly two or three hours, and the defendant is permitted to offer evidence to rebut this presumption.\n\nForward extrapolation can also be attempted. If the amount of alcohol consumed is known, along with such variables as the weight and sex of the subject and period and rate of consumption, the blood alcohol level can be estimated by extrapolating forward. Although subject to the same infirmities as retrograde extrapolation—guessing based upon averages and unknown variables—this can be relevant in estimating BAC when driving and/or corroborating or contradicting the results of a later chemical test.\n\nThere have been reported cases of blood alcohol content higher than 1%:\n\n\n"}
{"id": "4848", "url": "https://en.wikipedia.org/wiki?curid=4848", "title": "Barrister", "text": "Barrister\n\nA barrister (also known as barrister-at-law or bar-at-law) is a type of lawyer in common law jurisdictions. Barristers mostly specialise in courtroom advocacy and litigation. Their tasks include taking cases in superior courts and tribunals, drafting legal pleadings, researching the philosophy, hypothesis and history of law, and giving expert legal opinions. Often, barristers are also recognised as \"legal scholars\".\n\nBarristers are distinguished from solicitors, who have more direct access to clients, and may do transactional-type legal work. It is mainly barristers who are appointed as judges, and they are rarely hired by clients directly. In some legal systems, including those of Scotland, South Africa, Scandinavia, Pakistan, India, Bangladesh, and the British Crown dependencies of Jersey, Guernsey and the Isle of Man, the word barrister is also regarded as an honorific title.\n\nIn a few jurisdictions, barristers are usually forbidden from \"conducting\" litigation, and can only act on the instructions of a senior solicitor, who performs tasks such as corresponding with parties and the court, and drafting court documents. In England and Wales, barristers may seek authorisation from the Bar Standards Board to conduct litigation. This allows a barrister to practise in a 'dual capacity', fulfilling the role of both barrister and solicitor.\n\nIn some countries with common law legal systems, such as New Zealand and some regions of Australia, lawyers are entitled to practise both as barristers and solicitors, but it remains a separate system of qualification to practise exclusively as a barrister.\n\nA barrister, who can be considered as a jurist, is a lawyer who represents a litigant as advocate before a court of appropriate jurisdiction. A barrister speaks in court and presents the case before a judge or jury. In some jurisdictions, a barrister receives additional training in evidence law, ethics, and court practice and procedure. In contrast, a solicitor generally meets with clients, does preparatory and administrative work and provides legal advice. In this role, he or she may draft and review legal documents, interact with the client as necessary, prepare evidence, and generally manage the day-to-day administration of a lawsuit. A solicitor can provide a crucial support role to a barrister when in court, such as managing large volumes of documents in the case or even negotiating a settlement outside the courtroom while the trial continues inside.\n\nThere are other essential differences. A barrister will usually have rights of audience in the higher courts, whereas other legal professionals will often have more limited access, or will need to acquire additional qualifications to have such access. As in common law countries in which there is a split between the roles of barrister and solicitor, the barrister in civil law jurisdictions is responsible for appearing in trials or pleading cases before the courts.\n\nBarristers usually have particular knowledge of case law, precedent, and the skills to \"build\" a case. When a solicitor in general practice is confronted with an unusual point of law, they may seek the \"opinion of counsel\" on the issue.\n\nIn most countries, barristers operate as sole practitioners, and are prohibited from forming partnerships or from working as a barrister as part of a corporation. (In 2009, the Clementi Report recommended the abolition of this restriction in England and Wales.) However, barristers normally band together into \"chambers\" to share clerks (administrators) and operating expenses. Some chambers grow to be large and sophisticated, and have a distinctly corporate feel. In some jurisdictions, they may be employed by firms of solicitors, banks, or corporations as in-house legal advisers.\n\nIn contrast, solicitors and attorneys work directly with the clients and are responsible for engaging a barrister with the appropriate expertise for the case. Barristers generally have little or no direct contact with their 'lay clients', particularly without the presence or involvement of the solicitor. All correspondence, inquiries, invoices, and so on, will be addressed to the solicitor, who is primarily responsible for the barrister's fees.\n\nIn court, barristers are often visibly distinguished from solicitors by their apparel. For example, in Ireland, England, and Wales, a barrister usually wears a horsehair wig, stiff collar, bands, and a gown. Since January 2008, solicitor advocates have also been entitled to wear wigs, but wear different gowns.\n\nIn many countries the traditional divisions between barristers and solicitors are breaking down. Barristers once enjoyed a monopoly on appearances before the higher courts, but in Great Britain this has now been abolished, and solicitor advocates can generally appear for clients at trial. Increasingly, firms of solicitors are keeping even the most advanced advisory and litigation work in-house for economic and client relationship reasons. Similarly, the prohibition on barristers taking instructions directly from the public has also been widely abolished. But, in practice, direct instruction is still a rarity in most jurisdictions, partly because barristers with narrow specializations, or who are only really trained for advocacy, are not prepared to provide general advice to members of the public.\n\nHistorically, barristers have had a major role in trial preparation, including drafting pleadings and reviewing evidence. In some areas of law, that is still the case. In other areas, it is relatively common for the barrister to receive the brief from the instructing solicitor to represent a client at trial only a day or two before the proceeding. Part of the reason for this is cost. A barrister is entitled to a 'brief fee' when a brief is delivered, and this represents the bulk of her/his fee in relation to any trial. They are then usually entitled to a 'refresher' for each day of the trial after the first. But if a case is settled before the trial, the barrister is not needed and the brief fee would be wasted. Some solicitors avoid this by delaying delivery of the brief until it is certain the case will go to trial.\n\nSome benefits of maintaining the split include:\n\nSome disadvantages of the split include:\n\nA detailed examination of the justifications for a split legal profession and of the arguments in favour of a fused profession can be found in English solicitor Peter Reeve’s 1986 book, \"Are Two Legal Professions Necessary?\"\n\nBarristers are regulated by the Bar for the jurisdiction where they practise, and in some countries, by the Inn of Court to which they belong. In some countries, there is external regulation.\n\nInns of Court, where they exist, regulate admission to the profession. Inns of Court are independent societies that are titularly responsible for the training, admission (calling), and discipline of barristers. Where they exist, a person may only be called to the Bar by an Inn, of which they must first be a member. In fact, historically, call to and success at the Bar, to a large degree, depended upon social connections made early in life.\n\nA Bar collectively describes all members of the profession of barrister within a given jurisdiction. While as a minimum the Bar is an association embracing all its members, it is usually the case, either \"de facto\" or \"de jure\", that the Bar is invested with regulatory powers over the manner in which barristers practise.\n\nIn the common law tradition, the respective roles of a lawyer – that is as legal adviser and advocate – were formally split into two separate, regulated sub-professions, the other being the office of solicitor. Historically, the distinction was absolute, but in the modern legal age, some countries that had a split legal profession now have a fused profession – anyone entitled to practise as a barrister may also practise as a solicitor, and vice versa. In practice, the distinction may be non-existent, minor, or marked, depending on the jurisdiction. In some jurisdictions, such Australia, Scotland and Ireland, there is little overlap.\n\nIn the Australian states of New South Wales and Queensland, there is a split profession. Nevertheless, subject to conditions, barristers can accept direct access work from clients. Each state Bar Association regulates the profession and essentially has the functions of the English Inns of Court. In the states of South Australia, Victoria, and Western Australia, as well as the Australian Capital Territory, the professions of barrister and solicitor are fused, but an independent bar nonetheless exists, regulated by the Legal Practice Board of the state or territory. In Tasmania and the Northern Territory, the profession is fused, although a very small number of practitioners operate as an independent bar.\n\nGenerally counsel dress in the traditional English manner (wig, gown, and jabot) before superior courts, although this is not usually done for interlocutory applications. Wigs are no longer worn in the highest civil court in New South Wales, the Court of Appeal. Wigs are still worn in the Supreme Court, while only robes without wigs are worn in the District Courts in civil matters. Robes and wigs are worn in all criminal cases. In Western Australia, wigs are no longer worn in any court.\n\nEach year, the Bar Association appoints certain barristers of seniority and eminence to the rank of \"Senior Counsel\" (in most States and Territories) or \"Queen's Counsel\" (in the Northern Territory, Queensland, and Victoria). Such barristers carry the title \"SC\" or \"QC\" after their name. The appointments are made after a process of consultation with members of the profession and the judiciary. Senior Counsel appear in particularly complex or difficult cases. They make up about 14 per cent of the bar in New South Wales.\n\nIn Canada (except Quebec), the professions of barrister and solicitor are fused, and many lawyers refer to themselves with both names, even if they do not practise in both areas. In colloquial parlance within the Canadian legal profession, lawyers often term themselves as \"litigators\" (or \"barristers\"), or as \"solicitors\", depending on the nature of their law practice though some may in effect practise as both litigators and solicitors. However, \"litigators\" would generally perform all litigation functions traditionally performed by barristers and solicitors; in contrast, those terming themselves \"solicitors\" would generally limit themselves to legal work not involving practice before the courts (not even in a preparatory manner as performed by solicitors in England), though some might practise before chambers judges. As is the practice in many other Commonwealth jurisdictions such as Australia, Canadian litigators are \"gowned\", but without a wig, when appearing before courts of \"superior jurisdiction\".\n\nThe situation is somewhat different in Quebec as a result of its civil law tradition. The profession of solicitor, or \"avoué\", never took hold in colonial Quebec, so attorneys (\"avocats\") have traditionally been a fused profession, arguing and preparing cases in contentious matters, whereas Quebec's other type of lawyer, civil-law notaries (\"notaires\"), handle out-of-court non-contentious matters. However, a number of areas of non-contentious private law are not monopolized by notaries so that attorneys often specialise in handling either trials, cases, advising, or non-trial matters. The only disadvantage is that attorneys cannot draw up public instruments that have the same force of law as notarial acts. Most large law firms in Quebec offer the full range of legal services of law firms in common-law provinces. Intending Quebec attorneys must earn a bachelor's degree in civil law, pass the provincial bar examination, and successfully complete a legal internship to be admitted to practice. Attorneys are regulated by the Quebec Law Society (\"Barreau du Québec\").\n\nIn France, \"avocats\", or attorneys, were, until the 20th century, the equivalent of barristers. The profession included several grades ranked by seniority: \"avocat-stagiaire\" (trainee, who was already qualified but needed to complete two years (or more, depending on the period) of training alongside seasoned lawyers), \"avocat\", and \"avocat honoraire\" (senior barrister). Since the 14th century and during the course of the 19th and 20th in particular, French barristers competed in territorial battles over respective areas of legal practice against the \"conseil juridique\" (legal advisor, transactional solicitor) and \"avoué\" (procedural solicitor), and expanded to become the generalist legal practitioner, with the notable exception of \"notaires\" (notaries), who are ministry appointed lawyers (with a separate qualification) and who retain exclusivity over conveyancing and probate. After the 1971 and 1990 legal reforms, the \"avocat\" was fused with the \"avoué\" and the \"conseil juridique\", making the \"avocat\" (or, if female, \"avocate\") an all-purpose lawyer for matters of contentious jurisdiction, analogous to an American attorney. French attorneys usually do not (although it they are entitled to) act both as litigators (trial lawyers) and legal consultants (advising lawyers), known respectively as \"avocat plaidant\" and \"avocat-conseil\". This distinction is however purely informal and does not correspond to any difference in qualification or admission to the roll. All intending attorneys must pass an examination to be able to enrol in one of the \"Centre régional de formation à la profession d'avocat (CRFPA)\" (Regional centre for the training of lawyers). The \"CRFPA\" course has a duration of two years and is a mix between classroom teachings and internships. Its culmination is the \"stage final\" (final training), where the intending attorney spends 6 months in a law firm (generally in his/her favoured field of practice and in a firm in which he/she hopes to be recruited afterwards). The intending attorney then needs to pass the \"Certificat d'Aptitude à la Profession d'Avocat (CAPA)\", which is the last professional examination allowing him/her to join a court's bar (\"barreau\"). It is generally recognised that the first examination is much more difficult than the CAPA and is dreaded by most law students. Each bar is regulated by a Bar Council (\"Ordre du barreau\").\n\nIn Germany, no distinction is made and lawyers may plead at all courts with the exception of the civil branch of the Federal Court of Justice (\"Bundesgerichtshof\") to which fewer than fifty lawyers are admitted as of 25 September 2007. See the \"list of lawyers admitted to the Bundesgerichtshof\". Those lawyers may not plead at other courts, almost only deal with litigation, and are usually instructed by a lawyer who represented the client in the lower courts. However, these restrictions do not apply to criminal cases, nor to pleadings at courts of the other court systems (labour, administrative, taxation, and social courts, as well as the EU court system).\n\nThe legal profession in Hong Kong is also divided into two branches: barristers and solicitors.\n\nIn the High Court and the Court of Final Appeal, as a general rule, only barristers and solicitor-advocates are allowed to speak on behalf of any party in open court. This means that solicitors are restricted from doing so. In these two courts, barristers dress in the traditional English manner, as do the judges and other lawyers.\n\nIn Hong Kong, the rank of Queen's Counsel was granted prior to the transfer of the sovereignty of Hong Kong from the United Kingdom to China in 1997. After the handover, the rank has been replaced by Senior Counsel post-nominal letters: SC. Senior Counsels may still, however, style themselves as silks, like their British counterparts.\n\nIn the Republic of Ireland, admission to the Bar by the Chief Justice of Ireland is restricted to those on whom a Barrister-at-Law degree (B.L.) has first been conferred. The Honorable Society of King's Inns is the only educational establishment which runs vocational courses for barristers in the Republic and degrees of Barrister-at-Law can only be conferred by King's Inns. King's Inns are also the only body with the capacity to call individuals to the bar and to disbar them.\n\nMost Irish barristers choose to be governed thereafter by the Bar Council of Ireland, a quasi-private entity. Senior members of the profession may be selected for elevation to the Inner Bar, when they may describe themselves as Senior Counsel (\"S.C.\"). Admission to the Inner Bar is made by declaration before the Supreme Court, patents of precedence having been granted by the Government. Irish barristers are sole practitioners and may not form chambers or partnerships if they wish to remain members of the Bar Council's Law Library.\n\nTo practise under the Bar Council of Ireland's rules, a newly qualified barrister is apprenticed to an experienced barrister of at least seven years' experience. This apprenticeship is known as pupillage or devilling. Devilling is compulsory for those barristers who wish to be members of the Law Library and lasts for one legal year. It is common to devil for a second year in a less formal arrangement but this is not compulsory.\n\nIn Israel there is no distinction between barristers and solicitors, even though the judicial system is based mostly on English common law, as a continuation of the British Mandate in Palestine.\n\nJapan adopts a unified system. However, there are certain classes of qualified professionals who are allowed to practise in certain limited areas of law, such as scriveners (\"\"shiho shoshi\"\", qualified to handle title registration, deposit, and certain petite court proceedings with additional certification), tax accountants (\"\"zeirishi\"\", qualified to prepare tax returns, provide advice on tax computation and represent a client in administrative tax appeals) and patent agents (\"\"benrishi\"\", qualified to practise patent registration and represent a client in administrative patent appeals). Only the lawyers (\"\"bengoshi\"\") can appear before court and are qualified to practise in any areas of law, including, but not limited to, areas that those qualified law-related professionals above are allowed to practise. Most attorneys still focus primarily on court practice and still a very small number of attorneys give sophisticated and expertised legal advice on a day-to-day basis to large corporations.\n\nThe Netherlands used to have a semi-separated legal profession comprising the lawyer and the \"procureur\", the latter resembling, to some extent, the profession of barrister. Under that system, lawyers were entitled to represent their clients in law, but were only able to file cases before the court at which they were registered. Cases falling under the jurisdiction of another court had to be filed by a \"procureur\" registered at that court, in practice often another lawyer exercising both functions. Questions were raised on the necessity of the separation, given the fact that its main purpose – the preservation of the quality of the legal profession and observance of local court rules and customs – had become obsolete. For that reason, the \"procureur\" as a separate profession was abolished and its functions merged with the legal profession in 2008. Currently, lawyers can file cases before any court, regardless of where they are registered. The only notable exception concerns cases brought before the Supreme Court, which have to be handled by lawyers registered in the district of South Holland, mainly for qualitative reasons.\n\nIn New Zealand, the professions are not formally fused but practitioners are enrolled in the High Court as \"Barristers and Solicitors\". They may choose, however, to practise as barristers sole. About 15% practise solely as barristers, mainly in the larger cities and usually in \"chambers\" (following the British terminology). They receive \"instructions\" from other practitioners, at least nominally. They usually conduct the proceedings in their entirety.\n\nAny lawyer may apply to become a Queen's Counsel (QC) to recognize long standing contribution to the legal profession but this status is only conferred on those practising as solicitors in exceptional circumstances. This step, referred to as \"being called to the inner bar\" or \"taking silk\", is considered highly prestigious and has been a step in the career of many New Zealand judges.\n\nUnlike other jurisdictions, the term \"junior barrister\" is popularly used to refer to a lawyer who holds a practising certificate as a barrister, but is employed by another, more senior barrister. Generally, junior barristers are within their first five years of practise and are not yet qualified to practise as barristers sole. Barristers sole (i.e. barristers who are not employed by another barrister) who are not Queen's Counsel are never referred to as junior barristers.\n\nIn Nigeria, there is no formal distinction between barristers and solicitors. All students who pass the bar examinations – offered exclusively by the Nigerian Law School – are called to the Nigerian bar, by the Body of Benchers. Lawyers may argue in any Federal trial or appellate court as well as any of the courts in Nigeria's 36 states and the Federal Capital Territory. The Legal Practitioner's Act, refers to Nigerian lawyers as Legal Practitioners, and following their call to the Bar, Nigerian lawyers enter their names in the register or Roll of Legal Practitioners kept at the Supreme Court. Perhaps for this reason, a Nigerian lawyer is also often referred to as a Barrister and Solicitor of the Supreme Court of Nigeria, and many Nigerian lawyers term themselves Barrister-at-Law complete with the postnominal initials \"B.L.\".\n\nThe vast majority of Nigerian lawyers combine contentious and non-contentious work, although there is a growing tendency for practitioners in the bigger practices to specialise in one or the other. In colloquial parlance within the Nigerian legal profession, lawyers may for this reason be referred to as \"litigators\" or as \"solicitors\".\n\nConsistent with the practice in England and elsewhere in the Commonwealth, senior members of the profession may be selected for elevation to the Inner Bar by conferment of the rank of Senior Advocate of Nigeria (SAN).\n\nIn Poland, there are two main types of legal professions: advocate and legal counsel. Both are regulated and these professions are restricted only for people who graduated five-year law studies, have at least three years of experience and passed five difficult national exams (civil law, criminal law,company law, administrative law and ethic) or have a doctor of law degree. Before 2015, the only difference was that advocates have a right to represent clients before the court in all cases and the legal advisors could not represent clients before the court in criminal cases. Presently, the legal advisors can also represent clients in criminal cases so currently, the differences between this professions are only historical significance.\n\nThe role of barristers in South Asia generally have been difficult to identify and it has been considered as controversial.\n\nIn India, the law relating to the Barrister is the Advocates Act, 1961 introduced and thought up by Ashoke Kumar Sen, the then law minister of India, which is a law passed by the Parliament and is administered and enforced by the Bar Council of India. Under the act, the Bar Council of India is the supreme regulatory body to regulate the legal profession in India and also to ensure the compliance of the laws and maintenance of professional standards by the legal profession in the country. For this purpose, the Bar Council of India is authorized to pass regulations and make orders in individual cases and also generally.\n\nEach State has a Bar Council of its own whose function is to enroll the Barristers willing to practise predominately within the territorial confines of that State and to perform the functions of the Bar Council of India within the territory assigned to them. Therefore, each law degree holder must be enrolled with a (single) State Bar Council to practise in India. However, enrollment with any State Bar Council does not restrict the Barrister from appearing before any court in India, even though it is beyond the territorial jurisdiction of the State Bar Council which he is enrolled in.\nThe advantage with having the State Bar Councils is that the work load of the Bar Council of India can be divided into these various State Bar Councils and also that matters can be dealt with locally and in an expedited manner. However, for all practical and legal purposes, the Bar Council of India retains with it, the final power to take decisions in any and all matters related to the legal profession on the whole or with respect to any \nThe process for being entitled to practise in India is twofold. First, the applicant must be a holder of a law degree from a recognized institution in India (or from one of the four recognised Universities in the United Kingdom) and second, must pass the enrollment qualifications of the Bar Council of the state where he/she seeks to be enrolled. For this purpose, the Bar Council of India has an internal Committee whose function is to supervise and examine the various institutions conferring law degrees and to grant recognition to these institutions once they meet the required standards. In this manner the Bar Council of India also ensures the standard of education required for practising in India are met with. As regards the qualification for enrollment with the State Bar Council, while the actual formalities may vary from one State to another, yet predominately they ensure that the application has not been a bankrupt /criminal and is generally fit to practise before courts of India.\nEnrollment with a Bar Council also means that the law degree holder is recognized as a Barrister and is required to maintain a standards of conduct and professional demeanor at all times, both on and off the profession. The Bar Council of India also prescribes \"Rules of Conduct\" to be observed by the Barristers in the courts, while interacting with clients and even otherwise.\n\nIn Pakistan to practice as a Barrister, law graduates have to complete three steps. They have to pass the Bar Practice and Training Course (BPTC), be Called to the Bar by an Inn of Court from England and Wales and attain a licence to practice as an advocate in the Courts of Pakistan from the relevant Bar Council, provincial or federal. \n\nIn Bangladesh, graduate lawyers have to seat for and pass the Bar Council Exam to become professional barristers.\nBy passing the Bar Council Exam, barristers are eligible to practise in the Supreme Court of Bangladesh and other courts. In Bangladesh there is an association called Barristers' Association of Bangladesh that represents the barrister. A license is obtained after successful completion of two years' practice in the lower courts by applicant, which is reviewed by a body of the relevant provincial Bar Council. Most applications after successful completion of the requirement, are accepted.\n\nIn South Africa the employment and practise of advocates (as barristers are known in South Africa) is consistent with the rest of the Commonwealth. Advocates carry the rank of Junior or Senior Counsel (SC), and are mostly briefed and paid by solicitors (known as attorneys). They are usually employed in the higher courts, particularly in the Appeal Courts where they often appear as specialist counsel. South African solicitors (attorneys) follow a practice of referring cases to Counsel for an opinion before proceeding with a case, when Counsel in question practises as a specialist in the case law at stake. Aspiring advocates currently spend one year in pupillage (formerly only six months) before being admitted to the bar in their respective provincial or judicial jurisdictions. The term 'Advocate' is sometimes used in South Africa as a title, e. g. 'Advocate John Doe, SC' ('Advokaat' in Afrikaans) in the same fashion as 'Dr. John Doe' for a medical doctor.\n\nIn South Korea, there is no distinction between the judiciary and lawyers. Previously, a person who has passed the national bar exam after two years of national education is able to become a judge, prosecutor, or \"lawyer\" in accordance to their grades upon graduation. As a result of changes from implementing an accommodated law school system, there are two standard means of becoming a lawyer. Under the current legal system, to be a judge or a prosecutor, lawyers need to practise their legal knowledge. A \"lawyer\" does not have any limitation of practice.\n\nSpain has a division but it does not correspond to the division in Britain between barristers/advocates and solicitors. \"Procuradores\" represent the litigant procedurally in court, generally under the authority of a power of attorney executed by a civil law notary, while \"abogados\" represent the substantive claims of the litigant through trial advocacy. \"Abogados\" perform both transactional work and advise in connection with court proceedings, and they have full right of audience in front of the court. The court proceeding is carried out with \"abogados\", not with procuradores. In a nutshell, procuradores are court agents that operate under the instructions of an \"abogado\". Their practice is confined to the locality of the court to which they are admitted.\n\nThe United States does not draw a distinction between lawyers as pleaders (barristers) and lawyers as agents (or solicitors). All lawyers who have passed a bar examination and have been admitted to practice may prosecute or defend in the courts of the state where they are admitted. Historically, a distinction was made, and a separate label for barristers (called \"counselors\", hence the expression \"attorney \"and\" counselor at law\") existed in certain states, though both professions have long since been fused into the all-purpose attorney. Attorneys specializing in court procedure, combining advocacy and case preparation, are called \"trial attorneys\" or \"litigators\".\n\nSouth Carolina no longer requires attorneys to be licensed separately to plead in a courtroom. Additionally, some state appellate courts require attorneys to obtain a separate certificate of admission to plead and practise in the appellate court. Federal courts require specific admission to that court's bar to practise before it. At the state appellate level and in Federal courts, there is generally no separate examination process, although some U.S. district courts require an examination on practices and procedures in their specific courts. Unless an examination is required, admission is usually granted as a matter of course to any licensed attorney in the state where the court is located. Some federal courts will grant admission to any attorney licensed in any U.S. jurisdiction.\n\nAlthough with somewhat different laws, England and Wales are considered within the United Kingdom a single united and unified legal jurisdiction for the purposes of both civil and criminal law, alongside Scotland and Northern Ireland, the other two legal jurisdictions within the United Kingdom. England and Wales are covered by a common bar (an organisation of barristers) and a single law society (an organisation of solicitors).\n\nThe profession of barrister in England and Wales is a separate profession from that of solicitor. It is, however, possible to hold the qualification of both barrister and solicitor at the same time. It is not necessary to leave the bar to qualify as a solicitor.\n\nBarristers are regulated by the Bar Standards Board, a division of the General Council of the Bar. A barrister must be a member of one of the Inns of Court, which traditionally educated and regulated barristers. There are four Inns of Court: The Honourable Society of Lincoln's Inn, The Honourable Society of Gray's Inn, The Honourable Society of the Middle Temple, and The Honourable Society of the Inner Temple. All are situated in central London, near the Royal Courts of Justice. They perform scholastic and social roles, and in all cases, provide financial aid to student barristers (subject to merit) through scholarships. It is the Inns that actually \"call\" the student to the Bar at a ceremony similar to a graduation. Social functions include dining with other members and guests and hosting other events.\n\nLaw graduates wishing to work and be known as barristers must take the Bar Professional Training Course (BPTC – previously Bar Vocational Course or BVC) at one of the institutions authorised by the Bar Council to offer the BPTC. On successful completion of the BPTC student barristers are \"called\" to the bar by their respective inns and are elevated to the degree of \"Barrister\". However, before they can practise independently they must first undertake 12 months of pupillage. The first six months of this period is spent shadowing more senior practitioners, after which pupil barristers may begin to undertake some court work of their own. Following successful completion of this stage, most barristers then join a set of Chambers, a group of counsel who share the costs of premises and support staff whilst remaining individually self-employed.\n\nIn December 2014 there were just over 15,500 barristers in independent practice, of whom about ten percent are Queen's Counsel and the remainder are junior barristers. Many barristers (about 2,800) are employed in companies as 'in-house' counsel, or by local or national government or in academic institutions.\n\nCertain barristers in England and Wales are now instructed directly by members of the public. Members of the public may engage the services of the barrister directly within the framework of the Public Access Scheme; a solicitor is not involved at any stage. Barristers undertaking public access work can provide legal advice and representation in court in almost all areas of law (see the Public Access Information on the Bar Council website) and are entitled to represent clients in any court or tribunal in England and Wales. Once instructions from a client are accepted, it is the barrister (rather than the solicitor) who advises and guides the client through the relevant legal procedure or litigation.\n\nBefore a barrister can undertake Public Access work, they must have completed a special course. At present, about one in 20 barristers has so qualified. There is also a separate scheme called 'Licensed Access', available to certain nominated classes of professional client; it is not open to the general public. Public access work is experiencing a huge surge at the bar, with barristers taking advantage of the new opportunity for the bar to make profit in the face of legal aid cuts elsewhere in the profession.\n\nThe ability of barristers to accept such instructions is a recent development; it results from a change in the rules set down by the General Council of the Bar in July 2004. The Public Access Scheme has been introduced as part of the drive to open up the legal system to the public and to make it easier and cheaper to obtain access to legal advice. It further reduces the distinction between solicitors and barristers. The distinction remains however because there are certain aspects of a solicitor's role that a barrister is not able to undertake.\n\nSome honorific suffixes to signify notable barristers may be \"Esquire\". Even though the term \"barrister-at-law\" is sometimes seen, and was once very common, it has never been formally correct in England and Wales. Barrister is the only correct nomenclature.\n\nIn April 2003 there were 554 barristers in independent practice in Northern Ireland. 66 were Queen's Counsel (QCs), barristers who have earned a high reputation and are appointed by the Queen on the recommendation of the Lord Chancellor as senior advocates and advisers.\n\nThose barristers who are not QCs are called Junior Counsel and are styled \"BL\" or \"Barrister-at-Law\". The term \"junior\" is often misleading since many members of the Junior Bar are experienced barristers with considerable expertise.\n\nBenchers are, and have been for centuries, the governing bodies of the four Inns of Court in London and King's Inns, Dublin. The Benchers of the Inn of Court of Northern Ireland governed the Inn until the enactment of the Constitution of the Inn in 1983, which provides that the government of the Inn is shared between the Benchers, the Executive Council of the Inn and members of the Inn assembled in General Meeting.\n\nThe Executive Council (through its Education Committee) is responsible for considering Memorials submitted by applicants for admission as students of the Inn and by Bar students of the Inn for admission to the degree of Barrister-at-Law and making recommendations to the Benchers. The final decisions on these Memorials are taken by the Benchers. The Benchers also have the exclusive power of expelling or suspending a Bar student and of disbarring a barrister or suspending a barrister from practice.\n\nThe Executive Council is also involved with: education; fees of students; calling counsel to the Bar, although call to the Bar is performed by the Lord Chief Justice of Northern Ireland on the invitation of the Benchers; administration of the Bar Library (to which all practising members of the Bar belong); and liaising with corresponding bodies in other countries.\n\nThe Bar Council is responsible for the maintenance of the standards, honour and independence of the Bar and, through its Professional Conduct Committee, receives and investigates complaints against members of the Bar in their professional capacity.\n\nIn Scotland, an advocate is, in all respects except name, a barrister, but there are significant differences in professional practice.\n\nIn Scotland, admission to and the conduct of the profession is regulated by the Faculty of Advocates (as opposed to an Inn).\n\nIn the Bailiwick of Jersey, there are solicitors (called \"ecrivains\") and advocates (French \"avocat\"). In the Bailiwicks of Jersey and Guernsey and on the Isle of Man, Advocates perform the combined functions of both solicitors and barristers.\n\nGibraltar is a British Overseas Territory boasting a legal profession based on the common law. The legal profession includes both barristers and solicitors with most barristers also acting as solicitors. Admission and Disciplinary matters in Gibraltar are dealt with by the Bar Council of Gibraltar and the Supreme Court of Gibraltar. In order for barristers or solicitors to be admitted as practising lawyers in Gibraltar they must comply with the Supreme Court Act 1930 as amended by the Supreme Court Amendment Act 2015 which requires, amongst other things, for all newly admitted lawyers as of the 1 July 2015 to undertake a year's course in Gibraltar law at the University of Gibraltar. Solicitors also have right of audience in Gibraltar's courts.\n\n\n\n\n\n\n"}
{"id": "4849", "url": "https://en.wikipedia.org/wiki?curid=4849", "title": "Battle of Gettysburg", "text": "Battle of Gettysburg\n\nThe Battle of Gettysburg (, with an sound) was fought July 1–3, 1863, in and around the town of Gettysburg, Pennsylvania, by Union and Confederate forces during the American Civil War. The battle involved the largest number of casualties of the entire war and is often described as the war's turning point. Union Maj. Gen. George Meade's Army of the Potomac defeated attacks by Confederate Gen. Robert E. Lee's Army of Northern Virginia, ending Lee's attempt to invade the North.\n\nAfter his success at Chancellorsville in Virginia in May 1863, Lee led his army through the Shenandoah Valley to begin his second invasion of the North—the Gettysburg Campaign. With his army in high spirits, Lee intended to shift the focus of the summer campaign from war-ravaged northern Virginia and hoped to influence Northern politicians to give up their prosecution of the war by penetrating as far as Harrisburg, Pennsylvania, or even Philadelphia. Prodded by President Abraham Lincoln, Maj. Gen. Joseph Hooker moved his army in pursuit, but was relieved of command just three days before the battle and replaced by Meade.\n\nElements of the two armies initially collided at Gettysburg on July 1, 1863, as Lee urgently concentrated his forces there, his objective being to engage the Union army and destroy it. Low ridges to the northwest of town were defended initially by a Union cavalry division under Brig. Gen. John Buford, and soon reinforced with two corps of Union infantry. However, two large Confederate corps assaulted them from the northwest and north, collapsing the hastily developed Union lines, sending the defenders retreating through the streets of the town to the hills just to the south.\n\nOn the second day of battle, most of both armies had assembled. The Union line was laid out in a defensive formation resembling a fishhook. In the late afternoon of July 2, Lee launched a heavy assault on the Union left flank, and fierce fighting raged at Little Round Top, the Wheatfield, Devil's Den, and the Peach Orchard. On the Union right, Confederate demonstrations escalated into full-scale assaults on Culp's Hill and Cemetery Hill. All across the battlefield, despite significant losses, the Union defenders held their lines.\n\nOn the third day of battle, fighting resumed on Culp's Hill, and cavalry battles raged to the east and south, but the main event was a dramatic infantry assault by 12,500 Confederates against the center of the Union line on Cemetery Ridge, known as Pickett's Charge. The charge was repulsed by Union rifle and artillery fire, at great loss to the Confederate army.\n\nLee led his army on a torturous retreat back to Virginia. Between 46,000 and 51,000 soldiers from both armies were casualties in the three-day battle, the most costly in US history.\n\nOn November 19, President Lincoln used the dedication ceremony for the Gettysburg National Cemetery to honor the fallen Union soldiers and redefine the purpose of the war in his historic Gettysburg Address.\n\nShortly after the Army of Northern Virginia won a major victory over the Army of the Potomac at the Battle of Chancellorsville (April 30 – May 6, 1863), Robert E. Lee decided upon a second invasion of the North (the first was the unsuccessful Maryland Campaign of September 1862, which ended in the bloody Battle of Antietam). Such a move would upset U.S. plans for the summer campaigning season and possibly reduce the pressure on the besieged Confederate garrison at Vicksburg. The invasion would allow the Confederates to live off the bounty of the rich Northern farms while giving war-ravaged Virginia a much-needed rest. In addition, Lee's 72,000-man army could threaten Philadelphia, Baltimore, and Washington, and possibly strengthen the growing peace movement in the North.\n\nThus, on June 3, Lee's army began to shift northward from Fredericksburg, Virginia. Following the death of Thomas J. \"Stonewall\" Jackson, Lee reorganized his two large corps into three new corps, commanded by Lt. Gen. James Longstreet (First Corps), Lt. Gen. Richard S. Ewell (Second), and Lt. Gen. A.P. Hill (Third); both Ewell and Hill, who had formerly reported to Jackson as division commanders, were new to this level of responsibility. The Cavalry Division remained under the command of Maj. Gen. J.E.B. Stuart.\n\nThe Union Army of the Potomac, under Maj. Gen. Joseph Hooker, consisted of seven infantry corps, a cavalry corps, and an Artillery Reserve, for a combined strength of more than 100,000 men.\n\nThe first major action of the campaign took place on June 9 between cavalry forces at Brandy Station, near Culpeper, Virginia. The 9,500 Confederate cavalrymen under Stuart were surprised by Maj. Gen. Alfred Pleasonton's combined arms force of two cavalry divisions (8,000 troopers) and 3,000 infantry, but Stuart eventually repulsed the Union attack. The inconclusive battle, the largest predominantly cavalry engagement of the war, proved for the first time that the Union horse soldier was equal to his Southern counterpart.\n\nBy mid-June, the Army of Northern Virginia was poised to cross the Potomac River and enter Maryland. After defeating the U.S. garrisons at Winchester and Martinsburg, Ewell's Second Corps began crossing the river on June 15. Hill's and Longstreet's corps followed on June 24 and 25. Hooker's army pursued, keeping between the U.S. capital and Lee's army. The U.S. crossed the Potomac from June 25 to 27.\n\nLee gave strict orders for his army to minimize any negative impacts on the civilian population. Food, horses, and other supplies were generally not seized outright, although quartermasters reimbursing Northern farmers and merchants with Confederate money were not well received. Various towns, most notably York, Pennsylvania, were required to pay indemnities in lieu of supplies, under threat of destruction. During the invasion, the Confederates seized some 40 northern African Americans. A few of them were escaped fugitive slaves, but most were freemen; all were sent south into slavery under guard.\n\nOn June 26, elements of Maj. Gen. Jubal Early's division of Ewell's Corps occupied the town of Gettysburg after chasing off newly raised Pennsylvania militia in a series of minor skirmishes. Early laid the borough under tribute but did not collect any significant supplies. Soldiers burned several railroad cars and a covered bridge, and destroyed nearby rails and telegraph lines. The following morning, Early departed for adjacent York County.\n\nMeanwhile, in a controversial move, Lee allowed J.E.B. Stuart to take a portion of the army's cavalry and ride around the east flank of the Union army. Lee's orders gave Stuart much latitude, and both generals share the blame for the long absence of Stuart's cavalry, as well as for the failure to assign a more active role to the cavalry left with the army. Stuart and his three best brigades were absent from the army during the crucial phase of the approach to Gettysburg and the first two days of battle. By June 29, Lee's army was strung out in an arc from Chambersburg (28 miles (45 km) northwest of Gettysburg) to Carlisle (30 miles (48 km) north of Gettysburg) to near Harrisburg and Wrightsville on the Susquehanna River.\n\nIn a dispute over the use of the forces defending the Harpers Ferry garrison, Hooker offered his resignation, and Abraham Lincoln and General-in-Chief Henry W. Halleck, who were looking for an excuse to get rid of him, immediately accepted. They replaced Hooker early on the morning of June 28 with Maj. Gen. George Gordon Meade, then commander of the V Corps.\n\nOn June 29, when Lee learned that the Army of the Potomac had crossed the Potomac River, he ordered a concentration of his forces around Cashtown, located at the eastern base of South Mountain and eight miles (13 km) west of Gettysburg. On June 30, while part of Hill's Corps was in Cashtown, one of Hill's brigades, North Carolinians under Brig. Gen. J. Johnston Pettigrew, ventured toward Gettysburg. In his memoirs, Maj. Gen. Henry Heth, Pettigrew's division commander, claimed that he sent Pettigrew to search for supplies in town—especially shoes.\n\nWhen Pettigrew's troops approached Gettysburg on June 30, they noticed Union cavalry under Brig. Gen. John Buford arriving south of town, and Pettigrew returned to Cashtown without engaging them. When Pettigrew told Hill and Heth what he had seen, neither general believed that there was a substantial U.S. force in or near the town, suspecting that it had been only Pennsylvania militia. Despite General Lee's order to avoid a general engagement until his entire army was concentrated, Hill decided to mount a significant reconnaissance in force the following morning to determine the size and strength of the enemy force in his front. Around 5 a.m. on Wednesday, July 1, two brigades of Heth's division advanced to Gettysburg.\n\nThe Army of the Potomac, initially under Maj. Gen. Joseph Hooker (Maj. Gen. George Meade replaced Hooker in command on June 28), consisted of more than 100,000 men in the following organization:\n\nDuring the advance on Gettysburg, Maj. Gen. Reynolds was in operational command of the left, or advanced, wing of the Army, consisting of the I, III, and XI Corps. Note that many other Union units (not part of the Army of the Potomac) were actively involved in the Gettysburg Campaign, but not directly involved in the Battle of Gettysburg. These included portions of the Union IV Corps, the militia and state troops of the Department of the Susquehanna, and various garrisons, including that at Harpers Ferry.\nIn reaction to the death of Lt. Gen. Thomas J. \"Stonewall\" Jackson after Chancellorsville, Lee reorganized his Army of Northern Virginia (75,000 men) from two infantry corps into three.\n\nAnticipating that the Confederates would march on Gettysburg from the west on the morning of July 1, Buford laid out his defenses on three ridges west of the town: Herr Ridge, McPherson Ridge and Seminary Ridge. These were appropriate terrain for a delaying action by his small cavalry division against superior Confederate infantry forces, meant to buy time awaiting the arrival of Union infantrymen who could occupy the strong defensive positions south of town at Cemetery Hill, Cemetery Ridge, and Culp's Hill. Buford understood that if the Confederates could gain control of these heights, Meade's army would have difficulty dislodging them.\nHeth's division advanced with two brigades forward, commanded by Brig. Gens. James J. Archer and Joseph R. Davis. They proceeded easterly in columns along the Chambersburg Pike. Three miles (5 km) west of town, about 7:30 a.m. on July 1, the two brigades met light resistance from vedettes of Union cavalry, and deployed into line. According to lore, the Union soldier to fire the first shot of the battle was Lt. Marcellus Jones. In 1886 Lt. Jones returned to Gettysburg to mark the spot where he fired the first shot with a monument. Eventually, Heth's men reached dismounted troopers of Col. William Gamble's cavalry brigade, who raised determined resistance and delaying tactics from behind fence posts with fire from their breechloading carbines. Still, by 10:20 a.m., the Confederates had pushed the Union cavalrymen east to McPherson Ridge, when the vanguard of the I Corps (Maj. Gen. John F. Reynolds) finally arrived.\n\nNorth of the pike, Davis gained a temporary success against Brig. Gen. Lysander Cutler's brigade but was repulsed with heavy losses in an action around an unfinished railroad bed cut in the ridge. South of the pike, Archer's brigade assaulted through Herbst (also known as McPherson's) Woods. The U.S. Iron Brigade under Brig. Gen. Solomon Meredith enjoyed initial success against Archer, capturing several hundred men, including Archer himself.\n\nGeneral Reynolds was shot and killed early in the fighting while directing troop and artillery placements just to the east of the woods. Shelby Foote wrote that the Union cause lost a man considered by many to be \"the best general in the army.\" Maj. Gen. Abner Doubleday assumed command. Fighting in the Chambersburg Pike area lasted until about 12:30 p.m. It resumed around 2:30 p.m., when Heth's entire division engaged, adding the brigades of Pettigrew and Col. John M. Brockenbrough.\n\nAs Pettigrew's North Carolina Brigade came on line, they flanked the 19th Indiana and drove the Iron Brigade back. The 26th North Carolina (the largest regiment in the army with 839 men) lost heavily, leaving the first day's fight with around 212 men. By the end of the three-day battle, they had about 152 men standing, the highest casualty percentage for one battle of any regiment, North or South. Slowly the Iron Brigade was pushed out of the woods toward Seminary Ridge. Hill added Maj. Gen. William Dorsey Pender's division to the assault, and the I Corps was driven back through the grounds of the Lutheran Seminary and Gettysburg streets.\n\nAs the fighting to the west proceeded, two divisions of Ewell's Second Corps, marching west toward Cashtown in accordance with Lee's order for the army to concentrate in that vicinity, turned south on the Carlisle and Harrisburg roads toward Gettysburg, while the Union XI Corps (Maj. Gen. Oliver O. Howard) raced north on the Baltimore Pike and Taneytown Road. By early afternoon, the U.S. line ran in a semicircle west, north, and northeast of Gettysburg.\n\nHowever, the U.S. did not have enough troops; Cutler, whose brigade was deployed north of the Chambersburg Pike, had his right flank in the air. The leftmost division of the XI Corps was unable to deploy in time to strengthen the line, so Doubleday was forced to throw in reserve brigades to salvage his line.\n\nAround 2 p.m., the Confederate Second Corps divisions of Maj. Gens. Robert E. Rodes and Jubal Early assaulted and out-flanked the Union I and XI Corps positions north and northwest of town. The Confederate brigades of Col. Edward A. O'Neal and Brig. Gen. Alfred Iverson suffered severe losses assaulting the I Corps division of Brig. Gen. John C. Robinson south of Oak Hill. Early's division profited from a blunder by Brig. Gen. Francis C. Barlow, when he advanced his XI Corps division to Blocher's Knoll (directly north of town and now known as Barlow's Knoll); this represented a salient in the corps line, susceptible to attack from multiple sides, and Early's troops overran Barlow's division, which constituted the right flank of the Union Army's position. Barlow was wounded and captured in the attack.\n\nAs U.S. positions collapsed both north and west of town, Gen. Howard ordered a retreat to the high ground south of town at Cemetery Hill, where he had left the division of Brig. Gen. Adolph von Steinwehr in reserve. Maj. Gen. Winfield S. Hancock assumed command of the battlefield, sent by Meade when he heard that Reynolds had been killed. Hancock, commander of the II Corps and Meade's most trusted subordinate, was ordered to take command of the field and to determine whether Gettysburg was an appropriate place for a major battle. Hancock told Howard, \"I think this the strongest position by nature upon which to fight a battle that I ever saw.\" When Howard agreed, Hancock concluded the discussion: \"Very well, sir, I select this as the battle-field.\" Hancock's determination had a morale-boosting effect on the retreating Union soldiers, but he played no direct tactical role on the first day.\n\nGeneral Lee understood the defensive potential to the Union if they held this high ground. He sent orders to Ewell that Cemetery Hill be taken \"if practicable.\" Ewell, who had previously served under Stonewall Jackson, a general well known for issuing peremptory orders, determined such an assault was not practicable and, thus, did not attempt it; this decision is considered by historians to be a great missed opportunity.\n\nThe first day at Gettysburg, more significant than simply a prelude to the bloody second and third days, ranks as the 23rd biggest battle of the war by number of troops engaged. About one quarter of Meade's army (22,000 men) and one third of Lee's army (27,000) were engaged.\n\nThroughout the evening of July 1 and morning of July 2, most of the remaining infantry of both armies arrived on the field, including the Union II, III, V, VI, and XII Corps. Two of Longstreet's brigades were on the road: Brig. Gen. George Pickett, had begun the 22 mile march from Chambersburg, while Brig. Gen. E. M. Law had begun the march from Guilford. Both arrived late in the morning. Law completed his 28-mile march in eleven hours.\n\nThe Union line ran from Culp's Hill southeast of the town, northwest to Cemetery Hill just south of town, then south for nearly two miles (3 km) along Cemetery Ridge, terminating just north of Little Round Top. Most of the XII Corps was on Culp's Hill; the remnants of I and XI Corps defended Cemetery Hill; II Corps covered most of the northern half of Cemetery Ridge; and III Corps was ordered to take up a position to its flank. The shape of the Union line is popularly described as a \"fishhook\" formation.\n\nThe Confederate line paralleled the Union line about a mile (1,600 m) to the west on Seminary Ridge, ran east through the town, then curved southeast to a point opposite Culp's Hill. Thus, the Union army had interior lines, while the Confederate line was nearly five miles (8 km) long.\n\nLee's battle plan for July 2 called for a general assault of Meade's positions. On the right, Longstreet's First Corps was to position itself to attack the Union left flank, facing northeast astraddle the Emmitsburg Road, and to roll up the U.S.line. The attack sequence was to begin with Maj. Gens. John Bell Hood's and Lafayette McLaws's divisions, followed by Maj. Gen. Richard H. Anderson's division of Hill's Third Corps.\n\nOn the left, Lee instructed Ewell to position his Second Corps to attack Culp's Hill and Cemetery Hill when he heard the gunfire from Longstreet's assault, preventing Meade from shifting troops to bolster his left. Though it does not appear in either his or Lee's Official Report, Ewell claimed years later that Lee had changed the order to simultaneously attack, calling for only a \"diversion\", to be turned into a full-scale attack if a favorable opportunity presented itself.\n\nLee's plan, however, was based on faulty intelligence, exacerbated by Stuart's continued absence from the battlefield. Though Lee personally reconnoitered his left during the morning, he did not visit Longstreet's position on the Confederate right. Even so, Lee rejected suggestions that Longstreet move beyond Meade's left and attack the Union flank, capturing the supply trains and effectively blocking Meade's escape route.\n\nLee did not issue orders for the attack until 11:00 a.m. About noon, General Anderson's advancing troops were discovered by General Sickles' outpost guard and the Third Corps–upon which Longstreet's First Corps was to form–did not get into position until 1:00 p.m.\n\nHood and McLaws, after their long march, were not yet in position and did not launch their attacks until just after 4 p.m. and 5 p.m., respectively.\n\nAs Longstreet's left division, under Maj. Gen. Lafayette McLaws, advanced, they unexpectedly found Maj. Gen. Daniel Sickles's III Corps directly in their path. Sickles had been dissatisfied with the position assigned him on the southern end of Cemetery Ridge. Seeing ground better suited for artillery positions a half mile (800 m) to the west, he advanced his corps—without orders—to the slightly higher ground along the Emmitsburg Road. The new line ran from Devil's Den, northwest to the Sherfy farm's peach orchard, then northeast along the Emmitsburg Road to south of the Codori farm. This created an untenable salient at the Peach Orchard; Brig. Gen. Andrew A. Humphreys's division (in position along the Emmitsburg Road) and Maj. Gen. David B. Birney's division (to the south) were subject to attacks from two sides and were spread out over a longer front than their small corps could defend effectively. The Confederate artillery was ordered to open fire at 3:00 p.m. Meade was with Sickles at the time, urging Sickles to return to his assigned position.\n\nMeade was forced to send 20,000 reinforcements: the entire V Corps, Brig. Gen. John C. Caldwell's division of the II Corps, most of the XII Corps, and portions of the newly arrived VI Corps. Hood's division moved more to the east than intended, losing its alignment with the Emmitsburg Road, attacking Devil's Den and Little Round Top. McLaws, coming in on Hood's left, drove multiple attacks into the thinly stretched III Corps in the Wheatfield and overwhelmed them in Sherfy's Peach Orchard. McLaws's attack eventually reached Plum Run Valley (the \"Valley of Death\") before being beaten back by the Pennsylvania Reserves division of the V Corps, moving down from Little Round Top. The III Corps was virtually destroyed as a combat unit in this battle, and Sickles's leg was amputated after it was shattered by a cannonball. Caldwell's division was destroyed piecemeal in the Wheatfield. Anderson's division, coming from McLaws's left and starting forward around 6 p.m., reached the crest of Cemetery Ridge, but could not hold the position in the face of counterattacks from the II Corps, including an almost suicidal bayonet charge by the 1st Minnesota regiment against a Confederate brigade, ordered in desperation by Hancock to buy time for reinforcements to arrive.\n\nAs fighting raged in the Wheatfield and Devil's Den, Col. Strong Vincent of V Corps had a precarious hold on Little Round Top, an important hill at the extreme left of the Union line. His brigade of four relatively small regiments was able to resist repeated assaults by Brig. Gen. Evander M. Law's brigade of Hood's division. Meade's chief engineer, Brig. Gen. Gouverneur K. Warren, had realized the importance of this position, and dispatched Vincent's brigade, an artillery battery, and the 140th New York to occupy Little Round Top mere minutes before Hood's troops arrived. The defense of Little Round Top with a bayonet charge by the 20th Maine, ordered by Col. Joshua L. Chamberlain but possibly led by Lt. Holman S. Melcher, was one of the most fabled episodes in the Civil War and propelled Col. Chamberlain into prominence after the war.\n\nEwell interpreted his orders as calling only for a cannonade. His 32 guns, along with A. P. Hill's 55 guns, engaged in a two-hour artillery barrage at extreme range that had little effect. Finally, about six o'clock, Ewell sent orders to each of his division commanders to attack the Union lines in his front.\n\nMaj. Gen. Edward \"Allegheny\" Johnson's Division \"had not been pushed close to [Culp's Hill] in preparation for an assault, although one had been contemplated all day. It now had a full mile to advance and Rock Creek had to be crossed. This could only be done at few places and involved much delay. Only three of Johnson's four brigades moved to the attack.\" Most of the hill's defenders, the Union XII Corps, had been sent to the left to defend against Longstreet's attacks, leaving only a brigade of New Yorkers under Brig. Gen. George S. Greene behind strong, newly constructed defensive works. With reinforcements from the I and XI Corps, Greene's men held off the Confederate attackers, though giving up some of the lower earthworks on the lower part of Culp's Hill.\n\nEarly was similarly unprepared when he ordered Harry T. Hays' and Isaac E. Avery's Brigades to attack the Union XI Corps positions on East Cemetery Hill. Once started, fighting was fierce: Col. Andrew L. Harris of the Union 2nd Brigade, 1st Division, came under a withering attack, losing half his men. Avery was wounded early on, but the Confederates reached the crest of the hill and entered the Union breastworks, capturing one or two batteries. Seeing he was not supported on his right, Hays withdrew. His right was to be supported by Robert E. Rodes' Division, but Rodes—like Early and Johnson—had not been ordered up in preparation for the attack. He had twice as far to travel as Early; by the time he came in contact with the Union skirmish line, Early's troops had already begun to withdraw.\n\nJeb Stuart and his three cavalry brigades arrived in Gettysburg around noon but had no role in the second day's battle. Brig. Gen. Wade Hampton's brigade fought a minor engagement with newly promoted 23-year-old Brig. Gen. George Armstrong Custer's Michigan cavalry near Hunterstown to the northeast of Gettysburg.\n\nGeneral Lee wished to renew the attack on Friday, July 3, using the same basic plan as the previous day: Longstreet would attack the U.S. left, while Ewell attacked Culp's Hill. However, before Longstreet was ready, Union XII Corps troops started a dawn artillery bombardment against the Confederates on Culp's Hill in an effort to regain a portion of their lost works. The Confederates attacked, and the second fight for Culp's Hill ended around 11 a.m. Harry Pfanz judged that, after some seven hours of bitter combat, \"the Union line was intact and held more strongly than before.\"\n\nLee was forced to change his plans. Longstreet would command Pickett's Virginia division of his own First Corps, plus six brigades from Hill's Corps, in an attack on the U.S. II Corps position at the right center of the Union line on Cemetery Ridge. Prior to the attack, all the artillery the Confederacy could bring to bear on the U.S. positions would bombard and weaken the enemy's line.\n\nMuch has been made over the years of General Longstreet's objections to General Lee's plan. In his memoirs, Longstreet described their discussion as follows:\n\nAround 1 p.m., from 150 to 170 Confederate guns began an artillery bombardment that was probably the largest of the war. In order to save valuable ammunition for the infantry attack that they knew would follow, the Army of the Potomac's artillery, under the command of Brig. Gen. Henry Jackson Hunt, at first did not return the enemy's fire. After waiting about 15 minutes, about 80 U.S. cannons added to the din. The Army of Northern Virginia was critically low on artillery ammunition, and the cannonade did not significantly affect the Union position.\n\nAround 3 p.m., the cannon fire subsided, and 12,500 Southern soldiers stepped from the ridgeline and advanced the three-quarters of a mile (1,200 m) to Cemetery Ridge in what is known to history as \"Pickett's Charge\". As the Confederates approached, there was fierce flanking artillery fire from Union positions on Cemetery Hill and north of Little Round Top, and musket and canister fire from Hancock's II Corps. In the Union center, the commander of artillery had held fire during the Confederate bombardment (in order to save it for the infantry assault, which Meade had correctly predicted the day before), leading Southern commanders to believe the Northern cannon batteries had been knocked out. However, they opened fire on the Confederate infantry during their approach with devastating results. Nearly one half of the attackers did not return to their own lines.\n\nAlthough the U.S. line wavered and broke temporarily at a jog called the \"Angle\" in a low stone fence, just north of a patch of vegetation called the Copse of Trees, reinforcements rushed into the breach, and the Confederate attack was repulsed. The farthest advance of Brig. Gen. Lewis A. Armistead's brigade of Maj. Gen. George Pickett's division at the Angle is referred to as the \"High-water mark of the Confederacy\", arguably representing the closest the South ever came to its goal of achieving independence from the Union via military victory. Union and Confederate soldiers locked in hand-to-hand combat, attacking with their rifles, bayonets, rocks and even their bare hands. Armistead ordered his Confederates to turn two captured cannons against Union troops, but discovered that there was no ammunition left, the last double canister shots having been used against the charging Confederates. Armistead was wounded shortly afterward three times.\n\nThere were two significant cavalry engagements on July 3. Stuart was sent to guard the Confederate left flank and was to be prepared to exploit any success the infantry might achieve on Cemetery Hill by flanking the U.S. right and hitting their trains and lines of communications. Three miles (5 km) east of Gettysburg, in what is now called \"East Cavalry Field\" (not shown on the accompanying map, but between the York and Hanover Roads), Stuart's forces collided with U.S. cavalry: Brig. Gen. David McMurtrie Gregg's division and Brig. Gen. Custer's brigade. A lengthy mounted battle, including hand-to-hand sabre combat, ensued. Custer's charge, leading the 1st Michigan Cavalry, blunted the attack by Wade Hampton's brigade, blocking Stuart from achieving his objectives in the U.S. rear.\n\nMeanwhile, after hearing news of the day's victory, Brig. Gen. Judson Kilpatrick launched a cavalry attack against the infantry positions of Longstreet's Corps southwest of Big Round Top. Brig. Gen. Elon J. Farnsworth protested against the futility of such a move, but obeyed orders. Farnsworth was killed in the attack, and his brigade suffered significant losses.\n\nThe two armies suffered between 46,000 and 51,000 casualties. Union casualties were 23,055 (3,155 killed, 14,531 wounded, 5,369 captured or missing), while Confederate casualties are more difficult to estimate. Many authors have referred to as many as \"28,000 Confederate casualties\", and Busey and Martin's more recent 2005 work, \"Regimental Strengths and Losses at Gettysburg\", documents 23,231 (4,708 killed, 12,693 wounded, 5,830 captured or missing). Nearly a third of Lee's general officers were killed, wounded, or captured. The casualties for both sides during the entire campaign were 57,225.\n\nIn addition to being the deadliest battle of the war in terms of total casualties, Gettysburg also had the highest number of Generals killed in action of any battle in the war. The Confederacy lost generals Paul Jones Semmes, William Barksdale, Richard Garnett, and Lewis Armistead, as well as J. Johnston Pettigrew during the retreat after the battle. The Union lost Generals John Reynolds, Samuel K. Zook, Stephen H. Weed, and Elon J. Farnsworth, as well as Strong Vincent, who after being mortally wounded was given a deathbed promotion to brigadier general. Additional senior officer casualties included the wounding of Union Generals Dan Sickles (lost a leg) and Winfield Scott Hancock. For the Confederacy, Major General John Bell Hood lost the use of his left arm, while Major General Henry Heth received a shot to the head on the first day of battle (Though incapacitated for the rest of the battle, he remarkably survived without long term injuries, credited in part due to his hat stuffed full of paper dispatches). Confederate Generals James Kemper and Isaac R. Trimble were severely wounded during Pickett's charge and captured during the Confederate retreat. General James J. Archer, in command of a brigade that most likely was responsible for killing Reynolds, was taken prisoner shortly after Reynolds' death.\n\nThe following tables summarize casualties by corps for the Union and Confederate forces during the three-day battle.\n\nBruce Catton wrote, \"The town of Gettysburg looked as if some universal moving day had been interrupted by catastrophe.\" But there was only one documented civilian death during the battle: Ginnie Wade (also widely known as Jennie), 20 years old, was hit by a stray bullet that passed through her kitchen in town while she was making bread. Another notable civilian casualty was John L. Burns, a 69-year old veteran of the War of 1812 who walked to the front lines on the first day of battle and participated in heavy combat as a volunteer, receiving numerous wounds in the process. Despite his age and injuries, Burns survived the battle and lived until 1872. Nearly 8,000 had been killed outright; these bodies, lying in the hot summer sun, needed to be buried quickly. Over 3,000 horse carcasses were burned in a series of piles south of town; townsfolk became violently ill from the stench. Meanwhile, the town of Gettysburg, with its population of just 2,400, found itself tasked with taking care of 14,000 wounded Union troops and an additional 8,000 Confederate prisoners.\n\nThe armies stared at one another in a heavy rain across the bloody fields on July 4, the same day that the Vicksburg garrison surrendered to Maj. Gen. Ulysses S. Grant. Lee had reformed his lines into a defensive position on Seminary Ridge the night of July 3, evacuating the town of Gettysburg. The Confederates remained on the battlefield, hoping that Meade would attack, but the cautious Union commander decided against the risk, a decision for which he would later be criticized. Both armies began to collect their remaining wounded and bury some of the dead. A proposal by Lee for a prisoner exchange was rejected by Meade.\n\nLee started his Army of Northern Virginia in motion late the evening of July 4 towards Fairfield and Chambersburg. Cavalry under Brig. Gen. John D. Imboden was entrusted to escort the miles-long wagon train of supplies and wounded men that Lee wanted to take back to Virginia with him, using the route through Cashtown and Hagerstown to Williamsport, Maryland. Meade's army followed, although the pursuit was half-spirited. The recently rain-swollen Potomac trapped Lee's army on the north bank of the river for a time, but when the Union troops finally caught up, the Confederates had forded the river. The rear-guard action at Falling Waters on July 14 added some more names to the long casualty lists, including General Pettigrew, who was mortally wounded. General James Kemper, severely wounded during Pickett's charge, was captured during Lee's retreat.\n\nIn a brief letter to Maj. Gen. Henry W. Halleck written on July 7, Lincoln remarked on the two major Union victories at Gettysburg and Vicksburg. He continued:\n\nHalleck then relayed the contents of Lincoln's letter to Meade in a telegram. Despite repeated pleas from Lincoln and Halleck, which continued over the next week, Meade did not pursue Lee's army aggressively enough to destroy it before it crossed back over the Potomac River to safety in the South. The campaign continued into Virginia with light engagements until July 23, in the minor Battle of Manassas Gap, after which Meade abandoned any attempts at pursuit and the two armies took up positions across from each other on the Rappahannock River.\n\nThe news of the Union victory electrified the North. A headline in \"The Philadelphia Inquirer\" proclaimed \"VICTORY! WATERLOO ECLIPSED!\" New York diarist George Templeton Strong wrote:\n\nHowever, the Union enthusiasm soon dissipated as the public realized that Lee's army had escaped destruction and the war would continue. Lincoln complained to Secretary of the Navy Gideon Welles that \"Our army held the war in the hollow of their hand and they would not close it!\" Brig. Gen. Alexander S. Webb wrote to his father on July 17, stating that such Washington politicians as \"Chase, Seward and others,\" disgusted with Meade, \"write to me that Lee really won that Battle!\"\n\nIn fact, the Confederates had lost militarily and also politically. During the final hours of the battle, Confederate Vice President Alexander Stephens was approaching the Union lines at Norfolk, Virginia, under a flag of truce. Although his formal instructions from Confederate President Jefferson Davis had limited his powers to negotiate on prisoner exchanges and other procedural matters, historian James M. McPherson speculates that he had informal goals of presenting peace overtures. Davis had hoped that Stephens would reach Washington from the south while Lee's victorious army was marching toward it from the north. President Lincoln, upon hearing of the Gettysburg results, refused Stephens's request to pass through the lines. Furthermore, when the news reached London, any lingering hopes of European recognition of the Confederacy were finally abandoned. Henry Adams wrote, \"The disasters of the rebels are unredeemed by even any hope of success. It is now conceded that all idea of intervention is at an end.\"\n\nCompounding the effects of the defeat would be end of the Siege of Vicksburg, which surrendered to Grant's Federal armies in the West on July 4, the day after the Gettysburg battle.\n\nThe immediate reaction of the Southern military and public sectors was that Gettysburg was a setback, not a disaster. The sentiment was that Lee had been successful on July 1 and had fought a valiant battle on July 2–3, but could not dislodge the Union Army from the strong defensive position to which it fled. The Confederates successfully stood their ground on July 4 and withdrew only after they realized Meade would not attack them. The withdrawal to the Potomac that could have been a disaster was handled masterfully. Furthermore, the Army of the Potomac had been kept away from Virginia farmlands for the summer and all predicted that Meade would be too timid to threaten them for the rest of the year. Lee himself had a positive view of the campaign, writing to his wife that the army had returned \"rather sooner than I had originally contemplated, but having accomplished what I proposed on leaving the Rappahannock, viz., relieving the Valley of the presence of the enemy and drawing his Army north of the Potomac.\" He was quoted as saying to Maj. John Seddon, brother of the Confederate secretary of war, \"Sir, we did whip them at Gettysburg, and it will be seen for the next six months that \"that army\" will be as quiet as a sucking dove.\" Some Southern publications, such as the \"Charleston Mercury\", criticized Lee's actions in the campaign and on August 8, he offered his resignation to President Davis, who quickly rejected it.\n\nGettysburg became a postbellum focus of the \"Lost Cause\", a movement by writers such as Edward A. Pollard and Jubal Early to explain the reasons for the Confederate defeat in the war. A fundamental premise of their argument was that the South was doomed because of the overwhelming advantage in manpower and industrial might possessed by the North. However, they claim it also suffered because Robert E. Lee, who up until this time had been almost invincible, was betrayed by the failures of some of his key subordinates at Gettysburg: Ewell, for failing to seize Cemetery Hill on July 1; Stuart, for depriving the army of cavalry intelligence for a key part of the campaign; and especially Longstreet, for failing to attack on July 2 as early and as forcefully as Lee had originally intended. In this view, Gettysburg was seen as a great lost opportunity, in which a decisive victory by Lee could have meant the end of the war in the Confederacy's favor.\n\nAfter the war, General Pickett was asked why Confederates lost at Gettysburg. He replied \"I always thought the Yankees had something to do with it.\"\n\nThe ravages of war were still evident in Gettysburg more than four months later when, on November 19, the Soldiers' National Cemetery was dedicated. During this ceremony, President Abraham Lincoln honored the fallen and redefined the purpose of the war in his historic Gettysburg Address.\n\nThe nature of the result of the Battle of Gettysburg has been the subject of controversy for years. Although not seen as overwhelmingly significant at the time, particularly since the war continued for almost two years, in retrospect it has often been cited as the \"turning point\", usually in combination with the fall of Vicksburg the following day. This is based on the observation that after Gettysburg Lee's army conducted no more strategic offensives—his army merely reacted to the initiative of Ulysses S. Grant in 1864 and 1865—and by the speculative viewpoint of the Lost Cause writers that a Confederate victory at Gettysburg might have resulted in the end of the war.\nIt is currently a widely held view that Gettysburg was a decisive victory for the Union, but the term is considered imprecise. It is inarguable that Lee's offensive on July 3 was turned back decisively and his campaign in Pennsylvania was terminated prematurely (although the Confederates at the time argued that this was a temporary setback and that the goals of the campaign were largely met). However, when the more common definition of \"decisive victory\" is intended—an indisputable military victory of a battle that determines or significantly influences the ultimate result of a conflict—historians are divided. For example, David J. Eicher called Gettysburg a \"strategic loss for the Confederacy\" and James M. McPherson wrote that \"Lee and his men would go on to earn further laurels. But they never again possessed the power and reputation they carried into Pennsylvania those palmy summer days of 1863.\"\n\nHowever, Herman Hattaway and Archer Jones wrote that the \"strategic impact of the Battle of Gettysburg was ... fairly limited.\" Steven E. Woodworth wrote that \"Gettysburg proved only the near impossibility of decisive action in the Eastern theater.\" Edwin Coddington pointed out the heavy toll on the Army of the Potomac and that \"after the battle Meade no longer possessed a truly effective instrument for the accomplishments of his task. The army needed a thorough reorganization with new commanders and fresh troops, but these changes were not made until Grant appeared on the scene in March 1864.\" Joseph T. Glatthaar wrote that \"Lost opportunities and near successes plagued the Army of Northern Virginia during its Northern invasion,\" yet after Gettysburg, \"without the distractions of duty as an invading force, without the breakdown of discipline, the Army of Northern Virginia [remained] an extremely formidable force.\" Ed Bearss wrote, \"Lee's invasion of the North had been a costly failure. Nevertheless, at best the Army of the Potomac had simply preserved the strategic stalemate in the Eastern Theater ...\" Furthermore, the Confederacy soon proved it was still capable of winning significant victories over the Northern forces in both the East (Battle of Cold Harbor) and West (Battle of Chickamauga).\n\nPeter Carmichael refers to the military context for the armies, the \"horrendous losses at Chancellorsville and Gettysburg, which effectively destroyed Lee's offensive capacity,\" implying that these cumulative losses were not the result of a single battle. Thomas Goss, writing in the U.S. Army's \"Military Review\" journal on the definition of \"decisive\" and the application of that description to Gettysburg, concludes: \"For all that was decided and accomplished, the Battle of Gettysburg fails to earn the label 'decisive battle'.\" The military historian John Keegan agrees. Gettysburg was a landmark battle, the largest of the war and it would not be surpassed. The Union had restored to it the belief in certain victory, and the loss dispirited the Confederacy. If \"not exactly a decisive battle\", Gettysburg was the end of Confederate use of Northern Virginia as a military buffer zone, the setting for Grant's Overland Campaign.\n\nPrior to Gettysburg, Robert E. Lee had established a reputation as an almost invincible general, achieving stunning victories against superior numbers—although usually at the cost of high casualties to his army—during the Seven Days, the Northern Virginia Campaign (including the Second Battle of Bull Run), Fredericksburg, and Chancellorsville. Only the Maryland Campaign, with its tactically inconclusive Battle of Antietam, had been less than successful. Therefore, historians have attempted to explain how Lee's winning streak was interrupted so dramatically at Gettysburg. Although the issue is tainted by attempts to portray history and Lee's reputation in a manner supporting different partisan goals, the major factors in Lee's loss arguably can be attributed to: (1) his overconfidence in the invincibility of his men; (2) the performance of his subordinates, and his management thereof; (3) his failing health, and (4) the performance of his opponent, George G. Meade, and the Army of the Potomac.\nThroughout the campaign, Lee was influenced by the belief that his men were invincible; most of Lee's experiences with the Army of Northern Virginia had convinced him of this, including the great victory at Chancellorsville in early May and the rout of the Union troops at Gettysburg on July 1. Since morale plays an important role in military victory when other factors are equal, Lee did not want to dampen his army's desire to fight and resisted suggestions, principally by Longstreet, to withdraw from the recently captured Gettysburg to select a ground more favorable to his army. War correspondent Peter W. Alexander wrote that Lee \"acted, probably, under the impression that his troops were able to carry any position however formidable. If such was the case, he committed an error, such however as the ablest commanders will sometimes fall into.\" Lee himself concurred with this judgment, writing to President Davis, \"No blame can be attached to the army for its failure to accomplish what was projected by me, nor should it be censured for the unreasonable expectations of the public—I am alone to blame, in perhaps expecting too much of its prowess and valor.\"\n\nThe most controversial assessments of the battle involve the performance of Lee's subordinates. The dominant theme of the Lost Cause writers and many other historians is that Lee's senior generals failed him in crucial ways, directly causing the loss of the battle; the alternative viewpoint is that Lee did not manage his subordinates adequately, and did not thereby compensate for their shortcomings. Two of his corps commanders—Richard S. Ewell and A.P. Hill—had only recently been promoted and were not fully accustomed to Lee's style of command, in which he provided only general objectives and guidance to their former commander, Stonewall Jackson; Jackson translated these into detailed, specific orders to his division commanders. All four of Lee's principal commanders received criticism during the campaign and battle:\nIn addition to Hill's illness, Lee's performance was affected by heart troubles, which would eventually lead to his death in 1870; he had been diagnosed with pericarditis by his staff physicians in March 1863, though modern doctors believe he had in fact suffered a heart attack. He wrote to Jefferson Davis that his physical condition prevented him from offering full supervision in the field, and said, \"I am so dull that in making use of the eyes of others I am frequently misled.\"\n\nAs a final factor, Lee faced a new and formidable opponent in George G. Meade, and the Army of the Potomac fought well on its home territory. Although new to his army command, Meade deployed his forces relatively effectively; relied on strong subordinates such as Winfield S. Hancock to make decisions where and when they were needed; took great advantage of defensive positions; nimbly shifted defensive resources on interior lines to parry strong threats; and, unlike some of his predecessors, stood his ground throughout the battle in the face of fierce Confederate attacks.\n\nLee was quoted before the battle as saying Meade \"would commit no blunders on my front and if I make one ... will make haste to take advantage of it.\" That prediction proved to be correct at Gettysburg. Stephen Sears wrote, \"The fact of the matter is that George G. Meade, unexpectedly and against all odds, thoroughly outgeneraled Robert E. Lee at Gettysburg.\" Edwin B. Coddington wrote that the soldiers of the Army of the Potomac received a \"sense of triumph which grew into an imperishable faith in [themselves]. The men knew what they could do under an extremely competent general; one of lesser ability and courage could well have lost the battle.\"\n\nMeade had his own detractors as well. Similar to the situation with Lee, Meade suffered partisan attacks about his performance at Gettysburg, but he had the misfortune of experiencing them in person. Supporters of his predecessor, Maj. Gen. Joseph Hooker, lambasted Meade before the U.S. Congress's Joint Committee on the Conduct of the War, where Radical Republicans suspected that Meade was a Copperhead and tried in vain to relieve him from command. Daniel E. Sickles and Daniel Butterfield accused Meade of planning to retreat from Gettysburg during the battle. Most politicians, including Lincoln, criticized Meade for what they considered to be his half-hearted pursuit of Lee after the battle. A number of Meade's most competent subordinates—Winfield S. Hancock, John Gibbon, Gouverneur K. Warren, and Henry J. Hunt, all heroes of the battle—defended Meade in print, but Meade was embittered by the overall experience.\n\nToday, the Gettysburg National Cemetery and Gettysburg National Military Park are maintained by the U.S. National Park Service as two of the nation's most revered historical landmarks. Although Gettysburg is one of the best known of all Civil War battlefields, it too faces threats to its preservation and interpretation. Many historically significant locations on the battlefield lie outside the boundaries of Gettysburg National Military Park and are vulnerable to residential or commercial development.\n\nOn July 20, 2009, a Comfort Inn and Suites opened on Cemetery Hill, adjacent to Evergreen Cemetery, just one of many modern edifices infringing on the historic field. The Baltimore Pike corridor attracts development that concerns preservationists.\n\nSome preservation successes have emerged in recent years. Two proposals to open a casino at Gettysburg were defeated in 2006 and most recently in 2011, when public pressure forced the Pennsylvania Gaming Control Board to reject the proposed gambling hub at the intersection of Routes 15 and 30, near East Cavalry Field. The Civil War Trust also successfully purchased and transferred 95 acres at the former site of the Gettysburg Country Club to the control of the U.S. Department of the Interior in 2011.\n\nLess than half of the over 11,500 acres on the old Gettysburg Battlefield have been preserved for posterity thus far. The Civil War Trust has preserved 815 acres around the site, some of which is now part of the 4,998 acres of Gettysburg National Military Park.\n\nDuring the Civil War Centennial, the U.S. Post Office issued five postage stamps commemorating the 100th anniversaries of famous battles, as they occurred over a four-year period, beginning with the Battle of Fort Sumter Centennial issue of 1961. The Battle of Shiloh commemorative stamp was issued in 1962, the Battle of Gettysburg in 1963, the Battle of the Wilderness in 1964, and the Appomattox Centennial commemorative stamp in 1965.\n\nA commemorative half dollar for the battle was produced in 1936. As was typical for the period, mintage for the coin was very low, just 26,928. On January 24, 2011, the America the Beautiful quarters released a 25-cent coin commemorating Gettysburg National Military Park and the Battle of Gettysburg. The reverse side of the coin depicts the monument on Cemetery Ridge to the 72nd Pennsylvania Infantry.\nFilm records survive of two Gettysburg reunions, held on the battlefield. At the 50th anniversary (1913), veterans re-enacted Pickett's Charge in a spirit of reconciliation, a meeting that carried great emotional force for both sides. At the 75th anniversary (1938), 2500 veterans attended, and there was a ceremonial mass hand-shake across a stone wall. This was recorded on sound film, and some Confederates can be heard giving the Rebel Yell.\n\nIced Earth's three-part song cycle \"Gettysburg (1863)\", published in 2004, dramatizes the battle.\n\nThe Battle of Gettysburg was depicted in the 1993 film \"Gettysburg\", based on Michael Shaara's 1974 novel \"The Killer Angels\". The film and novel focused primarily on the actions of Joshua Lawrence Chamberlain, John Buford, Robert E. Lee, and James Longstreet during the battle. The first day focused on Buford's cavalry defense, the second day on Chamberlain's defense at Little Round Top, and the third day on Pickett's Charge.\n\nThe south winning the Battle of Gettysburg is a popular premise for a point of divergence in American Civil War alternate histories. Here are some examples which either depict or make significant reference to an alternate Battle of Gettysburg (sometimes simply inserting fantasy or sci-fi elements in an account of the battle):\n\n\n\n\n\n"}
{"id": "4851", "url": "https://en.wikipedia.org/wiki?curid=4851", "title": "Budweiser", "text": "Budweiser\n\nBudweiser () is an American-style pale lager produced by Anheuser-Busch, currently part of the multinational corporation Anheuser-Busch InBev. Introduced in 1876 by Carl Conrad & Co. of St. Louis, Missouri, it has grown to become one of the largest selling beers in the United States, and is available in over 80 markets worldwidethough, due to a trademark dispute, does not necessarily do so under the Budweiser name. It is made with up to 30% rice in addition to hops and barley malt. Produced in various breweries around the world, Budweiser is a filtered beer available in draft and packaged forms.\n\nAnheuser–Busch has been involved in a trademark dispute with European beer companies, in particular the Budweiser Budvar Brewery of České Budějovice, Czech Republic, over the trademark rights to the name \"Budweiser\". Beer has been brewed in České Budějovice (known as \"Budweis\" in German) since it was founded by King Ottokar II of Bohemia in 1245. The name Budweiser is a derivative adjective, meaning \"of Budweis\". In 1876, Adolphus Busch and his friend Carl Conrad, a liquor importer, developed a \"Bohemian-style\" lager in the United States, inspired after a trip to the region.\n\nIn the European Union, excluding the United Kingdom, Republic of Ireland, Finland and Spain, the American beer is marketed as \"Bud\", as the Budweiser trademark name is owned solely by the Czech beer maker, Budweiser Budvar.\n\nIn 2008, Anheuser-Busch had a market share in the United States of 50.9% for all beers sold. Budweiser brands account for about half of Anheuser-Busch's sales volume, a figure which has been steadily declining at 1½-2% per year. In 2008, the Belgian-Brazilian beer giant InBev bought the majority of Anheuser-Busch stock at $70 per share in an all-cash agreement, creating the largest brewing company in the world.\n\nAnheuser-Busch advertises the Budweiser brand heavily, expending $449 million in 2012 in the United States. This made it the most advertised beverage brand in America and accounted for a third of the company's US marketing budget.\n\nThe Budweiser from Budějovice has been called \"The Beer of Kings\" since the 16th century. Adolphus Busch adapted this slogan to \"The King Of Beers.\"\n\nThis history notwithstanding, Anheuser Busch owns the trademark to both slogans in the United States.\n\nIn 2010, the Bud Light brand paid $1 billion for a six-year licensing agreement with the NFL. Budweiser pays $20 million annually for MLB licensing rights.\n\nBudweiser has produced a number of TV advertisements, such as the Budweiser Frogs, lizards impersonating the Budweiser frogs, a campaign built around the phrase \"Whassup?\", and a team of Clydesdale horses commonly known as the Budweiser Clydesdales.\n\nBudweiser also advertises extensively in motorsports, from Bernie Little's Miss Budweiser hydroplane boat to sponsorship of the Budweiser King Top Fuel Dragster driven by Brandon Bernstein. Anheuser-Busch has sponsored the CART championship. It is the \"Official Beer of NHRA\" and it was the \"Official Beer of NASCAR\" from 1998 to 2007. It has sponsored motorsport events such as the Daytona Speedweeks, Budweiser Shootout, Budweiser Duel, Budweiser Pole Award, Budweiser 500, Budweiser 400, Budweiser 300, Budweiser 250, Budweiser 200, and Carolina Pride / Budweiser 200. However, starting in 2016, the focus of A-B's NASCAR sponsorship became its Busch brand.\n\nBudweiser has been sponsor of NASCAR teams such as Junior Johnson, Hendrick Motorsports, DEI, and Stewart-Haas Racing. Sponsored drivers include Dale Earnhardt, Jr. (1999-2007), Kasey Kahne (2008-2010), and Kevin Harvick (2011–2015). In IndyCar, Budweiser sponsored Mario Andretti (1983-1984), Bobby Rahal (1985-1988), Scott Pruett (1989-1992), Roberto Guerrero (1993), Scott Goodyear (1994), Paul Tracy (1995), Christian Fittipaldi (1996-1997), and Richie Hearn (1998-1999).\n\nAnheuser-Busch has placed Budweiser as an official partner and sponsor of Major League Soccer and Los Angeles Galaxy and was the headline sponsor of the British Basketball League in the 1990s. Anheuser-Busch has also placed Budweiser as an official sponsor of the Premier League and the presenting sponsor of the FA Cup.\n\nIn the early 20th century, the company commissioned a play-on-words song called \"Under the Anheuser Bush,\" which was recorded by several early phonograph companies.\n\nIn 2009, Anheuser-Busch partnered with popular Chinese video-sharing site, Tudou.com for a user-generated online video contest. The contest encourages users to suggest ideas that include ants for a Bud TV spot set to run in February 2010 during the Chinese New Year.\n\nIn 2010, Budweiser produced an online reality TV series, called \"Bud House,\" centered around the 2010 FIFA World Cup in South Africa, following the lives of 32 international football fans (one representing each nation in the World Cup) living together in a house in South Africa.\n\nOn November 5, 2012, Anheuser-Busch asked Paramount Pictures to obscure or remove the Budweiser logo from the film \"Flight\" (2012), directed by Robert Zemeckis and starring Denzel Washington.\n\nIn an advertisement titled \"Brewed the Hard Way\" that aired during Super Bowl XLIX, Budweiser touted itself as \"Proudly A Macro Beer\", distinguishing it from smaller production craft beers.\n\nIn 2016, Beer Park by Budweiser opened on the Las Vegas Strip.\n\nOver the years, Budweiser has been distributed in many sizes and containers. Until the early 1950s Budweiser was primarily distributed in three packages: kegs, bottles and bottles. Cans were first introduced in 1936, which helped sales to climb. In 1955 August Busch Jr. made a strategic move to expand Budweiser's national brand and distributor presence. Along with this expansion came advances in bottling automation, new bottling materials and more efficient distribution methods. These advances brought to market many new containers and package designs. Budweiser is distributed in four large container volumes: half-barrel kegs (), quarter-barrel kegs (), 1/6 barrel kegs () and \"beer balls\". Budweiser produces a variety of cans and bottles ranging from . On August 3, 2011, Anheuser-Busch announced its twelfth can design since 1936, one which emphasizes the bowtie.\n\nPackages are sometimes tailored to local customs and traditions. In St. Mary's County, Maryland, ten ounce cans are the preferred package.\n\nThe Budweiser bottle has remained relatively unchanged since its introduction in 1876. A small label is affixed to the neck of the bottle with the Budweiser \"bow-tie\" logo. The main label is red with a white box in the center, overlaid with a Budweiser logo resembling a coat of arms, with the word \"Budweiser\" below it.\n\nIn attempt to re-stimulate interest in their beer after the repeal of Prohibition, Budweiser began canning their beer in 1936. This new packaging led to an increase in sales which lasted until the start of World War II in 1939.\n\nOver the years, Budweiser cans have undergone various design changes in response to market conditions and consumer tastes. Since 1936, 12 major can design changes have occurred, not including the temporary special edition designs.\n\nBudweiser cans have traditionally displayed patriotic American symbols, such a eagles and the colors red, white, and blue. In 2011, there was a branding redesign of that eliminated some of the traditional imagery. The new design was largely in response to the huge decline in sales threatening Budweiser's status as America's best-selling beer. In order to regain the domestic market share that Budweiser has lost, the company tried to update its appearance by giving the can a more contemporary look. The company hopes that the new design will offset the effects that unemployment had on its sales. Although the more modern design is intended for young male Americans, the new design was also part of an attempt to focus on the international market. Budweiser began selling its beer in Russia in 2010, and is currently expanding its operations in China.\n\nBudweiser is brewed using barley malt, rice, water, hops and yeast. It is lagered with beechwood chips in the aging vessel. While beechwood chips are used in the maturation tank, there is little to no flavor contribution from the wood, mainly because they are boiled in sodium bicarbonate [baking soda] for seven hours for the very purpose of removing any flavor from the wood. The maturation tanks that Anheuser-Busch uses are horizontal and, as such, flocculation of the yeast occurs much more quickly. Anheuser-Busch refers to this process as a secondary fermentation, with the idea being that the chips give the yeast more surface area to rest on. This is also combined with a krausening procedure that re-introduces wort into the chip tank, therefore reactivating the fermentation process. By placing the beechwood chips at the bottom of the tank, the yeast remains in suspension longer, giving it more time to reabsorb and process green beer flavors, such as acetaldehyde and diacetyl, that Anheuser-Busch believes are off-flavors which detract from overall drinkability.\nSome drinkers prefer the lightness of beers like Budweiser and consume it as a refreshment or for its inebriating effects. Several beer writers consider it to be bland. The beer is light-bodied with faint sweet notes and negligible bitterness, leading to reviews characterizing it as a \"...beer of underwhelming blandness.\" Even Adolphus Busch disliked the beer he marketed in the United States. But based upon sales alone, it became the second most popular American brewed pale lager among North American beer consumers.\n\nBudweiser and \"Bud Light\" are sometimes advertised as vegan beers, in that their ingredients and conditioning do not use animal by-products. Some may object to the inclusion of genetically engineered rice and animal products used in the brewing process. In July 2006, Anheuser-Busch brewed a version of Budweiser with organic rice, for sale in Mexico. It has yet to extend this practice to any other countries.\n\nIn addition to the regular Budweiser, Anheuser-Busch brews several different beers under the Budweiser brand, including Bud Light and Bud Ice.\n\nIn July 2010, Anheuser-Busch launched Budweiser 66 in the United Kingdom. Budweiser Brew No.66 has 4% alcohol by volume, and is brewed and distributed in the UK by Inbev UK Limited.\n\nOn May 10, 2016, \"Advertising Age\" reported that the Alcohol and Tobacco Tax and Trade Bureau had approved new Budweiser labels to be used on 12-ounce cans and bottles from May 23 until the November elections. The name \"Budweiser\" was changed to \"America\" (even though the parent company is based in Belgium, a fact which resulted in objections on Twitter). Much of the text on the packaging was replaced with patriotic American slogans, such as E Pluribus Unum and \"Liberty & Justice For All\".\n\nBudweiser is licensed, produced and distributed in Canada by Labatt Breweries of Canada. Of the 15 Anheuser-Busch breweries outside of the United States, 14 of them are positioned in China. Budweiser is the fourth leading brand in the Chinese beer market.\n\n\n"}
{"id": "4854", "url": "https://en.wikipedia.org/wiki?curid=4854", "title": "Bermuda Triangle", "text": "Bermuda Triangle\n\nThe Bermuda Triangle, also known as the Devil's Triangle, is a loosely-defined region in the western part of the North Atlantic Ocean, where a number of aircraft and ships are said to have disappeared under mysterious circumstances. Most reputable sources dismiss the idea that there is any mystery. The vicinity of the Bermuda Triangle is one of the most heavily traveled shipping lanes in the world, with ships frequently crossing through it for ports in the Americas, Europe, and the Caribbean islands. Cruise ships and pleasure craft regularly sail through the region, and commercial and private aircraft routinely fly over it.\n\nPopular culture has attributed various disappearances to the paranormal or activity by extraterrestrial beings. Documented evidence indicates that a significant percentage of the incidents were spurious, inaccurately reported, or embellished by later authors.\n\nIn 1964, Vincent Gaddis wrote in the pulp magazine \"Argosy\" of the boundaries of the Bermuda Triangle, giving its vertices as Miami, San Juan, Puerto Rico, and Bermuda. Subsequent writers did not necessarily follow this definition. Some writers gave different boundaries and vertices to the triangle, with the total area varying from . Consequently, the determination of which accidents occurred inside the triangle depends on which writer reported them. The United States Board on Geographic Names does not recognize the Bermuda Triangle.\n\nThe earliest suggestion of unusual disappearances in the Bermuda area appeared in a September 17, 1950, article published in \"The Miami Herald\" (Associated Press) by Edward Van Winkle Jones. Two years later, \"Fate\" magazine published \"Sea Mystery at Our Back Door\", a short article by George X. Sand covering the loss of several planes and ships, including the loss of Flight 19, a group of five US Navy Grumman TBM Avenger torpedo bombers on a training mission. Sand's article was the first to lay out the now-familiar triangular area where the losses took place. Flight 19 alone would be covered again in the April 1962 issue of \"American Legion\" magazine. In it, author Allan W. Eckert wrote that the flight leader had been heard saying, \"We are entering white water, nothing seems right. We don't know where we are, the water is green, no white.\" He also wrote that officials at the Navy board of inquiry stated that the planes \"flew off to Mars.\" Sand's article was the first to suggest a supernatural element to the Flight 19 incident. In the February 1964 issue of \"Argosy\", Vincent Gaddis' article \"The Deadly Bermuda Triangle\" argued that Flight 19 and other disappearances were part of a pattern of strange events in the region. The next year, Gaddis expanded this article into a book, \"Invisible Horizons\".\n\nOthers would follow with their own works, elaborating on Gaddis' ideas: John Wallace Spencer (\"Limbo of the Lost\", 1969, repr. 1973); Charles Berlitz (\"The Bermuda Triangle\", 1974); Richard Winer (\"The Devil's Triangle\", 1974), and many others, all keeping to some of the same supernatural elements outlined by Eckert.\n\nLawrence David Kusche, author of \"The Bermuda Triangle Mystery: Solved\" (1975) argued that many claims of Gaddis and subsequent writers were often exaggerated, dubious or unverifiable. Kusche's research revealed a number of inaccuracies and inconsistencies between Berlitz's accounts and statements from eyewitnesses, participants, and others involved in the initial incidents. Kusche noted cases where pertinent information went unreported, such as the disappearance of round-the-world yachtsman Donald Crowhurst, which Berlitz had presented as a mystery, despite clear evidence to the contrary. Another example was the ore-carrier recounted by Berlitz as lost without trace three days out of an \"Atlantic\" port when it had been lost three days out of a port with the same name in the \"Pacific\" Ocean. Kusche also argued that a large percentage of the incidents that sparked allegations of the Triangle's mysterious influence actually occurred well outside it. Often his research was simple: he would review period newspapers of the dates of reported incidents and find reports on possibly relevant events like unusual weather, that were never mentioned in the disappearance stories.\n\nKusche concluded that:\n\nIn a 2013 study, the World Wide Fund for Nature identified the world's 10 most dangerous waters for shipping, but the Bermuda Triangle was not among them.\n\nWhen the UK Channel 4 television program \"The Bermuda Triangle\" (1992) was being produced by John Simmons of Geofilms for the \"Equinox\" series, the marine insurance market Lloyd's of London was asked if an unusually large number of ships had sunk in the Bermuda Triangle area. Lloyd's determined that large numbers of ships had not sunk there. Lloyd's does not charge higher rates for passing through this area. United States Coast Guard records confirm their conclusion. In fact, the number of supposed disappearances is relatively insignificant considering the number of ships and aircraft that pass through on a regular basis.\n\nThe Coast Guard is also officially skeptical of the Triangle, noting that they collect and publish, through their inquiries, much documentation contradicting many of the incidents written about by the Triangle authors. In one such incident involving the 1972 explosion and sinking of the tanker , the Coast Guard photographed the wreck and recovered several bodies, in contrast with one Triangle author's claim that all the bodies had vanished, with the exception of the captain, who was found sitting in his cabin at his desk, clutching a coffee cup. In addition, \"V. A. Fogg\" sank off the coast of Texas, nowhere near the commonly accepted boundaries of the Triangle.\n\nThe NOVA/Horizon episode \"The Case of the Bermuda Triangle\", aired on June 27, 1976, was highly critical, stating that \"When we've gone back to the original sources or the people involved, the mystery evaporates. Science does not have to answer questions about the Triangle because those questions are not valid in the first place ... Ships and planes behave in the Triangle the same way they behave everywhere else in the world.\"\n\nSkeptical researchers, such as Ernest Taves and Barry Singer, have noted how mysteries and the paranormal are very popular and profitable. This has led to the production of vast amounts of material on topics such as the Bermuda Triangle. They were able to show that some of the pro-paranormal material is often misleading or inaccurate, but its producers continue to market it. Accordingly, they have claimed that the market is biased in favor of books, TV specials, and other media that support the Triangle mystery, and against well-researched material if it espouses a skeptical viewpoint.\n\nPersons accepting the Bermuda Triangle as a real phenomenon have offered a number of explanatory approaches.\n\nTriangle writers have used a number of supernatural concepts to explain the events. One explanation pins the blame on leftover technology from the mythical lost continent of Atlantis. Sometimes connected to the Atlantis story is the submerged rock formation known as the Bimini Road off the island of Bimini in the Bahamas, which is in the Triangle by some definitions. Followers of the purported psychic Edgar Cayce take his prediction that evidence of Atlantis would be found in 1968, as referring to the discovery of the Bimini Road. Believers describe the formation as a road, wall, or other structure, but the Bimini Road is of natural origin.\n\nOther writers attribute the events to UFOs. This idea was used by Steven Spielberg for his science fiction film \"Close Encounters of the Third Kind\", which features the lost Flight 19 aircrews as alien abductees.\n\nCharles Berlitz, author of various books on anomalous phenomena, lists several theories attributing the losses in the Triangle to anomalous or unexplained forces.\n\nA paranormal explanation in the 2005 three-part US-British-German science fiction miniseries \"The Triangle\", says the triangle is a wormhole.\n\nCompass problems are one of the cited phrases in many Triangle incidents. While some have theorized that unusual local magnetic anomalies may exist in the area, such anomalies have not been found. Compasses have natural magnetic variations in relation to the magnetic poles, a fact which navigators have known for centuries. Magnetic (compass) north and geographic (true) north are only exactly the same for a small number of places – for example, as of 2000, in the United States, only those places on a line running from Wisconsin to the Gulf of Mexico. But the public may not be as informed, and think there is something mysterious about a compass \"changing\" across an area as large as the Triangle, which it naturally will.\n\nThe Gulf Stream is a major surface current, primarily driven by thermohaline circulation that originates in the Gulf of Mexico and then flows through the Straits of Florida into the North Atlantic. In essence, it is a river within an ocean, and, like a river, it can and does carry floating objects. It has a maximum surface velocity of about . A small plane making a water landing or a boat having engine trouble can be carried away from its reported position by the current.\n\nOne of the most cited explanations in official inquiries as to the loss of any aircraft or vessel is human error. Human stubbornness may have caused businessman Harvey Conover to lose his sailing yacht, \"Revonoc\", as he sailed into the teeth of a storm south of Florida on January 1, 1958.\n\nHurricanes are powerful storms that form in tropical waters and have historically cost thousands of lives and caused billions of dollars in damage. The sinking of Francisco de Bobadilla's Spanish fleet in 1502 was the first recorded instance of a destructive hurricane. These storms have in the past caused a number of incidents related to the Triangle.\n\nA powerful downdraft of cold air was suspected to be a cause in the sinking of \"Pride of Baltimore\" on May 14, 1986. The crew of the sunken vessel noted the wind suddenly shifted and increased velocity from to . A National Hurricane Center satellite specialist, James Lushine, stated \"during very unstable weather conditions the downburst of cold air from aloft can hit the surface like a bomb, exploding outward like a giant squall line of wind and water.\" A similar event occurred to \"Concordia\" in 2010, off the coast of Brazil. Scientists are currently investigating whether \"hexagonal\" clouds may be the source of these up-to- \"air bombs\".\n\nAn explanation for some of the disappearances has focused on the presence of large fields of methane hydrates (a form of natural gas) on the continental shelves. Laboratory experiments carried out in Australia have proven that bubbles can, indeed, sink a scale model ship by decreasing the density of the water; any wreckage consequently rising to the surface would be rapidly dispersed by the Gulf Stream. It has been hypothesized that periodic methane eruptions (sometimes called \"mud volcanoes\") may produce regions of frothy water that are no longer capable of providing adequate buoyancy for ships. If this were the case, such an area forming around a ship could cause it to sink very rapidly and without warning.\n\nPublications by the USGS describe large stores of undersea hydrates worldwide, including the Blake Ridge area, off the coast of the southeastern United States. However, according to the USGS, no large releases of gas hydrates are believed to have occurred in the Bermuda Triangle for the past 15,000 years.\n\n\"Ellen Austin\" supposedly came across a derelict ship, placed on board a prize crew, and attempted to sail with it to New York in 1881. According to the stories, the derelict disappeared; others elaborating further that the derelict reappeared minus the prize crew, then disappeared again with a second prize crew on board. A check from Lloyd's of London records proved the existence of \"Meta\", built in 1854, and that in 1880, \"Meta\" was renamed \"Ellen Austin\". There are no casualty listings for this vessel, or any vessel at that time, that would suggest a large number of missing men were placed on board a derelict that later disappeared.\n\nThe incident resulting in the single largest loss of life in the history of the US Navy not related to combat occurred when the collier \"Cyclops\", carrying a full load of manganese ore and with one engine out of action, went missing without a trace with a crew of 309 sometime after March 4, 1918, after departing the island of Barbados. Although there is no strong evidence for any single theory, many independent theories exist, some blaming storms, some capsizing, and some suggesting that wartime enemy activity was to blame for the loss. In addition, two of \"Cyclops\"s sister ships, and were subsequently lost in the North Atlantic during World War II. Both ships were transporting heavy loads of metallic ore similar to that which was loaded on \"Cyclops\" during her fatal voyage. In all three cases structural failure due to overloading with a much denser cargo than designed is considered the most likely cause of sinking.\n\nA five-masted schooner built in 1919, \"Carroll A. Deering\" was found hard aground and abandoned at Diamond Shoals, near Cape Hatteras, North Carolina, on January 31, 1921. Rumors and more at the time indicated \"Deering\" was a victim of piracy, possibly connected with the illegal rum-running trade during Prohibition, and possibly involving another ship, , which disappeared at roughly the same time. Just hours later, an unknown steamer sailed near the lightship along the track of \"Deering\", and ignored all signals from the lightship. It is speculated that \"Hewitt\" may have been this mystery ship, and possibly involved in \"Deering\"s crew disappearance.\n\nFlight 19 was a training flight of five TBM Avenger torpedo bombers that disappeared on December 5, 1945, while over the Atlantic. The squadron's flight plan was scheduled to take them due east from Fort Lauderdale for , north for , and then back over a final leg to complete the exercise. The flight never returned to base. The disappearance is attributed by Navy investigators to navigational error leading to the aircraft running out of fuel.\n\nOne of the search and rescue aircraft deployed to look for them, a PBM Mariner with a 13-man crew, also disappeared. A tanker off the coast of Florida reported seeing an explosion and observing a widespread oil slick when fruitlessly searching for survivors. The weather was becoming stormy by the end of the incident. According to contemporaneous sources the Mariner had a history of explosions due to vapour leaks when heavily loaded with fuel, as it might have been for a potentially long search-and-rescue operation.\n\nG-AHNP \"Star Tiger\" disappeared on January 30, 1948, on a flight from the Azores to Bermuda; G-AGRE \"Star Ariel\" disappeared on January 17, 1949, on a flight from Bermuda to Kingston, Jamaica. Both were Avro Tudor IV passenger aircraft operated by British South American Airways. Both planes were operating at the very limits of their range and the slightest error or fault in the equipment could keep them from reaching the small island.\n\nOn December 28, 1948, a Douglas DC-3 aircraft, number NC16002, disappeared while on a flight from San Juan, Puerto Rico, to Miami. No trace of the aircraft, or the 32 people on board, was ever found. A Civil Aeronautics Board investigation found there was insufficient information available on which to determine probable cause of the disappearance.\n\nA pleasure yacht was found adrift in the Atlantic south of Bermuda on September 26, 1955; it is usually stated in the stories (Berlitz, Winer) that the crew vanished while the yacht survived being at sea during three hurricanes. The 1955 Atlantic hurricane season shows Hurricane Ione passing nearby between 14 and 18 September, with Bermuda being affected by winds of almost gale force. In his second book on the Bermuda Triangle, Winer quoted from a letter he had received from Mr J.E. Challenor of Barbados:\n\nOn the morning of September 22, \"Connemara IV\" was lying to a heavy mooring in the open roadstead of Carlisle Bay. Because of the approaching hurricane, the owner strengthened the mooring ropes and put out two additional anchors. There was little else he could do, as the exposed mooring was the only available anchorage. ... In Carlisle Bay, the sea in the wake of Hurricane Janet was awe-inspiring and dangerous. The owner of \"Connemara IV\" observed that she had disappeared. An investigation revealed that she had dragged her moorings and gone to sea.\n\nOn August 28, 1963, a pair of US Air Force KC-135 Stratotanker aircraft collided and crashed into the Atlantic. The Triangle version (Winer, Berlitz, Gaddis) of this story states that while the two aircraft did collide and crash, there were two distinct crash sites, separated by over of water. However, Kusche's research showed that the unclassified version of the Air Force investigation report stated that the debris field defining the second \"crash site\" was examined by a search and rescue ship, and found to be a mass of seaweed and driftwood tangled in an old buoy.\n\n\nNotes\nBibliography<br>\nThe incidents cited above, apart from the official documentation, come from the following works. Some incidents mentioned as having taken place within the Triangle are found \"only\" in these sources:\n\nFurther reading\nProQuest has newspaper source material for many incidents, archived in Portable Document Format (PDF). The newspapers include \"The New York Times\", \"The Washington Post\", and \"The Atlanta Constitution\". To access this website, registration is required, usually through a library connected to a college or university.\n\nFlight 19\n\nSS \"Cotopaxi\"\n\nUSS \"Cyclops\" (AC-4)\n\nCarroll A. Deering\n\nWreckers\n\nS.S. \"Suduffco\"\n\nStar Tiger\" and \"Star Ariel\n\nDC-3 Airliner NC16002 disappearance\n\nHarvey Conover and \"Revonoc\"\n\nKC-135 Stratotankers\n\nB-52 Bomber (\"Pogo 22\")\n\nCharter vessel \"Sno'Boy\"\n\nSS \"Marine Sulphur Queen\"\n\nSS \"Sylvia L. Ossa\"\n\nThe following websites have either online material that supports the popular version of the Bermuda Triangle, or documents published from official sources as part of hearings or inquiries, such as those conducted by the United States Navy or United States Coast Guard. Copies of some inquiries are not online and may have to be ordered; for example, the losses of Flight 19 or USS Cyclops can be ordered direct from the United States Naval Historical Center.\n\nMost of the works listed here are largely out of print. Copies may be obtained at your local library, or purchased used at bookstores, or through eBay or Amazon.com. These books are often the \"only\" source material for some of the incidents that have taken place within the Triangle.\n"}
{"id": "4856", "url": "https://en.wikipedia.org/wiki?curid=4856", "title": "Borough", "text": "Borough\n\nA borough is an administrative division in various English-speaking countries. In principle, the term \"borough\" designates a self-governing walled town, although in practice, official use of the term varies widely.\n\nThe word \"borough\" derives from common Proto-Germanic \"*burgz\", meaning \"fort\": compare with \"bury\", \"burgh\" and \"brough\" (England), \"burgh\" (Scotland), \"Burg\" (Germany), \"borg\" (Scandinavia), \"burcht\" (Dutch), \"boarch\" (West Frisian), and the Germanic borrowing present in neighbouring Indo-european languages such as \"borgo\" (Italian), \"bourg\" (French), \"burgo\" (Spanish and Portuguese), \"burg\" (Romanian), \"purg\" (Kajkavian) and \"durg\" (दर्ग) (Hindi) and \"arg\" (ارگ) (Persian). The incidence of these words as suffixes to place names (for example, Aldeburgh, Bamburgh, Tilbury, Tilburg, Strasbourg (Strossburi in the local dialect), Luxembourg, Edinburgh, Grundisburgh, Hamburg, Gothenburg) usually indicates that they were once fortified settlements.\n\nIn the Middle Ages, boroughs were settlements in England that were granted some self-government; burghs were the Scottish equivalent. In medieval England, boroughs were also entitled to elect members of parliament. The use of the word \"borough\" probably derives from the burghal system of Alfred the Great. Alfred set up a system of defensive strong points (Burhs); in order to maintain these settlements, he granted them a degree of autonomy. After the Norman Conquest, when certain towns were granted self-governance, the concept of the burh/borough seems to have been reused to mean a self-governing settlement.\n\nThe concept of the borough has been used repeatedly (and often differently) throughout the world. Often, a borough is a single town with its own local government. However, in some cities it is a subdivision of the city (for example, New York City, London, and Montreal). In such cases, the borough will normally have either limited powers delegated to it by the city's local government, or no powers at all. In other places, such as the U.S. state of Alaska, \"borough\" designates a whole region; Alaska's largest borough, the North Slope Borough, is comparable in area to the entire United Kingdom, although its population is less than that of Swanage on England's south coast with around 9,600 inhabitants. In Australia, a \"borough\" was once a self-governing small town, but this designation has all but vanished, except for the only remaining borough in the country, which is the Borough of Queenscliffe.\n\nBoroughs as administrative units are to be found in Ireland and the United Kingdom, more specifically in England and Northern Ireland. Boroughs also exist in the Canadian province of Quebec and formerly in Ontario, in some states of the United States, in Israel, formerly in New Zealand and only one left in Australia.\n\nThe word \"borough\" derives from the Old English word \"burh\", meaning a fortified settlement. Other English derivatives of \"burh\" include \"bury\", \"brough\" and \"burgh\". There are obvious cognates in other Indo-European languages. For example; \"burgh\" in Scots and Middle English; \"burg\" in German and Old English, \"borg\" in Scandinavian languages; \"parcus\" in Latin and \"pyrgos\" in Greek, \"برج\" (borj) in Persian.\n\nA number of other European languages have cognate words that were borrowed from the Germanic languages during the Middle Ages, including \"brog\" in Irish, \"bwr\" or \"bwrc\", meaning \"wall, rampart\" in Welsh, \"bourg\" in French, \"burg\" in Catalan (in Catalonia there is a town named \"Burg\"), \"borgo\" in Italian, and \"burgo\" in Spanish (hence the place-name Burgos).\n\nThe 'burg' element, which means \"castle\" or \"fortress\", is often confused with 'berg' meaning \"hill\" or \"mountain\" (c.f. iceberg, inselberg). Hence the 'berg' element in Bergen or Heidelberg relates to a hill, rather than a fort. In some cases, the 'berg' element in place names has converged towards burg/borough; for instance Farnborough, from \"fernaberga\" (fern-hill).\n\nIn many parts of England, \"borough\" is pronounced as an independent word, and as when a suffix of a place-name. As a suffix, it is sometimes spelled \"-brough\".\n\nIn the United States, \"borough\" is pronounced or . When appearing as the suffix \"-burg(h)\" in place-names, it is pronounced .\n\nIn Australia, the term \"borough\" is an occasionally used term for a local government area. Currently there is only one borough in Australia, the Borough of Queenscliffe in Victoria, although there have been more in the past. However, in some cases it can be integrated into the council's name instead of used as an official title, such as the Municipality of Kingborough in Tasmania.\n\nIn Quebec, the term borough is generally used as the English translation of arrondissement, referring to an administrative division of a municipality. Only eight municipalities in Quebec are divided into boroughs. See List of boroughs in Quebec.\n\nIt was previously used in Metropolitan Toronto, Ontario, to denote suburban municipalities including Scarborough, York, North York, Etobicoke prior to their conversion into cities. The Borough of East York was the last Toronto municipality to hold this status, relinquishing it upon becoming part of the City of Toronto on January 1, 1998.\n\nThe Colombian Municipalities are subdivided into boroughs with a local executive and an administrative board for local government.\nThese Boroughs are divided in neighborhoods.\n\nThe Local Government Reform Act 2014 replaced the urban-only second-tier local government units with new urban and rural units termed \"municipal districts\". The abolished units included five which were termed \"boroughs\", namely Clonmel, Drogheda, Kilkenny, Sligo, and Wexford. However, the municipal districts containing four of these are styled \"borough districts\"; the exception is Kilkenny, whose district is the \"Municipal District of Kilkenny City\", because of Kilkenny's city status.\n\nEarlier Irish boroughs include the 117 parliamentary boroughs of the Irish House of Commons, of which 80 were disfranchised by the Acts of Union 1800 and all but 11 abolished under the Municipal Corporations (Ireland) Act 1840. The six largest of those eleven became county boroughs under the Local Government (Ireland) Act 1898, of which those in the Republic were reclassed as \"cities\" under the Local Government Act 2001. Galway was a borough from 1937 until promoted to county borough in 1985, and Dún Laoghaire was a borough from 1930 until merged into Dún Laoghaire–Rathdown county in 1993.\n\nUnder Israeli law, inherited from British Mandate municipal law, the possibility of creating a municipal borough exists. However, no borough was actually created under law until 2005–2006, when Neve Monosson and Maccabim-Re'ut, both communal settlements (Heb: yishuv kehilati) founded in 1953 and 1984, respectively, were declared to be autonomous municipal boroughs (Heb: vaad rova ironi), within their mergers with the towns of Yehud and Modi'in. Similar structures have been created under different types of legal status over the years in Israel, notably Kiryat Haim in Haifa, Jaffa in Tel Aviv-Yafo and Ramot and Gilo in Jerusalem. However, Neve Monosson is the first example of a full municipal borough actually declared under law by the Minister of the Interior, under a model subsequently adopted in Maccabim-Re'ut as well.\n\nIt is the declared intention of the Interior Ministry to use the borough mechanism in order to facilitate municipal mergers in Israel, after a 2003 wide-reaching merger plan, which, in general, ignored the sensitivities of the communal settlements, and largely failed.\n\nIn Mexico as translations from English to Spanish applied to Mexico City, the word \"borough\" has resulted in a delegación (delegation), referring to the 16 administrative areas within the Mexican Federal District. Also the municipalities of some states are administratively subdivided into boroughs, as shown in Municipality of Mexicali#Boroughs. (see: Boroughs of Mexico and Municipalities of Mexico City)\n\nIn the Netherlands, the municipalities of Rotterdam and Amsterdam are divided into administrative boroughs, or deelgemeenten, which have their own borough council and a borough mayor. Other large cites are usually divided into districts, or stadsdelen, for census purposes.\n\nNew Zealand formerly used the term borough to designate self-governing towns of more than 1,000 people, although 19th century census records show many boroughs with populations as low as 200. A borough of more than 20,000 people could become a city by proclamation. Boroughs and cities were collectively known as municipalities, and were enclaves separate from their surrounding counties. Boroughs proliferated in the suburban areas of the larger cities: By the 1980s there were 19 boroughs and three cities in the area that is now the City of Auckland.\n\nIn the 1980s, some boroughs and cities began to be merged with their surrounding counties to form districts with a mixed urban and rural population. A nationwide reform of local government in 1989 completed the process. Counties and boroughs were abolished and all boundaries were redrawn. Under the new system, most territorial authorities cover both urban and rural land. The more populated councils are classified as cities, and the more rural councils are classified as districts. Only Kawerau District, an enclave within Whakatāne District, continues to follow the tradition of a small town council that does not include surrounding rural area.\n\nDuring the medieval period many towns were granted self-governance by the Crown, at which point they became referred to as boroughs. The formal status of borough came to be conferred by Royal Charter. These boroughs were generally governed by a self-selecting corporation (i.e., when a member died or resigned his replacement would be by co-option). Sometimes boroughs were governed by bailiffs or headboroughs.\n\nDebates on the Reform Bill (eventually the Reform Act 1832) had highlighted the variations in systems of governance of towns, and a Royal Commission was set up to investigate the issue. This resulted in a regularisation of municipal government (Municipal Corporations Act 1835). 178 of the ancient boroughs were reformed as \"municipal boroughs\", with all municipal corporations to be elected according to a standard franchise based on property ownership. The unreformed boroughs either lapsed in borough status, or were reformed (or abolished) at a later time. Several new municipal boroughs were formed in the new industrial cities after the bill enacted, according to the provisions of the bill.\n\nAs part of a large-scale reform of local government in England and Wales in 1974, municipal boroughs were finally abolished (having become increasingly irrelevant). However, the civic traditions of many boroughs were continued by the grant of a charter to their successor district councils. In smaller boroughs, a town council was formed for the area of the abolished borough, while charter trustees were formed in other former boroughs. In each case, the new body was allowed to use the regalia of the old corporation, and appoint ceremonial office holders such as sword and mace bearers as provided in their original charters. The council or trustees may apply for an Order in Council or Royal Licence to use the former borough coat of arms.\n\nFrom 1265, two burgesses from each borough were summoned to the Parliament of England, alongside two knights from each county. Thus parliamentary constituencies were derived from the ancient boroughs. Representation in the House of Commons was decided by the House itself, which resulted in boroughs being established in some small settlements for the purposes of parliamentary representation, despite their possessing no actual corporation.\n\nAfter the Reform Act, which disenfranchised many of the rotten boroughs (boroughs that had declined in importance, had only a small population, and had only a handful of eligible voters), parliamentary constituencies began to diverge from the ancient boroughs. While many ancient boroughs remained as municipal boroughs, they were disenfranchised by the Reform Act.\n\nThe Local Government Act 1888 established a new sort of borough – the county borough. These were designed to be 'counties-to-themselves'; administrative divisions to sit alongside the new administrative counties. They allowed urban areas to be administered separately from the more rural areas. They, therefore, often contained pre-existing municipal boroughs, which thereafter became part of the second tier of local government, below the administrative counties and county boroughs.\n\nThe county boroughs were, like the municipal boroughs, abolished in 1974, being reabsorbed into their parent counties for administrative purposes.\n\nIn 1899, as part of a reform of local government in the County of London, the various parishes in London were reorganised as new entities, the 'metropolitan boroughs'. These were reorganised further when Greater London was formed out of Middlesex and the County of London in 1965.\n\nWhen the new metropolitan counties (Greater Manchester, Merseyside, South Yorkshire, Tyne and Wear, West Midlands, and West Yorkshire) were created in 1974, their sub-divisions also became metropolitan boroughs; in many cases these metropolitan boroughs recapitulated abolished county boroughs (for example, Stockport). The metropolitan boroughs possessed slightly more autonomy from the metropolitan county councils than the shire county districts did from their county councils.\n\nWith the abolition of the metropolitan county councils in 1986, these metropolitan boroughs became independent, and continue to be so at present.\n\nElsewhere in England a number of districts and unitary authority areas are called \"borough\". Until 1974, this was a status that denoted towns with a certain type of local government (a municipal corporation). Since 1974, it has been a purely ceremonial style granted by royal charter to districts which may consist of a single town or may include a number of towns or rural areas. Borough status entitles the council chairman to bear the title of mayor. Districts may apply to the British Crown for the grant of borough status upon advice of the Privy Council of the United Kingdom.\n\nIn Northern Ireland, local government was reorganised in 1973. Under the legislation that created the 26 districts of Northern Ireland, a district council whose area included an existing municipal borough could resolve to adopt the charter of the old municipality and thus continue to enjoy borough status. Districts that do not contain a former borough can apply for a charter in a similar manner to English districts.\n\nIn the United States, a borough is a unit of local government below the level of the state. The term is currently used in seven states.\n\nThe following states use, or have used, the word with the following meanings:\n\nCertain names of places, such as Hillsboro, Oregon; Greensboro, North Carolina; Tyngsborough, Massachusetts; and Maynesborough, New Hampshire reflect the historical use of \"borough\" as a geographical unit in the United States.\n\n\n"}
{"id": "4858", "url": "https://en.wikipedia.org/wiki?curid=4858", "title": "Bodmin", "text": "Bodmin\n\nBodmin () is a civil parish and historic town in Cornwall, England, United Kingdom. It is situated south-west of Bodmin Moor.\n\nThe extent of the civil parish corresponds fairly closely to that of the town so is mostly urban in character. It is bordered to the east by Cardinham parish, to the southeast by Lanhydrock parish, to the southwest and west by Lanivet parish, and to the north by Helland parish.\n\nBodmin had a population of 12,778 (2001 census). This population had increased to 14,736 at the 2011 Census. It was formerly the county town of Cornwall until the Crown Courts moved to Truro which is also the administrative centre (before 1835 the county town was Launceston). Bodmin was in the administrative North Cornwall District until local government reorganisation in 2009 abolished the District (\"see also Cornwall Council\"). The town is part of the North Cornwall parliamentary constituency, which is represented by Scott Mann MP.\n\nBodmin Town Council is made up of sixteen councillors who are elected to serve a term of four years. Each year, the Council elects one of its number as Mayor to serve as the town's civic leader and to chair council meetings.\n\nBodmin lies in the east of Cornwall, south-west of Bodmin Moor. It has been suggested that the town's name comes from an archaic word in the Cornish language \"bod\" (meaning a dwelling; the later word is \"bos\") and a contraction of \"menegh\" (monks). The \"monks' dwelling\" may refer to an early monastic settlement instituted by St. Guron, which St. Petroc took as his site. Guron is said to have departed to St Goran on the arrival of Petroc.\n\nThe hamlets of Cooksland, Dunmere and Turfdown are in the parish.\n\nSt. Petroc founded a monastery in Bodmin in the 6th century and gave the town its alternative name of \"Petrockstow\". The monastery was deprived of some of its lands at the Norman conquest but at the time of Domesday still held eighteen manors, including Bodmin, Padstow and Rialton. Bodmin is one of the oldest towns in Cornwall, and the only large Cornish settlement recorded in the Domesday Book in 1086. In the 15th century the Norman church of St Petroc was largely rebuilt and stands as one of the largest churches in Cornwall (the largest after the cathedral at Truro). Also built at that time was an abbey of canons regular, now mostly ruined. For most of Bodmin's history, the tin industry was a mainstay of the economy.\n\nThe name of the town probably derives from the Cornish \"Bod-meneghy\", meaning \"dwelling of or by the sanctuary of monks\". Variant spellings recorded include \"Botmenei\" in 1100, \"Bodmen\" in 1253, \"Bodman\" in 1377 and \"Bodmyn\" in 1522. The \"Bodman\" spelling also appears in sources and maps from the 16th and 17th centuries, most notably in the celebrated map of Cornwall produced by John Speed but actually engraved by the Dutch cartographer Jodocus Hondius the Elder (1563–1612) in Amsterdam in 1610 (published in London by Sudbury and Humble in 1626). It is unclear whether the Bodman spelling signifies any historical or monastic connection with the equally ancient settlement of Bodman at the western end of the Bodensee in the German province of Baden.\n\nAn inscription on a stone built into the wall of a summer house in Lancarffe furnishes proof of a settlement in Bodmin in the early Middle Ages. It is a memorial to one \"Duno[.]atus son of Me[.]cagnus\" and has been dated from the 6th to 8th centuries.\nArthur Langdon (1896) records three Cornish crosses at Bodmin; one was near the Berry Tower, one was outside Bodmin Gaol and another was in a field near Castle Street Hill. There is also Carminow Cross at a road junction southeast of the town.\nThe Black Death killed half of Bodmin's population in the mid 14th century (1,500 people).\n\nBodmin was the centre of three Cornish uprisings. The first was the Cornish Rebellion of 1497 when a Cornish army, led by Michael An Gof, a blacksmith from St. Keverne and Thomas Flamank, a lawyer from Bodmin, marched to Blackheath in London where they were eventually defeated by 10,000 men of the King's army under Baron Daubeny. Then, in the autumn of 1497, Perkin Warbeck tried to usurp the throne from Henry VII. Warbeck was proclaimed King Richard IV in Bodmin but Henry had little difficulty crushing the uprising. In 1549, Cornishmen, allied with other rebels in neighbouring Devon, rose once again in rebellion when the staunchly Protestant Edward VI tried to impose a new Prayer Book. The lower classes of Cornwall and Devon were still strongly attached to the Catholic religion and again a Cornish army was formed in Bodmin which marched across the border into Devon to lay siege to Exeter. This became known as the Prayer Book Rebellion. Proposals to translate the Prayer Book into Cornish were suppressed and in total 4,000 people were killed in the rebellion.\n\nThe Borough of Bodmin was one of the 178 municipal boroughs which under the auspices of the Municipal Corporations Act 1835 was mandated to create an electable council and a Police Watch Committee responsible for overseeing a police force in the town. The new system directly replaced the Parish Constables that had policed the borough since time immemorial and brought paid, uniformed and accountable law enforcement for the first time. Bodmin Borough Police was the municipal police force for the Borough of Bodmin from 1836 to 1866. The creation of the Cornwall Constabulary in 1857 put pressure on smaller municipal police forces to merge with the county. The two-man force of Bodmin came under threat almost immediately, but it would take until 1866 for the Mayor of Bodmin and the Chairman of the Police Watch Committee to agree on the terms of amalgamation. After a public enquiry, the force was disbanded in January 1866 and policing of the borough was deferred to the county from thereon.\n\nThe song \"Bodmin Town\" was collected from the Cornishman William Nichols at Whitchurch, Devon, in 1891 by Sabine Baring-Gould who published a version in his \"A Garland of Country Song\" (1924).\n\nThe existing church building is dated 1469–72 and was until the building of Truro Cathedral the largest church in Cornwall. The tower which remains from the original Norman church and stands on the north side of the church (the upper part is 15th century) was, until the loss of its spire in 1699, 150 ft high. The building underwent two Victorian restorations and another in 1930. It is now listed Grade I. There are a number of interesting monuments, most notably that of Prior Vivian which was formerly in the Priory Church (Thomas Vivian's effigy lying on a chest: black Catacleuse stone and grey marble). The font of a type common in Cornwall is of the 12th century: large and finely carved.\n\nThe Chapel of St Thomas Becket is a ruin of a 14th-century building in Bodmin churchyard. The holy well of St Guron is a small stone building at the churchyard gate. The Berry Tower is all that remains of the former church of the Holy Rood and there are even fewer remains from the substantial Franciscan Friary established ca. 1240: a gateway in Fore Street and two pillars elsewhere in the town. The Roman Catholic Abbey of St Mary and St Petroc, formerly belonging to the Canons Regular of the Lateran was built in 1965 next to the already existing seminary. The Roman Catholic parish of Bodmin includes a large area of North Cornwall and there are churches also at Wadebridge, Padstow and Tintagel. In 1881 the Roman Catholic mass was celebrated in Bodmin for the first time since 1539. A church was planned in the 1930s but delayed by the Second World War: the Church of St Mary and St Petroc was eventually consecrated in 1965: it was built next to the already existing seminary. There are also five other churches in Bodmin, including a Methodist church.\n\nBodmin Jail, operational for over 150 years but now a semi-ruin, was built in the late 18th century, and was the first British prison to hold prisoners in separate cells (though often up to ten at a time) rather than communally. Over fifty prisoners condemned at the Bodmin Assize Court were hanged at the prison. It was also used for temporarily holding prisoners sentenced to transportation, awaiting transfer to the prison hulks lying in the highest navigable reaches of the River Fowey. Also, during the First World War the prison held some of Britain's priceless national treasures including the Domesday Book, the ring and the Crown Jewels of the United Kingdom.\n\nOther buildings of interest include the former Shire Hall, now a tourist information centre, and Victoria Barracks, formerly depot of the now defunct Duke of Cornwall's Light Infantry and now the site of the regimental museum. It includes the history of the regiment from 1702, plus a military library. The original barracks house the regimental museum which was founded in 1925. There is a fine collection of small arms and machine guns, plus maps, uniforms and paintings on display.\n\nBodmin County Lunatic Asylum was designed by John Foulston and afterwards George Wightwick. William Robert Hicks the humorist was domestic superintendent in the mid-19th century.\n\nThere is a sizable single storey Masonic Hall in St Nicholas Street, which is home to no less than seven Masonic bodies.\n\nBodmin Beacon Local Nature Reserve is the hill overlooking the town. The reserve has 83 acres (33.6 ha) of public land and at its highest point it reaches 162 metres with the distinctive landmark at the summit. The 44-metre tall monument to Sir Walter Raleigh Gilbert was built in 1857 by the townspeople of Bodmin to honour the soldier's life and work in India.\n\nIn 1966, the \"\"Finn VC Estate\"\" was named in honour of Victoria Cross winner James Henry Finn who once lived in the town. An ornate granite drinking bowl which serves the needs of thirsty dogs at the entrance to Bodmin’s Priory car park was donated by Prince Chula Chakrabongse of Thailand who lived at Tredethy.\n\nThere are no independent schools in the area.\n\nSt Petroc's Voluntary Aided Church of England Primary School, Athelstan Park, Bodmin, was given this title in September 1990 after the amalgamation of St. Petroc's Infant School and St. Petroc's Junior School. St. Petroc's is a large school with some 440 pupils between the ages of four and 11. Eight of its fourteen governors are nominated by the Diocese of Truro or the Parochial Church Council of St. Petroc's, Bodmin.\n\nThere are a further three primary schools within Bodmin; Berrycoombe School in the northwest corner of the town, and St. Mary's Catholic Primary School and Beacon ACE Academy both situated west of the town centre. Beacon ACE Academy is part of the Atlantic Centre of Excellence Multi Academy Trust.\n\nBodmin College is a large state comprehensive school for ages 11–18 on the outskirts of the town and on the edge of Bodmin Moor. Its headmaster is Mr Brett Elliott. The college is home to the nationally acclaimed \"Bodmin College Jazz Orchestra\", founded and run by the previous Director of Music, Adrian Evans, until 2007 and more recently, by the current Director, Ben Vincent. In 1997, Systems & Control students at Bodmin College constructed Roadblock, a robot which entered and won the first series of Robot Wars and was succeeded by \"The Beast of Bodmin\" (presumably named after the phantom cat purported to roam Bodmin Moor). The school also has one of the largest sixth forms in the county.\n\nCallywith College is a Further Education college in Bodmin, Cornwall, due to open in September 2017, with applications being accepted from September 2016. A new-build college on a site close to the Bodmin Asda supermarket, it will eventually cater for 1,280 students, with 197 staff employed. A total of 660 places will be available in its first year. It is being created with the assistance of the Ofsted Outstanding Truro and Penwith College to serve students aged 16–19 from Bodmin, North Cornwall and East Cornwall. It received the go-ahead in February 2016, funded as a Free School. Its aim is to \"provide the outstanding Truro and Penwith College experience for up to 1280 young people in Bodmin and North and East Cornwall.\" \n\nAspirant National Service Sergeant Instructors of the Royal Army Education Corps underwent training at the Army School of Education, situated at the end of the Second World War at Buchanan Castle, Drymen in Scotland, and later, from 1948, at the Walker Lines, Bodmin, until it moved to Wilton Park, Beaconsfield.\n\nBodmin Parkway railway station is a principal calling point on the Cornish Main Line about 3½ miles (5½ km) south-east of the town centre. Buses to central Bodmin, Wadebridge and Padstow depart from outside the station entrance. \n\nBus and coach services connect Bodmin with some other districts of Cornwall and Devon.\n\nBodmin has a non-league football club Bodmin Town playing in the South West Peninsula League; a level 10 league in the English football league system. Their home ground is at Priory Park. Bodmin Rugby Club play rugby union at Clifden Parc and compete in the Tribute Cornwall/Devon league; a level 8 league in the English rugby union system.\n\nThe Royal Cornwall Golf Club (now defunct) was located on Bodmin Moor. It was founded in 1889. The club disbanded following WW2.\n\nThere is an active running club: Bodmin RoadRunners.\n\nThe \"Cornish Guardian\" is a weekly newspaper published every Wednesday in seven separate editions, including the Bodmin edition.\n\nBodmin is the home of NCB Radio, an Internet radio station which aims to bring a dedicated station to North Cornwall.\n\nSee also \n\nBodmin is twinned with Bederkesa in Germany; Grass Valley, in California, United States; and Le Relecq-Kerhuon (Ar Releg-Kerhuon in Brittany), France.\n\nW. H. Pascoe’s 1979 \"A Cornish Armory\" gives the arms of the priory and the monastery and the seal of the borough.\n\nOn Halgaver Moor (Goats' Moor) near Bodmin there was once an annual carnival in July which was on one occasion attended by King Charles II. Halgaver is in the parish of Lanhydrock.\n\nBodmin Riding, a horseback procession through the town, is a traditional annual ceremony.\n\nIn 1865–66 William Robert Hicks was mayor of Bodmin, when he revived the custom of Beating the bounds of the town. He was — according to the Dictionary of National Biography — a very good man of business. This still takes place more or less every five years and concludes with a game of Cornish hurling. Hurling survives as a traditional part of beating the bounds at Bodmin, commencing at the close of the 'Beat'. The game is organised by the Rotary club of Bodmin and was last played in 2015. The game is started by the Mayor of Bodmin by throwing a silver ball into a body of water known as the \"Salting Pool\". There are no teams and the hurl follows a set route. The aim is to carry the ball from the \"Salting Pool\" via the old A30, along Callywith Road, then through Castle Street, Church Square and Honey Street to finish at the Turret Clock in Fore Street. The participant carrying the ball when it reaches the turret clock will receive a £10 reward from the mayor. \nIn 2015, beating of the bounds and Cornish hurling took place at Bodmin 8 April organised by the Rotary club of Bodmin.\n\n\n\n"}
{"id": "4859", "url": "https://en.wikipedia.org/wiki?curid=4859", "title": "Bodmin Moor", "text": "Bodmin Moor\n\nBodmin Moor () is a granite moorland in northeastern Cornwall, England. It is in size, and dates from the Carboniferous period of geological history. It includes Brown Willy, the highest point in Cornwall, and Rough Tor, a slightly lower peak. Many of Cornwall's rivers have their sources here. It has been inhabited since at least the Neolithic era, when primitive farmers started clearing trees and farming the land. They left their megalithic monuments, hut circles and cairns, and the Bronze Age culture that followed left further cairns, and more stone circles and stone rows. By medieval and modern times, nearly all the forest was gone and livestock rearing predominated.\n\nThe name Bodmin Moor is relatively recent, an Ordnance Survey invention of 1813. The upland area was formerly known as Fowey Moor after the River Fowey, which rises within it.\n\nBodmin Moor is one of five granite plutons in Cornwall that make up part of the Cornubian batholith (see also Geology of Cornwall).\n\nDramatic granite tors rise from the rolling moorland: the best known are Brown Willy, the highest point in Cornwall at , and Rough Tor at . To the south-east Kilmar Tor and Caradon Hill are the most prominent hills. Considerable areas of the moor are poorly drained and form marshes (in hot summers these can dry out). The rest of the moor is mostly rough pasture or overgrown with heather and other low vegetation.\n\nThe moor contains about 500 holdings with around 10,000 beef cows, 55,000 breeding ewes and 1,000 horses and ponies. Most of the moor is a Site of Special Scientific Interest (SSSI), \"Bodmin Moor, North\", and has been officially designated an Area of Outstanding Natural Beauty (AONB), as part of Cornwall AONB. Almost a third of Cornwall has AONB designation, with the same status and protection as a National Park. The moor has been identified by BirdLife International as an Important Bird Area (IBA) because it supports about 260 breeding pairs of European stonechats as well as a wintering population of 10,000 Eurasian golden plovers. The moor has also been recognised as a separate natural region and designated as national character area 153 by Natural England.\n\nBodmin Moor is the source of several of Cornwall's rivers: they are mentioned here anti-clockwise from the south.\n\nThe River Fowey rises at a height of and flows through Lostwithiel and into the Fowey estuary.\n\nThe River Tiddy rises near Pensilva and flows southeast to its confluence with the River Lynher (the Lynher flows generally south-east until it joins the Hamoaze near Plymouth). The River Inny rises near Davidstow and flows southeast to its confluence with the River Tamar.\n\nThe River Camel rises on Hendraburnick Down and flows for approximately before joining the sea at Padstow. The River Camel and its tributary the De Lank River are an important habitat for the otter and both have been proposed as Special Areas of Conservation (SAC) The De Lank River rises near Roughtor and flows along an irregular course before joining the Camel south of Wenford.\n\nThe River Warleggan rises near Temple and flows south to join the Fowey.\n\nOn the southern slopes of the moor lies Dozmary Pool. It is Cornwall's only natural inland lake and is glacial in origin. In the 20th century three reservoirs have been constructed on the moor; these are Colliford Lake, Siblyback Lake and Crowdy reservoirs which supply water for a large part of the county's population. Various species of waterfowl are resident around these waters.\n\nThe parishes on the moor are as follows:\n\n10,000 years ago, in the Mesolithic period, hunter-gatherers wandered the area when it was wooded. There are several documented cases of flint scatters being discovered by archaeologists, indicating that these hunter gatherers practised flint knapping in the region.\n\nDuring the Neolithic era, from about 4,500 to 2,300 BC, people began clearing trees and farming the land. It was also in this era that the production of various megalithic monuments began, predominantly long cairns (three of which have currently been identified, at Louden, Catshole and Bearah) and stone circles (sixteen of which have been identified). It was also likely that the naturally forming tors were also viewed in a similar manner to the manmade ceremonial sites.\n\nIn the following Bronze Age, the creation of monuments increased dramatically, with the production of over 300 further cairns, and more stone circles and stone rows. More than 200 Bronze Age settlements with enclosures and field patterns have been recorded. and many prehistoric stone barrows and circles lie scattered across the moor. In a programme shown in 2007 Channel 4's \"Time Team \"investigated a 500-metre cairn and the site of a Bronze Age village on the slopes of Rough Tor.\n\nKing Arthur's Hall thought to be a late Neolithic or early Bronze Age ceremonial site can be found to the east of St Breward on the moor.\n\nWhere practicable areas of the moor were used for pasture by herdsmen from the parishes surrounding the moor. Granite boulders were also taken from the moor and used for stone posts and to a certain extent for building (such material is known as moorstone). Granite quarrying only became reasonably productive when gunpowder became available.\n\nThe moor gave its name (Foweymore) to one of the medieval districts called stannaries which administered tin mining: the boundaries of these were never defined precisely. Until the establishment of a turnpike road through the moor (the present A30) in the 1770s the size of the moorland area made travel within Cornwall very difficult.\n\nIts Cornish name, Goen Bren, is first recorded in the 12th century.\n\nEnglish Heritage monographs \"Bodmin Moor: An Archaeological Survey\" Volume 1 and Volume 2 covering the post-medieval and modern landscape are publicly available through the Archaeology Data Service.\n\nRoughtor was the site of a medieval chapel of St Michael and is now designated as a memorial to the 43rd Wessex Division of the British Army. In 1844 on Bodmin Moor the body of 18-year-old Charlotte Dymond was discovered. Local labourer Matthew Weeks was accused of the murder and at noon on 12 August 1844 he was led from Bodmin Gaol and hanged. The murder site now has a monument erected from public money and the grave is at Davidstow churchyard.\n\nDozmary Pool is identified by some people with the lake in which, according to Arthurian legend, Sir Bedivere threw Excalibur to The Lady of the Lake. Another legend relating to the pool concerns Jan Tregeagle.\n\nThe Beast of Bodmin has been reported many times but never identified with certainty.\n\n\"Cornish Cowboy\", a 2014 short documentary film screened at the 2015 Cannes Film Festival, was shot on Bodmin Moor. The film features the work of St Neot horse trainer, Dan Wilson.\n\n\n\n"}

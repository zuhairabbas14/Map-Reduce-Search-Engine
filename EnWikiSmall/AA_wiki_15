{"id": "2338", "url": "https://en.wikipedia.org/wiki?curid=2338", "title": "Rise and Fall of the City of Mahagonny", "text": "Rise and Fall of the City of Mahagonny\n\nRise and Fall of the City of Mahagonny () is a political-satirical opera composed by Kurt Weill to a German libretto by Bertolt Brecht. It was first performed on 9 March 1930 at the in Leipzig.\n\nThe libretto was mainly written in early 1927 and the music was finished in the spring of 1929, although both text and music were partly revised by the authors later. An early by-product, however, was the \"Mahagonny-Songspiel\", sometimes known as \"Das kleine Mahagonny\", a concert work for voices and small orchestra commissioned by the Deutsche Kammermusik Festival in Baden-Baden and premiered there on 18 July 1927. The ten numbers, which include the \"Alabama Song\" and \"Benares Song\", were duly incorporated into the full opera. The opera had its premiere in Leipzig in March 1930 and played in Berlin in December of the following year. The opera was banned by the Nazis in 1933 and did not have a significant production until the 1960s.\n\nWeill's score uses a number of styles, including rag-time, jazz and formal counterpoint, notably in the \"Alabama Song\" (covered by multiple artists, notably Ute Lemper, The Doors and David Bowie).\n\nThe lyrics for the \"Alabama Song\" and another song, the \"Benares Song\" are in English (albeit specifically idiosyncratic English) and are performed in that language even when the opera is performed in its original (German) language. The name of the city itself is a mix between the English and German word for mahogany, \"Mahagoni\".\n\nIt has played in opera houses around the world. Never achieving the popularity of Weill and Brecht's \"The Threepenny Opera,\" \"Mahagonny\" is still considered a work of stature with a haunting score. Herbert Lindenberger in his book \"Opera in History\", for example, views \"Mahagonny\" alongside Schoenberg's \"Moses und Aron\" as indicative of the two poles of modernist opera.\n\nFollowing the Leipzig premiere, the opera was presented in Berlin in December 1931 at the Theater am Schiffbauerdamm conducted by Alexander von Zemlinsky with Lotte Lenya as Jenny, Trude Hesterberg as Begbick, and Harald Paulsen as Jimmy. Another production was presented in January 1934 in Copenhagen at the Det ny Teater. Other productions within Europe waited until the end of the Second World War, some notable ones being in January 1963 in London at Sadler's Wells Opera conducted by Colin Davis and in Berlin in September 1977 by the Komische Oper.\n\nIt was not presented in the United States until 1970, when a short-lived April production at the Phyllis Anderson Theatre off Broadway starred Barbara Harris as Jenny, Frank Porretta as Jimmy, and Estelle Parsons as Begbick.\n\nA full version was presented at the Yale Repertory Theatre in New Haven, Connecticut, in 1974, with Gilbert Price as Jimmy and Stephanie Cotsirilos as Jenny. Kurt Kasznar played Moses. The libretto was performed in an original translation by Michael Feingold; the production was directed by Alvin Epstein. In October 1978, Yale presented a \"chamber version\" adapted and directed by Keith Hack, with John Glover as Jimmy and June Gable as Begbick. Mark Lynn-Baker played Fatty; Michael Gross was Trinity Moses. In November 1979, \"Mahagonny\" debuted at the Metropolitan Opera in a John Dexter production conducted by James Levine. The cast included Teresa Stratas as Jenny, Astrid Varnay as Begbick, Richard Cassilly as Jimmy, Cornell MacNeil as Moses, Ragnar Ulfung as Fatty and Paul Plishka as Joe. The production was televised in 1979 and was released on DVD in 2010.\n\nThe Los Angeles Opera presented the opera in September 1989 under conductor Kent Nagano and with a Jonathan Miller production. Other notable productions in Europe from the 1980s included the March 1986 presentation by the Scottish Opera in Glasgow; a June 1990 production in Florence by the Maggio Musicale Fiorentino. In October 1995 and 1997, the Paris Opera staged by Graham Vick, under the baton of Jeffrey Tate starring Marie McLaughlin as Jenny, Felicity Palmer (1995) and Kathryn Harries (1997) as Begbick, and Kim Begley (1995)/Peter Straka (1997) as Jimmy. \n\nThe July 1998 Salzburg Festival production featured Catherine Malfitano as Jenny, Gwyneth Jones as Begbick, and Jerry Hadley as Jimmy. The Vienna State Opera added it to its repertoire in January 2012 in a production by Jérôme Deschamps conducted by Ingo Metzmacher starring Christopher Ventris as Jimmy and Angelika Kirchschlager as Jenny, notably casting young mezzo-soprano Elisabeth Kulman as Begbick, breaking the tradition of having a veteran soprano (like Varnay or Jones) or musical theater singer (like Patti LuPone) perform the role.\n\nProductions within the US have included those in November 1998 by the Lyric Opera of Chicago directed by David Alden. Catherine Malfitano repeated her role as Jenny, while Felicity Palmer sang Begbick, and Kim Begley sang the role of Jimmy. The Los Angeles Opera's February 2007 production directed by John Doyle and conducted by James Conlon included Audra McDonald as Jenny, Patti LuPone as Begbick, and Anthony Dean Griffey as Jimmy. This production was recorded on DVD, and subsequently won the 2009 Grammy Awards for \"Best Classical Album\" and \"Best Opera Recording.\"\n\nIn 2014 it was performed using an alternate libretto as a \"wrestling opera\" at the Oakland Metro by the performers of Hoodslam.\n\n\"Scene 1: A desolate no-man's land\"\n\nA truck breaks down. Three fugitives from justice get out and find themselves in the city of Mahagonny: Fatty the Bookkeeper, Trinity Moses, and Leocadia Begbick. Because the federal agents pursuing them will not search this far north, and they are in a good location to attract ships coming south from the Alaskan gold fields, Begbick decides that they can profit by staying where they are and founding a pleasure city, where men can have fun, because there is nothing else in the world to rely on.\n\"Scene 2\"\n\nThe news of Mahagonny spreads quickly, and sharks from all over flock to the bait, including the whore Jenny Smith, who is seen, with six other girls, singing the \"Alabama Song\", in which she waves goodbye to her home and sets out in pursuit of whiskey, dollars and pretty boys.\n\n\"Scene 3\"\n\nIn the big cities, where men lead boring, purposeless lives, Fatty and Moses spread the gospel of Mahagonny, city of gold, among the disillusioned.\n\n\"Scene 4\"\n\nFour Alaskan Lumberjacks who have shared hard times together in the timberlands and made their fortunes set off together for Mahagonny. Jimmy Mahoney and his three friends – Jacob Schmidt, Bank Account Billy, and Alaska Wolf Joe – sing of the pleasures awaiting them in \"Off to Mahagonny\", they look forward to the peace and pleasure they will find there.\n\n\"Scene 5\"\n\nThe four friends arrive in Mahagonny, only to find other disappointed travelers already leaving. Begbick, well-informed about their personal tastes, marks down her prices, but for the penurious Billy they still seem too high. Jimmy impatiently calls for the girls of Mahagonny to show themselves, so he can make a choice. Begbick suggests Jenny as the right girl for Jack, who finds her rates too high. She pleads with Jack to reconsider (\"Havana Song\"), which arouses Jim's interest, and he chooses her. Jenny and the girls sing a tribute to \"the Jimmys from Alaska.\"\n\n\"Scene 6\"\n\nJimmy and Jenny get to know one another as she asks him to define the terms of their contact: Does he wish her to wear her hair up or down, to wear fancy underwear or none at all? \"What is your wish?\" asks Jim, but Jenny evades answering.\n\n\"Scene 7\"\n\nBegbick, Fatty and Moses meet to discuss the pleasure city's financial crisis: People are leaving in droves, and the price of whiskey is sinking rapidly. Begbick suggests going back to civilization, but Fatty reminds her that the federal agents have been inquiring for her in nearby Pensacola. Money would solve everything, declares Begbick, and she decides to soak the four new arrivals for all they've got.\n\n\"Scene 8\"\n\nJimmy, restless, attempts to leave Mahagonny, because he misses the wife he left in Alaska.\n\n\"Scene 9\"\n\nIn front of the Rich Man's Hotel, Jimmy and the others sit lazily as a pianist plays Tekla Bądarzewska's \"A Maiden's Prayer\". With growing anger, Jimmy sings of how his hard work and suffering in Alaska have led only to this. Drawing a knife, he shouts for Begbick, while his friends try to disarm him and the other men call to have him thrown out. Calm again, he tells Begbick that Mahagonny can never make people happy: it has too much peace and quiet.\n\n\"Scene 10\"\n\nAs if in answer to Jimmy's complaint, the city is threatened by a typhoon. Everyone sings in horror of the destruction awaiting them.\n\n\"Scene 11\"\n\nTensely, people watch for the hurricane's arrival. The men sing a hymn-like admonition not to be afraid. Jim meditatively compares Nature's savagery to the far greater destructiveness of Man. Why do we build, he asks, if not for the pleasure of destroying? Since Man can outdo any hurricane, fear makes no sense. For the sake of human satisfaction, nothing should be forbidden: If you want another man's money, his house or his wife, knock him down and take it; do what you please. As Begbick and the men ponder Jimmy's philosophy, Fatty and Moses rush in with news: The hurricane has unexpectedly struck Pensacola, destroying Begbick’s enemies, the federal agents. Begbick and her cohorts take it as a sign that Jimmy is right; they join him, Jenny, and his three friends in singing a new, defiant song: If someone walks on, then it's me, and if someone gets walked on, then it's you. In the background, the men continue to chant their hymn as the hurricane draws nearer.\n\n\"Scene 12\"\n\nMagically, the hurricane bypasses Mahagonny, and the people sing in awe of their miraculous rescue. This confirms Begbick's belief in the philosophy of \"Do what you want,\" and she proceeds to put it into effect.\n\"Scene 13 At the renovated \"Do It\" tavern.\"\n\nThe men sing of the four pleasures of life: Eating, Lovemaking, Fighting and Drinking. First comes eating: To kitschy cafe music, Jimmy's friend Jacob gorges until he keels over and dies. The men sing a chorale over his body, saluting \"a man without fear\".\n\n\"Scene 14: Loving.\"\n\nWhile Begbick collects money and issues tips on behavior, Moses placates the impatient men queuing to make love to Jenny and the other whores. The men sing the \"Mandalay Song\", warning that love does not last forever, and urging those ahead of them to make it snappy.\n\n\"Scene 15: Fighting.\"\n\nThe men flock to see a boxing match between Trinity Moses and Jim's friend Alaska Wolf Joe. While most of the men, including the ever-cautious Billy, bet on the burly Moses, Jim, out of friendship, bets heavily on Joe. The match is manifestly unfair; Moses not only wins but kills Joe in knocking him out.\n\n\"Scene 16: Drinking.\"\n\nIn an effort to shake off the gloom of Joe's death, Jimmy invites everyone to have a drink on him. The men sing \"Life in Mahagonny\", describing how one could live in the city for only five dollars a day, but those who wanted to have fun always needed more. Jim, increasingly drunk, dreams of sailing back to Alaska. He takes down a curtain rod for a mast and climbs on the pool table, pretending it is a ship; Jenny and Billy play along. Jimmy is abruptly sobered up when Begbick demands payment for the whiskey as well as for the damage to her property. Totally broke, he turns in a panic to Jenny, who explains her refusal to help him out in the song \"Make your own bed\" – an adaptation of the ideas he proclaimed at the end of act 1. Jim is led off in chains as the chorus, singing another stanza of \"Life in Mahagonny\", returns to its pastimes. Trinity Moses assures the crowd that Jimmy will pay for his crimes with his life.\n\n\"Scene 17\"\n\nAt night, Jim alone and chained to a lamppost, sings a plea for the sun not to rise on the day of his impending trial.\n\n\"Scene 18: In the courtroom\"\n\nMoses, like a carnival barker, sells tickets to the trials. He serves as prosecutor, Fatty as defense attorney, Begbick as judge. First comes the case of Toby Higgins, accused of premeditated murder for the purpose of testing an old revolver. Fatty invites the injured party to rise, but no one does so, since the dead do not speak. Toby bribes all three, and as a result, Begbick dismisses the case. Next Jimmy's case is called. Chained, he is led in by Billy, from whom he tries to borrow money; Billy of course refuses, despite Jim's plea to remember their time together in Alaska. In virtually the same speech he used to attack Higgins, Moses excoriates him for not paying his bills, for seducing Jenny (who presents herself as a plaintiff) to commit a \"carnal act\" with him for money, and for inciting the crowd with \"an illegal joyous song\" on the night of the typhoon. Billy, with the chorus's support, counters that, in committing the latter act, Jimmy discovered the laws by which Mahagonny lives. Moses argues that Jim hastened his friend Joe's death in a prizefight by betting on him, and Billy counters by asking who actually killed Joe. Moses does not reply. But there is no answer for the main count against him. Jim gets short sentences for his lesser crimes, but for having no money, he is sentenced to death. Begbick, Fatty and Moses, rising to identify themselves as the injured parties, proclaim \"in the whole human race / there is no greater criminal / than a man without money\". As Jim is led off to await execution, everyone sings the \"Benares Song\", in which they long for that exotic city \"where the sun is shining.\" But Benares has been destroyed by an earthquake. \"Where shall we go?\" they ask.\n\n\"Scene 19: At the gallows\"\n\nJim says a tender goodbye to Jenny, who, dressed in white, declares herself his widow. He surrenders her to Billy, his last remaining companion from Alaska. When he tries to delay the execution by reminding the people of Mahagonny that God exists, they play out for him, under Moses' direction, the story of \"God in Mahagonny\", in which the Almighty condemns the town and is overthrown by its citizens, who declare that they can not be sent to Hell because they are already in Hell. Jim, chastened, asks only for a glass of water, but is refused even this as Moses gives the signal for the trap to be sprung.\n\n\"Scene 20\"\n\nA caption advises that, after Jim's death, increasing hostility among the city's various factions has caused the destruction of Mahagonny. To a potpourri of themes from earlier in the opera, groups of protesters are seen on the march, in conflict with one another, while the city burns in the background. Jenny and the whores carry Jim's clothing and accessories like sacred relics; Billy and several men carry his coffin. In a new theme, they and the others declare, \"Nothing you can do will help a dead man\". Begbick, Fatty and Moses appear with placards of their own, joining the entire company in its march and declaring \"Nothing will help him or us or you now,\" as the opera ends in chaos.\n\n\n\n\nTo an extent, \"Mahagonny\" is an opera that satirizes operas. Brecht said that \"[i]t attacks the society that needs operas of such a sort\" and Weill said that it \"pays conscious tribute to the irrationality of the operatic form\". Both thought operas had become too full of ritual and bereft of substance, and \"Mahagonny\" in part sought to deflate the pompous arrogance of traditional opera. With this aim, many traditional operatic themes are subverted and made grotesque; love becomes a commodity, the \"deus ex machina\" tells everyone to go to hell, the law is run by criminals, etc. A traditional opera theme is true love, but in Mahagonny the closest such thing is the love between Jimmy and the prostitute Jenny. Furthermore, when given the choice to pay off Jimmy's debt and save his life, she tearfully regrets that while she loves him and will miss him dearly, she cannot part with her money. This commodification of love is brought to a grotesque apex after the hurricane spares Mahagonny; the residents now feel free to do what they want, and naturally they want to love. Consequently, in act 2 scene 3, the largely male population take turns having sex with the prostitutes. In contrast to the supposed theme of love, the scene portrays a perverse form of love; the prostitutes are carted around like giant slabs of meat and the \"love\" is regimented by the queue of men each waiting impatiently for his own turn. The \"Mandalay Song\" also heightens the ongoing tension. At no point is the music entirely tonal, and while the tune is seemingly jazzy and carefree, the tonalities betray an uneasiness about the whole business. In \"Mahagonny\", operatic love is mutated from a grand aspiration to a mere commodity.\n\nAnother trope of operas is the \"deus ex machina\", in which the protagonist is saved at the last minute by divine intervention. This is a useful technique to quickly wrap up a story and make a happy ending, and has been used in drama many times. In \"Mahagonny\", though there are no supernatural occurrences for most of the opera, there is in fact a \"deus ex machina\"; God himself comes to Mahagonny right before Jimmy is executed. The typical opera would have God solving all the problems just in time for the end of the opera, but \"Mahagonny\"'s god does not. He does not even acknowledge that Jimmy is tied up and ready to be killed, but at least tries to fix the moral problems in Mahagonny. He tries to convince them to give up their degraded way of life, but the residents all refuse the offer. God then tells them literally to go to hell, but the people are not even offended; they proclaim that they already are in hell so that is no punishment. After fixing nothing, God then lets Jimmy have his say. Jimmy realizes that money did not buy him happiness or freedom, and he has learned his lesson. However, God does not spare him even then, and Jimmy is executed off-stage.\n\nMahagonny as a city was also intended to be a parable of capitalism stripped of its veneer of bourgeois respectability, as it \"arose to meet the needs and desires of the people, and it was these same needs and desires that brought about its destruction\". Ultimately, this was also intended as a commentary on the state of Weimar Germany; underneath that facade of prosperity and happiness, lay corruption and savagery. Under Brecht's (and to some extent Weill's) Marxist-influenced view of capitalism, it is created to provide people the goods and services they need, but it does so at the expense of reducing everything to a mere commodity. Furthermore, since obtaining wealth in capitalism is a cutthroat enterprise, the powerful are no better than a gang of bandits, and the law in turn is run by such thugs.\n\nThe city of Mahagonny embodies many of these characteristics. Mahagonny was originally created to provide people with useful services; the gold prospectors wanted a relaxation spot, and the three criminals needed to stay there. However, this led to the commodification of everything the tourists desired, especially love. In the end, nobody could buy true happiness; Alaska Wolf Joe and Jacob Schmidt died, the city is burning down, and Jimmy declared before his death that \"[t]he happiness I bought was no happiness\". His death was also ordered by the court of law, which was run by the three criminals. To make matters even more farcical, they let a murderer bribe his way to freedom while Jimmy is sentenced to death for petty crimes. The parallels between the events of \"Mahagonny\" and the Marxist view of capitalism are clear.\n\nTo make the comparison more obvious, the opera is set in a pseudo-Wild West America, with Mahagonny itself placed somewhere far from the rest of civilization. America was the land of unbridled capitalism, the frontier just as much so. The only difference is that bourgeois civility and civilization has yet to occupy the frontier, and thus there is no hiding the nature of capitalism beneath the facade of gentlemanly conduct. In \"Mahagonny\", the characters are prostitutes, lumberjacks, criminals, and the like. Not one of them comes from the moneyed class, and yet the same system of exploitation was set up, but in a more naked manner. Instead of seducing a woman's love with power and influence, the residents of Mahagonny pay for a prostitute. But in \"Mahagonny\", poverty is not just a condition the poor bring upon themselves, but a crime to be punished. Thus, Brecht and Weill tried to display capitalism as the meatgrinder they believed it to be.\n\nThough Kurt Weill was not a vocal proponent of the \"Gebrauchsmusik\" movement in Germany, many of his works, including the music for \"Mahagonny\", share many of its characteristics. Loosely defined, \"Gebrauchsmusik\" is the idea that music can be more than just pure music. For example, music that accompanies a silent film is perfectly respectable, so long as it is done well. Also, simple music to be performed by amateurs is also acceptable. Weill's musical setting of \"Mahagonny\" exemplifies many of these characteristics. In the first place, this is music composed for the stage and not for the concert hall, and Weill intentionally chose that so. He wished to make his music speak out to as many people as possible, so throughout his career his mostly wrote music for the stage, and all the while in Europe he was considered a real composer and not just some hack pandering to the playwright to make a living.\n\nFor example, in act 1, scene 2, the scenario is that Jenny and other girls are walking to Mahagonny. The music is surprisingly simple; just a simple solo with a short chorus and sparse orchestration. The music is not some baroque contrapuntal scheme, nor is it a Romantic forest of sound; rather, the music is very easy to listen to. This music setting matches with the idea of making music accessible to the public, and not just for educated artists. The music style also displays influences from popular music. During this time, American jazz was a sensation in Europe; since opera is set in America, it is not surprising that the tune and the beat have a jazz influence. The orchestration, also includes such non-classical instruments as a saxophone, a decidedly jazz instrument. By using a jazz style in the music, Weill immediately associates the action as happening in America. In addition to making a relatively exotic sound, Weill manages to incorporate the jazz style in the song without making it seem incongruous; the American and European music are seamlessly joined under Weill's hands.\n\nElsewhere Weill uses other such non-classical instruments as the accordion, and he uses other popular influences, including those of his native Germany. The most enduring feature of \"Gebrauchsmusik\" in \"Mahagonny\", however, are the tunes. This reflects Weill's greatest desire to create simple music that would go straight to the heart of the audience. Many of the songs in \"Mahagonny\" are very simple and accessible. The \"Alabama Song\", for example, can be picked up absentmindedly and hummed. And while it seems carefree, something seems wrong with it, despite or perhaps because of its simplicity.\n\nSince Mahagonny was co-produced by Brecht, there is a prominent display of the \"Verfremdungseffekt\", often translated as the \"alienation effect\". Brecht and Weill wished to replace the old dramatic theater and its emphasis on emotions with epic theatre and its emphasis on reason. In the case of Brecht, it was more as a didactic tool for communist philosophy, but for Weill, it was more of a social scheme, a way to get people involved and thinking. The general scheme was to shake up people's preconceived notions and make them think about what is happening on stage, or to emotionally distance the audience from the action thus making logical evaluation of the play's events easier. Brecht and Weill used different methods to achieve this effect.\n\nOne of the most noticeable methods Brecht uses are the inscriptions at the beginning of most of the scenes. Before the majority of the scenes, there is a short summary of that scene recited to the audience. By being already aware of what will happen, the audience can then better concentrate on what is going on in the scene. Often, Brecht will also have seemingly bizarre events occur, seemingly just to keep the audience unable to guess what will happen next. For example, Jimmy is going crazy at having nothing to do, when all of a sudden a hurricane starts heading towards Mahagonny. The audience is forced to give up concentrating on how Jimmy feels and think about what the meaning of this sudden hurricane is.\n\nWeill also contributed greatly to the \"Verfremdungseffekt\" by his music. Often the music would intentionally be unsuited for the onstage action, preventing the audience from getting carried away by the onstage emotion. For example, in act 2, scene 13, the hurricane has spared Mahagonny, and the people feel free to do whatever makes them happy. For Jacob Schmidt, this means eating a lot. He sings of how he has not had his fill yet with such lines as \"Not enough by half! / I may eat myself for supper.\" And yet, the music betrays the seeming unbridled ecstasy of Jacob; he is singing to a discordant melody, and the accordion accompaniment sounds stark and rather macabre. The intention is that the audience realizes that all this is very wrong; Jacob claims to be having a great time, but the music suggests all may not be well, thus the audience needs to pay attention and think about what is really going on. To further this point, Jacob then dies and the chorus sings of how happy he was while dragging out his corpse. This last twist of welcoming death is unexpected and contributes to the alienation.\n\nAnother example of \"Verfremdungseffekt\" in the music is in the \"Alabama Song\". This time, instead of the music sounding deeply disturbing compared to the stage action, it is the reverse. When the \"Alabama Song\" first appears, the women are going to Mahagonny. The second time the song appears is near the end of the opera, after Jimmy has been executed. Mahagonny is in decline, and there are street protests. The entire stage is singing about how rotten the world and man are, when all of a sudden Jenny and the prostitutes come walking through singing the \"Alabama Song\", a total departure from the previous mood. What is more, they are carrying Jimmy's corpse through the stage. The music refuses to set and keep the audience in a particular mood, and the conflict between the lighthearted \"Alabama Song\" and the imagery of the funeral procession is confusing. This tension serves to distance the audience from the action, even at an exceptionally powerful moment of the opera, giving the audience one last chance to digest all the contradictions and perversions of Mahagonny.\n\nThe 2005 movie \"Manderlay\", directed by Lars von Trier, contains several references to the plot of \"Mahagonny\". The most notable of these is the threat of a hurricane approaching the city during the first act. Von Trier's earlier movie \"Dogville\", to which Manderlay is a sequel, was for a large part based on a song from Brecht's \"Threepenny Opera\" (\"Pirate Jenny\"). In the brothel scene in act 2 of \"Mahagonny\", the choir sings a \"Song von Mandelay\". The play \"Happy End\" (1929) by Elisabeth Hauptmann, Brecht and Weill, also contains a song called \"Der Song von Mandelay\", which uses the same refrain as in the brothel scene of \"Mahagonny\". Brecht's use of the name Mandelay/Mandalay was inspired by Rudyard Kipling's poem \"Mandalay\".\n\n\"Rise and Fall of the City of Mahagonny\": Teresa Stratas, Astrid Varnay, Richard Cassilly(MET, Recorded 1979)\n\n\"Alabama Song\" (covered by multiple artists, notably Ute Lemper, The Doors and David Bowie).\n\n"}
{"id": "2339", "url": "https://en.wikipedia.org/wiki?curid=2339", "title": "Avery Hopwood", "text": "Avery Hopwood\n\nJames Avery Hopwood (May 28, 1882 – July 1, 1928) was an American playwright of the Jazz Age. He had four plays running simultaneously on Broadway in 1920.\n\nHopwood was born to James and Jule Hopwood on May 28, 1882, in Cleveland, Ohio. He graduated from Cleveland's West High School in 1900. In 1901, he began attending the University of Michigan in Ann Arbor. However, his family experienced financial difficulties, so for his sophomore year he transferred to Adelbert College. He returned to the University of Michigan in the fall of 1903, and graduated Phi Beta Kappa in 1905.\n\nHopwood started out as a journalist for a Cleveland newspaper as its New York correspondent, but within a year had a play, \"Clothes\" (1906), produced on Broadway. He became known as \"The Playboy Playwright\" and specialized in comedies and farces, some of them with material considered risqué at the time. One play, \"The Demi-Virgin\" in 1921, prompted a court case because of its suggestive subject matter, including a risque game of cards, \"Stripping Cupid\", where a bevy of showgirls teased the audience in their lingerie. The case was dismissed.\n\nHis many plays included \"Nobody's Widow\" (1910), starring Blanche Bates; \"Fair and Warmer\" (1915), starring Madge Kennedy (filmed in 1919); \"The Gold Diggers\" (1919), starring Ina Claire (filmed in 1923 as \"The Gold Diggers\", in 1928 as \"Gold Diggers of Broadway\" and also as \"Gold Diggers of 1933\"); \"Ladies' Night\", 1920, starring Charlie Ruggles (filmed in 1928); the famous mystery play \"The Bat\" (with Mary Roberts Rinehart), 1920 (filmed in 1926 as \"The Bat\", in 1930 as \"The Bat Whispers,\" and in 1959 as \"The Bat\"); \"Getting Gertie's Garter\" (with Wilson Collison), 1921, starring Hazel Dawn (filmed in 1927 and 1945); \"The Demi-Virgin\", 1921, also starring Dawn; \"The Alarm Clock\", 1923; \"The Best People\" (with David Gray), 1924 (filmed in 1925 and as \"Fast and Loose\" in 1930), the song-farce \"Naughty Cinderella\", 1925, starring Irene Bordoni and \"The Garden of Eden\" in 1927 (filmed in 1928 as \"The Garden of Eden\").\n\nHopwood was asked to write the third act of Mary Roberts Rinehart's play \"The Bat\". Hopwood collaborated with Rinehart to then work on the last act of the play in Sewickley and sometimes in New York.\n\nThe early sound film \"The Bat Whispers\" played an influence on Bob Kane's Batman because the inspiration for Batman's costume came from the \"mysterious Bat\" character portrayed in the movie from 1930.\n\nIn 1906, Hopwood was introduced to writer and photographer Carl Van Vechten. The two became close friends and were sometimes sexual partners. In the 1920s Hopwood had a tumultuous and abusive romantic relationship with fellow Cleveland-born playwright John Floyd. Although Hopwood announced to the press in 1924 that he was engaged to vaudeville dancer and choreographer Rosa Rolanda, Van Vechten confirmed in later years that it was a publicity stunt. Rolanda would later marry caricaturist Miguel Covarrubias.\n\nOn July 1, 1928, while swimming at Juan-les-Pins on the French Riviera, Hopwood had a heart attack and died. He was buried in Riverside Cemetery, Cleveland. His mother, Jule Hopwood, inherited a large trust from him, but he had not made arrangements for the disposition of other items, including literary rights. While she was working through the legal issues with his estate, Jule Hopwood fell ill and died on March 1, 1929. She was buried next to her son.\n\nHopwood's plays were very successful commercially, but did not have the lasting literary significance he hoped to achieve.\n\nThe terms of Hopwood's will left a substantial portion of his estate to his alma mater, the University of Michigan for the establishment of the Avery Hopwood and Jule Hopwood Creative Writing Awards. The bequest stipulated: \"It is especially desired that students competing for prizes shall be allowed the widest possible latitude, and that the new, the unusual, and the radical shall be especially encouraged.\" Famous Hopwood award winners include Robert Hayden, Marge Piercy, Arthur Miller, Betty Smith, Lawrence Kasdan, John Ciardi, Mary Gaitskill, Edmund White, Nancy Willard, Frank O’Hara, and Steve Hamilton.\n\nThroughout his life, Hopwood worked on a novel that he hoped would \"expose\" the strictures the commercial theater machine imposed on playwrights, but the manuscript was never published. Jack Sharrar recovered the manuscript for this novel in 1982 during his research for \"Avery Hopwood, His Life and Plays\". The novel was published in July 2011 as \"The Great Bordello\".\n\n\n\n\n\n\n\n"}
{"id": "2340", "url": "https://en.wikipedia.org/wiki?curid=2340", "title": "Antipope Felix II", "text": "Antipope Felix II\n\nAntipope Felix II, an archdeacon of Rome, was installed as Pope in 355 AD after the Emperor Constantius II banished the reigning Pope, Liberius, for refusing to subscribe to a sentence of condemnation against Saint Athanasius.\n\nIn May 357 AD the Roman laity, which had remained faithful to Liberius, demanded that Constantius, who was on a visit to Rome, should recall Liberius. The Emperor planned to have Felix and Liberius rule jointly, but when Liberius returned Felix was forced to retire to Porto, near Rome, where, after making an unsuccessful attempt to establish himself again in Rome, he died on 22 November 365 AD.\n\nThis Felix was later confused with a Roman martyr named Felix, with the result that he was included in lists of the Popes as Felix II and that the succeeding Popes of the same name (Pope Felix III and Pope Felix IV) were given wrong numerals, as was Antipope Felix V.\n\nThe Catholic Encyclopedia (1909) called this confusion a \"distortion of the true facts\" and suggested that it arose because the \"Liber Pontificalis\", which at this point may be registering a reliable tradition, says that this Felix built a church on the Via Aurelia, which is where the Roman martyr of an earlier date was buried. However, a more recent source says that of the martyr Felix nothing is known except his name, that he was a martyr, and that he was buried in the cemetery on the Via Portuensis that bears his name.\n\nThe Catholic Encyclopedia remarked that \"the real story of the antipope was lost and he obtained in local Roman history the status of a saint and a confessor. As such he appears in the Roman Martyrology on 29 July.\" At that time (1909) the Roman Martyrology had the following text: This entry was based on what the Catholic Encyclopedia called later legends that confound the relative positions of Felix and Liberius. More recent editions of the Roman Martyrology have instead: \n\nThe feast day of the Roman martyr Felix is 29 July. The antipope Felix died, as stated above, on a 22 November, and his death was not a martyr's, occurring when the Peace of Constantine had been in force for half a century.\n\nAs well as the Roman Martyrology, the Roman Missal identified the Saint Felix of 29 July with the antipope. This identification, still found in the 1920 typical edition, does not appear in the 1962 typical edition. To judge by the Marietti printing of 1952, which omits the numeral \"II\" and the word \"Papae\", the correction had already been made by then. One Catholic writer excuses this by saying that the antipope \"himself did refuse to accept Arianism, and so his feast has been kept in the past on [29 July]\".\n\n"}
{"id": "2341", "url": "https://en.wikipedia.org/wiki?curid=2341", "title": "Alkaloid", "text": "Alkaloid\n\nAlkaloids are a group of naturally occurring chemical compounds that mostly contain basic nitrogen atoms. This group also includes some related compounds with neutral and even weakly acidic properties. Some synthetic compounds of similar structure are also termed alkaloids. In addition to carbon, hydrogen and nitrogen, alkaloids may also contain oxygen, sulfur and, more rarely, other elements such as chlorine, bromine, and phosphorus.\n\nAlkaloids are produced by a large variety of organisms including bacteria, fungi, plants, and animals. They can be purified from crude extracts of these organisms by acid-base extraction. Alkaloids have a wide range of pharmacological activities including antimalarial (\"e.g.\" quinine), antiasthma (\"e.g.\" ephedrine), anticancer (\"e.g.\" homoharringtonine), cholinomimetic (\"e.g.\" galantamine), vasodilatory (\"e.g.\" vincamine), antiarrhythmic (\"e.g.\" quinidine), analgesic (\"e.g.\" morphine), antibacterial (\"e.g.\" chelerythrine), and antihyperglycemic activities (\"e.g.\" piperine). Many have found use in traditional or modern medicine, or as starting points for drug discovery. Other alkaloids possess psychotropic (\"e.g.\" psilocin) and stimulant activities (\"e.g.\" cocaine, caffeine, nicotine, theobromine), and have been used in entheogenic rituals or as recreational drugs. Alkaloids can be toxic too (\"e.g.\" atropine, tubocurarine). Although alkaloids act on a diversity of metabolic systems in humans and other animals, they almost uniformly evoke a bitter taste.\n\nThe boundary between alkaloids and other nitrogen-containing natural compounds is not clear-cut. Compounds like amino acid peptides, proteins, nucleotides, nucleic acid, amines, and antibiotics are usually not called alkaloids. Natural compounds containing nitrogen in the exocyclic position (mescaline, serotonin, dopamine, etc.) are usually classified as amines rather than as alkaloids. Some authors, however, consider alkaloids a special case of amines.\n\nThe name \"alkaloids\" () was introduced in 1819 by the German chemist , and is derived from late Latin root ' (which, in turn, comes from the Arabic \"al-qalwī\" – \"ashes of plants\") and the suffix ' – \"like\". However, the term came into wide use only after the publication of a review article by Oscar Jacobsen in the chemical dictionary of Albert Ladenburg in the 1880s.\n\nThere is no unique method of naming alkaloids. Many individual names are formed by adding the suffix \"ine\" to the species or genus name. For example, atropine is isolated from the plant \"Atropa belladonna\", strychnine is obtained from the seed of Strychnine tree (\"Strychnos nux-vomica\" L.). If several alkaloids are extracted from one plant then their names often contain suffixes \"idine\", \"anine\", \"aline\", \"inine\" etc. There are also at least 86 alkaloids whose names contain the root \"vin\" because they are extracted from \"vinca\" plants such as \"Vinca rosea\" (\"Catharanthus roseus\"); these are called \"vinca\" alkaloids.\n\nAlkaloid-containing plants have been used by humans since ancient times for therapeutic and recreational purposes. For example, medicinal plants have been known in the Mesopotamia at least around 2000 BC. The \"Odyssey\" of Homer referred to a gift given to Helen by the Egyptian queen, a drug bringing oblivion. It is believed that the gift was an opium-containing drug. A Chinese book on houseplants written in 1st–3rd centuries BC mentioned a medical use of Ephedra and opium poppies. Also, coca leaves have been used by South American Indians since ancient times.\n\nExtracts from plants containing toxic alkaloids, such as aconitine and tubocurarine, were used since antiquity for poisoning arrows.\n\nStudies of alkaloids began in the 19th century. In 1804, the German chemist Friedrich Sertürner isolated from opium a \"soporific principle\" (), which he called \"morphium\" in honor of Morpheus, the Greek god of dreams; in German and some other Central-European languages, this is still the name of the drug. The term \"morphine\", used in English and French, was given by the French physicist Joseph Louis Gay-Lussac.\n\nA significant contribution to the chemistry of alkaloids in the early years of its development was made by the French researchers Pierre Joseph Pelletier and Joseph Bienaimé Caventou, who discovered quinine (1820) and strychnine (1818). Several other alkaloids were discovered around that time, including xanthine (1817), atropine (1819), caffeine (1820), coniine (1827), nicotine (1828), colchicine (1833), sparteine (1851), and cocaine (1860).\n\nThe first complete synthesis of an alkaloid was achieved in 1886 by the German chemist Albert Ladenburg. He produced coniine by reacting 2-methylpyridine with acetaldehyde and reducing the resulting 2-propenyl pyridine with sodium. The development of the chemistry of alkaloids was accelerated by the emergence of spectroscopic and chromatographic methods in the 20th century, so that by 2008 more than 12,000 alkaloids had been identified.\n\nCompared with most other classes of natural compounds, alkaloids are characterized by a great structural diversity and there is no uniform classification of alkaloids. First classification methods have historically combined alkaloids by the common natural source, \"e.g.\", a certain type of plants. This classification was justified by the lack of knowledge about the chemical structure of alkaloids and is now considered obsolete.\n\nMore recent classifications are based on similarity of the carbon skeleton (\"e.g.\", indole-, isoquinoline-, and pyridine-like) or biochemical precursor (ornithine, lysine, tyrosine, tryptophan, etc.). However, they require compromises in borderline cases; for example, nicotine contains a pyridine fragment from nicotinamide and pyrrolidine part from ornithine and therefore can be assigned to both classes.\n\nAlkaloids are often divided into the following major groups:\n\n\nSome alkaloids do not have the carbon skeleton characteristic of their group. So, galantamine and homoaporphines do not contain isoquinoline fragment, but are, in general, attributed to isoquinoline alkaloids.\n\nMain classes of monomeric alkaloids are listed in the table below:\n\nMost alkaloids contain oxygen in their molecular structure; those compounds are usually colorless crystals at ambient conditions. Oxygen-free alkaloids, such as nicotine or coniine, are typically volatile, colorless, oily liquids. Some alkaloids are colored, like berberine (yellow) and sanguinarine (orange).\n\nMost alkaloids are weak bases, but some, such as theobromine and theophylline, are amphoteric. Many alkaloids dissolve poorly in water but readily dissolve in organic solvents, such as diethyl ether, chloroform or 1,2-dichloroethane. Caffeine, cocaine, codeine and nicotine are slightly soluble in water (with a solubility of ≥1g/L), whereas others, including morphine and yohimbine are very slightly water-soluble (0.1–1 g/L). Alkaloids and acids form salts of various strengths. These salts are usually freely soluble in water and ethanol and poorly soluble in most organic solvents. Exceptions include scopolamine hydrobromide, which is soluble in organic solvents, and the water-soluble quinine sulfate.\n\nMost alkaloids have a bitter taste or are poisonous when ingested. Alkaloid production in plants appeared to have evolved in response to feeding by herbivorous animals; however, some animals have evolved the ability to detoxify alkaloids. Some alkaloids can produce developmental defects in the offspring of animals that consume but cannot detoxify the alkaloids. One example is the alkaloid cyclopamine, produced in the leaves of corn lily. During the 1950s, up to 25% of lambs born by sheep that had grazed on corn lily had serious facial deformations. These ranged from deformed jaws to cyclopia (see picture). After decades of research, in the 1980s, the compound responsible for these deformities was identified as the alkaloid 11-deoxyjervine, later renamed to cyclopamine.\n\nAlkaloids are generated by various living organisms, especially by higher plants – about 10 to 25% of those contain alkaloids. Therefore, in the past the term \"alkaloid\" was associated with plants.\n\nThe alkaloids content in plants is usually within a few percent and is inhomogeneous over the plant tissues. Depending on the type of plants, the maximum concentration is observed in the leaves (black henbane), fruits or seeds (Strychnine tree), root (\"Rauwolfia serpentina\") or bark (cinchona). Furthermore, different tissues of the same plants may contain different alkaloids.\n\nBeside plants, alkaloids are found in certain types of fungi, such as psilocybin in the fungus of the genus \"Psilocybe\", and in animals, such as bufotenin in the skin of some toads. Many marine organisms also contain alkaloids. Some amines, such as adrenaline and serotonin, which play an important role in higher animals, are similar to alkaloids in their structure and biosynthesis and are sometimes called alkaloids.\n\nBecause of the structural diversity of alkaloids, there is no single method of their extraction from natural raw materials. Most methods exploit the property of most alkaloids to be soluble in organic solvents but not in water, and the opposite tendency of their salts.\n\nMost plants contain several alkaloids. Their mixture is extracted first and then individual alkaloids are separated. Plants are thoroughly ground before extraction. Most alkaloids are present in the raw plants in the form of salts of organic acids. The extracted alkaloids may remain salts or change into bases. Base extraction is achieved by processing the raw material with alkaline solutions and extracting the alkaloid bases with organic solvents, such as 1,2-dichloroethane, chloroform, diethyl ether or benzene. Then, the impurities are dissolved by weak acids; this converts alkaloid bases into salts that are washed away with water. If necessary, an aqueous solution of alkaloid salts is again made alkaline and treated with an organic solvent. The process is repeated until the desired purity is achieved.\n\nIn the acidic extraction, the raw plant material is processed by a weak acidic solution (\"e.g.\", acetic acid in water, ethanol, or methanol). A base is then added to convert alkaloids to basic forms that are extracted with organic solvent (if the extraction was performed with alcohol, it is removed first, and the remainder is dissolved in water). The solution is purified as described above.\n\nAlkaloids are separated from their mixture using their different solubility in certain solvents and different reactivity with certain reagents or by distillation.\n\nBiological precursors of most alkaloids are amino acids, such as ornithine, lysine, phenylalanine, tyrosine, tryptophan, histidine, aspartic acid, and anthranilic acid. Nicotinic acid can be synthesized from tryptophan or aspartic acid. Ways of alkaloid biosynthesis are too numerous and cannot be easily classified. However, there are a few typical reactions involved in the biosynthesis of various classes of alkaloids, including synthesis of Schiff bases and Mannich reaction.\n\nSchiff bases can be obtained by reacting amines with ketones or aldehydes. These reactions are a common method of producing C=N bonds.\n\nIn the biosynthesis of alkaloids, such reactions may take place within a molecule, such as in the synthesis of piperidine:\n\nAn integral component of the Mannich reaction, in addition to an amine and a carbonyl compound, is a carbanion, which plays the role of the nucleophile in the nucleophilic addition to the ion formed by the reaction of the amine and the carbonyl.\n\nThe Mannich reaction can proceed both intermolecularly and intramolecularly:\n\nIn addition to the described above monomeric alkaloids, there are also dimeric, and even trimeric and tetrameric alkaloids formed upon condensation of two, three, and four monomeric alkaloids. Dimeric alkaloids are usually formed from monomers of the same type through the following mechanisms:\n\nThere are also dimeric alkaloids formed from two distinct monomers, such as the \"vinca\" alkaloids vinblastine and vincristine, which are formed from the coupling of catharanthine and vindoline. The newer semi-synthetic chemotherapeutic agent vinorelbine is used in the treatment of non-small-cell lung cancer. It is another derivative dimer of vindoline and catharanthine and is synthesised from anhydrovinblastine, starting either from leurosine or the monomers themselves.\n\nThe role of alkaloids for living organisms that produce them is still unclear. It was initially assumed that the alkaloids are the final products of nitrogen metabolism in plants, as urea in mammals. It was later shown that alkaloid concentrations varies over time, and this hypothesis was refuted.\n\nMost of the known functions of alkaloids are related to protection. For example, aporphine alkaloid liriodenine produced by the tulip tree protects it from parasitic mushrooms. In addition, the presence of alkaloids in the plant prevents insects and chordate animals from eating it. However, some animals are adapted to alkaloids and even use them in their own metabolism. Such alkaloid-related substances as serotonin, dopamine and histamine are important neurotransmitters in animals. Alkaloids are also known to regulate plant growth. Another example of an organism that uses alkaloids for protection is the \"Utetheisa ornatrix\", more commonly known as the ornate moth. Pyrrolizidine alkaloids render these larvae and adult moths unpalatable to many of their natural enemies like coccinelid beetles, green lacewings, insectivorous hemiptera and insectivorous bats.\n\nMedical use of alkaloid-containing plants has a long history, and, thus, when the first alkaloids were isolated in the 19th century, they immediately found application in clinical practice. Many alkaloids are still used in medicine, usually in the form of salts, including the following:\n\nMany synthetic and semisynthetic drugs are structural modifications of the alkaloids, which were designed to enhance or change the primary effect of the drug and reduce unwanted side-effects. For example, naloxone, an opioid receptor antagonist, is a derivative of thebaine that is present in opium.\n\nPrior to the development of a wide range of relatively low-toxic synthetic pesticides, some alkaloids, such as salts of nicotine and anabasine, were used as insecticides. Their use was limited by their high toxicity to humans.\n\nPreparations of plants containing alkaloids and their extracts, and later pure alkaloids, have long been used as psychoactive substances. Cocaine, caffeine, and cathinone are stimulants of the central nervous system. Mescaline and many of indole alkaloids (such as psilocybin, dimethyltryptamine and ibogaine) have hallucinogenic effect. Morphine and codeine are strong narcotic pain killers.\n\nThere are alkaloids that do not have strong psychoactive effect themselves, but are precursors for semi-synthetic psychoactive drugs. For example, ephedrine and pseudoephedrine are used to produce methcathinone and methamphetamine. Thebaine is used in the synthesis of many painkillers such as oxycodone.\n\n"}
{"id": "2343", "url": "https://en.wikipedia.org/wiki?curid=2343", "title": "Adventism", "text": "Adventism\n\nAdventism is a minor branch of Protestant Christianity which was started by William Miller during the Second Great Awakening in the United States.\n\nThe name refers to belief in the imminent Second Coming (or \"Second Advent\") of Jesus Christ. William Miller started the Adventist movement in the 1830s. His followers became known as Millerites.\n\nAlthough the Adventist churches hold much in common, their theologies differ on whether the intermediate state is unconscious sleep or consciousness, whether the ultimate punishment of the wicked is annihilation or eternal torment, the nature of immortality, whether the wicked are resurrected after the millennium, and whether the sanctuary of refers to the one in heaven or one on earth. The movement has encouraged the examination of the whole Bible, leading Seventh-day Adventists and some smaller Adventist groups to observe the Sabbath. The General Conference of Seventh-day Adventists has compiled that church's core beliefs in the 28 Fundamental Beliefs (1980 and 2005), which use Biblical references as justification.\n\nIn 2010, Adventism claimed some 22 million believers scattered in various independent churches. The largest church within the movement — the Seventh-day Adventist Church — is one of the largest Christian churches in the world, with more than 18 million baptized members.\n\nAdventism began as an inter-denominational movement. Its most vocal leader was William Miller. Between 50,000 and 100,000 people in the United States supported Miller's predictions of Christ's return. After the \"Great Disappointment\" of October 22, 1844 many people in the movement gave up on Adventism. Of those remaining Adventist, the majority gave up believing in any prophetic (biblical) significance for the October 22 date, yet they remained expectant of the near Advent (second coming of Jesus).\n\nOf those who retained the October 22 date, many maintained that Jesus had come not literally but \"spiritually\", and consequently were known as \"spiritualizers\". A small minority held that something concrete had indeed happened on October 22, but this event had been misinterpreted. This viewpoint later emerged and crystallized with the Seventh-day Adventist Church, the largest remaining body today.\n\nThe Albany Conference in 1845, attended by 61 delegates, was called to attempt to determine the future course and meaning of the Millerite movement. Following this meeting, the \"Millerites\" then became known as \"Adventists\" or \"Second Adventists\". However, the delegates disagreed on several theological points. Four groups emerged from the conference: The Evangelical Adventists, The Life and Advent Union, the Advent Christian Church, and the Seventh-day Adventist Church.\n\nThe largest group was organized as the American Millennial Association, a portion of which was later known as the Evangelical Adventist Church. Unique among the Adventists, they believed in an eternal hell and consciousness in death. They declined in numbers, and by 1916 their name did not appear in the United States Census of Religious Bodies. It has diminished to almost non-existence today. Their main publication was the \"Advent Herald\", of which Sylvester Bliss was the editor until his death in 1863. It was later called the \"Messiah’s Herald\".\n\nThe Life and Advent Union was founded by George Storrs in 1863. He had established \"The Bible Examiner\" in 1842. It merged with the Adventist Christian Church in 1964.\n\nThe Advent Christian Church officially formed in 1861 grew rapidly at first. It declined a little during the 20th century. The Advent Christians publish the four magazines \"The Advent Christian Witness\", \"Advent Christian News\", \"Advent Christian Missions\" and \"Maranatha\". They also operate a liberal arts college at Aurora, Illinois; and a one-year Bible College in Lenox, Massachusetts called Berkshire Institute for Christian Studies. The Primitive Advent Christian Church later separated from a few congregations in West Virginia.\n\nThe Seventh-day Adventist Church officially formed in 1863. It believes in the sanctity of the seventh-day Sabbath as a holy day for worship. It published the \"Adventist Review, Kids Review, and Sabbath Herald\". It has grown to a large worldwide denomination and has a significant network of medical and educational institutions.\n\nMiller did not join any of the movements, and he spent the last few years of his life working for unity, before dying in 1849.\n\nThe \"Handbook of Denominations in the United States\", 12th edn., describes the following churches as \"Adventist and Sabbatarian (Hebraic) Churches\":\n\nThe Christadelphians were founded in 1844 by John Thomas and had an estimated 25,000 members in 170 ecclesias, or churches, in 2000 in America.\n\nThe Advent Christian Church was founded in 1860 and had 25,277 members in 302 churches in 2002 in America. It is a \"first-day\" body of Adventist Christians founded on the teachings of William Miller. It adopted the \"conditional immortality\" views of Charles F. Hudson and George Storrs who formed the \"Advent Christian Association\" in Salem, Massachusetts in 1860.\n\nThe Primitive Advent Christian Church is a small group which separated from the Advent Christian Church. It differs from the parent body mainly on two points. Its members observe foot washing as a rite of the church, and they teach that reclaimed backsliders should be baptized (even though they had formerly been baptized). This is sometimes referred to as rebaptism.\n\nThe Seventh-day Adventist Church, founded in 1863, had over 19,500,000 baptized members (not counting children of members) worldwide as of 30.6.2016. It is best known for its teaching that Saturday, the seventh day of the week, is the Sabbath and is the appropriate day for worship. However, it is the second coming of Jesus Christ along with the Judgement day, based on the three angels message in Revelation 14: 6-13, that is the main doctrine of SDA.\n\nThe Seventh Day Adventist Reform Movement is a small offshoot with an unknown number of members from the Seventh-day Adventist Church caused by disagreement over military service on the Sabbath day during World War I.\n\nThe Davidians (originally named Shepherd's Rod) is a small offshoot with an unknown number of members made up primarily of voluntarily disfellowshipped members of the Seventh-day Adventist Church. They were originally known as the Shepherd's Rod and are still sometimes referred to as such. The group derives its name from two books on Bible doctrine written by its founder, Victor Houteff, in 1929.\n\nThe Branch Davidians were a split (\"branch\") from the Davidians. Many of them were killed during the infamous Waco Siege of April 1993.\n\nThe Church of God (Seventh-Day) was founded in 1863 and it had an estimated 11,000 members in 185 churches in 1999 in America. Its founding members separated in 1858 from those Adventists associated with Ellen G. White who later organized themselves as Seventh-day Adventists in 1863. The Church of God (Seventh Day) split in 1933, creating two bodies: one headquartered in Salem, West Virginia, and known as the Church of God (7th day) - Salem Conference and the other one headquartered in Denver, Colorado and known as the General Conference of the Church of God (Seventh-Day). The Worldwide Church of God splintered from this. \n\nThe Church of God and Saints of Christ was founded in 1896 and had an estimated 40,000 members in approximately 200 congregations in 1999 in America.\n\nMany denominations known as \"Church of God\" have Adventist origins.\nThe Church of God General Conference was founded in 1921 and had 7,634 members in 162 churches in 2004 in America. It is an Adventist Christian body which is also known as the \"Church of God of the Abrahamic Faith\" and the \"Church of God General Conference (Morrow, GA)\".\n\nCreation Seventh Day Adventist Church\n\nThe United Seventh-Day Brethren is a small Sabbatarian Adventist body.\nIn 1947, several individuals and two independent congregations within the Church of God Adventist movement formed the \"United Seventh-Day Brethren\", seeking to increase fellowship and to combine their efforts in evangelism, publications, and other .\n\n\nThe Bible Students movement founded by Charles Taze Russell had in its early development close connections with the Millerite movement and stalwarts of the Adventist faith, including George Storrs and Joseph Seiss. The various groupings of independent Bible Students has currently have a cumulative membership about less than 20,000 worldwide. Although both Jehovah's Witnesses and Bible Students do not categorize themselves as part of the Millerite Adventist movement (or other denominations, in general), some theologians do categorize the group and schisms as Millerite Adventist because of its teachings regarding an imminent Second Coming and use of specific dates. As of January 2014 there are approximately 8 million Jehovah's Witnesses worldwide.\n\n\nGeneral:\n\n\n"}
{"id": "2345", "url": "https://en.wikipedia.org/wiki?curid=2345", "title": "Archbishop of Canterbury", "text": "Archbishop of Canterbury\n\nThe Archbishop of Canterbury is the senior bishop and principal leader of the Church of England, the symbolic head of the worldwide Anglican Communion and the diocesan bishop of the Diocese of Canterbury. The current archbishop is Justin Welby. His enthronement took place at Canterbury Cathedral on 21 March 2013. Welby is the 105th in a line which goes back more than 1400 years to Augustine of Canterbury, the \"Apostle to the English\", sent from Rome in the year 597. Welby succeeded Rowan Williams.\n\nFrom the time of St Augustine of Canterbury in the 6th century, until Archbishop Reginald Pole in the 16th century, the Archbishops of Canterbury were in full communion with the See of Rome and they usually received the pallium. During the English Reformation, based upon King Henry VIII's divorce from Catherine of Aragon, the Church of England broke away from the authority of the Pope and the Roman Catholic Church.\n\nIn the Middle Ages there was considerable variation in the methods of nomination of the Archbishop of Canterbury and other bishops. At various times the choice was made by the canons of Canterbury Cathedral, the Pope, or the King of England. Since the English Reformation, the Church of England has been more explicitly a state church and the choice is legally that of the Crown; today it is made by the Queen on the advice of the Prime Minister, who receives a shortlist of two names from an \"ad hoc\" committee called the Crown Nominations Commission.\n\nToday the archbishop fills four main roles:\n\n\nIn the last two of these functions, he has an important ecumenical and interfaith role, speaking on behalf of Anglicans in England and worldwide.\n\nThe archbishop's main residence is Lambeth Palace in the London Borough of Lambeth. He also has lodgings in the Old Palace, Canterbury, located beside Canterbury Cathedral, where the Chair of St Augustine sits.\n\nAs holder of one of the \"five great sees\" (the others being York, London, Durham and Winchester), the Archbishop of Canterbury is \"ex officio\" one of the Lords Spiritual of the House of Lords. He is one of the highest-ranking men in England and the highest ranking non-royal in the United Kingdom's order of precedence.\n\nSince Henry VIII broke with Rome, the Archbishops of Canterbury have been selected by the English (British since the Act of Union in 1707) monarch. Today the choice is made in the name of the monarch by the prime minister, from a shortlist of two selected by an ad-hoc committee called the Crown Nominations Commission. Since the 20th century, the appointment of Archbishops of Canterbury conventionally alternates between more moderate Anglo-Catholics and Evangelicals.\n\nThe current archbishop, Justin Welby, the 105th Archbishop of Canterbury, was enthroned at Canterbury Cathedral on 4 February 2013. As archbishop he signs himself as \"+ Justin Cantuar\". His predecessor, Rowan Williams, 104th Archbishop of Canterbury, was enthroned at Canterbury Cathedral on 27 February 2003. Immediately prior to his appointment to Canterbury, Williams was the Bishop of Monmouth and Archbishop of Wales. On 18 March 2012, Williams announced he would be stepping down as Archbishop of Canterbury at the end of 2012 to become Master of Magdalene College, Cambridge.\n\nIn addition to his office, the archbishop also holds a number of other positions; for example, he is Joint President of the Council of Christians and Jews in the United Kingdom. Some positions he formally holds \"ex officio\" and others virtually so (the incumbent of the day, although appointed personally, is appointed because of his office). Amongst these are:\n\nThe Archbishop of Canterbury is also a president of Churches Together in England (an ecumenical organisation). Geoffrey Fisher, 99th Archbishop of Canterbury, was the first since 1397 to visit Rome, where he held private talks with Pope John XXIII in 1960. In 2005, Rowan Williams became the first Archbishop of Canterbury to attend a papal funeral since the Reformation. He also attended the inauguration of Pope Benedict XVI. The 101st archbishop, Donald Coggan, was the first to attend a papal inauguration, that of Pope John Paul II in 1978.\n\nSince 2002, the Archbishop of Canterbury has co-sponsored the Alexandria Middle East Peace process with the Grand Mufti of Egypt. In July 2008, the archbishop attended a conference of Christians, Jews and Muslims convened by the King of Saudi Arabia at which the notion of the \"clash of civilizations\" was rejected. Delegates agreed \"on international guidelines for dialogue among the followers of religions and cultures.\" Delegates said that \"the deepening of moral values and ethical principles, which are common denominators among such followers, would help strengthen stability and achieve prosperity for all humans.\"\n\nIt has been suggested that the Roman province of Britannia had four archbishops, seated at London, York, Lincoln and Cirencester. However, in the 5th and 6th centuries Britannia began to be overrun by pagan, Germanic peoples who came to be known collectively as the Anglo-Saxons. Of the kingdoms they created, Kent arguably had the closest links with European politics, trade and culture, because it was conveniently situated for communication with continental Europe. In the late 6th century, King Æthelberht of Kent married a Christian Frankish princess named Bertha, possibly before becoming king, and certainly a number of years before the arrival of the first Christian mission to England. He permitted the preaching of Christianity.\n\nThe first Archbishop of Canterbury was St Augustine (not to be confused with St Augustine of Hippo), who arrived in Kent in 597 AD, having been sent by Pope Gregory I on a mission to the English. He was accepted by King Æthelbert, on his conversion to Christianity, about the year 598. It seems that Pope Gregory, ignorant of recent developments in the former Roman province, including the spread of the Pelagian heresy, had intended the new archiepiscopal sees for England to be established in London and York. In the event, Canterbury was chosen instead of London, owing to political circumstances. Since then the Archbishops of Canterbury have been referred to as occupying the Chair of St. Augustine.\n\nA Gospel Book believed to be directly associated with St Augustine's mission survives in the Parker Library, Corpus Christi College, Cambridge University, England. Catalogued as Cambridge \"Manuscript 286\", it has been positively dated to 6th century Italy and this bound book, the St Augustine Gospels, is still used during the swearing-in ceremony of new archbishops of Canterbury.\n\nBefore the break with papal authority in the 16th century, the Church of England was an integral part of the Western European church. Since the break the Church of England, an established national church, still considers itself part of the broader Western Catholic tradition (although this is not accepted by the Roman Catholic Church which regards Anglicanism as schismatic and does not accept Anglican holy orders as valid) as well as being the \"mother church\" of the worldwide Anglican Communion.\n\nThe Archbishop of Canterbury exercises metropolitical (or supervisory) jurisdiction over the Province of Canterbury, which encompasses thirty of the forty-four dioceses of the Church of England, with the rest falling within the Province of York. The four dioceses of Wales were formerly also under the Province of Canterbury until 1920 when they were transferred from the established Church of England to the disestablished Church in Wales.\nThe Archbishop of Canterbury has a ceremonial provincial \"curia\", or court, consisting of some of the senior bishops of his province. The Bishop of London—the most senior cleric of the church with the exception of the two archbishops—serves as Canterbury's provincial dean, the Bishop of Winchester as chancellor, the Bishop of Lincoln as vice-chancellor, the Bishop of Salisbury as precentor, the Bishop of Worcester as chaplain and the Bishop of Rochester as cross-bearer.\n\nAlong with primacy over the Archbishop of York, the Archbishop of Canterbury also has a precedence of honour over the other bishops of the Anglican Communion. He is recognised as \"primus inter pares\", or first amongst equals. He does not, however, exercise any direct authority in the provinces outside England, except in certain minor roles dictated by Canon in those provinces (for example, he is the judge in the event of an ecclesiastical prosecution against the Archbishop of Wales). He does hold metropolitical authority over several extra-provincial Anglican churches, and he serves as \"ex officio\" Bishop of the Falkland Islands.\n\nAt present the archbishop has three suffragan bishops:\n\n\nThe Bishop of Maidstone was previously a second \"actual\" suffragan bishop working in the diocese, until it was decided at the diocesan synod of November 2010 that a new bishop will not be appointed.\n\nThe Archbishop of Canterbury and the Archbishop of York are both styled as \"The Most Reverend\"; retired archbishops are styled as \"The Right Reverend\". Archbishops are, by convention, appointed to the Privy Council and may, therefore, also use the style of \"The Right Honourable\" for life (unless they are later removed from the council). In formal documents, the Archbishop of Canterbury is referred to as \"The Most Reverend Father in God, Forenames, by Divine Providence Lord Archbishop of Canterbury, Primate of All England and Metropolitan\". In debates in the House of Lords, the archbishop is referred to as \"The Most Reverend Primate, the Archbishop of Canterbury\". \"The Right Honourable\" is not used in either instance. He may also be formally addressed as \"Your Grace\"—or, more often these days, simply as \"Archbishop\", or \"Father\".\n\nThe surname of the Archbishop of Canterbury is not always used in formal documents; often only the first name and see are mentioned. The archbishop is legally entitled to sign his name as \"Cantuar\" (from the Latin for Canterbury). The right to use a title as a legal signature is only permitted to bishops, Peers of the Realm and peers by courtesy. The current Archbishop of Canterbury usually signs as \"\"+Justin Cantuar:\"\".\n\nIn the English and Welsh order of precedence, the Archbishop of Canterbury is ranked above all individuals in the realm, with the exception of the Sovereign and members of the Royal Family. Immediately below him is the Lord Chancellor and then the Archbishop of York.\n\nThe Archbishop of Canterbury awards academic degrees, commonly called \"Lambeth degrees\".\n\nThe Archbishop of Canterbury's official residence in London is Lambeth Palace.\nHe also has a residence, named The Old Palace, next to Canterbury Cathedral on the site of the medieval Archbishop's Palace.\nThe archbishops had palaces on the periphery of London and on the route between London and Canterbury.\n\nFormer palaces of the archbishops include\n\nSince 1900, the following have served as Archbishop of Canterbury:\n\n\n\n"}
{"id": "2346", "url": "https://en.wikipedia.org/wiki?curid=2346", "title": "Albion, Michigan", "text": "Albion, Michigan\n\nAlbion is a city in Calhoun County in the south central region of the Lower Peninsula of the U.S. state of Michigan. The population was 8,616 at the 2010 census and is part of the Battle Creek Metropolitan Statistical Area. From the time that the earliest English-speaking settlers arrived, the area has also been known as \"The Forks\", because it is situated at the confluence of the north and south branches of the Kalamazoo River. The \"Festival of the Forks\" has been held annually since 1967 to celebrate Albion's ethnic heritage.\n\nThe presence of several major manufacturers since the 19th century has given Albion the reputation of a factory town. This has changed with the closure of several manufacturers, and Albion's culture is changing to that of a college town with a strong interest in technology and sustainability issues. Albion College is a private liberal arts college with a student population of about 1,750. Albion is a sister city with Noisy-le-Roi, France.\n\nThe first European-American settler, Tenney Peabody, arrived in 1833 along with his brother-in-law Charles Blanchard, and a young man named Clark Dowling. Peabody's family followed soon after. In 1835, the Albion Company, a land development company formed by Jesse Crowell, platted a village and Peabody's wife was asked to name the settlement. She considered the name \"Peabodyville\", but \"Albion\" was selected instead, after the former residence of Jesse Crowell. Crowell became the first postmaster in 1838. Albion incorporated as a village in 1855 and as a city in 1885.\n\nIn 1835, Methodist Episcopal settlers established Albion College, which was known by a few other names before 1861 when the college was fully authorized to confer four-year degrees on both men and women. The first classes were held in Albion in 1843.\n\nThe forks of the Kalamazoo River provided power for mills, and Albion quickly became a mill town as well as an agricultural market. A railroad line arrived in 1852, fostering the development of other industries.\n\nIn 1973 Albion was named an All-America City by the National Civic League. It celebrated winning the award on May 15, 1974 when the Governor of Michigan, William Milliken, and many dignitaries came to town. However, in 1975 the closure of a major factory cut the celebration short and new challenges were created overnight.\n\nSince that time citizens have mobilized, with support from the Albion Community Foundation founded in 1968, and the Albion Volunteer Service Organization, founded in the 1980s with support from Albion College, to address the challenge of diminishing economic opportunity.\n\nKey to the City Honor Bestowed:\n\n\nAlbion has a Council-Manager form of government. City residents elect a Mayor and City Council members from six districts. The council in turn selects a City Manager to handle day-to-day affairs of the city. The mayor presides over and is a voting member of the council. Council members are elected to four-year terms, staggered every two years. A mayor is elected every two years. The city levies an income tax of 1 percent on residents and 0.5 percent on nonresidents.\n\nAccording to the United States Census Bureau, the city has a total area of , of which is land and is water. Albion is positioned 42.24 degrees north of the equator and 84.75 degrees west of the prime meridian.\n\nAmtrak, the national passenger rail system, provides daily service to Albion, operating its Wolverine both directions between Chicago, Illinois and Pontiac, Michigan via Detroit.\n\nGreyhound Lines provides daily intercity city bus service to Albion between Chicago, Illinois and Detroit.\n\n\n\n"}
{"id": "2348", "url": "https://en.wikipedia.org/wiki?curid=2348", "title": "Anointing of the Sick", "text": "Anointing of the Sick\n\nAnointing of the sick, known also by other names, is a form of religious anointing or \"unction\" (an older term with the same meaning) for the benefit of a sick person. It is practiced by many Christian churches and denominations.\n\nAnointing of the sick was a customary practice in many civilizations, including among the ancient Greeks and early Jewish communities. The use of oil for healing purposes is referred to in the writings of Hippocrates.\n\nAnointing of the sick should be distinguished from other religious anointings that occur in relation to other sacraments, in particular baptism, confirmation and ordination, and also in the coronation of a monarch.\n\nSince 1972, the Roman Catholic Church uses the name \"Anointing of the Sick\" both in the English translations issued by the Holy See of its official documents in Latin and in the English official documents of Episcopal conferences. It does not, of course, forbid the use of other names, for example the more archaic term \"Unction of the Sick\" or the term \"Extreme Unction\". Cardinal Walter Kasper used the latter term in his intervention at the 2005 Assembly of the Synod of Bishops. However, the Church declared that \"'Extreme unction' ... may also \"and more fittingly\" be called 'anointing of the sick'\" (emphasis added), and has itself adopted the latter term, while not outlawing the former. This is to emphasize that the sacrament is available, and recommended, to all those suffering from any serious illness, and to dispel the common misconception that it is exclusively for those at or very near the point of death.\n\nExtreme Unction was the usual name for the sacrament in the West from the late twelfth century until 1972, and was thus used at the Council of Trent and in the 1913 Catholic Encyclopedia. Peter Lombard (died 1160) is the first writer known to have used the term, which did not become the usual name in the West till towards the end of the twelfth century, and never became current in the East. The word \"extreme\" (final) indicated either that it was the last of the sacramental unctions (after the anointings at Baptism, Confirmation and, if received, Holy Orders) or because at that time it was normally administered only when a patient was \"in extremis\".\n\nOther names used in the West include the unction or blessing of consecrated oil, the unction of God, and the office of the unction. Among some Protestant bodies, who do not consider it a sacrament, but instead as a practice suggested rather than commanded by Scripture, it is called anointing with oil.\n\nIn the Greek Church the sacrament is called Euchelaion (Greek Εὐχέλαιον, from εὐχή, \"prayer\", and ἔλαιον, \"oil\"). Other names are also used, such as ἅγιον ἔλαιον (holy oil), ἡγιασμένον ἔλαιον (consecrated oil), and χρῖσις or χρῖσμα (anointing).\n\nThe Community of Christ uses the term administration to the sick.\n\nThe term \"last rites\" refers to administration to a dying person not only of this sacrament but also of Penance and Holy Communion, the last of which, when administered in such circumstances, is known as \"Viaticum\", a word whose original meaning in Latin was \"provision for the journey\". The normal order of administration is: first Penance (if the dying person is physically unable to confess, absolution, conditional on the existence of contrition, is given); next, Anointing; finally, Viaticum (if the person can receive it).\n\nThe chief Biblical text concerning the rite is : \"Is any among you sick? Let him call for the elders of the church, and let them pray over him, anointing him with oil in the name of the Lord; and the prayer of faith will save the sick man, and the Lord will raise him up; and if he has committed sins, he will be forgiven.\" (RSV)\n\n, and are also quoted in this regard.\n\nThe Roman Catholic, Eastern Orthodox and Coptic and Old Catholic Churches consider this anointing to be a sacrament. Other Christians too, in particular Anglicans, Lutherans and some Protestant and other Christian communities use a rite of anointing the sick, without necessarily classifying it as a sacrament.\n\nIn the Churches mentioned here by name, the oil used (called \"oil of the sick\" in both West and East) is blessed specifically for this purpose.\n\nAn extensive account of the teaching of the Catholic Church on Anointing of the Sick is given in \"Catechism of the Catholic Church\", 1499–1532.\n\nAnointing of the Sick is one of the seven Sacraments recognized by the Catholic Church, and is associated with not only bodily healing but also forgiveness of sins. Only ordained priests can administer it, and \"any priest may carry the holy oil with him, so that in a case of necessity he can administer the sacrament of anointing of the sick.\"\n\nThe Catholic Church sees the effects of the sacrament as follows. As the sacrament of Marriage gives grace for the married state, the sacrament of Anointing of the Sick gives grace for the state into which people enter through sickness. Through the sacrament a gift of the Holy Spirit is given, that renews confidence and faith in God and strengthens against temptations to discouragement, despair and anguish at the thought of death and the struggle of death; it prevents from losing Christian hope in God's justice, truth and salvation.\n\nThe special grace of the sacrament of the Anointing of the Sick has as its effects:\n\nThe duly blessed oil used in the sacrament is, as laid down in the Apostolic Constitution Sacram unctionem infirmorum, pressed from olives or from other plants. It is blessed by the bishop of the diocese at the Chrism Mass he celebrates on Holy Thursday or on a day close to it. If oil blessed by the bishop is not available, the priest administering the sacrament may bless the oil, but only within the framework of the celebration.\n\nThe Roman Rite Anointing of the Sick, as revised in 1972, puts greater stress than in the immediately preceding centuries on the sacrament's aspect of healing, and points to the place sickness holds in the normal life of Christians and its part in the redemptive work of the Church. Canon law permits its administration to any Catholic who has reached the use of reason and is beginning to be put in danger by illness or old age, unless the person in question obstinately persists in a manifestly grave sin. \"If there is any doubt as to whether the sick person has reached the use of reason, or is dangerously ill, or is dead, this sacrament is to be administered\". There is an obligation to administer it to the sick who, when they were in possession of their faculties, at least implicitly asked for it. A new illness or a renewal or worsening of the first illness enables a person to receive the sacrament a further time.\n\nThe ritual book on pastoral care of the sick provides three rites: anointing outside Mass, anointing within Mass, and anointing in a hospital or institution. The rite of anointing outside Mass begins with a greeting by the priest, followed by sprinkling of all present with holy water, if deemed desirable, and a short instruction. There follows a penitential act, as at the beginning of Mass. If the sick person wishes to receive the sacrament of penance, it is preferable that the priest make himself available for this during a previous visit; but if the sick person must confess during the celebration of the sacrament of anointing, this confession replaces the penitential rite A passage of Scripture is read, and the priest may give a brief explanation of the reading, a short litany is said, and the priest lays his hands on the head of the sick person and then says a prayer of thanksgiving over the already blessed oil or, if necessary, blesses the oil himself.\n\nThe actual anointing of the sick person is done on the forehead, with the prayer \"Through this holy anointing may the Lord in his love and mercy help you with the grace of the Holy Spirit\", and on the hands, with the prayer \"May the Lord who frees you from sin save you and raise you up\". To each prayer the sick person, if able, responds: \"Amen.\" It is permitted, in accordance with local culture and traditions and the condition of the sick person, to anoint other parts of the body in addition, such as the area of pain or injury, but without repeating the sacramental form. In case of emergency, a single anointing, not necessarily on the forehead, is sufficient.\n\nFrom the early Middle Ages until after the Second Vatican Council the sacrament was administered, within the Latin Church, only when death was approaching and, in practice, bodily recovery was not ordinarily looked for, giving rise, as mentioned above to the name \"Extreme Unction\" (i.e. final anointing). The form used in the Roman Rite included anointing of seven parts of the body while saying (in Latin): \"Through this holy unction and His own most tender mercy may the Lord pardon thee whatever sins or faults thou hast committed [quidquid deliquisti] by sight [by hearing, smell, taste, touch, walking, carnal delectation]\", the last phrase corresponding to the part of the body that was touched; however, in the words of the 1913 Catholic Encyclopedia, \"the unction of the loins is generally, if not universally, omitted in English-speaking countries, and it is of course everywhere forbidden in case of women\". Use of this form is still permitted under the conditions mentioned in article 9 of the 2007 motu proprio \"Summorum Pontificum\".\n\nLiturgical rites of the Catholic Church, both Western and Eastern, other than the Roman, have a variety of other forms for celebrating the sacrament.\n\nThe teaching of the Eastern Orthodox Church on the Holy Mystery (sacrament) of Unction is similar to that of the Roman Catholic Church. However, the reception of the Mystery is not limited to those who are enduring physical illness. The Mystery is given for healing (both physical and spiritual) and for the forgiveness of sin. For this reason, it is normally required that one go to confession before receiving Unction. Because it is a Sacred Mystery of the Church, only Orthodox Christians may receive it.\n\nThe solemn form of Eastern Christian anointing requires the ministry of seven priests. A table is prepared, upon which is set a vessel containing wheat. Into the wheat has been placed an empty shrine-lamp, seven candles, and seven anointing brushes. Candles are distributed for all to hold during the service. The rite begins with reading Psalm 50 (the great penitential psalm), followed by the chanting of a special canon. After this, the senior priest (or bishop) pours pure olive oil and a small amount of wine into the shrine lamp, and says the \"Prayer of the Oil\", which calls upon God to \"...sanctify this Oil, that it may be effectual for those who shall be anointed therewith, unto healing, and unto relief from every passion, every malady of the flesh and of the spirit, and every ill...\" Then follow seven series of epistles, gospels, long prayers, Ektenias (litanies) and anointings. Each series is served by one of the seven priests in turn. The afflicted one is anointed with the sign of the cross on seven places: the forehead, the nostrils, the cheeks, the lips, the breast, the palms of both hands, and the back of the hands. After the last anointing, the Gospel Book is opened and placed with the writing down upon the head of the one who was anointed, and the senior priest reads the \"Prayer of the Gospel\". At the end, the anointed kisses the Gospel, the Cross and the right hands of the priests, receiving their blessing.\n\nAnointing is considered to be a public rather than a private sacrament, and so as many of the faithful who are able are encouraged to attend. It should be celebrated in the church when possible, but if this is impossible, it may be served in the home or hospital room of the afflicted.\n\nUnction in the Greek Orthodox Church and Churches of Hellenic custom (Antiochian Eastern-Orthodox, Melkite, etc.) is usually given with a minimum of ceremony.\n\nAnointing may also be given during Forgiveness Vespers and Great Week, on Great and Holy Wednesday, to all who are prepared. Those who receive Unction on Holy Wednesday should go to Holy Communion on Maundy Thursday. The significance of receiving Unction on Holy Wednesday is shored up by the hymns in the Triodion for that day, which speak of the sinful woman who anointed the feet of Christ (). Just as her sins were forgiven because of her penitence, so the faithful are exhorted to repent of their sins. In the same narrative, Jesus says, \"in that she hath poured this ointment on my body, she did it for my burial\" (Id., v. 12), linking the unction with Christ's death and resurrection.\n\nIn some dioceses of the Russian Orthodox Church it is customary for the bishop to visit each parish or region of the diocese some time during Great Lent and give Anointing for the faithful, together with the local clergy.\n\nThe 1552 and later editions of the Book of Common Prayer omitted the form of anointing given in the original (1549) version in its Order for the Visitation of the Sick, but most twentieth-century Anglican prayer books do have anointing of the sick.\n\nSome Anglicans accept that anointing of the sick has a sacramental character and is therefore a channel of God's grace, seeing it as an \"outward and visible sign of an inward and spiritual grace\" which is the definition of a sacrament. The Catechism of the Episcopal Church of the United States of America includes Unction of the Sick as among the \"other sacramental rites\" and it states that unction can be done with oil or simply with laying on of hands. The rite of anointing is included in the Episcopal Church's \"Ministration to the Sick\" \n\nArticle 25 of the Thirty-Nine Articles, which are one of the historical formularies of the Church of England (and as such, the Anglican Communion), speaking of the sacraments, says: \"Those five commonly called Sacraments, that is to say, Confirmation, Penance, Orders, Matrimony, and extreme Unction, are not to be counted for Sacraments of the Gospel, being such as have grown partly of the corrupt following of the Apostles, partly are states of life allowed in the Scriptures; but yet have not like nature of Sacraments with Baptism, and the Lord's Supper, for that they have not any visible sign or ceremony ordained of God.\"\n\nAnointing of the sick has been retained in some Lutheran churches since the Reformation. Although it is not considered a sacrament like baptism and the Eucharist, it is known as a ritual in the same respect as confession, confirmation, holy orders, and matrimony.\n\nAfter the penitent has received absolution following confession, the presiding minister recites . He goes on to recite the following:\n[Name], you have confessed your sins and received Holy Absolution. In remembrance of the grace of God given by the Holy Spirit in the waters of Holy Baptism, I will anoint you with oil. Confident in our Lord and in love for you, we also pray for you that you will not lose faith. Knowing that in Godly patience the Church endures with you and supports you during this affliction. We firmly believe that this illness is for the glory of God and that the Lord will both hear our prayer and work according to His good and gracious will.\n\nHe anoints the person on the forehead and says this blessing:\n\nAlmighty God, the Father of our Lord Jesus Christ, who has given you the new birth of water and the Spirit and has forgiven you all your sins, strengthen you with His grace to life everlasting. Amen.\nAmong Protestants, anointing is provided in a wide variety of formats but, for the most part, however, it has fallen into disuse. Protestant communities generally vary widely on the sacramental character of anointing. Most Mainline Protestants recognize only two sacraments, the Eucharist and baptism, deeming Anointing only a humanly-instituted rite. Non-traditional Protestant communities generally use the term \"ordinance\" rather than \"Sacrament\".\n\nLiturgical or Mainline Protestant communities (e.g. Presbyterian, Congregationalist/United Church of Christ, Methodist, etc.) all have official yet often optional liturgical rites for the anointing of the sick partly on the model of Western pre-Reformation rites. Anointing need not be associated with grave illness or imminent danger of death.\n\nIn Charismatic and Pentecostal communities, anointing of the sick is a frequent practice and has been an important ritual in these communities since the respective movements were founded in the 19th and 20th centuries. These communities use extemporaneous forms of administration at the discretion of the minister, who need not be a pastor. There is minimal ceremony attached to its administration. Usually, several people physically touch (laying on of hands) the recipient during the anointing. It may be part of a worship service with the full assembly of the congregation present, but may also be done in more private settings, such as homes or hospital rooms. Some Pentecostals believe that physical healing is within the anointing and so there is often great expectation or at least great hope that a miraculous cure or improvement will occur when someone is being prayed over for healing.\n\nIn Evangelical and Fundamentalist communities, anointing of the sick is performed with varying degrees of frequency, although laying on of hands may be more common than anointing. The rite would be similar to that of Pentecostals in its simplicity, but would usually not have the same emotionalism attached to it. Unlike some Pentecostals, Evangelicals and Fundamentalists generally do not believe that physical healing is within the anointing. Therefore, God may or may not grant physical healing to the sick. The healing conferred by anointing is thus a spiritual event that may not result in physical recovery.\n\nThe Church of the Brethren practices Anointing with Oil as an ordinance along with Baptism, Communion, Laying on of Hands, and the Love Feast.\n\nEvangelical Protestants who use anointing differ about whether the person doing the anointing must be an ordained member of the clergy, whether the oil must necessarily be olive oil and have been previously specially consecrated, and about other details. Several Evangelical groups reject the practice so as not to be identified with charismatic and Pentecostal groups, which practice it widely.\n\nSome Protestant US military chaplains carry the Roman Rite version of the Anointing of the Sick with them for use if called upon to assist wounded or dying soldiers who are Catholics. The Catholic and Orthodox Churches consider invalid \"as a sacrament\" the administration of Anointing of the Sick by such chaplains, who in the eyes of those Churches are not validly ordained priests. The rite performed by them is thus seen as having the same by no means negligible value of any other form of prayer offered for the sick or dying.\n\nLatter-day Saints, who consider themselves restorationists, also practice ritual anointing of the sick, as well as other forms of anointing. Members of The Church of Jesus Christ of Latter-day Saints (LDS Church) consider anointing to be an ordinance.\n\nMembers of the LDS Church who hold the Melchizedek priesthood may use consecrated oil in performing the ordinance of blessing of the \"sick or afflicted\", though oil is not required if it is unavailable. The priesthood holder anoints the recipient's head with a drop of oil, then lays hands upon that head and declare their act of anointing. Then another priesthood holder joins in, if available, and pronounces a \"sealing\" of the anointing and other words of blessing, as he feels inspired. Melchizedek priesthood holders are also authorized to consecrate any pure olive oil and often carry a personal supply in case they have need to perform a blessing. Oil is not used in other blessings, such as for people seeking comfort or counsel.\n\nIn addition to the reference, the Doctrine and Covenants contains numerous references to the anointing and healing of the sick by those with authority to do so.\n\nAdministration to the sick is one of the eight sacraments of the Community of Christ, in which it has also been used for people seeking spiritual, emotional or mental healing.\n\n\n\nWestern\n\nEastern\n"}
{"id": "2349", "url": "https://en.wikipedia.org/wiki?curid=2349", "title": "Abstract data type", "text": "Abstract data type\n\nIn computer science, an abstract data type (ADT) is a mathematical model for data types, where a data type is defined by its behavior (semantics) from the point of view of a \"user\" of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations. This contrasts with data structures, which are concrete representations of data, and are the point of view of an implementer, not a user.\n\nFormally, an ADT may be defined as a \"class of objects whose logical behavior is defined by a set of values and a set of operations\"; this is analogous to an algebraic structure in mathematics. What is meant by \"behavior\" varies by author, with the two main types of formal specifications for behavior being \"axiomatic (algebraic) specification\" and an \"abstract model;\" these correspond to axiomatic semantics and operational semantics of an abstract machine, respectively. Some authors also include the computational complexity (\"cost\"), both in terms of time (for computing operations) and space (for representing values). In practice many common data types are not ADTs, as the abstraction is not perfect, and users must be aware of issues like arithmetic overflow that are due to the representation. For example, integers are often stored as fixed width values (32-bit or 64-bit binary numbers), and thus experience integer overflow if the maximum value is exceeded.\n\nADTs are a theoretical concept in computer science, used in the design and analysis of algorithms, data structures, and software systems, and do not correspond to specific features of computer languages—mainstream computer languages do not directly support formally specified ADTs. However, various language features correspond to certain aspects of ADTs, and are easily confused with ADTs proper; these include abstract types, opaque data types, protocols, and design by contract. ADTs were first proposed by Barbara Liskov and Stephen N. Zilles in 1974, as part of the development of the CLU language.\n\nFor example, integers are an ADT, defined as the values …, −2, −1, 0, 1, 2, …, and by the operations of addition, subtraction, multiplication, and division, together with greater than, less than, etc., which behave according to familiar mathematics (with care for integer division), independently of how the integers are represented by the computer. Explicitly, \"behavior\" includes obeying various axioms (associativity and commutativity of addition etc.), and preconditions on operations (cannot divide by zero). Typically integers are represented in a data structure as binary numbers, most often as two's complement, but might be binary-coded decimal or in ones' complement, but the user is abstracted from the concrete choice of representation, and can simply use the data as integers.\n\nAn ADT consists not only of operations, but also of values of the underlying data and of constraints on the operations. An \"interface\" typically refers only to the operations, and perhaps some of the constraints on the operations, notably pre-conditions and post-conditions, but not other constraints, such as relations between the operations.\n\nFor example, an abstract stack, which is a last-in-first-out structure, could be defined by three operations: push, that inserts a data item onto the stack; pop, that removes a data item from it; and peek or top, that accesses a data item on top of the stack without removal. An abstract queue, which is a first-in-first-out structure, would also have three operations: enqueue, that inserts a data item into the queue; dequeue, that removes the first data item from it; and front, that accesses and serves the first data item in the queue. There would be no way of differentiating these two data types, unless a mathematical constraint is introduced that for a stack specifies that each pop always returns the most recently pushed item that has not been popped yet. When analyzing the efficiency of algorithms that use stacks, one may also specify that all operations take the same time no matter how many data items have been pushed into the stack, and that the stack uses a constant amount of storage for each element.\n\nAbstract data types are purely theoretical entities, used (among other things) to simplify the description of abstract algorithms, to classify and evaluate data structures, and to formally describe the type systems of programming languages. However, an ADT may be implemented by specific data types or data structures, in many ways and in many programming languages; or described in a formal specification language. ADTs are often implemented as modules: the module's interface declares procedures that correspond to the ADT operations, sometimes with comments that describe the constraints. This information hiding strategy allows the implementation of the module to be changed without disturbing the client programs.\n\nThe term abstract data type can also be regarded as a generalized approach of a number of algebraic structures, such as lattices, groups, and rings. The notion of abstract data types is related to the concept of data abstraction, important in object-oriented programming and design by contract methodologies for software development.\n\nAn abstract data type is defined as a mathematical model of the data objects that make up a data type as well as the functions that operate on these objects.\nThere are no standard conventions for defining them. A broad division may be drawn between \"imperative\" and \"functional\" definition styles.\n\nIn the philosophy of imperative programming languages, an abstract data structure is conceived as an entity that is \"mutable\"—meaning that it may be in different \"states\" at different times. Some operations may change the state of the ADT; therefore, the order in which operations are evaluated is important, and the same operation on the same entities may have different effects if executed at different times—just like the instructions of a computer, or the commands and procedures of an imperative language. To underscore this view, it is customary to say that the operations are \"executed\" or \"applied\", rather than \"evaluated\". The imperative style is often used when describing abstract algorithms. (See The Art of Computer Programming by Donald Knuth for more details)\n\nImperative-style definitions of ADT often depend on the concept of an \"abstract variable\", which may be regarded as the simplest non-trivial ADT. An abstract variable \"V\" is a mutable entity that admits two operations:\nwith the constraint that\n\nAs in so many programming languages, the operation store(\"V\", \"x\") is often written \"V\" ← \"x\" (or some similar notation), and fetch(\"V\") is implied whenever a variable \"V\" is used in a context where a value is required. Thus, for example, \"V\" ← \"V\" + 1 is commonly understood to be a shorthand for store(\"V\",fetch(\"V\") + 1).\n\nIn this definition, it is implicitly assumed that storing a value into a variable \"U\" has no effect on the state of a distinct variable \"V\". To make this assumption explicit, one could add the constraint that\n\nMore generally, ADT definitions often assume that any operation that changes the state of one ADT instance has no effect on the state of any other instance (including other instances of the same ADT) — unless the ADT axioms imply that the two instances are connected (aliased) in that sense. For example, when extending the definition of abstract variable to include abstract records, the operation that selects a field from a record variable \"R\" must yield a variable \"V\" that is aliased to that part of \"R\".\n\nThe definition of an abstract variable \"V\" may also restrict the stored values \"x\" to members of a specific set \"X\", called the \"range\" or \"type\" of \"V\". As in programming languages, such restrictions may simplify the description and analysis of algorithms, and improve their readability.\n\nNote that this definition does not imply anything about the result of evaluating fetch(\"V\") when \"V\" is \"un-initialized\", that is, before performing any store operation on \"V\". An algorithm that does so is usually considered invalid, because its effect is not defined. (However, there are some important algorithms whose efficiency strongly depends on the assumption that such a fetch is legal, and returns some arbitrary value in the variable's range.)\n\nSome algorithms need to create new instances of some ADT (such as new variables, or new stacks). To describe such algorithms, one usually includes in the ADT definition a create() operation that yields an instance of the ADT, usually with axioms equivalent to\nThis axiom may be strengthened to exclude also partial aliasing with other instances. On the other hand, this axiom still allows implementations of create() to yield a previously created instance that has become inaccessible to the program.\n\nAs another example, an imperative-style definition of an abstract stack could specify that the state of a stack \"S\" can be modified only by the operations\nwith the constraint that\n\nSince the assignment \"V\" ← \"x\", by definition, cannot change the state of \"S\", this condition implies that \"V\" ← pop(\"S\") restores \"S\" to the state it had before the push(\"S\", \"x\"). From this condition and from the properties of abstract variables, it follows, for example, that the sequence\nwhere \"x\", \"y\", and \"z\" are any values, and \"U\", \"V\", \"W\" are pairwise distinct variables, is equivalent to\n\nHere it is implicitly assumed that operations on a stack instance do not modify the state of any other ADT instance, including other stacks; that is,\n\nAn abstract stack definition usually includes also a Boolean-valued function empty(\"S\") and a create() operation that returns a stack instance, with axioms equivalent to\n\nSometimes an ADT is defined as if only one instance of it existed during the execution of the algorithm, and all operations were applied to that instance, which is not explicitly notated. For example, the abstract stack above could have been defined with operations push(\"x\") and pop(), that operate on \"the\" only existing stack. ADT definitions in this style can be easily rewritten to admit multiple coexisting instances of the ADT, by adding an explicit instance parameter (like \"S\" in the previous example) to every operation that uses or modifies the implicit instance.\n\nOn the other hand, some ADTs cannot be meaningfully defined without assuming multiple instances. This is the case when a single operation takes two distinct instances of the ADT as parameters. For an example, consider augmenting the definition of the abstract stack with an operation compare(\"S\", \"T\") that checks whether the stacks \"S\" and \"T\" contain the same items in the same order.\n\nAnother way to define an ADT, closer to the spirit of functional programming, is to consider each state of the structure as a separate entity. In this view, any operation that modifies the ADT is modeled as a mathematical function that takes the old state as an argument, and returns the new state as part of the result. Unlike the imperative operations, these functions have no side effects. Therefore, the order in which they are evaluated is immaterial, and the same operation applied to the same arguments (including the same input states) will always return the same results (and output states).\n\nIn the functional view, in particular, there is no way (or need) to define an \"abstract variable\" with the semantics of imperative variables (namely, with fetch and store operations). Instead of storing values into variables, one passes them as arguments to functions.\n\nFor example, a complete functional-style definition of an abstract stack could use the three operations:\n\nIn a functional-style definition there is no need for a create operation. Indeed, there is no notion of \"stack instance\". The stack states can be thought of as being potential states of a single stack structure, and two stack states that contain the same values in the same order are considered to be identical states. This view actually mirrors the behavior of some concrete implementations, such as linked lists with hash cons.\n\nInstead of create(), a functional-style definition of an abstract stack may assume the existence of a special stack state, the \"empty stack\", designated by a special symbol like Λ or \"()\"; or define a bottom() operation that takes no arguments and returns this special stack state. Note that the axioms imply that\nIn a functional-style definition of a stack one does not need an empty predicate: instead, one can test whether a stack is empty by testing whether it is equal to Λ.\n\nNote that these axioms do not define the effect of top(\"s\") or pop(\"s\"), unless \"s\" is a stack state returned by a push. Since push leaves the stack non-empty, those two operations are undefined (hence invalid) when \"s\" = Λ. On the other hand, the axioms (and the lack of side effects) imply that push(\"s\", \"x\") = push(\"t\", \"y\") if and only if \"x\" = \"y\" and \"s\" = \"t\".\n\nAs in some other branches of mathematics, it is customary to assume also that the stack states are only those whose existence can be proved from the axioms in a finite number of steps. In the abstract stack example above, this rule means that every stack is a \"finite\" sequence of values, that becomes the empty stack (Λ) after a finite number of pops. By themselves, the axioms above do not exclude the existence of infinite stacks (that can be poped forever, each time yielding a different state) or circular stacks (that return to the same state after a finite number of pops). In particular, they do not exclude states \"s\" such that pop(\"s\") = \"s\" or push(\"s\", \"x\") = \"s\" for some \"x\". However, since one cannot obtain such stack states with the given operations, they are assumed \"not to exist\".\n\nAside from the behavior in terms of axioms, it is also possible to include, in the definition of an ADT operation, their algorithmic complexity. Alexander Stepanov, designer of the C++ Standard Template Library, included complexity guarantees in the STL specification, arguing:\n\nAbstraction provides a promise that any implementation of the ADT has certain properties and abilities; knowing these is all that is required to make use of an ADT object. The user does not need any technical knowledge of how the implementation works to use the ADT. In this way, the implementation may be complex but will be encapsulated in a simple interface when it is actually used.\n\nCode that uses an ADT object will not need to be edited if the implementation of the ADT is changed. Since any changes to the implementation must still comply with the interface, and since code using an ADT object may only refer to properties and abilities specified in the interface, changes may be made to the implementation without requiring any changes in code where the ADT is used.\n\nDifferent implementations of the ADT, having all the same properties and abilities, are equivalent and may be used somewhat interchangeably in code that uses the ADT. This gives a great deal of flexibility when using ADT objects in different situations. For example, different implementations of the ADT may be more efficient in different situations; it is possible to use each in the situation where they are preferable, thus increasing overall efficiency.\n\nSome operations that are often specified for ADTs (possibly under other names) are\n\nIn imperative-style ADT definitions, one often finds also\n\nThe free operation is not normally relevant or meaningful, since ADTs are theoretical entities that do not \"use memory\". However, it may be necessary when one needs to analyze the storage used by an algorithm that uses the ADT. In that case one needs additional axioms that specify how much memory each ADT instance uses, as a function of its state, and how much of it is returned to the pool by free.\n\nSome common ADTs, which have proved useful in a great variety of applications, are\n\nEach of these ADTs may be defined in many ways and variants, not necessarily equivalent. For example, an abstract stack may or may not have a count operation that tells how many items have been pushed and not yet popped. This choice makes a difference not only for its clients but also for the implementation.\n\nAn extension of ADT for computer graphics was proposed in 1979: an abstract graphical data type (AGDT). It was introduced by Nadia Magnenat Thalmann, and Daniel Thalmann. AGDTs provide the advantages of ADTs with facilities to build graphical objects in a structured way.\n\nImplementing an ADT means providing one procedure or function for each abstract operation. The ADT instances are represented by some concrete data structure that is manipulated by those procedures, according to the ADT's specifications.\n\nUsually there are many ways to implement the same ADT, using several different concrete data structures. Thus, for example, an abstract stack can be implemented by a linked list or by an array.\n\nIn order to prevent clients from depending on the implementation, an ADT is often packaged as an \"opaque data type\" in one or more modules, whose interface contains only the signature (number and types of the parameters and results) of the operations. The implementation of the module—namely, the bodies of the procedures and the concrete data structure used—can then be hidden from most clients of the module. This makes it possible to change the implementation without affecting the clients. If the implementation is exposed, it is known instead as a \"transparent data type.\"\n\nWhen implementing an ADT, each instance (in imperative-style definitions) or each state (in functional-style definitions) is usually represented by a handle of some sort.\n\nModern object-oriented languages, such as C++ and Java, support a form of abstract data types. When a class is used as a type, it is an abstract type that refers to a hidden representation. In this model an ADT is typically implemented as a class, and each instance of the ADT is usually an object of that class. The module's interface typically declares the constructors as ordinary procedures, and most of the other ADT operations as methods of that class. However, such an approach does not easily encapsulate multiple representational variants found in an ADT. It also can undermine the extensibility of object-oriented programs.\nIn a pure object-oriented program that uses interfaces as types, types refer to behaviors not representations.\n\nAs an example, here is an implementation of the abstract stack above in the C programming language.\nAn imperative-style interface might be:\nThis interface could be used in the following manner:\nThis interface can be implemented in many ways. The implementation may be arbitrarily inefficient, since the formal definition of the ADT, above, does not specify how much space the stack may use, nor how long each operation should take. It also does not specify whether the stack state \"s\" continues to exist after a call \"x\" ← pop(\"s\").\n\nIn practice the formal definition should specify that the space is proportional to the number of items pushed and not yet popped; and that every one of the operations above must finish in a constant amount of time, independently of that number. To comply with these additional specifications, the implementation could use a linked list, or an array (with dynamic resizing) together with two integers (an item count and the array size).\n\nFunctional-style ADT definitions are more appropriate for functional programming languages, and vice versa. However, one can provide a functional-style interface even in an imperative language like C. For example:\nMany modern programming languages, such as C++ and Java, come with standard libraries that implement several common ADTs, such as those listed above.\n\nThe specification of some programming languages is intentionally vague about the representation of certain built-in data types, defining only the operations that can be done on them. Therefore, those types can be viewed as \"built-in ADTs\". Examples are the arrays in many scripting languages, such as Awk, Lua, and Perl, which can be regarded as an implementation of the abstract list.\n\n\n"}
{"id": "2357", "url": "https://en.wikipedia.org/wiki?curid=2357", "title": "American Football League", "text": "American Football League\n\nThe American Football League (AFL) was a major professional American football league that operated from 1960 until 1969, when it merged with the National Football League (NFL). The upstart AFL operated in direct competition with the more established NFL throughout its existence. It was more successful than earlier rivals to the NFL with the same name, the American Football League (1926), American Football League (1936), and American Football League (1940).\n\nThe AFL was created by a number of owners who had been refused NFL expansion franchises or had minor shares of NFL franchises. The AFL's original lineup consisted of an Eastern division of the New York Titans, Boston Patriots, Buffalo Bills, and the Houston Oilers, and a Western division of the Los Angeles Chargers, Denver Broncos, Oakland Raiders, and Dallas Texans. The league first gained attention by signing 75% of the NFL's first-round draft choices in 1960, including Houston's successful signing of Heisman Trophy winner Billy Cannon.\n\nWhile the first years of the AFL saw uneven competition and low attendance, the league was buttressed by a generous television contract with ABC (followed by a contract with NBC for games starting with the 1965 season) that broadcast the more offense-oriented football league nationwide. Continuing to attract top talent from colleges and the NFL by the mid-1960s, as well as successful franchise shifts of the Chargers to San Diego and the Texans to Kansas City, the AFL established a dedicated following. The transformation of the struggling Titans into the New York Jets under new ownership further solidified the league's reputation among the major media.\n\nAs fierce competition made player salaries skyrocket in both leagues, especially after a series of \"raids\", the leagues agreed to a merger in 1966. Among the conditions were a common draft and a championship game played between the two league champions, which would eventually become known as the Super Bowl.\n\nThe AFL and NFL operated as separate leagues until 1970, with separate regular season and playoff schedules except for the championship game. During this time the AFL added the Miami Dolphins and Cincinnati Bengals. After losses by Kansas City and Oakland in the first two AFL-NFL Championship Games to the Green Bay Packers, the New York Jets and Kansas City Chiefs won Super Bowls III and IV respectively, cementing the league's claim to being an equal to the NFL.\n\nIn 1970, the AFL was absorbed into the NFL, and the ten AFL franchises along with the Baltimore Colts, Cleveland Browns, and Pittsburgh Steelers became the American Football Conference.\n\nDuring the 1950s, the National Football League had grown to rival Major League Baseball as one of the most popular professional sports leagues in the United States. One franchise that did not share in this newfound success of the league was the Chicago Cardinals, owned by the Bidwill family, who had become overshadowed by the more popular Chicago Bears. The Bidwills hoped to relocate their franchise, preferably to St. Louis but could not come to terms with the league on a relocation fee. Needing cash, the Bidwills began entertaining offers from would-be investors, and one of the men who approached the Bidwills was Lamar Hunt, son and heir of millionaire oilman H. L. Hunt. Hunt offered to buy the Cardinals and move them to Dallas, where he had grown up. However, these negotiations came to nothing, since the Bidwills insisted on retaining a controlling interest in the franchise and were unwilling to move their team to a city where a previous NFL franchise had failed in 1952. While Hunt negotiated with the Bidwills, similar offers were made by Bud Adams, Bob Howsam, and Max Winter.\n\nWhen Hunt, Adams, and Howsam were unable to secure a controlling interest in the Cardinals, they approached NFL commissioner Bert Bell and proposed the addition of expansion teams. Bell, wary of expanding the 12-team league and risking its newfound success, rejected the offer. On his return flight to Dallas, Hunt conceived the idea of an entirely new league and decided to contact the others who had shown interest in purchasing the Cardinals. He contacted Adams, Howsam, and Winter (as well as Winter's business partner, Bill Boyer) to gauge their interest in starting a new league. Hunt's first meeting with Adams was held in March 1959. Hunt, who felt a regional rivalry would be critical for the success of the new league, convinced Adams to join and found his team in Houston. Hunt next secured an agreement from Howsam to bring a team to Denver.\n\nAfter Winter and Boyer agreed to start a team in Minneapolis-Saint Paul, the new league had its first four teams. Hunt then approached Willard Rhodes, who hoped to bring pro football to Seattle. However, the University of Washington was unwilling to let the fledgling league use Husky Stadium, probably due to the excessive wear and tear that would have been caused to the facility's grass surface. With no place for his team to play, Rhodes' effort came to nothing. Hunt also sought franchises in Los Angeles, Buffalo and New York City. During the summer of 1959, he sought the blessings of the NFL for his nascent league, as he did not seek a potentially costly rivalry. Within weeks of the July 1959 announcement of the league's formation, Hunt received commitments from Barron Hilton and Harry Wismer to bring teams to Los Angeles and New York, respectively. His initial efforts for Buffalo, however, were rebuffed, when Hunt's first choice of owner, Pat McGroder, declined to take part; McGroder had hoped that the threat of the AFL would be enough to prompt the NFL to expand to Buffalo.\n\nOn August 14, 1959, the first league meeting was held in Chicago, and charter memberships were given to Dallas, New York, Houston, Denver, Los Angeles, and Minneapolis-Saint Paul. On August 22 the league officially was named the American Football League at a meeting in Dallas. The NFL's initial reaction was not as openly hostile as it had been with the earlier All-America Football Conference (Bell had even given his public approval), yet individual NFL owners soon began a campaign to undermine the new league. AFL owners were approached with promises of new NFL franchises or ownership stakes in existing ones. Only the party from Minneapolis accepted, and the Minnesota group joined the NFL the next year in 1961; the Minneapolis group were joined by Ole Haugsrud and Bernie Ridder in the new NFL team's ownership group, with was named the Minnesota Vikings. The older league also announced on August 29 that it had conveniently reversed its position against expansion, and planned to bring NFL expansion teams to Houston and Dallas, to start play in 1961. (The NFL did not expand to Houston at that time, the promised Dallas team – the Dallas Cowboys – actually started play in 1960, and the Vikings began play in 1961.) Finally, the NFL quickly came to terms with the Bidwills and allowed them to relocate the struggling Cardinals to St. Louis, eliminating that city as a potential AFL market.\n\nRalph Wilson, who owned a minority interest in the NFL's Detroit Lions at the time, initially announced he was placing a team in Miami, but like the Seattle situation, was also rebuffed by local ownership; given five other choices, Wilson negotiated with McGroder and brought the team that would become the Bills to Buffalo. Buffalo was officially awarded its franchise on October 28. During a league meeting on November 22, a 10-man ownership group from Boston (led by Billy Sullivan) was awarded the AFL's eighth team. On November 30, 1959, Joe Foss, a World War II Marine fighter ace and former governor of South Dakota, was named the AFL's first commissioner. Foss commissioned a friend of Harry Wismer's to develop the AFL's eagle-on-football logo. Hunt was elected President of the AFL on January 26, 1960.\n\nThe AFL's first draft took place the same day Boston was awarded its franchise, and lasted 33 rounds. The league held a second draft on December 2, which lasted for 20 rounds. Because the Raiders joined after the AFL draft, they inherited Minnesota's selections. A special \"allocation draft\" was held in January 1960, to allow the Raiders to stock their team, as some of the other AFL teams had already signed some of Minneapolis' original draft choices.\n\nIn November 1959, Minneapolis owner Max Winter announced his intent to leave the AFL to accept a franchise offer from the NFL. In 1961, his team began play in the NFL as the Minnesota Vikings. Los Angeles Chargers owner Barron Hilton demanded that a replacement for Minnesota be placed in California, to reduce his team's operating costs and to create a rivalry. After a brief search, Oakland was chosen and an ownership group led by F. Wayne Valley and local real estate developer Chet Soda was formed. After initially being called the Oakland \"\"Señores\"\", the Oakland Raiders officially joined the AFL on January 30, 1960.\n\nThe AFL's first major success came when the Houston Oilers signed Billy Cannon, the All-American and 1959 Heisman Trophy winner from LSU. Cannon signed a $100,000 contract to play for the Oilers, despite having already signed a $50,000 contract with the NFL's Los Angeles Rams. The Oilers filed suit and claimed that Rams general manager Pete Rozelle had unduly manipulated Cannon. The court upheld the Houston contract, and with Cannon the Oilers appeared in the AFL's first three championship games (winning two).\n\nOn June 9, 1960, the league signed a five-year television contract with ABC, which brought in revenues of approximately US$2,125,000 per year for the entire league. On June 17, the AFL filed an antitrust lawsuit against the NFL, which was dismissed in 1962 after a two-month trial. The AFL began regular-season play (a night game on Friday, September 9, 1960) with eight teams in the league — the Boston Patriots, Buffalo Bills, Dallas Texans, Denver Broncos, Houston Oilers, Los Angeles Chargers, New York Titans, and Oakland Raiders. Raiders' co-owner Wayne Valley dubbed the AFL ownership \"The Foolish Club\", a term Lamar Hunt subsequently used on team photographs he sent as Christmas gifts.\n\nThe Oilers became the first-ever league champions by defeating the Chargers, 24–16, in the AFL Championship on January 1, 1961. Attendance for the 1960 season was respectable for a new league, but not nearly that of the NFL. In 1960, the NFL averaged attendance of more than 40,000 fans per game and more popular NFL teams in 1960 regularly saw attendance figures in excess of 50,000 per game, while CFL attendances averaged approximately 20,000 per game. By comparison, AFL attendance averaged about 16,500 per game and generally hovered between 10,000-20,000 per game. Professional football was still primarily a gate-driven business in 1960, so low attendance meant financial losses. The Raiders, with a league-worst average attendance of just 9,612, lost $500,000 in their first year and only survived after receiving a $400,000 loan from Bills owner Ralph Wilson. In an early sign of stability, however, the AFL did not lose any teams after its first year of operation. In fact, the only major change was the relocation of the Chargers from Los Angeles to nearby San Diego.\n\nOn August 8, 1961, the AFL challenged the Canadian Football League to an exhibition game that would feature the Hamilton Tiger-Cats and the Buffalo Bills, which was attended by 24,376 spectators. Playing at Civic Stadium in Hamilton, Ontario, the Tiger-Cats defeated the Bills 38–21 playing a mix of AFL and CFL rules.\n\nWhile the Oilers found instant success in the AFL, other teams did not fare as well. The Oakland Raiders and New York Titans struggled on and off the field during their first few seasons in the league. Oakland's eight-man ownership group was reduced to just three in 1961, after heavy financial losses in their first season. Attendance for home games was poor, partly due to the team playing in the San Francisco Bay Area—which already had an established NFL team (the San Francisco 49ers)—but the product on the field was also to blame. After winning six games in their debut season, the Raiders won a total of three times in the 1961 and 1962 seasons. Oakland took part in a 1961 supplemental draft meant to boost the weaker teams in the league, but it did little good. They participated in another such draft in 1962.\n\nThe Titans fared a little better on the field but had their own financial troubles. Attendance was so low for home games that team owner Harry Wismer had fans move to seats closer to the field to give the illusion of a fuller stadium on television. Eventually Wismer could no longer afford to meet his payroll, and on November 8, 1962 the AFL took over operations of the team. The Titans were sold to a five-person ownership group headed by Sonny Werblin on March 28, 1963, and in April the new owners changed the team's name to the New York Jets.\n\nThe Raiders and Titans both finished last in their respective divisions in the 1962 season. The Texans and Oilers, winners of their divisions, faced each other for the 1962 AFL Championship on December 23. The Texans dethroned the two-time champion Oilers, 20–17, in a double-overtime contest that was, at the time, professional football's longest-ever game.\n\nIn 1963, the Texans became the second AFL team to relocate. Lamar Hunt felt that despite winning the league championship in 1962, the Texans could not succeed financially competing in the same market as the Dallas Cowboys, which entered the NFL as an expansion franchise in 1960. After meetings with New Orleans, Atlanta, and Miami, Hunt announced on May 22 that the Texans' new home would be Kansas City, Missouri. Kansas City mayor Harold Roe Bartle (nicknamed \"Chief\") was instrumental in his city's success in attracting the team. Partly to honor Bartle, the franchise officially became the Kansas City Chiefs on May 26.\n\nThe San Diego Chargers, under head coach Sid Gillman, won a decisive 51–10 victory over the Boston Patriots for the 1963 AFL Championship. Confident that his team was capable of beating the NFL-champion Chicago Bears (he had the Chargers' rings inscribed with the phrase \"World Champions\"), Gillman approached NFL Commissioner Pete Rozelle and proposed a final championship game between the two teams. Rozelle declined the offer; however, the game would be instituted three seasons later.\n\nA series of events throughout the next few years demonstrated the AFL's ability to achieve a greater level of equality with the NFL. On January 29, 1964, the AFL signed a lucrative $36 million television contract with NBC (beginning in the 1965 season), which gave the league money it needed to compete with the NFL for players. Pittsburgh Steelers owner Art Rooney was quoted as saying to NFL Commissioner Pete Rozelle that \"They don't have to call us 'Mister' anymore\". A single-game attendance record was set on November 8, 1964, when 61,929 fans packed Shea Stadium to watch the New York Jets and Buffalo Bills.\n\nThe bidding war for players between the AFL and NFL escalated in 1965. The Chiefs drafted University of Kansas star Gale Sayers in the first round of the 1965 AFL draft (held November 28, 1964), while the Chicago Bears did the same in the NFL draft. Sayers eventually signed with the Bears. A similar situation occurred when the New York Jets and the NFL's St. Louis Cardinals both drafted University of Alabama quarterback Joe Namath. In what was viewed as a key victory for the AFL, Namath signed a $427,000 contract with the Jets on January 2, 1965 (the deal included a new car). It was the highest amount of money ever paid to a collegiate football player, and is cited as the strongest contributing factor to the eventual merger between the two leagues.\n\nAfter the 1963 season, the Newark Bears of the Atlantic Coast Football League expressed interest in joining the AFL; concerns over having to split the New York metro area with the still-uncertain Jets were a factor in the Bears bid being rejected. In early 1965, the AFL awarded its first expansion team to Rankin Smith of Atlanta. The NFL quickly counteroffered Smith a franchise, which Smith accepted; the Atlanta Falcons began play as an NFL franchise. In March 1965, Joe Robbie had met with Commissioner Foss to inquire about an expansion franchise for Miami. On May 6, after Atlanta's exit, Robbie secured an agreement with Miami mayor Robert King High to bring a team to Miami. League expansion was approved at a meeting held on June 7, and on August 16 the AFL's ninth franchise was officially awarded to Robbie and television star Danny Thomas. The Miami Dolphins joined the league for a fee of $7.5 million and started play in the AFL's Eastern Division in 1966.\n\nIn 1966, the rivalry between the AFL and NFL reached an all-time peak. On April 7, Joe Foss resigned as AFL commissioner. His successor was Oakland Raiders head coach and general manager Al Davis, who had been instrumental in turning around the fortunes of that franchise. No longer content with trying to outbid the NFL for college talent, the AFL under Davis started to recruit players already on NFL squads. Davis's strategy focused on quarterbacks in particular, and in two months he persuaded seven NFL quarterbacks to sign with the AFL. Although Davis's intention was to help the AFL win the bidding war, some AFL and NFL owners saw the escalation as detrimental to both leagues. Alarmed with the rate of spending in the league, Hilton Hotels forced Barron Hilton to relinquish his stake in the Chargers as a condition of maintaining his leadership role with the hotel chain.\n\nThe same month Davis was named commissioner, several NFL owners, along with Dallas Cowboys general manager Tex Schramm, secretly approached Lamar Hunt and other AFL owners and asked the AFL to merge. They held a series of secret meetings in Dallas to discuss their concerns over rapidly increasing player salaries, as well as the practice of player poaching. Hunt and Schramm completed the basic groundwork for a merger of the two leagues by the end of May, and on June 8, 1966, the merger was officially announced. Under the terms of the agreement, the two leagues would hold a common player draft. The agreement also called for a title game to be played between the champions of the respective leagues. The two leagues would be fully merged by 1970, NFL commissioner Pete Rozelle would remain as commissioner of the merged league, and additional expansion teams would eventually be awarded by 1970 or soon thereafter to bring it to a 28-team league. The AFL also agreed to pay indemnities of $18 million to the NFL over 20 years. In protest, Davis resigned as AFL commissioner on July 25 rather than remain until the completion of the merger, and Milt Woodard was named President of the AFL.\n\nOn January 15, 1967, the first-ever World Championship Game between the champions of the two separate professional football leagues, the AFL-NFL Championship Game (retroactively referred to as Super Bowl I), was played in Los Angeles. After a close first half, the NFL champion Green Bay Packers overwhelmed the AFL champion Kansas City Chiefs, 35–10. The loss reinforced for many the notion that the AFL was an inferior league. Packers head coach Vince Lombardi stated after the game, \"I do not think they are as good as the top teams in the National Football League.\"\n\nThe second AFL-NFL Championship (Super Bowl II) yielded a similar result. The Oakland Raiders—who had easily beaten the Houston Oilers to win their first AFL championship—were overmatched by the Packers, 33–14. The more experienced Packers capitalized on a number of Raiders miscues and never trailed. Green Bay defensive tackle Henry Jordan offered a compliment to Oakland and the AFL, when he said, \"... the AFL is becoming much more sophisticated on offense. I think the league has always had good personnel, but the blocks were subtler and better conceived in this game.\"\n\nThe AFL added its tenth and final team on May 24, 1967, when it awarded the league's second expansion franchise to an ownership group from Cincinnati, Ohio, headed by NFL legend Paul Brown. Although Brown had intended to join the NFL, he agreed to join the AFL when he learned that his team would be included in the NFL once the merger was completed. The Cincinnati Bengals began play in the 1968 season, finishing last in the Western Division.\n\nWhile many AFL players and observers believed their league was the equal of the NFL, their first two Super Bowl performances did nothing to prove it. However, on November 17, 1968, when NBC cut away from a game between the Jets and Raiders to air the children's movie \"Heidi\", the ensuing uproar helped disprove the notion that fans still considered the AFL an inferior product. The perception of AFL inferiority forever changed on January 12, 1969, when the AFL Champion New York Jets shocked the heavily favored NFL Champion Baltimore Colts in Super Bowl III. The Colts, who entered the contest favored by as many as 18 points, had completed the 1968 NFL season with a 13–1 record, and won the NFL title with a convincing 34–0 win over the Cleveland Browns. Led by their stalwart defense—which allowed a record-low 144 points—the 1968 Colts were considered one of the best-ever NFL teams.\n\nBy contrast, the Jets had allowed 280 points, the highest total for any division winner in the two leagues. They had also only narrowly beaten the favored Oakland Raiders 27–23 in the AFL championship game. Jets quarterback Joe Namath recalled that in the days leading up to the game, he grew increasingly angry when told New York had no chance to beat Baltimore. Three days before the game, a frustrated Namath responded to a heckler at the Touchdown Club in Miami by declaring, \"We're going to win Sunday, I'll guarantee you.\"\n\nNamath and the Jets made good on his guarantee as they held the Colts scoreless until late in the fourth quarter. The Jets won, 16–7, in what is considered one of the greatest upsets in American sports history. With the win, the AFL finally achieved parity with the NFL and legitimized the merger of the two leagues. That notion was reinforced one year later in Super Bowl IV, when the AFL champion Kansas City Chiefs upset the NFL champion Minnesota Vikings, 23–7, in the last championship game to be played between the two leagues. The Vikings, favored by 12½ points, were held to just 67 rushing yards.\n\nThe last game in AFL history was the AFL All-Star Game, held in Houston's Astrodome on January 17, 1970. The Western All-Stars, led by Chargers quarterback John Hadl, defeated the Eastern All-Stars, 26–3. Buffalo rookie back O.J. Simpson carried the ball for the last play in AFL history. Hadl was named the game's Most Valuable Player. Prior to the start of the 1970 NFL season, the merged league was organized into two conferences of three divisions each. All ten AFL teams made up the bulk of the new American Football Conference. To avoid having an inequitable number of teams in each conference, the leagues voted to move three NFL teams to the AFC. Motivated by the prospect of an intrastate rivalry with the Bengals as well as by personal animosity toward Paul Brown, Cleveland Browns owner Art Modell quickly offered to include his team in the AFC. He helped persuade the Pittsburgh Steelers (the Browns' archrivals) and Baltimore Colts (who shared the Baltimore/Washington, D.C. market with the Washington Redskins) to follow suit, and each team received US $3 million to make the switch. All the other NFL squads became part of the National Football Conference.\n\nPro Football Hall of Fame receiver Charlie Joiner, who started his career with the Houston Oilers (1969), was the last AFL player active in professional football, retiring after the 1986 season, when he played for the San Diego Chargers.\n\nThe American Football League stands as the only professional football league to successfully compete against the NFL. When the two leagues merged in 1970, all ten AFL franchises and their statistics became part of the new NFL. Every other professional league that had competed against the NFL before the AFL–NFL merger had folded completely: the three previous leagues named \"American Football League\" and the All-America Football Conference. From an earlier AFL (1936–1937), only the Cleveland Rams (now the Los Angeles Rams) joined the NFL and are currently operating, as are the Cleveland Browns and the San Francisco 49ers from the AAFC. A third AAFC team, the Baltimore Colts (not related to the 1953–1983 Baltimore Colts or to the current Indianapolis Colts franchise), played only one year in the NFL, disbanding at the end of the 1950 season. The league resulting from the merger was a 26-team juggernaut (since expanded to 32) with television rights covering all of the Big Three television networks and teams in close proximity to almost all of the top 40 metropolitan areas, a fact that has precluded any other competing league from gaining traction since the merger; failed attempts to mimic the AFL's success included the World Football League (1974–75), United States Football League (1983–85), XFL (2001) and United Football League (2009–2012).\n\nThe AFL was also the most successful of numerous upstart leagues of the 1960s and 1970s that attempted to challenge a major professional league's dominance. All nine teams that were in the AFL at the time the merger was agreed upon were accepted into the league intact (as was the tenth team added between the time of the merger's agreement and finalization), and none of the AFL's teams have ever folded. For comparison, the World Hockey Association (1972–79) managed to have four of its six remaining teams merged into the National Hockey League, which actually caused the older league to contract a franchise, but WHA teams were forced to disperse the majority of their rosters and restart as expansion teams. The merged WHA teams were also not financially sound (in large part from the expansion fees the NHL imposed on them), and three of the four were forced to relocate within 20 years. The American Basketball Association (1967–76) managed to have only four of its teams merged into the National Basketball Association, and the rest of the league was forced to fold. Both the WHA and ABA lost several teams to financial insolvency over the course of their existences. The Continental League, a proposed third league for Major League Baseball that was to begin play in 1961, never played a single game, largely because MLB responded to the proposal by expanding to four of that league's proposed cities. Historically, the only other professional sports league in the United States to exhibit a comparable level of franchise stability from its inception was the American League of Major League Baseball.\n\nThe NFL adopted some of the innovations introduced by the AFL immediately and a few others in the years following the merger. One was including the names on player jerseys. The older league also adopted the practice of using the stadium scoreboard clocks to keep track of the official game time, instead of just having a stopwatch used by the referee. The AFL played a 14-game schedule for its entire existence, starting in 1960. The NFL, which had played a 12-game schedule since 1947, changed to a 14-game schedule in 1961, a year after the American Football League instituted it. The AFL also introduced the two-point conversion to professional football thirty-four years before the NFL instituted it in 1994 (college football had adopted the two-point conversion in the late 1950s). All of these innovations pioneered by the AFL, including its more exciting style of play and colorful uniforms, have essentially made today's professional football more like the \"AFL\" than like the old-line NFL. The AFL's challenge to the NFL also laid the groundwork for the Super Bowl, which has become the standard for championship contests in the United States of America.\n\nThe NFL also adapted how the AFL used the growing power of televised football games, which were bolstered with the help of major network contracts (first with ABC and later with NBC). With that first contract with ABC, the AFL adopted the first-ever cooperative television plan for professional football, in which the proceeds were divided equally among member clubs. It featured many outstanding games, such as the classic 1962 double-overtime American Football League championship game between the Dallas Texans and the defending champion Houston Oilers. At the time it was the longest professional football championship game ever played. The AFL also appealed to fans by offering a flashier style of play (just like the ABA in basketball), compared to the more conservative game of the NFL. Long passes (\"bombs\") were commonplace in AFL offenses, led by such talented quarterbacks as John Hadl, Daryle Lamonica and Len Dawson.\n\nDespite having a national television contract, the AFL often found itself trying to gain a foothold, only to come up against roadblocks. For example, CBS-TV, which broadcast NFL games, ignored and did not report scores from the innovative AFL, on orders from the NFL. It was only after the merger agreement was announced that CBS began to give AFL scores.\n\nThe AFL took advantage of the burgeoning popularity of football by locating teams in major cities that lacked NFL franchises. Hunt's vision not only brought a new professional football league to California and New York, but introduced the sport to Colorado, restored it to Texas and later to fast-growing Florida, as well as bringing it to New England for the first time in 12 years. Buffalo, having lost its original NFL franchise in 1929 and turned down by the NFL at least twice (1940 and 1950) for a replacement, returned to the NFL with the merger. The return of football to Kansas City was the first time that city had seen professional football since the NFL's Kansas City Blues/Cowboys of the 1920s; the arrival of the Chiefs, and the contemporary arrival of the St. Louis Football Cardinals, brought professional football back to Missouri for the first time since the temporary St. Louis Gunners of 1934.\n\nIf not for the AFL, at least 17 of today's NFL teams would probably never have existed: the ten teams from the AFL, and seven clubs that were instigated by the AFL's presence to some degree. Three NFL franchises were awarded as a direct result of the AFL's competition with the older league: the Minnesota Vikings, who were awarded to Max Winter in exchange for dropping his bid to join the AFL; the Atlanta Falcons, whose franchise went to Rankin Smith to dissuade him from purchasing the AFL's Miami Dolphins; and the New Orleans Saints, because of successful anti-trust legislation which let the two leagues merge, and was supported by several Louisiana politicians.\n\nIn the case of the Dallas Cowboys, the NFL had long sought to return to the Dallas area after the Dallas Texans folded in 1952, but was originally met with strong opposition by Washington Redskins owner George Preston Marshall, who had enjoyed a monopoly as the only NFL team to represent the American South. Marshall later changed his position after future-Cowboys owner Clint Murchison bought the rights to Washington's fight song \"Hail to the Redskins\" and threatened to prevent Marshall from playing it at games. By then, the NFL wanted to quickly award the new Dallas franchise to Murchison so the team could immediately begin play and complete with the AFL's Texans. As a result, the Cowboys played its inaugural season in 1960 without the benefit of the NFL draft.\n\nAs part of the merger agreement, additional expansion teams would be awarded by 1970 or soon thereafter to bring the league to 28 franchises; this requirement was fulfilled when the Seattle Seahawks and the Tampa Bay Buccaneers began play in 1976. In addition, had it not been for the existence of the Oilers from 1960 to 1996, the Houston Texans also would likely not exist today; the 2002 expansion team restored professional football in Houston after the original charter AFL member Oilers relocated to become the Tennessee Titans.\n\nKevin Sherrington of \"The Dallas Morning News\" has argued that the presence of AFL and the subsequent merger radically altered the fortunes of the Pittsburgh Steelers, saving the team \"from stinking\". Before the merger, the Steelers had long been one of the NFL's worst teams. Constantly lacking the money to build a quality team, the Steelers had only posted eight winning seasons, and just one playoff appearance, since their first year of existence in 1933. They also finished with a 1-13 record in 1969, tied with the Chicago Bears for the worst record in the NFL. The $3 million indemnity that the Steelers received for joining the AFC with the rest of the former AFL teams after the merger helped them rebuild into a contender, drafting eventual-Pro Football Hall of Famers like Terry Bradshaw and Joe Greene, and ultimately winning four Super Bowls in the 1970s. Since the 1970 merger, the Steelers have the NFL's highest winning percentage, the most total victories, the most trips to either conference championship game, are tied for the second most trips to the Super Bowl (with the Dallas Cowboys and Denver Broncos, trailing only the New England Patriots), and have won an NFL-record six Super Bowl championships.\n\nPerhaps the greatest social legacy of the AFL was the domino effect of its policy of being more liberal than the entrenched NFL in offering opportunity for black players. While the NFL was still emerging from thirty years of segregation influenced by Washington Redskins' owner George Preston Marshall, the AFL actively recruited from small and predominantly black colleges. The AFL's color-blindness led not only to the explosion of black talent on the field, but to the eventual entry of blacks into scouting, coordinating, and ultimately head coaching positions, long after the league ceased to exist.\n\nThe AFL's free agents came from several sources. Some were players who could not find success playing in the NFL, while another source was the Canadian Football League. In the late 1950s, many players released by the NFL, or un-drafted and unsigned out of college by the NFL, went North to try their luck with the CFL, and later returned to the states to play in the AFL.\n\nIn the league's first years, players such as Oilers' George Blanda, Chargers/Bills' Jack Kemp, Texans' Len Dawson, the NY Titans' Don Maynard, Raiders/Patriots/Jets' Babe Parilli, Pats' Bob Dee proved to be AFL standouts. Other players such as the Broncos' Frank Tripucka, the Pats' Gino Cappelletti, the Bills' Cookie Gilchrist and the Chargers' Tobin Rote, Sam DeLuca and Dave Kocourek also made their mark to give the fledgling league badly needed credibility. Rounding out this mix of potential talent were the true \"free agents\", the walk-ons and the \"wanna-be's\", who tried out in droves for the chance to play professional American football.\n\nAfter the AFL–NFL merger agreement in 1966, and after the AFL's Jets defeated the \"best team in the history of the NFL\", the Colts, a popular misconception fostered by the NFL and spread by media reports was that the AFL defeated the NFL because of the Common Draft instituted in 1967. This apparently was meant to assert that the AFL could not achieve parity as long as it had to compete with the NFL in the draft. But the 1968 Jets had less than a handful of \"common draftees\". Their stars were honed in the AFL, many of them since the Titans days. As noted below, the AFL got its share of stars long before the \"common draft\".\n\nPlayers who chose the AFL to develop their talent included Lance Alworth and Ron Mix of the Chargers, who had also been drafted by the NFL's San Francisco 49ers and Baltimore Colts respectively. Both eventually were elected to the Pro Football Hall of Fame after earning recognition during their careers as being among the best at their positions. Among specific teams, the 1964 Buffalo Bills stood out by holding their opponents to a pro football record 913 yards rushing on 300 attempts, while also recording fifty quarterback sacks in a 14-game schedule.\n\nAnother example is cited by the University of Kansas website, which describes the 1961 Bluebonnet Bowl, won by KU, and goes on to say \"\"Two Kansas players, quarterback John Hadl and fullback Curtis McClinton, signed professional contracts on the field immediately after the conclusion of the game. Hadl inked a deal with the \"[AFL]\" San Diego Chargers, and McClinton went to the \"[AFL]\" Dallas Texans.\"\" Between them, in their careers Hadl and McClinton combined for an American Football League Rookie of the Year award, seven AFL All-Star selections, two Pro Bowl selections, a team MVP award, two AFL All-Star Game MVP awards, two AFL championships, and a World Championship. And these were players selected by the AFL long \"before\" the \"Common Draft\".\n\nIn 2009, a five-part series, \"\", on the \"Showtime Network\", refuted many of the long-held misconceptions about the AFL. In it, Abner Haynes tells of how his father forbade him to accept being drafted by the NFL, after drunken scouts from that league had visited the Haynes home; the NFL Cowboys' Tex Schramm is quoted as saying that if his team had ever agreed to play the AFL's Dallas Texans, they would very likely have lost; George Blanda makes a case for more AFL players being inducted to the Pro Football Hall of Fame by pointing out that Hall of Famer Willie Brown was cut by the Houston Oilers because he couldn't cover Oilers flanker Charlie Hennigan in practice. Later, when Brown was with the Broncos, Hennigan needed nine catches in one game against the Broncos to break Lionel Taylor's Professional Football record of 100 catches in one season. Hennigan caught the nine passes and broke the record, even though he was covered by Brown, Blanda's point being that if Hennigan could do so well against a Hall of Fame DB, he deserves induction, as well.\n\nThe AFL also spawned coaches whose style and techniques have profoundly affected the play of professional football to this day. In addition to AFL greats like Hank Stram, Lou Saban, Sid Gillman and Al Davis were eventual hall of fame coaches such as Bill Walsh, a protégé of Davis with the AFL Oakland Raiders for one season; and Chuck Noll, who worked for Gillman and the AFL LA/San Diego Chargers from 1960 through 1965. Others include Buddy Ryan (AFL's New York Jets), Chuck Knox (Jets), Walt Michaels (Jets), and John Madden (AFL's Oakland Raiders). Additionally, many prominent coaches began their pro football careers as players in the AFL, including Sam Wyche (Cincinnati Bengals), Marty Schottenheimer (Buffalo Bills), Wayne Fontes (Jets), and two-time Super Bowl winner Tom Flores (Oakland Raiders). Flores also has a Super Bowl ring as a player (1969 Kansas City Chiefs).\n\nAs the influence of the AFL continues through the present, the 50th anniversary of its launch was celebrated during 2009. The season-long celebration began in August with the 2009 Pro Football Hall of Fame Game in Canton, Ohio between two AFC teams (as opposed to the AFC-vs-NFC format the game first adopted in 1971). The opponents were two of the original AFL franchises, the Buffalo Bills and Tennessee Titans (the former Houston Oilers). Bills' owner Ralph C. Wilson Jr. (a 2009 Hall of Fame inductee) and Titans' owner Bud Adams were the only surviving members of the Foolish Club, the eight original owners of AFL franchises.\n\nThe Hall of Fame Game was the first of several \"Legacy Weekends\", during which each of the \"original eight\" AFL teams sported uniforms from their AFL era. Each of the 8 teams took part in at least two such \"legacy\" games. On-field officials also wore red-and-white-striped AFL uniforms during these games.\n\nIn the fall of 2009, the Showtime pay-cable network premiered \"\", a 5-part documentary series produced by NFL Films that features vintage game film and interviews as well as more recent interviews with those associated with the AFL.\n\nThe NFL sanctioned a variety of \"\"Legacy\"\" gear to celebrate the AFL anniversary, such as \"throwback\" jerseys, T-shirts, signs, pennants and banners, including items with the logos and colors of the Dallas Texans, Houston Oilers, and New York Titans, the three of the Original Eight AFL teams which have changed names or venues. A December 5, 2009 story by Ken Belson in the \"New York Times\" quotes league officials as stating that AFL \"\"Legacy\"\" gear made up twenty to thirty percent of the league's annual $3 billion merchandise income. Fan favorites were the Denver Broncos' vertically striped socks, which could not be re-stocked quickly enough.\n\nToday, two of the NFL's eight divisions are composed entirely of former AFL teams, the AFC West (Broncos, Chargers, Chiefs, and Raiders) and the AFC East (Bills, Dolphins, Jets, and Patriots). Additionally, the Bengals now play in the AFC North and the Tennessee Titans (formerly the Oilers) play in the AFC South.\n\nFrom 1960 to 1968, the AFL determined its champion via a single-elimination playoff game between the winners of its two divisions. The home teams alternated each year by division, so in 1968 the Jets hosted the Raiders, even though Oakland had a better record (this was changed in 1969). In 1963, the Buffalo Bills and Boston Patriots finished tied with identical records of 7–6–1 in the AFL East Division. There was no tie-breaker protocol in place, so a one-game playoff was held in War Memorial Stadium in December. The visiting Patriots defeated the host Bills 26–8. The Patriots traveled to San Diego as the Chargers completed a three-game season sweep over the weary Patriots with a 51–10 victory. A similar situation occurred in the 1968 season, when the Oakland Raiders and the Kansas City Chiefs finished the regular season tied with identical records of 12–2 in the AFL West Division. The Raiders beat the Chiefs 41–6 in a division playoff to qualify for the AFL Championship Game. In 1969, the final year of the independent AFL, Professional Football's first \"wild card\" playoffs were conducted. A four-team playoff was held, with the second-place teams in each division playing the winner of the other division. The Chiefs upset the Raiders in Oakland 17–7 in the league's Championship, the final AFL game played. The Kansas City Chiefs were the first Super Bowl champion to win two road playoff games and the first wildcard team to win the Super Bowl, although the term \"wildcard\" was coined by the media, and not used officially until several years later.\n\n\"Italics\" – Super Bowl Appearance, Bold – Super Bowl Victory\n\nThe AFL did not play an All-Star game after its first season in 1960, but did stage All-Star games for the 1961 through 1969 seasons. All-Star teams from the Eastern and Western divisions played each other after every season except 1965. That season, the league champion Buffalo Bills played all-stars from the other teams.\n\nAfter the 1964 season, the AFL All-Star game had been scheduled for early 1965 in New Orleans' Tulane Stadium. After numerous black players were refused service by a number of area hotels and businesses, black and white players alike called for a boycott. Led by Bills players such as Cookie Gilchrist, the players successfully lobbied to have the game moved to Houston's Jeppesen Stadium.\n\nAs chosen by 1969 AFL Hall of Fame Selection Committee Members:\n\nThe following is a sample of some records set during the existence of the league. The NFL considers AFL statistics and records equivalent to its own.\n\n\n\n\n\n"}
{"id": "2358", "url": "https://en.wikipedia.org/wiki?curid=2358", "title": "A.S. Roma", "text": "A.S. Roma\n\nAssociazione Sportiva Roma (, ; \"Rome Sport Association\"), commonly referred to as simply Roma , is a professional Italian football club based in Rome. Founded by a merger in 1927, Roma have participated in the top-tier of Italian football for all of their existence except for 1951–52.\n\nRoma have won Serie A three times, in 1941–42, 1982–83 and 2000–01, as well as winning nine Coppa Italia titles and two Supercoppa Italiana titles. In european competitions Roma won the Inter-Cities Fairs Cup in 1960–61, and were runners-up in the 1983–84 European Cup and the 1990–91 UEFA Cup.\n\nSince 1953 Roma have played their home games at the Stadio Olimpico, a venue they share with city rivals Lazio. With a capacity of over 72,000, it is the second largest of its kind in Italy, with only the San Siro able to seat more. The club plan to move to a new stadium, though this is yet to start construction.\n\nThe club's home colours are Tyrian purple and gold, which gives Roma their nickname \"I Giallorossi\" (The Yellow and Reds). Their club badge features a she-wolf, an allusion to the founding myth of Rome.\n\nA.S. Roma was founded in the summer of 1927 when Italo Foschi, initiated the merger of three older Italian Football Championship clubs from the city of Rome; Roman FC, SS Alba-Audace and Fortitudo-Pro Roma SGS. The purpose of the merger was to give the Italian capital a strong club to rival that of the more dominant Northern Italian clubs of the time. The only major Roman club to resist the merger was S.S. Lazio because of the intervention of the army General Vaccaro, member of the club and executive of Italian Football Federation.\nThe club played its earliest seasons at the \"Motovelodromo Appio\" stadium, before settling in the working-class streets of Testaccio, where it built an all-wooden ground \"Campo Testaccio\"; this was opened in November 1929. An early season in which Roma made a large mark was the 1930–31 championship, the club finished as runners-up behind Juventus. Captain Attilio Ferraris along with Guido Masetti, Fulvio Bernardini and Rodolfo Volk were highly important players during this period.\n\nAfter a slump in league form and the departure of high key players, Roma eventually rebuilt their squad adding goalscorers such as the Argentine Enrique Guaita. Under the management of Luigi Barbesino, the Roman club came close to their first title in 1935–36; finishing just one point behind champions Bologna.\n\nRoma returned to form after being inconsistent for much of the late 1930s; Roma recorded an unexpected title triumph in the 1941–42 season by winning their first ever\" scudetto\" title. The eighteen goals scored by local player Amedeo Amadei were essential to the Alfréd Schaffer coached Roma side winning the title. At the time Italy was involved in World War II and Roma were playing at the \"Stadio del Partito Nazionale Fascista\".\n\nIn the years just after the war, Roma were unable to recapture their league stature from the early 1940s. Roma finished in the lower half of Serie A for five seasons in a row, before eventually succumbing to their only ever relegation to Serie B at the end of the 1950–51 season; around a decade after their championship victory. Under future national team manager Giuseppe Viani, promotion straight back up was achieved.\n\nAfter returning to the Serie A, Roma managed to stabilise themselves as a top half club again with players such as Egisto Pandolfini, Dino Da Costa and Dane Helge Bronée. Their best finish of this period was under the management of Englishman Jesse Carver, when in 1954–55 they finished as runners-up, after Udinese who originally finished second were relegated for corruption.\nAlthough Roma were unable to break into the top four during the following decade, they did achieve some measure of cup success. Their first honour outside of Italy was recorded in 1960–61 when Roma won the Inter-Cities Fairs Cup by beating Birmingham City 4–2 in the finals. A few years later Roma won their first Coppa Italia trophy in 1963–64, by beating Torino 1–0.\n\nTheir lowest point came during the 1964–65 season when manager Juan Carlos Lorenzo announced that the club could not pay its players and was unlikely to be able to afford to travel to Vicenza to fulfil its next fixture. Supporters kept the club going with a fundraiser at the Sistine Theatre and bankruptcy was avoided with the election of a new club president Franco Evangelisti.\n\nTheir second Coppa Italia trophy was won in 1968–69 when it competed in a small league like system. Giacomo Losi set a Roma appearance record during 1969 with 450 appearances in all competitions, the record he set would last for 38 years.\n\nRoma were able to add another cup to their collection in 1972, with a 3–1 victory over Blackpool in the Anglo-Italian Cup. During much of the 1970s Roma's appearance in the top half of Serie A was sporadic. The best place the club were able to achieve during the decade was third in 1974–75. Notable players who turned out for the club during this period included midfielders Giancarlo De Sisti and Francesco Rocca.\n\nThe dawning of a newly successful era in Roma's footballing history was brought in with another Coppa Italia victory, they beat Torino on penalties to win the 1979–80 cup. Roma would reach heights in the league which they had not touched since the 1940s by narrowly and controversially finishing as runners-up to Juventus in 1980–81. Former Milan player Nils Liedholm was the manager at the time, with players such as Bruno Conti, Agostino Di Bartolomei, Roberto Pruzzo and Falcão.\nThe second \"scudetto\" did not elude Roma for much longer; in 1982–83 the Roman club won the title for the first time in 41 years, amidst celebrations in the capital. The following season Roma finished as runners-up in Italy and collected a Coppa Italia title, they also finished as runners-up in the European Cup final of 1984. The European Cup final with Liverpool ended in a 1–1 draw with a goal from Pruzzo, but Roma eventually lost the penalty shoot-out. Roma's successful run in the 1980s would finish with a runners-up spot in 1985–86 and a Coppa Italia victory, beating out Sampdoria 3–2.\n\nAfter that a comparative decline began in the league, one of the few league highs from the following period being a third-place finish in 1987–88. At the start of the 1990s the club was involved in an all-Italian UEFA Cup final, where they lost 2–1 to Internazionale in 1991; the same season the club won its seventh Coppa Italia trophy and ended runners-up to Sampdoria in the Supercoppa Italiana. Aside from finishing runners-up to Torino in a Coppa Italia final, the rest of the decade was largely sub-par in the history of Roma; especially in the league where the highest they could manage was fourth in 1997–98. The early 1990s also saw the emergence of homegrown striker Francesco Totti who would go on to be an important member of the team and the club's iconic captain.\n\nRoma returned to form in the 2000s, starting the decade in great style by winning their third ever Serie A title in 2000–01; the \"scudetto\" was won on the last day of the season by beating Parma 3–1, edging out Juventus by two points. The club's captain, Francesco Totti was a large reason for the title victory and he would become one of the main heroes in the club's history, going on to break several club records. Other important players during this period included Aldair, Cafu, Gabriel Batistuta, and Vincenzo Montella.\n\nThe club attempted to defend the title in the following season but ended as runners-up to Juventus by just one point. This would be the start of Roma finishing as runners-up many times in both Serie A and Coppa Italia during the 2000s; they lost out 4–2 to AC Milan in the Coppa Italia final of 2003 and lost out to Milan again by finishing second in Serie A for the 2003–04 season. The club also re-capitalized several time in 2003–04 season. In November 2003 €37.5 million was injected by \"Roma 2000\" to cover the half-year loss and loss carried from previous year. and again on 30 June for €44.57 million. Through stock market, a further €19.850 million of new shares issued, and at the year end, the share capital was €19.878 million, which unchanged . The following season also saw the departure of Walter Samuel for €25 million and Emerson for €28 million, which decreased the strength of the squad, thus \"Giallorossi\" finished as the eighth place, one of the worst of recent season.\n\nOn 9 July 2006, Roma's Francesco Totti, Daniele De Rossi and Simone Perrotta were part of the Italy team that beat France in the 2006 FIFA World Cup final. A Serie A scandal was revealed during 2006 and Roma were one of the teams not involved; after punishments were handed out, Roma was re-classified as runners-up for 2005–06; the same season in which they finished second in the Coppa Italia losing to Internazionale. In the two following seasons, 2006–07 and 2007–08, Roma finished as Serie A runners-up, meaning that in the 2000s Roma have finished in the top two positions more than any other decade in their history Meanwhile, in the UEFA Champions League during both of these seasons, they reached the quarter-finals before going out to Manchester United. Despite the sloppy start in the 2008–09 Champions League, Roma managed to reach the knockout stage ahead of Chelsea in their group, thus finishing for the first time in their history as winners of the group stage. The \"Giallorossi\", however, would lose to Arsenal in the knockout stage on penalty kicks, ending their Champions League campaign.\n\nAfter a disappointing start to the 2009–10 season, Claudio Ranieri replaced Luciano Spalletti as head coach. At the time of the switch, Roma lay bottom of the Serie A table after losses to Juventus and Genoa. Despite this setback, Roma would later embark on an incredible unbeaten streak of 24 matches in the league – with the last of the 24 being a 2–1 win over rivals Lazio, whereby Roma came from 1–0 down at half-time to defeat their city rivals after Ranieri courageously substituted both Totti and De Rossi at the interval. The Giallorossi were on top of the table at one point, before a loss to U.C. Sampdoria later in the season. Roma would finish runners-up to Inter yet again in both Serie A and the Coppa Italia. This rounded out a highly successful decade in Roma's history, following somewhat mediocre results of the 1990s. During the 2000s, Roma had finally recaptured the \"Scudetto\", two Coppa Italia trophies, and their first two Supercoppa Italiana titles. Other notable contributions to the club's history have included a return to the Champions League quarter-finals (in the 2006–07 and 2007–08 editions) since 1984, six runners up positions in the league, four Coppa Italia finals and three Supercoppa finals – marking Roma's greatest ever decade.\n\nIn the summer of 2010, the Sensi family agreed to relinquish their control of Roma as part of a debt-settlement agreement. This brought an end to the presidential reign of the Sensi family, who had presided over the club since 1993. Until a new owner was appointed, Rosella Sensi would continue her directorial role of the club. The 2010–11 season had once again seen Roma start off with mixed fortunes on both a domestic and European level. These included losses against teams like Cagliari, Brescia and a 2–0 defeat against Bayern Munich in the group stages of the Champions League, a match which saw manager Claudio Ranieri openly criticised by his players. However, these were accompanied by victories against Inter and a sensational victory against Bayern in the return fixture, which saw Roma fight back from 0–2 down at half-time to emerge as 3–2 winners. Following a series of poor results which saw Roma engage in a winless-streak of five consecutive matches, Ranieri resigned as head coach in February 2011, and former striker Vincenzo Montella was appointed as caretaker manager until the end of the season. It was also during this season that Roma icon Francesco Totti scored his 200th Serie A goal against Fiorentina in March 2011 – becoming only the sixth ever player to achieve such a feat.\n\nOn 16 April 2011, the takeover contract was closed with an American investment group led by Thomas R. DiBenedetto, with James Pallotta, Michael Ruane and Richard D'Amore as partners. DiBenedetto became the 22nd president of the club, serving from 27 September 2011 to 27 August 2012 and was succeeded by Pallotta. The new intermediate holding company, NEEP Roma Holding, was 60% owned by American's \"AS Roma SPV, LLC\" and the rest (40%) was retained by the creditor of Sensi, UniCredit; NEEP in turn owned all shares held previously by Sensi (about 67%) with the rest free float in the stock market. UniCredit later disinvested NEEP Roma Holding to sold to \"AS Roma SPV, LLC\" and Pallotta.\n\nThe new ownership immediately went into effect by making significant changes in the club, hiring Walter Sabatini as director of football and former Spanish international and Barcelona B coach Luis Enrique as manager. The first high-profile player signings from the duo were attacking midfielder Érik Lamela from River Plate, forward Bojan from Barcelona, goalkeeper Maarten Stekelenburg from Ajax and unattached defender Gabriel Heinze. The club also sold and released defender John Arne Riise, goalkeeper Doni and forwards Jérémy Ménez and Mirko Vučinić. At the financial level, the company had recapitalized for more than €100 million, the last recapitalization occurring in the early 2000s.\n\nRoma, however, was eliminated from 2011–12 UEFA Europa League play-off round. After the formal takeover on 18 August, Roma bought forward Dani Osvaldo, midfielders Miralem Pjanić and Fernando Gago and defender Simon Kjær, as well as youngster Fabio Borini, which cost the club more than €40 million. In 2012, Pallotta became the new president.\n\nThe 2012-13 pre-season started with the June hiring of former manager Zdeněk Zeman. Zeman replaced Luis Enrique who resigned at the end of the 2011–12 season. Enrique's lone season reign had seen the disappointing loss to Slovan Bratislava in the Europa League as well as the inability to qualify for international competitions for the 2012–13 season. Roma eventually finished 7th, losing the Europa League chase to rivals Lazio, Napoli and Internazionale. Zeman brought back his high-scoring 4–3–3 formation and his hard working ethic which successfully guided former team Pescara to the Serie A. He was, however, sacked on 2 February 2013. He was replaced by caretaker manager Aurelio Andreazzoli, who's reign saw the continuation of a disappointing season, with the team ending up in 6th place in Serie A, whilst also losing 1–0 to rivals Lazio in the Coppa Italia final. As a result, Roma missed out on European competition for the second season in a row. \n\nOn 12 June 2013, Pallotta announced that Rudi García had been appointed the new manager of Roma. He enjoyed a fantastic start to his Roma career, winning his first ten consecutive games (an all-time Serie A record) including a 2–0 derby win against Lazio, a 0–3 victory away to Inter and a 2–0 home win over title rivals Napoli. During this run, Roma scored 24 times while conceding just once, away to Parma. The 2013–14 season saw one of Roma's best ever in Serie A, the club tallying an impressive 85 points and finishing second to Juventus, who won the league with a record-breaking 102 points. Roma's defense was significantly better than in previous seasons, with only 25 goals conceded and a total of 21 clean sheets, including nine in their first ten matches.\n\nIn 2014-15, Roma finished second behind Juventus for the second consecutive season after a poor run of form in 2015. At the end of season the club was sanctioned for lose making and breaking UEFA Financial Fair Play Regulations.\n\nOn 13 January 2016, Garcia was sacked after a run of one win in seven Serie A games. Luciano Spalletti was appointed manager of Roma for his second spell. On 21 February, Totti publicly criticised Spalletti due to his own lack of playing-time since returning from injury; as a result, he was subsequently dropped by Spalletti for Roma's 5–0 win over Palermo, with the decision causing an uproar among the fans and in the media. After their initial disagreements, Spalletti began to use Totti as an immediate impact substitute, which proved to be an effective decision, as the Roma number 10 rediscovered his form, and contributed with four goals and an assist after coming off the bench in five consecutive Serie A games; as a result, Spalletti was able to lead Roma from a mid-table spot to a third-place finish in Serie A, clinching the UEFA Champions League play-off spot.\n\nDuring summer 2016 Roma lost star midfielder Miralem Pjanić to rivals Juventus in order to improve its financial position.\n\nOn 13 June 2017, Eusebio Di Francesco was appointed as Roma manager, replacing Spalletti, who left for Inter.\n\nRoma's colours of imperial purple with a golden yellow trim represents the traditional colours of Rome, the official seal of the \"Comune di Roma\" features the same colours. The gold and the purple-red represent Roman imperial dignity. White shorts and black socks are usually worn with the red shirt, however in particularly high key games the shorts and socks are the same colour as the home shirt.\n\nThe kit itself was originally worn by \"Roman Football Club\"; one of the three clubs who merged to form the current incarnation in 1927. Because of the colours they wear, Roma are often nicknamed \"i giallorossi\" meaning the yellow-reds. Roma's away kit is traditionally white, with a third kit changing colour from time to time. \n\nA popular nickname for the club is \"i lupi\" (the wolves), the animal has always featured on the club's badge in different forms throughout their history. Currently the emblem of the team is the one which was used when the club was first founded. It portrays the female wolf with the two infant brothers Romulus and Remus, illustrating the myth of the founding of Rome, superimposed on a bipartite golden yellow over maroon red shield. In the myth from which the club take their nickname and logo, the twins (sons of Mars and Rhea Silvia) are thrown into the River Tiber by their uncle Amulius, a she-wolf saved the twins and looked after them. Eventually the two twins took revenge on Amulius, before falling out themselves; Romulus killed Remus and as thus was made king of a new city named in his honour, Rome.\n\nThe very first sport facility A.S. Roma used was Motovelodromo Appio which was previously used by Alba-Audace. A.S. Roma only played the 1927–28 season there until they moved to Campo Testaccio the very next season. Campo Testaccio was used through 1929 to 1940. The team moved later to the Stadio Nazionale del PNF where they spent 13 years before moving once again.\n\nIn the 1953–54 season A.S. Roma moved to the Olympic arena, Stadio Olimpico, which it shares with Lazio. The arena has undergone several changes over the years. The most significant change took place in the nineties when Stadio Olimpico was demolished and then reconstructed to for the Football World Cup 1990, witch took place in Italy. A.S. Roma has played almost every season since 1953–54, with exception of the 1989–90 seasons due to the reconstruction of Stadio Olimpico. That year Roma played its home games at Stadio Flaminio.\n\nOn 30 December 2012, AS Roma president James Pallotta announced the construction of a new stadium in the Tor di Valle area of Rome. The new stadium, Stadio della Roma will have a capacity of 52,500 spectators. On 2 February 2017, the Region of Lazio and the mayor of Rome rejected the proposal to build a new stadium, however, was later approved on 24 February after final review of the stadium's design adjustments. In August 2017, the stadium hit another delay, forcing Roma to renew their lease with the Stadio Olimpico until 2020. It is still uncertain how long it will take to open the stadium.\n\n\nA sports centre located in at kilometer 3600 in south-east of Rome was purchased on 22 July 1977 by the then club president Gaetano Anzalone. It was opened on 23 July 1979 as Anzalone's final act as president. The complex had its first expansion in 1984 when the club was handled by Dino Viola and another in 1998 under the chairmanship of Franco Sensi. The sports centre official name is Fulvio Bernardini di Trigoria, named after the club icon Fulvio Bernardini.\n\nThe sports centre is also known for hosting the Argentinian football team during the 1990 FIFA World Cup.\n\nRoma is the fifth-most supported football club in Italy, behind Juventus, Internazionale, Milan and Napoli, with around 7% of Italian football fans supporting the club (according to the Doxa Institute-L'Espresso's research of April 2006). Historically, the largest section of Roma supporters in the city of Rome have come from the inner-city, especially Testaccio.\n\nThe traditional ultras group of the club was \"Commando Ultrà Curva Sud\" commonly abbreviated as \"CUCS\". This group was founded by the merger of many smaller groups and was considered one of the most historic in the history of European football. By the mid-1990s, however, \"CUCS\" had been usurped by rival factions and ultimately broke up. Since that time, the \"Curva Sud\" of the Stadio Olimpico has been controlled by more right-wing groups, including \"A.S. Roma Ultras\", \"Boys\", \"Giovinezza\" and others. The oldest group, \"Fedayn\", is apolitical, however, and politics is not the main identity of Roma, just a part of their overall identity. Besides ultras groups, it is believed that Roma fans support the left as opposed to Lazio supporters, that are notoriously proud of their right-wing affiliation. In September 2009, the club unveiled plans to build a new 55,000-capacity stadium in Rome's western suburbs.\n\nIn November 2015, Roma's ultras and their Lazio counterparts boycotted Roma's 1-0 victory in the Derby della Capitale in protest at new safety measures imposed at the Stadio Olimpico. The measures, imposed by Rome’s prefect, Franco Gabrielli, had involved plastic glass dividing walls being installed in both the Curva Sud and Curva Nord, splitting the sections behind each goal in two. Both sets of ultras continued their protests for the rest of the season, including during Roma's 4-1 victory in the return fixture. Lazio's ultras returned to the Curva Nord for Roma's 1-4 victory in December 2016, but the Roma ultras continue to boycott games.\nThe most known club anthem is \"Roma (non-si discute, si ama)\", also known as \"Roma Roma\", by singer Antonello Venditti. The title roughly means, \"Roma is not to be questioned, it is to be loved,\" and it is sung before each match. The song \"Grazie Roma\", by the same singer, is played at the end of victorious home games. Recently, the main riff of The White Stripes' song \"Seven Nation Army\" has also become widely popular at games.\n\nIn Italian football, Roma is a club with many rivalries; first and foremost is their rivalry with Lazio, the club with whom they share the Stadio Olimpico. The derby between the two is called the \"Derby della Capitale\", it is amongst the most heated and emotional footballing rivalries in the world. The fixture has seen some occasional instances of violence in the past, including the death of Lazio fan Vincenzo Paparelli in 1979–80 as a result of an emergency flare fired from the Curva Sud, and the abandonment of a game in March 2004, following unfounded rumours of a fatality which led to violence outside the stadium.\n\nWith Napoli, Roma also compete in the \"Derby del Sole\", rivalry meaning the \"Derby of the Sun\". Nowadays, fans also consider other Serie A giants like Juventus (rivalry born especially in the 1980s), Milan and Inter (increased in recent years) among their rivals, as these four compete for the top three spots in the league table to secure a spot in the Champions League.\n\nThere have been a number of instances of conflict in recent years between some Roma supporters and fans of English clubs, and the subsequent violence outside the stadium which saw a number of Liverpool fans stabbed. Since then, there have been further instances of some English supporters being attacked and stabbed in Rome, including incidents in 2001 when Liverpool visited Roma twice and subsequent clashes with Middlesbrough fans in 2006 and Manchester United fans in 2007. In March 2009, a coach carrying Arsenal supporters was attacked by a group of Roma ultras just outside the Stadio Olimpico. The coach's windows were smashed and at least one person entered the vehicle, letting off a flare and stabbed a supporter in the knee.\n\nRoma have had numerous chairmen over the course of their history, some of which have been the owners of the club, others have been honorary chairmen. Franco Sensi was the chairman until his death in 2008, with his daughter Rosella Sensi in place as honorary chairmen. Here is a complete list of Roma chairmen from 1927 until the present day.\nRoma have had many managers and trainers running the team during their history, here is a chronological list of them from 1927 onwards.\nSerie A\n\nCoppa Italia\n\nSupercoppa Italiana\n\nSerie B\n\nInter-Cities Fairs Cup\n\nOn 7 October 2012, the Hall of Fame of Roma was announced.\nThe Hall of Fame players was voted via the club's official website and a special Hall of Fame panel. In 2013 four players was voted in as well as in 2014, the third year of AS Roma Hall of Fame four more players was voted in.\n\nAdded in 2012:\n\nAdded in 2013:\n\nAdded in 2014:\n\nAdded in 2015:\n\nAdded in 2016:\nFrancesco Totti holds Roma's official appearance record, having made 785 (as of 20 May 2017) appearances in all competitions, over the course of 25 seasons from 1993 until the present day. He also holds the record for Serie A appearances with 618, as he passed Giacomo Losi on 1 March 2008 during a home match against Parma.\n\nIncluding all competitions, Totti is the all-time leading goalscorer for Roma with 307 goals since joining the club, 250 of which were scored in Serie A (another Roma record). Roberto Pruzzo, who was the all-time topscorer since 1988, comes in second in all competitions with 138. In the 1930–31 season, Rodolfo Volk scored 29 goals in Serie A over the course of a single season; not only was he the league's top scorer that year, but he set a Roma record for most goals scored in a season which was later equalled by Edin Džeko in the 2016-17 season.\n\nIts major founders Fortitudo and Alba having been relegated at the end of 1926–27 campaign, new-founded Roma had to take part to Southern First Division championship (Serie B) for its inaugural season; nevertheless the FIGC decided a special enlargement of first level division re-admitting AS Roma as SSC Napoli. The first ever official game participated in by Roma was in the National Division, the predecessor of Serie A, of 1927–28, against Livorno; Roma won 2–0. The biggest ever victory recorded by Roma was 9–0 against Cremonese during the Serie A season of 1929–30. The heaviest defeat Roma have ever suffered is 7–1, which has occurred three times, first against Juventus during 1931–32, then against Torino in 1947–48 and most recently against Manchester United in 2006–07.\n\nSince 1999, during Franco Sensi's period in charge, Associazione Sportiva Roma has been a listed Società per azioni on Borsa Italiana. From 2004 to 2011, Roma's shares are distributed between; 67.1% to Compagnia Italpetroli SpA (the Sensi family \"holding\"; Banca di Roma later acquired 49% stake on Italpetroli due to debt restructuring) and 32.9% to other public shareholders.\n\nAlong with Lazio and Juventus, Roma is one of only three quotated Italian clubs. According to The Football Money League published by consultants Deloitte, in the 2010–11 season, Roma was the 15th highest-earning football club in the world with an estimated revenue of €143.5 million.\n\nIn April 2008, after months of speculation, George Soros was confirmed by Rosella Sensi, CEO of Italian Serie A association football club A.S. Roma, to be bidding for a takeover. The takeover bid was successively rejected by the Sensi family, who instead preferred to maintain the club's ownership. On 17 August 2008 club chairman and owner Franco Sensi died after a long illness; his place at the chairmanship of the club was successively taken by his daughter Rosella.\n\nSince the takeover in 2011, NEEP Roma Holding S.p.A. owned all shares Sensi previously hold. NEEP, itself a joint venture, was held by DiBenedetto AS Roma LLC (later renamed to AS Roma SPV, LLC) and Unicredit in 60–40 ratio from 2011 to 2013, which the former had four real person shareholders in equal ratio, led by future Roma president Thomas R. DiBenedetto (2011–12). The takeover also activated a mandatory bid of shares from the general public, however not all minority shareholders willing to sell their shares. The mandatory bid had made NEEP held 78.038% of shares of AS Roma (increased from 67.1% of the Sensi). On 1 August 2013, the president of Roma as well as one of the four American shareholder of AS Roma SPV, LLC, James Pallotta, bought an additional 9% shares of NEEP Roma Holding from Unicredit (through Raptor Holdco LLC), as the bank not willing to fully participate in the capital increase of NEEP from €120,000 to €160,008,905 (excluding share premium). On 4 April 2014 Starwood Capital Group also became the fifth shareholder of AS Roma SPV, as well as forming strategic partnership with AS Roma SpA to develop real estate around the new stadium. The private investment firm was represented by Zsolt Kohalmi in AS Roma SPV, whom was appointed on 4 April as a partner and head of European acquisitions of the firm. On 11 August 2014, UniCredit sold the remain shares on NEEP (of 31%) for €33 million which made AS Roma SPV LLC (91%) and Raptor Holdco LLC (9%) were the sole intermediate holding company of AS Roma SpA.\n\nSince re-capitalization in 2003–04, Roma had a short-lived financial self-sustainability, until the takeover in 2011. The club had set up a special amortisation fund using Articolo 18-bis Legge 91/1981 mainly for the abnormal signing prior 2002–03 season, (such as Davide Bombardini for €11 million account value in June 2002, which the flopped player exchange boosted 2001–02 season result) and the tax payment of 2002–03 was rescheduled. In 2004–05, Roma made a net profit of €10,091,689 and followed by €804,285 in 2005–06. In 2006–07 season the accounting method changed to IFRS, which 2005–06 result was reclassified as net loss of €4,051,905 and 2006–07 season was net income of €10,135,539 (€14.011 million as a group). Moreover, the special fund (€80,189,123) was removed from the asset and co-currently for the equity as scheduled, made Roma group had a negative equity of €8.795 million on 30 June 2007. In 2007–08, Roma made a net income of €18,699,219. (€19 million as a group) However, 2008–09 saw the decrease of gate and TV income, co-currently with finished sixth in Serie A, which saw Roma made a net loss of €1,894,330. (€1.56 million as a group) The gate and TV income further slipped in 2009–10 with a net loss of €21,917,292 (already boosted by the sale of Alberto Aquilani; €22 million as a group) despite sporting success (finishing in second place in 2009–10). Moreover, despite a positive equity as a separate company (€105,142,589), the AS Roma Group had a negative equity on the consolidated balance sheet, and fell from +€8.8 million to −€13.2 million. In the 2010–11 season, Roma was administrated by UniCredit as the Sensi family failed to repay the bank and the club was put into the market, which also saw Roma not have a major signing in 2010–11. Concurrently with no selling profit on the player, Roma's net loss rose to €30,589,137 (€30.778 million as a group) and the new owner already planned a re-capitalization after the mandatory bid on the shares. On the positive side, TV income was increased from €75,150,744 to €78,041,642, and gate income increased from €23,821,218 to €31,017,179. This was because Roma entered 2010–11 Champions League, which counter-weighed the effect of the new collective agreement of Serie A. In 2011–12, the renewal of squad and participate in 2011–12 UEFA Europa League had worsened the financial result, which the €50 million capital increase (in advance) was counter-weighted totally by the net loss. In the 2012–13 season, the participation in domestic league only, not only not harmful to the revenue but increase in gate income as well as decrease in wage bill, however Roma still did not yet break even (€40.130 million net loss in consolidated accounts). NEEP Roma also re-capitalized AS Roma in advance for another €26,550,000 during 2012–13. A proposed capital increase by €100 million for Roma was announced on 25 June 2014; however, until 22 May 2014, NEEP already injected €108 million into the club, which depends on public subscription; more than €8 million would convert to medium-long-term loan from shareholder instead of becoming share capital.\n\nOne of the subsidiaries of Roma (joint venture with football clubs Lazio, 37.5% x2 and Parma, 25%), Società Diritti Sportivi S.r.l., was in the process of liquidation since 2005. The company was a joint-venture of four football clubs, including Fiorentina. After the bankruptcy of the old \"Viola\", however, both Roma and Lazio had increased their shares ratio from 25% to 37.5%. Another subsidiary, \"Soccer S.A.S. di Brand Management S.r.l.\", was a special-purpose entity (SPV) that Roma sold their brand to the subsidiary in 2007. In February 2015, another SPV, \"ASR Media and Sponsorship S.r.l\", was set up in order to secure a five-year bank loan of €175 million from Goldman Sachs, for three month Euribor (min. 0.75%) + 6.25% spread (i.e. min. 7% interests rate p.a.).\n\nIn 2015, Inter and Roma were the only two Italian clubs that were sanctioned by UEFA for breaking UEFA Financial Fair Play Regulations.\n\nA.S. Roma had a team in the Superleague Formula race car series where teams were sponsored by football clubs. Roma's driver was ex-IndyCar Series driver Franck Perera. The team had posted three podiums and was operated by Alan Docking Racing.\n\n\n"}
{"id": "2360", "url": "https://en.wikipedia.org/wiki?curid=2360", "title": "Abu Nidal Organization", "text": "Abu Nidal Organization\n\nThe Abu Nidal Organization (ANO) is the most common name for the Palestinian group Fatah–The Revolutionary Council (\"Fatah al-Majles al-Thawry\").\nThe ANO is named after its founder Abu Nidal. It was created by a split from Yasser Arafat's Fatah faction of the PLO in 1974. The group has been designated as a terrorist organization by the United States, the United Kingdom, Israel and the European Union.\n\nThe ANO was originally formed as a result of the 1974 Rejectionist Front split in the PLO, after Arafat's Fatah had pushed through amendments of the PLO's goals, which were seen as a step towards compromise with Israel. Abu Nidal then moved to Ba'athist Iraq where he set up the ANO, which soon began a vicious string of terrorist attacks.\n\nIt hasn't clearly defined its ideological position, but was clearly opposed to any form of compromise or negotiation with Israel. It is known as one of the most uncompromisingly militant Palestinian groups ever. It had an estimated membership of several hundred, but its strength today is not known.\n\nThe ANO carried out attacks in 20 countries, killing or injuring almost 1650 persons. Targets include the United States, the United Kingdom, France, Israel, moderate Palestinians, the PLO, and various Arab and European countries. The group has not attacked Western targets since the late 1980s.\n\nMajor attacks included the Rome and Vienna Airport Attacks in December 1985, the Neve Shalom synagogue in Istanbul and the Pan Am Flight 73 hijacking in Karachi in September 1986, and the \"City of Poros\" day-excursion ship attack in Greece in July 1988.\n\nThe ANO has been especially noted for its uncompromising stance on negotiation with Israel, treating anything less than all-out military struggle against Israel as treachery. This led the group to perform numerous attacks against the PLO, which had made clear it accepted a negotiated solution to the conflict. Fatah-RC is believed to have assassinated PLO deputy chief Abu Iyad and PLO security chief Abu Hul in Tunis in January 1991. It assassinated a Jordanian diplomat in Lebanon in January 1994 and has been linked to the killing of the PLO representative there. Noted PLO moderate Issam Sartawi was killed by the Fatah-RC in 1983. In the late 1970s, the group also made failed assassination attempt on the present Palestinian president and PLO chairman, Mahmoud Abbas. These attacks, and numerous others, led to the PLO issuing a death sentence \"in absentia\" against Abu Nidal. In the early 1990s, it made an attempt to gain control of a refugee camp in Lebanon, but this was thwarted by PLO organizations.\n\n\n"}
{"id": "2362", "url": "https://en.wikipedia.org/wiki?curid=2362", "title": "Antibody", "text": "Antibody\n\nAn antibody (Ab), also known as an immunoglobulin (Ig), is a large, Y-shaped protein produced mainly by plasma cells that is used by the immune system to neutralize pathogens such as bacteria and viruses. The antibody recognizes a unique molecule of the harmful agent, called an antigen, via the Fab's variable region. Each tip of the \"Y\" of an antibody contains a paratope (analogous to a lock) that is specific for one particular epitope (similarly analogous to a key) on an antigen, allowing these two structures to bind together with precision. Using this binding mechanism, an antibody can \"tag\" a microbe or an infected cell for attack by other parts of the immune system, or can neutralize its target directly (for example, by blocking a part of a microbe that is essential for its invasion and survival). Depending on the antigen, the binding may impede the biological process causing the disease or may activate macrophages to destroy the foreign substance. The ability of an antibody to communicate with the other components of the immune system is mediated via its Fc region (located at the base of the \"Y\"), which contains a conserved glycosylation site involved in these interactions. The production of antibodies is the main function of the humoral immune system.\n\nAntibodies are secreted by B cells of the adaptive immune system, mostly by differentiated B cells called plasma cells. Antibodies can occur in two physical forms, a soluble form that is secreted from the cell to be free in the blood plasma, and a membrane-bound form that is attached to the surface of a B cell and is referred to as the B-cell receptor (BCR). The BCR is found only on the surface of B cells and facilitates the activation of these cells and their subsequent differentiation into either antibody factories called plasma cells or memory B cells that will survive in the body and remember that same antigen so the B cells can respond faster upon future exposure. In most cases, interaction of the B cell with a T helper cell is necessary to produce full activation of the B cell and, therefore, antibody generation following antigen binding. Soluble antibodies are released into the blood and tissue fluids, as well as many secretions to continue to survey for invading microorganisms.\n\nAntibodies are glycoproteins belonging to the immunoglobulin superfamily. They constitute most of the gamma globulin fraction of the blood proteins. They are typically made of basic structural units—each with two large heavy chains and two small light chains. There are several different types of antibody heavy chains that define the five different types of crystallisable fragments (Fc) that may be attached to the antigen-binding fragments. The five different types of Fc regions allow antibodies to be grouped into five \"isotypes\". Each Fc region of a particular antibody isotype is able to bind to its specific Fc Receptor (except for IgD, which is essentially the BCR), thus allowing the antigen-antibody complex to mediate different roles depending on which FcR it binds. The ability of an antibody to bind to its corresponding FcR is further modulated by the structure of the glycan(s) present at conserved sites within its Fc region. The ability of antibodies to bind to FcRs helps to direct the appropriate immune response for each different type of foreign object they encounter. For example, IgE is responsible for an allergic response consisting of mast cell degranulation and histamine release. IgE's Fab paratope binds to allergic antigen, for example house dust mite particles, while its Fc region binds to Fc receptor ε. The allergen-IgE-FcRε interaction mediates allergic signal transduction to induce conditions such as asthma.\n\nThough the general structure of all antibodies is very similar, a small region at the tip of the protein is extremely variable, allowing millions of antibodies with slightly different tip structures, or antigen-binding sites, to exist. This region is known as the \"hypervariable region\". Each of these variants can bind to a different antigen. This enormous diversity of antibody paratopes on the antigen-binding fragments allows the immune system to recognize an equally wide variety of antigens. The large and diverse population of antibody paratope is generated by random recombination events of a set of gene segments that encode different antigen-binding sites (or \"paratopes\"), followed by random mutations in this area of the antibody gene, which create further diversity. This recombinational process that produces clonal antibody paratope diversity is called V(D)J or VJ recombination. Basically, the antibody paratope is polygenic, made up of three genes, V, D, and J. Each paratope locus is also polymorphic, such that during antibody production, one allele of V, one of D, and one of J is chosen. These gene segments are then joined together using random genetic recombination to produce the paratope. The regions where the genes are randomly recombined together is the hyper variable region used to recognise different antigens on a clonal basis.\n\nAntibody genes also re-organize in a process called class switching that changes the one type of heavy chain Fc fragment to another, creating a different isotype of the antibody that retains the antigen-specific variable region. This allows a single antibody to be used by different types of Fc receptors, expressed on different parts of the immune system.\n\nThe membrane-bound form of an antibody may be called a \"surface immunoglobulin\" (sIg) or a \"membrane immunoglobulin\" (mIg). It is part of the \"B cell receptor\" (BCR), which allows a B cell to detect when a specific antigen is present in the body and triggers B cell activation. The BCR is composed of surface-bound IgD or IgM antibodies and associated Ig-α and Ig-β heterodimers, which are capable of signal transduction. A typical human B cell will have 50,000 to 100,000 antibodies bound to its surface. Upon antigen binding, they cluster in large patches, which can exceed 1 micrometer in diameter, on lipid rafts that isolate the BCRs from most other cell signaling receptors.\nThese patches may improve the efficiency of the cellular immune response. In humans, the cell surface is bare around the B cell receptors for several hundred nanometers, which further isolates the BCRs from competing influences.\n\nThe antibody's paratope interacts with the antigen's epitope. An antigen usually contains different epitopes along its surface arranged discontinuously, and dominant epitopes on a given antigen are called determinants.\n\nAntibody and antigen interact by spatial complementarity (lock and key). The molecular forces involved in the Fab-epitope interaction are weak and non-specific – for example electrostatic forces, hydrogen bonds, hydrophobic interactions, and van der Waals forces. This means binding between antibody and antigen is reversible, and the antibody's affinity towards an antigen is relative rather than absolute. Relatively weak binding also means it is possible for an antibody to cross-react with different antigens of different relative affinities.\n\nOften, once an antibody and antigen bind, they become an immune complex, which functions as a unitary object and can act as an antigen in its own right, being countered by other antibodies. Similarly, haptens are small molecules that provoke no immune response by themselves, but once they bind to proteins, the resulting complex or hapten-carrier adduct is antigenic.\n\nAntibodies can come in different varieties known as isotypes or classes. In placental mammals there are five antibody isotypes known as IgA, IgD, IgE, IgG, and IgM. They are each named with an \"Ig\" prefix that stands for immunoglobulin, a name sometimes used interchangeably with antibody, and differ in their biological properties, functional locations and ability to deal with different antigens, as depicted in the table. The different suffixes of the antibody isotypes denote the different types of heavy chains the antibody contains, with each heavy chain class named alphabetically: α (alpha), γ (gamma), δ (delta), ε (epsilon), and μ (mu). This gives rise to IgA, IgG, IgD, IgE, and IgM, respectively.\n\nThe antibody isotype of a B cell changes during cell development and activation. Immature B cells, which have never been exposed to an antigen, express only the IgM isotype in a cell surface bound form. The B lymphocyte, in this ready-to-respond form, is known as a \"naive B lymphocyte.\" The naive B lymphocyte expresses both surface IgM and IgD. The co-expression of both of these immunoglobulin isotypes renders the B cell ready to respond to antigen. B cell activation follows engagement of the cell-bound antibody molecule with an antigen, causing the cell to divide and differentiate into an antibody-producing cell called a plasma cell. In this activated form, the B cell starts to produce antibody in a secreted form rather than a membrane-bound form. Some daughter cells of the activated B cells undergo isotype switching, a mechanism that causes the production of antibodies to change from IgM or IgD to the other antibody isotypes, IgE, IgA, or IgG, that have defined roles in the immune system.\n\nAntibodies are heavy (~150 kDa) globular plasma proteins. They have sugar chains (glycans) added to conserved amino acid residues. In other words, antibodies are \"glycoproteins\". The attached glycans are critically important to the structure and function of the antibody. Among other things the expressed glycans can modulate an antibody's affinity for its corresponding FcR(s).\n\nThe basic functional unit of each antibody is an immunoglobulin (Ig) monomer (containing only one Ig unit); secreted antibodies can also be dimeric with two Ig units as with IgA, tetrameric with four Ig units like teleost fish IgM, or pentameric with five Ig units, like mammalian IgM.\n\nThe Ig monomer is a \"Y\"-shaped molecule that consists of four polypeptide chains; two identical \"heavy chains\" and two identical \"light chains\" connected by disulfide bonds.\nEach chain is composed of structural domains called immunoglobulin domains. These domains contain about 70–110 amino acids and are classified into different categories (for example, variable or IgV, and constant or IgC) according to their size and function. They have a characteristic immunoglobulin fold in which two beta sheets create a \"sandwich\" shape, held together by interactions between conserved cysteines and other charged amino acids.\n\nThere are five types of mammalian Ig heavy chain denoted by the Greek letters: α, δ, ε, γ, and μ. The type of heavy chain present defines the \"class\" of antibody; these chains are found in IgA, IgD, IgE, IgG, and IgM antibodies, respectively. Distinct heavy chains differ in size and composition; α and γ contain approximately 450 amino acids, whereas μ and ε have approximately 550 amino acids.\nEach heavy chain has two regions, the \"constant region\" and the \"variable region\". The constant region is identical in all antibodies of the same isotype, but differs in antibodies of different isotypes. Heavy chains γ, α and δ have a constant region composed of \"three\" tandem (in a line) Ig domains, and a hinge region for added flexibility; heavy chains μ and ε have a constant region composed of \"four\" immunoglobulin domains. The variable region of the heavy chain differs in antibodies produced by different B cells, but is the same for all antibodies produced by a single B cell or B cell clone. The variable region of each heavy chain is approximately 110 amino acids long and is composed of a single Ig domain.\n\nIn mammals there are two types of immunoglobulin light chain, which are called lambda (λ) and kappa (κ). A light chain has two successive domains: one constant domain and one variable domain. The approximate length of a light chain is 211 to 217 amino acids. Each antibody contains two light chains that are always identical; only one type of light chain, κ or λ, is present per antibody in mammals. Other types of light chains, such as the iota (ι) chain, are found in other vertebrates like sharks (Chondrichthyes) and bony fishes (Teleostei).\n\nSome parts of an antibody have the same functions. The arms of the Y, for example, contain the sites that can bind to antigens (in general, identical) and, therefore, recognize specific foreign objects. This region of the antibody is called the \"Fab (fragment, antigen-binding) region\". It is composed of one constant and one variable domain from each heavy and light chain of the antibody.\nThe paratope is shaped at the amino terminal end of the antibody monomer by the variable domains from the heavy and light chains. The variable domain is also referred to as the F region and is the most important region for binding to antigens. To be specific, variable loops of β-strands, there each on the light (V) and heavy (V) chains are responsible for binding to the antigen. These loops are referred to as the complementarity determining regions (CDRs).\nThe structures of these CDRs have been clustered and classified by Chothia et al.\nand more recently by North et al.\nand Nikoloudis et al.\nIn the framework of the immune network theory, CDRs are also called idiotypes. According to immune network theory, the adaptive immune system is regulated by interactions between idiotypes.\n\nThe base of the Y plays a role in modulating immune cell activity. This region is called the \"Fc (Fragment, crystallizable) region\", and is composed of two heavy chains that contribute two or three constant domains depending on the class of the antibody. Thus, the Fc region ensures that each antibody generates an appropriate immune response for a given antigen, by binding to a specific class of Fc receptors, and other immune molecules, such as complement proteins. By doing this, it mediates different physiological effects including recognition of opsonized particles (binding to FcγR), lysis of cells (binding to complement), and degranulation of mast cells, basophils, and eosinophils (binding to FcεR).\n\nIn summary, the Fab region of the antibody determines antigen specificity while the Fc region of the antibody determines the antibody's class effect. Since only the constant domains of the heavy chains make up the Fc region of an antibody, the classes of heavy chain in antibodies determine their class effects. Possible classes of heavy chains in antibodies include alpha, gamma, delta, epsilon, and mu, and they define the antibody's isotypes IgA, G, D, E, and M, respectively. This infers different isotypes of antibodies have different class effects due to their different Fc regions binding and activating different types of receptors. Possible class effects of antibodies include: Opsonisation, agglutination, haemolysis, complement activation, mast cell degranulation, and neutralisation (though this class effect may be mediated by the Fab region rather than the Fc region). It also implies that Fab-mediated effects are directed at microbes or toxins, whilst Fc mediated effects are directed at effector cells or effector molecules (see below).\n\nThe main categories of antibody action include the following:\n\nActivated B cells differentiate into either antibody-producing cells called plasma cells that secrete soluble antibody or memory cells that survive in the body for years afterward in order to allow the immune system to remember an antigen and respond faster upon future exposures.\n\nAt the prenatal and neonatal stages of life, the presence of antibodies is provided by passive immunization from the mother. Early endogenous antibody production varies for different kinds of antibodies, and usually appear within the first years of life. Since antibodies exist freely in the bloodstream, they are said to be part of the humoral immune system. Circulating antibodies are produced by clonal B cells that specifically respond to only one antigen (an example is a virus capsid protein fragment). Antibodies contribute to immunity in three ways: They prevent pathogens from entering or damaging cells by binding to them; they stimulate removal of pathogens by macrophages and other cells by coating the pathogen; and they trigger destruction of pathogens by stimulating other immune responses such as the complement pathway. Antibodies will also trigger vasoactive amine degranulation to contribute to immunity against certain types of antigens (helminths, allergens).\n\nAntibodies that bind to surface antigens (for example, on bacteria) will attract the first component of the complement cascade with their Fc region and initiate activation of the \"classical\" complement system. This results in the killing of bacteria in two ways. First, the binding of the antibody and complement molecules marks the microbe for ingestion by phagocytes in a process called opsonization; these phagocytes are attracted by certain complement molecules generated in the complement cascade. Second, some complement system components form a membrane attack complex to assist antibodies to kill the bacterium directly (bacteriolysis).\n\nTo combat pathogens that replicate outside cells, antibodies bind to pathogens to link them together, causing them to agglutinate. Since an antibody has at least two paratopes, it can bind more than one antigen by binding identical epitopes carried on the surfaces of these antigens. By coating the pathogen, antibodies stimulate effector functions against the pathogen in cells that recognize their Fc region.\n\nThose cells that recognize coated pathogens have Fc receptors, which, as the name suggests, interact with the Fc region of IgA, IgG, and IgE antibodies. The engagement of a particular antibody with the Fc receptor on a particular cell triggers an effector function of that cell; phagocytes will phagocytose, mast cells and neutrophils will degranulate, natural killer cells will release cytokines and cytotoxic molecules; that will ultimately result in destruction of the invading microbe. The activation of natural killer cells by antibodies initiates a cytotoxic mechanism known as antibody-dependent cell-mediated cytotoxicity (ADCC) – this process may explain the efficacy of monoclonal antibodies used in biological therapies against cancer. The Fc receptors are isotype-specific, which gives greater flexibility to the immune system, invoking only the appropriate immune mechanisms for distinct pathogens.\n\nHumans and higher primates also produce \"natural antibodies\" that are present in serum before viral infection. Natural antibodies have been defined as antibodies that are produced without any previous infection, vaccination, other foreign antigen exposure or passive immunization. These antibodies can activate the classical complement pathway leading to lysis of enveloped virus particles long before the adaptive immune response is activated. Many natural antibodies are directed against the disaccharide galactose α(1,3)-galactose (α-Gal), which is found as a terminal sugar on glycosylated cell surface proteins, and generated in response to production of this sugar by bacteria contained in the human gut. Rejection of xenotransplantated organs is thought to be, in part, the result of natural antibodies circulating in the serum of the recipient binding to α-Gal antigens expressed on the donor tissue.\n\nVirtually all microbes can trigger an antibody response. Successful recognition and eradication of many different types of microbes requires diversity among antibodies; their amino acid composition varies allowing them to interact with many different antigens. It has been estimated that humans generate about 10 billion different antibodies, each capable of binding a distinct epitope of an antigen. Although a huge repertoire of different antibodies is generated in a single individual, the number of genes available to make these proteins is limited by the size of the human genome. Several complex genetic mechanisms have evolved that allow vertebrate B cells to generate a diverse pool of antibodies from a relatively small number of antibody genes.\n\nThe chromosomal region that encodes an antibody is large and contains several distinct gene loci for each domain of the antibody—the chromosome region containing heavy chain genes (IGH@) is found on chromosome 14, and the loci containing lambda and kappa light chain genes (IGL@ and IGK@) are found on chromosomes 22 and 2 in humans. One of these domains is called the variable domain, which is present in each heavy and light chain of every antibody, but can differ in different antibodies generated from distinct B cells. Differences, between the variable domains, are located on three loops known as hypervariable regions (HV-1, HV-2 and HV-3) or complementarity determining regions (CDR1, CDR2 and CDR3). CDRs are supported within the variable domains by conserved framework regions. The heavy chain locus contains about 65 different variable domain genes that all differ in their CDRs. Combining these genes with an array of genes for other domains of the antibody generates a large cavalry of antibodies with a high degree of variability. This combination is called V(D)J recombination discussed below.\n\nSomatic recombination of immunoglobulins, also known as \"V(D)J recombination\", involves the generation of a unique immunoglobulin variable region. The variable region of each immunoglobulin heavy or light chain is encoded in several pieces—known as gene segments (subgenes). These segments are called variable (V), diversity (D) and joining (J) segments. V, D and J segments are found in Ig heavy chains, but only V and J segments are found in Ig light chains. Multiple copies of the V, D and J gene segments exist, and are tandemly arranged in the genomes of mammals. In the bone marrow, each developing B cell will assemble an immunoglobulin variable region by randomly selecting and combining one V, one D and one J gene segment (or one V and one J segment in the light chain). As there are multiple copies of each type of gene segment, and different combinations of gene segments can be used to generate each immunoglobulin variable region, this process generates a huge number of antibodies, each with different paratopes, and thus different antigen specificities. Interestingly, the rearrangement of several subgenes (i.e. V2 family) for lambda light chain immunoglobulin is coupled with the activation of microRNA miR-650, which further influences biology of B-cells.\n\nRAG proteins play an important role with V(D)J recombination in cutting DNA at a particular region. Without the presence of these proteins, V(D)J recombination would not occur.\n\nAfter a B cell produces a functional immunoglobulin gene during V(D)J recombination, it cannot express any other variable region (a process known as allelic exclusion) thus each B cell can produce antibodies containing only one kind of variable chain.\n\nFollowing activation with antigen, B cells begin to proliferate rapidly. In these rapidly dividing cells, the genes encoding the variable domains of the heavy and light chains undergo a high rate of point mutation, by a process called \"somatic hypermutation\" (SHM). SHM results in approximately one nucleotide change per variable gene, per cell division. As a consequence, any daughter B cells will acquire slight amino acid differences in the variable domains of their antibody chains.\n\nThis serves to increase the diversity of the antibody pool and impacts the antibody's antigen-binding affinity. Some point mutations will result in the production of antibodies that have a weaker interaction (low affinity) with their antigen than the original antibody, and some mutations will generate antibodies with a stronger interaction (high affinity). B cells that express high affinity antibodies on their surface will receive a strong survival signal during interactions with other cells, whereas those with low affinity antibodies will not, and will die by apoptosis. Thus, B cells expressing antibodies with a higher affinity for the antigen will outcompete those with weaker affinities for function and survival allowing the average affinity of antibodies to increase over time. The process of generating antibodies with increased binding affinities is called \"affinity maturation\". Affinity maturation occurs in mature B cells after V(D)J recombination, and is dependent on help from helper T cells.\nIsotype or class switching is a biological process occurring after activation of the B cell, which allows the cell to produce different classes of antibody (IgA, IgE, or IgG). The different classes of antibody, and thus effector functions, are defined by the constant (C) regions of the immunoglobulin heavy chain. Initially, naive B cells express only cell-surface IgM and IgD with identical antigen binding regions. Each isotype is adapted for a distinct function; therefore, after activation, an antibody with an IgG, IgA, or IgE effector function might be required to effectively eliminate an antigen. Class switching allows different daughter cells from the same activated B cell to produce antibodies of different isotypes. Only the constant region of the antibody heavy chain changes during class switching; the variable regions, and therefore antigen specificity, remain unchanged. Thus the progeny of a single B cell can produce antibodies, all specific for the same antigen, but with the ability to produce the effector function appropriate for each antigenic challenge. Class switching is triggered by cytokines; the isotype generated depends on which cytokines are present in the B cell environment.\n\nClass switching occurs in the heavy chain gene locus by a mechanism called class switch recombination (CSR). This mechanism relies on conserved nucleotide motifs, called \"switch (S) regions\", found in DNA upstream of each constant region gene (except in the δ-chain). The DNA strand is broken by the activity of a series of enzymes at two selected S-regions. The variable domain exon is rejoined through a process called non-homologous end joining (NHEJ) to the desired constant region (γ, α or ε). This process results in an immunoglobulin gene that encodes an antibody of a different isotype.\n\nA group of antibodies can be called \"monovalent\" (or \"specific\") if they have affinity for the same epitope, or for the same antigen (but potentially different epitopes on the molecule), or for the same strain of microorganism (but potentially different antigens on or in it). In contrast, a group of antibodies can be called \"polyvalent\" (or \"unspecific\") if they have affinity for various antigens or microorganisms. Intravenous immunoglobulin, if not otherwise noted, consists of polyvalent IgG. In contrast, monoclonal antibodies are monovalent for the same epitope.\n\nHeterodimeric antibodies, which are also asymmetrical and antibodies, allow for greater flexibility and new formats for attaching a variety of drugs to the antibody arms. One of the general formats for a heterodimeric antibody is the “knobs-into-holes” format. This format is specific to the heavy chain part of the constant region in antibodies. The “knobs” part is engineered by replacing a small amino acid with a larger one. It fits into the “hole”, which is engineered by replacing a large amino acid with a smaller one. What connects the “knobs” to the “holes” are the disulfide bonds between each chain. The “knobs-into-holes” shape facilitates antibody dependent cell mediated cytotoxicity. Single chain variable fragments (scFv) are connected to the variable domain of the heavy and light chain via a short linker peptide. The linker is rich in glycine, which gives it more flexibility, and serine/threonine, which gives it specificity. Two different scFv fragments can be connected together, via a hinge region, to the constant domain of the heavy chain or the constant domain of the light chain. This gives the antibody bispecificity, allowing for the binding specificities of two different antigens. The “knobs-into-holes” format enhances heterodimer formation but doesn’t suppress homodimer formation.\n\nTo further improve the function of heterodimeric antibodies, many scientists are looking towards artificial constructs. Artificial antibodies are largely diverse protein motifs that use the functional strategy of the antibody molecule, but aren’t limited by the loop and framework structural constraints of the natural antibody. Being able to control the combinational design of the sequence and three-dimensional space could transcend the natural design and allow for the attachment of different combinations of drugs to the arms.\n\nHeterodimeric antibodies have a greater range in shapes they can take and the drugs that are attached to the arms don’t have to be the same on each arm, allowing for different combinations of drugs to be used in cancer treatment. Pharmaceuticals are able to produce highly functional bispecific, and even multispecific, antibodies. The degree to which they can function is impressive given that such a change shape from the natural form should lead to decreased functionality.\n\nDetection of particular antibodies is a very common form of medical diagnostics, and applications such as serology depend on these methods. For example, in biochemical assays for disease diagnosis, a titer of antibodies directed against Epstein-Barr virus or Lyme disease is estimated from the blood. If those antibodies are not present, either the person is not infected or the infection occurred a \"very\" long time ago, and the B cells generating these specific antibodies have naturally decayed.\n\nIn clinical immunology, levels of individual classes of immunoglobulins are measured by nephelometry (or turbidimetry) to characterize the antibody profile of patient. Elevations in different classes of immunoglobulins are sometimes useful in determining the cause of liver damage in patients for whom the diagnosis is unclear. For example, elevated IgA indicates alcoholic cirrhosis, elevated IgM indicates viral hepatitis and primary biliary cirrhosis, while IgG is elevated in viral hepatitis, autoimmune hepatitis and cirrhosis.\n\nAutoimmune disorders can often be traced to antibodies that bind the body's own epitopes; many can be detected through blood tests. Antibodies directed against red blood cell surface antigens in immune mediated hemolytic anemia are detected with the Coombs test. The Coombs test is also used for antibody screening in blood transfusion preparation and also for antibody screening in antenatal women.\n\nPractically, several immunodiagnostic methods based on detection of complex antigen-antibody are used to diagnose infectious diseases, for example ELISA, immunofluorescence, Western blot, immunodiffusion, immunoelectrophoresis, and magnetic immunoassay. Antibodies raised against human chorionic gonadotropin are used in over the counter pregnancy tests.\n\nNew dioxaborolane chemistry enables radioactive fluoride (F) labeling of antibodies, which allows for positron emission tomography (PET) imaging of cancer.\n\nTargeted monoclonal antibody therapy is employed to treat diseases such as rheumatoid arthritis, multiple sclerosis, psoriasis, and many forms of cancer including non-Hodgkin's lymphoma, colorectal cancer, head and neck cancer and breast cancer.\n\nSome immune deficiencies, such as X-linked agammaglobulinemia and hypogammaglobulinemia, result in partial or complete lack of antibodies. These diseases are often treated by inducing a short term form of immunity called passive immunity. Passive immunity is achieved through the transfer of ready-made antibodies in the form of human or animal serum, pooled immunoglobulin or monoclonal antibodies, into the affected individual.\n\nRh factor, also known as Rh D antigen, is an antigen found on red blood cells; individuals that are Rh-positive (Rh+) have this antigen on their red blood cells and individuals that are Rh-negative (Rh–) do not. During normal childbirth, delivery trauma or complications during pregnancy, blood from a fetus can enter the mother's system. In the case of an Rh-incompatible mother and child, consequential blood mixing may sensitize an Rh- mother to the Rh antigen on the blood cells of the Rh+ child, putting the remainder of the pregnancy, and any subsequent pregnancies, at risk for hemolytic disease of the newborn.\n\nRho(D) immune globulin antibodies are specific for human RhD antigen. Anti-RhD antibodies are administered as part of a prenatal treatment regimen to prevent sensitization that may occur when a Rh-negative mother has a Rh-positive fetus. Treatment of a mother with Anti-RhD antibodies prior to and immediately after trauma and delivery destroys Rh antigen in the mother's system from the fetus. It is important to note that this occurs before the antigen can stimulate maternal B cells to \"remember\" Rh antigen by generating memory B cells. Therefore, her humoral immune system will not make anti-Rh antibodies, and will not attack the Rh antigens of the current or subsequent babies. Rho(D) Immune Globulin treatment prevents sensitization that can lead to Rh disease, but does not prevent or treat the underlying disease itself.\n\nSpecific antibodies are produced by injecting an antigen into a mammal, such as a mouse, rat, rabbit, goat, sheep, or horse for large quantities of antibody. Blood isolated from these animals contains \"polyclonal antibodies\"—multiple antibodies that bind to the same antigen—in the serum, which can now be called antiserum. Antigens are also injected into chickens for generation of polyclonal antibodies in egg yolk. To obtain antibody that is specific for a single epitope of an antigen, antibody-secreting lymphocytes are isolated from the animal and immortalized by fusing them with a cancer cell line. The fused cells are called hybridomas, and will continually grow and secrete antibody in culture. Single hybridoma cells are isolated by dilution cloning to generate cell clones that all produce the same antibody; these antibodies are called \"monoclonal antibodies\". Polyclonal and monoclonal antibodies are often purified using Protein A/G or antigen-affinity chromatography.\n\nIn research, purified antibodies are used in many applications. Antibodies for research applications can be found directly from antibody suppliers, or through use of a specialist search engine. Research antibodies are most commonly used to identify and locate intracellular and extracellular proteins. Antibodies are used in flow cytometry to differentiate cell types by the proteins they express; different types of cell express different combinations of cluster of differentiation molecules on their surface, and produce different intracellular and secretable proteins. They are also used in immunoprecipitation to separate proteins and anything bound to them (co-immunoprecipitation) from other molecules in a cell lysate, in Western blot analyses to identify proteins separated by electrophoresis, and in immunohistochemistry or immunofluorescence to examine protein expression in tissue sections or to locate proteins within cells with the assistance of a microscope. Proteins can also be detected and quantified with antibodies, using ELISA and ELISPOT techniques.\n\nAntibodies used in research are some of the most powerful, yet most problematic reagents with a tremendous number of factors that must be controlled in any experiment including cross reactivity, or the antibody recognizing multiple epitopes and affinity, which can vary widely depending on experimental conditions such as pH, solvent, state of tissue etc. Multiple attempts have been made to improve both the way that researchers validate antibodies and ways in which they report on antibodies. Researchers using antibodies in their work need to record them correctly in order to allow their research to be reproducible (and therefore tested, and qualified by other researchers). Less than half of research antibodies referenced in academic papers can be easily identified. Papers published in F1000 in 2014 and 2015 provide researchers with a guide for reporting research antibody use. The RRID paper, is co-published in 4 journals that implemented the RRIDs Standard for research resource citation, which draws data from the antibodyregistry.org as the source of antibody identifiers (see also group at Force11)\n\nTraditionally, most antibodies are produced by hybridoma cell lines through immortalization of antibody-producing cells by chemically-induced fusion with myeloma cells. In some cases, additional fusions with other lines have created \"triomas\" and \"quadromas\". The manufacturing process should be appropriately described and validated. Validation studies should\nat least include :\n\n\n\n\nThe importance of antibodies in health care and the biotechnology industry demands knowledge of their structures at high resolution. This information is used for protein engineering, modifying the antigen binding affinity, and identifying an epitope, of a given antibody. X-ray crystallography is one commonly used method for determining antibody structures. However, crystallizing an antibody is often laborious and time-consuming. Computational approaches provide a cheaper and faster alternative to crystallography, but their results are more equivocal, since they do not produce empirical structures. Online web servers such as \"Web Antibody Modeling\" (WAM) and \"Prediction of Immunoglobulin Structure\" (PIGS) enables computational modeling of antibody variable regions. Rosetta Antibody is a novel antibody F region structure prediction server, which incorporates sophisticated techniques to minimize CDR loops and optimize the relative orientation of the light and heavy chains, as well as homology models that predict successful docking of antibodies with their unique antigen.\n\nThe ability to describe the antibody through binding affinity to the antigen is supplemented by information on antibody structure and amino acid sequences for the purpose of patent claims.\n\nThe first use of the term \"antibody\" occurred in a text by Paul Ehrlich. The term \"Antikörper\" (the German word for \"antibody\") appears in the conclusion of his article \"Experimental Studies on Immunity\", published in October 1891, which states that, \"if two substances give rise to two different antikörper, then they themselves must be different\". However, the term was not accepted immediately and several other terms for antibody were proposed; these included \"Immunkörper\", \"Amboceptor\", \"Zwischenkörper\", \"substance sensibilisatrice\", \"copula\", \"Desmon\", \"philocytase\", \"fixateur\", and \"Immunisin\". The word \"antibody\" has formal analogy to the word \"antitoxin\" and a similar concept to \"Immunkörper\" (\"immune body\" in English). As such, the original construction of the word contains a logical flaw; the antitoxin is something directed against a toxin, while the antibody is a body directed against something.\n\nThe study of antibodies began in 1890 when Kitasato Shibasaburō described antibody activity against diphtheria and tetanus toxins. Kitasato put forward the theory of humoral immunity, proposing that a mediator in serum could react with a foreign antigen. His idea prompted Paul Ehrlich to propose the side-chain theory for antibody and antigen interaction in 1897, when he hypothesized that receptors (described as \"side-chains\") on the surface of cells could bind specifically to toxins – in a \"lock-and-key\" interaction – and that this binding reaction is the trigger for the production of antibodies. Other researchers believed that antibodies existed freely in the blood and, in 1904, Almroth Wright suggested that soluble antibodies coated bacteria to label them for phagocytosis and killing; a process that he named opsoninization.\n\nIn the 1920s, Michael Heidelberger and Oswald Avery observed that antigens could be precipitated by antibodies and went on to show that antibodies are made of protein. The biochemical properties of antigen-antibody-binding interactions were examined in more detail in the late 1930s by John Marrack. The next major advance was in the 1940s, when Linus Pauling confirmed the lock-and-key theory proposed by Ehrlich by showing that the interactions between antibodies and antigens depend more on their shape than their chemical composition. In 1948, Astrid Fagreaus discovered that B cells, in the form of plasma cells, were responsible for generating antibodies.\n\nFurther work concentrated on characterizing the structures of the antibody proteins. A major advance in these structural studies was the discovery in the early 1960s by Gerald Edelman and Joseph Gally of the antibody light chain, and their realization that this protein is the same as the Bence-Jones protein described in 1845 by Henry Bence Jones. Edelman went on to discover that antibodies are composed of disulfide bond-linked heavy and light chains. Around the same time, antibody-binding (Fab) and antibody tail (Fc) regions of IgG were characterized by Rodney Porter. Together, these scientists deduced the structure and complete amino acid sequence of IgG, a feat for which they were jointly awarded the 1972 Nobel Prize in Physiology or Medicine. The Fv fragment was prepared and characterized by David Givol. While most of these early studies focused on IgM and IgG, other immunoglobulin isotypes were identified in the 1960s: Thomas Tomasi discovered secretory antibody (IgA); David S. Rowe and John L. Fahey discovered IgD; and Kimishige Ishizaka and Teruko Ishizaka discovered IgE and showed it was a class of antibodies involved in allergic reactions. In a landmark series of experiments beginning in 1976, Susumu Tonegawa showed that genetic material can rearrange itself to form the vast array of available antibodies.\n\nAntibody mimetics are organic compounds that, like antibodies, can specifically bind antigens. They are usually artificial peptides or proteins with a molar mass of about 3 to 20 kDa. Nucleic acids and small molecules are sometimes considered antibody mimetics, but not artificial antibodies, antibody fragments and fusion proteins are composed from these. Common advantages over antibodies are better solubility, tissue penetration, stability towards heat and enzymes, and comparatively low production costs. Antibody mimetics such as the Affimer and the DARPin have being developed and commercialised as research, diagnostic and therapeutic agents.\n\n"}
{"id": "2363", "url": "https://en.wikipedia.org/wiki?curid=2363", "title": "Alessandro Scarlatti", "text": "Alessandro Scarlatti\n\nPietro Alessandro Gaspare Scarlatti (2 May 1660 – 22 October 1725) was an Italian Baroque composer, especially famous for his operas and chamber cantatas. He is considered the founder of the Neapolitan school of opera. He was the father of two other composers, Domenico Scarlatti and Pietro Filippo Scarlatti.\n\nScarlatti was born in Palermo (or in Trapani), then part of the Kingdom of Sicily. He is generally said to have been a pupil of Giacomo Carissimi in Rome, and some theorize that he had some connection with northern Italy because his early works seem to show the influence of Stradella and Legrenzi. The production at Rome of his opera \"Gli Equivoci nell sembiante\" (1679) gained him the support of Queen Christina of Sweden (who at the time was living in Rome), and he became her \"Maestro di Cappella\". In February 1684 he became \"Maestro di Cappella\" to the viceroy of Naples, perhaps through the influence of his sister, an opera singer, who might have been the mistress of an influential Neapolitan noble. Here he produced a long series of operas, remarkable chiefly for their fluency and expressiveness, as well as other music for state occasions.\n\nIn 1702 Scarlatti left Naples and did not return until the Spanish domination had been superseded by that of the Austrians. In the interval he enjoyed the patronage of Ferdinando de' Medici, for whose private theatre near Florence he composed operas, and of Cardinal Ottoboni, who made him his \"maestro di cappella\", and procured him a similar post at the Basilica di Santa Maria Maggiore in Rome in 1703.\n\nAfter visiting Venice and Urbino in 1707, Scarlatti took up his duties in Naples again in 1708, and remained there until 1717. By this time Naples seems to have become tired of his music; the Romans, however, appreciated it better, and it was at the Teatro Capranica in Rome that he produced some of his finest operas (\"Telemaco\", 1718; \"Marco Attilio Regolò\", 1719; \"La Griselda\", 1721), as well as some noble specimens of church music, including a mass for chorus and orchestra, composed in honor of Saint Cecilia for Cardinal Acquaviva in 1721. His last work on a large scale appears to have been the unfinished serenata for the marriage of the prince of Stigliano in 1723. He died in Naples in 1725.\nScarlatti's music forms an important link between the early Baroque Italian vocal styles of the 17th century, with their centers in Florence, Venice and Rome, and the classical school of the 18th century. Scarlatti's style, however, is more than a transitional element in Western music; like most of his Naples colleagues he shows an almost modern understanding of the psychology of modulation and also frequently makes use of the ever-changing phrase lengths so typical of the Napoli school. His early operas (\"Gli equivoci nel sembiante\" 1679; \"L'honestà negli amori\" 1680, containing the famous aria \"Già il sole dal Gange\"; \"Il Pompeo\" 1683, containing the well-known airs \"O cessate di piagarmi\" and \"Toglietemi la vita ancor,\" and others down to about 1685) retain the older cadences in their recitatives, and a considerable variety of neatly constructed forms in their charming little arias, accompanied sometimes by the string quartet, treated with careful elaboration, sometimes with the continuo alone. By 1686 he had definitely established the \"Italian overture\" form (second edition of \"Dal male il bene\"), and had abandoned the ground bass and the binary form air in two stanzas in favour of the ternary form or da capo type of air. His best operas of this period are \"La Rosaura\" (1690, printed by the Gesellschaft für Musikforschung), and \"Pirro e Demetrio\" (1694), in which occur the arias \"Le Violette\", and \"Ben ti sta, traditor\".\n\nFrom about 1697 onwards (\"La caduta del Decemviri\"), influenced partly perhaps by the style of Giovanni Bononcini and probably more by the taste of the viceregal court, his opera arias become more conventional and commonplace in rhythm, while his scoring is hasty and crude, yet not without brilliance (\"L'Eraclea\", 1700), the oboes and trumpets being frequently used, and the violins often playing in unison. The operas composed for Ferdinando de' Medici are lost; they might have given a more favourable idea of his style as his correspondence with the prince shows that they were composed with a very sincere sense of inspiration.\n\n\"Mitridate Eupatore\", accounted his masterpiece, composed for Venice in 1707, contains music far in advance of anything that Scarlatti had written for Naples, both in technique and in intellectual power. The later Neapolitan operas (\"L'amor volubile e tiranno\" 1709; \"La principessa fedele\" 1710; \"Tigrane\", 1714, &c.) are showy and effective rather than profoundly emotional; the instrumentation marks a great advance on previous work, since the main duty of accompanying the voice is thrown upon the string quartet, the harpsichord being reserved exclusively for the noisy instrumental ritornelli. In his opera \"Teodora\" (1697) he originated the use of the orchestral \"ritornello\".\nHis last group of operas, composed for Rome, exhibit a deeper poetic feeling, a broad and dignified style of melody, a strong dramatic sense, especially in accompanied recitatives, a device which he himself had been the first to use as early as 1686 (\"Olimpia vendicata\") and a much more modern style of orchestration, the horns appearing for the first time, and being treated with striking effect.\n\nBesides the operas, oratorios (\"Agar et Ismaele esiliati\", 1684; \"La Maddalena\", 1685; \"La Giuditta\", 1693; \"Christmas Oratorio\", c. 1705; \"S. Filippo Neri\", 1714; and others) and serenatas, which all exhibit a similar style, Scarlatti composed upwards of five hundred chamber-cantatas for solo voice. These represent the most intellectual type of chamber-music of their period, and it is to be regretted that they have remained almost entirely in manuscript, since a careful study of them is indispensable to anyone who wishes to form an adequate idea of Scarlatti's development.\nHis few remaining Masses (the story of his having composed two hundred is hardly credible) and church music in general are comparatively unimportant, except the great \"St Cecilia Mass\" (1721), which is one of the first attempts at the style which reached its height in the great Masses of Johann Sebastian Bach and Beethoven. His instrumental music, though not without interest, is curiously antiquated as compared with his vocal works.\n\n\n\n"}
{"id": "2369", "url": "https://en.wikipedia.org/wiki?curid=2369", "title": "Aston Martin", "text": "Aston Martin\n\nAston Martin Lagonda Limited is a British manufacturer of luxury sports cars and grand tourers. It was founded in 1913 by Lionel Martin and Robert Bamford. Steered from 1947 by David Brown, it became associated with expensive grand touring cars in the 1950s and 1960s, and with the fictional character James Bond following his use of a DB5 model in the 1964 film \"Goldfinger\". Their sports cars are regarded as a British cultural icon. Aston Martin has held a Royal Warrant as purveyor of motorcars to HRH the Prince of Wales since 1982.\n\nHeadquarters and the main production site are in Gaydon, Warwickshire, England, on the site of a former RAF V Bomber airbase. One of Aston Martin's recent cars was named after the 1950s Vulcan Bomber. Aston Martin has diversified to speed boats, and real estate development. \n\nAston Martin had a troubled history after the third quarter of the 20th century but has also enjoyed long periods of success and stability. “In the first century we went bankrupt seven times”, incoming CEO Andy Palmer told \"Automotive News Europe\". “The second century is about making sure that is not the case.” On the back of strong demand for Aston Martin’s DB11, its first all-new model in a decade, the company swung back to a profit in the first quarter of 2017.\n\nAston Martin was founded in 1913 by Lionel Martin and Robert Bamford. The two had joined forces as Bamford & Martin the previous year to sell cars made by Singer from premises in Callow Street, London where they also serviced GWK and Calthorpe vehicles. Martin raced specials at Aston Hill near Aston Clinton, and the pair decided to make their own vehicles. The first car to be named \"Aston Martin\" was created by Martin by fitting a four-cylinder Coventry-Simplex engine to the chassis of a 1908 Isotta-Fraschini.\n\nThey acquired premises at Henniker Mews in Kensington and produced their first car in March 1915. Production could not start because of the outbreak of World War I, and Martin joined the Admiralty and Bamford the Royal Army Service Corps. All machinery was sold to the Sopwith Aviation Company.\n\nAfter the war they found new premises at Abingdon Road, Kensington and designed a new car. Bamford left in 1920 and Aston Martin was revitalised with funding from Count Louis Zborowski. In 1922, Bamford & Martin produced cars to compete in the French Grand Prix, which went on to set world speed and endurance records at Brooklands. Three works Team Cars with 16-valve were built for racing and record breaking: chassis number 1914, later developed as the Green Pea; chassis number 1915, the Razor Blade record car; and chassis number 1916, later developed as the Halford Special.\n\nApproximately 55 cars were built for sale in two configurations; and short chassis. Aston Martin went bankrupt in 1924 and was bought by Dorothea, Lady Charnwood who put her son John Benson on the board. Aston Martin failed again in 1925 and the factory closed in 1926, with Lionel Martin leaving.\n\nLater that year, Bill Renwick, Augustus (Bert) Bertelli and investors including Lady Charnwood took control of the business. They renamed it Aston Martin Motors and moved it to the former Whitehead Aircraft Limited Hanworth works in Feltham. Renwick and Bertelli had been in partnership some years and had developed an overhead-cam four-cylinder engine using Renwick's patented combustion chamber design, which they had tested in an Enfield-Allday chassis. The only \"Renwick and Bertelli\" motor car made, it was known as \"Buzzbox\" and still survives.\n\nThe pair had planned to sell their engine to motor manufacturers, but having heard that Aston Martin was no longer in production realised they could capitalise on its reputation to jump start the production of a completely new car.\n\nBetween 1926 and 1937 Bertelli was both technical director and designer of all new Aston Martins, since known as \"Bertelli cars\". They included the 1½-litre \"T-type\", \"International\", \"Le Mans\", \"MKII\" and its racing derivative, the \"Ulster\", and the 2-litre 15/98 and its racing derivative, the \"Speed Model\". Most were open two-seater sports cars bodied by Bert Bertelli's brother , with a small number of long-chassis four-seater tourers, dropheads and saloons also produced.\n\nBertelli was a competent driver keen to race his cars, one of few owner/manufacturer/drivers. The \"LM\" team cars were very successful in national and international motor racing including at Le Mans and the Mille Miglia.\n\nFinancial problems reappeared in 1932. Aston Martin was rescued for a year by Lance Prideaux Brune before passing it on to Sir Arthur Sutherland. In 1936, Aston Martin decided to concentrate on road cars, producing just 700 until World War II halted work. Production shifted to aircraft components during the war.\n\nIn 1947, old-established (1860) privately-owned Huddersfield gear and machine tools manufacturer David Brown Limited bought Aston Martin putting it under control of its Tractor Group. David Brown became Aston Martin's latest saviour. He also acquired without its factory Lagonda's business for its 2.6-litre W. O. Bentley-designed engine. Lagonda moved operations to Newport Pagnell and shared engines, resources and workshops. Aston Martin began to build the classic \"DB\" series of cars. \n\nIn April 1950, they announced planned production of their Le Mans prototype to be called the DB2, followed by the DB2/4 in 1953, the DB2/4 MkII in 1955, the DB Mark III in 1957 and the Italian-styled 3.7 L DB4 in 1958.\n\nWhile these models helped Aston Martin establish a good racing pedigree, the DB4 stood out and yielded the famous DB5 in 1963. Aston stayed true to its grand touring style with the DB6 (1965–70), and DBS (1967–1972).\n\nThe six-cylinder engines of these cars from 1954 up to 1965 were designed by Tadek Marek.\n\nAston Martin was often financially troubled. In 1972 David Brown paid off all its debts, said to be £5 million or more, and handed it for £101 to Company Developments, a Birmingham-based investment bank consortium chaired by accountant William Willson. More detail on this period may be read at Willson's biography. The world-wide recession, lack of working capital and the difficulties of developing without proper resources an engine to meet California's exhaust emission requirements — it stopped Aston's US sales — again pulled Aston Martin into receivership at the end of 1974. There were 460 workers when the plant closed.\nThe receiver sold the business in April 1975 for £1.05 million to North American businessmen Peter Sprague of National Semiconductor and Toronto hotelier, George Minden, and Jeremy Turner, a London businessman, who insisted to reporters Aston Martin remained a British controlled business. Sprague later claimed he had fallen in love with the factory, not the cars, the workforce's craftsmanship dedication and intelligence. At this point, he and Minden had brought in investor, Alan Curtis, a British office property developer together with George Flather, a retired Sheffield steel magnate.\n\nSix months later in September 1975 the factory — shut-down the previous December — re-opened under its new owner Aston Martin Lagonda (1975) Limited with 100 employees and plans to lift staff to 250 by the end of 1975. In January 1976 AML revealed it now held orders for 150 cars for USA, 100 for other markets and another 80 from a Japanese importing agency. At the Geneva Motor Show Fred Hartley, managing director and sales director for 13 years before that, announced he had resigned over \"differences in marketing policy\". Alan Curtis made himself managing director. \n\nThe new owners pushed Aston Martin into modernising its line, producing the V8 Vantage in 1977, the convertible Volante in 1978, and the one-off William Towns-styled Bulldog in 1980. Towns also styled the futuristic new Lagonda saloon, based on the V8 model.\n\nCurtis, who had a 42% stake in Aston Martin, also brought about a change in direction from the usual customers who were Aston Martin fanatics (fans) to successful young married businessmen. Prices had been increased by 25%. There was speculation that AML was about to buy Lamborghini. At the end of the 1970s there was widespread debate about running MG into the Aston Martin consortium. 85 Tory MPs formed themselves into a pressure group to get British Leyland to release their grip and hand it over. CH Industrials plc (car components) bought a 10% share in AML. But in July 1980 blaming a recession AML cut back their workforce of 450 by more than 20% making those people redundant and the following day British Leyland announced it had abandoned hope of an MG rescue by Aston Martin.\n\nin January 1981 there having been no satisfactory revival partners Alan Curtis and Peter Sprague announced they had never intended to maintain a long term financial stake in Aston Martin Lagonda and it was to be sold to Pace Petroleum's Victor Gauntlett. Sprague and Curtis pointed out that under their ownership AML finances had improved to where an offer for MG might have been feasible.Worldwide sales had shrunk to three cars per week, prompting chairman Alan Curtis, Sprague, and Minden to consider shutting down production to concentrate on service and restoration. At this point Curtis attended the 1980 Pace sponsored Stirling Moss benefit day at Brands Hatch, and met fellow Farnham resident Victor Gauntlett.\n\nGauntlett bought a 12.5% stake in Aston Martin for £500,000 via Pace Petroleum in 1980, with Tim Hearley of CH Industrials taking a similar share. Pace and CHI took over as joint 50/50 owners at the beginning of 1981, with Gauntlett as executive chairman. Gauntlett also led the sales team, and after some development and publicity when it became the world's fastest 4-seater production car, was able to sell the Aston Martin Lagonda in Oman, Kuwait, and Qatar.\n\nIn 1982, Aston Martin was granted a Royal Warrant of Appointment by the Prince of Wales. Aston Martin holds the warrant to this day.\n\nUnderstanding that it would take some time to develop new Aston Martin products, they created an engineering service subsidiary to develop automotive products for other companies. It was decided to use, a trade name of Salmons & Son their in-house coachbuilder, Tickford which Aston Martin had bought in 1955. Tickford's name had been long associated with expensive high quality carriages and cars and their folding roofs. New products included a Tickford Austin Metro, a Tickford Ford Capri and even Tickford train interiors, particularly on the Jaguar XJS. Pace continued sponsoring racing events, and now sponsored all Aston Martin Owners Club events, taking a Tickford-engined Nimrod Group C car owned by AMOC President Viscount Downe, which came third in the Manufacturers Championship in both 1982 and 1983. It also finished seventh in the 1982 24 Hours of Le Mans race. However, sales of production cars were now at an all-time low of 30 cars produced in 1982.\n\nAs trading became tighter in the petroleum market, and Aston Martin was requiring more time and money, Gauntlett agreed to sell Hays/Pace to the Kuwait Investment Office in September 1983. As Aston Martin required greater investment, he also agreed to sell his share holding to American importer and Greek shipping tycoon Peter Livanos, who invested via his joint venture with Nick and John Papanicolaou, ALL Inc. Gauntlett remained chairman of AML 55% owned by ALL, with Tickford a 50/50 venture between ALL and CHI. The uneasy relationship was ended when ALL exercised options to buy a larger share in AML; CHI's residual shares were exchanged for CHI's complete ownership of Tickford, which retained development of existing Aston Martin projects. In 1984 Papanicolaou's Titan shipping business was in trouble so Livanos's father George bought out the Papanicolaou's shares in ALL, while Gauntlett again became a shareholder with a 25% holding in AML. The deal valued Aston Martin/AML at £2 million, the year it built its 10,000th car.\n\nAlthough as a result Aston Martin had to make 60 members of the workforce redundant, Gauntlett bought a stake in Italian styling house Zagato, and resurrected its collaboration with Aston Martin.\n\nIn 1986, Gauntlett negotiated the return of fictional British secret agent James Bond to Aston Martin. Cubby Broccoli had chosen to recast the character using actor Timothy Dalton, in an attempt to re-root the Bond-brand back to a more Sean Connery-like feel. Gauntlett supplied his personal pre-production Vantage for use in the filming of \"The Living Daylights\", and sold a Volante to Broccoli for use at his home in America. Gauntlett turned down the role of a KGB colonel in the film, however: \"I would have loved to have done it but really could not afford the time.\"\n\nAston Martin needed funds to survive in the long term. In May 1987, Gauntlett and Prince Michael of Kent were staying at the home of Contessa Maggi, the wife of the founder of the original Mille Miglia, while watching the revival event. Another house guest was Walter Hayes, vice-president of Ford of Europe. Despite problems over the previous acquisition of AC Cars, Hayes saw the potential of the brand and the discussion resulted in Ford taking a share holding in September 1987. In 1988, having produced some 5,000 cars in 20 years, a revived economy and successful sales of limited edition Vantage, and 52 Volante Zagato coupes at £86,000 each; Aston Martin finally retired the ancient V8 and introduced the Virage range—the first new Aston launched in 20 years.\n\nAlthough Gauntlett was contractually to stay as chairman for two years, his racing interests took Aston back into sports car racing in 1989 with limited European success. However, with engine rule changes for the 1990 season and the launch of the new Aston Martin Volante model, Ford provided the limited supply of Cosworth engines to the Jaguar cars racing team. As the \"small Aston\" DB7 would require a large engineering input, Ford agreed to take full control of Aston Martin, and Gauntlett handed over Aston Martin's chairmanship to Hayes in 1991. In 1992, the Vantage version was announced, and the following year Aston Martin renewed the DB range by announcing the DB7.\n\nFord placed Aston in the Premier Automotive Group, invested in new manufacturing and ramped up production. In 1994, Ford opened a new factory at Banbury Road in Bloxham. In 1995 Aston Martin produced a record 700 vehicles. Until the Ford era, cars had been produced by hand coachbuilding craft methods, such as the English wheel. In 1998 the 2,000th DB7 was built, and in 2002 the 6,000th, exceeding production of all previous DB models. The DB7 range was boosted by the addition of V12 Vantage models in 1999, and in 2001 Aston Martin introduced the V12-engined Aston Martin Vanquish.\n\nAt the North American International Auto Show in Detroit, Michigan in 2003, Aston Martin introduced the AMV8 Vantage concept car. Expected to have few changes before its introduction in 2005, the Vantage brought back the classic V8 engine to allow Aston Martin to compete in a larger market. 2003 also saw the opening of the Gaydon factory, the first purpose-built factory in Aston Martin's history. Also introduced in 2003 was the DB9 coupé, which replaced the ten-year-old DB7. A convertible version of the DB9, the DB9 Volante, was introduced at the 2004 Detroit Auto Show.\n\nIn October 2004, Aston Martin set up the dedicated AMEP engine production plant within the Ford Germany Niehl, Cologne plant. With capacity to produce up to 5,000 engines a year by 100 specially trained personnel, like traditional Aston Martin engine production from Newport Pagnell, assembly of each unit is entrusted to a single technician from a pool of 30, with V8 and V12 variants assembled in under 20 hours. By bringing engine production back to within Aston Martin, the promise was that Aston Martin would be able to produce small runs of higher performance variants engines. This expanded engine capacity allowed in 2006, the V8 Vantage sports car to enter production at the Gaydon factory, joining the DB9 and DB9 Volante.\n\nIn December 2003 Aston Martin announced it would return to motor racing in 2005. A new division was created, called Aston Martin Racing, which became responsible, together with Prodrive, for the design, development, and management of the DBR9 program. The DBR9 competes in the GT class in sports car races, including the world-famous 24 Hours of Le Mans.\n\nIn 2006, an internal audit led Ford to consider divesting itself of parts of its Premier Automotive Group. After suggestions of selling Jaguar Cars, Land Rover, or Volvo Cars were weighed, Ford announced in August 2006 it had engaged UBS AG to sell all or part of Aston Martin at auction.\n\nOn 12 March 2007, a consortium led by Prodrive chairman David Richards purchased Aston Martin for £475m (US$848m). The group included American investment banker John Singers and two Kuwaiti companies, Investment Dar and Adeem Investment; Prodrive had no financial involvement in the deal.\nFord kept a stake in Aston Martin valued at £40m (US$70m).\n\nTo demonstrate the V8 Vantage's durability across hazardous terrain and promote the car in China, the first east-west crossing of the Asian Highway was undertaken between June and August 2007. A pair of Britons drove from Tokyo to Istanbul before joining the European motorway network for another to London. The promotion was so successful Aston Martin opened dealerships in Shanghai and Beijing within three months.\n\nOn 19 July 2007, the Newport Pagnell plant rolled out the last of nearly 13,000 cars made there since 1955, a Vanquish S. The Tickford Street facility was converted to Aston Martin's service and restoration department. UK production is now concentrated at Gaydon on the former RAF V-bomber airfield. In March 2008 Aston Martin announced a partnership with Magna Steyr to outsource manufacture of over 2,000 cars annually to Graz, Austria, reassuringly stating: \"The continuing growth and success of Aston Martin is based upon Gaydon as the focal point and heart of the business, with the design and engineering of all Aston Martin products continuing to be carried out there.\"\n\nMore dealers in Europe and the new pair in China brought the total to 120 in 28 countries.\n\nOn 1 September 2008, Aston Martin announced the revival of the Lagonda marque, proposing a concept to be shown in 2009 to coincide with the brand's 100th anniversary. The first production cars are slated for 2012.\n\nIn December 2008, Aston Martin announced it would cut its workforce from 1,850 to 1,250.\n\nThe first four-door Aston Martin Rapide sports cars rolled out of the Magna Steyr factory in Graz, Austria in 2010. The contract manufacturer provides dedicated facilities to ensure compliance with the exacting standards of Aston Martin and other marques, including Mercedes-Benz. Ulrich Bez has publicly speculated about outsourcing all of Aston Martin's operations with the exception of marketing. In September 2011 it was announced Rapide production would be returned to Gaydon in the second half of 2012, restoring all manufacture there.\n\nIn late 2012, Investment Dar reviewed its stake, with Mahindra & Mahindra emerging as a potential bidder for as much as half of Aston Martin. Instead, Italian private equity fund Investindustrial signed a deal on 6 December 2012 to buy 37.5% of Aston Martin, investing £150 million as a capital increase. This was confirmed by Aston Martin in a press release on 7 December 2012. In April 2013 it was reported that Dr Ulrich Bez would be leaving his role as chief executive officer to take up a more ambassadorial position widely seen as the first move by the new shareholders in reviewing the leadership and strategy of Aston Martin. On 2 September 2014, Aston Martin announced it had appointed the Nissan executive Andy Palmer as CEO with Ulrich Bez retaining a position as non-executive chairman. As sales had been declining, from 2015 Aston Martin sought new customers (particularly wealthy female buyers) with cars like Lagonda and DBX while releasing concept cars like the Vulcan. According to Palmer, the troubles started when sales of the DB9 failed to generate sufficient fund to develop next-generation models which led to a downward spiral of declining sales and profitability.\n\nIn 2014, Aston Martin suffered a pre-tax loss of £72 million, almost triple that of 2013 selling 3,500 cars during the year, well below 7,300 sold in 2007 and 4,200 sold in 2013. In March 2014 Aston Martin issued “payment in kind” notes of US$165 million, at 10.25% interest, in addition to the £304 million of senior secured notes at 9.25% issued in 2011. Aston Martin also had to secure an additional investment of £200 million from its shareholders to fund development of new models.\nIt is reported that Aston Martin's pre-tax losses for 2016 increased by 27% to £162.8 million, the sixth year it continued to suffer a loss.\n\nIn 2013 Aston Martin signed a deal with Daimler AG to supply the next generation Aston Martin cars with new Mercedes-AMG engines. Daimler AG now owns 5% of Aston Martin. Mercedes-AMG will also supply Aston Martin with electrical systems. This technical partnership will support Aston Martin’s launch of a new generation of models that will incorporate new technology and V8s. The first model to sport Mercedes technology is the DB11, announced at the 2016 Geneva Motor, sporting Mercedes electronics for the entertainment, navigation and other systems.\n\n\n\nAston Martin sponsors 2. Bundesliga club 1860 Munich.\n\n\n"}
{"id": "2371", "url": "https://en.wikipedia.org/wiki?curid=2371", "title": "Albert Pike", "text": "Albert Pike\n\nAlbert Pike (December 29, 1809 – April 2, 1891) was an attorney, soldier, writer, and Freemason. Albert Pike is the only Confederate military officer with an outdoor statue in Washington, D.C.\n\nPike was born in Boston, Massachusetts, the son of Ben and Sarah (Andrews) Pike, and spent his childhood in Byfield and Newburyport, Massachusetts. His colonial ancestors settled the area in 1635, and included John Pike (1613–1688/1689), the founder of Woodbridge, New Jersey. He attended school in Newburyport and Framingham until he was 15. In August 1825, he passed entrance exams at Harvard University, though when the college requested payment of tuition fees for the first two years he chose not to attend. He began a program of self-education, later becoming a schoolteacher in Gloucester, North Bedford, Fairhaven and Newburyport.\n\nPike was an imposing figure; six feet tall and 300 pounds with hair that reached his shoulders and a long beard. In 1831, he left Massachusetts to travel west, first stopping in Nashville, Tennessee and later moving on to St. Louis, Missouri. There he joined an expedition to Taos, New Mexico, hunting and trading. During the excursion his horse broke and ran, forcing Pike to walk the remaining 500 miles to Taos. After this he joined a trapping expedition to the Llano Estacado in New Mexico and Texas. Trapping was minimal and, after traveling about 1,300 miles (650 on foot), he finally arrived at Fort Smith, Arkansas.\n\nSettling in Arkansas in 1833, Pike taught in a school and wrote a series of articles for the Little Rock \"Arkansas Advocate\" under the pen name of \"Casca.\" The articles were popular enough that he was asked to join the newspaper's staff. After marrying Mary Ann Hamilton in 1834, he purchased the newspaper. Under Pike's administration the \"Advocate\" promoted the viewpoint of the Whig Party in a politically volatile and divided Arkansas December 1832.\n\nHe was the first reporter for the Arkansas Supreme Court and also wrote a book (published anonymously), titled \"The Arkansas Form Book\", which was a guidebook for lawyers. Pike then began to study law and was admitted to the bar in 1837, selling the \"Advocate\" the same year. He also made several contacts among the Native American tribes in the area. He specialized in claims on behalf of Native Americans against the federal government. In 1852 he represented Creek Nation before the Supreme Court in a claim regarding ceded tribal land. In 1854 he advocated for the Choctaw and Chickasaw although compensation later awarded to the tribes in 1856 and 1857 was insufficient. These relationships were to influence the course of his Civil War service.\n\nAdditionally, Pike wrote on several legal subjects and continued producing poetry, a hobby he had begun in his youth in Massachusetts. His poems were highly regarded in his day, but are now mostly forgotten. Several volumes of his works were privately published posthumously by his daughter. In 1859, he received an honorary Master of Arts degree from Harvard.\n\nWhen the Mexican–American War started, Pike joined the Regiment of Arkansas Mounted Volunteers (a cavalry regiment) and was commissioned as a troop commander with the rank of captain in June 1846. With his regiment, he fought in the Battle of Buena Vista. Pike was discharged in June 1847. He and his commander, Colonel John Selden Roane, had several differences of opinion. This situation led finally to an \"inconclusive\" duel between Pike and Roane on July 29, 1847 near Fort Smith, Arkansas. Although several shots were fired in the duel, nobody was injured, and the two were persuaded by their seconds to discontinue it.\n\nAfter the war, Pike returned to the practice of law, moving to New Orleans for a time beginning in 1853. He wrote another book, \"Maxims of the Roman Law and some of the Ancient French Law, as Expounded and Applied in Doctrine and Jurisprudence\". Although unpublished, this book increased his reputation among his associates in law. He returned to Arkansas in 1857, gaining some amount of prominence in the legal field and becoming an advocate of slavery, although retaining his affiliation with the Whig Party.\n\nIn 1847 Pike became disillusioned when the Whig Party refused to take a stand on slavery. At the Southern Commercial Convention of 1854, Pike said the South should remain in the Union and seek equality with the North, but if the South \"were forced into an inferior status, she would be better out of the Union than in it.\" His anti-Catholicism stand led him to join the Know Nothing movement when it was organized in 1856, but was again disappointed when it refused to adopt a strong pro-slavery platform. He joined the other Southern delegates and walked out of the convention. His stand was that state's rights superseded national law and supported the idea of a Southern secession. This stand is made clear in his pamphlet of 1861, \"State or Province, Bond or Free?\"\n\nIn 1861 Pike penned the lyrics to \"Dixie to Arms!\". At the beginning of the war, Pike was appointed as Confederate envoy to the Native Americans. In this capacity he negotiated several treaties, one of the most important being with Cherokee chief John Ross, which was concluded in 1861.\n\nPike was commissioned as a brigadier general on November 22, 1861, and given a command in the Indian Territory. With Gen. Ben McCulloch, Pike trained three Confederate regiments of Indian cavalry, most of whom belonged to the \"civilized tribes\", whose loyalty to the Confederacy was variable. Although initially victorious at the Battle of Pea Ridge (Elkhorn Tavern) in March 1862, Pike's unit was defeated later in a counterattack, after falling into disarray. When Pike was ordered to send troops to Arkansas in May 1862, he resigned in protest. As in the previous war, Pike came into conflict with his superior officers, at one time drafting a letter to Jefferson Davis complaining about his direct superior.\n\nAfter Pea Ridge, Pike was faced with charges that his troops had scalped soldiers in the field. Maj. Gen. Thomas C. Hindman also charged Pike with mishandling of money and material, ordering his arrest. Both these charges were later found to be considerably lacking in evidence; nevertheless Pike, facing arrest, escaped into the hills of Arkansas, sending his resignation from the Confederate States Army on July 12. He was at length arrested on November 3 under charges of insubordination and treason, and held briefly in Warren, Texas, but his resignation was accepted on November 11 and he was allowed to return to Arkansas.\n\nPike first joined the Independent Order of Odd Fellows in 1840, and he had then joined a Masonic Lodge, where he became extremely active in the affairs of the organization, being elected Sovereign Grand Commander of the Scottish Rite's Southern Jurisdiction in 1859. He remained Sovereign Grand Commander for the remainder of his life (a total of thirty-two years), devoting a large amount of his time to developing the rituals of the order. Notably, he published a book called \"Morals and Dogma of the Ancient and Accepted Scottish Rite of Freemasonry\" in 1871, of which there were several subsequent editions.\n\nIn America, Pike is still considered an eminent and influential Freemason, primarily in the Scottish Rite Southern Jurisdiction.\n\nPike died in Washington, D.C., at the age of 81, and was buried at Oak Hill Cemetery. Burial was against his wishes; he had left instructions for his body to be cremated. In 1944, his remains were moved to the House of the Temple, headquarters of the Southern Jurisdiction of the Scottish Rite. A memorial to Pike is located in the Judiciary Square neighborhood of Washington, D.C.\n\nThe Albert Pike Memorial Temple is an historic Masonic lodge in Little Rock, Arkansas listed on the National Register of Historic Places.\n\nAs a young man, Pike wrote poetry and he continued to do so for the rest of his life. At 23, he published his first poem, “Hymns to the Gods.” Later work was printed in literary journals like Blackwood’s \"Edinburgh Magazine\" and local newspapers. His first collection of poetry, \"Prose Sketches and Poems Written in the Western Country\", appeared in 1834. He later gathered many of his poems and republished them in \"Hymns to the Gods and Other Poems\" (1872). After his death these appeared again in \"Gen. Albert Pike’s Poems\" (1900) and \"Lyrics and Love Songs\" (1916).\n\n\n\n\nMy Personal Views On Pike's Morals and Dogma masonicme.com\n"}
{"id": "2372", "url": "https://en.wikipedia.org/wiki?curid=2372", "title": "ALF Tales", "text": "ALF Tales\n\nALF Tales is a 30-minute Saturday morning animated series that aired on NBC from September 10, 1988 to December 9, 1989. The show is a spin-off of \"\" which featured characters from that series play various characters from fairy tales. The fairy tale was usually altered for comedic effect in a manner akin to Fractured Fairy Tales.\n\nEach story typically spoofs a film genre, such as the \"Cinderella\" episode done as an Elvis movie. Some episodes featured a \"fourth wall\" effect where ALF is backstage preparing for the episode, and Rob Cowan would appear drawn as a TV executive (who introduced himself as \"Roger Cowan, network executive\") to try to brief ALF on how to improve this episode. For instance Cowan once told ALF who was readying for a medieval themed episode that \"less than 2% of our audience lives in the Dark Ages\".\n\n\nThe first seven episodes were released on DVD on May 30, 2006 in Region 1 from Lions Gate Home Entertainment in a single-disc release entitled \"ALF and The Beanstalk and Other Classic Fairy Tales\".\n\n"}
{"id": "2376", "url": "https://en.wikipedia.org/wiki?curid=2376", "title": "Abdul Rashid Dostum", "text": "Abdul Rashid Dostum\n\nAbdul Rashid Dostum ( ; Persian: عبدالرشید دوستم) (born 1954) is an Afghan politician who has served as Vice President of Afghanistan since 2014. He is an ethnic Uzbek, former warlord and general, previously part of the leadership council of the National Front of Afghanistan along with Ahmad Zia Massoud and Mohammad Mohaqiq, as well as chairman of his own political party, Junbish-e Milli-yi Islami-yi Afghanistan (National Islamic Movement of Afghanistan). He also served in the past as Chairman Joint Chiefs of Staff of the Afghan National Army, a role often viewed as ceremonial.\n\nDuring the Soviet war in Afghanistan, Dostum was a general in the Afghan army. He later became an independent warlord and leader of Afghanistan's Uzbek community. He participated in battles against the Mujahideen fighters in the 1980s as well as against the Taliban in the 1990s. After the fall of the Taliban, he mainly resided in Turkey before returning to the country. In 2013 he made a public apology for his role in the civil war. He subsequently entered parliament, and later joined Ashraf Ghani's presidential administration as a vice president.\n\nDostum was born in 1954 in Khwaja du koh, Jowzjan Province, Afghanistan. Coming from an impoverished family, he received a very basic traditional education as he was forced to drop out of school at a young age. From there, he took up work in the gas fields.\n\nDostum began working in 1970 in a state-owned gas refinery in Sheberghan, participating in union politics, as the new government started to arm the staff of the workers in the oil and gas refineries. The reason for this was to create \"groups for the defense of the revolution\". Because of the new communist ideas entering Afghanistan in the 1970s, he enlisted in the army in 1978. Dostum received his basic military training in Jalalabad. His squadron was deployed in the rural areas around Sheberghan, under the auspices of the Ministry of National Security.\n\nBy the mid-1980s he commanded around 20,000 militia men and controlled the northern provinces of Afghanistan. While the unit recruited throughout Jowzjan and had a relatively broad base, many of its early troops and commanders came from Dostum's home village. He left the army after the purge of Parchamis, but returned after the Soviet occupation began.\n\nDuring the Soviet war in Afghanistan, Dostum was commanding a militia battalion to fight and rout mujahideen forces; he had been appointed an officer due to prior military experience. This eventually became a regiment and later became incorporated into the defense forces as the 53rd Infantry Division. Dostum and his new division reported directly to President Mohammad Najibullah. Later on he became the commander of the military unit 374 in Jowzjan. He defended the Soviet-backed Afghan government against the mujahideen forces throughout the 1980s. While he was only a regional commander, he had largely raised his forces by himself. The Jowzjani militia Dostum controlled was one of the few in the country which was able to be deployed outside its own region. They were deployed in Kandahar in 1988 when Soviet forces were withdrawing from Afghanistan.\n\nDostum's men would become an important force in the fall of Kabul in 1992. In April 1992, the opposition forces began their march to Kabul against the government of Najibullah. Dostum had allied himself with the opposition commanders Ahmad Shah Massoud and Sayed Jafar Naderi, the head of the Isma'ili community, and together they captured the capital city. He and Massoud fought in a coalition against Gulbuddin Hekmatyar. Massoud and Dostum's forces joined together to defend Kabul against Hekmatyar, with some 4000-5000 of his troops, units of his Shiberghan-based 53rd Division and Balkh-based Guards Division, garrisoning Bala Hissar fort, Maranjan Hill, and Khwaja Rawash International Airport. In 1994, Dostum allied himself with Gulbuddin Hekmatyar against the government of Burhanuddin Rabbani and Ahmad Shah Massoud.\n\nFollowing the rise of the Taliban and their capture of Kabul, Dostum aligned himself with the Northern Alliance (United Front) against the Taliban. He stationed his troops in the city of Mazar-e-Sharif. The Northern Alliance was assembled in late 1996 by Dostum, Massoud and Karim Khalili against the Taliban. At this point he is said to have had a force of some 50,000 men supported by both aircraft and tanks. He ruled what was, in effect, an independent region. He printed his own Afghan currency and ran a small airline named Balkh Air.\n\nMuch like other northern alliance leaders, Dostum also faced infighting within his group and was later forced to surrender his power to General Abdul Malik Pahlawan. Malik entered into secret negotiations with the Taliban, who promised to respect his authority over much of northern Afghanistan, in exchange for the apprehension of Ismail Khan, one of their enemies. Accordingly, on 25 May 1997 Malik arrested Khan, handed him over and let the Taliban enter Mazar-e-Sharif, giving them control over most of northern Afghanistan. Because of this, Dostum was forced to flee to Turkey. However, Malik soon realized that the Taliban were not sincere with their promises as he saw his men being disarmed. He then rejoined the Northern Alliance, and turned against his erstwhile allies, driving them from Mazar-e-Sharif. In October 1997, Dostum returned from exile and retook charge. After Dostum briefly regained control of Mazar-e-Sharif, the Taliban returned in 1998 and he again fled to Turkey.\n\nDostum returned to Afghanistan in October 2001 to join the U.S.-led campaign against the Taliban. Along with General Fahim, Ismail Khan and Mohammad Mohaqiq. In November 2001, with the beginning of the U.S. invasion of Afghanistan, and against the wishes of the CIA who distrusted Dostum, a team including Johnny Micheal Spann landed to set up communications in the Dar-e-Suf. A few hours later 23 men of Operational Detachment Alpha (ODA) 595 landed to begin the war.\n\nOn 24 November 2001, 300 Taliban soldiers retreated after the Siege of Kunduz by American and Northern Alliance. The Taliban laid down their weapons a few miles from the city of Mazar-i-Sharif. They eventually surrendered to Dostum. A small group of armed foreign fighters were transferred to the 19th century prison fortress, Qala-i-Jangi. The Taliban used concealed weapons to start the Battle of Qala-i-Jangi against the opposition forces. The uprising was eventually brought under control.\n\nIn late 2001, Carlotta Gall, Jamie Doran and Newsweek began reporting rumors that Dostum's forces, who were fighting the Taliban alongside the US Special Forces, intentionally suffocated as many as 2,000 Taliban prisoners in container trucks in an ill-defined incident that has become known as the Dasht-i-Leili massacre. In July 2009, \"The New York Times\" reported that according to anonymous witnesses they interviewed, \"over a three-day period, Taliban prisoners were stuffed into closed metal shipping containers and given no food or water; many suffocated while being trucked to the prison. Other prisoners were killed when guards shot into the containers. The bodies were said to have been buried in a mass grave in Dasht-i-Leili, a stretch of desert just outside Sheberghan. A 2002 declassified U.S. State Department intelligence report quoting a news source states that another anonymous source concluded that about 1,500 Taliban prisoners died. Estimates from other anonymous witnesses or from a report by Physicians for Human Rights range from several hundred to several thousand. The report also says that several Afghan witnesses were later tortured or killed.\" Dostum, the Red Cross and eyewitnesses in the prison claimed that only 200 taliban prisoners died from wounds or sickness. Physicians for Human Rights claims there is satellite evidence that graves had been dug up but no investigation was done despite Dostum inviting the UN to investigate. No formal investigation was conducted and an official website of General Dostum using eyewitnesses who go on the record lays out a timeline of events that debunk the allegations. The foundation of the controversy lay in confusion in estimating the number of Taliban that possibly joined the Northern Alliance or simply returned to their villages after the Kunduz surrender. According to the biography \"The Last Warlord, The Life and Times of General Dostum written by Professor Brian Williams, General Dostum has been the target of a number of sensational claims that were later debunked. Among them was the famous claim in Ahmed Rashid's book \"The Taliban\" that describes a tank was used to crush a thief. Ahmed Rashid corrects what turns out to be a second hand story in William's book and provides first person description of events that directly contradict the rumors.\n\nIn the aftermath of Taliban's removal from northern Afghanistan, forces loyal to Dostum frequently clashed with Tajik forces loyal to Atta Muhammad Nur. Atta's men kidnapped and killed a number of Dostum's men, and constantly agitated to gain control of Mazar-e-Sharif. Through the political mediations of the Karzai administration, the International Security Assistance Force (ISAF) and the United Nations, the Dostum-Atta feud has gradually declined.\n\nDostum served as deputy defense minister the early period of the Karzai administration. In March 2003, he established a North Zone of Afghanistan. On 20 May 2003, Dostum narrowly escaped an assassination attempt. He was often residing outside Afghanistan, mainly in Turkey.\n\nOn 16 August 2009, Dostum made a requested return from exile to Afghanistan to support President Hamid Karzai in his bid for re-election. He later flew by helicopter to his northern stronghold of Sheberghan, where he was greeted by thousands of his supporters in the local stadium. He subsequently made overtures to the United States, promising he could \"destroy the Taliban and al Qaeda\" if supported by the U.S., saying that \"the U.S. needs strong friends like Dostum.\"\n\nDostum became Vice President of Afghanistan in the 2014 Afghan presidential election. His running mates were Ashraf Ghani and Sarwar Danish.\n\nIn July 2016 Human Rights Watch accused Abdul Rashid Dostum's National Islamic Movement of Afghanistan of killing, abusing and looting civilians in the northern Faryab Province during June. Militia forces loyal to Dostum stated that the civilians they targeted - at least 13 killed and 32 wounded - were supporters of the Taliban.\n\nSome media reports stated earlier that Dostum was \"seeking political asylum\" in Turkey while others said he was exiled. One Turkish media outlet said Dostum was visiting after flying there with then Turkey's Foreign Minister Ali Babacan during a meeting of the Organization for Security and Cooperation in Europe (OSCE).\n\nWhile Dostum was ruling northern Afghanistan before the Taliban took over in 1998, women were able to go about unveiled, girls were allowed to go to school and study at the University of Balkh in Mazar-e-Sharif, cinemas showed Indian films and music played on television, activities which were all banned by the Taliban.\n\nHe viewed the ISAF forces attempt to crush the Taliban as ineffective and has gone on record saying that he could mop up the Taliban \"in six months\" if allowed to raise a 10,000 strong army of Afghan veterans. Senior Afghan government officials do not trust Dostum as they are concerned that he might be secretly rearming his forces.\n\nDostum is barred from entering the U.S.\n\n\n"}
{"id": "2377", "url": "https://en.wikipedia.org/wiki?curid=2377", "title": "Andhra Pradesh", "text": "Andhra Pradesh\n\nAndhra Pradesh () () is one of the 29 states of India, situated on the southeastern coast of the country. The state is the seventh largest state in India covering an area of . As per 2011 Census of India, the state is tenth largest by population with 49,386,799 inhabitants.\n\nOn 2 June 2014, the north-western portion of the state was bifurcated to form a new state of Telangana. Andhra Pradesh's longtime capital, Hyderabad, was transferred to Telangana as part of the division. However, in accordance with the Andhra Pradesh Reorganisation Act, 2014, Hyderabad will remain the \"de jure\" capital of both Andhra Pradesh and Telangana states for a period of time not exceeding 10 years. The new riverfront proposed capital in Guntur district is Amaravati, which is under the jurisdiction of APCRDA. The Gross State Domestic Product (GSDP) of the state in the 2016–2017 financial year at current prices stood at .\n\nThe state has a coastline of with jurisdiction over nearly 15,000 km territorial waters, the second longest among all the states of India after Gujarat. It is bordered by Telangana in the north-west, Chhattisgarh in the north, Odisha in the north-east, Karnataka in the west, Tamil Nadu in the south and the water body of Bay of Bengal in the east. A small enclave of of Yanam, a district of Puducherry, lies south of Kakinada in the Godavari delta to the east of the state.\n\nAndhra Pradesh is composed of two regions: Coastal Andhra, located along the Bay of Bengal, and Rayalaseema, in the inland southwestern part of the state. These two regions comprise 13 districts, with 9 in Coastal Andhra and 4 in Rayalaseema. Visakhapatnam, located on the Bay of Bengal in North Coastal Andhra is the largest city and commercial hub of the state with a GDP of $26 billion, followed in population and GDP by Vijayawada, which is located on the Krishna River and which has a GDP of $3 billion as of 2010.\n\nAndhra Pradesh hosted 121.8 million visitors in 2015, a 30% growth in tourist arrivals over the previous year. The Tirumala Venkateswara Temple in Tirupati is one of the world's most visited religious sites, with 18.25 million visitors per year. Other pilgrimage centers in Andhra Pradesh include the Mahachaitya at Amaravathi, and the Kanaka Durga Temple in Vijayawada, while the state's natural attractions include the beaches of Visakhapatnam, hill stations such as the Araku Valley and Horsley Hills, and the island of Konaseema in the Godavari River delta.\n\nA tribe named Andhra has been mentioned in the Sanskrit texts such as Aitareya Brahmana (800-500 BCE). According to \"Aitareya Brahmana\" of the Rig Veda, the Andhras left north India and settled in south India. The Satavahanas have been mentioned by the names \"Andhra\", \"Andhrara-jatiya\" and \"Andhrabhrtya\" in the Puranic literature. They did not refer themselves as \"Andhra\" in any of their coins or inscriptions; it could be possible that they were termed as \"Andhras\" because of their ethnicity or because their territory included the Andhra region.\n\nArchaeological evidence from places such as Amaravati, Dharanikota and Vaddamanu suggests that the Andhra region was part of the Mauryan Empire. Amaravati might have been a regional centre for the Mauryan rule. After the death of emperor Ashoka, the Mauryan rule weakened around 200 BCE, and was replaced by several smaller kingdoms in the Andhra region.\n\nThe Satavahana dynasty dominated the Deccan region from the 1st century BC to the 3rd century. The later Satavahanas made Dharanikota and Amaravathi as their capital, which according to the Buddhists is the place where Nagarjuna, the philosopher of Mahayana lived in the 2nd and 3rd centuries. The Andhra Ikshvakus with their capital at Vijayapuri, succeeded the Satavahanas in the Krishna River valley in the later half of the 2nd century. Pallavas, who were originally executive officers under the Satavahana kings, were not a recognised political power before the 2nd century AD and were swept by the Western Chalukyan invasion, led by Pulakesin II in the first quarter of the seventh century AD. After the downfall of the Ikshvakus, the Vishnukundinas were the first great dynasty in the 5th and 6th centuries with, which held sway way over the entire Andhra country including Kalinga and parts of Telangana. They played an important and imperial role in the history of Deccan during the 5th and 6th century AD, with Eluru, Amaravathi and Puranisangam.\n\nThe Salankayanas were an ancient dynasty that ruled the Andhra region between Godavari and Krishna with their capital as Vengi, modern Pedavegi from 300 to 440 AD. The Eastern Chalukyas of Vengi, whose dynasty lasted for around 500 years from the 7th century until 1130 C.E., got merged with the Chola empire. They continued to rule under the protection of the Chola empire until 1189 C.E., when the kingdom succumbed to the Hoysalas and the Yadavas. The roots of the Telugu language have been seen on inscriptions found near the Guntur district and from others dating to the rule of Renati Cholas in the fifth century CE.\n\nThe Reddy dynasty (1325–1448 CE) was established by Prolaya Vema Reddi in the early 14th century, who ruled the present day from Visakhapatnam in the north to Kanchipuram in the south. Prolaya Vema Reddi was part of the confederation of states that started a movement against the invading Turkic Muslim armies of the Delhi Sultanate in 1323 CE and succeeded in repulsing them from Warangal. They constructed Kondaveedu Fort and was ruled by them between 1328–1428 and then taken over by Gajpathis of Orissa, later ravaged by the Muslim rulers of the Bahmani kingdom in 1458. The Vijayanagara emperor Krishnadevaraya captured it in 1516. The Golconda Sultans fought for the fort in 1531, 1536 and 1579, and Sultan Quli Qutb Shah captured it in 1579, renaming it \"Murtuzanagar\". Again it was reconquered by Vijayanagarans who overthrew sultnate rule from the entire modern day Andhra Pradesh excluding Telangana. Even after the resolution of Vijayanagarans none of Bahmani sultans didn't dare for any military compaigns outside their kingdoms as Marathas soon emerged the mightiest power in India. Efforts are in progress to classify Kondaveedu Fort as a UNESCO World Heritage Site.\n\nThe Vijayanagara Empire was originated in the Deccan Plateau region in the early 14th century. It was established in 1336 by Harihara Raya I and his brother Bukka Raya I of Sangama Dynasty. The empire's patronage enabled fine arts and literature to reach new heights in Kannada, Telugu, Tamil and Sanskrit, while Carnatic music evolved into its current form.\n\nInspired by their success, the Vijayanagara Empire, one of the greatest empires in the history of Andhra Pradesh and India, was founded by Harihara and Bukka, who served as treasury officers of the Kakatiyas of Warangal. In 1347 CE, an independent Muslim state, the Bahmani Sultanate, was established in south India by Ala-ud-Din Bahman Shah in a revolt against the Delhi Sultanate. The Qutb Shahi dynasty held sway over the Andhra country for about two hundred years from the early part of the sixteenth century to the end of the seventeenth century.\n\nIn the early 19th century, Northern Circars was ceded and it became part of the British East India company held Madras Presidency. Eventually this region emerged as the Coastal Andhra region. Later the Nizam rulers of Hyderabad ceded five territories to the British which eventually emerged as Rayalaseema region. The Nizams retained control of the interior provinces as the princely state of Hyderabad, acknowledging British rule in return for local autonomy. However, Komaram Bheem, a tribal leader, started his fight against the erstwhile Asaf Jahi Dynasty for the liberation of Hyderabad State. Meanwhile, the French occupied Yanam, in the Godavari delta, and (save for periods of British control) would hold it until 1954. In 1947 Vizianagaram was the largest Hindu Princely state in Andhra Pradesh.\n\nIndia became independent from the United Kingdom in 1947. The Nizam wanted to retain the independence of the Princely Hyderabad State from India, but the people of the region launched a movement to join the Indian Union. The state of Hyderabad was forcibly joined to the Republic of India with Operation Polo in 1948.\n\nIn an effort to gain an independent state based on linguistic basis and to protect the interests of the Telugu-speaking people of Madras State, Potti Sreeramulu fasted until death in 1952. As Madras became a bone of contention, in 1949 a JVP committee report stated \"Andhra Province could be formed provided the Andhras give up their claim on the city of Madras (now Chennai)\". After Potti Sreeramulu's death, the Telugu-speaking areas, i.e. Andhra State, was carved out of Madras State on 1 October 1953, with Kurnool as its capital city. On the basis of a gentlemen's agreement of 1 November 1956, the States Reorganisation Act formed Andhra Pradesh by merging Andhra State with the Telugu-speaking areas of the already existing Hyderabad State. Hyderabad was made the capital of the new state. The Marathi-speaking areas of Hyderabad State merged with Bombay State and the Kannada-speaking areas were merged with Mysore state.\n\nIn February 2014, the Andhra Pradesh Reorganisation Act, 2014 bill was passed by the Parliament of India for the formation of Telangana state comprising ten districts. Hyderabad will remain as a joint capital for not exceeding 10 years. The new state of Telangana came into existence on 2 June 2014 after approval from the President of India.\n\nThe state has varied topography ranging from the hills of Eastern Ghats and Nallamala Hills to the shores of Bay of Bengal that supports varied ecosystems, rich diversity of flora and fauna. There are two main rivers namely, Krishna and Godavari, that flow through the state. The seacoast of the state extends along the Bay of Bengal from Srikakulam to Nellore district. The plains to the east of Eastern Ghats form the Eastern coastal plains. The coastal plains are for the most part of delta regions formed by the Godavari, Krishna, and Penner Rivers. The Eastern Ghats are discontinuous and individual sections have local names. The Eastern Ghats are a major dividing line in the state's geography. The Kadapa Basin formed by two arching branches of the Eastern Ghats is a mineral-rich area. The Ghats become more pronounced towards the south and extreme north of the coast. Most of the coastal plains are put to intense agricultural use. The Rayalaseema region has semi-arid conditions.\n\n\"Andhra Pradesh Forest Department\" deals with protection, conservation and management of forests. The total forest cover of the state after the bifurcation is left with an area of 22,862 km. The forest in the state can be broadly divided into four major biotic provinces. They are:\n\nEastern Ghats region is home to dense tropical forests, while the vegetation becomes sparse as the Ghats give way to the Deccan Plateau, where shrub vegetation is more common. The vegetation found in the state is largely of dry deciduous types with a mixture of teak, \"Terminalia\", \"Dalbergia\", \"Pterocarpus\", \"Anogeissus\", etc.\n\nThe state has many Sanctuaries, National Parks and Zoological Parks such as, Coringa, Krishna Wildlife Sanctuary, Nagarjunsagar-Srisailam Tiger Reserve, Kambalakonda Wildlife Sanctuary, Sri Venkateswara Zoological Park, Indira Gandhi Zoological Park etc. Atapaka Bird Sanctuary, Nelapattu Bird Sanctuary and Pulicat Lake Bird Sanctuary attracts many migratory birds.\nThe state possesses some rare and endemic plants like \"Cycas beddomei\", \"Pterocarpus santalinus\", \"Terminalia pallida\", \"Syzygium alternifolium\", \"Shorea talura\", \"Shorea tumburgia\", \"Psilotum nudum\", etc. The diversity of fauna includes tigers, panthers, hyenas, black bucks, cheetals, sambars, sea turtles and a number of birds and reptiles. The estuaries of river Godavari and Krishna support rich mangrove forests with fishing cats and otters as keystone species.\n\nThe climate of Andhra Pradesh varies considerably, depending on the geographical region. Summers last from March to June. In the coastal plain, the summer temperatures are generally higher than the rest of the state, with temperature ranging between 20 °C and 41 °C. July to September is the season for tropical rains. About one third of the total rainfall is brought by the northeast monsoon. October and November see low-pressure systems and tropical cyclones form in the Bay of Bengal which, along with the northeast monsoon, bring rains to the southern and coastal regions of the state.\n\nNovember, December, January, and February are the winter months in Andhra Pradesh. Since the state has a long coastal belt the winters are not very cold. The range of winter temperature is generally 12 °C to 30 °C. Lambasingi in Visakhapatnam district is the only place in South India which receives snowfall because of its location as at above the sea level. It is also nicknamed as the \"Kashmir of Andhra Pradesh\" and the temperature ranges from 0 °C to 10 °C.\n\n Census of India, the state had a population of with a population density of . The total population constitute, 70.4% of rural population with inhabitants and 29.6% of urban population with inhabitants. Children in the age group of 0–6 years are , constituting 10.6% of the total population, among them are boys and are girls. Visakhapatnam district has the largest urban population of 47.5% and Srikakulam district with 83.8%, has the largest rural population, among others districts in the state. The overall population of the state comprises 17.1% of Scheduled Caste and 5.3% of Scheduled Tribe population.\n\nThere are male and female citizens—a sex ratio of 996 females per 1000 males, higher than the national average of 926 per 1000. The literacy rate of the state stands at 67.41%. West Godavari district has the highest literacy rate of 74.6% and Vizianagaram district has the least with 58.9%.\n\nAndhra Pradesh ranks tenth of all Indian States in the Human Development Index scores with a score of 0.416. The National Council of Applied Economic Research district analysis in 2001 reveals that Krishna, West Godavari and Chittoor are the three districts in rural AP with the highest Human Development Index scores in ascending order.\n\nThe official language of Andhra Pradesh is Telugu. The Minister of Tourism and Culture has issued a declaration of the Telugu language as a Classical Language.\n\nMajority of the people in Andhra Pradesh are Hindus while Muslims constitute a sizeable minority. According to the 2011 census, the major religious groups in the state are Hindus (90.87%), Muslims (7.32%) and Christians (1.38%). Buddhists, Sikhs, Jains & the people who declined to state their religion make up the remaining portion of population.\nAndhra Pradesh is home to Shankaracharya of Pushpagiri Peetham. Other Hindu saints include Sadasiva Brahmendra, Bhaktha Kannappa, Yogi Vemana, Yogi Sri Potuluri Virabrahmendra Swami.\n\n\nBuddhism spread to Andhra Pradesh early in its history. The Krishna River valley was \"a site of extraordinary Buddhist activity for almost a thousand years.\" The ancient Buddhist sites in the lower Krishna Valley, including Amaravati, Nagarjunakonda and Jaggayyapeta \"can be traced to at least the third century BCE, if not earlier.\"\n\nThe region played a central role in the development of Mahayana-buddhism, along with the Magadha-area in northeastern India. A.K. Warder holds that \"the Mahāyāna originated in the south of India and almost certainly in the Andhra country.\" According to Xing, \"Several scholars have suggested that the Prajnaparamita probably developed among the Mahasamghikas in Southern India probably in the Andhra country, on the Krishna River.\" The Prajñāpāramitā Sutras belong to the earliest Mahayana Sutras.\n\nRegions:\n\nHitherto, it comprised two regions: Northern Circars and Ceded districts. Now, the state comprises two regions:\n\nDistricts:\n\nIt has a total of 13 districts, nine in Kosta and four in Rayalaseema.\n\nRevenue divisions:\n\nThese 13 districts are further divided into 50 revenue divisions\nThere are as many as 7 revenue divisions in East Godavari district and only 2 in Vizianagaram district.\n\nMandals:\n\nThe 50 revenue divisions are in turn divided into 670 mandals. Chittoor district has the most number of mandals with 66 and Vizianagaram district has the least with 34.\n\nCities:\n\nThere are a total of 31 cities which include, 16 municipal corporations and 14 municipalities. There are two million plus cities namely, Visakhapatnam and Vijayawada.\n\nLegislative Assembly of Andhra Pradesh is the lower house of the state and legislative council of andhra pradesh is the upper house. with 58 members. In the Parliament of India, Andhra Pradesh has 11 seats in the Rajya Sabha, and 25 seats in the Lok Sabha. There are a total of 175 Assembly constituencies in the state. East Godavari district has the most number of constituencies with 19 and Vizianagaram district has the least with 9 assembly seats. Whereas, the legislative council of the state has 58 seats, which is one-third of total assembly seats.\n\nUntil 1962, the CPI, along with socialist parties namely Praja Socialist Party and Krishi Lok Party played an important role in the 1950s. In the 1967 state assembly elections, all socialist parties were eliminated and CPI lost opposition party status. The first Chief Minister of Andhra Pradesh was Neelam Sanjiva Reddy who later served as President of India.\n\nIn 1983, the Telugu Desam Party (TDP) won the state elections and N.T. Rama Rao became the chief minister of the state for the first time. This broke the long time single party monopoly enjoyed by the INC from 1956 until 1982. Nandamuri Taraka Rama Rao is the founder of Telugu Desam party and served as the first chief minister from the party. The 1989 elections ended the rule of NTR, with the INC party returning to power with Marri Chenna Reddy at the helm. He was replaced by Janardhan Reddy in 1990, who was replaced by Kotla Vijaya Bhaskara Reddy in 1992.\n\nN. Chandrababu Naidu held the record for the longest serving chief minister (1995 to 2004). In 1994, Andhra Pradesh gave a mandate to the Telugu Desam Party again, and NTR became the chief minister again. Nara Chandrababu Naidu, the son-in-law of NTR, came to power with the backing of a majority of the MLAs. The Telugu Desam Party won both the assembly and Lok Sabha election in 1999 under the leadership of Chandrababu Naidu.\n\nIn what would be the last elections held in the unified state, Telugu Desam Party got a mandate in their favour in the residuary (new)state. Nara Chandrababu Naidu, the chief of Telugu Desam Party became Chief Minister on 8 June 2014, for the new state of Andhra Pradesh.\n\nAndhra Pradesh was ranked eighth among other Indian states in terms of GSDP for the financial year 2014–2015. The GSDP at current prices was and at constant prices was . The domestic product of agriculture sector accounts for and Industrial sector for . The service sector of the state accounts more percentage of the GSDP with a total of . In the 2010 list by \"Forbes\" magazine, there were several from Andhra Pradesh among the top 100 richest Indians.\n\nAndhra Pradesh economy is mainly based on agriculture and livestock. Four important rivers of India, the Godavari, Krishna, Penna, and Thungabhadra flow through the state and provide irrigation. 60 percent of population is engaged in agriculture and related activities. Rice is the major food crop and staple food of the state. It is an exporter of many agricultural products and is also known as \"Rice Bowl of India\". The state has three Agricultural Economic Zones in Chittoor district for mango pulp and vegetables, Krishna district for mangoes, Guntur district for chilies.\n\nBesides rice, farmers also grow jowar, bajra, maize, minor millet, coarse grain, many varieties of pulses, oil seeds, sugarcane, cotton, chili pepper, mango nuts and tobacco. Crops used for vegetable oil production such as sunflower and peanuts are popular. There are many multi-state irrigation projects under development, including Godavari River Basin Irrigation Projects and Nagarjuna Sagar Dam.\n\nLivestock and poultry is also another profitable business, which involves rearing cattle in enclosed areas for commercial purposes. The state is also a largest producer of eggs in the country and hence, it is nicknamed as \"\"Egg Bowl of Asia\"\".\n\nFisheries contribute 10% of total fish and over 70% of the shrimp production of India. The geographical location of the state allows marine fishing as well as inland fish production. The most exported marine exports include \"Vannamei shrimp\" and are expected to cross $1 billion in 2013–2014.\n\nThe industrial sector of the state includes some of the key sectors like Pharma, Automobile, Textiles etc. Sricity located in Chittoor district is an integrated business city which is home to many renowned firms like PepsiCo, Isuzu Motors, Cadbury India, Kellogg's, Colgate-Palmolive, Kobelco etc. The PepsiCo firm has its largest plant in India at Sri City.\n\nThe state is also emerging in information technology and biotechnology. The IT/ITES revenues of Visakhapatnam is at in 2012–2013. The development of IT in Tier-II and Tier-III cities like Vijayawada, Kakinada and Tirupati is also improving. In the fiscal year 2012–2013, Vijayawada's IT/ITeS revenues were crore. Tirupati with and Kakinada with stand next. For the benefit of state i.e., After separating Telangana from andhra, people of andhra protested for special status during the month of January in 2017\n\nAndhra Pradesh is one of the storehouses of mineral resources in India. Andhra Pradesh with varied geological formations, contain rich and variety of industrial minerals and building stones.\n\nAndhra Pradesh is listed top in the deposit and production of mica in India. Minerals found in the state include limestone, reserves of oil and natural gas, manganese, asbestos, iron ore, ball clay, fire clay, gold diamonds, graphite, dolomite, quartz, tungsten, steatitic, feldspar, silica sand. It has about one third of India's limestone reserves and is known for large exclusive deposits of barytes and galaxy granite in the international market.\n\nMining\n\nMining is identified as one of the growth engines for the overall development of industry and infrastructure. The Tummalapalle Uranium mine in Andhra has confirmed 49,000 tonnes of ore and there are indications that it could hold reserves totalling three times its current size. 700 million tonnes of metal grade Bauxite deposits in proximity to Visakhapatnam Port.\n\nReliance Industries Limited struck nine trillion cubic feet of gas reserves in the KG basin, off the Andhra Pradesh coast near Kakinada. Discovery of large quantity of natural gas in KG Basin is expected to provide rapid economic growth. During the year 2016, nearly 134 trillion cubic feet of methane hydrate deposits were explored in KG basin whose extraction is adequate to impart energy security for many decades to India.\n\nPower plants\n\nThe state is a pioneer nationwide in solar power generation. APGENCO is the power generating company owned by the state. The state has become power surplus with excess power generation being exported to other states.\nThermal (natural gas and coal based) and renewable power plants totalling to 21,000 MW were installed in the state by the year 2015. Local power plants of 9,600 MW capacity only are supplying electricity in the state which includes Simhadri Super Thermal Power Plant (2000 MW) of NTPC, Vizag Thermal Power Station (1040 MW), Rayalaseema Thermal Power Station (1050 MW), Sri Damodaram Sanjeevaiah Thermal Power Station (1600 MW), Vijayawada Thermal Power Plant (1760 MW), etc. Hydel power plants are having a capacity of 1671 MW.\n\nAndhra Pradesh has rich culture and heritage. Kuchipudi, the state dance originated in the village of Kuchipudi in Krishna district, had entered the Guinness World Records for performing \"Mahabrinda Natyam\" with a total of 6,117\ndancers in Vijayawada. It had thirteen geographical indications in categories of agricultural handicrafts, foodstuff and textiles as per \"Geographical Indications of Goods (Registration and Protection) Act, 1999\". It increased to fifteen with the addition of Banaganapalle Mangoes and Bandar laddu. The other GI tagged goods are, Bobbili Veena, Budithi Bell and Brass Craft, Dharmavaram Handloom Pattu Sarees and Paavadas, Guntur Sannam, Kondapalli Toys, Machilipatnam Kalamkari, Mangalagiri Sarees and Fabrics, Srikalahasti Kalamkari, Tirupati Laddu, Uppada Jamdani Sari and Venkatagiri Sari.\n\nMachilipatnam and Srikalahasti Kalamkari are the two unique textile art forms practised in India. There are also other notable handicrafts present in the state, like the soft limestone idol carvings of Durgi. Etikoppaka in Visakhapatnam district is notable for its Lac industry, producing lacquered wooden.\n\nThe state has many museums, which features a varied collection of ancient sculptures, paintings, idols, weapons, cutlery and inscriptions, and religious artifacts such as the Amaravati Archaeological Museum, Visakha Museum and Telugu Cultural Museum in Visakhapatnam displays the history of the pre-Independence and the Victoria Jubilee Museum in Vijayawada with large collection of artifacts.\n\nNannayya, Tikkana and Yerrapragada form the trinity who translated the Sanskrit epic \"Mahabharata\" into Telugu language. Nannayya wrote the first treatise on Telugu grammar called \"Andhra Shabda Chintamani\" in Sanskrit, as there was no grammatical work in Telugu prior to that. Pothana is the poet who composed the classic \"Srimad Maha Bhagavatamu\", a Telugu translation of \"Sri Bhagavatam\". Vemana is notable for his philosophical poems. The Vijayanagara emperor Krishnadevaraya wrote Amuktamalyada. Telugu literature after Kandukuri Veeresalingam is termed as Adhunika Sahityam. He is known as \"Gadya Tikkana\" and was the author of Telugu social novel, \"Satyavati Charitam\". Jnanpith Award winners include Sri Viswanatha Satya Narayana. The Andhra Pradesh native and revolutionary poet Sri Sri brought new forms of expressionism into Telugu literature.\n\nMany composers of Carnatic music like Annamacharya, Kshetrayya, and Bhadrachala Ramadas were of Telugu descent. Modern Carnatic music composers and singers like Ghantasala, Sujatha Puligella and M. Balamuralikrishna are also of Telugu descent. The Telugu film industry hosts many music composers and playback singers such as S. P. Balasubrahmanyam, P. Susheela, S. Janaki, P B Srinivas. Folk songs are popular in the many rural areas of the state. Forms such as the \"Burra katha\" and \"Poli\" are still performed today. \"Harikathaa Kalakshepam (or Harikatha)\" involves the narration of a story, intermingled with various songs relating to the story. Harikatha was originated in Andhra. \"Burra katha\" is an oral storytelling technique with the topic be either a Hindu mythological story or a contemporary social issue. \"Rangasthalam\" is an Indian theatre in the Telugu language, based predominantly in Andhra Pradesh. Gurazada Apparao wrote the play, \"Kanyasulkam\" in 1892, which is often considered the greatest play in the Telugu language. C. Pullaiah is cited as the father of Telugu theatre movement.\n\nThe Telugu film industry had largely shifted from Chennai to Hyderabad. The Telugu film culture (or, \"Tollywood\") is the second -largest film industry in India next to Bollywood Film Industry. Prolific film producer from the state, D. Ramanaidu holds a Guinness Record for the most number of films produced by a person. In the years 2005, 2006 and 2008 the Telugu film industry produced the largest number of films in India, exceeding the number of films produced in Bollywood. The industry holds the Guinness World Record for the largest film production facility in the world.\n\nTourism\n\nThe state has several beaches in its coastal districts such as, Rushikonda, Mypadu, Suryalanka etc.; caves such as, Borra Caves, Indian rock-cut architecture depicting Undavalli caves and the country's second longest caves named as Belum Caves. The valleys and hills include, Araku Valley, Horsley Hills, Papi Hills etc Arma Konda peak located in Visakhapatnam district is the highest peak in Eastern Ghats.\n\nThe state is home to various religious pilgrim destinations such as, Tirumala Temple, Simhachalam Temple, Annavaram, Srisailam temple, Kanaka Durga Temple, Amaravati, Srikalahasti temple, Shahi jamia masjid in Adoni, Gunadala Church in Vijayawada, \"Buddhist centres\" at Amaravati, Nagarjuna Konda etc., and many more as well.\n\nThe state is well connected to other states through road and rail networks. It is also connected to other countries by means of airways and seaports as well. With a long seacoast along the Bay of Bengal, it also has many ports for sea trade. The state has one of the largest railway junctions at Vijayawada and one of the largest seaports at Visakhapatnam.\n\nRoads in Andhra Pradesh consist of National Highways and state highways with district roads as well. NH 5, with a highway network of around in the state, is a part of Golden Quadrilateral Project undertaken by National Highways Development Project. It also forms part of AH 45 which comes under the Asian Highway Network.\n\nThe Andhra Pradesh State Road Transport Corporation (APSRTC) is the major public bus transport owned by the state government which runs thousands of buses connecting different parts of the state. Pandit Nehru Bus Station (PNBS) in Vijayawada is one of the largest bus terminals in Asia.\n\nAndhra Pradesh has a railway network of . One of the highest broad gauge tracks in the world is in Eastern Ghats route that runs from Visakhapatnam to Anantagiri. Most of Andhra Pradesh falls under Guntur, Vijayawada, Guntakal (South Central Railway zone and Waltair (East Coast Railway zone) divisions.\n\nWaltair Railway Division under ECoR zone is fourth largest revenue earning division in India. Vijayawada railway station is the highest grosser in the SCR zone and one of busiest railway junctions in India.\n\nVisakhapatnam Airport, is the only airport in the state with international connectivity. The state has five domestic airports, Vijayawada Airport at Gannavaram, Rajahmundry Airport at Madhurapudi, Tirupati Airport at Renigunta, Cuddapah Airport and a privately owned, public use airport at Puttaparthi. There are also 16 small air strips located in the state.\n\nAndhra Pradesh has one of the country's largest port at Visakhapatnam in terms of cargo handling. The other famous ports are Krishnapatnam Port (Nellore), Gangavaram Port and Kakinada Port. Gangavaram Port is a deep seaport which can accommodate ocean liners up to 200,000–250,000 DWT. There are 14 notified non-major ports at Bheemunipatnam, S.Yanam, Machilipatnam, Nizampatnam, Vadarevu etc.\n\nAndhra Pradesh has an overall literacy rate of 67.41% as per the 2011 Indian census. The primary and secondary school education is imparted by government, aided and private schools, under the administration of \"School Education Department\" of the state. These schools include, Municipal, Andhra Pradesh Residential, Andhra Pradesh Social Welfare Residential, Zilla Parishad, aided and unaided private schools. There a total of 6,864,201 students enrolled in 61,529 schools in the state. The mediums of instruction followed by the schools are Telugu, English, Urdu, Hindi, Kannada, Odia and Tamil. The \"Directorate of Government Examinations\" of the state administers the conduct of Secondary School Certificate examination. 652,374 candidates took the 2016 Secondary School Certificate exam and recorded a pass percentage of 94.52% for regular and 55.47% by private candidates.\n\nThe higher education in the state is administered by the \"Department of Higher Education\". The central universities in the state are, All India Institute of Medical Sciences, IIM Visakhapatnam, IIT Tirupati, NIT Tadepalligudem and NIT Kurnool, Indian Institute of Petroleum and Energy. The Government of Andhra Pradesh has established Rajiv Gandhi University of Knowledge Technologies (RGUKT) in 2008 to cater to the educational needs of the rural youth of Andhra Pradesh. As per the University Grants Commission,\nGITAM, K L University and Vignan University are the Deemed Universities in the state. There are eighteen state universities in different districts providing higher education in the fields of horticulture, law, medical, techonology, vedic and veterinary. Andhra University is the oldest of all the universities in the state, established in 1926.\n\nResearch institutes have been set up by the central government in the state. NSTL Naval Science & Technological Laboratory, NIO National Institute of Oceanography, Visakhapatnam, School of Planning and Architecture at Vijayawada is an autonomous research institute under Ministry of Human Resource Development of Government of India, National Atmospheric Research Laboratory carry out fundamental and applied research in Atmospheric and Space Sciences, Indian Institute of Science Education and Research, Tirupati, Society For Applied Microwave Electronics Engineering and Research, Visakhapatnam Central Tobacco Research Institute, Rajahmundry under control of ICAR (Indian Council of Agriculture Research) conducts fundamental and applied research on Tobacco for the benefit of the farming community, Indian Institute of Oil Palm Research (IIOPR) at Pedavegi near Eluru in West Godavari district serves as a centre for conducting and co-ordinating research on all aspects of oil palm conservation, improvement, production, protection, post-harvest technology and transfer of technology, CCRH Regional Research Institute at Gudivada, Clinical Research Institute at Tirupati and National Institute of Oceanography at Visakhapatnam are some of them.\n\nSpace research organisation\n\nIndian Space Research Organisation (or Sriharikota Range (SHAR)) at barrier island of Sriharikota in Nellore district of Andhra Pradesh is a satellite launching station. It is India's primary orbital launch site. India's lunar orbiter Chandrayaan-1 was launched from the centre at 6:22 AM IST on 22 October 2008.\n\nThe Sports Authority of Andhra Pradesh, is the governing body which looks after the infrastructure development in cricket, field hockey, association football, Olympic weightlifting, chess, water sports, tennis, badminton, table tennis, cycling, etc.\n\nCricket is one of the most popular sports in the state. The ACA-VDCA Stadium in Visakhapatnam is the home to Andhra Pradesh cricket team. The venue regularly hosts international as well as domestic matches. Notable cricketers from Andhra Pradesh, include Maharajkumar of Vizianagram, M. V. Narasimha Rao, M. S. K. Prasad, V.V.S. Laxman, Tirumalasetti Suman, Arshad Ayub, Ambati Rayudu, Venkatapathy Raju, Sravanthi Naidu, Yalaka Venugopal Rao etc. Humpy Koneru, from Gudivada of Krishna district of the state, is an Indian chess Grandmaster.\n\nKarnam Malleswari, the first female Indian to win an Olympic medal, hails from Srikakulam district of Andhra Pradesh. She won the bronze medal on 19 September 2000, in the 69 kg category with a lift of 240 kg.\n\nPullela Gopichand, is a former Indian badminton player. He won the All England Open Badminton Championships (2001), to becoming the second Indian to achieve it after Prakash Padukone.\n\nCherukuri Lenin 1985 or 1986 – 24 October 2010) was an Indian archer and coach who won a silver medal at the Asian Grand Prix in Malaysia, and was a National Archery Coach.\n\n\n\n"}
{"id": "2380", "url": "https://en.wikipedia.org/wiki?curid=2380", "title": "Accelerated Graphics Port", "text": "Accelerated Graphics Port\n\nThe Accelerated Graphics Port (AGP) is a high-speed point-to-point channel for attaching a video card to a computer system, primarily to assist in the acceleration of 3D computer graphics. It was originally designed as a successor to PCI-type connections for video cards. Since 2004, AGP has been progressively phased out in favor of PCI Express (PCIe); by mid-2008, PCI Express cards dominated the market and only a few AGP models were available.\n\nAs computers increasingly became graphically oriented, successive generations of graphics adapters began to push the limits of PCI, a bus with shared bandwidth. This led to the development of AGP, a \"bus\" dedicated to graphics adapters.\n\nAGP is heavily based on PCI, and in fact the AGP bus is a superset of the conventional PCI bus, and AGP cards must act as PCI cards.\n\nThe primary advantage of AGP over PCI is that it provides a dedicated pathway between the slot and the processor rather than sharing the PCI bus. In addition to a lack of contention for the bus, the direct connection allows for higher clock speeds.\n\nThe second major change is that AGP uses split transactions, where the address and data phases of a PCI transaction are separated. The card may send many address phases, and the host processes them in order. This avoids long delays, with the bus idle, during read operations.\n\nThird, PCI bus handshaking is simplified. Unlike PCI bus transactions whose length is negotiated on a cycle-by-cycle basis using the FRAME# and STOP# signals, AGP transfers are always a multiple of 8 bytes long, and the total length is included in the request. Further, rather than using the IRDY# and TRDY# signals for each word, data is transferred in blocks of four clock cycles (32 words at AGP 8× speed), and pauses are allowed only between blocks.\n\nFinally, AGP allows (optional in AGP 1.0 and 2.0, mandatory in AGP 3.0) \"sideband addressing\", meaning that the address and data buses are separated so the address phase does not use the main address/data (AD) lines at all. This is done by adding an extra 8-bit \"SideBand Address\" bus over which the graphics controller can issue new AGP requests while other AGP data is flowing over the main 32 address/data (AD) lines. This results in improved overall AGP data throughput.\n\nThis great improvement in memory read performance makes it practical for an AGP card to read textures directly from system RAM, while a PCI graphics card must copy it from system RAM to the card's video memory. System memory is made available using the graphics address remapping table (GART), which apportions main memory as needed for texture storage. The maximum amount of system memory available to AGP is defined as the \"AGP aperture\".\n\nThe AGP slot first appeared on x86-compatible system boards based on Socket 7 Intel P5 Pentium and Slot 1 P6 Pentium II processors. Intel introduced AGP support with the i440LX Slot 1 chipset on August 26, 1997, and a flood of products followed from all the major system board vendors.\n\nThe first Socket 7 chipsets to support AGP were the VIA Apollo VP3, SiS 5591/5592, and the ALI Aladdin V. Intel never released an AGP-equipped Socket 7 chipset. FIC demonstrated the first Socket 7 AGP system board in November 1997 as the \"FIC PA-2012\" based on the VIA Apollo VP3 chipset, followed very quickly by the \"EPoX P55-VP3\" also based on the VIA VP3 chipset which was first to market.\n\nEarly video chipsets featuring AGP support included the Rendition Vérité V2200, 3dfx Voodoo Banshee, Nvidia RIVA 128, 3Dlabs PERMEDIA 2, Intel i740, ATI Rage series, Matrox Millennium II, and S3 ViRGE GX/2. Some early AGP boards used graphics processors built around PCI and were simply bridged to AGP. This resulted in the cards benefiting little from the new bus, with the only improvement used being the 66 MHz bus clock, with its resulting doubled bandwidth over PCI, and bus exclusivity. Examples of such cards were the Voodoo Banshee, Vérité V2200, Millennium II, and S3 ViRGE GX/2. Intel's i740 was explicitly designed to exploit the new AGP feature set. In fact it was designed to texture only from AGP memory, making PCI versions of the board difficult to implement (local board RAM had to emulate AGP memory.)\n\nMicrosoft first introduced AGP support into \"Windows 95 OEM Service Release 2\" (OSR2 version 1111 or 950B) via the \"USB SUPPLEMENT to OSR2\" patch. After applying the patch the Windows 95 system became \"Windows 95 version 4.00.950 B\". The first Windows NT-based operating system to receive AGP support was Windows NT 4.0 with Service Pack 3, introduced in 1997. Linux support for AGP enhanced fast data transfers was first added in 1999 with the implementation of the AGPgart kernel module.\n\nIntel released \"AGP specification 1.0\" in 1997. It specified 3.3 V signals and 1× and 2× speeds. Specification 2.0 documented 1.5 V signaling, which could be used at 1×, 2× and the additional 4× speed and 3.0 added 0.8 V signaling, which could be operated at 4× and 8× speeds. (1× and 2× speeds are physically possible, but were not specified.)\n\nAvailable versions are listed in the table on the right.\n\nAGP version 3.5 is only publicly mentioned by Microsoft under \"Universal Accelerated Graphics Port (UAGP)\", which specifies mandatory supports of extra registers once marked optional under AGP 3.0. Upgraded registers include PCISTS, CAPPTR, NCAPID, AGPSTAT, AGPCMD, NISTAT, NICMD. New required registers include APBASELO, APBASEHI, AGPCTRL, APSIZE, NEPG, GARTLO, GARTHI.\n\nThere are various physical interfaces (connectors); see the Compatibility section.\n\nAn official extension for cards that required more electrical power, with a longer slot with additional pins for that purpose. AGP Pro cards were usually workstation-class cards used to accelerate professional computer-aided design applications employed in the fields of architecture, machining, engineering, simulations, and similar fields.\n\nA 64-bit channel was once proposed as an optional standard for AGP 3.0 in draft documents, but it was dropped in the final version of the standard.\n\nThe standard allows 64-bit transfer for AGP8× reads, writes, and fast writes; 32-bit transfer for PCI operations.\n\nA number of non-standard variations of the AGP interface have been produced by manufacturers.\n\n\nAGP cards are backward and forward compatible within limits. 1.5 V-only keyed cards will not go into 3.3 V slots and vice versa, though \"Universal\" cards exist which will fit into either type of slot. There are also unkeyed \"Universal\" slots that will accept either type of card. When an AGP Universal card is plugged-into an AGP Universal slot, only the 1.5 V portion of the card is used. Some cards, like Nvidia's GeForce 6 series (except the 6200) or ATI's Radeon X800 series, only have keys for 1.5 V to prevent them from being installed in older mainboards without 1.5 V support. Some of the last modern cards with 3.3 V support were the Nvidia GeForce FX series (FX 5200, FX 5500, FX 5700, some FX 5800, FX 5900 and some FX 5950), Geforce 6 Series (6200, 6600/6600 LE/6600 GT only) and the ATI Radeon 9500/9700/9800(R350) (but not 9600/9800(R360)). Some Geforce 6200 and Geforce 6600 cards will function with AGP 1.0 (3.3v) slots.\n\nAGP Pro cards will not fit into standard slots, but standard AGP cards will work in a Pro slot. Motherboards equipped with a Universal AGP Pro slot will accept a 1.5 V or 3.3 V card in either the AGP Pro or standard AGP configuration, a Universal AGP card, or a Universal AGP Pro card.\n\nSome cards incorrectly have dual notches, and some motherboards incorrectly have fully open slots, allowing a card to be plugged into a slot that does not support the correct signaling voltage, which may damage card or motherboard. Some incorrectly designed older 3.3 V cards have the 1.5 V key.\n\nThere are some proprietary systems incompatible with standard AGP; for example, Apple Power Macintosh computers with the Apple Display Connector (ADC) have an extra connector which delivers power to the attached display. Some cards designed to work with a specific CPU architecture (e.g., PC, Apple) may not work with others due to firmware issues.\n\nMark Allen of Playtools.com made the following comments regarding Practical AGP Compatibility for AGP 3.0 and AGP 2.0:\n\n\"...nobody makes AGP 3.0 cards, and nobody makes AGP 3.0 motherboards. At least not any manufacturers I can find. Every single video card I could find which claimed to be an AGP 3.0 card was actually a universal 1.5V AGP 3.0 card. And every motherboard which claimed to be an AGP 3.0 motherboard turned out to be a universal 1.5V AGP 3.0 motherboard. It makes sense, if you think about it, because if anyone actually shipped a consumer-oriented product which supported only 0.8 volts, they would end up with lots of confused customers and a support nightmare. In the consumer market, you'd have to be crazy to ship a 0.8 volt only product.\"\n\nActual power supplied by an AGP slot depends upon the card used. The maximum current drawn from the various rails is given in the specifications for the various versions. For example, if maximum current is drawn from all supplies and all voltages are at their specified upper limits, an AGP 3.0 slot can supply up to 48.25 watts; this figure can be used to specify a power supply conservatively, but in practice a card is unlikely ever to draw more than 40 W from the slot, with many using less. AGP Pro provides additional power up to 110 W. Many AGP cards had additional power connectors to supply them with more power than the slot could provide.\n\nBy 2010 few new motherboards had AGP slots. No new motherboard chipsets were equipped with AGP support, but motherboards continued to be produced with older chipsets with support for AGP.\n\nGraphics processors of this period use PCI-Express, a general-purpose (not restricted to graphics) standard that supports higher data transfer rates and full-duplex. To create AGP-compatible graphics cards, those chips require an additional PCIe-to-AGP bridge-chip to convert PCIe signals to and from AGP signals. This incurs additional board costs due to the need for the additional bridge chip and for a separate AGP-designed circuit board.\n\nVarious manufacturers of graphics cards continued to produce AGP cards for the shrinking AGP user-base. The first bridged cards were the GeForce 6600 and ATI Radeon X800 XL boards, released during 2004-5. In 2009 AGP cards from Nvidia had a ceiling of the GeForce 7 Series. In 2011 DirectX 10-capable AGP cards from AMD vendors (Club 3D, HIS, Sapphire, Jaton, Visiontek, Diamond, etc.) included the Radeon HD 2400, 3450, 3650, 3850, 4350, 4650, and 4670. The HD 5000 AGP series mentioned in the catalyst software was never available. There were many problems with the AMD Catalyst 11.2 - 11.6 AGP hotfix drivers under Windows 7 with the HD 4000 series AGP video cards; use of 10.12 or 11.1 AGP hotfix drivers is the recommended workaround. Several of the vendors listed above make available past versions of the AGP drivers.\n\nAn AGP bus is a superset of a 66 MHz conventional PCI bus and, immediately after reset, follows the same protocol. The card must act as a PCI target, and optionally may act as a PCI master. (AGP 2.0 added a \"fast writes\" extension which allows PCI writes from the motherboard to the card to transfer data at higher speed.)\n\nAfter initialization, AGP transactions are permitted. For these, the card is always the AGP master and the motherboard is always the AGP target. The card queues multiple requests which correspond to the PCI address phase, and the motherboard schedules the corresponding data phases later. An important part of initialization is telling the card the maximum number of outstanding AGP requests which may be queued at a given time.\n\nAGP requests are similar to PCI memory read and write requests, but use a different encoding on command lines C/BE[3:0] and are always 8-byte aligned; their starting address and length are always multiples of 8 bytes (64 bits). The three low-order bits of the address are used instead to communicate the length of the request.\n\nWhenever the PCI GNT# signal is asserted, granting the bus to the card, three additional status bits ST[2:0] indicate the type of transfer to be performed next. If the three bits are codice_1, the card may begin a PCI transaction or (if sideband addressing is not in use) queue a request in-band using PIPE#.\n\nTo queue a request in-band, the card must request the bus using the standard PCI REQ# signal, and receive GNT# plus bus status ST[2:0] equal to codice_1. Then the card asserts the PIPE# signal while driving the AGP command, address, and length on the C/BE[3:0], AD[31:3] and AD[2:0] lines, respectively. (If the address is 64 bits, a dual address cycle similar to PCI is used.) For every cycle that PIPE# is asserted, the card sends another request without waiting for acknowledgement from the motherboard, up to the configured maximum queue depth. The last cycle is marked by deasserting REQ#, and PIPE# is deasserted on the following idle cycle.\n\nIn-band requests are always sent at single data rate (1× speed).\n\nPossible request codes are:\n\nAGP 3.0 dropped high-priority requests and the long read commands, as they were little used.\n\nIf side-band addressing is supported and configured, the PIPE# signal is not used. (And the signal is re-used for another purpose in the AGP 3.0 protocol, which requires side-band addressing.) Instead, requests are broken into 16-bit pieces and sent across the SBA bus. The possible values are:\n\n\nSideband address bytes are sent at the same rate as data transfers, up to 8× the 66 MHz basic bus clock. Sideband addressing has the advantage that it mostly eliminates the need for turnaround cycles on the AD bus between transfers, in the usual case when read operations greatly outnumber writes.\n\nWhile asserting GNT#, the motherboard may instead indicate via the ST bits that a data phase for a queued request will be performed next. There are four queues: two priorities (low- and high-priority) for each of reads and writes, and each is processed in order. Obviously, the motherboard will attempt to complete high-priority requests first, but there is no limit on the number of low-priority responses which may be delivered while the high-priority request is processed.\n\nFor each cycle when the GNT# is asserted and the status bits have the value codice_12, a read response of the indicated priority is scheduled to be returned. At the next available opportunity (typically the next clock cycle), the motherboard will assert TRDY# (target ready) and begin transferring the response to the oldest request in the indicated read queue. (Other PCI bus signals like FRAME#, DEVSEL# and IRDY# remain deasserted.) Up to four clock cycles worth of data (16 bytes at AGP 1× or 128 bytes at AGP 8×) are transferred without waiting for acknowledgement from the card. If the response is longer than that, both the card and motherboard must indicate their ability to continue on the third cycle by asserting IRDY# (initiator ready) and TRDY#, respectively. If either one does not, wait states will be inserted until two cycles after they both do. (The value of IRDY# and TRDY# at other times is irrelevant and they are usually deasserted.)\n\nThe C/BE# byte enable lines may be ignored during read responses, but are held asserted (all bytes valid) by the motherboard.\n\nThe card may also assert the RBF# (read buffer full) signal to indicate that it is temporarily unable to receive more low-priority read responses. The motherboard will refrain from scheduling any more low-priority read responses. The card must still be able to receive the end of the current response, and the first four-cycle block of the following one if scheduled, plus any high-priority responses it has requested.\n\nFor each cycle when GNT# is asserted and the status bits have the value codice_13, write data is scheduled to be sent across the bus. At the next available opportunity (typically the next clock cycle), the card will assert IRDY# (initiator ready) and begin transferring the data portion of the oldest request in the indicated write queue. If the data is longer than four clock cycles, the motherboard will indicate its ability to continue by asserting TRDY# on the third cycle. Unlike reads, there is no provision for the card to delay the write; if it didn't have the data ready to send, it shouldn't have queued the request.\n\nThe C/BE# lines \"are\" used with write data, and may be used by the card to select which bytes should be written to memory.\n\nThe multiplier in AGP 2×, 4× and 8× indicates the number of data transfers across the bus during each 66 MHz clock cycle. Such transfers use source synchronous clocking with a \"strobe\" signal (AD_STB[0], AD_STB[1], and SB_STB) generated by the data source. AGP 4× adds complementary strobe signals.\n\nAt AGP 4× and 8× speeds, it is possible for a request to complete in the middle of a clock cycle. In such a case, the cycle is padded with dummy data transfers (with the C/BE# byte enable lines held deasserted).\n\nThe AGP connector contains almost all PCI signals, plus several additions. The connector has 66 contacts on each side, although 4 are removed for each keying notch. Pin 1 is closest to the I/O bracket, and the B and A sides are as in the table, looking down at the motherboard connector.\n\nContacts are spaced at 1 mm intervals, however they are arranged in two staggered vertical rows so that there is 2 mm space between pins in each row. Odd-numbered A-side contacts, and even-numbered B-side contacts are in the lower row (1.0 to 3.5 mm from the card edge). The others are in the upper row (3.7 to 6.0 mm from the card edge).\n\nPCI signals omitted are:\n\nSignals added are:\n\n\n"}
{"id": "2381", "url": "https://en.wikipedia.org/wiki?curid=2381", "title": "Andreas Aagesen", "text": "Andreas Aagesen\n\nAndreas Aagesen (5 August 1826 – 26 October 1879) was a Danish jurist.\n\nAagesen was educated for the law at Christianshavn and Copenhagen, and interrupted his studies in 1848 to take part in the First Schleswig War, in which he served as the leader of a reserve battalion.\n\nIn 1855 Aagesen became a professor of jurisprudence at the University of Copenhagen. In 1870 he was appointed a member of the commission for drawing up a maritime and commercial code, and the navigation law of 1882 is mainly his work. In 1879 he was elected a member of the Landsting (one of two chambers of the Danish Parliament, the Rigsdagen); but it is as a teacher at the university that he won his reputation. Aagesen was Carl Christian Hall's successor as lecturer on Roman law at the university, and in this department his research was epoch-making.\n\nAmong his numerous juridical works may be mentioned:\n\n\n"}
{"id": "2382", "url": "https://en.wikipedia.org/wiki?curid=2382", "title": "Aalen", "text": "Aalen\n\nAalen () is a former Free Imperial City located in the eastern part of the German state of Baden-Württemberg, about east of Stuttgart and north of Ulm. It is the seat of the Ostalbkreis district and is its largest town. It is also the largest town in the Ostwürttemberg region. Since 1956, Aalen has had the status of Große Kreisstadt (major district town). It is noted for its many half-timbered houses constructed from the 16th century through the 18th century.\n\nWith an area of 146.63 km, Aalen is ranked 7th in Baden-Württemberg and 2nd within the Government Region of Stuttgart, after Stuttgart. With a population of about 66,000, Aalen is the 15th most-populated settlement in Baden-Württemberg.\n\nAalen is situated on the upper reaches of the river Kocher, at the foot of the Swabian Jura which lies to the south and south-east, and close to the hilly landscapes of the Ellwangen Hills to the north and the \"Welland\" to the north-west.\n\nThe west of Aalen's territory is on the foreland of the eastern Swabian Jura, and the north and north-west is on the Swabian-Franconian Forest, both being part of the Swabian Keuper-Lias Plains. The south-west is part of the Albuch, the east is part of the Härtsfeld, these two both being parts of the Swabian Jura.\n\nThe Kocher enters the town's territory from Oberkochen to the south, crosses the district of Unterkochen, then enters the town centre, where the \"Aal\" flows into it. The \"Aal\" is a small river located only within the town's territory. Next, the Kocher crosses the district of Wasseralfingen, then leaves the town for Hüttlingen. Rivers originating near Aalen are the Rems (near Essingen, west of Aalen) and the Jagst (near Unterschneidheim, east of Aalen), both being tributaries of the Neckar, just like the Kocher.\n\nThe elevation in the centre of the market square is relative to Normalhöhennull. The territory's lowest point is at the Lein river near Rodamsdörfle, the highest point is the Grünberg's peak near Unterkochen at .\n\nAalen's territory ranges over all lithostratigraphic groups of the South German Jurassic: Aalen's south and the \"Flexner\" massif are on top of the White Jurassic, the town centre is on the Brown Jurassic, and a part of Wasseralfingen is on the Black Jurassic. As a result, the town advertises itself as a \"Geologist's Mecca\".\n\nMost parts of the territory are on the \"Opalinuston-Formation\" (Opalinum Clay Formation) of the Aalenian subdivision of the Jurassic Period, which is named after Aalen. On the \"Sandberg\", the \"Schnaitberg\" and the \"Schradenberg\" hills, all in the west of Aalen, the \"Eisensandstein\" (Iron Sandstone) formation emerges to the surface. On the other hills of the city, sands \"(Goldshöfer Sande)\", gravel and residual rubble prevail.\nThe historic centre of Aalen and the other areas in the Kocher valley are founded completely on holocenic floodplain loam \"(Auelehm)\" and riverbed gravel that have filled in the valley.\n\nMost parts of Dewangen and Fachsenfeld are founded on formations of \"Jurensismergel\" (Jurensis Marl), \"Posidonienschiefer\" (cf. Posidonia Shale), \"Amaltheenton\" (Amalthean Clay), \"Numismalismergel\" (Numismalis Marl) and \"Obtususton\" (Obtusus Clay, named after Asteroceras obtusum ammonites) moving from south to north, all belonging to the Jurassic and being rich in fossils. They are at last followed by the \"Trossingen Formation\" already belonging to the Late Triassic.\n\nUntil 1939 iron ore was mined on the \"Braunenberg\" hill. (see Tiefer Stollen section).\n\nThe maximum extent of the town's territory amounts to in a north-south dimension and in an east-west dimension. The area is , which includes 42.2% agriculturally used area and 37.7% of forest. 11.5% are built up or vacant, 6.4% is used by traffic infrastructure. Sporting and recreation grounds and parks comprise 1% , other areas 1.1% .\n\nThe following municipalities border on Aalen. They are listed clockwise, beginning south, with their respective linear distances to Aalen town centre given in brackets:\n\nOberkochen (), Essingen (), Heuchlingen (), Abtsgmünd (), Neuler (), Hüttlingen (), Rainau (), Westhausen (), Lauchheim (), Bopfingen () and Neresheim (), all in the Ostalbkreis district, furthermore Heidenheim an der Brenz () and Königsbronn (), both in Heidenheim district.\n\nAalen's territory consists of the town centre \"(Kernstadt)\" and the municipalities\nmerged from between 1938 (Unterrombach) and 1975 (Wasseralfingen, see mergings section).\nThe municipalities merged in the course of the latest municipal reform of the 1970s are also called \"Stadtbezirke\" (quarters or districts), and are \"Ortschaften\" (\"settlements\") in terms of Baden-Württemberg's \"Gemeindeordnung\" (municipal code), which means, each of them has its own council elected by its respective residents \"(Ortschaftsrat)\" and is presided by a spokesperson \"(Ortsvorsteher)\".\n\nThe town centre itself and the merged former municipalities consist of numerous villages \"(Teilorte)\", mostly separated by open ground from each other and having their own independent and long-standing history. Some however have been created as planned communities, which were given proper names, but no well-defined borders.\n\nList of villages:\n\nAalen forms a \"Mittelzentrum\" (\"medium-level centre\") within the Ostwürttemberg region. Its designated catchment area includes the following municipalities of the central and eastern Ostalbkreis district: Abtsgmünd, Bopfingen, Essingen, Hüttlingen, Kirchheim am Ries, Lauchheim, Neresheim, Oberkochen, Riesbürg and Westhausen, and is interwoven with the catchment area of Nördlingen, situated in Bavaria, east of Aalen.\n\nAs Aalen's territory sprawls on escarpments of the Swabian Jura, on the Albuch and the Härtsfeld landscapes, and its elevation has a range of , the climate varies from district to district.\n\nThe weather station the following data originate from is located between the town centre and Wasseralfingen at about and has been in operation since 1991.\n\nThe sunshine duration is about 1800 hours per year, which averages 4.93 hours per day. So Aalen is above the German average of 1550 hours per year. However, with 167 days of precipitation, Aalen's region also ranks above the German average of 138. The annual rainfall is , which places Aalen in the middle within Baden-Württemberg.\nThe annual mean temperature is . Here Aalen ranks above the German average of and the Baden-Württemberg average of .\n\nNumerous remains of early civilization have been found in the area. Tools made of flint and traces of Mesolithic human settlement dated between the 8th and 5th millennium BC were found on several sites on the margins of the Kocher and Jagst valleys. On the \"Schloßbaufeld\" plateau (appr. ), situated behind \"Kocherburg\" castle near Unterkochen, a hill-top settlement was found, with the core being dated to the Bronze Age. In the \"Appenwang\" forest near Wasseralfingen, in Goldshöfe, and in Ebnat, tumuli of the Hallstatt culture were found. In Aalen and Wasseralfingen, gold and silver coins left by the Celts were found. The Celts were responsible for the fortifications in the Schloßbaufeld settlement consisting of sectional embankments and a stone wall. Also, Near Heisenberg (Wasseralfingen), a Celtic nemeton has been identified; however it is no longer readily apparent.\n\nAfter abandoning the Alb Limes (a \"limes\" generally following the ridgeline of the Swabian Jura) around 150 AD, Aalen's territory became part of the Roman Empire, in direct vicinity of the then newly erected Rhaetian Limes. The Romans erected a castrum to house the cavalry unit \"Ala II Flavia milliaria\"; its remains are known today as \"Kastell Aalen\" (\"Aalen Roman fort\"). The site is west of today's town centre at the bottom of the \"Schillerhöhe\" hill. With about 1,000 horsemen and nearly as many grooms, it was the greatest fort of auxiliaries along the Rhaetian Limes. There were Civilian settlements adjacent along the south and the east. Around 260 AD, the Romans gave up the fort as they withdrew their presence in unoccupied Germania back to the Rhine and Danube rivers, and the Alamanni took over the region. Based on 3rd- and 4th-century coins found, the civilian settlement continued to exist for the time being. However, there is no evidence of continued civilization between the Roman era and the Middle Ages.\n\nBased on discovery of alamannic graves, archaeologists have established the 7th century as the origination of Aalen. In the northern and western walls of St. John's church, which is located directly adjacent to the eastern gate of the Roman fort, Roman stones were incorporated. The building that exists today probably dates to the 9th century.\n\nThe first mention of Aalen was in 839, when emperor Louis the Pious reportedly permitted the Fulda monastery to exchange land with the Hammerstadt village, then known as \"Hamarstat\".\nAalen itself was first mentioned in an inventory list of Ellwangen Abbey, dated ca. 1136, as the village \"Alon\", along with a lower nobleman named Conrad of Aalen. This nobleman probably had his ancestral castle at a site south of today's town centre and was subject first to Ellwangen abbey, later to the House of Hohenstaufen, and eventually to the House of Oettingen. 1426 was the last time a member of that house was mentioned in connection with Aalen.\nDocuments, from the Middle Ages, indicate that the town of Aalen was founded by the Hohenstaufen some time between 1241 and 1246, but at a different location than the earlier village, which was supposedly destroyed in 1388 during the war between the Alliance of Swabian Cities and the Dukes of Bavaria.\nLater, it is documented that the counts of Oettingen ruled the town in 1340. They are reported to have pawned the town to Count Eberhard II and subsequently to the House of Württemberg in 1358 or 1359 in exchange for an amount of money.\n\nDuring the war against Württemberg, Emperor Charles IV took the town without a fight after a siege. On 3 December 1360, he declared Aalen an Imperial City, that is, a city or town responsible only to the emperor, a status that made it a quasi-sovereign city-state and that it kept until 1803. In 1377, Aalen joined the Alliance of Swabian Cities, and in 1385, the term \"civitas\" appears in the town's seal for the first time. In 1398, Aalen was granted the right to hold markets, and in 1401 Aalen obtained proper jurisdiction.\nThe oldest artistic representation of Aalen was made in 1528. It was made as the basis of a lawsuit between the town and the Counts of Oettingen at the Reichskammergericht in Speyer. It shows Aalen surrounded by walls, towers, and double moats. The layout of the moats, which had an embankment built between them, is recognizable by the present streets named \"Nördlicher, Östlicher, Südlicher\" and \"Westlicher Stadtgraben\" (Northern, Eastern, Southern and Western Moat respectively). The wall was about tall, 1518 single paces () long and enclosed an area of . During its early years, the town had two town gates: The \"Upper\" or \"Ellwangen Gate\" in the east, and St. Martin's gate in the south; however due to frequent floods, St. Martin's gate was bricked up in the 14th century and replaced by the \"Lower\" or \"Gmünd Gate\" built in the west before 1400. Later, several minor side gates were added. The central street market took place on the \"Wettegasse\" (today called \"Marktplatz\", \"market square\") and the \"Reichsstädter Straße\". So the market district stretched from one gate to the other, however in Aalen it was not straight, but with a 90-degree curve between southern (St. Martin's) gate and eastern (Ellwangen) gate.\n\nAround 1500, the civic graveyard was relocated from the town church to St. John's Church, and in 1514, the \"Vierundzwanziger\" (\"Group of 24\") was the first assembly constituted by the citizens.\n\nDelegated by Württemberg's Duke Louis III, on 28 June 1575, nearly 30 years after Martin Luther's death, Jakob Andreae, professor and chancellor of the University of Tübingen, arrived in Aalen. The sermon he gave the following day convinced the mayor, the council, and the citizens to adopt the Reformation in the town. Andreae stayed in Aalen for four weeks to help with the change. This brought along enormous changes, as the council forbade the Roman Catholic priests to celebrate masses and give sermons. However, after victories of the imperial armies at the beginning of the Thirty Years' War, the Prince-Provostry of Ellwangen, which still held the right of patronage in Aalen, were able to temporarily bring Catholicism back to Aalen; however after the military successes of the Protestant Union, Protestant church practices were instituted again.\n\nOn the night of 5 September 1634, two ensigns of the army of Bernard of Saxe-Weimar who were fighting with the Swedes and retreating after the Battle of Nördlingen set fire to two powder carriages, to prevent the war material to fall into Croatian hands and to prevent their advance. The result was a conflagration, that some say destroyed portions of the town. There are differing stories regarding this fire. According to 17th-century accounts, the church and all the buildings, except of the \"Schwörturm\" tower, were casualties of the fire, and only nine families survived. 19th century research by Hermann Bauer, Lutheran pastor and local historian, discovered that the 17th-century account is exaggerated, but he does agree that the town church and buildings in a \"rather large\" semicircle around it were destroyed. The fire also destroyed the town archive housed in an addition to the church, with all of its documents. After the fire, soldiers of both armies went through the town looting. It took nearly 100 years for the town to reach its population of 2,000.\n\nFrench troops marched through Aalen in 1688 during the Nine Years' War; however, unlike other places, they left without leaving severe damages. The French came through again in 1702 during the War of the Spanish Succession and in 1741 during the War of the Austrian Succession, the latter also caused imperial troops to move through in 1743.\n\nThe town church's tower collapsed in 1765, presumably because proper building techniques were not utilized during the reconstruction after the fire of 1634. The collapsing tower struck two children of the tower watchman who died of their injuries, and destroyed the nave, leaving only the altar cross intact. The remaining walls had to be knocked down due to the damage. Reconstruction began the same year, creating the building that exists today.\n\nOn 22 November 1749, the so-called \"Aalen protocol\" regulating the cohabitation of Lutherans and Roman Catholics in the jointly ruled territory of Oberkochen was signed in Aalen by the Duchy of Württemberg and the Prince-Provostry of Ellwangen. Aalen had been chosen because of its neutral status as a Free Imperial City.\n\nDuring the War of the First Coalition (1796), Aalen was looted. The War of the Second Coalition concluded in 1801 with the signing of the Treaty of Lunéville, which led to the German Mediatisation of 1803 that assigned most Imperial Cities to the neighbouring principalities. Aalen was assigned to the electorate of Württemberg, which later became the Kingdom of Württemberg, and became seat of the District (\"Oberamt\") of Aalen. During the War of the Third Coalition, on 6 October 1805, Napoleon Bonaparte arrived in Aalen, with an army of 40,000. This event, along with Bavarian and Austrian troops moving in some days later, caused miseries that according to the town clerk \"no feather could describe\".\n\nIn 1811, the municipality of Unterrombach was formed out of some villages previously belonging to Aalen, some to the Barons of Wöllwarth, and the eastern villages were assigned to the municipality of Unterkochen.\n\nIn the age of the Napoleonic wars, the town walls were no longer of use, and in the 18th century, with the maintenance of walls, gates and towers becoming more neglected Finally, due to the fact that the funds were lacking, starting in 1800, most towers were demolished, the other buildings followed soon.\n\nBefore the industrial revolution, Aalen's economy was shaped by its rural setting. Many citizens were pursuing farming besides their craft, such as tanning. In the mid 19th century, there were twelve tanneries in Aalen, due to the proximity of Ulm, an important sales market. Other crafts that added to the economy were weaving mills, which produced linen and woolen goods, and baking of sweet pastry and gingerbread.\n\nIn Aalen, industrialisation was a slow process. The first major increase was in the 1840s, when three factories for nails and some other factories emerged. It was the link with the railway network, by the opening of the Rems Railway from Cannstatt to Wasseralfingen in 1861, that brought more industry to Aalen, along with the royal steel mill (later \"Schwäbische Hüttenwerke\") in Wasseralfingen. The Rems Railway's extension to Nördlingen in 1863, the opening of the Brenz Railway in 1864 and of the Upper Jagst Railway in 1866 turned Aalen into a railway hub. Furthermore, between 1901 and its shutdown in 1972, the Härtsfeld Railway connected Aalen with Dillingen an der Donau via Neresheim. Part of becoming a rail hub entailed more jobs based on the rail industry. These included, a maintenance facility, a roundhouse, an administrative office, two track maintenance shops, and a freight station with an industrial branch line. This helped shape Aalen into what today's historians call a \"railwayman's town\". Starting in 1866, the utilities in town all began to be upgraded. Starting with the Aalen gasworks which were opened and gas lighting was introduced. Then in 1870, a modern water supply system was started and in 1912 the mains electricity. Finally, in 1935, the first electrically powered street lights were installed.\nTo fight housing shortage during and immediately after World War I, the town set up barracks settlement areas at the \"Schlauch\" and \"Alter Turnplatz\" grounds. In spite of the industry being crippled by the Great Depression of 1929, the public baths at the Hirschbach creek where modernized, extended and re-opened in 1931.\n\nIn the federal election of 1932, the Nazi Party performed below average in Aalen with 25.8% of votes compared to 33.1% on the national level, thus finishing second to the Centre Party which had 26.6% (11.9% nationwide) of the votes, and ahead of the Social Democratic Party of Germany with 19.8% (20.4%). However, the March 1933 federal elections showed that the sentiment had changed as the Nazi Party received 34.1% (still below German average 43.9% nationwide), but by far the leading vote-getter in Aalen, followed by the Centre party at 26.6% (11.3% nationwide) and the Social Democrats 18.6% (18.3% nationwide).\n\nThe democratically elected mayor Friedrich Schwarz remained in office until the Nazis removed him from office, in 1934, and replaced him by chairman of the Nazi Party town council head and brewery owner Karl Barth. Karl Barth was a provisional mayor until the more permanent solution of Karl Schübel. In August 1934, the Nazi consumer fair Braune Messe (\"brown fair\") was held in Aalen.\n\nDuring Nazi rule in Germany, there were many military offices constructed in Aalen, starting with, in 1936, a military district riding and driving school. The Nazis also built an army replenishment office \"(Heeresverpflegungsamt)\", a branch arsenal office \"(Heeresnebenzeugamt)\" and a branch army ammunitions institute \"(Heeresnebenmunitionsanstalt)\".\n\nStarting in 1935, mergers of neighbouring towns began. In 1938, the Oberamt was transformed into the Landkreis of Aalen and the municipality of Unterrombach was disbanded. Its territory was mostly added to Aalen, with the exception of Hammerstadt, which was added to the municipality of Dewangen. Forst, Rauental and Vogelsang were added to Essingen (in 1952 the entire former municipality of Unterrombach was merged into Aalen, with the exception of Forst, which is part of Essingen until present).\n\nIn September 1944, the \"Wiesendorf\" concentration camp, a subcamp of Natzweiler-Struthof, was constructed nearby. It was designated for between 200 and 300 prisoners who were utilized for forced labor in industrial businesses nearby. Until the camp's dissolution in February 1945, 60 prisoners died. Between 1946 and 1957, the camp buildings were torn down; however, its foundations are still in place in house \"Moltkestraße 44/46\". Also, there were several other labour camps which existed where prisoners of war along with women and men from occupied countries occupied by Germany were pooled. The prisoners at these other camps had to work for the arms industry in major businesses like \"Schwäbische Hüttenwerke\" and the \"Alfing Keßler\" machine factory.\n\nIn the civic hospital, the deaconesses on duty were gradually replaced by National Socialist People's Welfare nurses. Nazi eugenics led to compulsory sterilization of some 200 persons there.\n\nFortunately, Aalen avoided most of the combat activity during World War II. It was only during the last weeks of the war that Aalen became a target of air warfare, which led to the destruction and severe damage of parts of the town, the train station, and other railway installations. A series of air attacks lasting for more than three weeks reached its peak on 17 April 1945, when United States Army Air Forces planes bombed the branch arsenal office and the train station. During this raid, 59 people were killed, more than half of them buried by debris, and more than 500 lost their homes. Also, 33 residential buildings, 12 other buildings and 2 bridges were destroyed, and 163 buildings, including 2 churches, were damaged. Five days later, the Nazi rulers of Aalen were unseated by the US forces.\n\nAalen became part of the State of Baden-Württemberg, upon its creation in 1952. Then, with the Baden-Württemberg territorial reform of 1973, the District of Aalen was merged into the Ostalbkreis district. Subsequently, Aalen became seat of that district, and in 1975, the town's borough attained its present size (see below).\n\nThe population of Aalen exceeded the limit of 20,000, which was the requirement for to gain the status of Große Kreisstadt (\"major district town\") in 1946. On 1 August 1947, Aalen was declared \"Unmittelbare Kreisstadt\" (\"immediate district town\"), and with the creation of the Gemeindeordnung (municipal code) of Baden-Württemberg on 1 April 1956, it was declared \"Große Kreisstadt\".\n\nOn 31 December 2008, 51.1 percent of Aalen were members of the Catholic Church, 23.9 percent were members of the Evangelical-Lutheran Church. About 25 percent belong to other or no religious community or gave no information. The district of Waldhausen was the district with the highest percentage of Roman Catholic inhabitants at 75.6 percent, and the central district was the one with the highest percentage of Evangelical-Lutheran inhabitants at 25.6 percent, as well as those claiming no religious preference at 32.5 percent.\n\nAalen's population originally was subject to the jus patronatus of Ellwangen Abbey, and thus subject to the Roman Catholic Diocese of Augsburg.\n\nWith the assistance of the Duke of Württemberg, in 1575, the reformation was implemented in Aalen. Subsequently, Aalen has been a predominantly Protestant town for centuries, with the exception of the years from 1628 until 1632 (see reformation section). Being an Imperial City, Aalen could govern its clerical matters on its own, so Clerics, organists and choir masters were direct subjects to the council, which thus exerted bishop-like power. There was even a proper hymn book for Aalen. After the transition to Württemberg, in 1803, Aalen became seat of a deanery, with the dean church being the Town Church (with the building constructed from 1765 to 1767 and existing until present). Another popular church is St. John's Church, located on the cemetery and refurbished in 1561.\n\nAs Aalen's population grew in the 20th century, more parishes were founded: St. Mark's parish with its church building of 1967 and St. Martin's parish with its church of 1974. In the borough of Unterrombach, Aalen had implemented the reformation as well, but the community remained a chapel-of-ease of Aalen. A proper church, the Christ Church, was erected in 1912 and a proper parish was established in 1947. In Fachsenfeld, the ruling family of Woellwarth resp. of Leinroden implemented the reformation. A parish church was built in 1591, however with an influx of Catholics in the 18th century, a Catholic majority was established. The other districts of present-day Aalen remained mostly catholic after the reformation, however Wasseralfingen established a Lutheran parish in 1891 and a church, St. Magdalene's Church, in 1893. In Unterkochen, after World War II, a parish was established and a church was built in 1960. All four parishes belong to the deanery of Aalen within the Evangelical-Lutheran Church in Württemberg. Furthermore, in Aalen there are Old Pietistic communities.\n\nThe few Catholics of today's central district were covered by the parish of Unterkochen until the 19th century, a situation which continued for some years even after completion of St. Mary's Church in 1868, which was constructed by Georg Morlok. However, in 1872 Aalen got its proper parish again, and in 1913, a second Catholic church, Salvator's Church, was completed, and in 1969 the Holy Cross Church was also finished. In 1963, a second parish was set up, and in 1972 it got a new Church, the new St. Mary's Church, which has been erected in place of the old St. Mary's church, which had been torn down in 1968. Another church of the second parish was St. Augustine's Church, which was completed in 1970. Finally, in 1976 and 1988, St. Elizabeth's Church and St. Thomas' Church were completed. Furthermore, in 1963, the St. Michael pastoral care office was built.\n\nHofherrnweiler has its own Catholic church, St. Boniface's, since 1904. The villages of Dewangen, Ebnat, Hofen, Waldhausen and Wasseralfingen had remained Catholic after reformation, so old parishes and churches persist there. The \"Assumption of Mary\" Church in Dewangen has an early Gothic tower and a newly built nave (1875). Mary's Immaculate Conception Church in Ebnat was constructed in 1723; however the church was first mentioned in 1298.\nHofen's Saint George's Church is a fortified church, whose current nave was built between 1762 and 1775. Alongside the church, the Late Gothic St. Odile's Chapel is standing, whose entrance has the year 1462 engraved upon it. Foundations of prior buildings have been dated to the 11th and 13th century.\n\nSt. Mary's Church of Unterkochen was first mentioned in 1248, and has served the Catholics of Aalen for a long time. Waldhausen's parish church of St. Nicholas was built between 1699 and 1716. Wasseralfingen at first was a chapel of ease for Hofen, but has since had its own chapel, St. Stephen, built. It was presumably built in 1353 and remodeled in 1832. In 1834, a proper parish was established, which built a new St. Stephen's Church. This new building utilized the Romanesque Revival architecture style and was built between 1881 and 1883, and has since remained the parish's landmark. Also, Fachsenfeld received its own church, named Sacred Heart in 1895. All Catholic parishes within Aalen are today incorporated into four pastoral care units within the \"Ostalb\" Deanery of the Diocese of Rottenburg-Stuttgart; however these units also comprise some parishes outside of Aalen. Pastoral Care Unit two comprises the parishes of Essingen, Dewangen and Fachsenfeld, unit four comprises Hofen and Wasseralfingen, unit five comprises both parishes of Aalen's centre and Hofherrnweiler, unit five comprises Waldhausen, Ebnat, Oberkochen and Unterkochen.\n\nIn addition to the two major religions within Aalen, there are also free churches and other communities, including the United Methodist Church, the Baptists, the Seventh-day Adventist Church and the New Apostolic Church.\n\nUntil the late 19th century, no Jews were documented within Aalen. In 1886 there were four Jews were living in Aalen, a number that rose to ten in 1900, fell to seven in 1905, and remained so until 1925. Upon the Nazis' rise to power in 1933, seven Jews, including two children, lived in Aalen. During the Kristallnacht in 1938, the vitrines of the three Jewish shops in the town were smashed and their proprietors imprisoned for several weeks. After their release, most Aalen Jews emigrated. The last Jews of Aalen, Fanny Kahn, was forcibly resettled to Oberdorf am Ipf, which had a large Jewish community. Today, a street of Aalen is named after her. The Jew Max Pfeffer returned from Brussels to Aalen in 1948 to continue his shop, but emigrated to Italy in 1967.\n\nIn Aalen, there is an Islamic Ditib community, which maintains the \"D.I.T.I.B. Mosque of Aalen (Central Mosque)\" located at Ulmer Straße. The mosque's construction started on 30 August 2008. The Millî Görüş organisation maintains the Fatih Mosque, as well at Ulmer Straße.\n\nThe present-day make up of Aalen was created on 21 June 1975 by the unification of the cities of Aalen and Wasseralfingen, with the initial name of \"Aalen-Wasseralfingen\". This annexation made Aalen's territory one third larger than its prior size. On 1 July 1975, the name \"Aalen\" was revived. Prior to this merger, the town of Aalen had already annexed the following municipalities:\n\nDuring the Middle Ages and the early modern period, Aalen was just a small town with a few hundred inhabitants. The population grew slowly due to numerous wars, famines and epidemics. It was the beginning of the Industrial Revolution in the 19th century where Aalen's growth accelerated. Whereas in 1803, only 1,932 people inhabited the town, in 1905 it had already increased to 10,442. The number continued to rise and reached 15,890 in 1939.\n\nThe influx of refugees and ethnic Germans from Germany's former eastern territories after World War II pushed the population to 31,814 in 1961. The merger with Wasseralfingen on 21 June 1975 added 14,597 persons and resulted in a total population of 65,165 people. On 30 June 2005, the population, which was officially determined by the Statistical Office of Baden-Württemberg, was 67,125.\n\nThe following overview shows how the population figures of the borough were ascertained. Until 1823, the figures are mostly estimates, thereafter census results or official updates by the state statistical office. Starting in 1871, the figures were determined by non-uniform method of tabulation using extrapolation.\n\nOn 31 December 2008, Aalen had precisely 66,058 inhabitants, of which 33,579 were female and 32,479 were male. The average age of Aalen's inhabitants rose from 40.5 years in 2000 to 42.4 in 2008. Within the borough, 6,312 foreigners resided, which is 9.56 percent. Of them, the largest percentage are from Turkey (38 percent of all foreigners), the second largest group are from Italy (13 percent), followed by Croatians (6 percent) and Serbs (5 percent).\n\nThe number of married residents fell from 32,948 in 1996 to 31,357 in 2007, while the number of divorced residents rose in the same period from 2,625 to 3,859. The number of single residents slightly increased between 1996 and 2004 from 25,902 to 26,268 and fell slightly until 2007 to 26,147. The number of widowed residents fell from 5,036 in 1996 to 4,783 in 2007.\n\nAalen has arranged a municipal association with Essingen and Hüttlingen.\n\nSince the local election of 25 May 2014, the town council consists of 51 representatives having a term of five years. The seats are distributed as follows on parties and groups (changes refer to the second last election of 2004):\n\nSince 1374, the mayor and the council maintain the government of the town. In the 16th century, the town had two, sometimes three mayors, and in 1552, the council had 13 members. Later, the head of the administration was reorganized several times. In the Württemberg era, the mayor's title was initially called \"Bürgermeister\", then from 1819 it was Schultheiß, and since 1947 it is \"Oberbürgermeister\". The mayor is elected for a term of eight years, and he is chairman and a voting member of the council. He has one deputy with the official title of \"Erster Bürgermeister\" (\"first mayor\") and one with the official title of \"Bürgermeister\" (\"mayor\").\n\nHeads of town in Aalen since 1802\n\nAalen's coat of arms depicts a black eagle with a red tongue on golden background, having a red shield on its breast with a bent silver eel on it. Eagle and eel were first acknowledged as Aalen's heraldic animals in the seal of 1385, with the eagle representing the town's imperial immediacy. After the territorial reform, it was bestowed again by the Administrative District of Stuttgart on 16 November 1976.\n\nThe coat of arms' blazon reads: “In gold, the black imperial eagle, with a red breast shield applied to it, therein a bent silver eel” \"(In Gold der schwarze Reichsadler, belegt mit einem roten Brustschild, darin ein gekrümmter silberner Aal)\".\n\nAalen’s flag is striped in red and white and contains the coat of arms.\n\nThe origin of the town’s name is uncertain. Matthäus Merian (1593–1650) presumed the name to originate from its location at the Kocher river, where \"frequently eels are caught\", while \"Aal\" is German for \"eel\". Other explanations point to Aalen as the garrison of an ala during the Roman empire, respectively to an abridgement of the Roman name \"Aquileia\" as a potential name of the Roman fort, a name that nearby Heidenheim an der Brenz bore as well. Another interpretation points to a Celtic word aa meaning \"water\".\n\nThe \"Twin Cities Society of Aalen\" \"(Städtepartnerschaftsverein Aalen e. V.)\" promotes \"friendly relations\" between Aalen and its twin cities, which comprises mutual exchanges of sports and cultural clubs, schools and other civic institutions. On the occasion of the Reichsstädter Tage, from 11 until 13 September 2009 the first conference of twinned cities was held.\n\nAalen has five twin cities:\n\nOn the occasion of the 1980 \"Reichsstädter Tage\", Aalen took over godparenthood for the more than 3000 ethnic Germans displaced from the Wischau linguistic enclave. 972 of them settled in Aalen in 1946. The \"Wischau Linguistic Enclave Society\" \"(Gemeinschaft Wischauer Sprachinsel)\" regularly organises commemorative meetings in Aalen. Their traditional costumes are stored in the Old Town Hall.\n\nAccording to the 2007 municipal poll by the Baden-Württemberg chapter of the German Taxpayers Federation, municipal tax revenues totalling to 54,755 million Euros (2006) resp. 62,148 million Euros (2007) face the following debts:\n\nThe town operates the “Theatre of the Town of Aalen” \"(Theater der Stadt Aalen)\". Having been founded in 1991 and featuring six salaried actors, it is the newest as well as the smallest civic theatre in Germany. In addition to regular plays, it also offers four theatre clubs for all age levels. During the 2008/2009 season, 400 performances of ten productions attracted more than 21,000 visitors.\n\nThe town endowed the \"Schubart Literary Award\" \"(Schubart-Literaturpreis)\" in 1955 in tribute to Christian Friedrich Daniel Schubart, who spent his childhood and youth in Aalen. It is one of the earliest literary awards in Baden-Württemberg and is awarded biennially to German-language writers whose work coincide with Schubart's \"liberal and enlightened reasoning\". It is compensated with 12,000 Euros.\n\nFounded in 1958, the \"Music School of the Town of Aalen\" today has about 1,500 students taught by 27 music instructors in 30 subjects. In 1977, a symphony orchestra was founde in Aalen, which today is called \"Aalener Sinfonieorchester\", and consists mostly of instructors and students of the music school. It performs three public concerts annually: The “New Year’s Concert” in January, the “Symphony Concert” in July and a “Christmas Concert” in December. Beyond that, music festivals regularly take place in Aalen, like the Aalen Jazzfest.\n\nThe Aalen volunteer fire department has had a marching band since 1952, whose roots date back to 1883. In 1959, the band received its first glockenspiel from TV host Peter Frankenfeld on the occasion of a TV appearance.\n\nA famous German rapper, designer and singer, that goes under the name of Cro, was born in Aalen and lived his early years here.\n\nIn the central district of Aalen, there are two museums: The “Aalen Limes Museum\" \"(Limesmuseum Aalen)\" is located at the place of the largest Roman cavalry fort north of the Alps until about 200 AD. It opened in 1964. The museum exhibits numerous objects from the Roman era. The ruins of the cavalry fort located beside the museum is open to museum visitors. Every other year, a Roman festival is held in the area of the museum (see below).\n\nIn the Geological-Paleontological Museum located in the historic town hall, there are more than 1500 fossils from the Swabian Jura, including ammonites, ichthyosaurs and corals, displayed.\n\nIn the Waldhausen district the \"Heimatstüble\" museum of local history has an exhibition on agriculture and rural living.\n\nIn the Wasseralfingen district, there are two more museums: The \"Museum Wasseralfingen\" comprises a local history exhibition and an art gallery including works of Hermann Plock, Helmut Schuster and Sieger Köder. Also, the stove plate collection of the \"Schwäbische Hüttenwerke\" steel mill is exhibited, with artists, modellers and the production sequence of a cast plate from design to final product being presented.\n\nThere is memorial stone at the \"Schillerlinde\" tree above Wasseralfingen's ore pit dedicated to four prisoners of the subcamp of Natzweiler-Struthof concentration camp killed there. Also in Wasseralfingen, in the cemetery a memorial with the Polish inscription \"To the victims of Hitler\" which commemorates the deceased forced labourers buried there.\n\nIn 1954, on the \"Schillerhöhe\" hill the town erected a bell tower as a memorial to Aalen's victims of both world wars and to the displacement of ethnic Germans. The tower was planned by Emil Leo, the bell was endowed by Carl Schneider. The tower is open on request. Every evening at 18:45 (before 2003: at 19:45), the memorial's bell rings.\n\nThe town centre is dominated by the Evangelical-Lutheran St. Nicholas' Church in the heart of the pedestrian area. The church, in its present shape being built between 1765 and 1767, is the only major Late Baroque building in Aalen and is the main church of the Evangelical-Lutheran parish of Aalen.\n\n\"St. John's Church\" is located inside of St. John's cemetery in the western centre. The building presumably is from the 9th century and thus is one of Württemberg's oldest existing churches. The interior features frescos from the early 13th century.\n\nFor other churches in Aalen, see the Religions section.\n\nThe Historic Town Hall was originally built in the 14th century. After the fire of 1634, it was re-constructed in 1636. This building received a clock from Lauterburg, and the Imperial City of Nuremberg donated a Carillon. It features a figurine of the \"Spy of Aalen\" and historically displayed other figurines, however the latter ones were lost by a fire in 1884. Since then, the Spy resides inside the reconstructed tower and has become a symbol of the town. The building was used as the town hall until 1907. Since 1977, the Geological-Paleontological Museum resides in the Historic Town Hall.\n\nAccording to legend, the citizens of Aalen owe the \"Spy of Aalen\" \"(Spion von Aalen)\" their town having been spared from destruction by the emperor's army:\n\nThe Imperial City of Aalen once was were in quarrel with the emperor, and his army was shortly before the gates to take the town. The people of Aalen got scared and thus dispatched their “most cunning” one out into the enemy’s camp to spy out the strength of their troops. Without any digression, he went straight into the middle of the enemy camp, which inescapably led to him being seized and presented to the emperor. When the emperor asked him what he had lost here, he answered in Swabian German: \"Don't frighten, high lords, I just want to peek how many cannons and other war things you've got, since I am the spy of Aalen\". The emperor laughed upon such a blatancy and \"acted\" naïvety, steered him all through the camp and then sent him back home. Soon the emperor withdrew with his army as he thought a town such \"wise guys\" reside in deserved being spared.\n\nThe earliest record of the Old Town Hall was in 1575. Its outside wall features the oldest known coat of arms, which is of 1664. Until 1851, the building also housed the \"Krone-Post\" hotel, which coincided with being a station of the Thurn und Taxis postal company. It has housed many notable persons. Thus the so-called \"Napoleon Window\" with its \"N\" painted on reminds of the stay of French emperor Napoleon Bonaparte in 1805. According to legend, he rammed his head so hard it bled on this window, when he was startled by the noise of his soldiers ridiculing the \"Spy of Aalen\". The building was used as Aalen's town hall from 1907 until 1975. Today it houses a cabaret café and the stage of the Theatre of the Town of Aalen. The town has adopted the \"Wischau Linguistic Enclave Society\" due to their godparenthood and stores their traditional constumes in the building.\n\nThe \"Bürgerspital\" (\"Civic Asylum\") is a timber-frame house erected on \"Spritzenhausplatz\" (\"Fire Engine House Square\") in 1702. Until 1873, it was used as civic hospital, then, later as a retirement home. After a comprehensive renovation in 1980 it was turned into a senior citizen's community centre.\n\nOn a slope of the \"Langert\" mountain, south of the town, the \"Limes-Thermen\" (\"Limes Thermae\") hot springs are located. They were built in ancient Roman style and opened in 1985. The health spa is supplied with water about .\n\nThe market square is the historic hub of Aalen and runs along about from the town hall in the south to the Historic Town Hall and the Old Town Hall in the north, where it empties into \"Radgasse\" alley. Since 1809, it is site of the weekly market on Wednesday and Saturday. About in front of the \"Reichsstädter Brunnen\" fountain at the town hall, the coats of arms of Aalen, its twinned cities and of the Wischau linguistic enclave are paved into the street as mosaic.\n\nIn 1705, for the water supply of Aalen a well casing was erected at the northern point of the market square, in front of the Historic Town Hall. It was a present of duke Eberhard Louis. The fountain bore a statue of emperor Joseph I., who was enthroned in 1705 and in 1707 renewed Aalen's Imperial City privileges. The fountain was supplied via a wooden pipe. Excessive water was dissipated through ditches branched from Kocher river. When in the early 1870s Aalen's water network was constructed, the fountain was replaced by a smaller fountain about distant. In 1975, the old market fountain was re-erected in baroque style. It bears a replica of the emperor's statue, with the original statue exhibited in the new town hall's lobby. The cast iron casing plates depict the 1718 coat of arms of the Duchy of Württemberg and the coats of arms of Aalen and of the merged municipalities.\n\nThe \"Reichsstädter Brunnen\" fountain (\"Imperial Civic Fountain\") is located in front of the town hall at the southern point of the market square. It was created by sculptor Fritz Nuss in 1977 to commemorate Aalen's time as an Imperial City (1360–1803). On its circumference is a frieze showing bronze figurines illustrating the town's history.\n\nThe \"Radgasse\" (\"Wheel Alley\") features Aalen's oldest façade. Originally a small pond was on its side. The buildings were erected between 1659 and 1662 for peasants with citizenry privileges and renovated in the mid-1980s. The namesake for the alley was the \"Wheel\" tavern, which was to be found at the site of today's address \"Radgasse 15\".\n\nThe former iron ore pit \"Wilhelm\" at Braunenberg hill was converted into the \"Tiefer Stollen\" tourist mine in order to remind of the old-day miners' efforts and to maintain it as a memorial of early industrialisation in the Aalen area. It has a mining museum open for visitors, and a mine railway takes visitors deep into the mountain. The Town of Aalen, a sponsorship association, and many citizens volunteered several thousand hours of labour to put the mine into its current state. As far as possible, things were left in the original state. In 1989, a sanitary gallery was established where respiratory diseases are treated within rest cures. Thus the Aalen village of Röthard, where the gallery is located, was awarded the title of \"Place with sanitary gallery service\" in 2004.\n\nThe Aalen Observatory was built in 1969 as school observatory for the Schubart Gymnasium. In 2001, it was converted to a public observatory. Since then, it has been managed by the \"Astronomische Arbeitsgemeinschaft Aalen\" (\"Aalen Astronomical Society\"). It is located on Schillerhöhe hill and features two refractive telescopes. They were manufactured by Carl Zeiss AG which has its headquarters in nearby Oberkochen and operates a manufacturing works in Aalen (see below). In the observatory, guided tours and lectures are held regularly.\n\nThe \"Windpark Waldhausen\" wind farm began operations in early 2007. It consists of seven REpower MM92 wind turbines with a nameplate capacity of 2 MW each. The hub height of each wind turbine is , with a rotor diameter of .\n\nThe tall \"Aalbäumle\" observation tower is built atop \"Langert\" mountain. This popular hiking destination was built in 1898 and was remodelled in 1992. It features a good view over Aalen and the Welland region, up to the Rosenstein mountain and Ellwangen. Beneath the tower, an adventure playground and a cabin is located. A flag on the tower signals whether the cabin's restaurant is open.\n\nThe Baden-Württemberg State Institute for Environment, Measurements and Natural Conservation has laid out six protected landscapes in Aalen (the \"Swabian Jura escarpment between Lautern and Aalen with adjacent territories\", the \"Swabian Jura escarpment between Unterkochen and Baiershofen\", the \"Hilllands around Hofen\", the \"Kugeltal and Ebnater Tal valleys with parts of Heiligental valley and adjacent territories\", \"Laubachtal valley\" and \"Lower Lein Valley with side valleys\"), two sanctuary forests (\"Glashütte\" and \"Kocher Origin\"), 65 extensive natural monuments, 30 individual natural monuments and the following two protected areas:\n\nThe large \"Dellenhäule\" protected area between Aalen's Waldhausen district and Neresheim's Elchingen district, created in 1969, is a sheep pasture with juniper and wood pasture of old willow oaks.\n\nThe large \"Goldshöfer Sande\" protected area was established in 2000 and is situated between Aalen's Hofen district and Hüttlingen. The sands on the hill originated from the Early Pleistocene are of geological importance, and the various grove structures offer habitat to severely endangered bird species.\n\nThe football team, VfR Aalen, was founded in 1921 and played in the 2nd German League between 2012 and 2015, after which they were relegated to 3. Liga. Its playing venue is the Scholz-Arena situated in the west of the town, which bore the name \"Städtisches Waldstadion Aalen\" (\"Civic Forest Stadium of Aalen\") until 2008. From 1939 until 1945, the VfR played in the Gauliga Württemberg, then one of several parallel top-ranking soccer leagues of Germany.\n\nThe KSV Aalen wrestles in the Wrestling Federal League. It was German champion in team wrestling in 2010. Its predecessor, the \"KSV Germania Aalen\" disbanded in 2005, was German champion eight times and runner-up five times since 1976. Another Aalen club, the TSV Dewangen, wrestled in the Federal League until 2009.\n\nTwo American sports, American Football and Baseball, are pursued by the \"MTV Aalen\". Volleyball has been gaining in popularity in Aalen for years. The first men's team of \"DJK Aalen\" accomplished qualification for regional league in the season of 2008/09.\n\nThe \"Ostalb\" ski lifts are located south of the town centre, at the northern slope of the Swabian Jura. The skiing area comprises two platter lifts that have a vertical rise of , with two runs with lengths of and a beginners' run.\n\nSince 1975, \"Reichsstädter Tage\" (\"Imperial City days\") festival is held annually in the town centre on the second weekend in September. It is deemed the largest festival of the Ostwürttemberg region, and is associated with a shopping Sunday in accordance with the Ladenschlussgesetz code. The festival is also attended by delegations from the twinned cities. On the town hall square, on Sunday an ecumenical service is held.\n\nThe international Roman Festival \"(Römertage)\" are held biannially on the site of the former Roman fort and the modern Limes museum. The festival's ninth event in 2008 was attended by around 11,000 people.\n\nAnnually during the second week of November, the Aalen Jazz Festival brings known and unknown artists to Aalen. It has already featured musicians like Miles Davis, B. B. King, Ray Charles, David Murray, McCoy Tyner, Al Jarreau, Esbjörn Svensson and Albert Mangelsdorff. The festival is complemented by individual concerts in spring and summer, and, including the individual concerts, comprises around 25 concerts with a total of about 13,000 visitors.\n\nIn 2008 there were 30,008 employees liable to social insurance living in Aalen. 13,946 (46.5 percent) were employed in the manufacturing sector, 4,715 (15.7 percent) in commerce, catering, hotels and transport, and 11,306 (37.7 percent) in other services. Annually 16,000 employees commute to work, with about 9,000 living in the town and commuting out.\n\nAltogether in Aalen there are about 4,700 business enterprises, 1,100 of them being registered in the trade register. The others comprise 2,865 small enterprises and 701 craft enterprises.\n\nIn Aalen, metalworking is the predominant industry, along with machine-building. Other industries include optics, paper, information technology, chemicals, textiles, medical instruments, pharmaceuticals, and food.\n\nNotable enterprises include \"SHW Automotive\" (originating from the former \"Schwäbische Hüttenwerke\" steel mills and a mill of 1671 in Wasseralfingen), the \"Alfing Kessler\" engineering works, the precision tools manufacturer \"MAPAL Dr. Kress\", the snow chain manufacturer \"RUD Ketten Rieger & Dietz\" and its subsidiary \"Erlau\", the \"Gesenkschmiede Schneider\" forging die smithery, the \"SDZ Druck und Medien\" media company, the \"Papierfabrik Palm\" paper mill, the alarm system manufacturer \"Telenot\", the laser show provider \"LOBO electronic\" and the textile finisher \"Lindenfarb\", which all have their seat in Aalen. A branch in Aalen is maintained by optical systems manufacturer Carl Zeiss headquartered in nearby Oberkochen.\n\nAalen station is a regional railway hub on the Rems Railway from Stuttgart, the Brenz Railway from Ulm, the Upper Jagst Railway to Crailsheim and the Ries Railway to Donauwörth. Until 1972, the Härtsfeld Railway connected Aalen with Dillingen an der Donau via Neresheim. Other railway stations within the town limits are \"Hofen (b Aalen)\", \"Unterkochen\", \"Wasseralfingen\" and Goldshöfe station. The \"Aalen-Erlau\" stop situated in the south is no longer operational.\n\nAalen station is served at two-hour intervals by trains of Intercity line 61 Karlsruhe–Stuttgart–Aalen–Nuremberg. For regional rail travel, Aalen is served by various lines of the Interregio-Express, Regional-Express and Regionalbahn categories. The town also operates the Aalen industrial railway \"(Industriebahn Aalen)\", which carries about 250 carloads per year.\n\nThe junctions of \"Aalen/Westhausen\" and \"Aalen/Oberkochen\" connect Aalen with the Autobahn A7 (Würzburg–Füssen). Federal roads (\"Bundesstraßen\") connecting with Aalen are B 19 (Würzburg–Ulm), B 29 (Waiblingen–Nördlingen) and B 290 (Tauberbischofsheim–Westhausen). The Schwäbische Dichterstraße (\"Swabian Poets' Route\") tourist route established in 1977/78 leads through Aalen.\n\nSeveral bus lines operate within the borough. The \"Omnibus-Verkehr Aalen\" company is one of the few in Germany that use double-decker buses, it has done so since 1966. A district-wide fare system, \"OstalbMobil\", has been in effect since 2007.\n\nStuttgart Airport, offering international connections, is about away, the travel time by train is about 100 Minutes. At Aalen-Heidenheim Airport, located south-east of Aalen, small aircraft are permitted. Gliding airfields nearby are in Heubach and Bartholomä.\n\nBicycle routes stretching through Aalen are the \"Deutscher Limes-Radweg\" (\"German Limes Bicycle Route\") and the \"Kocher-Jagst\" Bicycle Route.\n\nAalen houses an Amtsgericht (local district court), chambers of the Stuttgart Labour Court, a notary's office, a tax office and an employment agency. It is the seat of the Ostalbkreis district office, of the Aalen Deanery of the Evangelical-Lutheran Church and of the \"Ostalb\" deanery of the Roman Catholic Diocese of Rottenburg-Stuttgart.\n\nThe Stuttgart administrative court, the Stuttgart Labour Court and the Ulm Social Welfare Court are in charge for Aalen.\n\nAalen had a civic hospital, which resided in the \"Bürgerspital\" building until 1873, then in a building at \"Alte Heidenheimer Straße\". In 1942, the hospital was taken over by the district. The district hospital at the present site of \"Kälblesrain\", known today as \"Ostalb-Klinikum\", was opened in 1955.\n\nThe first local newspaper, \"Der Bote von Aalen\" (\"The Herald of Aalen\"), has been published on Wednesdays and Saturdays since 1837.\n\nCurrently, local newspapers published in Aalen are the \"Schwäbische Post\", which obtains its supra-regional pages from the Ulm-based Südwestpresse, and the \"Aalener Nachrichten\" (erstwhile \"Aalener Volkszeitung\"), a local edition of Schwäbische Zeitung in Leutkirch im Allgäu.\n\nTwo of Germany's biggest Lesezirkels (magazine rental services) are headquartered in Aalen: \"Brabandt LZ Plus Media\" and \"Lesezirkel Portal\".\n\nRegional event magazines are \"Xaver\", \"åla\", \"ålakultur\".\n\nThe commercial broadcasters \"Radio Ton\" and \"Radio 7\" have studios in Aalen.\n\nA Latin school was first recorded in Aalen in 1447; it was remodeled in 1616 and also later in various buildings that were all situated near the town church, and continued up through the 19th century. In the course of the reformation, a \"German school\" was established in tandem, being a predecessor of the latter Volksschule school type. In 1860, the \"Ritterschule\" was built as a \"Volksschule\" for girls; the building today houses the \"Pestalozzischule\". In 1866, a new building was erected for the Latin school and for the Realschule established in 1840. This building, later known as the \"Alte Gewerbeschule\", was torn down in 1975 to free up land for the new town hall. In 1912, the \"Parkschule\" building was opened. It was designed by Paul Bonatz and today houses the \"Schubart-Gymnasium\"\n\nThe biggest educational institution in the town is the \"Hochschule Aalen\", which was founded in 1962 and focuses on engineering and economics. It is attended by 5000 students on five campuses and employs 129 professors and 130 other lecturers.\n\nThe town provides three Gymnasiums, four Realschulen, two \"Förderschulen\" (special schools), six combined Grundschulen and Hauptschulen and eight standalone Grundschulen. The Ostalbkreis district provides three vocational schools and three additional special schools. Finally, six non-state schools of various types exist.\n\nThe German Esperanto Library (German: \"Deutsche Esperanto-Bibliothek\", Esperanto: \"Germana Esperanto-Biblioteko\") has been located in the building of the town library since 1989.\n\nThe Südwestrundfunk broadcasting company operates the Aalen transmission tower on the \"Braunenberg\" hill. The tower was erected in 1956, it is tall and made of reinforced concrete.\n\nThe following vehicles are named \"Aalen\":\n\n\n\n\n\n\n\n"}
{"id": "2383", "url": "https://en.wikipedia.org/wiki?curid=2383", "title": "Alois Alzheimer", "text": "Alois Alzheimer\n\nAloysius Alzheimer (; ; 14 June 1864 – 19 December 1915), known as Alois Alzheimer, was a German psychiatrist and neuropathologist and a colleague of Emil Kraepelin. Alzheimer is credited with identifying the first published case of \"presenile dementia\", which Kraepelin would later identify as Alzheimer's disease.\n\nAloysius Alzheimer was born in Marktbreit, Bavaria on 14 June 1864. His father served in the office of notary public in the family's hometown. \n\nThe Alzheimers moved when Alois was still young in order to give their children an opportunity to attend the Royal Humanistic Gymnasium. Later, Alois studied medicine at Aschaffenburg and at the universities of Tübingen, Berlin, and Würzburg. In his final year of school he was on the fencing team and a member of a fraternity, and even received a fine for disturbing the peace while out with his team. \n\nIn April 1884, he married Cecille Simonette Nathalie Geisenheimer, with whom he had three children. Cecille died in 1901. In 1887, Alois Alzheimer graduated from Würzburg with a degree in medicine.\n\nThe following year, he spent five months assisting mentally ill women before he took an office in the city mental asylum in Frankfurt am Main, the Städtische Anstalt für Irre und Epileptische (Asylum for Lunatics and Epileptics). , a noted psychiatrist, was the dean of the asylum. Another neurologist, Franz Nissl, began to work in the same asylum with Alzheimer. Together, they conducted research on the pathology of the nervous system, specifically the normal and pathological anatomy of the cerebral cortex. Alzheimer was the co-founder and co-publisher of the journal \"Zeitschrift für die gesamte Neurologie und Psychiatrie\", though he never wrote a book that he could call his own.\n\nWhile at the Frankfurt asylum, Alzheimer also met Emil Kraepelin, one of the best-known German psychiatrists of the time. Kraepelin became a mentor to Alzheimer, and the two worked very closely for the next several years. When Kraepelin moved to Munich to work at the Royal Psychiatric Hospital in 1903, he invited Alzheimer to join him. \n\nAt the time, Kraepelin was doing clinical research on psychosis in senile patients; Alzheimer, on the other hand, was more interested in the lab work of senile illnesses. The two men would face many challenges involving the politics of the psychiatric community. For example, both formal and informal arrangements would be made among psychiatrists at asylums and universities to receive cadavers. In 1908 he was a professor at the Ludwig Maximilian University and the Neurological and Psychiatric Clinic of the Friedrich-Wilhelm University from 1912 until he fell ill.\n\nIn 1901, Alzheimer observed a patient at the Frankfurt Asylum named Auguste Deter. The 51-year-old patient had strange behavioral symptoms, including a loss of short-term memory; she became his obsession over the coming years. Auguste Deter was a victim of the politics of the time in the psychiatric community; the Frankfurt asylum was too expensive for her husband. Herr Deter made several requests to have his wife moved to a less expensive facility, but Alzheimer intervened in these requests. Ms. Deter remained at the Frankfurt asylum, where Alzheimer had made a deal to receive her records and brain upon her death. \n\nOn 8 April 1906, Frau Deter died, and Alzheimer had her medical records and brain brought to Munich where he was working in Kraepelin's laboratory. With two Italian physicians, he used the staining techniques of Bielschowsky to identify amyloid plaques and neurofibrillary tangles. These brain anomalies would become identifiers of what later became known as Alzheimer's disease.\n\nAlzheimer discussed his findings on the brain pathology and symptoms of presenile dementia publicly on 3November 1906, at the Tübingen meeting of the Southwest German Psychiatrists. The attendees at this lecture seemed uninterested in what he had to say. The lecturer that followed Alzheimer was to speak on the topic of \"compulsive masturbation\", which the audience was so eagerly awaiting that they sent Alzheimer away without any questions or comments on his discovery of the pathology of a type of senile dementia. \n\nFollowing the lecture, Alzheimer published a short paper summarizing his lecture; in 1907 he wrote a larger paper detailing the disease and his findings. The disease would not become known as Alzheimer's disease until 1910, when Kraepelin named it so in the chapter on \"Presenile and Senile Dementia\" in the 8th edition of his \"Handbook of Psychiatry\". By 1911, his description of the disease was being used by European physicians to diagnose patients in the US.\n\nAmerican Solomon Carter Fuller gave a report similar to that of Alzheimer at a lecture five months before Alzheimer. Oskar Fischer was a fellow German psychiatrist, 12 years Alzheimer's junior, who reported 12 cases of senile dementia in 1907 around the time that Alzheimer published his short paper summarizing his lecture.\n\nThe two men had different interpretations of the disease, but due to Alzheimer's short life, they never had the opportunity to meet and discuss their ideas.\n\nIn August 1912, Alzheimer fell ill on the train on his way to the University of Breslau, where he had been appointed professor of psychiatry in July 1912. Most probably he had a streptococcal infection and subsequent rheumatic fever leading to valvular heart disease, heart failure and kidney failure. He never recovered completely from this illness. \n\nHe died of heart failure on 19December 1915, aged 51, in Breslau, Silesia (present-day Wrocław, Poland). He was buried on 23 December 1915 next to his wife in the Hauptfriedhof in Frankfurt am Main.\n\nIn the early 1990s, critics began to question Alzheimer's findings and form their own hypotheses based on Alzheimer's notes and papers. Amaducci and colleagues hypothesized that Auguste Deter had metachromatic leukodystrophy, a rare condition in which accumulations of fats affect the cells that produce myelin. \n\nAnother hypothesis offered by Claire O'Brien was that Auguste Deter actually had a vascular dementing disease. Through extremely fortunate circumstances the original microscope preparations on which Alzheimer based his description of the disease were rediscovered in 1998 in Munich, and his findings could thus be reevaluated. The slides confirmed that Auguste Deter did in fact have what is now known as Alzheimer's disease.\n\nAlzheimer was known for having a variety of medical interests including vascular diseases of the brain, early dementia, brain tumors, forensic psychiatry and epilepsy. Alzheimer was a leading specialist in histopathology in Europe. His colleagues knew him to be a dedicated professor and cigar smoker.\n\n\n"}
{"id": "2384", "url": "https://en.wikipedia.org/wiki?curid=2384", "title": "Aedile", "text": "Aedile\n\nAedile ( , from \"aedes,\" \"temple edifice\") was an office of the Roman Republic. Based in Rome, the aediles were responsible for maintenance of public buildings (\"aedēs\") and regulation of public festivals. They also had powers to enforce public order.\n\nThere were two pairs of aediles: the first were the \"plebeian aediles\" (Latin \"aediles plebis\") and possession of this office was limited to plebeians; the other two were \"curule aediles\" (Latin \"aediles curules\"), open to both plebeians and patricians, in alternating years. An \"aedilis curulis\" was classified as a \"magister curulis\".\n\nThe office of the aedilis was generally held by young men intending to follow the cursus honorum to high political office, traditionally after their quaestorship but before their praetorship. It was not a compulsory part of the cursus, and hence a former quaestor could be elected to the praetorship without having held the position of aedile. However, it was an advantageous position to hold because it demonstrated the aspiring politician's commitment to public service, as well as giving him the opportunity to hold public festivals and games, an excellent way to increase his name recognition and popularity.\n\nThe plebeian aediles were created in the same year as the Tribunes of the People (494 BC). Originally intended as assistants to the tribunes, they guarded the rights of the plebs with respect to their headquarters, the Temple of Ceres. Subsequently, they assumed responsibility for maintenance of the city's buildings as a whole. Their duties at first were simply ministerial. They were the assistants to the tribunes in whatever matters that the tribunes might entrust to them, although most matters with which they were entrusted were of minimal importance. Around 446 BC, they were given the authority to care for the decrees of the senate (\"senatus consulta\"). When a \"senatus consultum\" was passed, it would be transcribed into a document, and deposited in the public treasury, the \"Aerarium\". They were given this power because the Roman Consuls, who had held this power before, arbitrarily suppressed and altered the documents. They also maintained the acts of the Plebeian Council (popular assembly), the \"plebiscites\". Plebiscites, once passed, were also transcribed into a physical document for storage. While their powers grew over time, it is not always easy to distinguish the difference between their powers, and those of the Roman Censors. Occasionally, if a Censor was unable to carry out one of his tasks, an Aedile would perform the task instead.\n\nAccording to Livy (vi. 42), after the passing of the Licinian rogations in 367 BC, an extra day was added to the Roman games; the plebeian aediles refused to bear the additional expense, whereupon the patricians offered to undertake it, on condition that they were admitted to the aedileship. The plebeians accepted the offer, and accordingly two \"curule\" aediles were appointed—at first from the patricians alone, then from patricians and plebeians in turn, lastly, from either—at the Tribal Assembly under the presidency of the consul. Curule Aediles, as formal magistrates, held certain honors that Plebeian Aediles (who were not technically magistrates), did not hold. Besides having the right to sit on a Curule Chair (\"sella curulis\") and to wear a toga praetexta, the Curule Aediles also held the power to issue edicts (\"jus edicendi\"). These edicts often pertained to matters such as the regulation of the public markets, or what we might call \"economic regulation\". Livy suggests, perhaps incorrectly, that both Curule as well as Plebeian Aediles were sacrosanct. Although the curule aediles always ranked higher than the plebeian, their functions gradually approximated and became practically identical. Within five days after the beginning of their terms, the four Aediles (two Plebeian, two Curule) were required to determine, by lot or by agreement among themselves, what parts of the city each should hold jurisdiction over.\n\nThere was a distinction between the two sets of Aediles when it came to public festivals. Some festivals were Plebeian in nature, and thus were under the superintendence of Plebeian Aediles. Other festivals were supervised exclusively by the Curule Aediles, and it was often with these festivals that the Aediles would spend lavishly. This was often done so as to secure the support of voters in future elections. Because Aediles were not reimbursed for any of their public expenditures, most individuals who sought the office were independently wealthy. Since this office was a stepping stone to higher office and the Senate, it helped to ensure that only wealthy individuals (mostly landowners) would win election to high office. These extravagant expenditures began shortly after the end of Second Punic War, and increased as the spoils returned from Rome's new eastern conquests. Even the decadence of the emperors rarely surpassed that of the Aediles under the Republic, as could have been seen during Julius Caesar's Aedileship.\n\nPlebeian Aediles were elected by the Plebeian Council (popular assembly), usually while under the presidency of a Plebeian Tribune. Curule Aediles were elected by the Tribal Assembly, usually while under the presidency of a Roman Consul. Since the Plebeian Aediles were elected by the Plebeians (commoners), rather than by all of the People of Rome (Plebeians as well as members of the Patrician aristocracy), they were not technically magistrates. Before the passage of the \"lex annalis\", individuals could run for the Aedileship by the time they turned twenty-seven. After the passage of this law in 180 BC, a higher age was set, probably thirty-five. By the 1st century BC, Aediles were elected in July, and took office on the first day in January.\n\nCicero (Legg. iii. 3, 7) divides these functions under three heads:\n\n(1) Care of the city:\nthe repair and preservation of temples, sewers and aqueducts; street cleansing and paving; regulations regarding traffic, dangerous animals and dilapidated buildings; precautions against fire; superintendence of baths and taverns; enforcement of sumptuary laws; punishment of gamblers and usurers; the care of public morals generally, including the prevention of foreign superstitions and the registration of meretrices. They also punished those who had too large a share of the ager publicus, or kept too many cattle on the state pastures.\n\n(2) Care of provisions:\ninvestigation of the quality of the articles supplied and the correctness of weights and measures; the purchase of grain for disposal at a low price in case of necessity.\n\n(3) Care of the games: \nsuperintendence and organization of the public games, as well as of those given by themselves and private individuals (e.g. at funerals) at their own expense. \nAmbitious persons often spent enormous sums in this manner to win the popular favor with a view to official advancement.\n\nIn 44 BC Julius Caesar added two plebeian aediles, called \"Cereales\", whose special duty was the care of the cereal (grain) supply. Under Augustus the office lost much of its importance, its judicial functions and the care of the games being transferred to the praetor, while its city responsibilities were limited by the appointment of a praefectus urbi. Augustus took for himself its powers over various religious duties. By stripping it of its powers over temples, Augustus effectively destroyed the office, by taking from it its original function. After this point, few people were willing to hold such a powerless office, and Augustus was even known to compel individuals into holding the office. Augustus accomplished this by randomly selecting former tribunes and quaestors for the office. Future emperors would continue to dilute the power of the office by transferring its powers to newly created offices. However, the office did retain some powers over licentiousness and disorder, in particular over the baths and brothels, as well as the registration of prostitutes. In the 3rd century, it disappeared altogether.\n\nUnder the Empire, Roman colonies and cities often had officials with powers similar to those of the republican aediles, although their powers widely varied. It seems as though they were usually chosen annually. Today in Portugal the county mayor can still be referred to as 'edil' (e.g. 'O edil de Coimbra', meaning 'the mayor of Coimbra'), a way of reference used also in Romania for any mayors (ex. 'Edil al Bucureștiului', meaning 'mayor of Bucharest'). In Spain (and Latin America) the members of municipal councils are called concejales or ediles.\n\nIn his play \"Coriolanus\", Shakespeare references the aediles. However, they are minor characters, and their chief role is to serve as policemen.\n\n"}
{"id": "2386", "url": "https://en.wikipedia.org/wiki?curid=2386", "title": "American Airlines", "text": "American Airlines\n\nAmerican Airlines, Inc. (AA), commonly referred to as American, is a major American airline headquartered in Fort Worth, Texas, within the Dallas-Fort Worth metroplex. It is the world's largest airline when measured by fleet size, revenue, scheduled passenger-kilometres flown, and number of destinations served. American together with its regional partners operates an extensive international and domestic network with an average of nearly 6,700 flights per day to nearly 350 destinations in more than 50 countries.\n\nAmerican Airlines is a founding member of Oneworld alliance, the third largest airline alliance in the world and coordinates fares, services, and scheduling with alliance partners British Airways, Iberia, and Finnair in the transatlantic market and with Cathay Pacific and Japan Airlines in the transpacific market. Regional service is operated by independent and subsidiary carriers under the brand name of American Eagle.\n\nAmerican operates out of ten hubs located in Dallas/Fort Worth, Charlotte, Chicago-O'Hare, Philadelphia, Miami, Phoenix, Washington, DC-National, Los Angeles, New York-JFK, and New York-LaGuardia. American operates its primary maintenance base at Tulsa International Airport in addition to the maintenance locations located at its hubs. Dallas/Fort Worth International Airport is American's largest passenger carrying hub handling 51.1 million passengers annually with an average of 140,000 passengers daily. The company as of 2015 employs over 113,300 people. Through the airline's parent company, American Airlines Group, it is publicly traded under NASDAQ: AAL with a market capitalization of over $40.99 billion as of 2015.\n\nAmerican Airlines was started in 1930 via a union of more than eighty small airlines.\n\nThe two organizations from which American Airlines was originated were Robertson Aircraft Corporation and Colonial Air Transport. The former was first formed in Missouri in 1921, with both being merged in 1929 into holding company The Aviation Corporation. This in turn, was made in 1930 into an operating company and rebranded as American Airways. In 1934, when new laws and attrition of mail contracts forced many airlines to reorganize, the corporation redid its routes into a connected system, and was renamed American Airlines. Between 1970 and 2000, the company grew into being an international carrier, purchasing Trans World Airlines in 2001.\n\nIn 2011, due to a downturn in the airline industry, American Airlines' parent company AMR Corporation filed for bankruptcy protection. In 2013, US Airways and American Airlines merged. Eventually operations were merged under one operating certificate to create the largest United States airline which kept the American Airlines brand name.\n\nAmerican Airlines is headquartered in Fort Worth, Texas, adjacent to the Dallas/Fort Worth International Airport. The headquarters is located in two office buildings in the CentrePort office complex and these buildings together have about of space. over 4,300 employees work at this complex.\n\nBefore it was headquartered in Texas, American Airlines was headquartered at 633 Third Avenue in the Murray Hill area of Midtown Manhattan, New York City. In 1979 American moved its headquarters to a site at Dallas/Fort Worth International Airport, which affected up to 1,300 jobs. Mayor of New York City Ed Koch described the move as a \"betrayal\" of New York City. American moved to two leased office buildings in Grand Prairie, Texas. On January 17, 1983, the airline finished moving into a $150 million ($ when adjusted for inflation), facility in Fort Worth; $147 million (about $ when adjusted for inflation) in Dallas/Fort Worth International Airport bonds financed the headquarters. The airline began leasing the facility from the airport, which owns the facility.\n\nAs of 2015 American Airlines is the corporation with the largest presence in Fort Worth.\n\nIn 2015 the airline announced it will build a new headquarters in Fort Worth. Groundbreaking began in the spring of 2016 and occupancy is scheduled for summer 2019. The airline plans to house 5,000 new workers in the building.\n\nIt will be located on a property adjacent to the airline's flight academy and conference and training center, west of Texas State Highway 360, west from the current headquarters. The airline will lease a total of from Dallas-Fort Worth International Airport and this area will include the headquarters.Construction of the new headquarters is scheduled to occur after the demolition of the Sabre facility.\n\nThe airline considered developing a new headquarters in Irving, on the Texas Stadium site, before deciding to keep the headquarters in Fort Worth.\n\nAs of November 2013 American Airlines and American Eagle received $10,011,836 in annual federal subsidies for Essential Air Services. These subsidies are awarded by public tender and ensure that small, rural airports can be connected to the national air network.\n\n\nViolations occurring over a 4½ year period—from October 1993 to July 1998—targeted American Airlines for using high-sulfur fuel in motor vehicles at 10 major airports around the country. Under the federal Clean Air Act high sulfur fuel cannot be used in motor vehicles. American Airlines promptly identified and corrected these violations of the Clean Air Act.\n\nAmerican Airlines' wastewater treatment plant recycles water used at the base to wash aircraft, process rinse water tanks, and irrigate landscape. That alone has saved almost $1 million since 2002. In addition to that, American Airlines has also won the award for the reduction of hazardous waste that saved them $229,000 after a $2,000 investment. A bar code system is used to track hazardous waste. It has led to reduction of waste by 50 percent since 2000.\n\nAmerican Airlines is title sponsor of two basketball venues: American Airlines Center (Dallas Mavericks), (Dallas Stars) and American Airlines Arena (Miami Heat).\n\nThe company sponsors several professional sports teams:\n\nIn 1931, Goodrich Murphy, an American employee, designed the AA logo. The logo was redesigned by Massimo Vignelli in 1967. Thirty years later, in 1997, American Airlines was able to make its logo Internet-compatible by buying the domain AA.com. \"AA\" is also American's two-letter IATA airline designator.\n\nOn January 16, 2013, American launched a new rebranding and marketing campaign with FutureBrand dubbed, \"A New American\". This included a new logo replacing the logo used since 1967. American Airlines calls the new logo the \"Flight Symbol, incorporating the eagle, star, and the letter “A” of the classic logo.\n\nAmerican's early liveries varied widely, but a common livery was adopted in the 1930s, featuring an eagle painted on the fuselage. The eagle became a symbol of the company and inspired the name of American Eagle Airlines. Propeller aircraft featured an international orange lightning bolt running down the length of the fuselage, which was replaced by a simpler orange stripe with the introduction of jets.\n\nIn the late 1960s, American commissioned designer Massimo Vignelli to develop a new livery. The original design called for a red, white, and blue stripe on the fuselage, and a simple \"AA\" logo, without an eagle, on the tail; instead, Vignelli created a highly stylized eagle, which remained the company's logo until 2013. In 1999, American painted a new Boeing 757 (N679AN) in its 1959 international orange livery. One Boeing 777 and one Boeing 757 were painted in standard livery with a pink ribbon on the sides and on the tail, in support of Susan G. Komen for the Cure. One Boeing 757 is painted with a yellow ribbon on the tailfin on the aircraft and on the side of the body says \"Flagship Freedom\". American Eagle, the airline's regional airline has the same special livery on ERJ-145 aircraft.\nOn January 17, 2013, American unveiled a new livery. Before then, American had been the only major U.S. airline to leave most of its aircraft surfaces unpainted. This was because C. R. Smith hated painted aircraft, and refused to use any liveries that involved painting the entire plane. Robert \"Bob\" Crandall later justified the distinctive natural metal finish by noting that less paint reduced the aircraft's weight, thus saving on fuel costs.\n\nIn January 2013, American launched a new rebranding and marketing campaign dubbed, \"The New American\". In addition to a new logo, American Airlines introduced a new livery for its fleet. The airline calls the new livery and branding \"a clean and modern update\". The current design features an abstract American flag on the tail, along with a silver-painted fuselage, as a throw-back to the old livery. The new design was painted by Leading Edge Aviation Services in California. Doug Parker, the incoming CEO indicated that the new livery could be short-lived, stating that \"maybe we need to do something slightly different than that ... The only reason this is an issue now is because they just did it right in the middle, which kind of makes it confusing, so that gives us an opportunity, actually, to decide if we are going to do something different because we have so many airplanes to paint\".\n\nIn the end, American let its employees decide the new livery's fate. On an internal website for employees, American posted two options, one the new livery and one a modified version of the old livery. All of the American Airlines Group employees (including US Airways and other affiliates) were able to vote. American ultimately decided to keep the new look. Parker announced that American would keep a US Airways heritage aircraft in the fleet, with plans to add a heritage TWA aircraft and a heritage American plane with the old livery.\n\n\nAmerican currently operates ten hubs across the continental U.S.\n\n\n\nAmerican operated interchange flight services in conjunction with Alaska Airlines during the 1970s between Texas and Alaska during the construction of the Trans-Alaska oil pipeline. This interchange agreement allowed for single, no change of aircraft service between Houston, Texas and Dallas/Fort Worth, Texas, and Anchorage, Alaska and Fairbanks, Alaska. The round trip routing of this interchange flight was Houston-Dallas/Fort Worth-Seattle-Anchorage-Fairbanks with Seattle, Washington serving as the interchange point where flight and cabin crews were changed from one airline to the other. Boeing 727-200 jetliners provided by both American and Alaska Airlines were utilized to provide this interchange service.\n\nAmerican Airlines is the only US carrier that flies to Barranquilla, Belo Horizonte, Brasilia, Cali, Cap-Haitien, Cienfuegos, Fort-de-France, Guayaquil, La Paz, Manaus, Maracaibo, Montevideo, Pointe-a-Pitre, San Salvador (Bahamas), Santa Cruz de la Sierra, and Varadero. It is also the leading U.S. carrier to Cuba in terms of passenger volume.\n\nAmerican Airlines codeshares with the following airlines:\n\nIn particular, American has joint ventures with British Airways, Iberia, and Finnair on transatlantic routes and with Japan Airlines and Qantas on transpacific routes.\n\nAs of February 2017, American Airlines operates a fleet of 939 aircraft, making it the largest commercial fleet in the world. It operates a mix of Airbus, Boeing, Embraer, and McDonnell Douglas aircraft.\n\nOver two thirds of American's aircraft are narrow-bodies, mainly Airbus A320 series and Boeing 737-800. It also operates Boeing 757, Embraer 190 and McDonnell Douglas MD-82/83, but most of them are planned to be phased out within five years.\n\nIts wide-body aircraft are mainly Boeing airliners. It is the third-largest operator of the Boeing 767 series and the fifth-largest operator of the Boeing 777 series. It also operates the Airbus A330.\n\nThe Flagship Suite is American's international first class product. It is exclusively offered on all Boeing 777-300ERs in the fleet. \n\n• Boeing 777-300ER: Fully lie-flat seats with direct aisle access in a 1-2-1 reverse herringbone configuration. Seat length: 82 inches (208 cm). Equipped with a 17-inch (43 cm) touchscreen monitor and touchscreen handset, two universal AC power outlets, and USB ports.\n\nAmenities Include:\n\n• Flagship check-in privileges\n\n• 3 complimentary checked bags\n\n• Access to the Flagship Lounge (International First Class Lounge while the Flagship Lounges are being refurbished)\n\n• Early boarding\n\n• First Class amenity kit\n\n• Turndown service with pajamas\n\n• A pair of Bose QuietComfort Acoustic Noise Canceling Headsets to use during flight\n\n• Inflight wine tasting\n\n• Premium alcoholic beverages and wine selections (including pre-departure champagne service)\n\n• Chef-inspired dining options\n\n• Access to the premium cabin walk-up bar, which features assorted snacks and beverages throughout the duration of the flight.\n\n• Airbus A330: Fully lie-flat Cirrus seats manufactured by Zodiac Seats France and designed by JPA Design with direct aisle access in a 1-2-1 reverse herringbone configuration. Seat length: 76-80 inches (193–203 cm). Equipped with a 12.1 inch (31 cm) touchscreen monitor, one universal AC power outlet, and USB ports.[1]\n\n• Boeing 777-300ER: Fully lie-flat Cirrus seats manufactured by Zodiac Seats UK, designed by JPA Design, and licensed from Cathay Pacific with direct aisle access in a 1-2-1 reverse herringbone configuration. Seat length: 76-80 inches (193–203 cm). Equipped with a 15.4 (39 cm) inch touchscreen monitor, one universal AC power outlet, and USB ports.[2]\n\n• Boeing 787-8: Fully lie-flat seats manufactured by Zodiac Seats France and designed for American Airlines with direct aisle access in a 1-2-1 reverse herringbone configuration with front-facing and rear-facing seats. Seat length: 77 inches (196cm). Equipped with a 16-inch (41 cm) touchscreen monitor and touchscreen handset, two universal AC power outlets, and USB ports.\n\n• Boeing 777-200ER Version 1: Fully lie-flat seats manufactured by Zodiac Seats France, designed for American Airlines, with direct aisle access in a 1-2-1 reverse herringbone configuration with front-facing and rear-facing seats. Seat length: 77 inches (196cm). Equipped with a 16-inch (41 cm) touchscreen monitor and touchscreen handset, two universal AC power outlets, and USB ports.\n\n• Boeing 777-200ER Version 2: Fully lie-flat Super Diamond seats manufactured by B/E Aerospace and designed for American Airlines with direct aisle access in a 1-2-1 reverse herringbone configuration. Seat length: 77 inches (196cm). Equipped with a BLANK touchscreen monitor and touchscreen handset, one universal AC power outlet, and USB ports.\n\n• Boeing 767-300ER Post-Retrofit: Fully lie-flat seats designed by Thompson Aero Seating with direct aisle access in a 1-2-1 staggered configuration. Equipped with Samsung Galaxy Tab™ 10.1 inch (26 cm) tablets, two universal AC power outlets (one to power the tablet), and USB ports.\n\n• Boeing 767-300ER Pre-Retrofit: Angled lie-flat seats manufactured by Recaro in a 2-2-2 configuration. Seat length: 58-61 inches (147–155 cm). Equipped with Samsung Galaxy Tab™ 10.1 inch (26 cm) tablets, and two DC power outlets (one to power the tablet).These seats are currently in the process of being replaced.[5]\n\n• Boeing 757-200 Post-Retrofit: Fully lie-flat Diamond seats manufactured by B/E Aerospace and designed for American Airlines in a 2-2 configuration. Seat length: 75–78 inches (191–198cm). Equipped with Samsung Galaxy Tab™ 10.1 inch (26 cm) tablets, and two universal AC power outlets (one to power the tablet).\n\n• Boeing 757-200 Pre-Retrofit (Version 1): Angled lie-flat seats manufactured by Recaro in a 2-2 configuration equipped on legacy American Airlines aircraft. Seat length: 58-61 inches (147–155 cm). Equipped with a 10.6 inch touchscreen and a DC power outlet. These seats are currently in the process of being replaced.\n\n• Boeing 757-200 Pre-Retrofit (Version 2): Recliner seats in 2-2 configuration equipped on legacy US Airways aircraft. Seat length: 60 inches (152 cm). Equipped with Samsung Galaxy Tab™ 10.1 inch (26 cm) tablets, and a DC power outlet. These seats are currently in the process of being replaced.\n\nAmenities Include:\n\n• Priority check-in privileges\n\n• 2 complimentary checked bags\n\n• Access to the Admirals Club\n\n• Early boarding\n\n• Business Class amenity kit\n\n• A pair of Bose QuietComfort Acoustic Noise Canceling Headsets to use during flight\n\n• Premium alcoholic beverages and wine selections (including pre-departure beverage service)\n\n• Chef-inspired dining options\n\n• Access to the premium cabin walk-up bar, which features assorted snacks and beverages throughout the duration of the flight (available on the Boeing 777-300ER, Boeing 777-200, Boeing 787-8, and Boeing 787-9)\n\n• On flights from Los Angeles to Hong Kong and Sydney and Dallas to Hong Kong, turndown service and pajamas are also provided\n\nAmerican has dedicated 17 Airbus A321s (A321T) in its fleet for the specific use of flying transcontinental routes between New York JFK–Los Angeles and New York JFK–San Francisco. These aircraft offer two premium cabins, First Class and Business Class, which are unique among domestic mainline aircraft in American's fleet:\n\n• First Class: Seats are arranged in a 1-1 reverse herringbone configuration offering direct aisle access. They are fully lie-flat, and come equipped with a 15.4 (39 cm) inch touchscreen monitor, universal AC power outlets, and USB ports. These seats are similar to the ones in the Business Class cabin on the Boeing 777-300ER. Transcontinental First Class passengers receive exclusive amenities such as Flagship check-in at New York JFK and LAX, and an amenity kit that is similar to the one given to international Business Class passengers.\n\n• Business Class: Fully lie-flat seats are set up in a 2-2 configuration. Equipped with a 15.4 inch (39 cm) touchscreen monitor, two universal AC power outlets, and two USB ports.\n\nAmenities offered to all Transcontinental premium cabin passengers include Admirals Club access, premium food and beverage options, and a pair of Bose QuietComfort Acoustic Noise Canceling Headsets.\n\nFirst Class is offered on all domestic mainline aircraft, as well as regional aircraft with more than 50 seats. When such aircraft are used on flights to international destinations including Canada, Mexico, Central America, and the Caribbean, the First Class cabin is branded as Business Class. Seats range from 19–21 inches (48–53 cm) in width and have 37–42 inches (94–106 cm) of pitch. Dining options include free snacks, beverages, and alcohol on all flights, with three-course meals offered on flights 900 miles (1,448 km) or longer (select routes under 900 miles offer meal service).\n\nOn December 9, 2015, American announced a new Premium Economy product for most long-haul widebody aircraft. This new product will debut on the new 787-9s in late 2016 and will be available on the new A350s in 2018. It will also be retrofitted to all other widebody aircraft within the next three years, excluding 767s due to their upcoming retirement. The seats will be wider than standard Main Cabin seats and will offer 38\" of pitch, 2\" more than Main Cabin Extra seats, as well as a footrest. Premium Economy customers will also get two free checked bags, priority boarding, and enhanced food and drink service including free alcohol. This product will make American Airlines the first U.S. carrier to offer a four-cabin aircraft.\n\nAmerican's economy plus product (not to be confused with premium economy), Main Cabin Extra, is available on most of the mainline fleet and American Eagle regional aircraft with more than 50 seats. Exceptions include a majority of former US Airways aircraft (as of May 2015), US Airways Express regional aircraft, and a handful of 777-200ERs that have yet to be retrofitted. Seats range from 17.2–18.5 inches (44–47 cm) in width and have 34–38 inches (86–97 cm) of pitch, which is 4–6 more inches of pitch offered in regular economy seating. American will retain Main Cabin Extra when the new Premium Economy product enters service in late 2016.\n\nMain Cabin is American's economy product, and is found on all mainline and regional aircraft in its fleet. Seats range from 17–18.5 inches (43–47 cm) in width and have 30–32 inches (76–81 cm) of pitch. Newer aircraft, including all Boeing 777-300ER, refurbished Boeing 777-200ER's, all Boeing 787 Dreamliners, all Airbus A330s, all newly delivered Airbus A319s and Boeing 737s, and most newly delivered Airbus A321s, include seatback TVs, featuring AVOD in each seat.\n\nAmerican's basic economy product, Basic Economy, is available on select routes. It is American's lowest main cabin fare. Basic economy is located in main cabin, but comes with restrictions. These restrictions include assigned seat at check in, no access to overhead bins, no upgrades or refunds, and boarding in the last group.\n\nAmerican Airlines marketed increased legroom in economy class as \"More Room Throughout Coach\", also referred to as \"MRTC\" starting in February 2000. Two rows of economy class seats were removed on Boeing 737 and McDonnell Douglas MD-80 aircraft. Amid financial losses, this scheme was discontinued in 2004.\n\nIn May 2017, American announced they would be adding more seats to some of its Boeing 737 Max jetliners and reducing overall legroom in the basic economy class. The last three rows will lose two inches; going from the current 31 to 29 inches. The remainder of the economy cabin will have 30 inches of legroom. This compares to Jet Blue with 34 inches of legroom and Spirit with 28 inches.\n\nAAdvantage is the frequent flyer program for American Airlines. It was launched on May 1, 1981, and it remains the largest frequent flyer program with over 67 million members as of 2011.\n\nThe Admirals Club was conceived by AA president C.R. Smith as a marketing promotion shortly after he was made an honorary Texas Ranger. Inspired by the Kentucky colonels and other honorary organizations, Smith decided to make particularly valued passengers \"admirals\" of the \"Flagship fleet\" (AA called its aircraft \"Flagships\" at the time). The list of Admirals included many celebrities, politicians, and other VIPs, as well as more \"ordinary\" customers who had been particularly loyal to the airline.\n\nThere was no physical Admirals Club until shortly after the opening of LaGuardia Airport. During the airport's construction, New York Mayor Fiorello LaGuardia had an upper-level lounge set aside for press conferences and business meetings. At one such press conference, he noted that the entire terminal was being offered for lease to airline tenants; after a reporter asked whether the lounge would be leased as well, LaGuardia replied that it would, and a vice president of AA immediately offered to lease the premises. The airline then procured a liquor license and began operating the lounge as the \"Admirals Club\" in 1939.\n\nThe second Admirals Club opened at Washington National Airport. Because it was illegal to sell alcohol in Virginia at the time, the club contained refrigerators for the use of its members, so they could store their own liquor at the airport. For many years, membership in the Admirals Club (and most other airline lounges) was by the airline's invitation. After a passenger sued for discrimination, the Club (and most other airline lounges) switched to a paid membership program.\n\nThough affiliated with the Admirals Club and staffed by many of the same employees, the Flagship Lounge is a separate lounge specifically designed for customers flying in First Class on transcontinental domestic flights and international flights, as well as AAdvantage Executive Platinum and Oneworld Emerald frequent flyers. Flagship Lounges are now available at four airports: Chicago-O'Hare, London-Heathrow, Los Angeles, and New York-JFK. American also previously offered a Flagship Lounge in Miami from 2000 to 2002, and again from 2009. It plans to open again in 2017.\n\n\n\n"}
{"id": "2388", "url": "https://en.wikipedia.org/wiki?curid=2388", "title": "Antidepressant", "text": "Antidepressant\n\nAntidepressants are drugs used for the treatment of major depressive disorder and other conditions, including dysthymia, anxiety disorders, obsessive compulsive disorder, eating disorders, chronic pain, neuropathic pain and, in some cases, dysmenorrhoea, snoring, migraine, attention-deficit hyperactivity disorder (ADHD), addiction, dependence, and sleep disorders. They may be prescribed alone or in combination with other medications.\n\nThe most important classes of antidepressants are the selective serotonin reuptake inhibitors (SSRIs), serotonin–norepinephrine reuptake inhibitors (SNRIs), tricyclic antidepressants (TCAs), monoamine oxidase inhibitors (MAOIs), reversible inhibitors of monoamine oxidase A (RIMAs), tetracyclic antidepressants (TeCAs), and noradrenergic and specific serotonergic antidepressant (NaSSAs). St John's wort is also used in the treatment of depression.\n\nOne theory regarding the cause of depression is that it is characterized by an overactive hypothalamic–pituitary–adrenal axis (HPA axis) that resembles the neuro-endocrine response to stress. These HPA axis abnormalities participate in the development of depressive symptoms, and antidepressants may serve to regulate HPA axis function.\n\nFor depression, the Hamilton Depression Rating Scale (HAM-D) is often used to measure the severity of depression. The maximum score for the 17-item HAM-D questionnaire is 52; the higher the score, the more severe the depression.\n\nThe UK National Institute for Health and Care Excellence (NICE) 2009 guidelines indicate that antidepressants should not be routinely used for the initial treatment of mild depression, because the risk-benefit ratio is poor. The guidelines recommend that antidepressant treatment should be considered for:\n\nThe guidelines further note that antidepressant treatment should be used in combination with psychosocial interventions in most cases, should be continued for at least six months to reduce the risk of relapse, and that SSRIs are typically better tolerated than other antidepressants.\n\nAmerican Psychiatric Association treatment guidelines recommend that initial treatment should be individually tailored based on factors that include severity of symptoms, co-existing disorders, prior treatment experience, and patient preference. Options may include pharmacotherapy, psychotherapy, electroconvulsive therapy (ECT), transcranial magnetic stimulation (TMS) or light therapy. Antidepressant medication is recommended as an initial treatment choice in people with mild, moderate, or severe major depression, and should be given to all patients with severe depression unless ECT is planned.\n\nConflicting results have arisen from studies analyzing the efficacy of antidepressants by comparisons to placebo in people with acute mild to moderate depression. Stronger evidence supports the usefulness of antidepressants in the treatment of depression that is chronic (dysthymia) or severe.\n\nResearchers Irving Kirsch and Thomas Moore have contested the pharmacological activity of antidepressants in the relief of depression, and state that the evidence is most consistent a role as active placebos. Their study consisted of a meta analysis incorporating data from both published studies and unpublished data obtained from the FDA via a Freedom of Information Act request. Overall, antidepressant pills worked 18% better than placebos, a statistically significant difference, but not one that is clinically significant. In a later publication, Kirsch concluded that the overall effect of new-generation antidepressant medication is below recommended criteria for clinical significance.\n\nAnother study focusing on paroxetine (Paxil) and imipramine found that antidepressant drugs were only slightly better than placebo in cases of mild or moderate depression they surveyed but offered \"substantial\" benefit in those with severe depression.\n\nIn 2014 the U.S. FDA published a systematic review of all antidepressant maintenance trials submitted to the agency between 1985 and 2012. The authors concluded that maintenance treatment reduced the risk of relapse by 52% compared to placebo, and that this effect was primarily due to recurrent depression in the placebo group rather than a drug withdrawal effect.\n\nA review commissioned by the National Institute for Health and Care Excellence concluded that there is strong evidence that SSRIs have greater efficacy than placebo on achieving a 50% reduction in depression scores in moderate and severe major depression, and that there is some evidence for a similar effect in mild depression. The treatment guidelines developed in conjunction with this review suggest that antidepressants should be considered in patients with moderate to severe depression and those with mild depression that is persistent or resistant to other treatment modalities.\n\nThe Cochrane Collaboration recently performed a systematic review of clinical trials of the tricyclic antidepressant amitriptyline. The study concluded that in spite of moderate evidence for publication bias, there is strong evidence that the efficacy of amitriptyline is superior to placebo.\n\nA 2015 systematic review of add-on therapies for treatment-resistant depression concluded that quetiapine and aripiprazole have the strongest evidence-base supporting their efficacy, but they are associated with additional treatment-related side effects when used as an add-on therapy.\n\nA 2008 Cochrane Collaboration review on St John's wort (specifically, any extracts which contain \"Hypericum perforatum\"), and a 2015 meta-analytic systematic review by some of the same authors, both concluded that it: has superior efficacy to placebo in treating depression; is as effective as standard antidepressant pharmaceuticals for treating depression; and has fewer adverse effects than other antidepressants. The 2015 meta analysis concluded that it is difficult to assign a place for St. John's wort in the treatment of depression owing to limitations in the available evidence base, including large variations in efficacy seen in trials performed in German-speaking relative to other countries. Reversible inhibitors of monoamine oxidase A (RIMAs) have also been shown to be an effective drug therapy with greater tolerability than other antidepressants; however, the efficacy of SSRIs, tricyclic, and tetracyclic antidepressants in treating depression is supported by a much larger evidence base compared to other antidepressant drug therapies (i.e., St John's wort, rMAO-A inhibitors, serotonin–norepinephrine reuptake inhibitor, serotonin antagonist and reuptake inhibitors, noradrenaline reuptake inhibitors, and noradrenergic and specific serotonergic antidepressants).\n\nA study published in the \"Journal of the American Medical Association\" (\"JAMA\") demonstrated that the magnitude of the placebo effect in clinical trials of depression have been growing over time, while the effect size of tested drugs has remained relatively constant. The authors suggest that one possible explanation for the growing placebo effect in clinical trials is the inclusion of larger number of participants with shorter term, mild, or spontaneously remitting depression as a result of decreasing stigma associated with antidepressant use. Placebo response rates in clinical trials of complementary and alternative (CAM) therapies are significantly lower than those in clinical trials of traditional antidepressants.\n\nA 2004 review concluded that antidepressant studies that failed to support efficacy claims were dramatically less likely to be published than those that did support favorable efficacy claims. Similar results were obtained for a study of publication of clinical trials of antidepressants in children. A 2015 investigation of meta-analyses of antidepressant studies found that 79% of them had \"sponsorship or authors who were (pharmaceutical) industry employees and/or had conflicts of interest\".\n\nA 2012 meta-analysis found that fluoxetine and venlafaxine were effective for major depression in all age groups. The authors also found no evidence of a relationship between baseline severity of depression and degree of benefit of antidepressants over placebo.\n\nA review published in 2012 found a negative correlation between study year and efficacy of antidepressants as measured by response rate. The change in response rate was largely driven by increase in placebo response. However the authors still concluded that antidepressants were effective in treating depression. The authors found that TCAs were the most effective drug, followed by SNRIs, MAOIs, SSRIs and atypical antidepressants.\n\nThe largest and most expensive study conducted to date, on the effectiveness of pharmacological treatment for depression, was commissioned by the National Institute of Mental Health. The study was dubbed \"The Sequenced Treatment Alternatives to Relieve Depression\" (STAR*D) Study. The results are summarized here.\nParticipants in the trial were recruited when they sought medical care at general medical or psychiatric clinics. No advertising was used to recruit subjects in order to maximize the generalizability of the study results. Participants were required to have a minimum score of 14 point on the Hamilton Depression Scale (HAM-D17) in order to be enrolled in the trial. Generally accepted cutoffs are 7–17 points for mild depression, 18–24 points for moderate depression, and ≥ 24 for severe depression. The average participant baseline HAM-D17 score was 22. The pre-specified primary endpoint of this trial was remission as determined by the HAM-D score, with all patients with missing scores rated as non-responders. In the aftermath of the trial, the investigators have presented the results mainly using the secondary endpoint of remission according to the QIDS-SR16 Score, which tend to be somewhat higher.\nThere were no statistical or meaningful clinical differences in remission rates, response rates, or times to remission or response among any of the medications compared in this study. These included bupropion sustained release, bupropion, citalopram, lithium, mirtazapine, nortriptyline, sertraline, triiodothyronine, tranylcypromine, and venlafaxine extended release.\n\nA 2008 review of randomized controlled trials concluded that symptomatic improvement with SSRIs was greatest by the end of the first week of use, but that some improvement continued for at least 6 weeks.\n\nBetween 30% and 50% of individuals treated with a given antidepressant do not show a response. In clinical studies, approximately one-third of patients achieve a full remission, one-third experience a response and one-third are nonresponders. Partial remission is characterized by the presence of poorly defined residual symptoms. These symptoms typically include depressed mood, psychic anxiety, sleep disturbance, fatigue and diminished interest or pleasure. It is currently unclear which factors predict partial remission. However, it is clear that residual symptoms are powerful predictors of relapse, with relapse rates 3–6 times higher in patients with residual symptoms than in those who experience full remission. In addition, antidepressant drugs tend to lose efficacy over the course of treatment. According to data from the Centers for Disease Control and Prevention, less than one-third of Americans taking one antidepressant medication have seen a mental health professional in the previous year. A number of strategies are used in clinical practice to try to overcome these limits and variations. They include switching medication, augmentation, and combination.\n\nThe American Psychiatric Association 2000 Practice Guideline advises that where no response is achieved following six to eight weeks of treatment with an antidepressant, to switch to an antidepressant in the same class, then to a different class of antidepressant.\nA 2006 meta-analysis review found wide variation in the findings of prior studies; for patients who had failed to respond to an SSRI antidepressant, between 12% and 86% showed a response to a new drug. However, the more antidepressants an individual had already tried, the less likely they were to benefit from a new antidepressant trial. However, a later meta-analysis found no difference between switching to a new drug and staying on the old medication; although 34% of treatment resistant patients responded when switched to the new drug, 40% responded without being switched.\n\nFor a partial response, the American Psychiatric Association guidelines suggest augmentation, or adding a drug from a different class. These include lithium and thyroid augmentation, dopamine agonists, sex steroids, NRIs, glucocorticoid-specific agents, or the newer anticonvulsants.\n\nA combination strategy involves adding another antidepressant, usually from a different class so as to have effect on other mechanisms. Although this may be used in clinical practice, there is little evidence for the relative efficacy or adverse effects of this strategy. Other tests recently conducted include the use of psychostimulants as an augmentation therapy. Several studies have shown the efficacy of combining modafinil to treatment-resistant patients. It has been used to help combat SSRI-associated fatigue.\n\nThe therapeutic effects of antidepressants typically do not continue once the course of medication ends, resulting in a high rate of relapse. A 2003 meta-analysis of 31 placebo-controlled antidepressant trials, mostly limited to studies covering a period of one year, found that 18% of patients who had responded to an antidepressant relapsed while still taking it, compared to 41% whose antidepressant was switched for a placebo.\n\nA gradual loss of therapeutic benefit occurs in a minority of people during the course of treatment. A strategy involving the use of pharmacotherapy in the treatment of the acute episode, followed by psychotherapy in its residual phase, has been suggested by some studies.\n\nAntidepressants are recommended by the National Institute for Health and Care Excellence (NICE) for the treatment of generalized anxiety disorder (GAD) that has failed to respond to conservative measures such as education and self-help activities. GAD is a common disorder of which the central feature is excessive worry about a number of different events. Key symptoms include excessive anxiety about multiple events and issues, and difficulty controlling worrisome thoughts that persists for at least 6 months.\n\nAntidepressants provide a modest-to-moderate reduction in anxiety in GAD, and are superior to placebo in treating GAD. The efficacy of different antidepressants is similar.\n\nSSRIs are a second-line treatment of adult obsessive–compulsive disorder (OCD) with mild functional impairment and as first-line treatment for those with moderate or severe impairment. In children, SSRIs can be considered as a second-line therapy in those with moderate-to-severe impairment, with close monitoring for psychiatric adverse effects. SSRIs are efficacious in the treatment of OCD; patients treated with SSRIs are about twice as likely to respond to treatment as those treated with placebo. Efficacy has been demonstrated both in short-term treatment trials of 6 to 24 weeks and in discontinuation trials of 28 to 52 weeks duration.\n\nAntidepressants are recommended as an alternative or additional first step to self-help programs in the treatment of bulimia nervosa. SSRIs (fluoxetine in particular) are preferred over other antidepressants due to their acceptability, tolerability, and superior reduction of symptoms in short-term trials. Long-term efficacy remains poorly characterized. Bupropion is not recommended for the treatment of eating disorders due to an increased risk of seizure.\n\nSimilar recommendations apply to binge eating disorder. SSRIs provide short-term reductions in binge eating behavior, but have not been associated with significant weight loss.\n\nClinical trials have generated mostly negative results for the use of SSRIs in the treatment of anorexia nervosa. Treatment guidelines from the National Institute of Health and Care Excellence recommend against the use of SSRIs in this disorder. Those from the American Psychiatric Association note that SSRIs confer no advantage regarding weight gain, but that they may be used for the treatment of co-existing depressive, anxiety, or obsessive–compulsive disorders.\n\nA 2012 meta-analysis concluded that antidepressants treatment favorably affects pain, health-related quality of life, depression, and sleep in fibromyalgia syndrome. Tricyclics appear to be the most effective class, with moderate effects on pain and sleep and small effects on fatigue and health-related quality of life. The fraction of people experiencing a 30% pain reduction on tricyclics was 48% versus 28% for placebo. For SSRIs and SNRIs the fraction of people experiencing a 30% pain reduction was 36% (20% in the placebo comparator arms) and 42% (32% in the corresponding placebo comparator arms). Discontinuation of treatment due to side effects was common. Antidepressants including amitriptyline, fluoxetine, duloxetine, milnacipran, moclobemide, and pirlindole are recommended by the European League Against Rheumatism (EULAR) for the treatment of fibromyalgia based on \"limited evidence\".\n\nA 2014 meta-analysis from the Cochrane Collaboration found the antidepressant duloxetine to be effective for the treatment of pain resulting from diabetic neuropathy. The same group reviewed data for amitriptyline in the treatment of neuropathic pain and found limited useful randomized clinical trial data. They concluded that the long history of successful use in the community for the treatment of fibromyalgia and neuropathic pain justified its continued use. The group was concerned about the potential for overestimating the amount of pain relief provided by amitriptyline, and highlighted that only a small number of people will experience significant pain relief by taking this medication.\n\nDifficulty tolerating adverse effects is the most common reason for antidepressant discontinuation.\n\nAlmost any medication involved with serotonin regulation has the potential to cause serotonin toxicity (also known as \"serotonin syndrome\") an excess of serotonin that can induce mania, restlessness, agitation, emotional lability, insomnia and confusion as its primary symptoms. Although the condition is serious, it is not particularly common, generally only appearing at high doses or while on other medications. Assuming proper medical intervention has been taken (within about 24 hours) it is rarely fatal.\n\nMAOIs tend to have pronounced (sometimes fatal) interactions with a wide variety of medications and over-the-counter drugs. If taken with foods that contain very high levels of tyramine (e.g., mature cheese, cured meats, or yeast extracts), they may cause a potentially lethal hypertensive crisis. At lower doses the person may be bothered by only a headache due to an increase in blood pressure.\n\nIn response to these adverse effects, a different type of MAOI has been developed: the reversible inhibitor of monoamine oxidase A (RIMA) class of drugs. Their primary advantage is that they do not require the person to follow a special diet, while being purportedly effective as SSRIs and tricyclics in treating depressive disorders.\n\nSSRI use in pregnancy has been associated with a variety of risks with varying degrees of proof of causation. As depression is independently associated with negative pregnancy outcomes, determining the extent to which observed associations between antidepressant use and specific adverse outcomes reflects a causative relationship has been difficult in some cases. In other cases, the attribution of adverse outcomes to antidepressant exposure seems fairly clear.\n\nSSRI use in pregnancy is associated with an increased risk of spontaneous abortion of about 1.7-fold, and is associated with preterm birth and low birth weight.\n\nA systematic review of the risk of major birth defects in antidepressant-exposed pregnancies found a small increase (3% to 24%) in the risk of major malformations and a risk of cardiovascular birth defects that did not differ from non-exposed pregnancies. A study of fluoxetine-exposed pregnancies found a 12% increase in the risk of major malformations that just missed statistical significance. Other studies have found an increased risk of cardiovascular birth defects among depressed mothers not undergoing SSRI treatment, suggesting the possibility of ascertainment bias, e.g. that worried mothers may pursue more aggressive testing of their infants. Another study found no increase in cardiovascular birth defects and a 27% increased risk of major malformations in SSRI exposed pregnancies. The FDA advises for the risk of birth defects with the use of paroxetine and the MAOI should be avoided.\n\nA 2013 systematic review and meta-analysis found that antidepressant use during pregnancy was statistically significantly associated with some pregnancy outcomes, such as gestational age and preterm birth, but not with other outcomes. The same review cautioned that because differences between the exposed and unexposed groups were small, it was doubtful whether they were clinically significant.\n\nA neonate (infant less than 28 days old) may experience a withdrawal syndrome from abrupt discontinuation of the antidepressant at birth. Antidepressants have been shown to be present in varying amounts in breast milk, but their effects on infants are currently unknown.\n\nMoreover, SSRIs inhibit nitric oxide synthesis, which plays an important role in setting vascular tone. Several studies have pointed to an increased risk of prematurity associated with SSRI use, and this association may be due to an increase risk of pre-eclampsia of pregnancy.\n\nAnother possible problem with antidepressants is the chance of antidepressant-induced mania in patients with bipolar disorder. Many cases of bipolar depression are very similar to those of unipolar depression. Therefore, the patient can be misdiagnosed with unipolar depression and be given antidepressants. Studies have shown that antidepressant-induced mania can occur in 20–40% of bipolar patients. For bipolar depression, antidepressants (most frequently SSRIs) can exacerbate or trigger symptoms of hypomania and mania.\n\nStudies have shown that the use of antidepressants is correlated with an increased risk of suicidal behaviour and thinking (suicidality) in those aged under 25. This problem has been serious enough to warrant government intervention by the US Food and Drug Administration (FDA) to warn of the increased risk of suicidality during antidepressant treatment. According to the FDA, the heightened risk of suicidality is within the first one to two months of treatment. The National Institute for Health and Care Excellence (NICE) places the excess risk in the \"early stages of treatment\". A meta-analysis suggests that the relationship between antidepressant use and suicidal behavior or thoughts is age-dependent. Compared to placebo the use of antidepressants is associated with an increase in suicidal behavior or thoughts among those aged under 25 (OR=1.62). This increase in suicidality approaches that observed in children and adolescents. There is no effect or possibly a mild protective effect among those aged 25 to 64 (OR=0.79). Antidepressant treatment has a protective effect against suicidality among those aged 65 and over (OR=0.37).\n\nSexual side-effects are also common with SSRIs, such as loss of sexual drive, failure to reach orgasm, and erectile dysfunction. Although usually reversible, these sexual side-effects can, in rare cases, last for months or years after the drug has been completely withdrawn.\n\nIn a study of 1022 outpatients, overall sexual dysfunction with all antidepressants averaged 59.1% with SSRIs values between 57 and 73%, mirtazapine 24%, nefazodone 8%, amineptine 7% and moclobemide 4%. Moclobemide, a selective reversible MAO-A inhibitor, does not cause sexual dysfunction, and can actually lead to an improvement in all aspects of sexual function.\n\nBiochemical mechanisms suggested as causative include increased serotonin, particularly affecting 5-HT and 5-HT receptors; decreased dopamine; decreased norepinephrine; blockade of cholinergic and αadrenergic receptors; inhibition of nitric oxide synthetase; and elevation of prolactin levels. Mirtazapine is reported to have fewer sexual side-effects, most likely because it antagonizes 5-HT and 5-HT receptors and may, in some cases, reverse sexual dysfunction induced by SSRIs by the same mechanism.\n\nBupropion, a weak NDRI and nicotinic antagonist, may be useful in treating reduced libido as a result of SSRI treatment.\n\nChanges in appetite or weight are common among antidepressants, but largely drug-dependent and are related to which neurotransmitters they affect. Mirtazapine and paroxetine, for example, have the effect of weight gain and/or increased appetite, while others (such as bupropion and venlafaxine) achieve the opposite effect.\n\nThe antihistaminic properties of certain TCA- and TeCA-class antidepressants have been shown to contribute to the common side-effects of increased appetite and weight gain associated with these classes of medication.\n\nAntidepressant discontinuation symptoms were first reported with imipramine, the first tricyclic antidepressant (TCA), in the late 1950s, and each new class of antidepressants has brought reports of similar conditions, including monoamine oxidase inhibitors (MAOIs), SSRIs, and SNRIs. As of 2001, at least 21 different antidepressants, covering all the major classes, were known to cause discontinuation syndromes. The problem has been poorly studied, and most of the literature has been case reports or small clinical studies; incidence is hard to determine and controversial.\n\nPeople with discontinuation syndrome have been on an antidepressant for at least four weeks and have recently stopped taking the medication, either abruptly or after a fast taper. Common symptoms include flu-like symptoms (nausea, vomiting, diarrhea, headaches, sweating), sleep disturbances (insomnia, nightmares, constant sleepiness), sensory/movement disturbances (imbalance, tremors, vertigo, dizziness, electric-shock-like experiences), mood disturbances (dysphoria, anxiety, agitation) and cognitive disturbances (confusion and hyperarousal). Over fifty symptoms have been reported.\n\nMost cases of discontinuation syndrome last between one and four weeks, are relatively mild, and resolve on their own; in rare cases symptoms can be severe or extended. Paroxetine and venlafaxine seem to be particularly difficult to discontinue and prolonged withdrawal syndrome lasting over 18 months have been reported with paroxetine.\n\nWith the explosion of use and interest in SSRIs in the late 1980s and early 1990s, focused especially on Prozac, interest grew as well in discontinuation syndromes. In the late 1990s, some investigators thought that symptoms that emerged when antidepressants were discontinued, might mean that antidepressants were causing addiction, and some used the term \"withdrawal syndrome\" to describe the symptoms. Addictive substances cause physiological dependence, so that drug withdrawal causes suffering. These theories were abandoned, since addiction leads to drug-seeking behavior, and people taking antidepressants do not exhibit drug-seeking behavior. The term \"withdrawal syndrome\" is no longer used with respect to antidepressants, to avoid confusion with problems that arise from addiction. There are case reports of antidepressants being abused, but these are rare and are mostly limited to antidepressants with stimulant effects and to people who already had a substance use disorder. A 2012 comparison of the effects of stopping therapy with benzodiazepines and SSRIs argued that because the symptoms are similar, it makes no sense to say that benzodiazepines are addictive while SSRIs are not. Responses to that review noted that there is no evidence that people who stop taking SSRIs exhibit drug-seeking behavior while people who stop taking benzodiazepines do, and that the drug classes should be considered differently.\n\nAntidepressants can cause emotional blunting, or numbness. This is a reduction in extremes of emotion, both positive and negative. While the patient may feel less depressed, they may also feel less happiness or empathy in some situations. This may be cause for a dose reduction or medication change. The exact mechanism is unknown.\n\nThe earliest and probably most widely accepted scientific theory of antidepressant action is the monoamine hypothesis (which can be traced back to the 1950s), which states that depression is due to an imbalance (most often a deficiency) of the monoamine neurotransmitters (namely serotonin, norepinephrine and dopamine). It was originally proposed based on the observation that certain hydrazine anti-tuberculosis agents produce antidepressant effects, which was later linked to their inhibitory effects on monoamine oxidase, the enzyme that catalyses the breakdown of the monoamine neurotransmitters. All currently marketed antidepressants have the monoamine hypothesis as their theoretical basis, with the possible exception of agomelatine which acts on a dual melatonergic-serotonergic pathway. Despite the success of the monoamine hypothesis it has a number of limitations: for one, all monoaminergic antidepressants have a delayed onset of action of at least a week; and secondly, there are a sizeable portion (>40%) of depressed patients that do not adequately respond to monoaminergic antidepressants. A number of alternative hypotheses have been proposed, including the glutamate, neurogenic, epigenetic, cortisol hypersecretion and inflammatory hypotheses.\n\nSelective serotonin reuptake inhibitors (SSRIs) are believed to increase the extracellular level of the neurotransmitter serotonin by limiting its reabsorption into the presynaptic cell, increasing the level of serotonin in the synaptic cleft available to bind to the postsynaptic receptor. They have varying degrees of selectivity for the other monoamine transporters, with pure SSRIs having only weak affinity for the norepinephrine and dopamine transporters.\n\nSSRIs are the most widely prescribed antidepressants in many countries. The efficacy of SSRIs in mild or moderate cases of depression has been disputed.\n\nSerotonin–norepinephrine reuptake inhibitors (SNRIs) are potent inhibitors of the reuptake of serotonin and norepinephrine. These neurotransmitters are known to play an important role in mood. SNRIs can be contrasted with the more widely used selective serotonin reuptake inhibitors (SSRIs), which act mostly upon serotonin alone.\n\nThe human serotonin transporter (SERT) and norepinephrine transporter (NET) are membrane proteins that are responsible for the reuptake of serotonin and norepinephrine. Balanced dual inhibition of monoamine reuptake can possibly offer advantages over other antidepressants drugs by treating a wider range of symptoms.\n\nSNRIs are sometimes also used to treat anxiety disorders, obsessive–compulsive disorder (OCD), attention deficit hyperactivity disorder (ADHD), chronic neuropathic pain, and fibromyalgia syndrome (FMS), and for the relief of menopausal symptoms.\n\nSerotonin modulator and stimulators (SMSs), sometimes referred to more simply as serotonin modulators, are a type of drug with a multimodal action specific to the serotonin neurotransmitter system. To be precise, SMSs simultaneously modulate one or more serotonin receptors and inhibit the reuptake of serotonin. The term was created to describe the mechanism of action of the serotonergic antidepressant vortioxetine (Brintellix/Trintellix), which acts as a serotonin reuptake inhibitor (SRI), partial agonist of the 5-HT receptor, and antagonist of the 5-HT and 5-HT receptors. However, it can also technically be applied to vilazodone (Viibryd), which is an antidepressant as well and acts as an SRI and 5-HT receptor partial agonist.\n\nAn alternative term is serotonin partial agonist/reuptake inhibitor (SPARI), which can be applied only to vilazodone.\n\nSerotonin antagonist and reuptake inhibitors (SARIs) while mainly used as antidepressants, are also anxiolytics and hypnotics. They act by antagonizing serotonin receptors such as 5-HT and inhibiting the reuptake of serotonin, norepinephrine, and/or dopamine. Additionally, most also act as α-adrenergic receptor antagonists. The majority of the currently marketed SARIs belong to the phenylpiperazine class of compounds.\n\nNorepinephrine reuptake inhibitors (NRIs or NERIs) are a type of drug that acts as a reuptake inhibitor for the neurotransmitter norepinephrine (noradrenaline) by blocking the action of the norepinephrine transporter (NET). This in turn leads to increased extracellular concentrations of norepinephrine.\n\nNRIs are commonly used in the treatment of conditions like ADHD and narcolepsy due to their psychostimulant effects and in obesity due to their appetite suppressant effects. They are also frequently used as antidepressants for the treatment of major depressive disorder, anxiety and panic disorder. Additionally, many drugs of abuse such as cocaine and methylphenidate possess NRI activity, though it is important to mention that NRIs without combined dopamine reuptake inhibitor (DRI) properties are not significantly rewarding and hence are considered to have a negligible abuse potential. However, norepinephrine has been implicated as acting synergistically with dopamine when actions on the two neurotransmitters are combined (e.g., in the case of NDRIs) to produce rewarding effects in psychostimulant drugs of abuse.\n\nThe majority of the tricyclic antidepressants (TCAs) act primarily as serotonin–norepinephrine reuptake inhibitors (SNRIs) by blocking the serotonin transporter (SERT) and the norepinephrine transporter (NET), respectively, which results in an elevation of the synaptic concentrations of these neurotransmitters, and therefore an enhancement of neurotransmission. Notably, with the sole exception of amineptine, the TCAs have negligible affinity for the dopamine transporter (DAT), and therefore have no efficacy as dopamine reuptake inhibitors (DRIs). \n\nAlthough TCAs are sometimes prescribed for depressive disorders, they have been largely replaced in clinical use in most parts of the world by newer antidepressants such as selective serotonin reuptake inhibitors (SSRIs), serotonin–norepinephrine reuptake inhibitors (SNRIs) and norepinephrine reuptake inhibitors (NRIs). Adverse effects have been found to be of a similar level between TCAs and SSRIs.\n\nTetracyclic antidepressants (TeCAs) are a class of antidepressants that were first introduced in the 1970s. They are named after their chemical structure, which contains four rings of atoms, and are closely related to the tricyclic antidepressants (TCAs), which contain three rings of atoms.\n\nMonoamine oxidase inhibitors (MAOIs) are chemicals which inhibit the activity of the monoamine oxidase enzyme family. They have a long history of use as medications prescribed for the treatment of depression. They are particularly effective in treating atypical depression. They are also used in the treatment of Parkinson's disease and several other disorders.\n\nBecause of potentially lethal dietary and drug interactions, monoamine oxidase inhibitors have historically been reserved as a last line of treatment, used only when other classes of antidepressant drugs (for example selective serotonin reuptake inhibitors and tricyclic antidepressants) have failed.\n\nMAOIs have been found to be effective in the treatment of panic disorder with agoraphobia, social phobia, atypical depression or mixed anxiety and depression, bulimia, and post-traumatic stress disorder, as well as borderline personality disorder. MAOIs appear to be particularly effective in the management of bipolar depression according to a recent retrospective-analysis. There are reports of MAOI efficacy in obsessive–compulsive disorder (OCD), trichotillomania, dysmorphophobia, and avoidant personality disorder, but these reports are from uncontrolled case reports.\n\nMAOIs can also be used in the treatment of Parkinson's disease by targeting MAO-B in particular (therefore affecting dopaminergic neurons), as well as providing an alternative for migraine prophylaxis. Inhibition of both MAO-A and MAO-B is used in the treatment of clinical depression and anxiety disorders.\n\nSee the list of antidepressants for other drugs which are not specifically characterized.\n\nAdjunct medications are an umbrella term used to describe substances that increase the potency or \"enhance\" antidepressants. They work by affecting variables very close to the antidepressant, sometimes affecting a completely different mechanism of action. This may be attempted when depression treatments have not been successful in the past.\n\nCommon types of adjunct medication techniques generally fall into the following categories:\nIt is unknown if undergoing psychological therapy at the same time as taking anti-depressants enhances the anti-depressive effect of the medication.\n\nLithium has been used to augment antidepressant therapy in those who have failed to respond to antidepressants alone. Furthermore, lithium dramatically decreases the suicide risk in recurrent depression. There is some evidence for the addition of a thyroid hormone, triiodothyronine, in patients with normal thyroid function. \n\nPsychopharmacologists have also tried adding a stimulant, in particular, d-amphetamine. However, the use of stimulants in cases of treatment-resistant depression is relatively controversial. A review article published in 2007 found psychostimulants may be effective in treatment-resistant depression with concomitant antidepressant therapy, but a more certain conclusion could not be drawn due to substantial deficiencies in the studies available for consideration, and the somewhat contradictory nature of their results.\n\nBefore the 1950s, opioids and amphetamines were commonly used as antidepressants. Their use was later restricted due to their addictive nature and side effects. Extracts from the herb St John's wort have been used as a \"nerve tonic\" to alleviate depression.\n\nIn 1951, Irving Selikoff and Edward Robitzek, working out of Sea View Hospital on Staten Island, began clinical trials on two new anti-tuberculosis agents developed by Hoffman-LaRoche, isoniazid and iproniazid. Only patients with a poor prognosis were initially treated; nevertheless, their condition improved dramatically. Selikoff and Robitzek noted \"a subtle general stimulation … the patients exhibited renewed vigor and indeed this occasionally served to introduce disciplinary problems.\" The promise of a cure for tuberculosis in the Sea View Hospital trials was excitedly discussed in the mainstream press.\n\nIn 1952, learning of the stimulating side effects of isoniazid, the Cincinnati psychiatrist Max Lurie tried it on his patients. In the following year, he and Harry Salzer reported that isoniazid improved depression in two thirds of their patients and coined the term \"antidepressant\" to describe its action. A similar incident took place in Paris, where Jean Delay, head of psychiatry at Sainte-Anne Hospital, heard of this effect from his pulmonology colleagues at Cochin Hospital. In 1952 (before Lurie and Salzer), Delay, with the resident Jean-Francois Buisson, reported the positive effect of isoniazid on depressed patients. The mode of antidepressant action of isoniazid is still unclear. It is speculated that its effect is due to the inhibition of diamine oxidase, coupled with a weak inhibition of monoamine oxidase A.\n\nSelikoff and Robitzek also experimented with another anti-tuberculosis drug, iproniazid; it showed a greater psychostimulant effect, but more pronounced toxicity. Later, Jackson Smith, Gordon Kamman, George Crane, and Frank Ayd, described the psychiatric applications of iproniazid. Ernst Zeller found iproniazid to be a potent monoamine oxidase inhibitor. Nevertheless, iproniazid remained relatively obscure until Nathan Kline, the influential head of research at Rockland State Hospital, began to popularize it in the medical and popular press as a \"psychic energizer\". Roche put a significant marketing effort behind iproniazid. Its sales grew until it was recalled in 1961, due to reports of lethal hepatotoxicity.\n\nThe antidepressant effect of a tricyclic, a three ringed compound, was first discovered in 1957 by Roland Kuhn in a Swiss psychiatric hospital. Antihistamine derivatives were used to treat surgical shock and later as neuroleptics. Although in 1955 reserpine was shown to be more effective than placebo in alleviating anxious depression, neuroleptics were being developed as sedatives and antipsychotics.\n\nAttempting to improve the effectiveness of chlorpromazine, Kuhn in conjunction with the Geigy Pharmaceutical Company discovered the compound \"G 22355\", later renamed imipramine. Imipramine had a beneficial effect in patients with depression who showed mental and motor retardation. Kuhn described his new compound as a \"thymoleptic\" \"taking hold of the emotions,\" in contrast with neuroleptics, \"taking hold of the nerves\" in 1955–56. These gradually became established, resulting in the patent and manufacture in the US in 1951 by Häfliger and SchinderA.\n\nAntidepressants became prescription drugs in the 1950s. It was estimated that no more than 50 to 100 individuals per million suffered from the kind of depression that these new drugs would treat, and pharmaceutical companies were not enthusiastic in marketing for this small market. Sales through the 1960s remained poor compared to the sales of tranquilizers, which were being marketed for different uses. Imipramine remained in common use and numerous successors were introduced. The use of monoamine oxidase inhibitors (MAOI) increased after the development and introduction of \"reversible\" forms affecting only the MAO-A subtype of inhibitors, making this drug safer to use.\n\nBy the 1960s, it was thought that the mode of action of tricyclics was to inhibit norepinephrine reuptake. However, norepinephrine reuptake became associated with stimulating effects. Later tricyclics were thought to affect serotonin as proposed in 1969 by Carlsson and Lindqvist as well as Lapin and Oxenkrug.\n\nResearchers began a process of rational drug design to isolate antihistamine-derived compounds that would selectively target these systems. The first such compound to be patented was zimelidine in 1971, while the first released clinically was indalpine. Fluoxetine was approved for commercial use by the US Food and Drug Administration (FDA) in 1988, becoming the first blockbuster SSRI. Fluoxetine was developed at Eli Lilly and Company in the early 1970s by Bryan Molloy, Klaus Schmiegel, David Wong and others. SSRIs became known as \"novel antidepressants\" along with other newer drugs such as SNRIs and NRIs with various selective effects.\n\nSt John's wort fell out of favor in most countries through the 19th and 20th centuries, except in Germany, where Hypericum extracts were eventually licensed, packaged and prescribed. Small-scale efficacy trials were carried out in the 1970s and 1980s, and attention grew in the 1990s following a meta-analysis. It remains an over-the-counter drug (OTC) supplement in most countries. Research continues to investigate its active component hyperforin, and to further understand its mode of action.\n\nIn the United States, antidepressants were the most commonly prescribed medication in 2013. Of the estimated 16 million \"long term\" (over 24 months) users, roughly 70 percent are female.\n\nIn the UK, figures reported in 2010 indicated that the number of antidepressant prescribed by the National Health Service (NHS) almost doubled over a decade. Further analysis published in 2014 showed that number of antidepressants dispensed annually in the community went up by 25 million in the 14 years between 1998 and 2012, rising from 15 million to 40 million. Nearly 50% of this rise occurred in the four years after the 2008 banking crash, during which time the annual increase in prescriptions rose from 6.7% to 8.5%. These sources also suggest that aside from the recession, other factors that may influence changes in prescribing rates may include: improvements in diagnosis, a reduction of the stigma surrounding mental health, broader prescribing trends, GP characteristics, geographical location and housing status. Another factor that may contribute to increasing consumption of antidepressants is the fact that these medications now are used for other conditions including social anxiety and post traumatic stress.\n\nUnited States: The most commonly prescribed antidepressants in the US retail market in 2010 were:\n\nNetherlands: In the Netherlands, paroxetine, marketed as Seroxat among generic preparations, is the most prescribed antidepressant, followed by amitriptyline, citalopram and venlafaxine.\n\nIn looking at the issue of antidepressant use, some academics have highlighted the need to examine the use of antidepressants and other medical treatments in cross-cultural terms, due to the fact that various cultures prescribe and observe different manifestations, symptoms, meanings and associations of depression and other medical conditions within their populations. These cross-cultural discrepancies, it has been argued, then have implications on the perceived efficacy and use of antidepressants and other strategies in the treatment of depression in these different cultures. In India antidepressants are largely seen as tools to combat marginality, promising the individual the ability to re-integrate into society through their use—a view and association not observed in the West.\n\nSomewhat less than 10% of orally administered fluoxetine is excreted from humans unchanged or as glucuronide. Because most antidepressants function by inhibiting the reuptake of neurotransmitters serotonin, dopamine, and norepinepherine these drugs can interfere with natural neurotransmitter levels in other organisms impacted by indirect exposure. Antidepressants fluoxetine and sertraline have been detected in aquatic organisms residing in effluent dominated streams. The presence of antidepressants in surface waters and aquatic organisms has caused concern because ecotoxicological effects to aquatic organisms due to fluoxetine exposure have been demonstrated. Coral reef fish have been demonstrated to modulate aggressive behavior through serotonin.\n\nExposure to fluoxetine has been demonstrated to increase serotonergic activity in fish, subsequently reducing aggressive behavior. Artificially increasing serotonin levels in crustaceans can temporarily reverse social status and turn subordinates into aggressive and territorial dominant males. Perinatal exposure to fluoxetine at relevant environmental concentrations has been shown to lead to significant modifications of memory processing in 1-month-old cuttlefish. This impairment may disadvantage cuttlefish and decrease their survival.\n\n"}
{"id": "2389", "url": "https://en.wikipedia.org/wiki?curid=2389", "title": "Auger effect", "text": "Auger effect\n\nThe Auger effect is a physical phenomenon in which the filling of an inner-shell vacancy of an atom is accompanied by the emission of an electron from the same atom. When a core electron is removed, leaving a vacancy, an electron from a higher energy level may fall into the vacancy, resulting in a release of energy. Although most often this energy is released in the form of an emitted photon, the energy can also be transferred to another electron, which is ejected from the atom; this second ejected electron is called an Auger electron. The effect was first discovered by Lise Meitner in 1922; Pierre Victor Auger independently discovered the effect shortly after and is credited with the discovery in most of the scientific community.\n\nUpon ejection, the kinetic energy of the Auger electron corresponds to the difference between the energy of the initial electronic transition into the vacancy and the ionization energy for the electron shell from which the Auger electron was ejected. These energy levels depend on the type of atom and the chemical environment in which the atom was located. Auger electron spectroscopy involves the emission of Auger electrons by bombarding a sample with either X-rays or energetic electrons and measures the intensity of Auger electrons that result as a function of the Auger electron energy. The resulting spectra can be used to determine the identity of the emitting atoms and some information about their environment. Auger recombination is a similar Auger effect which occurs in semiconductors. An electron and electron hole (electron-hole pair) can recombine giving up their energy to an electron in the conduction band, increasing its energy. The reverse effect is known as impact ionization.\n\nThe Auger emission process was observed and published in 1922 by Lise Meitner, an Austrian-Swedish physicist, as a side effect in her competitive search for the nuclear beta electrons with the British physicist Charles Drummond Ellis.\n\nThe French physicist Pierre Victor Auger independently discovered it in 1923 upon analysis of a Wilson cloud chamber experiment and it became the central part of his PhD work. High-energy X-rays were applied to ionize gas particles and observe photoelectric electrons. The observation of electron tracks that were independent of the frequency of the incident photon suggested a mechanism for electron ionization that was caused from an internal conversion of energy from a radiationless transition. Further investigation, and theoretical work using elementary quantum mechanics and transition rate/transition probability calculations, showed that the effect was a radiationless effect more than an internal conversion effect.\n\n"}
{"id": "2391", "url": "https://en.wikipedia.org/wiki?curid=2391", "title": "Akio Morita", "text": "Akio Morita\n\nAkio Morita was born in Nagoya, Aichi, Japan. Morita's family was involved in sake, miso and soy sauce production in the village of Kosugaya (currently a part of Tokoname City) on the western coast of Chita Peninsula in Aichi Prefecture since 1665. He was the oldest of four siblings and his father Kyuzaemon trained him as a child to take over the family business. Akio, however, found his true calling in mathematics and physics, and in 1944 he graduated from Osaka Imperial University with a degree in physics. He was later commissioned as a sub-lieutenant in the Imperial Japanese Navy, and served in World War II. During his service, Morita met his future business partner Masaru Ibuka in the Navy's Wartime Research Committee.\n\nOn May 7, 1946, Ibuka founded \"Tokyo Tsushin Kogyo Kabushiki Kaisha\" (Tokyo Telecommunications Engineering Corporation, the forerunner of Sony Corporation) with about 20 employees and initial capital of ¥190,000. Ibuka was 38 years old. Morita, 25 years old joined \"Tokyo Tsushin Kogyo Kabushiki Kaisha\" shortly after its inception, with Morita's family investing in Sony during the early period and being the largest shareholder.\n\nIn 1949, the company developed magnetic recording tape and in 1950, sold the first tape recorder in Japan. In 1957, it produced a pocket-sized radio (the first to be fully transistorized), and in 1958, Morita and Ibuka decided to rename their company Sony (derived from \"sonus\"--Latin for \"sound\"—and \"Sonny-boys\" the most common American expression). Morita was an advocate for all the products made by Sony. However, since the radio was slightly too big to fit in a shirt pocket, Morita made his employees wear shirts with slightly larger pockets to give the radio a \"pocket sized\" appearance. In 1960, it produced the first transistor television in the world. In 1973, Sony received an Emmy Award for its Trinitron television-set technology. In 1975, it released the first Betamax home video recorder, a year before VHS format came out. In 1979, the Walkman was introduced, making it one of the world's first portable music players. In 1984, Sony launched the Discman series which extended their Walkman brand to portable CD products.\n\nIn 1960, the Sony Corporation of America (SONAM, currently abbreviated as SCA) was established in the United States. In 1961, Sony Corporation was the first Japanese company to be listed on the New York Stock Exchange, in the form of American depositary receipts (ADRs), which are traded over-the-counter. Sony bought CBS Records Group which consisted of Columbia Records, Epic Records and other CBS labels in 1988 and Columbia Pictures Entertainment (Columbia Pictures, TriStar Pictures and others) in 1989.\n\nOn November 25, 1994, Morita stepped down as Sony chairman after suffering a cerebral hemorrhage while playing tennis. He was succeeded by Norio Ohga, who had joined the company in the 1950s after sending Morita a letter denouncing the poor quality of the company's tape recorders.\n\nMorita was vice chairman of the Japan Business Federation (Japan Federation of Economic Organizations), and was a member of the Japan-U.S. Economic Relations Group, also known as the \"Wise Men's Group\". He was also the third Japanese chairman of the Trilateral Commission. His amateur radio call sign is JP1DPJ.\n\nIn 1966, Morita wrote a book called \"Gakureki Muyō Ron\" (学歴無用論, Never Mind School Records), where he stresses that school records are not important to success or one's business skills. In 1986, Morita wrote an autobiography titled \"Made in Japan\". He co-authored the 1991 book \"The Japan That Can Say No\" with politician Shintaro Ishihara, where they criticized American business practices and encouraged Japanese to take a more independent role in business and foreign affairs. The book was translated into English and caused controversy in the United States, and Morita later had his chapters removed from the English version and distanced himself from the book.\n\nMorita was awarded the Albert Medal by the United Kingdom's Royal Society of Arts in 1982, the first Japanese to receive the honor. Two years later, he received the prestigious Legion of Honour, and in 1991, was awarded the First Class Order of the Sacred Treasure from the Emperor of Japan. In 1993, he was awarded an honorary British knighthood (KBE). Morita received the International Distinguished Entrepreneur Award from the University of Manitoba in 1987. He was posthumously awarded the Grand Cordon of the Order of the Rising Sun in 1999.\n\nMorita suffered a stroke in 1993, during a game of tennis. On November 25, 1994, he stepped down as Sony chairman. On October 3, 1999, Morita died of pneumonia at the age of 78.\n\n\n\n \n"}
{"id": "2392", "url": "https://en.wikipedia.org/wiki?curid=2392", "title": "Anode", "text": "Anode\n\nAn anode is an electrode through which conventional current flows into a polarized electrical device. A common mnemonic is ACID for \"anode current into device\". The direction of (positive) electric current is opposite to the direction of electron flow: (negatively charged) electrons flow out the anode to the outside circuit.\n\nThe terms anode and cathode do not relate to the voltage polarity of those electrodes but the direction of the current: whether positive charge is flowing into or out of the device. Conventional current quantifies the flow of positive charge. In most cases, positive charge flows into the device via the anode, and positive charge leaves the device via the cathode.\n\nConventional current depends not only on the direction the charge carriers move, but also the carriers' charge. The currents outside the device are usually carried by electrons in a metal conductor. The flow of electrons is opposite to conventional current because electrons have a negative charge. Consequently, electrons leave the device via the anode, and electrons enter the device through the cathode.\n\nThe anode and cathode have slightly different definitions for electrical devices such as diodes and vacuum tubes where the electrode naming is fixed and does not depend on the actual charge flow (current). These devices usually allow substantial current flow in one direction but negligible current in the other direction. Consequently, the electrode names use the terms that have substantial ordinary currents. An ideal diode allows current in one direction but not in the other. The electrode that allows positive charges to flow into it would be the anode, but that electrode would never allow positive charges to flow out, so that ideal diode terminal could never be the cathode. For the ideal diode, it makes sense to always call that terminal the anode. For non-ideal diodes, the electrodes are also given fixed names even though such a diode under reverse bias would have a positive charge flow out of the \"anode\". For some operating conditions and devices, such as diode breakdown, Zener diodes, or photodiodes, the positive charge flow out of the \"anode\" could be substantial.\n\nThe polarity of voltage on an anode with respect to an associated cathode varies depending on the device type and on its operating mode. In the following examples, the anode is negative in a device that provides power, and positive in a device that consumes power:\n\nIn a discharging battery or galvanic cell (diagram at right), the anode is the negative terminal because it is where conventional current flows into \"the device\" (i.e. the battery cell). This inward current is carried externally by electrons moving outwards, negative charge flowing in one direction being electrically equivalent to positive charge flowing in the opposite direction.\n\nIn a recharging battery, or an electrolytic cell, the anode is the positive terminal, which receives current from an external generator. The current through a recharging battery is opposite to the direction of current during discharge; in other words, the electrode which was the cathode during battery discharge becomes the anode while the battery is recharging.\n\nIn a diode, the anode is the positive terminal at the tail of the arrow symbol (flat side of the triangle), where current flows into the device. Note electrode naming for diodes is always based on the direction of the forward current (that of the arrow, in which the current flows \"most easily\"), even for types such as Zener diodes or solar cells where the current of interest is the reverse current.\n\nIn a cathode ray tube, the anode is the positive terminal where electrons flow out of the device, i.e., where positive electric current flows in.\n\nThe word was coined in 1834 from the Greek ἄνοδος (\"anodos\"), 'ascent', by William Whewell, who had been consulted by Michael Faraday over some new names needed to complete a paper on the recently discovered process of electrolysis. In that paper Faraday explained that when an electrolytic cell is oriented so that electric current traverses the \"decomposing body\" (electrolyte) in a direction \"from East to West, or, which will strengthen this help to the memory, that in which the sun appears to move\", the anode is where the current enters the electrolyte, on the East side: \"\"ano\" upwards, \"odos\" a way; the way which the sun rises\".\n\nThe use of 'East' to mean the 'in' direction (actually 'in' → 'East' → 'sunrise' → 'up') may appear contrived. Previously, as related in the first reference cited above, Faraday had used the more straightforward term \"eisode\" (the doorway where the current enters). His motivation for changing it to something meaning 'the East electrode' (other candidates had been \"eastode\", \"oriode\" and \"anatolode\") was to make it immune to a possible later change in the direction convention for current, whose exact nature was not known at the time. The reference he used to this effect was the Earth's magnetic field direction, which at that time was believed to be invariant. He fundamentally defined his arbitrary orientation for the cell as being that in which the internal current would run parallel to and in the same direction as a hypothetical magnetizing current loop around the local line of latitude which would induce a magnetic dipole field oriented like the Earth's. This made the internal current East to West as previously mentioned, but in the event of a later convention change it would have become West to East, so that the East electrode would not have been the 'way in' any more. Therefore, \"eisode\" would have become inappropriate, whereas \"anode\" meaning 'East electrode' would have remained correct with respect to the unchanged direction of the actual phenomenon underlying the current, then unknown but, he thought, unambiguously defined by the magnetic reference. In retrospect the name change was unfortunate, not only because the Greek roots alone do not reveal the anode's function any more, but more importantly because as we now know, the Earth's magnetic field direction on which the \"anode\" term is based is subject to reversals whereas the current direction convention on which the \"eisode\" term was based has no reason to change in the future.\n\nSince the later discovery of the electron, an easier to remember and more durably correct technically although historically false, etymology has been suggested: anode, from the Greek \"anodos\", 'way up', 'the way (up) out of the cell (or other device) for electrons'.\n\nIn electrochemistry, the \"anode\" is where oxidation occurs and is the positive polarity contact in an electrolytic cell. At the anode, anions (negative ions) are forced by the electrical potential to react chemically and give off electrons (oxidation) which then flow up and into the driving circuit. Mnemonics: LEO Red Cat (Loss of Electrons is Oxidation, Reduction occurs at the Cathode), or AnOx Red Cat (Anode Oxidation, Reduction Cathode), or OIL RIG (Oxidation is Loss, Reduction is Gain of electrons), or Roman Catholic and Orthodox (Reduction – Cathode, anode – Oxidation), or LEO the lion says GER (Losing electrons is Oxidation, Gaining electrons is Reduction).\n\nThis process is widely used in metals refining. For example, in copper refining, copper anodes, an intermediate product from the furnaces, are electrolysed in an appropriate solution (such as sulfuric acid) to yield high purity (99.99%) cathodes. Copper cathodes produced using this method are also described as electrolytic copper.\n\nIn a battery or galvanic cell, the anode is the negative electrode from which electrons flow out towards the external part of the circuit. Internally the positively charged cations are flowing away from the anode (even though it is negative and therefore would be expected to attract them, this is due to electrode potential relative to the electrolyte solution being different for the anode and cathode metal/electrolyte systems); but, external to the cell in the circuit, electrons are being pushed out through the negative contact and thus through the circuit by the voltage potential as would be expected. Note: in a galvanic cell, contrary to what occurs in an electrolytic cell, no anions flow to the anode, the internal current being entirely accounted for by the cations flowing away from it (cf drawing).\n\nIn the United States, many battery manufacturers regard the positive electrode as the anode, particularly in their technical literature. Though technically incorrect, it does resolve the problem of which electrode is the anode in a secondary (or rechargeable) cell. Using the traditional definition, the anode switches ends between charge and discharge cycles.\n\nIn electronic vacuum devices such as a cathode ray tube, the anode is the positively charged electron collector. In a tube, the anode is a charged positive plate that collects the electrons emitted by the cathode through electric attraction. It also accelerates the flow of these electrons.\n\nIn a semiconductor diode, the anode is the P-doped layer which initially supplies \"holes\" to the junction. In the junction region, the holes supplied by the anode combine with electrons supplied from the N-doped region, creating a depleted zone. As the P-doped layer supplies holes to the depleted region, negative dopant ions are left behind in the P-doped layer ('P' for positive charge-carrier ions). This creates a base negative charge on the anode. When a positive voltage is applied to anode of the diode from the circuit, more \"holes\" are able to be transferred to the depleted region, and this causes the diode to become conductive, allowing current to flow through the circuit. The terms anode and cathode should not be applied to a Zener diode, since it allows flow in either direction, depending on the polarity of the applied potential (i.e. voltage).\n\nIn cathodic protection, a metal anode that is more reactive to the corrosive environment of the system to be protected is electrically linked to the protected system, and partially corrodes or dissolves, which protects the metal of the system it is connected to. As an example, an iron or steel ship's hull may be protected by a zinc sacrificial anode, which will dissolve into the seawater and prevent the hull from being corroded. Sacrificial anodes are particularly needed for systems where a static charge is generated by the action of flowing liquids, such as pipelines and watercraft. Sacrificial anodes are also generally used in tank-type water heaters.\n\nIn 1824 to reduce the impact of this destructive electrolytic action on ships hulls, their fastenings and underwater equipment, the scientist-engineer Sir Humphry Davy, developed the first and still most widely used marine electrolysis protection system. Davy installed sacrificial anodes made from a more electrically reactive (less noble) metal attached to the vessel hull and electrically connected to form a cathodic protection circuit.\n\nA less obvious example of this type of protection is the process of galvanising iron. This process coats iron structures (such as fencing) with a coating of zinc metal. As long as the zinc remains intact, the iron is protected from the effects of corrosion. Inevitably, the zinc coating becomes breached, either by cracking or physical damage. Once this occurs, corrosive elements act as an electrolyte and the zinc/iron combination as electrodes. The resultant current ensures that the zinc coating is sacrificed but that the base iron does not corrode. Such a coating can protect an iron structure for a few decades, but once the protecting coating is consumed, the iron rapidly corrodes.\n\nIf, conversely, tin is used to coat steel, when a breach of the coating occurs it actually accelerates oxidation of the iron.\n\nThe opposite of an anode is a cathode. When the current through the device is reversed, the electrodes switch functions, so anode becomes cathode, while cathode becomes anode, as long as the reversed current is applied, with the exception of diodes where electrode naming is always based on the forward current direction.\n\n"}
{"id": "2393", "url": "https://en.wikipedia.org/wiki?curid=2393", "title": "Analog television", "text": "Analog television\n\nAnalog television or analogue television is the original television technology that uses analog signals to transmit video and audio. In an analog television broadcast, the brightness, colors and sound are represented by rapid variations of either the amplitude, frequency or phase of the signal.\n\nAnalog signals vary over a continuous range of possible values which means that electronic noise and interference becomes reproduced by the receiver. So with analog, a moderately weak signal becomes snowy and subject to interference. In contrast, a moderately weak digital signal and a very strong digital signal transmit equal picture quality. Analog television may be wireless or can be distributed over a cable network using cable converters.\n\nAll broadcast television systems preceding digital transmission of digital television (DTV) used analog signals.\n\nAnalog television around the world has been in the process of shutting down since the late 2000s.\n\nThe earliest systems were mechanical television systems, which used spinning disks with patterns of holes punched into the disc to scan an image. A similar disk reconstructed the image at the receiver. Synchronization of the receiver disc rotation was handled through sync pulses broadcast with the image information. However these mechanical systems were slow, the images were dim and flickered severely, and the image resolution very low. Camera systems used similar spinning discs and required intensely bright illumination of the subject for the light detector to work.\n\nAnalog television did not really begin as an industry until the development of the cathode-ray tube (CRT), which uses a focused electron beam to trace lines across a phosphor coated surface. The electron beam could be swept across the screen much faster than any mechanical disc system, allowing for more closely spaced scan lines and much higher image resolution. Also far less maintenance was required of an all-electronic system compared to a spinning disc system. All-electronic systems became popular with households after the Second World War.\n\nBroadcasters of analog television encode their signal using different systems. The official systems of transmission are named: A, B, C, D, E, F, G, H, I, K, K1, L, M and N. These systems determine the number of scan lines, frame rate, channel width, video bandwidth, video-audio separation, and so on.\n\nThe colors in those systems are encoded with one of three color coding schemes: NTSC, PAL, or SECAM, and then use RF modulation to modulate this signal onto a very high frequency (VHF) or ultra high frequency (UHF) carrier. Each frame of a television image is composed of lines drawn on the screen. The lines are of varying brightness; the whole set of lines is drawn quickly enough that the human eye perceives it as one image. The next sequential frame is displayed, allowing the depiction of motion. The analog television signal contains timing and synchronization information, so that the receiver can reconstruct a two-dimensional moving image from a one-dimensional time-varying signal.\n\nThe first commercial television systems were black-and-white; the beginning of color television was in the 1950s.\n\nA practical television system needs to take luminance, chrominance (in a color system), synchronization (horizontal and vertical), and audio signals, and broadcast them over a radio transmission. The transmission system must include a means of television channel selection.\n\nAnalog broadcast television systems come in a variety of frame rates and resolutions. Further differences exist in the frequency and modulation of the audio carrier. The monochrome combinations still existing in the 1950s are standardized by the International Telecommunication Union (ITU) as capital letters A through N. When color television was introduced, the hue and saturation information was added to the monochrome signals in a way that black and white televisions ignore. In this way backwards compatibility was achieved. That concept is true for all analog television standards.\n\nThere were three standards for the way the additional color information can be encoded and transmitted. The first was the American NTSC (National Television Systems Committee) color television system. The European/Australian PAL (Phase Alternation Line rate) and the French-former Soviet Union SECAM (Séquentiel Couleur Avec Mémoire) standard were developed later and attempt to cure certain defects of the NTSC system. PAL's color encoding is similar to the NTSC systems. SECAM, though, uses a different modulation approach than PAL or NTSC.\n\nIn principle, all three color encoding systems can be combined with any scan line/frame rate combination. Therefore, in order to describe a given signal completely, it's necessary to quote the color system and the broadcast standard as a capital letter. For example, the United States, Canada, Mexico and South Korea use NTSC-M (many of these transitioned or transitioning to digital), Japan uses NTSC-J (discontinued in 2012, when Japan transitioned to digital (ISDB)), the UK uses PAL-I (discontinued in 2012, when UK transitioned to digital (DVB-T)), France uses SECAM-L (discontinued in 2011, when France transitioned to digital (DVB-T)), much of Western Europe and Australia use PAL-B/G (Many of these transitioned or transitioning to DVB-T as digital television standards), most of Eastern Europe uses SECAM-D/K or PAL-D/K and so on.\n\nHowever, not all of these possible combinations actually exist. NTSC is currently only used with system M, even though there were experiments with NTSC-A (405 line) in the UK and NTSC-N (625 line) in part of South America. PAL is used with a variety of 625-line standards (B,G,D,K,I,N) but also with the North American 525-line standard, accordingly named PAL-M. Likewise, SECAM is used with a variety of 625-line standards.\n\nFor this reason many people refer to any 625/25 type signal as \"PAL\" and to any 525/30 signal as \"NTSC\", even when referring to digital signals; for example, on DVD-video, which does not contain any analog color encoding, and thus no PAL or NTSC signals at all. Even though this usage is common, it is misleading, as that is not the original meaning of the terms PAL/SECAM/NTSC.\n\nAlthough a number of different broadcast television systems were in use worldwide, the same principles of operation apply.\n\nIn many countries, over-the-air broadcast television of analog audio and analog video signals has been discontinued, to allow the re-use of the television broadcast radio spectrum for other services such as datacasting and subchannels.\n\nA cathode-ray tube (CRT) television displays an image by scanning a beam of electrons across the screen in a pattern of horizontal lines known as a raster. At the end of each line the beam returns to the start of the next line; the end of the last line is a link that returns to the top of the screen. As it passes each point the intensity of the beam is varied, varying the luminance of that point. A color television system is identical except that an additional signal known as chrominance controls the color of the spot.\n\nRaster scanning is shown in a slightly simplified form below.\n\nWhen analog television was developed, no affordable technology for storing any video signals existed; the luminance signal has to be generated and transmitted at the same time at which it is displayed on the CRT. It is therefore essential to keep the raster scanning in the camera (or other device for producing the signal) in exact synchronization with the scanning in the television.\n\nThe physics of the CRT require that a finite time interval be allowed for the spot to move back to the start of the next line (\"horizontal retrace\") or the start of the screen (\"vertical retrace\"). The timing of the luminance signal must allow for this.\n\nThe human eye has a characteristic called Phi phenomenon. Quickly displaying successive scan images will allow the apparent illusion of smooth motion. Flickering of the image can be partially solved using a long persistence phosphor coating on the CRT, so that successive images fade slowly. However, slow phosphor has the negative side-effect of causing image smearing and blurring when there is a large amount of rapid on-screen motion occurring.\n\nThe maximum frame rate depends on the bandwidth of the electronics and the transmission system, and the number of horizontal scan lines in the image. A frame rate of 25 or 30 hertz is a satisfactory compromise, while the process of interlacing two video fields of the picture per frame is used to build the image. This process doubles the apparent number of video frames per second and further reduces flicker and other defects in transmission.\n\nPlasma screens and LCD screens have been used in analog television sets. These types of display screens use lower voltages than older CRT displays. Many dual system television receivers, equipped to receive both analog transmissions and digital transmissions have analog tuner receiving capability and must use a television antenna.\n\nThe television system for each country will specify a number of television channels within the UHF or VHF frequency ranges. A channel actually consists of two signals: the picture information is transmitted using amplitude modulation on one frequency, and the sound is transmitted with frequency modulation at a frequency at a fixed offset (typically 4.5 to 6 MHz) from the picture signal.\n\nThe channel frequencies chosen represent a compromise between allowing enough bandwidth for video (and hence satisfactory picture resolution), and allowing enough channels to be packed into the available frequency band. In practice a technique called vestigial sideband is used to reduce the channel spacing, which would be nearly twice the video bandwidth if pure AM was used.\n\nSignal reception is invariably done via a superheterodyne receiver: the first stage is a \"tuner\" which selects a television channel and frequency-shifts it to a fixed intermediate frequency (IF). The signal amplifier performs amplification to the IF stages from the microvolt range to fractions of a volt.\n\nAt this point the IF signal consists of a video carrier signal at one frequency and the sound carrier at a fixed offset. A demodulator recovers the video signal. Also at the output of the same demodulator is a new frequency modulated sound carrier at the offset frequency. In some sets made before 1948, this was filtered out, and the sound IF of about 22 MHz was sent to an FM demodulator to recover the basic sound signal. In newer sets, this new carrier at the offset frequency was allowed to remain as \"intercarrier sound\", and it was sent to an FM demodulator to recover the basic sound signal. One particular advantage of intercarrier sound is that when the front panel fine tuning knob is adjusted, the sound carrier frequency does not change with the tuning, but stays at the above-mentioned offset frequency. Consequently, it is easier to tune the picture without losing the sound.\n\nSo the FM sound carrier is then demodulated, amplified, and used to drive a loudspeaker. Until the advent of the NICAM and MTS systems, television sound transmissions were invariably monophonic.\n\nThe video carrier is demodulated to give a composite video signal; this contains luminance, chrominance and synchronization signals; this is identical to the video signal format used by analog video devices such as VCRs or CCTV cameras. Note that the RF signal modulation is inverted compared to the conventional AM: the minimum video signal level corresponds to maximum carrier amplitude, and vice versa. To ensure good linearity (fidelity), consistent with affordable manufacturing costs of transmitters and receivers, the video carrier is never shut off altogether. When intercarrier sound was invented later in 1948, not completely shutting off the carrier had the side effect of allowing intercarrier sound to be economically implemented.\n\nEach line of the displayed image is transmitted using a signal as shown above. The same basic format (with minor differences mainly related to timing and the encoding of color) is used for PAL, NTSC and SECAM television systems. A monochrome signal is identical to a color one, with the exception that the elements shown in color in the diagram (the color burst, and the chrominance signal) are not present.\nThe \"front porch\" is a brief (about 1.5 microsecond) period inserted between the end of each transmitted line of picture and the leading edge of the next line sync pulse. Its purpose was to allow voltage levels to stabilise in older televisions, preventing interference between picture lines. The \"front porch\" is the first component of the horizontal blanking interval which also contains the horizontal sync pulse and the \"back porch\".\n\nThe \"back porch\" is the portion of each scan line between the end (rising edge) of the horizontal sync pulse and the start of active video. It is used to restore the black level (300 mV) reference in analog video. In signal processing terms, it compensates for the fall time and settling time following the sync pulse.\n\nIn color television systems such as PAL and NTSC, this period also includes the colorburst signal. In the SECAM system it contains the reference subcarrier for each consecutive color difference signal in order to set the zero-color reference.\n\nIn some professional systems, particularly satellite links between locations, the audio is embedded within the back porch of the video signal, to save the cost of renting a second channel.\n\nThe luminance component of a composite video signal varies between 0 V and approximately 0.7 V above the \"black\" level. In the NTSC system, there is a \"blanking\" signal level used during the front porch and back porch, and a \"black\" signal level 75 mV above it; in PAL and SECAM these are identical.\n\nIn a monochrome receiver the luminance signal is amplified to drive the control grid in the electron gun of the CRT. This changes the intensity of the electron beam and therefore the brightness of the spot being scanned. Brightness and contrast controls determine the DC shift and amplification, respectively.\n\nA color signal conveys picture information for each of the red, green, and blue components of an image (see the article on color space for more information). However, these are not simply transmitted as three separate signals, because: such a signal would not be compatible with monochrome receivers (an important consideration when color broadcasting was first introduced). It would also occupy three times the bandwidth of existing television, requiring a decrease in the number of television channels available. Furthermore, typical problems with signal transmission (such as differing received signal levels between different colors) would produce unpleasant side effects.\n\nInstead, the RGB signals are converted into YUV form, where the Y signal represents the lightness and darkness (luminance) of the colors in the image. Because the rendering of colors in this way is the goal of both black and white (monochrome) film and black and white (monochrome) television systems, the Y signal is ideal for transmission as the luminance signal. This ensures a monochrome receiver will display a correct picture in black and white, where a given color is reproduced by a shade of gray that correctly reflects how light or dark the original color is.\n\nThe U and V signals are \"color difference\" signals. The U signal is the difference between the B signal and the Y signal, also known as B minus Y (B-Y), and the V signal is the difference between the R signal and the Y signal, also known as R minus Y (R-Y). The U signal then represents how \"purplish-blue\" or its complementary color \"yellowish-green\" the color is, and the V signal how \"purplish-red\" or its complementary \"greenish-cyan\" it is. The advantage of this scheme is that the U and V signals are zero when the picture has no color content. Since the human eye is more sensitive to errors in luminance than in color, the U and V signals can be transmitted in a relatively lossy (specifically: bandwidth-limited) way with acceptable results.\n\nIn the receiver, a single demodulator can extract an additive combination of U plus V. An example is the X demodulator used in the X/Z demodulation system. In that same system, a second demodulator, the Z demodulator, also extracts an additive combination of U plus V, but in a different ratio. The X and Z color difference signals are further matrixed into three color difference signals, (R-Y), (B-Y), and (G-Y). The combinations of usually two, but sometimes three demodulators were:\n\na) (I) / (Q), (as used in the 1954 RCA CTC-2 and the 1985 RCA \"Colortrak\" series, and the 1954 Arvin, and some professional color monitors in the 1990s),\n\nb) (R-Y) / (Q), as used in the 1955 RCA 21 inch color receiver,\n\nc) (R-Y) / (B-Y), used in the first color receiver on the market (Westinghouse, not RCA),\n\nd) (R-Y) / (G-Y), (as used in the RCA Victor CTC-4 chassis),\n\ne) (R-Y) / (B-Y) / (G-Y),\n\nf) (X) / (Z), as used in many receivers of the late 50's and throughout the 60's.\n\nIn the end, further matrixing of the above color-difference signals c through f yielded the three color-difference signals, (R-Y), (B-Y), and (G-Y).\n\nThe R,G,B signals in the receiver needed for the display device (CRT, Plasma display or LCD display) are electronically derived by matrixing as follows: R is the additive combination of (R-Y) with Y, G is the additive combination of (G-Y) with Y, and B is the additive combination of (B-Y) with Y. All of this is accomplished electronically. It can be seen that in the combining process, the low resolution portion of the Y signals cancel out, leaving R,G, and B signals able to render a low-resolution image in full color. However, the higher resolution portions of the Y signals do not cancel out, and so are equally present in R, G, and B, producing the higher definition (higher resolution) image detail in monochrome, although it appears to the human eye as a full-color and full resolution picture.\n\nIn the NTSC and PAL color systems, U and V are transmitted by using quadrature amplitude modulation of a subcarrier. This kind of modulation applies two independent signals to one subcarrier, with the idea that both signals will be recovered independently at the receive end. Before transmission, the subcarrier itself, is removed from the active (visible) portion of the video, and moved, in the form of a burst, to the horizontal blanking portion, which is not directly visible on screen. (More about the burst below.)\n\nFor NTSC, the subcarrier is a 3.58 MHz sine wave. For the PAL system it is a 4.43 MHz sine wave. After the above-mentioned quadrature amplitude modulation of the subcarrier, subcarrier sidebands are produced, and the subcarrier itself is filtered out of the visible portion of the video, since it is the subcarrier sidebands that carry all of the U and V information, and the subcarrier itself carries no information.\n\nThe resulting subcarrier sidebands is also known as \"chroma\" or \"chrominance\". Physically, this chrominance signal is a 3.58 MHz(NTSC) or 4.43 MHz(PAL) sine wave which, in response to changing U and V values, changes phase as compared to the subcarrier, and also changes amplitude.\n\nAs it turns out, the chroma amplitude (when considered together with the Y signal) represents the approximate saturation of a color, and the chroma phase against the subcarrier as reference, approximately represents the hue of the color. For particular test colors found in the test color bar pattern, exact amplitudes and phases are sometimes defined for test and trouble shooting purposes only.\n\nAlthough, in response to changing U and V values, the chroma sinewave changes phase with respect to the subcarrier, it's not correct to say that the subcarrier is simply \"phase modulated\". That is because a single sine wave U test signal with QAM produces only one pair of sidebands, whereas real phase modulation under the same test conditions would produce multiple sets of sidebands occupying more frequency spectrum.\n\nIn NTSC, the chrominance sine wave has the same average frequency as the subcarrier frequency. But a spectrum analyzer instrument shows that, for transmitted chrominance, the frequency component at the subcarrier frequency is actually zero energy, verifying that the subcarrier was indeed removed before transmission.\n\nThese sideband frequencies are within the luminance signal band, which is why they are called \"subcarrier\" sidebands instead of simply \"carrier\" sidebands. Their exact frequencies were chosen such that (for NTSC), they are midway between two harmonics of the frame repetition rate, thus ensuring that the majority of the power of the luminance signal does not overlap with the power of the chrominance signal.\n\nIn the British PAL (D) system, the actual chrominance center frequency, with equal lower and upper sidebands, is 4.43361875 MHz, a direct multiple of the scan rate frequency. This frequency was chosen to minimize the chrominance beat interference pattern that would be visible in areas of high color saturation in the transmitted picture.\n\nAt certain times, the chrominance signal represents only the U signal, and 70 nanoseconds (NTSC) later, the chrominance signal represents only the V signal. (This is the nature of the quadrature amplitude modulation process that created the chrominance signal.) About 70 nanoseconds later still, -U, and another 70 nanoseconds, -V.\n\nSo to extract U, a synchronous demodulator is utilized, which uses the subcarrier to briefly gate (sample) the chroma every 280 nanoseconds, so that the output is only a train of discrete pulses, each having an amplitude that is the same as the original U signal at the corresponding time. In effect, these pulses are discrete-time analog samples of the U signal. The pulses are then low-pass filtered so that the original analog continuous-time U signal is recovered. For V, a 90 degree shifted subcarrier briefly gates the chroma signal every 280 nanoseconds, and the rest of the process is identical to that used for the U signal.\n\nGating at any other time than those times mentioned above will yield an additive mixture of any two of U, V, -U, or -V. One of these \"off-axis\" (that is, off the U and V axis) gating methods is called I/Q demodulation. Another much more popular \"off-axis\" scheme was the X/Z demodulation system. Further matrixing recovered the original U and V signals. This scheme was actually the most popular demodulator scheme throughout the 60's.\n\nThe above process uses the subcarrier. But as previously mentioned, it was deleted before transmission, and only the chroma is transmitted. Therefore, the receiver must reconstitute the subcarrier. For this purpose, a short burst of subcarrier, known as the color burst, is transmitted during the back porch (re-trace blanking period) of each scan line. A subcarrier oscillator in the receiver locks onto this signal (see phase-locked loop) to achieve a phase reference, resulting in the oscillator producing the reconstituted subcarrier.\n\nNTSC uses this process unmodified. Unfortunately, this often results in poor color reproduction due to phase errors in the received signal, caused sometimes by multipath, but mostly by poor implementation at the studio end. With the advent of solid state receivers, cable TV, and digital studio equipment for conversion to an over-the-air analog signal, these NTSC problems have been largely fixed, leaving operator error at the studio end as the sole color rendition weakness of the NTSC system. In any case, the PAL D (delay) system mostly corrects these kind of errors by reversing the phase of the signal on each successive line, and the averaging the results over pairs of lines. This process is achieved by the use of a 1H (where H = horizontal scan frequency) duration delay line. (A typical circuit used with this device converts the low frequency color signal to ultrasound and back again). Phase shift errors between successive lines are therefore cancelled out and the wanted signal amplitude is increased when the two in-phase (coincident) signals are re-combined.\n\nNTSC is more spectrum efficient than PAL, giving more picture detail for a given bandwidth. This is because sophisticated comb filters in receivers are more effective with NTSC's 4 field color phase cadence compared to PAL's 8 field cadence. However, in the end, the larger channel width of most PAL systems in Europe still give their PAL systems the edge in transmitting more picture detail.\n\nIn the SECAM television system, U and V are transmitted on \"alternate\" lines, using simple frequency modulation of two different color subcarriers.\n\nIn some analog color CRT displays, starting in 1956, the brightness control signal (luminance) is fed to the cathode connections of the electron guns, and the color difference signals (chrominance signals) are fed to the control grids connections. This simple CRT matrix mixing technique was replaced in later solid state designs of signal processing with the original matrixing method used in the 1954 and 1955 color TV receivers.\n\nSynchronizing pulses added to the video signal at the end of every scan line and video frame ensure that the sweep oscillators in the receiver remain locked in step with the transmitted signal, so that the image can be reconstructed on the receiver screen.\n\nA \"sync separator\" circuit detects the sync voltage levels and sorts the pulses into horizontal and vertical sync. (see section below – Other technical information, for extra detail.)\n\nThe horizontal synchronization pulse (\"horizontal sync\" \"HSYNC\"), separates the scan lines. The horizontal sync signal is a single short pulse which indicates the start of every line. The rest of the scan line follows, with the signal ranging from 0.3 V (black) to 1 V (white), until the next horizontal or vertical synchronization pulse.\n\nThe format of the horizontal sync pulse varies. In the 525-line NTSC system it is a 4.85 µs-long pulse at 0 V. In the 625-line PAL system the pulse is 4.7 µs synchronization pulse at 0 V . This is lower than the amplitude of any video signal (\"blacker than black\") so it can be detected by the level-sensitive \"sync stripper\" circuit of the receiver.\n\nVertical synchronization (also called vertical sync or VSync) separates the video fields. In PAL and NTSC, the vertical sync pulse occurs within the vertical blanking interval. The vertical sync pulses are made by prolonging the length of HSYNC pulses through almost the entire length of the scan line.\n\nThe \"vertical sync\" signal is a series of much longer pulses, indicating the start of a new field. The sync pulses occupy the whole of line interval of a number of lines at the beginning and end of a scan; no picture information is transmitted during vertical retrace. The pulse sequence is designed to allow horizontal sync to continue during vertical retrace; it also indicates whether each field represents even or odd lines in interlaced systems (depending on whether it begins at the start of a horizontal line, or midway through).\n\nThe format of such a signal in 525-line NTSC is:\n\nEach pre- or post- equalizing pulse consists in half a scan line of black signal: 2 µs at 0 V, followed by 30 µs at 0.3 V.\n\nEach long sync pulse consists in an equalizing pulse with timings inverted: 30 µs at 0 V, followed by 2 µs at 0.3 V.\n\nIn video production and computer graphics, changes to the image are often kept in step with the vertical synchronization pulse to avoid visible discontinuity of the image. Since the frame buffer of a computer graphics display imitates the dynamics of a cathode-ray display, if it is updated with a new image while the image is being transmitted to the display, the display shows a mishmash of both frames, producing a page tearing artifact partway down the image.\n\nVertical synchronization eliminates this by timing frame buffer fills to coincide with the vertical blanking interval, thus ensuring that only whole frames are seen on-screen. Software such as video games and computer aided design (CAD) packages often allow vertical synchronization as an option, because it delays the image update until the vertical blanking interval. This produces a small penalty in latency, because the program has to wait until the video controller has finished transmitting the image to the display before continuing. Triple buffering reduces this latency significantly.\n\nTwo timing intervals are defined – the \"front porch\" between the end of displayed video and the start of the sync pulse, and the \"back porch\" after the sync pulse and before displayed video. These and the sync pulse itself are called the \"horizontal blanking\" (or \"retrace\") \"interval\" and represent the time that the electron beam in the CRT is returning to the start of the next display line.\n\nThe lack of precision timing components in early television receivers meant that the timebase circuits occasionally needed manual adjustment.\nIf their free-run frequencies were too far from the actual line and field rates, the circuits would not be able to follow the incoming sync signals.\nLoss of horizontal synchronization usually resulted in an unwatchable picture; loss of vertical synchronization would produce an image rolling up or down the screen.\n\nThe adjustment took the form of \"horizontal hold\" and \"vertical hold\" controls, usually on the front panel along with other common controls. These adjusted the free-run frequencies of the corresponding timebase oscillators.\n\nBy the early 1980s the efficacy of the synchronization circuits, plus the inherent stability of the sets' oscillators, had been improved to the point where these controls were no longer necessary.\n\nA typical analog monochrome television receiver is based around the block diagram shown below:\n\nImage synchronization is achieved by transmitting negative-going pulses; in a composite video signal of 1 volt amplitude, these are approximately 0.3 V below the \"black level\". The \"horizontal sync\" signal is a single short pulse which indicates the start of every line. Two timing intervals are defined – the \"front porch\" between the end of displayed video and the start of the sync pulse, and the \"back porch\" after the sync pulse and before displayed video. These and the sync pulse itself are called the \"horizontal blanking\" (or \"retrace\") \"interval\" and represent the time that the electron beam in the CRT is returning to the start of the next display line.\n\nThe \"vertical sync\" signal is a series of much longer pulses, indicating the start of a new field. The sync pulses occupy the whole of line interval of a number of lines at the beginning and end of a scan; no picture information is transmitted during vertical retrace. The pulse sequence is designed to allow horizontal sync to continue during vertical retrace; it also indicates whether each field represents even or odd lines in interlaced systems (depending on whether it begins at the start of a horizontal line, or midway through).\n\nIn the television receiver, a \"sync separator\" circuit detects the sync voltage levels and sorts the pulses into horizontal and vertical sync.\n\nLoss of horizontal synchronization usually resulted in an unwatchable picture; loss of vertical synchronization would produce an image rolling up or down the screen.\n\nIn an analog receiver with a CRT display sync pulses are fed to horizontal and vertical \"timebase\" circuits (commonly called \"sweep circuits\" in the United States), each consisting of an oscillator and an amplifier. These generate modified sawtooth and parabola current waveforms to scan the electron beam in a linear way. The waveform shapes are necessary to make up for the distance variations from the electron beam source and the screen surface. The oscillators are designed to free-run at frequencies very close to the field and line rates, but the sync pulses cause them to reset at the beginning of each scan line or field, resulting in the necessary synchronization of the beam sweep with the originating signal. The output waveforms from the timebase amplifiers are fed to the horizontal and vertical \"deflection coils\" wrapped around the CRT tube. These coils produce magnetic fields proportional to the changing current, and these deflect the electron beam across the screen.\n\nIn the 1950s, the power for these circuits was derived directly from the mains supply.\nA simple circuit consisted of a series voltage dropper resistance and a rectifier valve (tube) or semiconductor diode. This avoided the cost of a large high voltage mains supply (50 or 60 Hz) transformer. This type of circuit was used for thermionic valve (vacuum tube) technology. It was inefficient and produced a lot of heat which led to premature failures in the circuitry.\n\nIn the 1960s, semiconductor technology was introduced into timebase circuits. During the late 1960s in the UK, synchronous (with the scan line rate) power generation was introduced into solid state receiver designs. These had very complex circuits in which faults were difficult to trace, but had very efficient use of power.\n\nIn the early 1970s AC mains (50 or 60 Hz), and line timebase (15,625 Hz), thyristor based switching circuits were introduced. In the UK use of the simple (50 Hz) types of power circuits were discontinued. The reason for design changes arose from the electricity supply contamination problems arising from EMI, and supply loading issues due to energy being taken from only the positive half cycle of the mains supply waveform.\n\nMost of the receiver's circuitry (at least in transistor- or IC-based designs) operates from a comparatively low-voltage DC power supply. However, the anode connection for a cathode-ray tube requires a very high voltage (typically 10–30 kV) for correct operation.\n\nThis voltage is not directly produced by the main power supply circuitry; instead the receiver makes use of the circuitry used for horizontal scanning. Direct current (DC), is switched though the line output transformer, and alternating current (AC) is induced into the scan coils. At the end of each horizontal scan line the magnetic field, which has built up in both transformer and scan coils by the current, is a source of latent electromagnetic energy. This stored collapsing magnetic field energy can be captured. The reverse flow, short duration, (about 10% of the line scan time) current from both the line output transformer and the horizontal scan coil is discharged again into the primary winding of the flyback transformer by the use of a rectifier which blocks this negative reverse emf. A small value capacitor is connected across the scan switching device. This tunes the circuit inductances to resonate at a much higher frequency. This slows down (lengthens) the flyback time from the extremely rapid decay rate that would result if they were electrically isolated during this short period. One of the secondary windings on the flyback transformer then feeds this brief high voltage pulse to a Cockcroft–Walton generator design voltage multiplier. This produces the required EHT supply. A flyback converter is a power supply circuit operating on similar principles.\n\nA typical modern design incorporates the flyback transformer and rectifier circuitry into a single unit with a captive output lead, (known as a diode split line output transformer or an Integrated High Voltage Transformer (IHVT)), so that all high-voltage parts are enclosed. Earlier designs used a separate line output transformer and a well insulated high voltage multiplier unit. The high frequency (15 kHz or so) of the horizontal scanning allows reasonably small components to be used.\n\nThe first country to make a wholesale switch to digital over-the-air (terrestrial television) broadcasting was Luxembourg in 2006, followed later in 2006 by the Netherlands; in 2007 by Finland, Andorra, Sweden and Switzerland; in 2008 by Belgium (Flanders) and Germany; in 2009 by the United States (high power stations), southern Canada, the Isle of Man, Norway, and Denmark. In 2010, Belgium (Wallonia), Spain, Wales, Latvia, Estonia, the Channel Islands, San Marino and Slovenia; in 2011 Israel, Austria, Monaco, Cyprus, Japan (excluding Miyagi, Iwate, and Fukushima prefectures), Malta and France; in 2012 the Czech Republic, Arab World, Taiwan, Portugal, Japan (including Miyagi, Iwate, and Fukushima prefectures), Serbia, Italy, Canada, Mauritius, the United Kingdom, the Republic of Ireland, Lithuania, Slovakia, Gibraltar, and South Korea; in 2013, the Republic of Macedonia, Poland, Bulgaria, Hungary, Australia, and New Zealand, completed the transition. The United Kingdom made the transition to digital television between 2008 and 2012, with the exception of Barrow-in-Furness, which made the switch over in 2007. The first digital TV-only area in the United Kingdom was Ferryside in Carmarthenshire.\n\nIn the United States, high-power over-the-air broadcasts are solely in the ATSC digital format since 12 June 2009, the date that the Federal Communications Commission (FCC) set for the end of all high-power analog television transmissions. As a result, almost two million households could no longer watch television because they had not prepared for the transition. The switchover was originally scheduled for 17 February 2009, until the U.S. Congress passed the DTV Delay Act. By special dispensation, some analog television signals ceased on the original date. While the majority of the viewers of over-the-air broadcast television in the U.S. watch full-power stations (which number about 1800), there are three other categories of television stations in the U.S.: low-power broadcasting stations, class A stations, and television translator stations. There is presently no deadline for these stations, about 7100 in number, to convert to digital broadcasting. In broadcasting, whatever happens in the United States also influences southern Canada and northern Mexico because those areas are covered by television stations in the U.S.\n\nIn Japan, the switch to digital occurred on the 24 July 2011, but in Fukushima, Iwate, and Miyagi prefectures, the conversion was delayed to 31 March 2012, due to complications from the 2011 Tōhoku earthquake and tsunami and its related nuclear accidents. In Canada, most of the larger cities turned off analog broadcasts on 31 August 2011. China is scheduled to end analog broadcasting between 2015 and 2018, due to the large size of the country.\n\nBrazil switched to digital television on 2 December 2007 in its major cities. It is now estimated that Brazil will end analog broadcasting in 2023.\n\nIn Malaysia, the Malaysian Communications & Multimedia Commission (MCMC) advertised for tender bids to be submitted in the third quarter of 2009 for the 470 through 742 MHz UHF allocation, to enable Malaysia's broadcast system to move into DTV. The new broadcast band allocation would result in Malaysia's having to build an infrastructure for all broadcasters, using a single digital terrestrial transmission/television broadcast (DTTB) channel. Large portions of Malaysia are covered by television broadcasts from Singapore, Thailand, Brunei, and Indonesia (from Borneo and Batam)\n\nIn the Philippines, the National Telecommunications Commission required all broadcasting companies to end analog broadcasting on December 31, 2015 at 11:59 p.m. Due to delay of the release of the implementing rules and regulations for digital television broadcast, the target date was moved to 2020. Full digital broadcast is expected in 2021.\n\n"}
{"id": "2395", "url": "https://en.wikipedia.org/wiki?curid=2395", "title": "April 11", "text": "April 11\n\n\n\n"}
{"id": "2396", "url": "https://en.wikipedia.org/wiki?curid=2396", "title": "Adhesive", "text": "Adhesive\n\nAdhesive may be used interchangeably with glue, cement, mucilage, or paste, and is any substance applied to one surface, or both surfaces, of two separate items that binds them together and resists their separation. Adjectives may be used in conjunction with the word \"adhesive\" to describe properties based on the substance's physical or chemical form, the type of materials joined, or conditions under which it is applied.\n\nThe use of adhesives offers many advantages over binding techniques such as sewing, mechanical fastening, thermal bonding, etc. These include the ability to bind different materials together, to distribute stress more efficiently across the joint, the cost effectiveness of an easily mechanized process, an improvement in aesthetic design, and increased design flexibility. Disadvantages of adhesive use include decreased stability at high temperatures, relative weakness in bonding large objects with a small bonding surface area, and greater difficulty in separating objects during testing. Adhesives are typically organized by the method of adhesion. These are then organized into reactive and non-reactive adhesives, which refers to whether the adhesive chemically reacts in order to harden. Alternatively they can be organized by whether the raw stock is of natural or synthetic origin, or by their starting physical phase.\n\nAdhesives may be found naturally or produced synthetically. The earliest human use of adhesive-like substances was approximately 200,000 years ago. The first references to adhesives in literature first appeared in approximately 2000 BCE. The Greeks and Romans made great contributions to the development of adhesives. In Europe, glue was not widely used until the period 1500–1700 CE. From then until the 1900s increases in adhesive use and discovery were relatively gradual. Only since the last century has the development of synthetic adhesives accelerated rapidly, and innovation in the field continues to the present.\n\nThe earliest use of adhesives was discovered in central Italy when two stone flakes partially covered with birch-bark tar and a third uncovered stone from the Middle Pleistocene era (circa 200,000 years ago) were found. This is thought to be the oldest discovered human use of tar-hafted stones.\n\nThe birch-bark-tar adhesive is a simple, one-component adhesive. Although sticky enough, plant-based adhesives are brittle and vulnerable to environmental conditions. The first use of compound adhesives was discovered in Sibudu, South Africa. Here, 70,000-year-old stone segments that were once inserted in axe hafts were discovered covered with an adhesive composed of plant gum and red ochre (natural iron oxide) as adding ochre to plant gum produces a stronger product and protects the gum from disintegrating under wet conditions. The ability to produce stronger adhesives allowed middle stone age humans to attach stone segments to sticks in greater variations, which led to the development of new tools.\n\nMore recent examples of adhesive use by prehistoric humans have been found at the burial sites of ancient tribes. Archaeologists studying the sites found that approximately 6,000 years ago the tribesmen had buried their dead together with food found in broken clay pots repaired with tree resins. Another investigation by archaeologists uncovered the use of bituminous cements to fasten ivory eyeballs to statues in Babylonian temples dating to approximately 4000 BCE\n\nIn 2000, a paper revealed the discovery of a 5,200-year-old man nicknamed the \"Tyrolean Iceman\" or \"Ötzi\", who was preserved in a glacier near the Austria-Italy border. Several of his belongings were found with him including two arrows with flint arrowheads and a copper hatchet, each with evidence of organic glue used to connect the stone or metal parts to the wooden shafts. The glue was analyzed as pitch, which requires the heating of tar during its production. The retrieval of this tar requires a transformation of birch bark by means of heat, in a process known as pyrolysis.\n\nThe first references to adhesives in literature first appeared in approximately 2000 BCE. Further historical records of adhesive use are found from the period spanning 1500–1000 BCE. Artifacts from this period include paintings depicting wood gluing operations and a casket made of wood and glue in King Tutankhamun's tomb. Other ancient Egyptian artifacts employ animal glue for bonding or lamination. Such lamination of wood for bows and furniture is thought to have extended their life and was accomplished using casein (milk protein)-based glues. The ancient Egyptians also developed starch-based pastes for the bonding of papyrus to clothing and a plaster of Paris-like material made of calcined gypsum.\n\nFrom 1 to 500 AD the Greeks and Romans made great contributions to the development of adhesives. Wood veneering and marquetry were developed, the production of animal and fish glues refined, and other materials utilized. Egg-based pastes were used to bond gold leaves incorporated various natural ingredients such as blood, bone, hide, milk, cheese, vegetables, and grains. The Greeks began the use of slaked lime as mortar while the Romans furthered mortar development by mixing lime with volcanic ash and sand. This material, known as pozzolanic cement, was used in the construction of the Roman Colosseum and Pantheon. The Romans were also the first people known to have used tar and beeswax as caulk and sealant between the wooden planks of their boats and ships.\n\nIn Central Asia, the rise of the Mongols in approximately 1000 AD can be partially attributed to the good range and power of the bows of Genghis Khan's hordes. These bows were constructed with laminated lemonwood and bullhorn bonded by an unknown adhesive.\n\nIn Europe, glue fell into disuse until the period 1500–1700 AD. At this time, world-renowned cabinet and furniture makers such as Thomas Chippendale and Duncan Phyfe began to use adhesives to hold their products together.\n\nThe development of modern adhesives began in 1690 with the founding of the first commercial glue plant in Holland. This plant produced glues from animal hides.\n\nIn 1750, the first British glue patent was issued for fish glue. The following decades of the next century witnessed the manufacture of casein glues in German and Swiss factories. In 1876, the first US patent (number 183,024) was issued to the Ross brothers for the production of casein glue.\n\nThe first US postage stamps used starch-based adhesives when issued in 1840. The first US patent (number 61,991) on dextrin (a starch derivative) adhesive was issued in 1867.\n\nNatural rubber was first used as material for adhesives starting in 1830. In 1839, Charles Goodyear discovered that a rubber and sulfur mixture, when heated, becomes elastic. In 1843, Thomas Hancock named this process vulcanization. In 1862, a British patent (number 3288) was issued for the plating of metal with brass by electrodeposition to obtain a stronger bond to rubber. The development of the automobile and the need for rubber shock mounts required stronger and more durable bonds of rubber and metal. This spurred the development of cyclized rubber treated in strong acids. By 1927, this process was used to produce solvent-based thermoplastic rubber cements for metal to rubber bonding.\n\nNatural rubber-based sticky adhesives were first used on a backing by Henry Day (US Patent 3,965) in 1845. Later these kinds of adhesives were used in cloth backed surgical and electric tapes. By 1925, the pressure-sensitive tape industry was born.\nToday, sticky notes, Scotch tape, and other tapes are examples of PSA (pressure-sensitive adhesives).\n\nA key step in the development of synthetic plastics was the introduction of a thermoset plastic known as Bakelite phenolic in 1910. Within two years, phenolic resin was applied to plywood as a coating varnish. In the early 1930s, phenolics gained importance as adhesive resins.\n\nThe 1920s, 1930s, and 1940s witnessed great advances in the development and production of new plastics and resins due to the First and Second World Wars. These advances greatly improved the development of adhesives by allowing the use of newly developed materials that exhibited a variety of properties. With changing needs and ever evolving technology, the development of new synthetic adhesives continues to the present. However, due to their low cost, natural adhesives are still more commonly used.\n\nIn the course of time and during their development, adhesives have gained a stable position in an increasing number of production processes. There is hardly any product in our surroundings that does not contain at least one adhesive—be it the label on a beverage bottle, protective coatings on automobiles, or profiles on window frames. Market researchers forecast a turnover of almost US$50 billion for the global adhesives market in 2019. In particular, the economic development of emerging countries such as China, India, Russia, and Brazil will cause a rising demand for adhesives in the future.\n\nAdhesives are typically organized by the method of adhesion. These are then organized into reactive and non-reactive adhesives, which refers to whether the adhesive chemically reacts in order to harden. Alternatively they can be organized by whether the raw stock is of natural, or synthetic origin, or by their starting physical phase.\n\nThere are two types of adhesives that harden by drying: \"solvent-based adhesives\" and \"polymer dispersion adhesives\", also known as \"emulsion adhesives\". \nSolvent-based adhesives are a mixture of ingredients (typically polymers) dissolved in a solvent. White glue, contact adhesives and rubber cements are members of the \"drying adhesive\" family. As the solvent evaporates, the adhesive hardens. Depending on the chemical composition of the adhesive, they will adhere to different materials to greater or lesser degrees.\n\nPolymer dispersion adhesives are milky-white dispersions often based on polyvinyl acetate (PVAc). They are used extensively in the woodworking and packaging industries. They are also used with fabrics and fabric-based components, and in engineered products such as loudspeaker cones.\n\n\"Pressure-sensitive adhesives\" (PSA) form a bond by the application of light pressure to marry the adhesive with the adherend. They are designed to have a balance between flow and resistance to flow. The bond forms because the adhesive is soft enough to flow (i.e., \"wet\") to the adherend. The bond has strength because the adhesive is hard enough to resist flow when stress is applied to the bond. Once the adhesive and the adherend are in close proximity, molecular interactions, such as van der Waals forces, become involved in the bond, contributing significantly to its ultimate strength.\n\nPSAs are designed for either permanent or removable applications. Examples of permanent applications include safety labels for power equipment, foil tape for HVAC duct work, automotive interior trim assembly, and sound/vibration damping films. Some high performance permanent PSAs exhibit high adhesion values and can support kilograms of weight per square centimeter of contact area, even at elevated temperatures. Permanent PSAs may initially be removable (for example to recover mislabeled goods) and build adhesion to a permanent bond after several hours or days.\n\nRemovable adhesives are designed to form a temporary bond, and ideally can be removed after months or years without leaving residue on the adherend. Removable adhesives are used in applications such as surface protection films, masking tapes, bookmark and note papers, barcodes labels, price marking labels, promotional graphics materials, and for skin contact (wound care dressings, EKG electrodes, athletic tape, analgesic and transdermal drug patches, etc.). Some removable adhesives are designed to repeatedly stick and unstick. They have low adhesion, and generally cannot support much weight. Pressure-sensitive adhesive is used in Post-it notes.\n\nPressure-sensitive adhesives are manufactured with either a liquid carrier or in 100% solid form. Articles are made from liquid PSAs by coating the adhesive and drying off the solvent or water carrier. They may be further heated to initiate a cross-linking reaction and increase molecular weight. 100% solid PSAs may be low viscosity polymers that are coated and then reacted with radiation to increase molecular weight and form the adhesive, or they may be high viscosity materials that are heated to reduce viscosity enough to allow coating, and then cooled to their final form. Major raw material for PSA's are acrylate-based polymers.\n\n\"Contact adhesives\" are used in strong bonds with high shear-resistance like laminates, such as bonding Formica to a wooden counter, and in footwear, as in attaching outsoles to uppers.\n\nNatural rubber and polychloroprene (Neoprene) are commonly used contact adhesives. Both of these elastomers undergo strain crystallization. In the construction industry a specialised proprietary adhesive known as \"liquid nails\" is used. This also copes with tasks such as sealing artificial turf.\n\nContact adhesives must be applied to both surfaces and allowed some time to dry before the two surfaces are pushed together. Some contact adhesives require as long as 24 hours to dry before the surfaces are to be held together. Once the surfaces are pushed together, the bond forms very quickly. It is usually not necessary to apply pressure for a long time, so there is less need for clamps.\n\n\"Hot adhesives\", also known as \"hot melt adhesives\", are thermoplastics applied in molten form (in the 65–180 °C range) which solidify on cooling to form strong bonds between a wide range of materials. Ethylene-vinyl acetate-based hot-melts are particularly popular for crafts because of their ease of use and the wide range of common materials they can join. A glue gun (shown at right) is one method of applying hot adhesives. The glue gun melts the solid adhesive, then allows the liquid to pass through its barrel onto the material, where it solidifies.\n\nThermoplastic glue may have been invented around 1940 by Procter & Gamble as a solution to the problem that water-based adhesives, commonly used in packaging at that time, failed in humid climates, causing packages to open.\n\n\"Multi-component adhesives\" harden by mixing two or more components which chemically react. This reaction causes polymers to cross-link into acrylics, urethanes, and epoxies - See thermosetting polymers.\n\nThere are several commercial combinations of multi-component adhesives in use in industry. Some of these combinations are:\n\nThe individual components of a multi-component adhesive are not adhesive by nature. The individual components react with each other after being mixed and show full adhesion only on curing. The multi-component resins can be either solvent-based or solvent-less. The solvents present in the adhesives are a medium for the polyester or the polyurethane resin. The solvent is dried during the curing process.\n\n\"One-part adhesives\" harden via a chemical reaction with an external energy source, such as radiation, heat, and moisture.\n\n\"Ultraviolet\" (UV) \"light curing adhesives\", also known as \"light curing materials\" (LCM), have become popular within the manufacturing sector due to their rapid curing time and strong bond strength. Light curing adhesives can cure in as little as a second and many formulations can bond dissimilar substrates (materials) and withstand harsh temperatures. These qualities make UV curing adhesives essential to the manufacturing of items in many industrial markets such as electronics, telecommunications, medical, aerospace, glass, and optical. Unlike traditional adhesives, UV light curing adhesives not only bond materials together but they can also be used to seal and coat products. They are generally acrylic-based.\n\n\"Heat curing adhesives\" consist of a pre-made mixture of two or more components. When heat is applied the components react and cross-link. This type of adhesive includes thermoset epoxies, urethanes, and polyimides.\n\n\"Moisture curing adhesives\" cure when they react with moisture present on the substrate surface or in the air. This type of adhesive includes cyanoacrylates and urethanes.\n\nNatural adhesives are made from organic sources such as vegetable starch (dextrin), natural resins, or animals (e.g. the milk protein casein and hide-based animal glues). These are often referred to as bioadhesives.\n\nOne example is a simple paste made by cooking flour in water. Starch-based adhesives are used in corrugated board and paper sack production, paper tube winding, and wallpaper adhesives. Casein glue is mainly used to adhere glass bottle labels. Animal glues have traditionally been used in bookbinding, wood joining, and many other areas but now are largely replaced by synthetic glues except in specialist applications like the production and repair of stringed instruments. Albumen made from the protein component of blood has been used in the plywood industry. Masonite, a wood hardboard, was originally bonded using natural wood lignin, an organic polymer, though most modern particle boards such as MDF use synthetic thermosetting resins.\n\nSynthetic adhesives are based on elastomers, thermoplastics, emulsions, and thermosets. Examples of thermosetting adhesives are: epoxy, polyurethane, cyanoacrylate and acrylic polymers. The first commercially produced synthetic adhesive was Karlsons Klister in the 1920s.\n\nApplicators of different adhesives are designed according to the adhesive being used and the size of the area to which the adhesive will be applied. The adhesive is applied to either one or both of the materials being bonded. The pieces are aligned and pressure is added to aid in adhesion and rid the bond of air bubbles.\n\nCommon ways of applying an adhesive include brushes, rollers, using films or pellets, spray guns and applicator guns (\"e.g.\", caulk gun). All of these can be used manually or automated as part of a machine.\n\nFor an adhesive to be effective it must have three main properties. It must be able to wet the substrate. It must harden and finally it must be able to transmit load between the two surfaces/substrates being adhered.\n\nAdhesion, the attachment between adhesive and substrate may occur either by mechanical means, in which the adhesive works its way into small pores of the substrate, or by one of several chemical mechanisms. The strength of adhesion depends on many factors, including the means by which it occurs.\n\nIn some cases, an actual chemical bond occurs between adhesive and substrate. In others, electrostatic forces, as in static electricity, hold the substances together. A third mechanism involves the van der Waals forces that develop between molecules. A fourth means involves the moisture-aided diffusion of the glue into the substrate, followed by hardening.\n\nThe quality of adhesive bonding depends strongly on the ability of the adhesive to efficiency cover (wet) the substrate area. This happens when the surface energy of the substrate is greater than the surface energy of the adhesive. However, high strength adhesives have high surface energy. Thus, their application is problematic for low energy materials such as polymers. To solve this problem, surface treatment can be used to increase the surface energy as a preparation step before adhesive bonding. Importantly, surface preparation provides a reproducible surface allowing consistent bonding results. The commonly used surface activation techniques include plasma activation, flame treatment and wet chemistry priming.\n\nThere are several factors that could contribute to the failure of two adhered surfaces. Sunlight and heat may weaken the adhesive. Solvents can deteriorate or dissolve adhesive. Physical stresses may also cause the separation of surfaces. When subjected to loading, debonding may occur at different locations in the adhesive joint. The major fracture types are the following:\n\n\"Cohesive fracture\" is obtained if a crack propagates in the bulk polymer which constitutes the adhesive. In this case the surfaces of both adherends after debonding will be covered by fractured adhesive. The crack may propagate in the center of the layer or near an interface. For this last case, the cohesive fracture can be said to be \"cohesive near the interface\".\n\n\"Adhesive fracture\" (sometimes referred to as \"interfacial fracture\") is when debonding occurs between the adhesive and the adherend. In most cases, the occurrence of adhesive fracture for a given adhesive goes along with smaller fracture toughness.\n\nOther types of fracture include:\n\n\nAs a general design rule, the material properties of the object need to be greater than the forces anticipated during its use. (i.e. geometry, loads, etc.). The engineering work will consist of having a good model to evaluate the function. For most adhesive joints, this can be achieved using fracture mechanics. Concepts such as the stress concentration factor and the strain energy release rate can be used to predict failure. In such models, the behavior of the adhesive layer itself is neglected and only the adherents are considered.\n\nFailure will also very much depend on the opening \"mode\" of the joint.\n\nAs the loads are usually fixed, an acceptable design will result from combination of a material selection procedure and geometry modifications, if possible. In adhesively bonded structures, the global geometry and loads are fixed by structural considerations and the design procedure focuses on the material properties of the adhesive and on local changes on the geometry.\n\nIncreasing the joint resistance is usually obtained by designing its geometry so that:\n\nSome glues and adhesives have a limited shelf life. Exposure to heat, oxygen, water vapor, etc. can degrade the adhesive over time, preventing it from functioning properly.\n\n\n\n"}
{"id": "2397", "url": "https://en.wikipedia.org/wiki?curid=2397", "title": "Anthony Hopkins", "text": "Anthony Hopkins\n\nSir Philip Anthony Hopkins (born 31 December 1937) is a Welsh actor of film, stage, and television. After graduating from the Royal Welsh College of Music & Drama in 1957, he trained at the Royal Academy of Dramatic Art in London, and was then spotted by Laurence Olivier who invited him to join the Royal National Theatre. In 1968, he got his break in film in \"The Lion in Winter\", playing Richard the Lionheart.\n\nConsidered to be one of the greatest living actors, Hopkins is well known for his portrayal of Hannibal Lecter in \"The Silence of the Lambs\", for which he won the Academy Award for Best Actor, its sequel \"Hannibal\", and the prequel \"Red Dragon\". Other notable films include \"The Mask of Zorro\", \"The Bounty\", \"Meet Joe Black\", \"The Elephant Man\", \"Magic\", \"84 Charing Cross Road\", \"Bram Stoker's Dracula\", \"Legends of the Fall\", \"Thor\", \"The Remains of the Day\", \"Amistad\", \"Nixon\", \"The World's Fastest Indian\", \"Instinct\", \"Fracture\", and \"The Dresser\". Since 2016, he has starred in the critically acclaimed HBO television series \"Westworld\".\n\nAlong with his Academy Award, Hopkins has won three BAFTA Awards, two Emmys, and the Cecil B. DeMille Award. In 1993, he was knighted by Queen Elizabeth II for services to the arts. He received a star on the Hollywood Walk of Fame in 2003, and was made a Fellow of the British Academy of Film and Television Arts in 2008.\n\nHopkins was born on New Year's Eve 1937, in Margam, a suburb of Port Talbot, Glamorgan. His parents were Annie Muriel (\"née\" Yeates) and Richard Arthur Hopkins, a baker. His school days were unproductive; he would rather immerse himself in art, such as painting and drawing, or playing the piano, than attend to his studies. In 1949, to instill discipline, his parents insisted he attend Jones' West Monmouth Boys' School in Pontypool. He remained there for five terms and was then educated at Cowbridge Grammar School in the Vale of Glamorgan. In a 2002 profile in \"The New York Times\", Hopkins told journalist Franz Lidz: \"I was a poor learner, which left me open to ridicule and gave me an inferiority complex. I grew up absolutely convinced I was stupid.\" His only real talent was for drinking India ink, which impressed his school chums but not his teachers. In desperation, his parents sent him off to boarding school, where the headmaster told him he was \"hopeless\" and he developed a \"sheer contempt for authority.\" He stumbled into acting at 17 with a YMCA group (his one line: \"\").\n\nHopkins was influenced and encouraged by Welsh compatriot Richard Burton, whom he met at the age of 15. Hopkins promptly enrolled at the Royal Welsh College of Music & Drama in Cardiff, from which he graduated in 1957. After two years in the British Army doing his national service, he moved to London, where he studied in London at the Royal Academy of Dramatic Art and, in 1965, joined Laurence Olivier's National Theatre.\n\nHopkins made his first professional stage appearance in the Palace Theatre, Swansea, in 1960 with Swansea Little Theatre's production of \"Have a Cigarette\". In 1965, after several years in repertory, he was spotted by Laurence Olivier, who invited him to join the Royal National Theatre in London. Hopkins became Olivier's understudy, and filled in when Olivier was struck with appendicitis during a production of August Strindberg's \"The Dance of Death\". Olivier later noted in his memoir, \"Confessions of an Actor\", that \"A new young actor in the company of exceptional promise named Anthony Hopkins was understudying me and walked away with the part of Edgar like a cat with a mouse between its teeth.\"\n\nDespite his success at the National, Hopkins tired of repeating the same roles nightly and yearned to be in films. He made his small-screen debut in a 1967 BBC broadcast of \"A Flea in Her Ear\". His first starring role in a film came in 1964 in \"Changes\", a short directed by Drewe Henley, written and produced by James Scott and co-starring Jacqueline Pearce. In 1968, he got his break in \"The Lion in Winter\" playing Richard I. Although Hopkins continued in theatre (most notably at the National Theatre as Lambert Le Roux in \"Pravda\" by David Hare and Howard Brenton and as Antony in \"Antony and Cleopatra\" opposite Judi Dench as well as in the Broadway production of Peter Shaffer's \"Equus\") he gradually moved away from it to become more established as a television and film actor. He portrayed Charles Dickens in the BBC television film \"The Great Inimitable Mr. Dickens\" in 1970, and Pierre Bezukhov in the BBC's mini series \"War and Peace\" (1972). In 1972 he starred as British politician David Lloyd George in \"Young Winston\", and in 1977 he played British Army officer John Frost in Richard Attenborough's World War II-set film \"A Bridge Too Far\".\n\nIn 1980, he starred in \"The Elephant Man\" as the English doctor Sir Frederick Treves, who attends to Joseph Merrick (portrayed by John Hurt), a severely deformed man in 19th century London. That year he also starred opposite Shirley MacLaine in \"A Change of Seasons\" and famously said \"she was the most obnoxious actress I have ever worked with.\"\n\nIn 1983, Hopkins also became a company member of The Mirror Theater Ltd's Repertory Company.\nHe remained an enthusiastic member of the company and the Mirror’s Producing Artistic Director Sabra Jones visited him in London in 1986 to discuss moving \"Pravda\" to New York from the National Theater. In 1984, he starred opposite Mel Gibson in \"The Bounty\" as William Bligh, captain of the Royal Navy ship the HMS \"Bounty\", in a retelling of the mutiny on the \"Bounty\". In 1992, Hopkins portrayed Abraham Van Helsing in Francis Ford Coppola's \"Bram Stoker's Dracula\".\n\nSet in 1950s post-war Britain, Hopkins starred opposite Emma Thompson in the critically acclaimed \"The Remains of the Day\" (1993). Hopkins was nominated for an Academy Award for Best Actor for his performance, and the film frequently ranks among the best British films of all time. Hopkins portrayed Oxford academic C. S. Lewis in the 1993 British biographical film \"Shadowlands\", and received the BAFTA Award for Best Actor. During the 1990s, Hopkins had the chance to work with Bart the Bear in two films: \"Legends of the Fall\" (1994) and \"The Edge\" (1997). According to trainer, Lynn Seus, \"Tony Hopkins was absolutely brilliant with Bart...He acknowledged and respected him like a fellow actor. He would spend hours just looking at Bart and admiring him. He did so many of his own scenes with Bart.\"\n\nHopkins was Britain's highest paid performer in 1998, starring in \"The Mask of Zorro\" and \"Meet Joe Black\", and also agreed to reprise his role as Dr Hannibal Lecter for a fee of £15 million. In 2000, Hopkins narrated \"Dr. Seuss' How the Grinch Stole Christmas\". Hopkins received a star on the Hollywood Walk of Fame in 2003.\n\nHopkins stated that his role as Burt Munro, whom he portrayed in his 2005 film \"The World's Fastest Indian\", was his favourite. He also asserted that Munro was the easiest role that he had played because both men have a similar outlook on life. In 2006, Hopkins was the recipient of the Golden Globe Cecil B. DeMille Award for lifetime achievement. In 2008, he received the BAFTA Academy Fellowship Award, the highest award the British Film Academy can bestow.\n\nOn 24 February 2010, it was announced that Hopkins had been cast in \"The Rite\", which was released on 28 January 2011. He played a priest who is \"an expert in exorcisms and whose methods are not necessarily traditional\". Hopkins, who is quoted as saying \"I don't know what I believe, myself personally\", reportedly wrote a line--\"Some days I don't know if I believe in God or Santa Claus or Tinkerbell\"—into his character in order to identify with it. On the other hand, in other sources from the same time, he is quoted as saying that he did believe in God and had done so for decades. On 21 September 2011, Peter R. de Vries named Hopkins in the role of the Heineken owner Freddy Heineken in a future film about his kidnapping.\n\nHopkins portrayed Odin, the Allfather or \"king\" of Asgard, in the 2011 film adaptation of Marvel Comics' \"Thor\". Hopkins portrayed Alfred Hitchcock in Sacha Gervasi's biopic \"Hitchcock\", following his career while making \"Psycho\". The film was released on 23 November 2012. In 2013, he reprised his role as Odin in \"\". In 2014, he portrayed Methuselah in Darren Aronofsky's \"Noah\". Since October 2016, Hopkins has been starring as Robert Ford in the HBO sci-fi series \"Westworld\". Hopkins played Autobot ally Sir Edmund Burton in \"\", which was released in June 2017.\n\nHopkins' most famous role is as the cannibalistic serial killer Hannibal Lecter in \"The Silence of the Lambs\", for which he won the Academy Award for Best Actor in 1991, with Jodie Foster as Clarice Starling, who also won for Best Actress. The film won Best Picture, Best Director and Academy Award for Best Adapted Screenplay. Hopkins reprised his role as Lecter twice; in Ridley Scott's \"Hannibal\" (2001), and \"Red Dragon\" (2002). His original portrayal of the character in \"The Silence of the Lambs\" has been labelled by the AFI as the number-one film villain. At the time he was offered the role, Hopkins was making a return to the London stage, performing in \"M. Butterfly\". He had come back to Britain after living for a number of years in Hollywood, having all but given up on a career there, saying, \"Well that part of my life's over; it's a chapter closed. I suppose I'll just have to settle for being a respectable actor poncing around the West End and doing respectable BBC work for the rest of my life.\"\n\nHopkins played the iconic villain in adaptations of the first three of the Lecter novels by Thomas Harris. The author was reportedly very pleased with Hopkins' portrayal of his antagonist. However, Hopkins stated that \"Red Dragon\" would feature his final performance as the character, and that he would not reprise even a narrative role in the latest addition to the series, \"Hannibal Rising\".\n\nHopkins is renowned for his preparation for roles. He indicated in interviews that once he has committed to a project, he will go over his lines as many times as is needed (sometimes upwards of 200) until the lines sound natural to him, so that he can \"do it without thinking\". This leads to an almost casual style of delivery that belies the amount of groundwork done beforehand. While it can allow for some careful improvisation, it has also brought him into conflict with the occasional director who departs from the script, or demands what the actor views as an excessive number of takes. Hopkins has stated that after he is finished with a scene, he simply discards the lines, not remembering them later on. This is unlike others who usually remember their lines from a film, even years later.\n\nRichard Attenborough, who directed Hopkins on five occasions, found himself going to great lengths during the filming of \"Shadowlands\" (1993) to accommodate the differing approaches of his two stars (Hopkins and Debra Winger), who shared many scenes. Whereas Hopkins, preferring the spontaneity of a fresh take, liked to keep rehearsals to a minimum, Winger rehearsed continuously. To allow for this, Attenborough stood in for Hopkins during Winger's rehearsals, only bringing him in for the last one before a take. The director praised Hopkins for \"this extraordinary ability to make you believe when you hear him that it is the very first time he has ever said that line. It's an incredible gift.\"\n\nRenowned for his ability to remember lines, Hopkins keeps his memory supple by learning things by heart such as poetry, and Shakespeare. In Steven Spielberg's \"Amistad\", Hopkins astounded the crew with his memorisation of a seven-page courtroom speech, delivering it in one go. An overawed Spielberg couldn't bring himself to call him Tony, and insisted on addressing him as Sir Anthony throughout the shoot.\n\nHopkins is a gifted mimic, adept at turning his native Welsh accent into whatever is required by a character. He duplicated the voice of his late mentor, Laurence Olivier, for additional scenes in \"Spartacus\" in its 1991 restoration. His interview on the 1998 relaunch edition of the British TV talk show \"Parkinson\" featured an impersonation of comedian Tommy Cooper. Hopkins has said acting \"like a submarine\" has helped him to deliver credible performances in his thrillers. He said, \"It's very difficult for an actor to avoid, you want to show a bit. But I think the less one shows the better.\"\n\nAnthony Hopkins was made a Commander of the Order of the British Empire (CBE) in 1987, and was knighted as a Knight Bachelor at Buckingham Palace in 1993 for services to the arts. In 1988, Hopkins was made an Honorary D.Litt and in 1992 was awarded Honorary fellowship from the University of Wales, Lampeter. He was made a freeman of his hometown Port Talbot in 1996.\n\nHopkins resides in Malibu, California. He had moved to the US once before during the late 1970s to pursue his film career, but returned to London in the late 1980s. However, he decided to return to the US following his 1990s success. Retaining his British citizenship, he became a naturalised US citizen on 12 April 2000, with Hopkins stating: \"I have dual citizenship; it just so happens I live in America\".\n\nHopkins has been married three times: to Petronella Barker from 1966 to 1972; to Jennifer Lynton from 1973 to 2002; and, since 2003, to Stella Arroyave. On Christmas Eve 2012, he celebrated his 10th wedding anniversary by having a blessing at a private service at St David's Cathedral, Pembrokeshire in the most westerly point of Wales. He has a daughter, actress and singer Abigail Hopkins (born 20 August 1968), from his first marriage.\n\nHopkins is a recovering alcoholic; he has stayed sober since he stopped drinking just after Christmas 1975. In 2002, he told the New York Times that he woke up in a Phoenix hotel room with no memory of having driven from Los Angeles. \"It was two days before his 38th birthday. Still, he continued to spiral downward, at times sitting at home for hours without saying a word. He'd climb in his car and cruise aimlessly for days: once he went on a drive and didn't return for two months. \"If there is someone fighting within you, it makes your life unbearable,\" he said. \"Anger has to be converted into something else or it destroys you.\" He said that a major help in his recovery was his belief in God. He has criticised atheism, saying in 2011 that \"being an atheist must be like living in a closed cell with no windows\". In an interview with Larry King in 2016, Hopkins described himself as an agnostic and said he believed in a \"superior consciousness in all of us\". He gave up smoking using the Allen Carr method. In 2008, he embarked on a weight loss program, and by 2010, he had lost 80 pounds.\n\nIn January 2017, in an interview with \"The Desert Sun\", Hopkins reported that he had been diagnosed with Asperger syndrome, but that he was \"high end\".\n\nHopkins has offered his support to various charities and appeals, notably becoming President of the National Trust's Snowdonia Appeal, raising funds for the preservation of Snowdonia National Park in north Wales. In 1998 he donated £1 million towards the £3 million needed to aid the Trust's efforts in purchasing parts of Snowdon. Prior to the campaign, Hopkins authored \"Anthony Hopkins' Snowdonia\", which was published in 1995. Due to his contributions to Snowdonia, in addition to his film career, in 2004 Hopkins was named among the 100 Welsh Heroes in a Welsh poll.\n\nHopkins has been a patron of the YMCA centre in his hometown of Port Talbot, South Wales for more than 20 years, having first joined the YMCA in the 1950s. He supports other various philanthropic groups. He was a Guest of Honour at a Gala Fundraiser for Women in Recovery, Inc., a Venice, California-based non-profit organisation offering rehabilitation assistance to women in recovery from substance abuse. He is also a volunteer teacher at the Ruskin School of Acting in Santa Monica, California. Hopkins served as the Honorary Patron of The New Heritage Theatre Company in Boise, Idaho from 1997-2007, participating in fundraising and marketing efforts for the repertory theatre.\n\nHopkins contributed toward the refurbishment of a £2.3 million wing at his alma mater, the Royal Welsh College of Music & Drama in Cardiff, named the Anthony Hopkins Centre. It opened in 1999.\n\nHopkins is a prominent member of environmental protection group Greenpeace and as of early 2008 featured in a television advertisement campaign, voicing concerns about Japan's continuing annual whale hunt. He has also been a patron of RAPt (Rehabilitation for Addicted Prisoners Trust) since its early days and helped open their first intensive drug and alcohol rehabilitation unit at Downview (HM Prison) in 1992.\n\nHopkins is an admirer of the Welsh comedian Tommy Cooper. On 23 February 2008, as patron of the Tommy Cooper Society, he unveiled a commemorative statue in the entertainer's home town of Caerphilly. For the ceremony, he donned Cooper's trademark fez and performed a comic routine.\n\nIn a 2012 interview, Hopkins stated, \"I've been composing music all my life and if I'd been clever enough at school I would like to have gone to music college. As it was I had to settle for being an actor.\" In 1986, he released a single called \"Distant Star\", which peaked at No. 75 in the UK Singles Chart. In 2007, he announced he would retire temporarily from the screen to tour around the world. Hopkins has also written music for the concert hall, in collaboration with Stephen Barton as orchestrator. These compositions include \"The Masque of Time\", given its world premiere with the Dallas Symphony Orchestra in October 2008, and \"Schizoid Salsa\".\n\nIn 1990, Hopkins directed a film about his Welsh compatriot, poet Dylan Thomas, titled \"Dylan Thomas: Return Journey\", which was his directing debut for the screen. In the same year, as part of the restoration process for the Stanley Kubrick film \"Spartacus\", Hopkins was approached to re-record lines from a scene that was being added back to the film; this scene featured Laurence Olivier and Tony Curtis, with Hopkins recommended by Olivier's widow, Joan Plowright to perform her late husband's part thanks to his talent for mimicry.\n\nIn 1996, he directed \"August\", an adaptation of Chekhov's \"Uncle Vanya\" set in Wales. His first screenplay, an experimental drama called \"Slipstream\", which he also directed and scored, premiered at the Sundance Film Festival in 2007. In 1997, Hopkins narrated the BBC natural documentary series, \"Killing for a Living\", which showed predatory behaviour in nature. He narrated episode 1 through 3 before being replaced by John Shrapnel.\n\nHopkins is a fan of the BBC sitcom \"Only Fools and Horses\", and once remarked in an interview how he would love to appear in the series. Writer John Sullivan saw the interview, and with Hopkins in mind created the character Danny Driscoll, a local villain. However, filming of the new series coincided with the filming of \"The Silence of the Lambs\", making Hopkins unavailable. The role instead went to Roy Marsden.\n\nOn 31 October 2011, André Rieu released an album including a waltz which Hopkins had composed in 1964, at the age of 27. Hopkins had never heard his composition, \"And the Waltz Goes On\", before it was premiered by Rieu's orchestra in Vienna; Rieu's album was given the same name as Hopkins' piece.\n\nIn January 2012, Hopkins released an album of classical music, entitled \"Composer\", performed by the City of Birmingham Symphony Orchestra, and released on CD via the UK radio station Classic FM. The album consists of nine of his original works and film scores, with one of the pieces titled \"Margam\" in tribute to his home town near Port Talbot in Wales.\n\nIn October 2015, Hopkins appeared as Sir in a BBC Two production of Ronald Harwood's \"The Dresser\", alongside Ian McKellen, Edward Fox and Emily Watson. \"The Dresser\" is set in a London theatre during the Blitz, where an aging actor-manager, Sir, prepares for his starring role in \"King Lear\" with the help of his devoted dresser, Norman.\n\n"}
{"id": "2398", "url": "https://en.wikipedia.org/wiki?curid=2398", "title": "Ardal O'Hanlon", "text": "Ardal O'Hanlon\n\nArdal O'Hanlon (; born 8 October 1965) is an Irish comedian and actor. He played Father Dougal McGuire in \"Father Ted\", George Sunday/Thermoman in \"My Hero\", and DI Jack Mooney in \"Death in Paradise\".\n\nArdal O'Hanlon was born on 8 October 1965 in Carrickmacross, the son of politician and doctor Rory O'Hanlon and Teresa Ward. He has five siblings. The episode of \"Who Do You Think You Are?\" which aired on 6 October 2008 revealed that O'Hanlon's paternal grandfather, Michael O'Hanlon, was a UCD medicine student who had joined the IRA during the Irish War of Independence and was a member of Michael Collins' squad which assassinated British secret service agents on the morning of Bloody Sunday. Details of his grandfather's activities survive in UCD Archives, as well as Blackrock College. It also transpired that, on his mother's side, he is a close relative of Peter Fenelon Collier.\n\nO'Hanlon was schooled in Blackrock College in Dublin and graduated, in 1987, from the National Institute for Higher Education, Dublin (now Dublin City University) with a degree in Communications Studies.\n\nTogether with Kevin Gildea and Barry Murphy, O'Hanlon founded the International Comedy Cellar, upstairs in the International Bar on Dublin's South Wicklow Street. Dublin had no comedy scene at the time. As a stand up, O'Hanlon won the Hackney Empire New Act of the Year competition in 1994. For a time he was the presenter of \"The Stand Up Show\".\n\nHe was spotted by Graham Linehan, who was to cast him as Father Dougal McGuire in \"Father Ted\" (1995–98). In 1995 he received the Top TV Comedy Newcomer at the British Comedy Awards for this role. In 1995, he appeared (as Father Dougal) in a Channel 4 ident (\"Hello, you're watching... television\"), and during Comic Relief on BBC1. This was followed by the award-winning short comedy film \"Flying Saucer Rock'n'Roll\".\n\nO'Hanlon moved into straight acting alongside Emma Fielding and Beth Goddard in the ITV comedy-drama \"Big Bad World\", which aired for two series in summer 1999 and winter 2001. He also played a minor role in \"The Butcher Boy\" as Joe's (Francie's best friend) father, and appeared in an episode of the original \"Whose Line is it Anyway?\".\n\nIn 2000, O'Hanlon starred in the comedy series \"My Hero\", in which he played a very naive superhero from the planet Ultron. His character juggled world-saving heroics with life in suburbia. He stayed in the role until the first episode of series 6 in July 2006 where he was replaced by James Dreyfus during the same episode.\n\nHe also provided the voice of the lead character in the three Christmas television cartoon specials of \"Robbie the Reindeer\". He appeared in the 2005 BBC One sitcom \"Blessed\", written by Ben Elton; at the 2005 British Comedy Awards, it was publicly slated by Jonathan Ross, albeit in jest. Towards the end of 2005, he played an eccentric Scottish character, Coconut Tam, in the family-based film, \"The Adventures of Greyfriars Bobby\". Although more commonly on television, he has appeared on radio – on 18 July 2011, he appeared on \"Quote... Unquote\". Appropriately, one of his questions concerned a quotation from \"Father Ted\".\n\nIn 2006, O'Hanlon wrote and presented an RTÉ television series called \"Leagues Apart\", which saw him investigate the biggest and most passionate football rivalries in a number of European countries. Included were Roma vs Lazio in Italy, Barcelona vs Real Madrid in Spain, and Galatasaray vs Fenerbahce in Turkey. He followed this with another RTÉ show, \"So You Want To Be Taoiseach?\" in 2007. It was a political series where O'Hanlon gave tongue-in-cheek advice on how to go about becoming Taoiseach of Ireland. Both programmes went some way towards freeing O'Hanlon from his association with the character of Dougal in the minds of Irish audiences.\n\nHe appeared in the \"Doctor Who\" episode \"Gridlock\", broadcast on 14 April 2007, in which he played a cat-like creature named Thomas Kincade Brannigan. O'Hanlon appears in Series 3 of the TV show \"Skins\", playing Naomi Campbell (Lily Loveless)'s Politics teacher named Kieran, who attempted to kiss her. He then went on to form a relationship with Naomi's mother (Olivia Colman). O'Hanlon plays the lead role in Irish comedy television programme \"Val Falvey, TD\" on RTÉ One. He has recently performed in the Edinburgh Fringe.\n\nIn February 2011, O'Hanlon returned to the Gate Theatre, Dublin starring in the Irish premiere of Christopher Hampton's translation of Yasmina Reza's \"God of Carnage\", alongside Maura Tierney.\n\nIn 2011, he appeared in the comedy panel show \"Argumental\".\n\nO'Hanlon has written a novel, \"The Talk of the Town\" (known in the United States as \"Knick Knack Paddy Whack\"), which was published in 1998. The novel is about a teenage boy, Patrick Scully, and his friends.\n\nIn February 2015 he officially launched the 2015 Sky Cat Laughs Comedy Festival which takes place in Kilkenny from 28 May–1 June. In 2015 he played the role of Peter the Milkman in the Sky 1 sitcom \"After Hours\".\n\nOn 2 February 2017, it was announced he will play the lead role in the BBC crime sitcom \"Death in Paradise\" taking the role of DI Jack Mooney following Kris Marshall's departure the same day.\n\nArdal has been doing stand up for many years appearing on many shows including Live at the Apollo, Michael McIntyre's Comedy Roadshow and Dave's One Night Stand. In 1994 he won the Hackney Empire New Act of the Year.\nO'Hanlon is married to Melanie, whom he met as a teenager, and with whom he has three children: Emily, Rebecca and Red. He is a supporter of Leeds United.\n\n"}
{"id": "2400", "url": "https://en.wikipedia.org/wiki?curid=2400", "title": "Advanced Micro Devices", "text": "Advanced Micro Devices\n\nAdvanced Micro Devices, Inc. (AMD) is an American multinational semiconductor company based in Sunnyvale, California, United States, that develops computer processors and related technologies for business and consumer markets. While initially it manufactured its own processors, the company later outsourced its manufacturing, a practice known as fabless, after GlobalFoundries was spun off in 2009. AMD's main products include microprocessors, motherboard chipsets, embedded processors and graphics processors for servers, workstations and personal computers, and embedded systems applications.\n\nAMD is the second-largest supplier and only significant rival to Intel in the market for x86-based microprocessors. Since acquiring ATI in 2006, AMD and its competitor Nvidia have dominated the discrete Graphics Processing Unit (GPU) market.\n\nAdvanced Micro Devices was formally incorporated on May 1, 1969, by Jerry Sanders, along with seven of his colleagues from Fairchild Semiconductor. Sanders, an electrical engineer who was the director of marketing at Fairchild, had like many Fairchild executives, grown frustrated with the increasing lack of support, opportunity, and flexibility within that company, and decided to leave to start his own semiconductor company. The previous year Robert Noyce, who had invented the first practical integrated circuit or the microchip in 1959 at Fairchild, had left Fairchild together with Gordon Moore and founded the semiconductor company Intel in July 1968.\n\nIn September 1969, AMD moved from its temporary location in Santa Clara to Sunnyvale, California. To immediately secure a customer base, AMD initially became a second source supplier of microchips designed by Fairchild and National Semiconductor. AMD first focused on producing logic chips. The company guaranteed quality control to United States Military Standard, an advantage in the early computer industry since unreliability in microchips was a distinct problem that customers – including computer manufacturers, the telecommunications industry, and instrument manufacturers – wanted to avoid.\n\nIn November 1969, the company manufactured its first product, the Am9300, a 4-bit MSI shift register, which began selling in 1970. Also in 1970, AMD produced its first proprietary product, the Am2501 logic counter, which was highly successful. Its best-selling product in 1971 was the Am2505, the fastest multiplier available.\n\nIn 1971, AMD entered the RAM chip market, beginning with the Am3101, a 64-bit bipolar RAM. That year AMD also greatly increased the sales volume of its linear integrated circuits, and by year end the company's total annual sales reached $4.6 million.\n\nAMD went public in September 1972. The company was a second source for Intel MOS/LSI circuits by 1973, with products such as Am14/1506 and Am14/1507, dual 100-bit dynamic shift registers. By 1975, AMD was producing 212 products – of which 49 were proprietary, including the Am9102 (a static N-channel 1024-bit RAM) and three low-power Schottky MSI circuits: Am25LS07, Am25LS08, and Am25LS09.\n\nIntel had created the first microprocessor, its 4-bit 4004, in 1971. By 1975, AMD entered the microprocessor market with the Am9080, a reverse-engineered clone of the Intel 8080, and the Am2900 bit-slice microprocessor family. When Intel began installing microcode in its microprocessors in 1976, it entered into a cross-licensing agreement with AMD, granting AMD a copyright license to the microcode in its microprocessors and peripherals, effective October 1976.\n\nIn 1977, AMD entered into a joint venture with Siemens, a German engineering conglomerate wishing to enhance its technology expertise and enter the U.S. market. Siemens purchased 20% of AMD's stock, giving AMD an infusion of cash to increase its product lines. That year the two companies also jointly established Advanced Micro Computers, located in Silicon Valley and in Germany, giving AMD an opportunity to enter the microcomputer development and manufacturing field, in particular based on AMD's second-source Zilog Z8000 microprocessors. When the two companies' vision for Advanced Micro Computers diverged, AMD bought out Siemens' stake in the U.S. division in 1979. AMD closed its Advanced Micro Computers subsidiary in late 1981, after switching focus to manufacturing second-source Intel x86 microprocessors.\n\nTotal sales in fiscal year 1978 topped $100 million, and in 1979, AMD debuted on the New York Stock Exchange. In 1979, production also began in AMD's new semiconductor fab in Austin, Texas; the company already had overseas assembly facilities in Penang and Manila, and it began construction on a semiconductor fab in San Antonio in 1981. In 1980, AMD began supplying semiconductor products for telecommunications, an industry undergoing rapid expansion and innovation.\n\nIntel had introduced the first x86 microprocessors in 1978. In 1981, IBM created its PC, and wanted Intel's x86 processors, but only under the condition that Intel also provide a second-source manufacturer for its patented x86 microprocessors. Intel and AMD entered into a 10-year technology exchange agreement, first signed in October 1981 and formally executed in February 1982. The terms of the agreement were that each company could acquire the right to become a second-source manufacturer of semiconductor products developed by the other; that is, each party could \"earn\" the right to manufacture and sell a product developed by the other, if agreed to, by exchanging the manufacturing rights to a product of equivalent technical complexity. The technical information and licenses needed to make and sell a part would be exchanged for a royalty to the developing company. The 1982 agreement also extended the 1976 AMD–Intel cross-licensing agreement through 1995. The agreement included the right to invoke arbitration of disagreements, and after five years the right of either party to end the agreement with one year's notice. The main result of the 1982 agreement was that AMD became a second-source manufacturer of Intel's x86 microprocessors and related chips, and Intel provided AMD with database tapes for its 8086, 80186, and 80286 chips.\n\nBeginning in 1982, AMD began volume-producing second-source Intel-licensed 8086, 8088, 80186, and 80188 processors, and by 1984 its own Am286 clone of Intel's 80286 processor, for the rapidly growing market of IBM PCs and IBM clones. It also continued its successful concentration on proprietary bipolar chips. In 1983, it introduced INT.STD.1000, the highest manufacturing quality standard in the industry.\n\nThe company continued to spend greatly on research and development, and in addition to other breakthrough products, created the world's first 512K EPROM in 1984. That year AMD was listed in the book \"The 100 Best Companies to Work for in America\", and based on 1984 income it made the \"Fortune\" 500 list for the first time in 1985.\n\nBy mid-1985, however, the microchip market experienced a severe downturn, mainly due to long-term aggressive trade practices (dumping) from Japan, but also due to a crowded and non-innovative chip market in the U.S. AMD rode out the mid-1980s crisis by aggressively innovating and modernizing, devising the Liberty Chip program of designing and manufacturing one new chip or chip set per week for 52 weeks in fiscal year 1986, and by heavily lobbying the U.S. government until sanctions and restrictions were put in place to prevent predatory Japanese pricing. During this time period, AMD withdrew from the DRAM market, and at the same time made some headway into the CMOS market, which it had lagged in entering, having focused instead on bipolar chips.\n\nAMD had some success in the mid-1980s with the AMD7910 and AMD7911 \"World Chip\" FSK modem, one of the first multi-standard devices that covered both Bell and CCITT tones at up to 1200 baud half duplex or 300/300 full duplex. Beginning in 1986, AMD embraced the perceived shift toward RISC with their own AMD Am29000 (29k) processor; the 29k survived as an embedded processor. The company also increased its EPROM memory market share in the late 1980s. Throughout the 1980s, AMD was a second-source supplier of Intel x86 processors. In 1991, it introduced its own 386-compatible Am386, an AMD-designed chip. Creating its own chips, AMD began to compete directly with Intel.\n\nAMD had a large and successful flash memory business, even during the dotcom bust. In 2003, to divest some manufacturing and aid its overall cash flow, which was under duress from aggressive microprocessor competition from Intel, AMD spun off its flash memory business and manufacturing into Spansion, a joint venture with Fujitsu, which had been co-manufacturing flash memory with AMD since 1993. AMD divested itself of Spansion in December 2005, in order to focus on the microprocessor market, and Spansion went public in an IPO.\n\nAMD announced the acquisition of the graphics processor company ATI Technologies on July 24, 2006. AMD paid $4.3 billion in cash and 58 million shares of its stock, for a total of approximately $5.4 billion. The transaction completed on October 25, 2006. On August 30, 2010, AMD announced that it would retire the ATI brand name for its graphics chipsets in favor of the AMD brand name.\n\nIn October 2008, AMD announced plans to spin off manufacturing operations in the form of a multibillion-dollar joint venture with Advanced Technology Investment Co., an investment company formed by the government of Abu Dhabi. The new venture is called GlobalFoundries Inc. The partnership and spin-off gave AMD an infusion of cash and allowed AMD to focus solely on chip design. To assure the Abu Dhabi investors of the new venture's success, CEO Hector Ruiz stepped down as CEO of AMD in July 2008, while remaining Executive Chairman, in preparation for becoming Chairman of Global Foundries in March 2009. President and COO Dirk Meyer became AMD's CEO. Recessionary losses necessitated AMD cutting 1,100 jobs in 2009.\n\nIn August 2011, AMD announced that former Lenovo executive Rory Read would be joining the company as CEO, replacing Meyer. AMD announced in November 2011 plans to lay off more than 10% (1,400) of its employees from across all divisions worldwide. In October 2012, it announced plans to lay off an additional 15% of its workforce to reduce costs in the face of declining sales revenue.\n\nAMD acquired the low-power server manufacturer SeaMicro in early 2012, with an eye to bringing out an ARM architecture server chip.\n\nOn October 8, 2014, AMD announced that Rory Read had stepped down after three years as president and chief executive officer. He was succeeded by Lisa Su, a key lieutenant who had been serving as chief operating officer since June.\n\nOn October 16, 2014, AMD announced a new restructuring plan along with its Q3 results. Effective July 1, 2014, AMD reorganized into two business groups: Computing and Graphics, which primarily includes desktop and notebook processors and chipsets, discrete GPUs, and professional graphics; and Enterprise, Embedded and Semi-Custom, which primarily includes server and embedded processors, dense servers, semi-custom SoC products (including solutions for gaming consoles), engineering services, and royalties. As part of this restructuring, AMD announced that 7% of its global workforce would be laid off by the end of 2014.\n\nIn February 1982, AMD signed a contract with Intel, becoming a licensed second-source manufacturer of 8086 and 8088 processors. IBM wanted to use the Intel 8088 in its IBM PC, but IBM's policy at the time was to require at least two sources for its chips. AMD later produced the Am286 under the same arrangement. In 1984 Intel, in order to shore up its advantage in the marketplace, internally decided to no longer cooperate with AMD in supplying product information, and delayed and eventually refused to convey the technical details of the Intel 80386 to AMD. In 1987, AMD invoked arbitration over the issue, and Intel reacted by cancelling the 1982 technological-exchange agreement altogether. After three years of testimony, AMD eventually won in arbitration in 1992, but Intel disputed this decision. Another long legal dispute followed, ending in 1994 when the Supreme Court of California sided with the arbitrator and AMD.\n\nIn 1990, Intel also countersued AMD, renegotiating AMD's right to use derivatives of Intel's microcode for its cloned processors. In the face of uncertainty during the legal dispute, AMD was forced to develop clean-room designed versions of Intel code for its x386 and x486 processors, the former long after Intel had released its own x386 in 1985. In March 1991, AMD released the Am386, its clone of the Intel 386 processor. By October of the same year it had sold one million units.\n\nIn 1993, AMD introduced the first of the Am486 family of processors, which proved popular with a large number of original equipment manufacturers, including Compaq, which signed an exclusive agreement using the Am486. Another Am486-based processor, the Am5x86, was released in November 1995 and continued AMD's success as a fast, cost-effective processor.\n\nFinally, in an agreement effective 1996, AMD received the rights to the microcode in Intel's x386 and x486 processor families, but not the rights to the microcode in the following generations of processors.\n\nAMD's first in-house x86 processor was the K5, which was launched in 1996. The \"K\" was a reference to Kryptonite. (In comic books, the only substance which could harm Superman was Kryptonite. This is a reference to Intel's hegemony over the market, i.e., an anthropomorphization of them as Superman.) The numeral \"5\" refers to the fifth generation of x86 processors; rival Intel had previously introduced its line of fifth-generation x86 processors as Pentium because the U.S. Trademark and Patent Office had ruled that mere numbers could not be trademarked.\n\nIn 1996, AMD purchased NexGen, specifically for the rights to their Nx series of x86-compatible processors. AMD gave the NexGen design team their own building, left them alone, and gave them time and money to rework the Nx686. The result was the K6 processor, introduced in 1997. Although the K6 was based on Socket 7, variants such as K6-3/450 were faster than Intel's Pentium II (sixth-generation processor).\n\nThe K7 was AMD's seventh-generation x86 processor, making its debut on June 23, 1999, under the brand name Athlon. Unlike previous AMD processors, it could not be used on the same motherboards as Intel's, due to licensing issues surrounding Intel's Slot 1 connector, and instead used a Slot A connector, referenced to the Alpha processor bus. The Duron was a lower-cost and limited version of the Athlon (64KB instead of 256KB L2 cache) in a 462-pin socketed PGA (socket A) or soldered directly onto the motherboard. Sempron was released as a lower-cost Athlon XP, replacing Duron in the socket A PGA era. It has since been migrated upward to all new sockets, up to AM3.\n\nOn October 9, 2001, the Athlon XP was released. On February 10, 2003, the Athlon XP with 512KB L2 Cache was released.\n\nThe K8 was a major revision of the K7 architecture, with the most notable features being the addition of a 64-bit extension to the x86 instruction set (called x86-64, AMD64, or x64), the incorporation of an on-chip memory controller, and the implementation of an extremely high performance point-to-point interconnect called HyperTransport, as part of the Direct Connect Architecture. The technology was initially launched as the Opteron server-oriented processor on April 22, 2003. Shortly thereafter it was incorporated into a product for desktop PCs, branded Athlon 64.\n\nOn April 21, 2005, AMD released the first dual core Opteron, an x86-based server CPU. A month later, AMD released the Athlon 64 X2, the first desktop-based dual core processor family. In May 2007, AMD abandoned the string \"64\" in its dual-core desktop product branding, becoming Athlon X2, downplaying the significance of 64-bit computing in its processors. Further updates involved improvements to the microarchitecture, and a shift of target market from mainstream desktop systems to value dual-core desktop systems. In 2008, AMD started to release dual-core Sempron processors exclusively in China, branded as the Sempron 2000 series, with lower HyperTransport speed and smaller L2 cache. Thus AMD completed its dual-core product portfolio for each market segment.\n\nAfter K8 came K10. In September 2007, AMD released the first K10 processors, Third Generation Opteron processors, followed in November by the Phenom processor for desktop. K10 processors came in dual-core, triple-core, and quad-core versions, with all cores on a single die. AMD released a new platform, codenamed \"Spider\", which utilized the new Phenom processor, as well as an R770 GPU and a 790 GX/FX chipset from the AMD 700 chipset series. However, AMD built the Spider at 65nm, which was uncompetitive with Intel's smaller and more power-efficient 45nm.\n\nIn January 2009, AMD released a new processor line dubbed Phenom II, a refresh of the original Phenom built using the 45 nm process. AMD's new platform, codenamed “Dragon”, utilized the new Phenom II processor, and an ATI R770 GPU from the R700 GPU family, as well as a 790 GX/FX chipset from the AMD 700 chipset series. The Phenom II came in dual-core, triple-core and quad-core variants, all using the same die, with cores disabled for the triple-core and dual-core versions. The Phenom II resolved issues that the original Phenom had, including a low clock speed, a small L3 cache and a Cool'n'Quiet bug that decreased performance. The Phenom II cost less but was not performance-competitive with Intel's mid-to-high-range Core 2 Quads. The Phenom II also enhanced the Phenom's memory controller, allowing it to use DDR3 in a new native socket AM3, while maintaining backwards compatibility with AM2+, the socket used for the Phenom, and allowing the use of the DDR2 memory that was used with the platform.\n\nIn April 2010, AMD released a new Phenom II hexa-core (6-core) processor codenamed \"Thuban\". This was a totally new die based on the hexa-core “Istanbul” Opteron processor. It included AMD's “turbo core” technology, which allows the processor to automatically switch from 6 cores to 3 faster cores when more pure speed is needed.\n\nThe Magny Cours and Lisbon server parts were released in 2010. The Magny Cours part came in 8 to 12 cores and the Lisbon part in 4 and 6 core parts. Magny Cours is focused on performance while the Lisbon part is focused on high performance per watt. Magny Cours is an MCM (multi-chip module) with two hexa-core “Istanbul” Opteron parts. This will use a new G34 socket for dual and quad socket processors and thus will be marketed as Opteron 61xx series processors. Lisbon uses C32 socket certified for dual socket use or single socket use only and thus will be marketed as Opteron 41xx processors. Both will be built on a 45 nm SOI process.\n\nFollowing AMD's 2006 acquisition of Canadian graphics company ATI Technologies, an initiative codenamed \"Fusion\" was announced to integrate a CPU and GPU together on some of AMD's microprocessors, including a built in PCI Express link to accommodate separate PCI Express peripherals, eliminating the northbridge chip from the motherboard. The initiative intended to move some of the processing originally done on the CPU (e.g. floating-point unit operations) to the GPU, which is better optimized for some calculations. The Fusion was later renamed to the AMD APU (Accelerated Processing Unit).\n\nLlano was AMD's first APU built for laptops. Llano was the second APU released, targeted at the mainstream market. Incorporating a CPU and GPU on the same die, as well as northbridge functions, and using \"Socket FM1\" with DDR3 memory. The CPU part of the processor was based on the Phenom II \"Deneb\" processor. AMD suffered an unexpected decrease in revenue based on production problems for the Llano.\n\nBulldozer is AMD's microarchitecture codename for server and desktop AMD FX processors first released on October 12, 2011. This family 15h microarchitecture is the successor to the family 10h (K10) microarchitecture design. Bulldozer is designed from scratch, not a development of earlier processors. The core is specifically aimed at 10–125 W TDP computing products. AMD claims dramatic performance-per-watt efficiency improvements in high-performance computing (HPC) applications with Bulldozer cores. While hopes were very high that Bulldozer would bring AMD to be performance competitive with archrival Intel once more, most benchmarks were disappointing. In some cases the new Bulldozer products were slower than the K10 model they were built to replace.\n\nThe Piledriver microarchitecture was the 2012 successor to Bulldozer, increasing clock speeds and performance relative to its predecessor. Piledriver would be released in AMD FX, APU, and Opteron product lines. Piledriver was subsequently followed by the Steamroller microarchitecture in 2013. Used exclusively in AMD's APUs, Steamroller focused on greater parallelism.\n\nIn 2015, the Excavator microarchitecture replaced Piledriver. Expected to be the last microarchitecture of the Bulldozer series, Excavator focused on improved power efficiency.\n\nThe Bobcat microarchitecture was revealed during a speech from AMD executive vice-president Henri Richard in Computex 2007 and was put into production Q1 2011. Based on the difficulty competing in the x86 market with a single core optimized for the 10–100 W range, AMD had developed a simpler core with a target range of 1–10 watts. In addition, it was believed that the core could migrate into the hand-held space if the power consumption can be reduced to less than 1 W.\n\nJaguar is a microarchitecture codename for Bobcat's successor, released in 2013, that is used in various APUs from AMD aimed at the low-power/low-cost market. Jaguar and its derivates would go on to be used in the custom APUs of the Playstation 4, Xbox One, PlayStation 4 Pro, Xbox One S, and Xbox One X. Jaguar would be later followed by the Puma microarchitecture in 2014.\n\nIn 2012, AMD announced it was working on an ARM architecture products, both as a semi-custom product and server product. The initial server product was announced at the Opteron A1100 in 2014, and 8-core Cortex-A57 based ARMv8-A SoC, and was expected to be followed by an APU incorporating a Graphic Core Next GPU. However, the Opteron A1100 was not released until 2016, with the delay attributed to adding software support. The A1100 was also criticed for not having support from major vendors upon its release.\n\nIn 2014, AMD also announced the K12 custom core for release in 2016. While being ARMv8-A instruction set architecture compliant, the K12 is expected to be entirely custom designed targeting server, embedded, and semi-custom markets. The K12 was subsequently delayed until 2017, in preference to the development of AMD's x86 based Zen microarchitecture.\n\nZen is a new architecture for x86-64 based Ryzen series CPUs and APUS, introduced in 2017 by AMD and built from the ground up by a team led by Jim Keller, beginning with his arrival in 2012, and taping out before his departure in September 2015. One of AMD's primary goals with Zen was an IPC increase of at least 40%, however in February 2017 AMD announced that they had actually achieved a 52% increase. Processors made on the Zen architecture are built on the 14 nm FinFET node and have a renewed focus on single-core performance and HSA compatibility. Previous processors from AMD were either built in the 32 nm process (\"Bulldozer\" and \"Piledriver\" CPUs) or the 28 nm process (\"Steamroller\" and \"Excavator\" APUs). Because of this, Zen is much more energy efficient. The Zen architecture is the first to encompass CPUs and APUs from AMD built for a single socket (Socket AM4). Also new for this architecture is the implementation of simultaneous multithreading (SMT) technology, something Intel has had for years on some of their processors with their proprietary Hyper-Threading implementation of SMT. This is a departure from the \"Clustered MultiThreading\" design introduced with the Bulldozer architecture. Zen also has support for DDR4 memory. AMD released the Zen-based high-end Ryzen 7 \"Summit Ridge\" series CPUs on March 2, 2017, mid-range Ryzen 5 series CPUs on April 11, 2017, and entry level Ryzen 3 series CPUs on July 27, 2017. AMD later released the Epyc line of Zen derived server processors for 1P and 2P systems. AMD is also expected to release next-generation Zen-based \"Raven Ridge\" APUs sometime in 2017.\n\nIn 2008 the ATI division of AMD released the TeraScale microarchitecture implementing a unified shader model. This design replaced the previous fixed-function hardware of previous graphics cards with multipurpose, programmable shaders. Initially released a part of the GPU for the Xbox 360 this technology would go on to be used in Radeon branded HD 2000 parts. Three generations of TeraScale would be designed and used in parts from 2008-2014.\n\nIn a 2009 restructuring, AMD merged the CPU and GPU divisions to support the companies APU's which fused both graphics and general purpose processing. In 2011, AMD released the successor to TeraScale, Graphics Core Next (GCN). This new microarchitecture emphasized GPGPU compute capability in addition to graphics processing, with a particular aim of supporting heterogeneous computing on AMD's APUs. GCN's reduced instruction set ISA allowed for significantly increased compute capability over TeraScale's very long instruction word ISA. Since GCN's introduction with the HD 7970, five generations of the GCN architecture have been produced from 2008 through at least 2017.\n\nIn September 2015, AMD separated the graphics technology division of the company into an independent internal unit called the Radeon Technology Group (RTG) headed by Raja Koduri. This gave the graphics division of AMD autonomy in product design and marketing. The RTG then went on to create and release the Polaris and Vega microarchitectures released in 2016 and 2017, respectively. In particular the Vega, or 5th generation GCN, microarchitecture includes a number of major revisions to improve performance and compute capabilities.\n\nIn 2012, AMD's then CEO Rory Read began a program to offer semi-custom designs. Rather than AMD simply designing and offering a single product, potential customers could work with AMD to design a custom chip based on AMD's intellectual property. Customers pay a non-recurring engineering fees for design and development, and a purchase price for the resulting semi-custom products. In particular, AMD noted their unique position of offering both x86 and graphics intellectual property. These semi-custom designs would have design wins as the APUs in the Playstation 4 and Xbox One and the subsequent PlayStation 4 Pro, Xbox One S, and Xbox One X. Financially, these semi-custom products would represent a majority of the company's revenue in 2016.\n\nBefore the launch of Athlon 64 processors in 2003, AMD designed chipsets for their processors spanning the K6 and K7 processor generations. The chipsets include the AMD-640, AMD-751 and the AMD-761 chipsets. The situation changed in 2003 with the release of Athlon 64 processors, and AMD chose not to further design its own chipsets for its desktop processors while opening the desktop platform to allow other firms to design chipsets. This was the “Open Platform Management Architecture” with ATI, VIA and SiS developing their own chipset for Athlon 64 processors and later Athlon 64 X2 and Athlon 64 FX processors, including the Quad FX platform chipset from Nvidia.\n\nThe initiative went further with the release of Opteron server processors as AMD stopped the design of server chipsets in 2004 after releasing the AMD-8111 chipset, and again opened the server platform for firms to develop chipsets for Opteron processors. As of today, Nvidia and Broadcom are the sole designing firms of server chipsets for Opteron processors.\n\nAs the company completed the acquisition of ATI Technologies in 2006, the firm gained the ATI design team for chipsets which previously designed the Radeon Xpress 200 and the Radeon Xpress 3200 chipsets. AMD then renamed the chipsets for AMD processors under AMD branding (for instance, the CrossFire Xpress 3200 chipset was renamed as AMD 580X CrossFire chipset). In February 2007, AMD announced the first AMD-branded chipset since 2004 with the release of the AMD 690G chipset (previously under the development codename \"RS690\"), targeted at mainstream IGP computing. It was the industry's first to implement a HDMI 1.2 port on motherboards, shipping for more than a million units. While ATI had aimed at releasing an Intel IGP chipset, the plan was scrapped and the inventories of Radeon Xpress 1250 (codenamed \"RS600\", sold under ATI brand) was sold to two OEMs, Abit and ASRock. Although AMD stated the firm would still produce Intel chipsets, Intel had not granted the license of FSB to ATI.\n\nOn November 15, 2007, AMD announced a new chipset series portfolio, the AMD 7-Series chipsets, covering from enthusiast multi-graphics segment to value IGP segment, to replace the AMD 480/570/580 chipsets and AMD 690 series chipsets, marking AMD's first enthusiast multi-graphics chipset. Discrete graphics chipsets were launched on November 15, 2007, as part of the codenamed \"Spider\" desktop platform, and IGP chipsets were launched at a later time in spring 2008 as part of the codenamed \"Cartwheel\" platform.\n\nAMD returned to the server chipsets market with the AMD 800S series server chipsets. It includes support for up to six SATA 6.0 Gbit/s ports, the C6 power state, which is featured in Fusion processors and AHCI 1.2 with SATA FIS–based switching support. This is a chipset family supporting Phenom processors and Quad FX enthusiast platform (890FX), IGP(890GX).\n\nWith the advent of AMD's APUs in 2011, traditional north bridge features such as the connection to graphics and the PCI Express controller were incorporated into the APU die. Accordingly, APUs were connected to as single chip chipset, renamed the Fusion Controller Hub (FCH), which primarily provided southbridge functionality.\n\nAMD released new chipsets in 2017 to support the release of their new Ryzen products. As the Zen microarchitecture already includes much of the northbridge connectivity, the AM4 based chipsets primarily varied in the number of additional PCI Express lanes, USB connections, and SATA connections available. These AM4 chipsets were designed in conjunction with ASMedia.\n\nIn February 2002, AMD acquired Alchemy Semiconductor for its Alchemy line of MIPS processors for the hand-held and portable media player markets. On June 13, 2006, AMD officially announced that the line was to be transferred to Raza Microelectronics, Inc., a designer of MIPS processors for embedded applications.\n\nIn August 2003, AMD also purchased the Geode business which was originally the Cyrix MediaGX from National Semiconductor to augment its existing line of embedded x86 processor products. During the second quarter of 2004, it launched new low-power Geode NX processors based on the K7 Thoroughbred architecture with speeds of fanless processors and , and processor with fan, of TDP 25 W. This technology is used in a variety of embedded systems (Casino slot machines and customer kiosks for instance), several UMPC designs in Asia markets, as well as the OLPC XO-1 computer, an inexpensive laptop computer intended to be distributed to children in developing countries around the world. The Geode LX processor was announced in 2005 and is said will continue to be available through 2015.\n\nAMD has also introduced 64-bit processors into its embedded product line starting with the AMD Opteron processor. Leveraging the high throughput enabled through HyperTransport and the Direct Connect Architecture these server class processors have been targeted at high-end telecom and storage applications. In 2007, AMD added the AMD Athlon, AMD Turion, and Mobile AMD Sempron processors to its embedded product line. Leveraging the same 64-bit instruction set and Direct Connect Architecture as the AMD Opteron but at lower power levels, these processors were well suited to a variety of traditional embedded applications. Throughout 2007 and into 2008, AMD has continued to add both single-core Mobile AMD Sempron and AMD Athlon processors and dual-core AMD Athlon X2 and AMD Turion processors to its embedded product line and now offers embedded 64-bit solutions starting with 8W TDP Mobile AMD Sempron and AMD Athlon processors for fan-less designs up to multi-processor systems leveraging multi-core AMD Opteron processors all supporting longer than standard availability.\n\nThe ATI acquisition in 2006 included the Imageon and Xilleon product lines. In late 2008, the entire handheld division was sold off to Qualcomm, who have since produced the Adreno series. Also in 2008, the Xilleon division was sold to Broadcom.\n\nIn April 2007, AMD announced the release of the M690T integrated graphics chipset for embedded designs. This enabled AMD to offer complete processor and chipset solutions targeted at embedded applications requiring high-performance 3D and video such as emerging digital signage, kiosk and Point of Sale applications. The M690T was followed by the M690E specifically for embedded applications which removed the TV output, which required Macrovision licensing for OEMs, and enabled native support for dual TMDS outputs, enabling dual independent DVI interfaces.\n\nIn January 2011, AMD announced the AMD Embedded G-Series Accelerated Processing Unit. This was the first APU for embedded applications. These were followed by updates to the in 2013 and 2016.\n\nIn May 2012, AMD Announced the AMD Embedded R-Series Accelerated Processing Unit. This family of products incorporates the Bulldozer CPU architecture, and Discrete-class Radeon HD 7000G Series graphics. This was followed by a system on a chip (SoC) version in 2015 which offered a faster CPU and faster graphics, with support for DDR4 SDRAM memory.\n\nAMD builds graphic processors for use in embedded systems. They can be found in anything from casinos to healthcare, with a large portion of products being used in industrial machines. These products include a complete graphics processing device in a compact multi-chip module including RAM and the GPU. ATI began offering embedded GPUs with the E2400 in 2008. Since that time AMD has released regular updates to their embedded GPU lineup in 2009, 2011, 2015, and 2016; reflecting improvements in their GPU technology.\n\nAMD's portfolio of CPUs and APUs \n\nAMD's portfolio of dedicated graphics processors \n\nIn 2011 AMD began selling Radeon branded DDR3 SDRAM to support the higher bandwidth needs of AMD's APUs. While the RAM is sold by AMD, it was manufactured by Patriot Memory and VisionTek. This was later followed by higher speeds of gaming oriented DDR3 memory in 2013. Radeon branded DDR4 SDRAM memory was released in 2015, despite no AMD CPUs or APUs supporting DDR4 at the time. AMD noted in 2017 that these products are \"mostly distributed in Eastern Europe\" and that it continues to be active in the business.\n\nAMD announced in 2014 it would sell Radeon branded Solid state drives manufactured by OCZ with capacities up to 480 GB and using the SATA interface. This was followed in 2016 by updated drives of up to 960 GB, with M.2/NVMe drives expected later.\n\n technologies found in AMD CPU/APU products include:\n\n technologies found in AMD GPU products include:\n\n\n\n\nPreviously, AMD produced its chips at company owned semiconductor foundries. AMD pursued a strategy of collaboration with other semiconductor manufacturers IBM and Motorola to co-develop production technologies. AMD's founder Jerry Sanders termed this the \"Virtual Gorilla\" strategy to compete with Intel's significantly greater investments in fabrication.\n\nIn 2008 AMD spun off its chip foundries into an independent company named GlobalFoundries. This break-up of the company was attributed to the increasing costs of each process node. The Emirate of Abu Dhabi purchased the newly created company through its subsidiary Advanced Technology Investment Company (ATIC), purchasing the final stake from AMD in 2009.\n\nWith the spin-off of its foundries, AMD became a fabless semiconductor manufacturer, designing products to be produced at for-hire foundries. Part of the GlobalFoundries spin-off included an agreement with AMD to produce some number of products at GlobalFoundries. Both prior to the spin-off and after AMD has pursued production with other foundries including TSMC and Samsung. It has been argued that this would reduce risk for AMD by decreasing dependence on any one foundry which has caused issues in the past.\n\n\n\n\n\n\n\n\n\n\n\nAMD has a long history of litigation with former partner and x86 creator Intel.\n\n\n\n\n\n\n\n"}
{"id": "2402", "url": "https://en.wikipedia.org/wiki?curid=2402", "title": "Albrecht Dürer", "text": "Albrecht Dürer\n\nAlbrecht Dürer (; ; 21 May 1471 – 6 April 1528) was a painter, printmaker, and theorist of the German Renaissance. Born in Nuremberg, Dürer established his reputation and influence across Europe when he was still in his twenties due to his high-quality woodcut prints.\nHe was in communication with the major Italian artists of his time, including Raphael, Giovanni Bellini and Leonardo da Vinci, and from 1512 he was patronized by emperor Maximilian I.\n\nDürer's vast body of work includes engravings, his preferred technique in his later prints, altarpieces, portraits and self-portraits, watercolours and books. The woodcuts, such as the \"Apocalypse\" series (1498), are more Gothic than the rest of his work. \nHis well-known engravings include the \"Knight, Death, and the Devil\" (1513), \"Saint Jerome in his Study\" (1514) and \"Melencolia I\" (1514), which has been the subject of extensive analysis and interpretation. His watercolours also mark him as one of the first European landscape artists, while his ambitious woodcuts revolutionized the potential of that medium.\n\nDürer's introduction of classical motifs into Northern art, through his knowledge of Italian artists and German humanists, has secured his reputation as one of the most important figures of the Northern Renaissance. This is reinforced by his theoretical treatises, which involve principles of mathematics, perspective, and ideal proportions.\n\nDürer was born on 21 May 1471, third child and second son of his parents, who had at least fourteen and possibly as many as eighteen children. His father, Albrecht Dürer the Elder, was a successful goldsmith, originally Ajtósi, who in 1455 had moved to Nuremberg from Ajtós, near Gyula in Hungary. One of Albrecht's brothers, Hans Dürer, was also a painter and trained under him. Another of Albrecht's brothers, Endres Dürer, took over their father's business and was a master goldsmith. The German name \"Dürer\" is a translation from the Hungarian, \"Ajtósi\". Initially, it was \"Türer,\" meaning doormaker, which is \"ajtós\" in Hungarian (from \"ajtó\", meaning door). A door is featured in the coat-of-arms the family acquired. Albrecht Dürer the Younger later changed \"Türer\", his father's diction of the family's surname, to \"Dürer\", to adapt to the local Nuremberg dialect. Albrecht Dürer the Elder married Barbara Holper, the daughter of his master when he himself became a master in 1467.\n\nDürer's godfather was Anton Koberger, who left goldsmithing to become a printer and publisher in the year of Dürer's birth and quickly became the most successful publisher in Germany, eventually owning twenty-four printing-presses and having many offices in Germany and abroad. Koberger's most famous publication was the \"Nuremberg Chronicle\", published in 1493 in German and Latin editions. It contained an unprecedented 1,809 woodcut illustrations (albeit with many repeated uses of the same block) by the Wolgemut workshop. Dürer may have worked on some of these, as the work on the project began while he was with Wolgemut.\n\nBecause Dürer left autobiographical writings and became very famous by his mid-twenties, his life is well documented by several sources. After a few years of school, Dürer started to learn the basics of goldsmithing and drawing from his father. Though his father wanted him to continue his training as a goldsmith, he showed such a precocious talent in drawing that he started as an apprentice to Michael Wolgemut at the age of fifteen in 1486. A self-portrait, a drawing in silverpoint, is dated 1484 (Albertina, Vienna) \"when I was a child,\" as his later inscription says. Wolgemut was the leading artist in Nuremberg at the time, with a large workshop producing a variety of works of art, in particular woodcuts for books. Nuremberg was then an important and prosperous city, a centre for publishing and many luxury trades. It had strong links with Italy, especially Venice, a relatively short distance across the Alps.\n\nAfter completing his term of apprenticeship, Dürer followed the common German custom of taking \"Wanderjahre\"—in effect gap years —in which the apprentice learned skills from artists in other areas; Dürer was to spend about four years away. He left in 1490, possibly to work under Martin Schongauer, the leading engraver of Northern Europe, but who died shortly before Dürer's arrival at Colmar in 1492. It is unclear where Dürer travelled in the intervening period, though it is likely that he went to Frankfurt and the Netherlands. In Colmar, Dürer was welcomed by Schongauer's brothers, the goldsmiths Caspar and Paul and the painter Ludwig. In 1493 Dürer went to Strasbourg, where he would have experienced the sculpture of Nikolaus Gerhaert. Dürer's first painted self-portrait (now in the Louvre) was painted at this time, probably to be sent back to his fiancée in Nuremberg.\n\nIn early 1492 Dürer travelled to Basel to stay with another brother of Martin Schongauer, the goldsmith Georg. Very soon after his return to Nuremberg, on 7 July 1494, at the age of 23, Dürer was married to Agnes Frey following an arrangement made during his absence. Agnes was the daughter of a prominent brass worker (and amateur harpist) in the city. However, no children resulted from the marriage.\n\nWithin three months of his marriage, Dürer left for Italy, alone, perhaps stimulated by an outbreak of plague in Nuremberg. He made watercolour sketches as he traveled over the Alps. Some have survived and others may be deduced from accurate landscapes of real places in his later work, for example his engraving \"Nemesis\".\n\nIn Italy, he went to Venice to study its more advanced artistic world. Through Wolgemut's tutelage, Dürer had learned how to make prints in drypoint and design woodcuts in the German style, based on the works of Martin Schongauer and the Housebook Master. He also would have had access to some Italian works in Germany, but the two visits he made to Italy had an enormous influence on him. He wrote that Giovanni Bellini was the oldest and still the best of the artists in Venice. His drawings and engravings show the influence of others, notably Antonio Pollaiuolo with his interest in the proportions of the body, Andrea Mantegna, Lorenzo di Credi and others. Dürer probably also visited Padua and Mantua on this trip.\n\nOn his return to Nuremberg in 1495, Dürer opened his own workshop (being married was a requirement for this). Over the next five years his style increasingly integrated Italian influences into underlying Northern forms. Dürer's father died in 1502, and his mother died in 1513. His best works in the first years of the workshop were his woodcut prints, mostly religious, but including secular scenes such as \"The Men's Bath House\" (ca. 1496). These were larger and more finely cut than the great majority of German woodcuts hitherto, and far more complex and balanced in composition.\n\nIt is now thought unlikely that Dürer cut any of the woodblocks himself; this task would have been performed by a specialist craftsman. However, his training in Wolgemut's studio, which made many carved and painted altarpieces and both designed and cut woodblocks for woodcut, evidently gave him great understanding of what the technique could be made to produce, and how to work with block cutters. Dürer either drew his design directly onto the woodblock itself, or glued a paper drawing to the block. Either way, his drawings were destroyed during the cutting of the block.\n\nHis famous series of sixteen great designs for the \"Apocalypse\" is dated 1498, as is his engraving of\" St. Michael Fighting the Dragon\". He made the first seven scenes of the \"Great Passion\" in the same year, and a little later, a series of eleven on the Holy Family and saints. The \"Seven Sorrows Polyptych\", commissioned by Frederick III of Saxony in 1496, was executed by Dürer and his assistants c. 1500. Around 1503–1505 he produced the first seventeen of a set illustrating the \"Life of the Virgin\", which he did not finish for some years. Neither these, nor the \"Great Passion,\" were published as sets until several years later, but prints were sold individually in considerable numbers.\n\nDuring the same period Dürer trained himself in the difficult art of using the burin to make engravings. It is possible he had begun learning this skill during his early training with his father, as it was also an essential skill of the goldsmith. In 1496 he executed the \"Prodigal Son\", which the Italian Renaissance art historian Giorgio Vasari singled out for praise some decades later, noting its Germanic quality. He was soon producing some spectacular and original images, notably \"Nemesis\" (1502), \"The Sea Monster\" (1498), and \"Saint Eustace\" (c. 1501), with a highly detailed landscape background and animals. His landscapes of this period, such as \"Pond in the Woods\" and \"Willow Mill\", are quite different from his earlier watercolours. There is a much greater emphasis on capturing atmosphere, rather than depicting topography. He made a number of Madonnas, single religious figures, and small scenes with comic peasant figures. Prints are highly portable and these works made Dürer famous throughout the main artistic centres of Europe within a very few years.\n\nThe Venetian artist Jacopo de' Barbari, whom Dürer had met in Venice, visited Nuremberg in 1500, and Dürer said that he learned much about the new developments in perspective, anatomy, and proportion from him. De' Barbari was unwilling to explain everything he knew, so Dürer began his own studies, which would become a lifelong preoccupation. A series of extant drawings show Dürer's experiments in human proportion, leading to the famous engraving of \"Adam and Eve\" (1504), which shows his subtlety while using the burin in the texturing of flesh surfaces. This is the only existing engraving signed with his full name.\n\nDürer created large numbers of preparatory drawings, especially for his paintings and engravings, and many survive, most famously the \"Betende Hände\" (\"Praying Hands\") from circa 1508, a study for an apostle in the Heller altarpiece. He also continued to make images in watercolour and bodycolour (usually combined), including a number of still lifes of meadow sections or animals, including his \"Young Hare\" (1502) and the \"Great Piece of Turf\" (1503).\n\nIn Italy, he returned to painting, at first producing a series of works executed in tempera on linen. These include portraits and altarpieces, notably, the Paumgartner altarpiece and the \"Adoration of the Magi\". In early 1506, he returned to Venice and stayed there until the spring of 1507. By this time Dürer's engravings had attained great popularity and were being copied. In Venice he was given a valuable commission from the emigrant German community for the church of San Bartolomeo. This was the altar-piece known as the \"Adoration of the Virgin\" or the \"Feast of Rose Garlands\". It includes portraits of members of Venice's German community, but shows a strong Italian influence. It was subsequently acquired by the Emperor Rudolf II and taken to Prague. Other paintings Dürer produced in Venice include \"The Virgin and Child with the Goldfinch\", \"Christ among the Doctors\" (supposedly produced in a mere five days), and a number of smaller works.\n\nDespite the regard in which he was held by the Venetians, Dürer returned to Nuremberg by mid-1507, remaining in Germany until 1520. His reputation had spread throughout Europe and he was on friendly terms and in communication with most of the major artists including Raphael, Giovanni Bellini and—mainly through Lorenzo di Credi—Leonardo da Vinci.\n\nBetween 1507 and 1511 Dürer worked on some of his most celebrated paintings: \"Adam and Eve\" (1507), \"The Martyrdom of the Ten Thousand\" (1508, for Frederick of Saxony), \"Virgin with the Iris\" (1508), the altarpiece \"Assumption of the Virgin\" (1509, for Jacob Heller of Frankfurt), and \"Adoration of the Trinity\" (1511, for Matthaeus Landauer). During this period he also completed two woodcut series, the Great Passion and the Life of the Virgin, both published in 1511 together with a second edition of the Apocalypse series. The post-Venetian woodcuts show Dürer's development of chiaroscuro modelling effects, creating a mid-tone throughout the print to which the highlights and shadows can be contrasted.\n\nOther works from this period include the thirty-seven woodcut subjects of the Little Passion, published first in 1511, and a set of fifteen small engravings on the same theme in 1512. Indeed, complaining that painting did not make enough money to justify the time spent when compared to his prints, he produced no paintings from 1513 to 1516. However, in 1513 and 1514 Dürer created his three most famous engravings: \"Knight, Death, and the Devil\" (1513, probably based on Erasmus's treatise \"Enchiridion militis Christiani\"), \"St. Jerome in his Study\", and the much-debated \"Melencolia I\" (both 1514). Further outstanding pen and ink drawings of Dürer´s period of art work of 1513 were drafts for his friend Willibald Prickheimer. These drafts were later used to design the famous chandeliers lusterweibchen.\n\nIn 1515, he created his \"woodcut of a Rhinoceros\" which had arrived in Lisbon from a written description and sketch by another artist, without ever seeing the animal himself. An image of the Indian rhinoceros, the image has such force that it remains one of his best-known and was still used in some German school science text-books as late as last century. In the years leading to 1520 he produced a wide range of works, including the woodblocks for the first western printed star charts in 1515 and portraits in tempera on linen in 1516.\n\nFrom 1512, Maximilian I became Dürer's major patron. His commissions included \"The Triumphal Arch\", a vast work printed from 192 separate blocks, the symbolism of which is partly informed by Pirckheimer's translation of Horapollo's \"Hieroglyphica\". The design program and explanations were devised by Johannes Stabius, the architectural design by the master builder and court-painter Jörg Kölderer and the woodcutting itself by Hieronymous Andreae, with Dürer as designer-in-chief. \"The Arch\" was followed by \"The Triumphal Procession\", the program of which was worked out in 1512 by and includes woodcuts by Albrecht Altdorfer and Hans Springinklee, as well as Dürer.\n\nDürer worked with pen on the marginal images for an edition of the Emperor's printed Prayer-Book; these were quite unknown until facsimiles were published in 1808 as part of the first book published in lithography. Dürer's work on the book was halted for an unknown reason, and the decoration was continued by artists including Lucas Cranach the Elder and Hans Baldung. Dürer also made several portraits of the Emperor, including one shortly before Maximilian's death in 1519.\n\nMaximilian's death came at a time when Dürer was concerned he was losing \"my sight and freedom of hand\" (perhaps caused by arthritis) and increasingly affected by the writings of Martin Luther. In July 1520 Dürer made his fourth and last major journey, to renew the Imperial pension Maximilian had given him and to secure the patronage of the new emperor, Charles V, who was to be crowned at Aachen. Dürer journeyed with his wife and her maid via the Rhine to Cologne and then to Antwerp, where he was well received and produced numerous drawings in silverpoint, chalk and charcoal. In addition to going to the coronation, he made excursions to Cologne (where he admired the painting of Stefan Lochner), Nijmegen, 's-Hertogenbosch, Bruges (where he saw Michelangelo's Madonna of Bruges), Ghent (where he admired van Eyck's altarpiece), and Zeeland.\n\nDürer took a large stock of prints with him and wrote in his diary to whom he gave, exchanged or sold them, and for how much. This provides rare information of the monetary value placed on prints at this time. Unlike paintings, their sale was very rarely documented. While providing valuable documentary evidence, Dürer's Netherlandish diary also reveals that the trip was not a profitable one. For example, Dürer offered his last portrait of Maximilian to his daughter, Margaret of Austria, but eventually traded the picture for some white cloth after Margaret disliked the portrait and declined to accept it. During this trip he also met Bernard van Orley, Jan Provoost, Gerard Horenbout, Jean Mone, Joachim Patinir and Tommaso Vincidor, though he did not, it seems, meet Quentin Matsys.\n\nAt the request of Christian II of Denmark, Dürer went to Brussels to paint the King's portrait. There he saw \"the things which have been sent to the king from the golden land\"—the Aztec treasure that Hernán Cortés had sent home to Holy Roman Emperor Charles V following the fall of Mexico. Dürer wrote that this treasure \"was much more beautiful to me than miracles. These things are so precious that they have been valued at 100,000 florins\". Dürer also appears to have been collecting for his own cabinet of curiosities, and he sent back to Nuremberg various animal horns, a piece of coral, some large fish fins, and a wooden weapon from the East Indies.\n\nHaving secured his pension, Dürer finally returned home in July 1521, having caught an undetermined illness—perhaps malaria —which afflicted him for the rest of his life, and greatly reduced his rate of work.\n\nOn his return to Nuremberg, Dürer worked on a number of grand projects with religious themes, including a crucifixion scene and a Sacra Conversazione, though neither was completed. This may have been due in part to his declining health, but perhaps also because of the time he gave to the preparation of his theoretical works on geometry and perspective, the proportions of men and horses, and fortification.\n\nHowever, one consequence of this shift in emphasis was that during the last years of his life, Dürer produced comparatively little as an artist. In painting, there was only a portrait of , a , , and two panels showing St. John with St. Peter in and St. Paul with St. Mark in the . This last great work, the Four Apostles, was given by Dürer to the City of Nuremberg—although he was given 100 guilders in return.\n\nAs for engravings, Dürer's work was restricted to portraits and illustrations for his treatise. The portraits include Cardinal-Elector Albert of Mainz; Frederick the Wise, elector of Saxony; the humanist scholar Willibald Pirckheimer; Philipp Melanchthon, and Erasmus of Rotterdam. For those of the Cardinal, Melanchthon, and Dürer's final major work, a drawn portrait of the Nuremberg patrician Ulrich Starck, Dürer depicted the sitters in profile, perhaps reflecting a more mathematical approach.\n\nDespite complaining of his lack of a formal classical education, Dürer was greatly interested in intellectual matters and learned much from his boyhood friend Willibald Pirckheimer, whom he no doubt consulted on the content of many of his images. He also derived great satisfaction from his friendships and correspondence with Erasmus and other scholars. Dürer succeeded in producing two books during his lifetime. \"The Four Books on Measurement\" were published at Nuremberg in 1525 and was the first book for adults on mathematics in German, as well as being cited later by Galileo and Kepler. The other, a work on city fortifications, was published in 1527. \"The Four Books on Human Proportion\" were published posthumously, shortly after his death in 1528.\n\nDürer died in Nuremberg at the age of 56, leaving an estate valued at 6,874 florins—a considerable sum. His large house (purchased in 1509 from the heirs of the astronomer Bernhard Walther), where his workshop was located and where his widow lived until her death in 1539, remains a prominent Nuremberg landmark. It is now a museum. He is buried in the \"Johannisfriedhof\" cemetery.\n\nDürer's writings suggest that he may have been sympathetic to Martin Luther's ideas, though it is unclear if he ever left the Catholic Church. Dürer wrote of his desire to draw Luther in his diary in 1520: \"And God help me that I may go to Dr. Martin Luther; thus I intend to make a portrait of him with great care and engrave him on a copper plate to create a lasting memorial of the Christian man who helped me overcome so many difficulties.\" In a letter to Nicholas Kratzer in 1524, Dürer wrote \"because of our Christian faith we have to stand in scorn and danger, for we are reviled and called heretics.\" Most tellingly, Pirckheimer wrote in a letter to Johann Tscherte in 1530: \"I confess that in the beginning I believed in Luther, like our Albert of blessed memory...but as anyone can see, the situation has become worse.\" Dürer may even have contributed to the Nuremberg City Council's mandating Lutheran sermons and services in March 1525. Notably, Dürer had contacts with various reformers, such as Zwingli, Andreas Karlstadt, Melanchthon, Erasmus and Cornelius Grapheus from whom Dürer received Luther's \"Babylonian Captivity\" in 1520.\n\nDürer's later works have also been claimed to show Protestant sympathies. For example, his woodcut of \"The Last Supper\" of 1523 has often been understood to have an evangelical theme, focussing as it does on Christ espousing the Gospel, as well the inclusion of the Eucharistic cup, an expression of Protestant utraquism, although this interpretation has been questioned. The delaying of the engraving of St Philip, completed in 1523 but not distributed until 1526, may have been due to Dürer's uneasiness with images of Saints; even if Dürer was not an iconoclast, in his last years he evaluated and questioned the role of art in religion.\n\nDürer exerted a huge influence on the artists of succeeding generations, especially in printmaking, the medium through which his contemporaries mostly experienced his art, as his paintings were predominantly in private collections located in only a few cities. His success in spreading his reputation across Europe through prints was undoubtedly an inspiration for major artists such as Raphael, Titian, and Parmigianino, all of whom collaborated with printmakers in order to promote and distribute their work.\n\nHis work in engraving seems to have had an intimidating effect upon his German successors, the \"Little Masters\" who attempted few large engravings but continued Dürer's themes in small, rather cramped compositions. Lucas van Leyden was the only Northern European engraver to successfully continue to produce large engravings in the first third of the 16th century. The generation of Italian engravers who trained in the shadow of Dürer all either directly copied parts of his landscape backgrounds (Giulio Campagnola, Giovanni Battista Palumba, Benedetto Montagna and Cristofano Robetta), or whole prints (Marcantonio Raimondi and Agostino Veneziano). However, Dürer's influence became less dominant after 1515, when Marcantonio perfected his new engraving style, which in turn travelled over the Alps to dominate Northern engraving also.\n\nIn painting, Dürer had relatively little influence in Italy, where probably only his altarpiece in Venice was seen, and his German successors were less effective in blending German and Italian styles. His intense and self-dramatizing self-portraits have continued to have a strong influence up to the present, especially on painters in the 19th and 20th century who desired a more dramatic portrait style. Dürer has never fallen from critical favour, and there have been significant revivals of interest in his works in Germany in the \"Dürer Renaissance\" of about 1570 to 1630, in the early nineteenth century, and in German nationalism from 1870 to 1945.\n\nDürer's study of human proportions and the use of transformations to a coordinate grid to demonstrate facial variation inspired similar work by D'Arcy Thompson in his book \"On Growth and Form\".\n\nThe Lutheran Church remembers Dürer as a great Christian annually on April 6, along with Lucas Cranach the Elder and Hans Burgkmair. The liturgical calendar of the Episcopal Church (United States) remembers him, Cranach and Matthias Grünewald on August 5.\n\nIn all his theoretical works, in order to communicate his theories in the German language rather than in Latin, Dürer used graphic expressions based on a vernacular, craftsmen's language. For example, \"Schneckenlinie\" (\"snail-line\") was his term for a spiral form. Thus, Dürer contributed to the expansion in German prose which Martin Luther had begun with his translation of the Bible.\n\nDürer's work on geometry is called the \"Four Books on Measurement\" (\"Underweysung der Messung mit dem Zirckel und Richtscheyt\" or \"Instructions for Measuring with Compass and Ruler\"). The first book focuses on linear geometry. Dürer's geometric constructions include helices, conchoids and epicycloids. He also draws on Apollonius, and Johannes Werner's 'Libellus super viginti duobus elementis conicis' of 1522.\n\nThe second book moves onto two dimensional geometry, i.e. the construction of regular polygons. Here Dürer favours the methods of Ptolemy over Euclid. The third book applies these principles of geometry to architecture, engineering and typography. \n\nIn architecture Dürer cites Vitruvius but elaborates his own classical designs and columns. In typography, Dürer depicts the geometric construction of the Latin alphabet, relying on Italian precedent. However, his construction of the Gothic alphabet is based upon an entirely different modular system. The fourth book completes the progression of the first and second by moving to three-dimensional forms and the construction of polyhedra. Here Dürer discusses the five Platonic solids, as well as seven Archimedean semi-regular solids, as well as several of his own invention.\n\nIn all these, Dürer shows the objects as nets. Finally, Dürer discusses the Delian Problem and moves on to the 'construzione legittima', a method of depicting a cube in two dimensions through linear perspective. It was in Bologna that Dürer was taught (possibly by Luca Pacioli or Bramante) the principles of linear perspective, and evidently became familiar with the 'costruzione legittima' in a written description of these principles found only, at this time, in the unpublished treatise of Piero della Francesca. He was also familiar with the 'abbreviated construction' as described by Alberti and the geometrical construction of shadows, a technique of Leonardo da Vinci. Although Dürer made no innovations in these areas, he is notable as the first Northern European to treat matters of visual representation in a scientific way, and with understanding of Euclidean principles. In addition to these geometrical constructions, Dürer discusses in this last book of \"Underweysung der Messung\" an assortment of mechanisms for drawing in perspective from models and provides woodcut illustrations of these methods that are often reproduced in discussions of perspective.\n\nDürer's work on human proportions is called the \"Four Books on Human Proportion\" (\"Vier Bücher von Menschlicher Proportion\") of 1528. The first book was mainly composed by 1512/13 and completed by 1523, showing five differently constructed types of both male and female figures, all parts of the body expressed in fractions of the total height. Dürer based these constructions on both Vitruvius and empirical observations of, \"two to three hundred living persons,\" in his own words. The second book includes eight further types, broken down not into fractions but an Albertian system, which Dürer probably learned from Francesco di Giorgio's 'De harmonica mundi totius' of 1525. In the third book, Dürer gives principles by which the proportions of the figures can be modified, including the mathematical simulation of convex and concave mirrors; here Dürer also deals with human physiognomy. The fourth book is devoted to the theory of movement.\n\nAppended to the last book, however, is a self-contained essay on aesthetics, which Dürer worked on between 1512 and 1528, and it is here that we learn of his theories concerning 'ideal beauty'. Dürer rejected Alberti's concept of an objective beauty, proposing a relativist notion of beauty based on variety. Nonetheless, Dürer still believed that truth was hidden within nature, and that there were rules which ordered beauty, even though he found it difficult to define the criteria for such a code. In 1512/13 his three criteria were function ('Nutz'), naïve approval ('Wohlgefallen') and the happy medium ('Mittelmass'). However, unlike Alberti and Leonardo, Dürer was most troubled by understanding not just the abstract notions of beauty but also as to how an artist can create beautiful images. Between 1512 and the final draft in 1528, Dürer's belief developed from an understanding of human creativity as spontaneous or inspired to a concept of 'selective inward synthesis'. In other words, that an artist builds on a wealth of visual experiences in order to imagine beautiful things. Dürer's belief in the abilities of a single artist over inspiration prompted him to assert that \"one man may sketch something with his pen on half a sheet of paper in one day, or may cut it into a tiny piece of wood with his little iron, and it turns out to be better and more artistic than another's work at which its author labours with the utmost diligence for a whole year.\"\n\nFor lists of Albrecht Dürer's works, see:\n\n\n\n"}
{"id": "2403", "url": "https://en.wikipedia.org/wiki?curid=2403", "title": "Australian rules football", "text": "Australian rules football\n\nAustralian rules football, officially known as Australian football, or simply known as football or footy, is a contact sport played between two teams of eighteen players on an oval-shaped field, often a modified cricket ground.\n\nThe main way to score points is by kicking the oval-shaped ball between the two tall goal posts. The team with the higher score by the end of the match wins unless a draw is declared.\n\nDuring general play, players may position themselves anywhere on the field and use any part of their bodies to move the ball. The primary methods are kicking, handballing and running with the ball. There are rules on how the ball can be handled: for example, players running with the ball must intermittently bounce or touch it on the ground. Throwing the ball is not allowed and players must not get caught holding the ball. A distinctive feature of the game is the mark, where players anywhere on the field who catch a ball from a kick (with specific conditions) are awarded possession. Possession of the ball is in dispute at all times except when a free kick or mark is paid. Players can tackle using their hands or use their whole body to obstruct opponents. Dangerous physical contact (such as pushing an opponent in the back), interference when marking and deliberately slowing the play are discouraged with free kicks, distance penalties or suspension for a certain number of matches, depending on the seriousness of the infringement. The game features frequent physical contests, spectacular marking, fast movement of both players and the ball and high scoring.\n\nThe sport's origins can be traced to football matches played in Melbourne, Victoria in 1858, inspired by English public school football games. Seeking to develop a game more suited to adults and Australian conditions, the Melbourne Football Club published the first laws of Australian football in May 1859, making it the oldest of the world's major football codes.\n\nAustralian football has the highest spectator attendance and television viewership of all sports in Australia, while the Australian Football League (AFL), the sport's only fully professional competition, is the nation's wealthiest sporting body. Its annual Grand Final is the highest attended club championship event in the world. The sport is also played at amateur level in many countries and in several variations. The game's rules are governed by the AFL Commission with the advice of the AFL's Laws of the Game Committee.\n\nAustralian rules football is known by several nicknames, including Aussie rules, football and footy. In some regions, it is marketed as AFL after the Australian Football League.\n\nThere is evidence of football being played sporadically in the Australian colonies in the first half of the 19th century. Compared to cricket and horse racing, football was viewed as a minor \"amusement\" at the time, and while little is known about these early one-off games, it is clear they share no causal link with Australian football. In 1858, in a move that would help to shape Australian football in its formative years, public schools in Melbourne, Victoria began organising football games inspired by precedents at English public schools. The earliest such match, held in St Kilda on 15 June, was between Melbourne Grammar and St Kilda Grammar.\n\nOn 10 July 1858, the Melbourne-based \"Bell's Life in Victoria and Sporting Chronicle\" published a letter by Tom Wills, captain of the Victoria cricket team, calling for the formation of a \"foot-ball club\" with a \"code of laws\" to keep cricketers fit during winter. Born in Australia, Wills played a nascent form of rugby football whilst a pupil at Rugby School in England, and returned to his homeland a star athlete and cricketer. His letter is regarded by many historians as giving impetus for the development of a new code of football today known as Australian football. Two weeks later, Wills' friend, cricketer Jerry Bryant, posted an advertisement for a scratch match at the Richmond Paddock adjoining the Melbourne Cricket Ground (MCG). This was the first of several \"kickabouts\" held that year involving members of the Melbourne Cricket Club, including Wills, Bryant, W. J. Hammersley and J. B. Thompson. Trees were used as goalposts and play typically lasted an entire afternoon. Without an agreed upon code of laws, some players were guided by rules they had learned in the British Isles, \"others by no rules at all\".\n\nAnother significant milestone in 1858 was a match played under experimental rules between Melbourne Grammar and Scotch College, held at the Richmond Paddock. This 40-a-side contest, umpired by Wills and Scotch College teacher John Macadam, began on 7 August and continued over two subsequent Saturdays, ending in a draw with each side kicking one goal. It is commemorated with a statue outside the MCG, and the two schools have competed annually ever since in the Cordner-Eggleston Cup, the world's oldest continuous football competition.\n\nSince the early 20th century, it has been suggested that Australian football was derived from the Irish sport of Gaelic football, which was not codified until 1885. There is no archival evidence in favour of a Gaelic influence, and the style of play shared between the two modern codes was evident in Australia long before the Irish game evolved in a similar direction. Another theory, first proposed in 1983, posits that Wills, having grown up amongst Aborigines in Victoria, may have seen or played the Aboriginal game of Marn Grook, and incorporated some of its features into early Australian football. This evidence for this is only circumstantial, and according to biographer Greg de Moore's research, Wills was \"almost solely influenced by his experience at Rugby School\".\n\nA loosely organised Melbourne side, captained by Wills, played against other football enthusiasts in the winter and spring of 1858. The following year, on 14 May, the Melbourne Football Club officially came into being, making it one of the world's oldest football clubs. Three days later, Wills, Hammersley, Thompson and teacher Thomas H. Smith met near the MCG at the Parade Hotel, owned by Bryant, and drafted ten rules: \"The Rules of the Melbourne Football Club\". These are the laws from which Australian football evolved. The document was signed by the rule-framers and three other club office bearers: Alex Bruce, T. Butterworth and J. Sewell. The club's stated aim was to create a simple code that was suited to the hard playing surfaces around Melbourne, and to eliminate the roughest aspects of English school games—such as \"hacking\" (shin-kicking) in Rugby School football—to lessen the chance of injuries to working men. In another significant departure from English public school football, the Melbourne rules omitted any offside law. \"The new code was as much a reaction against the school games as influenced by them\", writes Mark Pennings.\n\nThe rules were distributed throughout the colony; Thompson in particular did much to promote the new code in his capacity as a journalist. Australian football's date of codification predates that of any other major football code, including soccer (codified in 1863) and rugby union (codified in 1871).\n\nFollowing Melbourne's lead, Geelong and Melbourne University also formed football clubs in 1859. While many early Victorian teams participated in one-off matches, most had not yet formed clubs for regular competition. A South Yarra side devised its own rules. To ensure the supremacy of the Melbourne rules, the first-club level competition in Australia, the Caledonian Society's Challenge Cup (1861–64), stipulated that only the Melbourne rules were to be used. This law was reinforced by the Athletic Sports Committee (ASC), which ran a variation of the Challenge Cup in 1865–66. With input from other clubs, the rules underwent several minor revisions, establishing a uniform code known as \"Victorian rules\". In 1866, the \"first distinctively Victorian rule\", the running bounce, was formalised at a meeting of club delegates chaired by H. C. A. Harrison, an influential pioneer who took up football in 1859 at the invitation of Wills, his cousin.\n\nThe game around this time was defensive and low-scoring, played low to the ground in congested rugby-style scrimmages. The typical match was a 20-per-side affair, played with a ball that was roughly spherical, and lasted until a team scored two goals. The shape of the playing field was not standardised; matches often took place in rough, tree-spotted public parks, most notably the Richmond Paddock (Yarra Park), known colloquially as the Melbourne Football Ground. Wills argued that the turf of cricket fields would benefit from being trampled upon by footballers in winter, and, as early as 1859, football was allowed on the MCG. However, cricket authorities frequently prohibited football on their grounds until the 1870s, when they saw an opportunity to capitalise on the sport's growing popularity. Football gradually adapted to an oval-shaped field, and most grounds in Victoria expanded to accommodate the dual purpose—a situation that continues to this day.\n\nAs \"Victorian rules\" gained roots in other Australasian colonies—beginning with South Australia (1860), Tasmania (1864), Queensland (1866), and New Zealand (1871)—it came to be known as \"Australian rules\" or \"Australasian rules\". In 1877, the sport's first governing bodies, the South Australian Football Association (SAFA) and the Victorian Football Association (VFA), formed on 30 April and 17 May respectively. The game was introduced to New South Wales in 1877 and Western Australia in 1881, where it took hold during the colony's gold rushes.\n\nBy the 1880s, Australian football had become the prevailing football code in Australia's southern and western colonies, and experienced a period of dominance in Queensland, where, like in areas of New South Wales, it struggled to thrive, largely due to the spread of rugby football, regional rivalries and the lack of strong local governing bodies. In the case of Sydney, denial of access to grounds, the influence of university headmasters from Britain who favoured rugby, and the loss of players to other codes inhibited the game's growth.\n\nIn 1879, the first intercolonial match took place in Melbourne between Victoria and South Australia, and clubs began touring the colonies. By this stage, the sport had become the first code of football to develop mass spectator appeal, with important matches drawing world record attendances for sports viewing. New rules such as holding the ball led to a \"golden era\" of fast, long-kicking and high-marking football in the 1880s, a time which also saw the rise of professionalism, particularly in Western Australia and Victoria, and players such as George Coulthard achieve superstardom. Australian football was now widely referred to as \"the people's game\".\n\nIn 1896, delegates from six of the wealthiest VFA clubs—Carlton, Essendon, Fitzroy, Geelong, Melbourne and South Melbourne—met to discuss the formation of a breakaway professional competition. Later joined by Collingwood and St Kilda, the clubs formed the Victorian Football League (VFL), which held its inaugural season in 1897. The VFL's popularity grew rapidly as it made several innovations, such as instituting a finals system, reducing teams from 20 to 18 players, and introducing the behind as a score. By 1925, with the addition of Hawthorn, Footscray and North Melbourne, it had become the preeminent league in the country and would take a leading role in many aspects of the sport.\n\nBoth World War I and World War II had a devastating effect on Australian football and on Australian sport in general. While scratch matches were played by Australian \"diggers\" in remote locations around the world, the game lost many of its great players to wartime service. Some clubs and competitions never fully recovered. Between 1914 and 1915, a proposed hybrid code of Australian football and rugby league, the predominant code of football in New South Wales and Queensland, was trialed without success. World War I saw the game in New Zealand go into recess for three quarters of a century. In Queensland, the state league went into recess for the duration of the war. VFL club University left the league and went into recess due to severe casualties. The WAFL lost two clubs and the SANFL was suspended for one year in 1916 due to heavy club losses. The ANZAC Day clash is one example of how the war continues to be remembered in the football community.\n\nThe role of the Australian National Football Council (ANFC) was primarily to govern the game at a national level and to facilitate interstate representative and club competition. The ANFC ran the Championship of Australia, the first national club competition, which commenced in 1888 and saw clubs from different states compete on an even playing field. Although clubs from other states were at times invited, the final was almost always between the premiers from the two strongest state competitions of the time—South Australia and Victoria—and the majority of matches were played in Adelaide at the request of the SAFA/SAFL. The last match was played in 1976, with North Adelaide being the last non-Victorian winner in 1972. Between 1976 and 1987, the ANFC, and later the Australian Football Championships (AFC) ran a night series, which invited clubs and representative sides from around the country to participate in a knock-out tournament parallel to the premiership seasons, which Victorian sides still dominated.\n\nWith the lack of international competition, state representative matches were regarded with great importance. The Australian Football Council co-ordinated regular interstate carnivals, including the Australasian Football Jubilee, held in Melbourne in 1908 to celebrate the game's bicentenary. Due in part to the VFL poaching talent from other states, Victoria dominated interstate matches for three quarters of a century. State of Origin rules, introduced in 1977, stipulated that rather than representing the state of their adopted club, players would return to play for the state they were first recruited in. This instantly broke Victoria's stranglehold over state titles and Western Australia and South Australia began to win more of their games against Victoria. Both New South Wales and Tasmania scored surprise victories at home against Victoria in 1990.\n\nThe term \"Barassi Line\", named after VFL star Ron Barassi, was coined by scholar Ian Turner in 1978 to describe the \"fictitious geographical barrier\" separating large parts of New South Wales and Queensland which predominately followed rugby from the rest of the country, where Australian football reigned. It became a reference point for the expansion of Australian football and for establishing a national league.\n\nThe way the game was played had changed dramatically due to innovative coaching tactics, with the phasing out of many of the game's kicking styles and the increasing use of handball; while presentation was influenced by television.\n\nIn 1982, in a move that heralded big changes within the sport, one of the original VFL clubs, South Melbourne, relocated to Sydney and became known as the Sydney Swans. In the late 1980s, due to the poor financial standing of many of the Victorian clubs, the VFL pursued a more national competition. Two more non-Victorian clubs, West Coast and Brisbane, joined the league in 1987. In their early years, the Sydney and Brisbane clubs struggled both on and off-field because the substantial TV revenues they generated by playing on a Sunday went to the VFL. To protect these revenues the VFL granted significant draft concessions and financial aid to keep the expansion clubs competitive. Each club was required to pay a licence fee which allowed the Victorian-based clubs to survive.\n\nThe VFL changed its name to the Australian Football League (AFL) for the 1990 season, and over the next decade, three non-Victorian clubs gained entry: Adelaide (1991), Fremantle (1995) and the SANFL's Port Adelaide (1997), the only pre-existing club outside Victoria to join the league. In 2011 and 2012 respectively, two new non-Victorian clubs were added to the competition: Gold Coast and Greater Western Sydney. The AFL, currently with 18 member clubs, is the sport's elite competition and most powerful body. Following the emergence of the AFL, state leagues were quickly relegated to a second-tier status. The VFA merged with the former VFL reserves competition in 1998, adopting the VFL name. State of Origin also declined in importance, especially after an increasing number of player withdrawals. The AFL turned its focus to the annual International Rules Series against Ireland in 1998 before abolishing State of Origin the following year. State and territorial leagues still contest interstate matches, as do AFL Women players.\n\nAlthough a Tasmanian AFL bid is ongoing, the AFL's focus has been on expanding into markets outside Australian football's traditional heartlands. The AFL regularly schedules pre-season exhibition matches in all Australian states and territories as part of the Regional Challenge. The AFL signalled further attempts at expansion in the 2010s by hosting home-and-away matches in New Zealand, followed by China.\n\nAustralian rules football playing fields have no fixed dimensions but at senior level are typically between 135 and 185 metres long and 110 and 155 metres wide wing-to-wing. The field, like the ball, is oval-shaped, and in Australia, cricket grounds are often used. No more than 18 players of each team are permitted to be on the field at any time.\n\nUp to four interchange (reserve) players may be swapped for those on the field at any time during the game. In Australian rules terminology, these players wait for substitution \"on the bench\"—an area with a row of seats on the sideline. Players must interchange through a designated interchange \"gate\" with strict penalties for too many players from one team on the field. In addition, some leagues like the AFL have each team designate one player as a substitute who can be used to make a single permanent exchange of players during a game.\n\nThere is no offside rule nor are there set positions in the rules; unlike many other forms of football, players from both teams may disperse across the whole field before the start of play. However, a typical on-field structure consists of six forwards, six defenders or \"backmen\" and six midfielders, usually two wingmen, one centre and three followers, including a ruckman, ruck-rover and rover. Only four players from each team are allowed within the centre square () at every centre bounce, which occurs at the commencement of each quarter, and to restart the game after a goal is scored. There are also other rules pertaining to allowed player positions during set plays (that is, after a mark or free kick) and during kick-ins following the scoring of a behind.\n\nA game consists of four quarters and a timekeeper officiates their duration. At the professional level, each quarter consist of 20 minutes of play, with the clock being stopped for instances such as scores, the ball going out of bounds or at the umpire's discretion, e.g. for serious injury. Lower grades of competition might employ shorter quarters of play. The umpire signals \"time-off\" to stop the clock for various reasons, such as the player in possession being tackled into stagnant play. Time resumes when the umpire signals \"time-on\" or when the ball is brought into play. Stoppages cause quarters to extend approximately 5–10 minutes beyond the 20 minutes of play. 6 minutes of rest is allowed before the second and fourth quarters, and 20 minutes of rest is allowed at \"half-time\".\n\nThe official game clock is available only to the timekeeper(s), and is not displayed to the players, umpires or spectators. The only public knowledge of game time is when the timekeeper sounds a siren at the start and end of each quarter. Coaching staff may monitor the game time themselves and convey information to players via on-field trainers or substitute players. Broadcasters usually display an approximation of the official game time for television audiences, although some will now show the exact time remaining in a quarter. \n\nGames are officiated by umpires. Before the game, the winner of a coin toss determines which directions the teams will play to begin. Australian football begins after the first siren, when the umpire bounces the ball on the ground (or throws it into the air if the condition of the ground is poor), and the two ruckmen (typically the tallest players from each team) battle for the ball in the air on its way back down. This is known as the \"ball-up\". Certain disputes during play may also be settled with a \"ball-up\" from the point of contention. If the ball is kicked or hit from a ball-up or boundary throw-in over the boundary line or into a behind post without the ball bouncing, a free kick is paid for out of bounds on the full. A free kick is also paid if the ball is deemed by the umpire to have been deliberately carried or directed out of bounds. If the ball travels out of bounds in any other circumstances (for example, contested play results in the ball being knocked out of bounds) a boundary umpire will stand with his back to the infield and return the ball into play with a \"throw-in\", a high backwards toss back into the field of play.\n\nThe ball can be propelled in any direction by way of a foot, clenched fist (called a handball or \"handpass\") or open-hand tap but it cannot be thrown under any circumstances. Once a player takes possession of the ball he must dispose of it by either kicking or handballing it. Any other method of disposal is illegal and will result in a free kick to the opposing team. This is usually called \"incorrect disposal\", \"dropping the ball\" or \"throwing\". If the ball is not in the possession of one player it can be moved on with any part of the body.\n\nA player may run with the ball, but it must be bounced or touched on the ground at least once every 15 metres. Opposition players may bump or tackle the player to obtain the ball and, when tackled, the player must dispose of the ball cleanly or risk being penalised for holding the ball. The ball carrier may only be tackled between the shoulders and knees. If the opposition player forcefully contacts a player in the back while performing a tackle, the opposition player will be penalised for a push in the back. If the opposition tackles the player with possession below the knees (a \"low tackle\" or a \"trip\") or above the shoulders (a \"high tackle\"), the team with possession of the football gets a free kick.\n\nIf a player takes possession of the ball that has travelled more than from another player's kick, by way of a catch, it is claimed as a \"mark\" (meaning that the game stops while he prepares to kick from the point at which he marked). Alternatively, he may choose to \"play on\" forfeiting the set shot in the hope of pressing an advantage for his team (rather than allowing the opposition to reposition while he prepares for the free kick). Once a player has chosen to play on, normal play resumes and the player who took the mark is again able to be tackled.\n\nThere are different styles of kicking depending on how the ball is held in the hand. The most common style of kicking seen in today's game, principally because of its superior accuracy, is the drop punt, where the ball is dropped from the hands down, almost to the ground, to be kicked so that the ball rotates in a reverse end over end motion as it travels through the air. Other commonly used kicks are the torpedo punt (also known as the spiral, barrel, or screw punt), where the ball is held flatter at an angle across the body, which makes the ball spin around its long axis in the air, resulting in extra distance (similar to the traditional motion of an American football punt), and the checkside punt or \"banana\", kicked across the ball with the outside of the foot used to curve the ball (towards the right if kicked off the right foot) towards targets that are on an angle. There is also the \"snap\", which is almost the same as a checkside punt except that it is kicked off the inside of the foot and curves in the opposite direction. It is also possible to kick the ball so that it bounces along the ground. This is known as a \"grubber\". Grubbers can bounce in a straight line, or curve to the left or right.\n\nApart from free kicks, marks or when the ball is in the possession of an umpire for a \"ball up\" or \"throw in\", the ball is always in dispute and any player from either side can take possession of the ball.\n\nA \"goal\", worth 6 points, is scored when the football is propelled through the goal posts at any height (including above the height of the posts) by way of a kick from the attacking team. It may fly through \"on the full\" (without touching the ground) or bounce through, but must not have been touched, on the way, by any player from either team. A goal cannot be scored from the foot of an opposition (defending) player.\n\nA \"behind\", worth 1 point, is scored when the ball passes between a goal post and a behind post at any height, or if the ball hits a goal post, or if any player sends the ball between the goal posts by touching it with any part of the body other than a foot. A behind is also awarded to the attacking team if the ball touches any part of an opposition player, including his foot, before passing between the goal posts. When an opposition player deliberately scores a behind for the attacking team (generally as a last resort to ensure that a goal is not scored) this is termed a rushed behind. As of the 2009 AFL season, a free kick is awarded against any player who deliberately rushes a behind.\n\nThe goal umpire signals a goal with two hands pointed forward at elbow height, or a behind with one hand. The goal umpire then waves flags above their heads to confirm the goal or behind to the goal umpire at the opposite end of the ground.\n\nThe team that has scored the most points at the end of play wins the game. If the scores are level on points at the end of play, then the game is a draw; extra time applies only during finals matches in some competitions.\n\nAs an example of a score report, consider a match between and with the former as the home team. Essendon's score of 11 goals and 14 behinds equates to 80 points. Melbourne's score of 10 goals and 7 behinds equates to a 67-point tally. Essendon wins the match by a margin of 13 points. Such a result would be written as:\n\nAnd spoken as:\n\nAdditionally, it can be said that:\n\nThe home team is typically listed first and the visiting side is listed second. The scoreline is written with respect to the home side.\n\nFor example, won in successive weeks, once as the home side and once as the visiting side. These would be written out thus:\n\nThe \"football season\" proper is from March to August (early autumn to late winter in Australia) with finals being held in September and October. In the tropics, the game is sometimes played in the wet season (October to March). Pre-season competitions in southern Australia usually begin in late February.\n\nThe AFL is recognised by the Australian Sports Commission as being the National Sporting Organisation for Australian Football. There are also seven state/territory-based organisations in Australia, most of which are now either owned by or affiliated to the AFL. Most of these hold annual semi-professional club competitions while the others oversee more than one league. Local semi-professional or amateur organisations and competitions are often affiliated to their state organisations.\n\nThe AFL is the \"de facto\" world governing body for Australian football. There are also a number of affiliated organisations governing amateur clubs and competitions around the world.\n\nFor almost all Australian football club competitions the aim is to win the \"Premiership\". The premiership is always decided by a \"finals series\". The teams that occupy the highest positions on the \"ladder\" after the \"home-and-away\" season play off in a \"semi-knockout\" finals series, culminating in a single Grand Final match to determine the premiers. Typically between four and eight teams contest the finals series. The team which finishes first on the ladder after the home-and-away season is referred to as a \"minor premier\", but this usually holds little stand-alone significance, other than receiving a better draw in the finals.\n\nMany suburban and amateur leagues have a sufficient number of teams to be played across several tiered divisions, with promotion of the lower division premiers and relegation of the upper division's last placed team at the end of each year. At present, none of the top level national or state level leagues in Australia are large enough to warrant this structure.\n\nThe level of interest shown by women in Australian football is considered unique among the world's football codes. It was the case in the 19th-century, as it is in modern times, that women made up approximately half of crowds at Australian football matches—a far greater proportion than soccer and the two rugby codes. This has been attributed in part to the egalitarian character of Australian football's origins in public parks where women could mingle freely and support the game in various ways.\n\nIn 2016, over 380,000 women played in organised games across Australia. The AFL Women's National Championships is women's football's state of origin competition. On the back of the inaugural AFL Women's Draft in 2013 and a series of exhibition matches at the MCG, the AFL stated that, by 2020, it would like to establish AFL Women's, a semi-professional, nationally televised women's league. A surge in viewing interest and participation in women's football prompted the AFL to push the founding date of the competition to 2017.\n\nMany related games have emerged from Australian football, mainly with variations of contact to encourage greater participation. These include Auskick (played by children aged between 5 and 12), kick-to-kick (and its variants end-to-end footy and marks up), rec footy, 9-a-side footy, masters Australian football, handball and longest-kick competitions. Players outside of Australia sometimes engage in related games adapted to available fields, like metro footy (played on gridiron fields) and Samoa rules (played on rugby fields).\n\nThe similarities between Australian football and the Irish sport of Gaelic football have allowed for the creation of a hybrid code known as international rules football. The first international rules matches were contested in Ireland during the 1967 Australian Football World Tour. Since then, various sets of compromise rules have been trialed, and in 1984 the International Rules Series commenced with national representative sides selected by Australia's state leagues (later by the AFL) and the Gaelic Athletic Association (GAA). The competition became an annual event in 1998, but was postponed indefinitely in 2007 when the GAA pulled out due to Australia's severe and aggressive style of play. It resumed in Australia in 2008 under new rules to protect the player with the ball.\n\nAustralian football is played at an amateur level in various countries throughout the world, currently there are no professional competitions outside of Australia. Twenty countries participated in the Euro Cup and 23 countries have participated in the International Cup with both competitions prohibiting Australian players. Over 20 countries have either affiliation or working agreements with the AFL. There have been many VFL/AFL players who were born outside Australia, an increasing number of which have been recruited through initiatives such as the Irish experiment and more recently, international scholarship programs.\n\nIn the late 19th and early 20th centuries, the game spread with the Australian diaspora to areas such as New Zealand and South Africa; however this growth went into rapid decline following World War I. After World War II, the sport experienced a small amount of growth in the Pacific region, particularly in Nauru (where Australian football is the national sport) as well as Papua New Guinea and New Zealand.\n\nMost of the current amateur clubs and leagues in existence have developed since the 1980s, when leagues began to be established in North America, Europe and Asia. The sport developed a cult following in the United States when matches were broadcast on ESPN in the late 1980s. As the size of the Australian diaspora has increased, so has the number of clubs outside Australia. This expansion has been further aided by multiculturalism and assisted by exhibition matches as well as exposure generated through players who have converted to and from other football codes. In Papua New Guinea, New Zealand, South Africa, Canada, and the United States there are many thousands of players.\n\nA fan of the sport since attending school in Geelong, Prince Charles is the Patron of AFL Europe. In 2013, participation across AFL Europe's 21 member nations was more than 5,000 players, the majority of which are European nationals rather than Australian expats. The sport also has a growing presence in India.\n\nThe AFL became the de facto governing body when it pushed for the closure of the International Australian Football Council in 2002. The Australian Football International Cup, held triennially in Melbourne since 2002, is the highest level of international competition.\n\nAustralian football is a sport rich in tradition and Australian cultural references, especially surrounding the rituals of gameday for players, officials and supporters.\n\nAustralian football has been an inspiration for writers and poets including Manning Clarke, Bruce Dawe and Philip Hodgins. Paintings by Arthur Streeton (\"The National Game\", 1889) and Sidney Nolan (\"Footballer\", 1946) helped to establish Australian football as a serious subject for artists. Many Aboriginal artists have explored the game, often fusing it with the mythology of their region. Statues of Australian football identities can be found throughout the country. In cartooning, WEG's VFL/AFL premiership posters—inaugurated in 1954—have achieved iconic status among Australian football fans. Dance sequences based on Australian football feature heavily in Robert Helpmann's 1964 ballet \"The Display\", his first and most famous work for the Australian Ballet. The game has also inspired well-known plays such as \"And the Big Men Fly\" (1963) by Alan Hopgood and David Williamson's \"The Club\" (1977), which was adapted into a 1980 film, directed by Bruce Beresford. Mike Brady's 1979 hit \"Up There Cazaly\" is considered an Australian football anthem, and references to the sport can be found in works by popular musicians, from singer-songwriter Paul Kelly to the alternative rock band TISM. Many Australian football video games have been released, most notably the AFL series.\nAustralian football has attracted more overall interest among Australians (as measured by the Sweeney Sports report) than any other football code, and, when compared with all sports throughout the nation, has consistently ranked first in the winter reports, and most recently third behind cricket and swimming in summer. Over 875,000 fans were paying members of AFL clubs in 2016, which is equal to one in every 28 Australians. The 2016 AFL Grand Final was the year's most-watched television broadcast in Australia, with an in-home audience of up to 6.5 million watching the match.\n\nIn 2006, 615,549 registered participants played Australian football in Australia. Participation increased 7.84% between 2005 and 2006. The Australian Sports Commission statistics show a 64% increase in the total number of participants over the 10-year period between 2001 and 2010. In 2008 there were 35,000 people in 32 countries playing in structured competitions of Australian football outside of Australia.\n\nFor the centenary of the VFL/AFL in 1996, the Australian Football Hall of Fame was established. In that year 136 identities were inducted, including 100 players, 10 coaches, 10 umpires, 10 administrators and six media representatives.\n\nThe elite \"Legend\" status was bestowed on 12 members of the Hall of Fame in 1996: Ron Barassi, Haydn Bunton Sr., Roy Cazaly, John Coleman, Jack Dyer, Polly Farmer, Leigh Matthews, John Nicholls, Bob Pratt, Dick Reynolds, Bob Skilton and Ted Whitten. The \"Legend\" status is the highest honour which can be bestowed on an Australian footballer.\n\nThe following fourteen members have been promoted to the status of \"Legend\" since 1996: Ian Stewart (1997), Gordon Coventry (1998), Peter Hudson (1999), Kevin Bartlett (2000), Barrie Robran (2001), Bill Hutchison (2003), Jock McHale (2005), Darrel Baldock (2006), Norm Smith (2007), Alex Jesaulenko (2008), Kevin Murray (2010), Barry Cable (2012), Tony Lockett (2015) and Malcolm Blight (2017).\n\n\nBooks\n\nJournals\n"}
{"id": "2405", "url": "https://en.wikipedia.org/wiki?curid=2405", "title": "Aon (company)", "text": "Aon (company)\n\nAon plc is a global professional services firm that provides risk, retirement and health consulting. Aon has approximately 500 offices worldwide, serving 120 countries with 50,000 employees.\n\nIn 2011, Aon was ranked as the largest insurance broker in the world based on revenue. Aon was the principal partner and global shirt sponsor of the Premier League team Manchester United F.C. from 2010 until 2014.\n\nAon was created in 1982 when the Ryan Insurance Group merged with the Combined Insurance Company of America. In 1987, that company was renamed Aon, a Gaelic word meaning [one].\n\nIn January 2012, Aon announced that its headquarters would be moved to London.\n\nW. Clement Stone's mother bought a small Detroit insurance agency, and in 1918 brought her son into the business. Mr. Stone sold low-cost, low-benefit accident insurance, underwriting and issuing policies on-site. The next year he founded his own agency, the Combined Registry Co.\n\nAs the Great Depression began, Stone reduced his workforce and improved training. Forced by his son's respiratory illness to winter in the South, Stone moved to Arkansas and Texas. In 1939 he bought American Casualty Insurance Co. of Dallas, Texas. It was consolidated with other purchases as the Combined Insurance Co. of America in 1947. The company continued through the 1950s and 1960s, continuing to sell health and accident policies. In the 1970s, Combined expanded overseas despite being hit hard by the recession.\n\nIn 1982, after 10 years of stagnation under Clement Stone Jr., the elder Stone, then 79, resumed control until the completion of a merger with Ryan Insurance Co. allowed him to transfer control to Patrick Ryan. Ryan, the son of a Ford dealer in Wisconsin, had started his company as an auto credit insurer in 1964. In 1976, the company bought the insurance brokerage units of the Esmark conglomerate. Ryan focused on insurance brokering and added more upscale insurance products. He also trimmed staff and took other cost-cutting measures, and in 1987 he changed Combined's name to Aon. In 1992, he bought Dutch insurance broker Hudig-Langeveldt. In 1995, the company sold its remaining direct life insurance holdings to General Electric to focus on consulting. The following year, it began offering hostile takeover insurance policies to small and mid-sized companies.\n\nAon built a global presence through purchases. In 1997, it bought The Minet Group, as well as insurance brokerage Alexander & Alexander Services, Inc. in a deal that made Aon (temporarily) the largest insurance broker worldwide. The firm made no US buys in 1998, but doubled its employee base with purchases including Spain's largest retail insurance broker, Gil y Carvajal, and the formation of Aon Korea, the first non-Korean firm of its kind to be licensed there.\n\nResponding to industry demands, Aon announced its new fee disclosure policy in 1999, and the company reorganised to focus on buying personal line insurance firms and to integrate its acquisitions. That year it bought Nikols Sedgwick Group, an Italian insurance firm, and formed RiskAttack (with Zurich US), a risk analysis and financial management concern aimed at technology companies. The cost of integrating its numerous purchases, however, hammered profits in 1999.\n\nDespite its troubles, in 2000 Aon bought Reliance Group's accident and health insurance business, as well as Actuarial Sciences Associates, a compensation and employee benefits consulting company. Later in that year, however, the company decided to cut 6% of its workforce as part of a restructuring effort. In 2003, the company saw revenues increase primarily because of rate hikes in the insurance industry. Also that year, Endurance Specialty, a Bermuda-based underwriting operation that Aon helped to establish in November 2001 along with other investors, went public. The next year Aon sold most of its holdings in Endurance.\n\nIn late 2007, Aon announced the divestiture of its underwriting business. With this move, the firm sold off its two major underwriting subsidiaries: Combined Insurance Company of America (acquired by ACE Limited for $2.4 billion) and Sterling Life Insurance Company (purchased by Munich Re Group for $352 million). The low margin and capital-intensive nature of the underwriting industry was the primary reason for the firm's decision to divest. Upon completion of the move, Aon turned its attention to expanding its broking and consulting capabilities.\n\nThis growth strategy manifested in November 2008 when Aon announced it had acquired reinsurance intermediary and capital advisor Benfield Group Limited for $1.75 billion. The acquisition amplified the firm's broking capabilities, positioning Aon one of the largest players in the reinsurance brokerage industry.\n\nIn 2010, Aon made its most significant acquisition to date with the purchase of Lincolnshire, Illinois-based Hewitt Associates for $4.9 billion. Aside from drastically boosting Aon's human resources consulting capacity and entering the firm into the business process outsourcing industry, the move added 23,000 colleagues and more than $3 billion in revenue.\n\nIn 10 February 2017, Aon announced that it is selling its employee benefits outsourcing business to Private equity firm Blackstone Group LP (BX.N) for US$4.8 billion (£3.8 billion) \n\nAon's New York offices were on the 92nd and 98th–105th floors of the South Tower of the World Trade Center at the time of the 11 September 2001 terrorist attack. When the North Tower was struck at 8:46 a.m., many executives began evacuating their employees from the upper floors of the South Tower. The evacuation of Aon's offices, ordered by Eric Eisenberg, was carried out quickly as 924 of the estimated 1,100 Aon employees present at the time managed to evacuate the building before United Airlines Flight 175 struck it twenty stories below them at 9:03 a.m.\n\nHowever, many were influenced to stay by security guards and security announcements, or did not exit the building in time. As a result, 176 employees of Aon were killed in the attacks, including Eisenberg and Kevin Cosgrove, a vice-president of the company, who made a call to 911 when the tower collapsed at 9:59 a.m.\n\nIn 2004–2005, Aon, along with other brokers including Marsh & McLennan and Willis, fell under regulatory investigation under New York Attorney General Eliot Spitzer and other state attorneys general. At issue was the practice of insurance companies' payments to brokers (known as contingent commissions). The payments were thought to bring a conflict of interest, swaying broker decisions on behalf of carriers, rather than customers. In the spring of 2005, without acknowledging any wrongdoing, Aon agreed to a $190 million settlement, payable over 30 months.\n\nIn January 2009, Aon was fined £5.25 million in the UK by the Financial Services Authority, who stated that the fine related to the company's inadequate bribery and corruption controls, claiming that between 14 January 2005 and 30 September 2007 Aon had failed to properly assess the risks involved in its dealings with overseas firms and individuals. The Authority did not find that any money had actually made its way to illegal organisations. Aon qualified for a 30% discount on the fine as a result of its co-operation with the investigation. Aon said its conduct was not deliberate, adding it had since \"significantly strengthened and enhanced its controls around the usage of third parties\".\n\nIn December 2011, Aon Corporation paid a $16.26 million penalty to the US Securities and Exchange Commission (SEC) and the US Department of Justice (DOJ) for violations of the US Foreign Corrupt Practices Act (FCPA).\nAccording to the SEC, Aon's subsidiaries made improper payments of over $3.6 million to government officials and third-party facilitators in Costa Rica, Egypt, Vietnam, Indonesia, the United Arab Emirates, Myanmar and Bangladesh, between 1983 and 2007, to obtain and retain insurance contracts.\n\nOn 10 February 2017, Aon announced that it is selling its employee benefits outsourcing business to Private equity firm Blackstone Group LP (BX.N) for US$4.8 billion (£3.8 billion) \n\nOn 31 October 2016, Aon's Aon Risk Solutions completed acquisition of Stroz Friedberg LLC, a specialised risk management firm focusing on cybersecurity.\n\nOn 16 June 2014, Aon announced that it agreed to buy National Flood Services, Inc., a leading processor of flood insurance, from Stoneriver Group, L.P.\n\nOn 22 October 2012, Aon announced that it agreed to buy OmniPoint, Inc, a Workday consulting firm. Financial terms were not disclosed.\n\nOn 19 July 2011, Aon announced that it bought Westfield Financial Corp., the owner of insurance-industry consulting firm Ward Financial Group, from Ohio Farmers Insurance Co. Financial terms were not disclosed.\n\nOn 7 April 2011, Aon announced that it had acquired Johannesburg, South Africa-based Glenrand MIB. Financial terms were not disclosed.\n\nOn 12 July 2010, Aon announced that it had agreed to buy Lincolnshire, Illinois-based Hewitt Associates for $4.9 billion in cash and stock.\n\nOn 5 Mar 2010, Hewitt Associates announced that it acquired Senior Educators Ltd. The acquisition offers companies a new way to address retiree medical insurance commitments.\n\nOn 22 August 2008, Aon announced that it had acquired London-based Benfield Group. The acquiring price was US$1.75 billion or £935 million, with US$170 million of debt.\n\nOn February 10, 2017, Aon PLC agreed to sell its human resources outsourcing platform for $4.3 billion to Blackstone Group L.P., creating a new company.\n\nOn 3 June 2009, it was reported that Aon had signed a four-year shirt sponsorship deal with English football giant Manchester United. On 1 June 2010, Aon replaced American insurance company AIG as the principal sponsor of the club. The Aon logo was prominently displayed on the front of the club's shirts until the 2014/2015 season when Chevrolet replaced them. The deal was said to be worth £80 million over four years, replacing United's deal with AIG as the most lucrative shirt deal in history at the time.\n\nIn April 2013, Aon signed a new eight-year deal with Manchester United to rename their training ground as the Aon Training Complex and sponsor the club's training kits, reportedly worth £180 million to the club.\n\n"}
{"id": "2406", "url": "https://en.wikipedia.org/wiki?curid=2406", "title": "Alban Berg", "text": "Alban Berg\n\nAlban Maria Johannes Berg (; ; February 9, 1885 – December 24, 1935) was an Austrian composer of the Second Viennese School. His compositional style combined Romantic lyricism with twelve-tone technique.\n\nBerg was born in Vienna, the third of four children of Johanna and Conrad Berg. His family lived comfortably until the death of his father in 1900.\n\nHe was more interested in literature than music as a child and did not begin to compose until he was fifteen, when he started to teach himself music. In late February or early March 1902 he fathered a child with Marie Scheuchl, a servant girl in the Berg family household. His daughter, Albine, was born on December 4, 1902.\n\nBerg had little formal music education before he became a student of Arnold Schoenberg in October 1904. With Schoenberg he studied counterpoint, music theory, and harmony. By 1906, he was studying music full-time; by 1907, he began composition lessons. His student compositions included five drafts for piano sonatas. He also wrote songs, including his \"Seven Early Songs\" (\"Sieben Frühe Lieder\"), three of which were Berg's first publicly performed work in a concert that featured the music of Schoenberg's pupils in Vienna that year. The early sonata sketches eventually culminated in Berg's Piano Sonata, Op. 1 (1907–1908); it is one of the most formidable \"first\" works ever written. Berg studied with Schoenberg for six years until 1911. Berg admired him as a composer and mentor, and they remained close lifelong friends.\n\nAmong Schoenberg's teaching was the idea that the unity of a musical composition depends upon all its aspects being derived from a single basic idea; this idea was later known as \"developing variation\". Berg passed this on to his students, one of whom, Theodor W. Adorno, stated: \"The main principle he conveyed was that of variation: everything was supposed to develop out of something else and yet be intrinsically different\". The Piano Sonata is an example—the whole composition is derived from the work's opening quartal gesture and its opening phrase.\n\nBerg was a part of Vienna's cultural elite during the heady \"fin de siècle\" period. His circle included the musicians Alexander von Zemlinsky and Franz Schreker, the painter Gustav Klimt, the writer and satirist Karl Kraus, the architect Adolf Loos, and the poet Peter Altenberg. In 1906, Berg met the singer Helene Nahowski, daughter of a wealthy family (said by some to be in fact the illegitimate daughter of Emperor Franz Joseph I of Austria from his liaison with Anna Nahowski); despite the outward hostility of her family, the two were married on May 3, 1911.\n\nIn 1913, two of Berg's \"Five Songs on Picture Postcard Texts by Peter Altenberg\" (1912) were premièred in Vienna, conducted by Schoenberg in the infamous \"Skandalkonzert\". Settings of aphoristic poetic utterances, the songs are accompanied by a very large orchestra. The performance caused a riot, and had to be halted. This was a crippling blow to Berg's self-confidence: he effectively withdrew the work, which is surely one of his most innovative and assured first orchestral compositions in the literature, and it was not performed in full until 1952. The full score remained unpublished until 1966.\n\nFrom 1915 to 1918, Berg served in the Austro-Hungarian Army and during a period of leave in 1917 he accelerated work on his first opera, \"Wozzeck\". After the end of World War I, he settled again in Vienna, where he taught private pupils. He also helped Schoenberg run his Society for Private Musical Performances, which sought to create the ideal environment for the exploration and appreciation of unfamiliar new music by means of open rehearsals, repeat performances, and the exclusion of professional critics.\n\nBerg had a particular interest in the number 23, using it to structure several works. Various suggestions have been made as to the reason for this interest: that he took it from the Biorhythms theory of Wilhelm Fliess, in which a 23-day cycle is considered significant, or because he first suffered an asthma attack on 23rd of the month.\n\nThree excerpts from \"Wozzeck\" were performed in 1924, and this brought Berg his first public success. The opera, which Berg completed in 1922, was first performed on December 14, 1925, when Erich Kleiber conducted the first performance in Berlin. Today \"Wozzeck\" is seen as one of the century's most important works. Berg made a start on his second opera, the three-act \"Lulu\", in 1928 but interrupted the work in 1929 for the concert aria \"Der Wein\" which he completed that summer. \"Der Wein\" presaged \"Lulu\" in a number of ways, including vocal style, orchestration, design and text.\n\nOther well-known Berg compositions include the \"Lyric Suite\" (1926), which was later shown to employ elaborate cyphers to document a secret love affair; the post-Mahlerian \"Three Pieces for Orchestra\" (completed in 1915 but not performed until after \"Wozzeck\"); and the Chamber Concerto (\"Kammerkonzert\", 1923–25) for violin, piano, and 13 wind instruments: this latter is written so conscientiously that Pierre Boulez has called it \"Berg's strictest composition\" and it, too, is permeated by cyphers and posthumously disclosed hidden programs.\n\nLife for the musical world was becoming increasingly difficult in the 1930s both in Vienna and Germany due to the rising tide of antisemitism and the Nazi cultural ideology that denounced modernity. Even to have an association with someone who was Jewish could lead to denunciation, and Berg's \"crime\" was to have studied with the Jewish composer Arnold Schoenberg. Berg found that opportunities for his work to be performed in Germany were becoming rare, and eventually his music was proscribed and placed on the list of degenerate music. In 1932 Berg and his wife acquired an isolated lodge, the \"Waldhaus\" on the southern shore of the \"Wörthersee\", near Schiefling am See in Carinthia, where he was able to work in seclusion, mainly on Lulu and the Violin Concerto. At the end of 1934 Berg became involved in the political intrigues around finding a replacement for Clemens Krauss as director of the Vienna State Opera. As more of the performances of his work in Germany were cancelled by the Nazis, who had come to power in early 1933, he needed to ensure the new director would be an advocate for modernist music. Originally the premiere of Lulu had been planned for the Berlin State Opera, where Erich Kleiber continued to champion his music and had conducted the premiere of \"Wozzeck\" in 1925, but now this was looking increasingly uncertain, and Lulu was rejected by the Berlin authorities in the spring of 1934. Kleiber's production of the Lulu symphonic suite on 30 November 1934 in Berlin was also the occasion of his resignation in protest at the extent of conflation of culture with politics. Even in Vienna, the opportunities for the Vienna School of musicians was dwindling.\n\nBerg had interrupted the orchestration of \"Lulu\" because of an unexpected (and financially much-needed) commission from the Russian-American violinist Louis Krasner for a Violin Concerto (1935). This profoundly elegiac work, composed at unaccustomed speed and posthumously premièred, has become Berg's best-known and beloved composition. Like much of his mature work, it employs an idiosyncratic adaptation of Schoenberg's \"dodecaphonic\" or twelve-tone technique, that enables the composer to produce passages openly evoking tonality, including quotations from historical tonal music, such as a Bach chorale and a Carinthian folk song. The Violin Concerto was dedicated \"to the memory of an Angel\", Manon Gropius, the deceased daughter of architect Walter Gropius and Alma Mahler.\n\nBerg died aged 50 in Vienna, on Christmas Eve 1935, from blood poisoning apparently caused by an insect-sting-induced carbuncle on his back that occurred in November.\n\nBerg completed the orchestration of only the first two acts of \"Lulu\" before he died. The first two acts were successfully premièred in Zürich in 1937, but for personal reasons Helene Berg subsequently imposed a ban on any attempt to \"complete\" the final act, which Berg had in fact completed in particell (short score) format. An orchestration was therefore commissioned in secret from Friedrich Cerha and premièred in Paris (under Pierre Boulez) only in 1979, soon after Helene Berg's own death. The complete opera has rapidly entered the repertoire as one of the landmarks of contemporary music and, like \"Wozzeck\", remains a consistent audience draw.\n\nBerg is remembered as one of the most important composers of the 20th century and to date is the most widely performed opera composer among the Second Viennese School. He is considered to have brought more \"human values\" to the twelve-tone system, his works seen as more \"emotional\" than Schoenberg's. Critically, he is seen as having preserved the Viennese tradition in his music. His popularity has been more easily secured than many other Modernists since he plausibly combined both Romantic and Expressionist idioms. Though Berg's Romanticism at one time seemed a drawback for some more modernist composers, the Berg scholar Douglas Jarman writes in the New Grove: \"As the 20th century closed, the 'backward-looking' Berg suddenly came as [George] Perle remarked, to look like its most forward-looking composer.\"\n\nThe asteroid 4528 Berg is named after him.\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "2408", "url": "https://en.wikipedia.org/wiki?curid=2408", "title": "Analytical chemistry", "text": "Analytical chemistry\n\nAnalytical chemistry studies and uses instruments and methods used to separate, identify, and quantify matter. In practice separation, identification or quantification may constitute the entire analysis or be combined with another method. Separation isolates analytes. Qualitative analysis identifies analytes, while quantitative analysis determines the numerical amount or concentration.\n\nAnalytical chemistry consists of classical, wet chemical methods and modern, instrumental methods. Classical qualitative methods use separations such as precipitation, extraction, and distillation. Identification may be based on differences in color, odor, melting point, boiling point, radioactivity or reactivity. Classical quantitative analysis uses mass or volume changes to quantify amount. Instrumental methods may be used to separate samples using chromatography, electrophoresis or field flow fractionation. Then qualitative and quantitative analysis can be performed, often with the same instrument and may use light interaction, heat interaction, electric fields or magnetic fields . Often the same instrument can separate, identify and quantify an analyte.\n\nAnalytical chemistry is also focused on improvements in experimental design, chemometrics, and the creation of new measurement tools. Analytical chemistry has broad applications to forensics, medicine, science and engineering.\n\nAnalytical chemistry has been important since the early days of chemistry, providing methods for determining which elements and chemicals are present in the object in question. During this period significant contributions to analytical chemistry include the development of systematic elemental analysis by Justus von Liebig and systematized organic analysis based on the specific reactions of functional groups.\n\nThe first instrumental analysis was flame emissive spectrometry developed by Robert Bunsen and Gustav Kirchhoff who discovered rubidium (Rb) and caesium (Cs) in 1860.\n\nMost of the major developments in analytical chemistry take place after 1900. During this period instrumental analysis becomes progressively dominant in the field. In particular many of the basic spectroscopic and spectrometric techniques were discovered in the early 20th century and refined in the late 20th century.\n\nThe separation sciences follow a similar time line of development and also become increasingly transformed into high performance instruments. In the 1970s many of these techniques began to be used together as hybrid techniques to achieve a complete characterization of samples.\n\nStarting in approximately the 1970s into the present day analytical chemistry has progressively become more inclusive of biological questions (bioanalytical chemistry), whereas it had previously been largely focused on inorganic or small organic molecules. Lasers have been increasingly used in chemistry as probes and even to initiate and influence a wide variety of reactions. The late 20th century also saw an expansion of the application of analytical chemistry from somewhat academic chemical questions to forensic, environmental, industrial and medical questions, such as in histology.\n\nModern analytical chemistry is dominated by instrumental analysis. Many analytical chemists focus on a single type of instrument. Academics tend to either focus on new applications and discoveries or on new methods of analysis. The discovery of a chemical present in blood that increases the risk of cancer would be a discovery that an analytical chemist might be involved in. An effort to develop a new method might involve the use of a tunable laser to increase the specificity and sensitivity of a spectrometric method. Many methods, once developed, are kept purposely static so that data can be compared over long periods of time. This is particularly true in industrial quality assurance (QA), forensic and environmental applications. Analytical chemistry plays an increasingly important role in the pharmaceutical industry where, aside from QA, it is used in discovery of new drug candidates and in clinical applications where understanding the interactions between the drug and the patient are critical.\n\nAlthough modern analytical chemistry is dominated by sophisticated instrumentation, the roots of analytical chemistry and some of the principles used in modern instruments are from traditional techniques many of which are still used today. These techniques also tend to form the backbone of most undergraduate analytical chemistry educational labs.\n\nA qualitative analysis determines the presence or absence of a particular compound, but not the mass or concentration. By definition, qualitative analyses do not measure quantity.\n\nThere are numerous qualitative chemical tests, for example, the acid test for gold and the Kastle-Meyer test for the presence of blood.\n\nInorganic qualitative analysis generally refers to a systematic scheme to confirm the presence of certain, usually aqueous, ions or elements by performing a series of reactions that eliminate ranges of possibilities and then confirms suspected ions with a confirming test. Sometimes small carbon containing ions are included in such schemes. With modern instrumentation these tests are rarely used but can be useful for educational purposes and in field work or other situations where access to state-of-the-art instruments are not available or expedient.\n\nQuantitative analysis is the measurement of the quantities of particular chemical constituents present in a substance.\n\nGravimetric analysis involves determining the amount of material present by weighing the sample before and/or after some transformation. A common example used in undergraduate education is the determination of the amount of water in a hydrate by heating the sample to remove the water such that the difference in weight is due to the loss of water.\n\nTitration involves the addition of a reactant to a solution being analyzed until some equivalence point is reached. Often the amount of material in the solution being analyzed may be determined. Most familiar to those who have taken chemistry during secondary education is the acid-base titration involving a color changing indicator. There are many other types of titrations, for example potentiometric titrations.\nThese titrations may use different types of indicators to reach some equivalence point.\n\nSpectroscopy measures the interaction of the molecules with electromagnetic radiation. Spectroscopy consists of many different applications such as atomic absorption spectroscopy, atomic emission spectroscopy, ultraviolet-visible spectroscopy, x-ray fluorescence spectroscopy, infrared spectroscopy, Raman spectroscopy, dual polarization interferometry, nuclear magnetic resonance spectroscopy, photoemission spectroscopy, Mössbauer spectroscopy and so on.\n\nMass spectrometry measures mass-to-charge ratio of molecules using electric and magnetic fields. There are several ionization methods: electron impact, chemical ionization, electrospray, fast atom bombardment, matrix assisted laser desorption ionization, and others. Also, mass spectrometry is categorized by approaches of mass analyzers: magnetic-sector, quadrupole mass analyzer, quadrupole ion trap, time-of-flight, Fourier transform ion cyclotron resonance, and so on.\n\nElectroanalytical methods measure the potential (volts) and/or current (amps) in an electrochemical cell containing the analyte. These methods can be categorized according to which aspects of the cell are controlled and which are measured. The four main categories are potentiometry (the difference in electrode potentials is measured), coulometry (the transferred charge is measured over time), amperometry (the cell's current is measured over time), and voltammetry (the cell's current is measured while actively altering the cell's potential).\n\nCalorimetry and thermogravimetric analysis measure the interaction of a material and heat.\n\nSeparation processes are used to decrease the complexity of material mixtures. Chromatography, electrophoresis and Field Flow Fractionation are representative of this field.\n\nCombinations of the above techniques produce a \"hybrid\" or \"hyphenated\" technique. Several examples are in popular use today and new hybrid techniques are under development. For example, gas chromatography-mass spectrometry, gas chromatography-infrared spectroscopy, liquid chromatography-mass spectrometry, liquid chromatography-NMR spectroscopy. liquid chromagraphy-infrared spectroscopy and capillary electrophoresis-mass spectrometry.\n\nHyphenated separation techniques refers to a combination of two (or more) techniques to detect and separate chemicals from solutions. Most often the other technique is some form of chromatography. Hyphenated techniques are widely used in chemistry and biochemistry. A slash is sometimes used instead of hyphen, especially if the name of one of the methods contains a hyphen itself.\n\nThe visualization of single molecules, single cells, biological tissues and nanomaterials is an important and attractive approach in analytical science. Also, hybridization with other traditional analytical tools is revolutionizing analytical science. Microscopy can be categorized into three different fields: optical microscopy, electron microscopy, and scanning probe microscopy. Recently, this field is rapidly progressing because of the rapid development of the computer and camera industries.\n\nDevices that integrate (multiple) laboratory functions on a single chip of only millimeters to a few square centimeters in size and that are capable of handling extremely small fluid volumes down to less than picoliters.\n\nError can be defined as numerical difference between observed value and true value.\n\nIn error the true value and observed value in chemical analysis can be related with each other by the equation\nwhere \nError of a measurement is an inverse measure of accurate measurement i.e. smaller the error greater the accuracy of the measurement. Errors are expressed relatively as:\n\nA general method for analysis of concentration involves the creation of a calibration curve. This allows for determination of the amount of a chemical in a material by comparing the results of unknown sample to those of a series of known standards. If the concentration of element or compound in a sample is too high for the detection range of the technique, it can simply be diluted in a pure solvent. If the amount in the sample is below an instrument's range of measurement, the method of addition can be used. In this method a known quantity of the element or compound under study is added, and the difference between the concentration added, and the concentration observed is the amount actually in the sample.\n\nSometimes an internal standard is added at a known concentration directly to an analytical sample to aid in quantitation. The amount of analyte present is then determined relative to the internal standard as a calibrant. An ideal internal standard is isotopically-enriched analyte which gives rise to the method of isotope dilution.\n\nThe method of standard addition is used in instrumental analysis to determine concentration of a substance (analyte) in an unknown sample by comparison to a set of samples of known concentration, similar to using a calibration curve. Standard addition can be applied to most analytical techniques and is used instead of a calibration curve to solve the matrix effect problem.\n\nOne of the most important components of analytical chemistry is maximizing the desired signal while minimizing the associated noise. The analytical figure of merit is known as the signal-to-noise ratio (S/N or SNR).\n\nNoise can arise from environmental factors as well as from fundamental physical processes.\n\nThermal noise results from the motion of charge carriers (usually electrons) in an electrical circuit generated by their thermal motion. Thermal noise is white noise meaning that the power spectral density is constant throughout the frequency spectrum.\n\nThe root mean square value of the thermal noise in a resistor is given by\n\nwhere \"k\" is Boltzmann's constant, \"T\" is the temperature, \"R\" is the resistance, and formula_5 is the bandwidth of the frequency formula_6.\n\nShot noise is a type of electronic noise that occurs when the finite number of particles (such as electrons in an electronic circuit or photons in an optical device) is small enough to give rise to statistical fluctuations in a signal.\n\nShot noise is a Poisson process and the charge carriers that make up the current follow a Poisson distribution. The root mean square current fluctuation is given by\n\nwhere \"e\" is the elementary charge and \"I\" is the average current. Shot noise is white noise.\n\nFlicker noise is electronic noise with a 1/\"ƒ\" frequency spectrum; as \"f\" increases, the noise decreases. Flicker noise arises from a variety of sources, such as impurities in a conductive channel, generation and recombination noise in a transistor due to base current, and so on. This noise can be avoided by modulation of the signal at a higher frequency, for example through the use of a lock-in amplifier.\n\nEnvironmental noise arises from the surroundings of the analytical instrument. Sources of electromagnetic noise are power lines, radio and television stations, wireless devices, Compact fluorescent lamps and electric motors. Many of these noise sources are narrow bandwidth and therefore can be avoided. Temperature and vibration isolation may be required for some instruments.\n\nNoise reduction can be accomplished either in computer hardware or software. Examples of hardware noise reduction are the use of shielded cable, analog filtering, and signal modulation. Examples of software noise reduction are digital filtering, ensemble average, boxcar average, and correlation methods.\n\nAnalytical chemistry has applications including in forensic science, bioanalysis, clinical analysis, environmental analysis, and materials analysis. Analytical chemistry research is largely driven by performance (sensitivity, detection limit, selectivity, robustness, dynamic range, linear range, accuracy, precision, and speed), and cost (purchase, operation, training, time, and space). Among the main branches of contemporary analytical atomic spectrometry, the most widespread and universal are optical and mass spectrometry. In the direct elemental analysis of solid samples, the new leaders are laser-induced breakdown and laser ablation mass spectrometry, and the related techniques with transfer of the laser ablation products into inductively coupled plasma. Advances in design of diode lasers and optical parametric oscillators promote developments in fluorescence and ionization spectrometry and also in absorption techniques where uses of optical cavities for increased effective absorption pathlength are expected to expand. The use of plasma- and laser-based methods is increasing. An interest towards absolute (standardless) analysis has revived, particularly in emission spectrometry.\n\nGreat effort is being put in shrinking the analysis techniques to chip size. Although there are few examples of such systems competitive with traditional analysis techniques, potential advantages include size/portability, speed, and cost. (micro total analysis system (µTAS) or lab-on-a-chip). Microscale chemistry reduces the amounts of chemicals used.\n\nMany developments improve the analysis of biological systems. Examples of rapidly expanding fields in this area are genomics, DNA sequencing and related research in genetic fingerprinting and DNA microarray; proteomics, the analysis of protein concentrations and modifications, especially in response to various stressors, at various developmental stages, or in various parts of the body, metabolomics, which deals with metabolites; transcriptomics, including mRNA and associated fields; lipidomics - lipids and its associated fields; peptidomics - peptides and its associated fields; and metalomics, dealing with metal concentrations and especially with their binding to proteins and other molecules.\n\nAnalytical chemistry has played critical roles in the understanding of basic science to a variety of practical applications, such as biomedical applications, environmental monitoring, quality control of industrial manufacturing, forensic science and so on.\n\nThe recent developments of computer automation and information technologies have extended analytical chemistry into a number of new biological fields. For example, automated DNA sequencing machines were the basis to complete human genome projects leading to the birth of genomics. Protein identification and peptide sequencing by mass spectrometry opened a new field of proteomics.\n\nAnalytical chemistry has been an indispensable area in the development of nanotechnology. Surface characterization instruments, electron microscopes and scanning probe microscopes enables scientists to visualize atomic structures with chemical characterizations.\n\n\n"}
{"id": "2411", "url": "https://en.wikipedia.org/wiki?curid=2411", "title": "A cappella", "text": "A cappella\n\nA cappella (Italian for \"in the manner of the chapel\") music is specifically group or solo singing without instrumental accompaniment, or a piece intended to be performed in this way. It contrasts with cantata, which is usually accompanied singing. The term \"a cappella\" was originally intended to differentiate between Renaissance polyphony and Baroque concertato style. In the 19th century a renewed interest in Renaissance polyphony coupled with an ignorance of the fact that vocal parts were often doubled by instrumentalists led to the term coming to mean unaccompanied vocal music. The term is also used, albeit rarely, as a synonym for alla breve.\n\nA cappella music was originally used in religious music, especially church music as well as anasheed and zemirot. Gregorian chant is an example of a cappella singing, as is the majority of secular vocal music from the Renaissance. The madrigal, up until its development in the early Baroque into an instrumentally-accompanied form, is also usually in a cappella form. Jewish and Christian music were originally a cappella, and this practice has continued in both of these religions as well as in Islam.\n\nThe polyphony of Christian a cappella music began to develop in Europe around the late 15th century AD, with compositions by Josquin des Prez. The early a cappella polyphonies may have had an accompanying instrument, although this instrument would merely double the singers' parts and was not independent. By the 16th century, a cappella polyphony had further developed, but gradually, the cantata began to take the place of a cappella forms. 16th century a cappella polyphony, nonetheless, continued to influence church composers throughout this period and to the present day. Recent evidence has shown that some of the early pieces by Palestrina, such as what was written for the Sistine Chapel was intended to be accompanied by an organ \"doubling\" some or all of the voices. Such is seen in the life of Palestrina becoming a major influence on Bach, most notably in the \"Mass in B Minor\". Other composers that utilized the a cappella style, if only for the occasional piece, were Claudio Monteverdi and his masterpiece, \"Lagrime d'amante al sepolcro dell'amata\" (A lover's tears at his beloved's grave), which was composed in 1610, and Andrea Gabrieli when upon his death it was discovered many choral pieces, one of which was in the unaccompanied style. Learning from the preceding two composeres, Heinrich Schütz utilized the a cappella style in numerous pieces, chief among these were the pieces in the oratorio style, which were traditionally performed during the Easter week and dealt with the religious subject matter of that week, such as Christ's suffering and the Passion. Five of Schutz's \"Historien\" were Easter pieces, and of these the latter three, which dealt with the passion from three different viewpoints, those of Matthew, Luke and John, were all done a cappella style. This was a near requirement for this type of piece, and the parts of the crowd were sung while the solo parts which were the quoted parts from either Christ or the authors were performed in a plainchant.\n\nIn the Byzantine Rite of the Eastern Orthodox Church and the Eastern Catholic Churches, the music performed in the liturgies is exclusively sung without instrumental accompaniment. Bishop Kallistos Ware says, \"The service is sung, even though there may be no choir... In the Orthodox Church today, as in the early Church, singing is unaccompanied and instrumental music is not found.\" This \"a cappella\" behavior arises from strict interpretation of Psalms 150, which states, \"Let every thing that hath breath praise the Lord. Praise ye the Lord.\" In keeping with this philosophy, early Russian \"musika\" which started appearing in the late 17th century, in what was known as \"khorovïye kontsertï\" (choral concertos) made a cappella adaptations of Venetian-styled pieces, such as the treatise, \"Grammatika musikiyskaya\" (1675), by Nikolai Diletsky. Divine Liturgies and Western Rite masses composed by famous composers such as Peter Tchaikovsky, Sergei Rachmaninoff, Alexander Arkhangelsky, and Mykola Leontovych are fine examples of this.\n\nPresent-day Christian religious bodies known for conducting their worship services without musical accompaniment include some Presbyterian churches devoted to the regulative principle of worship, Old Regular Baptists, Primitive Baptists, Plymouth Brethren, Churches of Christ, Church of God (Guthrie, Oklahoma), the Old German Baptist Brethren, Doukhobors the Byzantine Rite and the Amish, Old Order Mennonites and Conservative Mennonites. Certain high church services and other musical events in liturgical churches (such as the Roman Catholic Mass and the Lutheran Divine Service) may be a cappella, a practice remaining from apostolic times. Many Mennonites also conduct some or all of their services without instruments. Sacred Harp, a type of folk music, is an a cappella style of religious singing with shape notes, usually sung at singing conventions.\n\nOpponents of musical instruments in the Christian worship believe that such opposition is supported by the Christian scriptures and Church history. The scriptures typically referenced are Matthew 26:30; Acts 16:25; Romans 15:9; 1 Corinthians 14:15; Ephesians 5:19; Colossians 3:16; Hebrews 2:12, 13:15; James 5:13, which show examples and exhortations for Christians to sing.\n\nThere is no reference to instrumental music in early church worship in the New Testament, or in the worship of churches for the first six centuries. Several reasons have been posited throughout church history for the absence of instrumental music in church worship.\n\nChristians who believe in a cappella music today believe that in the Israelite worship assembly during Temple worship only the Priests of Levi sang, played, and offered animal sacrifices, whereas in the church era, all Christians are commanded to sing praises to God. They believe that if God wanted instrumental music in New Testament worship, He would have commanded not just singing, but singing and playing like he did in the Hebrew scriptures.\n\nThe first recorded example of a musical instrument in Roman Catholic worship was a pipe organ introduced by Pope Vitalian into a cathedral in Rome around 670.\n\nInstruments have divided Christendom since their introduction into worship. They were considered a Catholic innovation, not widely practiced until the 18th century, and were opposed vigorously in worship by a number of Protestant Reformers, including Martin Luther (1483–1546), Ulrich Zwingli, John Calvin (1509–1564) and John Wesley (1703–1791). Alexander Campbell referred to the use of an instrument in worship as \"a cow bell in a concert\". In Sir Walter Scott's \"The Heart of Midlothian\", the heroine, Jeanie Deans, a Scottish Presbyterian, writes to her father about the church situation she has found in England (bold added):\n\nThose who do not adhere to the regulative principle of interpreting Christian scripture, believe that limiting praise to the unaccompanied chant of the early church is not commanded in scripture, and that churches in any age are free to offer their songs with or without musical instruments.\n\nThose who subscribe to this interpretation believe that since the Christian scriptures never counter instrumental language with any negative judgment on instruments, opposition to instruments instead comes from an interpretation of history. There is no written opposition to musical instruments in any setting in the first century and a half of Christian churches (33 AD to 180AD). The use of instruments for Christian worship during this period is also undocumented. Toward the end of the 2nd century, Christians began condemning the instruments themselves. Those who oppose instruments today believe these Church Fathers had a better understanding of God's desire for the church, but there are significant differences between the teachings of these Church Fathers and Christian opposition to instruments today.\n\nSince \"a cappella\" singing brought a new polyphony (more than one note at a time) with instrumental accompaniment, it is not surprising that Protestant reformers who opposed the instruments (such as Calvin and Zwingli) also opposed the polyphony. While Zwingli was burning organs in Switzerland – Luther called him a fanatic – the Church of England was burning books of polyphony.\n\nSome Holiness Churches such as the Free Methodist Church opposed the use of musical instruments in church worship until the mid-20th century. The Free Methodist Church allowed for local church decision on the use of either an organ or piano in the 1943 Conference before lifting the ban entirely in 1955.\n\nWhile worship in the Temple in Jerusalem included musical instruments (), traditional Jewish religious services in the Synagogue, both before and after the last destruction of the Temple, did not include musical instruments given the practice of scriptural cantillation. The use of musical instruments is traditionally forbidden on the Sabbath out of concern that players would be tempted to repair (or tune) their instruments, which is forbidden on those days. (This prohibition has been relaxed in many Reform and some Conservative congregations.) Similarly, when Jewish families and larger groups sing traditional Sabbath songs known as zemirot outside the context of formal religious services, they usually do so a cappella, and Bar and Bat Mitzvah celebrations on the Sabbath sometimes feature entertainment by a cappella ensembles. During the Three Weeks musical instruments are prohibited. Many Jews consider a portion of the 49-day period of the counting of the omer between Passover and Shavuot to be a time of semi-mourning and instrumental music is not allowed during that time. This has led to a tradition of a cappella singing sometimes known as \"sefirah\" music.\n\nThe popularization of the Jewish chant may be found in the writings of the Jewish philosopher Philo, born 20 BCE. Weaving together Jewish and Greek thought, Philo promoted praise without instruments, and taught that \"silent singing\" (without even vocal chords) was better still. This view parted with the Jewish scriptures, where Israel offered praise with instruments by God's own command (). The shofar is the only temple instrument still being used today in the synagogue, and it is only used from Rosh Chodesh Elul through the end of Yom Kippur. The shofar is used by itself, without any vocal accompaniment, and is limited to a very strictly defined set of sounds and specific places in the synagogue service. However, silver trumpets, as described in , have been made in recent years and used in prayer services at the Western Wall.\n\nPeter Christian Lutkin, dean of the Northwestern University School of Music, helped popularize a cappella music in the United States by founding the Northwestern A Cappella Choir in 1906. The A Cappella Choir was \"the first permanent organization of its kind in America.\"\n\nA strong and prominent a cappella tradition was begun in the midwest part of the United States in 1911 by F. Melius Christiansen, a music faculty member at St. Olaf College in Northfield, Minnesota. The St. Olaf College Choir was established as an outgrowth of the local St. John's Lutheran Church, where Christiansen was organist and the choir was composed, at least partially, of students from the nearby St. Olaf campus. The success of the ensemble was emulated by other regional conductors, and a rich tradition of a cappella choral music was born in the region at colleges like Concordia College (Moorhead, Minnesota), Augustana College (Rock Island, Illinois), Wartburg College (Waverly, Iowa), Luther College (Decorah, Iowa), Gustavus Adolphus College (St. Peter, Minnesota), Augustana College (Sioux Falls, South Dakota), and Augsburg College (Minneapolis, Minnesota). The choirs typically range from 40 to 80 singers and are recognized for their efforts to perfect blend, intonation, phrasing and pitch in a large choral setting.\n\nMajor movements in modern a cappella over the past century include Barbershop and doo wop. The Barbershop Harmony Society, Sweet Adelines International, and Harmony Inc. host educational events including Harmony University, Directors University, and the International Educational Symposium, and international contests and conventions, recognizing international champion choruses and quartets.\n\nThese days, many a cappella groups can be found in high schools and colleges. There are amateur Barbershop Harmony Society and professional groups that sing a cappella exclusively. Although a cappella is technically defined as singing without instrumental accompaniment, some groups use their voices to emulate instruments; others are more traditional and focus on harmonizing. A cappella styles range from gospel music to contemporary to barbershop quartets and choruses.\n\nThe Contemporary A Cappella Society (CASA) is a membership option for former students, whose funds support hosted competitions and events.\n\nA cappella music was popularized between the late 2000s and the early to mid-2010s with media hits such as the 2009–2014 TV show \"The Sing-Off\", the musical \"Perfect Harmony\", and the musical comedy film series \"Pitch Perfect\".\n\nIn July 1943, as a result of the American Federation of Musicians boycott of US recording studios, the a cappella vocal group \"The Song Spinners\" had a best-seller with \"Comin' In On A Wing And A Prayer\". In the 1950s several recording groups, notably The Hi-Los and the Four Freshmen, introduced complex jazz harmonies to a cappella performances. The King's Singers are credited with promoting interest in small-group a cappella performances in the 1960s. Frank Zappa loves Doo wop and A cappella, so Zappa released The Persuasions first album from his label in 1970. In 1983 an a cappella group known as The Flying Pickets had a Christmas 'number one' in the UK with a cover of Yazoo's (known in the US as Yaz) \"Only You\". A cappella music attained renewed prominence from the late 1980s onward, spurred by the success of Top 40 recordings by artists such as The Manhattan Transfer, Bobby McFerrin, Huey Lewis and the News, All-4-One, The Nylons, Backstreet Boys and Boyz II Men.\n\nContemporary a cappella includes many vocal groups and bands who add vocal percussion or beatboxing to create a pop/rock/gospel sound, in some cases very similar to bands with instruments. Examples of such professional groups include Straight No Chaser, Pentatonix, The House Jacks, Rockapella, Mosaic, Home Free and M-pact. There also remains a strong a cappella presence within Christian music, as some denominations purposefully do not use instruments during worship. Examples of such groups are Take 6, Glad and Acappella. Arrangements of popular music for small a cappella ensembles typically include one voice singing the lead melody, one singing a rhythmic bass line, and the remaining voices contributing chordal or polyphonic accompaniment.\n\nA cappella can also describe the isolated vocal track(s) from a multitrack recording that originally included instrumentation. These vocal tracks may be remixed or put onto vinyl records for DJs, or released to the public so that fans can remix them. One such example is the a cappella release of Jay-Z's \"Black Album\", which Danger Mouse mixed with The Beatles' \"White Album\" to create \"The Grey Album\".\n\nA cappella's growth is not limited to live performance, with hundreds of recorded a cappella albums produced over the past decade. As of December 2006, the Recorded A Cappella Review Board (RARB) had reviewed over 660 a cappella albums since 1994, and its popular discussion forum had over 900 users and 19,000 articles.\n\nOn their 1966 album titled \"Album\", Peter, Paul and Mary included the song \"Normal Normal.\" All the sounds on that song, both vocals and instruments, were created by Paul's voice, with no actual instruments used.\n\nIn 2013, an artist by the name Smooth McGroove rose to prominence with his style of a cappella music. He is best known for his a cappella covers of video game music tracks on YouTube.\n\nin 2015, an a cappella version of Jerusalem by multi-instrumentalist Jacob Collier was selected for Beats by Dre \"The Game Starts Here\" for the England Rugby World Cup campaign.\n\nA cappella has been used as the sole orchestration for original works of musical theater that have had commercial runs Off-Broadway (theaters in New York City with 99 to 500 seats) only four times. The first was Avenue X which opened on 28 January 1994 and ran for 77 performances. It was produced by Playwrights Horizons with book by John Jiler, music and lyrics by Ray Leslee. The musical style of the show's score was primarily Doo-Wop as the plot revolved around Doo-Wop group singers of the 1960s.\n\nIn 2001, The Kinsey Sicks, produced and starred in the critically acclaimed off-Broadway hit, \"DRAGAPELLA! Starring the Kinsey Sicks\" at New York's legendary Studio 54. That production received a nomination for a Lucille Lortel award as Best Musical and a Drama Desk nomination for Best Lyrics. It was directed by Glenn Casale with original music and lyrics by Ben Schatz.\n\nThe a cappella musical Perfect Harmony, a comedy about two high school a cappella groups vying to win the National championship, made its Off Broadway debut at Theatre Row’s Acorn Theatre on 42nd Street in New York City in October, 2010 after a successful out-of-town run at the Stoneham Theatre, in Stoneham, Massachusetts. Perfect Harmony features the hit music of The Jackson 5, Pat Benatar, Billy Idol, Marvin Gaye, Scandal, Tiffany, The Romantics, The Pretenders, The Temptations, The Contours, The Commodores, Tommy James & the Shondells and The Partridge Family, and has been compared to a cross between Altar Boyz and The 25th Annual Putnam County Spelling Bee.\n\nThe fourth a cappella musical to appear Off-Broadway, In Transit, premiered 5 October 2010 and was produced by Primary Stages with book, music, and lyrics by Kristen Anderson-Lopez, James-Allen Ford, Russ Kaplan, and Sara Wordsworth. Set primarily in the New York City subway system its score features an eclectic mix of musical genres (including jazz, hip hop, Latin, rock, and country). In Transit incorporates vocal beat boxing into its contemporary a cappella arrangements through the use of a subway beat boxer character. Beat boxer and actor Chesney Snow performed this role for the 2010 Primary Stages production. According to the show's website, it is scheduled to reopen for an open-ended commercial run in the Fall of 2011. In 2011 the production received four Lucille Lortel Award nominations including Outstanding Musical, Outer Critics Circle and Drama League nominations, as well as five Drama Desk nominations including Outstanding Musical and won for Outstanding Ensemble Performance.\n\nIn December 2016, In Transit became the first a cappella musical on Broadway.\n\nBarbershop music is one of several uniquely American art forms. The earliest reports of this style of a cappella music involved African Americans. The earliest documented quartets all began in barbershops. In 1938, the first formal men's barbershop organization was formed, known as the Society for the Preservation and Encouragement of Barber Shop Quartet Singing in America (S.P.E.B.S.Q.S.A), and in 2004 rebranded itself and officially changed its public name to the Barbershop Harmony Society (BHS). Today the BHS has over 22,000 members in approximately 800 chapters across the United States, and the barbershop style has spread around the world with organizations in many other countries. The Barbershop Harmony Society provides a highly organized competition structure for a cappella quartets and choruses singing in the barbershop style.\n\nIn 1945, the first formal women's barbershop organization, Sweet Adelines, was formed. In 1953 Sweet Adelines became an international organization, although it didn't change its name to Sweet Adelines International until 1991. The membership of nearly 25,000 women, all singing in English, includes choruses in most of the fifty United States as well as in Australia, Canada, England, Finland, Germany, Ireland, Japan, New Zealand, Scotland, Sweden, Wales and the Netherlands. Headquartered in Tulsa, Oklahoma, the organization encompasses more than 1,200 registered quartets and 600 choruses.\n\nIn 1959, a second women's barbershop organization started as a break off from Sweet Adelines due to ideological differences. Based on democratic principles which continue to this day, Harmony, Inc. is smaller than its counterpart, but has an atmosphere of friendship and competition. With about 2,500 members in the United States and Canada, Harmony, Inc. uses the same rules in contest that the Barbershop Harmony Society uses. Harmony, Inc. is registered in Providence, Rhode Island.\n\nThe popularity of a cappella among high schools and amateurs was revived by television shows and movies such as \"Glee\" and \"Pitch Perfect\". High school groups have conductors or student leaders who keep the tempo for the group.\n\nComposer Dinesh Subasinghe became the first Sri Lankan to write a cappella pieces for SATB choirs. He wrote \"The Princes of the Lost Tribe\" and \"Ancient Queen of Somawathee\" for Menaka De Shabandu and Bridget Halpe's choirs, respectively, based on historical incidents in ancient Sri Lanka. Voice Print is also a professional a cappella music group in Sri Lanka.\n\nThe European a cappella tradition is especially strong in the countries around the Baltic and perhaps most so in Sweden as described by Richard Sparks in his doctoral thesis \"The Swedish Choral Miracle\" in 2000.\n\nSwedish a cappella choirs have over the last 25 years won around 25% of the annual prestigious European Grand Prix for Choral Singing (EGP) that despite its name is open to choirs from all over the world (see list of laureates in the Wikipedia article on the EGP competition).\n\nThe reasons for the strong Swedish dominance are as explained by Richard Sparks manifold; suffice to say here that there is a long-standing tradition, an unsusually large proportion of the populations (5% is often cited) regularly sing in choirs, the Swedish choral director Eric Ericson had an enormous impact on a cappella choral development not only in Sweden but around the world, and finally there are a large number of very popular primary and secondary schools (\"music schools\") with high admission standards based on auditions that combine a rigid academic regimen with high level choral singing on every school day, a system that started with Adolf Fredrik's Music School in Stockholm in 1939 but has spread over the country.\n\nA cappella has gained attention in the UK in recent years, with many groups forming at British universities by students seeking an alternative singing pursuit to traditional choral and chapel singing. This movement has been bolstered by organisations such as The Voice Festival UK.\n\nIt is not clear exactly where collegiate a cappella began. The Rensselyrics of Rensselaer Polytechnic Institute (formerly known as the RPI Glee Club), established in 1873 is perhaps the oldest known collegiate a cappella group. However the longest continuously-singing group is probably The Whiffenpoofs of Yale University, which was formed in 1909 and once included Cole Porter as a member. Collegiate a cappella groups grew throughout the 20th century. Some notable historical groups formed along the way include Colgate University's The Colgate 13 (1942), Dartmouth College's Aires (1946), Cornell University's Cayuga's Waiters (1949) and The Hangovers (1968), the University of Maine Maine Steiners (1958), the Columbia University Kingsmen (1949), the Jabberwocks of Brown University (1949), and the University of Rochester YellowJackets (1956). All-women a cappella groups followed shortly, frequently as a parody of the men's groups: the Smiffenpoofs of Smith College (1936), The Shwiffs of Connecticut College (The She-Whiffenpoofs, 1944), and The Chattertocks of Brown University (1951). A cappella groups exploded in popularity beginning in the 1990s, fueled in part by a change in style popularized by the Tufts University Beelzebubs and the Boston University Dear Abbeys. The new style used voices to emulate modern rock instruments, including vocal percussion/\"beatboxing\". Some larger universities now have multiple groups. Groups often join one another in on-campus concerts, such as the Georgetown Chimes' Cherry Tree Massacre, a 3-weekend a cappella festival held each February since 1975, where over a hundred collegiate groups have appeared, as well as International Quartet Champions The Boston Common and the contemporary commercial a cappella group Rockapella. Co-ed groups have produced many up-and-coming and major artists, including John Legend, an alumnus of the Counterparts at the University of Pennsylvania, and Sara Bareilles, an alumna of Awaken A Cappella at University of California, Los Angeles. Mira Sorvino is an alumna of the Harvard-Radcliffe Veritones of Harvard College, where she had the solo on Only You by Yaz.\n\nA cappella is gaining popularity among South Asians with the emergence of primarily Hindi-English College groups. The first South Asian a cappella group was Penn Masala, founded in 1996 at the University of Pennsylvania. Co-ed South Asian a cappella groups are also gaining in popularity. The first co-ed south Asian a cappella was Anokha, from the University of Maryland, formed in 2001. Also, Dil se, another co-ed a cappella from UC Berkeley, hosts the \"Anahat\" competition at the University of California, Berkeley annually. Maize Mirchi, the co-ed a cappella group from the University of Michigan hosts \"Sa Re Ga Ma Pella\", an annual South Asian a cappella invitational with various groups from the Midwest. Another South Asian group from the Midwest is Chai Town who is based in the University of Illinois at Urbana- Champaign.\n\nJewish-interest groups such as Tufts University's Shir Appeal, University of Chicago's Rhythm and Jews, Binghamton University's Kaskeset, Ohio State University's Meshuganotes, Rutgers University's Kol Halayla, New York University's Ani V'Ata and Yale University's Magevet are also gaining popularity across the U.S.\n\nIncreased interest in modern a cappella (particularly collegiate a cappella) can be seen in the growth of awards such as the Contemporary A Cappella Recording Awards (overseen by the Contemporary A Cappella Society) and competitions such as the International Championship of Collegiate A Cappella for college groups and the Harmony Sweepstakes for all groups. In December 2009, a new television competition series called \"The Sing-Off\" aired on NBC. The show featured eight a cappella groups from the United States and Puerto Rico vying for the prize of $100,000 and a recording contract with Epic Records/Sony Music. The show was judged by Ben Folds, Shawn Stockman, and Nicole Scherzinger and was won by an all-male group from Puerto Rico called Nota. The show returned for a second and third season, won by Committed and Pentatonix, respectively.\n\nEach year, hundreds of Collegiate a cappella groups submit their strongest songs in a competition to be on The Best of College A Cappella (BOCA), an album compilation of tracks from the best college a cappella groups around the world. The album is produced by Varsity Vocals – which also produces the International Championship of Collegiate A Cappella – and Deke Sharon. A group chosen to be on the BOCA album earns much credibility among the a cappella community.\n\nCollegiate a cappella groups may also submit their tracks to Voices Only, a two-disc series released at the beginning of each school year. A Voices Only album has been released every year since 2005.\n\nIn addition, all women's a cappella groups can send their strongest song tracks to the Women’s A Cappella Association (WACA) for its annual best of women's a cappella album. WACA offers another medium for women's voices to receive recognition and has released an album every year since 2014, featuring women's groups from across the United States.\n\nIn addition to singing words, some a cappella singers also emulate instrumentation by reproducing instrumental sounds with their vocal cords and mouth. One of the earliest 20th century practitioners of this method were The Mills Brothers whose early recordings of the 1930s clearly stated on the label that all instrumentation was done vocally. More recently, \"Twilight Zone\" by 2 Unlimited was sung a cappella to the instrumentation on the comedy television series \"Tompkins Square\". Another famous example of emulating instrumentation instead of singing the words is the theme song for \"The New Addams Family\" series on Fox Family Channel (now ABC Family). Groups such as Vocal Sampling and Undivided emulate Latin rhythms a cappella. In the 1960s, the Swingle Singers used their voices to emulate musical instruments to Baroque and Classical music. Vocal artist Bobby McFerrin is famous for his instrumental emulation. A cappella group Naturally Seven recreates entire songs using vocal tones for every instrument.\n\nThe Swingle Singers used nonsense words to sound like instruments, but have been known to produce non-verbal versions of musical instruments. Beatboxing, more accurately known as vocal percussion, is a technique used in a cappella music popularized by the hip-hop community, where rap is often performed a cappella also. The advent of vocal percussion added new dimensions to the a cappella genre and has become very prevalent in modern arrangements. Jazz vocalist Petra Haden used a four-track recorder to produce an a cappella version of \"The Who Sell Out\" including the instruments and fake advertisements on her album \"\" in 2005. Haden has also released a cappella versions of Journey's \"Don't Stop Believin'\", The Beach Boys' \"God Only Knows\" and Michael Jackson's \"Thriller\".\n\nChristian rock group Relient K recorded the song \"Plead the Fifth\" a cappella on its album \"Five Score and Seven Years Ago\". The group recorded lead singer Matt Thiessen making drum noises and played them with an electronic drum machine to record the song.\n\nThe German metal band van Canto uses vocal noises to imitate guitars on covers of well-known rock and metal songs (such as \"Master of Puppets\" by Metallica) as well as original compositions. Although they are generally classified as a cappella metal, the band also includes a drummer, and uses amplifiers on some songs to distort the voice to sound more like an electric guitar.\n\n\n\n"}
{"id": "2414", "url": "https://en.wikipedia.org/wiki?curid=2414", "title": "Arrangement", "text": "Arrangement\n\nIn music, an arrangement is a musical reconceptualization of a previously composed work. It may differ from the original work by means of reharmonization, melodic paraphrasing, orchestration, or development of the formal structure. Arranging differs from orchestration in that the latter process is limited to the assignment of notes to instruments for performance by an orchestra, concert band, or other musical ensemble. Arranging \"involves adding compositional techniques, such as new thematic material for introductions, transitions, or modulations, and endings... Arranging is the art of giving an existing melody musical variety\".\n\nArrangement and transcriptions of classical and serious music go back to the early history of this genre. In particular, music written for the piano has frequently undergone this treatment. The suite of ten piano pieces \"Pictures at an Exhibition\", by Modest Mussorgsky, has been arranged over twenty times, notably by Maurice Ravel.\n\nDue to his lack of expertise in orchestration, the American composer George Gershwin had his \"Rhapsody in Blue\" orchestrated and arranged by Ferde Grofé.\n\nPopular music recordings often include parts for brass, string, and other instruments which were added by arrangers and not composed by the original songwriters. Popular music arrangements may also be considered to include new releases of existing songs with a new musical treatment. These changes can include alterations to tempo, meter, key, instrumentation, and other musical elements.\n\nWell-known examples include Joe Cocker's version of the Beatles' \"With a Little Help from My Friends,\" Cream's Crossroads, and Ike And Tina Turner's version of Creedence Clearwater Revival's \"Proud Mary\". The American group Vanilla Fudge and British group Yes based their early careers on radical re-arrangements of contemporary hits. Bonnie Pointer performed disco and Motown-themed versions of \"Heaven Must Have Sent You.\" Remixes, such as in dance music, can also be considered arrangements.\n\nThough arrangers may contribute substantially to finished musical products, for copyright and royalty purposes, they usually hold no legal claim to their work.\n\nArrangements for small jazz combos are usually informal, minimal, and uncredited. Larger ensembles have generally had greater requirements for notated arrangements, though the early Count Basie big band is known for its many \"head\" arrangements, so called because they were worked out by the players themselves, memorized (in the player's \"head\"), and never written down. Most arrangements for big bands, however, were written down and credited to a specific arranger, as with arrangements by Sammy Nestico and Neal Hefti for Count Basie's later big bands.\n\nDon Redman made innovations in jazz arranging as a part of Fletcher Henderson's orchestra in the 1920s. Redman's arrangements introduced a more intricate melodic presentation and \"soli\" performances for various sections of the big band. Benny Carter became Henderson's primary arranger in the early 1930s, becoming known for his arranging abilities in addition to his previous recognition as a performer. Beginning in 1938, Billy Strayhorn became an arranger of great renown for the Duke Ellington orchestra. Jelly Roll Morton is sometimes considered the earliest jazz arranger. While he toured around the years 1912 to 1915, he wrote down parts to enable \"pick-up\" bands to perform his compositions.\n\nBig band arrangements are informally called \"charts\". In the swing era they were usually either arrangements of popular songs or they were entirely new compositions. Duke Ellington's and Billy Strayhorn's arrangements for the Duke Ellington big band were usually new compositions, and some of Eddie Sauter's arrangements for the Benny Goodman band and Artie Shaw's arrangements for his own band were new compositions as well. It became more common to arrange sketchy jazz combo compositions for big band after the bop era.\n\nAfter 1950, the big bands declined in number. However, several bands continued and arrangers provided renowned arrangements. Gil Evans wrote a number of large-ensemble arrangements in the late 1950s and early 1960s intended for recording sessions only. Other arrangers of note include Vic Schoen, Pete Rugolo, Oliver Nelson, Johnny Richards, Billy May, Thad Jones, Maria Schneider, Bob Brookmeyer, Lou Marini, Nelson Riddle, Ralph Burns, Billy Byers, Gordon Jenkins, Ray Conniff, Henry Mancini, Ray Reach, Vince Mendoza, and Claus Ogerman.\n\nIn the 21st century, the Big Band arrangement has made a modest comeback. Gordon Goodwin, Roy Hargrove, and Christian McBride have all rolled out New Big Bands with both original compositions and new arrangements of standard tunes.\n\nThe string section is a body of instruments composed of various stringed instruments. By the 19th century orchestral music in Europe had standardized the string section into the following homogeneous instrumental groups: first violins, second violins (the same instrument as the first violins, but typically playing an accompaniment or harmony part to the first violins, and often at a lower pitch), violas, cellos, and double basses. The string section in a multi-sectioned orchestra is referred sometimes to as the \"string choir.\"\n\nThe harp is also a stringed instrument, but is not a member of nor homogeneous with the violin family and is not considered part of the string choir. Samuel Adler classifies the harp as a plucked string instrument in the same category as the guitar (acoustic or electric), mandolin, banjo, or zither. Like the harp these instruments do not belong to the violin family and are not homogeneous with the string choir. In modern arranging these instruments are considered part of the rhythm section. The electric bass and upright string bass—depending on the circumstance—can be treated by the arranger as either string section or rhythm section instruments.\n\nA group of instruments in which each member plays a unique part—rather than playing in unison with other like instruments—is referred to as a chamber ensemble. A chamber ensemble made up entirely of strings of the violin family is referred to by its size. A string trio consists of three players, a string quartet four, a string quintet five, and so on.\n\nIn most circumstances the string section is treated by the arranger as one homogeneous unit and its members are required to play preconceived material rather than improvise.\n\nA string section can be utilized on its own (this is referred to as a string orchestra) or in conjunction with any of the other instrumental sections. More than one string orchestra can be utilized.\n\nA standard string section (vln., vln 2., vla., vcl, cb.) with each section playing unison allows the arranger to create a five-part texture. Often an arranger will divide each violin section in half or thirds to achieve a denser texture. It is possible to carry this division to its logical extreme in which each member of the string section plays his or her own unique part.\n\nArtistic, budgetary and logistical concerns will determine the size and instrumentation of a string section. The Broadway musical West Side Story, in 1957, was booked into the Winter Garden theater; composer Leonard Bernstein disliked the playing of \"house\" viola players he would have to use there, and so he chose to leave them out of the show's instrumentation; a benefit was the creation of more space in the pit for an expanded percussion section.\n\nGeorge Martin, producer and arranger for The Beatles, warns arrangers about the intonation issues when only two like instruments play in unison. \"After a string quartet,\" Martin explains, \"I do not think there is a satisfactory sound for strings until one has at least three players on each line...as a rule two stringed instruments together create a slight \"beat\" which does not give a smooth sound.\"\n\nWhile any combination and number of string instruments is possible in a section, a traditional string section sound is achieved with a violin-heavy balance of instruments.\n\n\n"}
{"id": "2416", "url": "https://en.wikipedia.org/wiki?curid=2416", "title": "Athanasian Creed", "text": "Athanasian Creed\n\nThe Athanasian Creed, also known as Pseudo-Athanasian Creed or Quicunque Vult (also Quicumque Vult), is a Christian statement of belief focused on Trinitarian doctrine and Christology. The Latin name of the creed, \"Quicunque vult\", is taken from the opening words, \"Whosoever wishes\". The creed has been used by Christian churches since the sixth century. It is the first creed in which the equality of the three persons of the Trinity is explicitly stated. It differs from the Nicene-Constantinopolitan and Apostles' Creeds in the inclusion of anathemas, or condemnations of those who disagree with the creed (like the original Nicene Creed).\n\nWidely accepted among Western Christians, including the Roman Catholic Church and some Anglican churches, Lutheran churches (it is considered part of Lutheran confessions in the Book of Concord), and ancient, liturgical churches generally, the Athanasian Creed has been used in public worship less and less frequently, but part of it can be found as an \"Authorized Affirmation of Faith\" in the recent (2000) Common Worship liturgy of the Church of England [Main Volume page 145]. \n\nIt was designed to distinguish Nicene Christianity from the heresy of Arianism. Liturgically, this Creed was recited at the Sunday Office of Prime in the Western Church; it is not in common use in the Eastern Church. The creed has never gained acceptance in liturgy among Eastern Christians since it was considered as one of many unorthodox fabrications that contained the Filioque clause. Today, the Athanasian Creed is rarely used even in the Western Church. When used, one common practice is to use it once a year on Trinity Sunday.\n\nA medieval account credited Athanasius of Alexandria, the famous defender of Nicene theology, as the author of the Creed. According to this account, Athanasius composed it during his exile in Rome and presented it to Pope Julius I as a witness to his orthodoxy. This traditional attribution of the Creed to Athanasius was first called into question in 1642 by Dutch Protestant theologian G. J. Voss. \n\nIt has since been widely accepted by modern scholars that the creed was not authored by Athanasius, that it was not originally called a creed at all, nor was Athanasius' name originally attached to it. Athanasius' name seems to have become attached to the creed as a sign of its strong declaration of Trinitarian faith. The reasoning for rejecting Athanasius as the author usually relies on a combination of the following:\n\n\nThe use of the creed in a sermon by Caesarius of Arles, as well as a theological resemblance to works by Vincent of Lérins, point to Southern Gaul as its origin. The most likely time frame is in the late fifth or early sixth century AD – at least 100 years after Athanasius. The theology of the creed is firmly rooted in the Augustinian tradition, using exact terminology of Augustine's \"On the Trinity\" (published 415 AD). In the late 19th century, there was a great deal of speculation about who might have authored the creed, with suggestions including Ambrose of Milan, Venantius Fortunatus, and Hilary of Poitiers, among others. \n\nThe 1940 discovery of a lost work by Vincent of Lérins, which bears a striking similarity to much of the language of the Athanasian Creed, have led many to conclude that the creed originated either with Vincent or with his students. For example, in the authoritative modern monograph about the creed, J. N. D. Kelly asserts that Vincent of Lérins was not its author, but that it may have come from the same milieu, namely the area of Lérins in southern Gaul. The oldest surviving manuscripts of the Athanasian Creed date from the late 8th century.\n\nThe Athanasian Creed is usually divided into two sections: lines 1–28 addressing the doctrine of the Trinity, and lines 29–44 addressing the doctrine of Christology. Enumerating the three persons of the Trinity (i.e., Father, the Son, and the Holy Spirit), the first section of the creed ascribes the divine attributes to each individually. Thus, each person of the Trinity is described as uncreated (\"increatus\"), limitless (\"Immensus\"), eternal (\"æternus\"), and omnipotent (\"omnipotens\"). \n\nWhile ascribing the divine attributes and divinity to each person of the Trinity, thus avoiding subordinationism, the first half of the Athanasian Creed also stresses the unity of the three persons in the one Godhead, thus avoiding a theology of tritheism. Furthermore, although one God, the Father, Son, and Holy Spirit are distinct from each other. For the Father is neither made nor begotten; the Son is not made but is begotten from the Father; the Holy Spirit is neither made nor begotten but proceeds from the Father and the Son (filioque).\n\nThe text of the Athanasian Creed is as follows:\n\nThe Christology of the second section is more detailed than that of the Nicene Creed, and reflects the teaching of the First Council of Ephesus (431) and the definition of the Council of Chalcedon (451). The Athanasian Creed uses the term \"substantia\" (a Latin translation of the Nicene \"homoousios\": 'same being' or 'consubstantial') not only with respect to the relation of the Son to the Father according to his divine nature, but also says the Son is \"substantia\" of his mother Mary according to his human nature.\n\nThe Creed's wording thus excludes not only Sabellianism and Arianism, but the Christological heresies of Nestorianism and Eutychianism. A need for a clear confession against Arianism arose in western Europe when the Ostrogoths and Visigoths, who had Arian beliefs, invaded at the beginning of the 5th century.\n\nThe final section of this Creed also moved beyond the Nicene (and Apostles') Creeds in making negative statements about the people's fate: \"They that have done good shall go into life everlasting: and they that have done evil into everlasting fire.\" This caused considerable debate in England in the mid-nineteenth century, centred on the teaching of Frederick Denison Maurice.\n\nComposed of 44 rhythmic lines, the Athanasian Creed appears to have been intended as a liturgical document – that is, the original purpose of the creed was to be spoken or sung as a part of worship. The creed itself uses the language of public worship, speaking of the worship of God rather than the language of belief (\"Now this is the catholic faith: We worship one God\"). In the Catholic Church in medieval times, this creed was recited following the Sunday sermon or at the Sunday Office of Prime. The creed was often set to music and used in the place of a Psalm.\n\nEarly Protestants inherited the late medieval devotion to the Athanasian Creed, and it was considered to be authoritative in many Protestant churches. The statements of Protestant belief (confessional documents) of various Reformers commend the Athanasian Creed to their followers, including the Augsburg Confession, the Formula of Concord, the Second Helvetic Confession, the Belgic Confession, the Bohemian Confession and the Thirty-nine Articles. A metric version titled \"Quicumque vult\", with a musical setting, was published in \"The Whole Booke of Psalmes\" printed by John Day in 1562. Among modern Lutheran and Reformed churches adherence to the Athanasian Creed is prescribed by the earlier confessional documents, but the creed does not receive much attention outside of occasional use – especially on Trinity Sunday.\n\nIn Reformed circles, it is included (for example) in the Christian Reformed Churches of Australia's Book of Forms (publ. 1991). However, it is rarely recited in public worship.\n\nIn the successive Books of Common Prayer of the reformed Church of England, from 1549 to 1662, its recitation was provided for on 19 occasions each year, a practice which continued until the nineteenth century, when vigorous controversy regarding its statement about 'eternal damnation' saw its use gradually decline. It remains one of the three Creeds approved in the Thirty-Nine Articles, and is printed in several current Anglican prayer books (e.g. A Prayer Book for Australia (1995)). As with Roman Catholic practice, its use is now generally only on Trinity Sunday or its octave. The Episcopal Church based in the United States has never provided for its use in worship, but added it to its Book of Common Prayer for the first time in 1979, where it is included in small print in a reference section entitled \"Historical Documents of the Church.\"\n\nIn Roman Catholic churches, it was traditionally said at Prime on Sundays when the Office was of the Sunday. The 1911 reforms reduced this to Sundays after Epiphany and Pentecost, and on Trinity Sunday, except when a commemoration of a Double feast or a day within an Octave occurred. The 1960 reforms further reduced its use to once a year, on Trinity Sunday. It has been effectively dropped from the Catholic liturgy since the Second Vatican Council. It is however maintained in the \"Forma Extraordinaria\", per the decree Summorum Pontificum, and also in the rite of exorcism, both in the \"Forma Ordinaria\" and the \"Forma Extraordinaria\" of the Roman Rite.\n\nIn Lutheranism, the Athanasian Creed is—along with the Apostles' and Nicene Creeds—one of the three ecumenical creeds placed at the beginning of the 1580 Book of Concord, the historic collection of authoritative doctrinal statements (confessions) of the Lutheran Church. It is still used in the liturgy on Trinity Sunday.\n\nA common visualisation of the first half of the Creed is the Shield of the Trinity.\n\n"}
{"id": "2417", "url": "https://en.wikipedia.org/wiki?curid=2417", "title": "Alicante", "text": "Alicante\n\nAlicante (, ), or (), both the Spanish and Valencian being official names, is a city and port in Spain on the Costa Blanca, the capital of the province of Alicante and of the comarca of Alacantí, in the south of the Valencian Community. It is also a historic Mediterranean port. The population of the city of Alicante proper was 330,525, estimated , ranking as the second-largest Valencian city. Including nearby municipalities, the Alicante conurbation had 452,462 residents. The population of the metropolitan area (including Elche and satellite towns) was 757,085 estimates, ranking as the eighth-largest metropolitan area of Spain.\nThe name of the city echoes the Arabic name \"Laqant\" (لَقَنْت) or \"Al-Laqant\" (ألَلَقَنْت), which in turn reflects the Latin \"Lucentum\".\n\nThe area around Alicante has been inhabited for over 7000 years. The first tribes of hunter-gatherers moved down gradually from Central Europe between 5000 and 3000 BC. Some of the earliest settlements were made on the slopes of Mount Benacantil. By 1000 BC Greek and Phoenician traders had begun to visit the eastern coast of Spain, establishing small trading ports and introducing the native Iberian tribes to the alphabet, iron and the pottery wheel. The town of Leuce Akra (white cape) was then founded by Greek settlers from Marseille around 325/324 b.C. By the 3rd century BC, the rival armies of Carthage and Rome began to invade and fight for control of the Iberian Peninsula. The Carthaginian general Hamilcar Barca established the fortified settlement of \"Akra Leuka\" (Greek: , meaning \"White Mountain\" or \"White Point\"), where Alicante stands today.\nAlthough the Carthaginians conquered much of the land around Alicante, the Romans would eventually rule Hispania Tarraconensis for over 700 years. By the 5th century AD, Rome was in decline and the Roman predecessor town of Alicante, known as \"Lucentum\" (Latin), was more or less under the control of the Visigothic warlord Theudimer. However neither the Romans nor the Goths put up much resistance to the Arab conquest of \"Medina Laqant\" in the 8th century. The Moors ruled southern and eastern Spain until the 13th century \"Reconquista\" (Reconquest). Alicante was finally taken in 1246 by the Castilian king Alfonso X, but it passed soon and definitively to the Kingdom of Valencia in 1298 with King James II of Aragon. It gained the status of Royal Village (\"Vila Reial\") with representation in the medieval Valencian Parliament (\"Corts Valencianes\").\nAfter several decades of being the battlefield where the Kingdom of Castile and the Crown of Aragon clashed, Alicante became a major Mediterranean trading station exporting rice, wine, olive oil, oranges and wool. But between 1609 and 1614 King Felipe III expelled thousands of Moriscos who had remained in Valencia after the Reconquista, due to their cooperation with Barbary pirates who continually attacked coastal cities and caused much harm to trade. This act cost the region dearly; with so many skilled artisans and agricultural labourers gone, the feudal nobility found itself sliding into bankruptcy. Things got worse in the early 18th century; after the War of Spanish Succession, Alicante went into a long, slow decline, surviving through the 18th and 19th centuries by making shoes and growing agricultural produce such as oranges and almonds, and thanks to its fisheries. The end of the 19th century witnessed a sharp recovery of the local economy with increasing international trade and the growth of the city harbour leading to increased exports of several products (particularly during World War I when Spain was a neutral country).\nDuring the early 20th century, Alicante was a minor capital that enjoyed the benefit of Spain's neutrality during World War I, and that provided new opportunities for local industry and agriculture. The Rif War in the 1920s saw numerous \"alicantinos\" drafted to fight in the long and bloody campaigns in the former Spanish protectorate (Northern Morocco) against the Rif rebels. The political unrest of the late 1920s led to the victory of Republican candidates in local council elections throughout the country, and the abdication of King Alfonso XIII. The proclamation of the Second Spanish Republic was much celebrated in the city on 14 April 1931. The Spanish Civil War broke out on 17 July 1936. Alicante was the last city loyal to the Republican government to be occupied by dictator Franco's troops on 1 April 1939, and its harbour saw the last Republican government officials fleeing the country. Vicious air bombings were targeted on Alicante during the three years of civil conflict, most notably the bombing by the Italian \"Aviazione Legionaria\" of the Mercado de Abastos on 25 May 1938 in which more than 300 civilians perished.\nThe late 1950s and early 1960s saw the onset of a lasting transformation of the city by the tourist industry. Large buildings and complexes rose in nearby Albufereta (e.g. El Barco) and Playa de San Juan, with the benign climate being the biggest draw to attract prospective buyers and tourists who kept the hotels reasonably busy. New construction benefited the whole economy, as the development of the tourism sector also spawned new businesses such as restaurants, bars and other tourist-oriented enterprises. Also, the old airfield at Rabassa was closed and air traffic moved to the new El Altet Airport, which made a more convenient and modern facility for charter flights bringing tourists from northern European countries.\n\nWhen Franco died in 1975, his successor Juan Carlos I played his part as the living symbol of the transition of Spain to a democratic constitutional monarchy. The governments of regional communities were given constitutional status as \"nationalities\", and their governments were given more autonomy, including that of the Valencian region, the \"Generalitat Valenciana\".\n\nThe Port of Alicante has been reinventing itself since the industrial decline the city suffered in the 1980s (with most mercantile traffic lost to Valencia's harbour). In recent years, the Port Authority has established it as one of the most important ports in Spain for cruises, with 72 calls to port made by cruise ships in 2007 bringing some 80,000 passengers and 30,000 crew to the city each year. The moves to develop the port for more tourism have been welcomed by the city and its residents, but the latest plans to develop an industrial estate in the port have caused great controversy.\n\nUntil the global recession which started in 2008, Alicante was one of the fastest-growing cities in Spain. The boom depended partly on tourism directed to the beaches of the Costa Blanca and particularly on the second residence-construction boom which started in the 1960s and revived again by the late 1990s. Services and public administration also play a major role in the city's economy. The construction boom has raised many environmental concerns and both the local autonomous government and city council are under scrutiny by the European Union. The construction surge was the subject of hot debates among politicians and citizens alike. The latest of many public battles concerns the plans of the Port Authority of Alicante to construct an industrial estate on reclaimed land in front of the city's coastal strip, in breach of local, national and European regulations. (See Port of Alicante for details).\nThe city serves as the headquarters of the European Union Intellectual Property Office and a sizeable population of European public workers live there.\n\nThe campus of the University of Alicante lies in San Vicente del Raspeig, bordering the city of Alicante to the north. More than 27,000 students attend the University.\n\nSince 2005 Ciudad de la Luz, one of the largest film studios in Europe, has had its base in Alicante. The studio has shot Spanish and international movies such as \"Asterix at the Olympic Games\" by Frédéric Forestier and Thomas Langmann, and \"Manolete\" by Menno Meyjes.\n\nThe official population of Alicante in 2014 was 332,067 inhabitants and 757,085 in the metropolitan area \"Alicante-Elche\". About 15% of the population is foreign, most of them immigrants from Argentina, Ecuador, United Kingdom and Colombia who have arrived in the previous 20 years. There are also immigrants from other countries such as Germany, Romania, Russia, Algeria, Ukraine, Morocco and Italy, many of whom coming outside the EU are under illegal alien status and therefore are not accounted for in official population figures. The real percentage of foreign residents is higher, since the Alicante metropolitan area is home to many Northern European retirees who are officially still residents of their own countries. In the same pattern, a sizable number of permanent residents are Spanish nationals who officially still live in Madrid, the Basque provinces, or other areas of the country.\n\nGabriel Echávarri is the Mayor of the city. He was elected for the post on June 13, 2015, following the municipal elections on May 24, 2015. He was supported by the votes from his own group (6), plus those from leftist parties Guanyar Alacant (6) and Compromís (3), as well as from centre-right party Ciudadanos (6). The People's Party (\"Partido Popular\", PP), with only 8 elected seats, lost the majority.\n\nIn the previous municipal elections of May 2011, Sonia Castedo of People's Party won the elections with an absolute majority, but resigned in December 2014 due to her involvement in several corruption scandals, at present being under investigation. Her fellow party member Miguel Valor went on to become mayor up until Echávarri's election.\n\nAt the foot of the main staircase of the City Hall Building (\"Ayuntamiento\") is the zero point (\"cota cero\"), used as the point of reference for measuring the height above or below sea level of any point in Spain, due to the marginal tidal variations of the Mediterranean sea in Alicante.\n\nAlicante enjoys mild winter temperatures, hot summers and little rain, concentrated in equinoctial periods. The climate of the Alicante region according to Köppen climate classification is a Hot semi-arid climate (\"BSh\"). On average the temperature ranges between and in January, and between and in August, with an average annual temperature of . Daily variations in temperature are generally small because of the stabilising influence of the sea, although occasional periods of westerly wind can produce temperature changes of or more. Seasonal variations in temperature are also relatively small, meaning that winters are mild and summers are hot.\n\nThe average rainfall is per year. The cold drop means that September and October are the wettest months. Rarely, the rainfall can be torrential, reaching over in a 24-hour period, leading to severe flooding. Because of this irregularity, only 35 rainy days are observed on average per year, and the annual number of sunshine hours is 2,953.\n\nThe record maximum temperature of was observed on 4 July 1994. The record minimum temperature of was recorded on 2 January 1971. The worst flooding in modern history occurred on 30 September 1997 when of rain fell within six hours. Temperatures under are very rare. Snow is unknown since 1926 The climate of Alicante is very similar to the climate of Los Angeles, California.\n\nAlicante Airport outranks its Valencian counterpart, being among the busiest airports in Spain after Madrid, Barcelona, Palma de Mallorca and Málaga. It is connected with Madrid and Barcelona by frequent Iberia and Vueling flights, and with many Western European cities through carriers such as Ryanair, Easyjet, Air Berlin, Monarch Airlines, and Jet2.com. There are also regular flights to Algeria and Russia.\nAlicante railway station is used by Cercanías linking Alicante with suburbs and Murcia. Long-range RENFE trains run frequently to Madrid, Barcelona, and Valencia.\n\nAlicante Tram connects the city with outlying settlements along Costa Blanca. , electric tram-trains run up to Benidorm, and diesel trains go further to Dénia.\n\nThe city has regular ferry services to the Balearic Islands and Algeria. The city is strongly fortified, with a spacious harbour.\n\nAmongst the most notable features of the city are the Castle of Santa Bárbara, which sits high above the city, and the port of Alicante. The latter was the subject of bitter controversy in 2006–2007 as residents battled, successfully, to keep it from being changed into an industrial estate.\n\nThe Santa Bárbara castle is situated on Mount Benacantil, overlooking the city. The tower (\"La Torreta\") at the top, is the oldest part of the castle, while part of the lowest zone and the walls were constructed later in the 18th century.\nThe promenade \"Explanada de España\", lined by palm trees, is paved with 6.5 million marble floor tiles creating a wavy form and is one of the most lovely promenades in Spain. The Promenade extends from the Port of Alicante to the Gran Vía and ends at the famous statue of Mark Hersch. For the people of Alicante, the promenade is the meeting place for the traditional Spanish \"paseo\", or stroll along the waterfront in the evenings, and a venue for outdoor musical concerts. At the end of the promenade is a monument by the artist Bañuls of the 19th century.\n\n\"Barrio de la Santa Cruz\" is a colourful quarter of the old city, situated on the south-west of Santa Bárbara castle. Its small houses climb up the hill leading to the walls and the castle, through narrow streets decorated with flags and tubs of flowers.\n\n\"L'Ereta Park\" is situated on the foothills of Mount Benacantil, on the way to the castle. It runs from the Santa Bárbara castle down to the old part of Alicante and consists of several levels, routes, decks and rest stops which offer a panoramic view overlooking the city.\n\n\"El Palmeral Park\" is one of the favorite parks of Alicante's citizens. It includes walking trails, children's playgrounds, ponds and brooks, picnic tables and an auditorium for concerts.\n\nJust a few kilometers from Alicante on the Mediterranean Sea lies Tabarca island. What was once a haven for Barbary pirates is now a beautiful tourist attraction.\nOther sights include:\n\nThere are a dozen museums in Alicante. On exhibition at the Archaeological Museum of Alicante (MARQ) are local artifacts dating from 100,000 years ago till the early 20th century. The collection is divided into different rooms representing three divisions of archaeological methodology: ground, urban and underwater archaeology, with dioramas, audiovisual and interactive zones. The archaeological museum won the European Museum of the Year Award in 2004. Gravina Museum of Fine Arts presents a number of paintings and sculptures from the 16th century to the 19th century. Asegurada Museum of Contemporary Art houses a major collection of twentieth-century art, composed mainly of works donated by .\n\nThe most important festival, the \"Bonfires of Saint John\" (\"Fogueres de Sant Joan\"), takes place during the summer solstice. This is followed a week later by seven nights of firework and pyrotechnic contests between companies on the urban beach \"Playa del Postiguet\". Another well-known festival is \"Moros i Cristians\" in Altozano or \"San Blas\" district. Overall, the city boasts a year-round nightlife for the enjoyment of tourists, residents, and a large student population of the University of Alicante. The nightlife social scene tends to shift to nearby Playa de San Juan (St. John's Beach) during the summer months.\n\nEvery summer in Alicante, a two-month-long programme of music, theatre and dance is staged in the Paseo del Puerto.\n\nThe two established Alicante football teams are Hércules CF, which competes in the Spanish Segunda División B, and Alicante CF, which plays in Tercera División and was dissolved in 2014 due to economic problems. Hércules CF is more well known as it was in the first division in Spain during 96/97 and had many popular players such as David Trezeguet, Royston Drenthe and Aedo Valvez. It is also known because, thanks to this team beating Barcelona, Real Madrid won the league in 1997. Nowadays their home games are played in the Estadio José Rico Pérez.\n\nBasketball club Lucentum Alicante participates in the Spanish basketball league. It plays in the Centro de Tecnificación de Alicante.\n\nAlicante serves as headquarters and the starting point of Volvo Ocean Race, a yacht race around the world. The latest race sailed in October 2014.\n\nAlicante is twinned with:\nIn 2009 a bid was made to twin Newcastle, United Kingdom, with Alicante.\n\n\n"}
{"id": "2418", "url": "https://en.wikipedia.org/wiki?curid=2418", "title": "August 4", "text": "August 4\n\n\n\n"}
{"id": "2421", "url": "https://en.wikipedia.org/wiki?curid=2421", "title": "Albrecht Achilles", "text": "Albrecht Achilles\n\nAlbrecht Achilles may refer to:\n"}
{"id": "2422", "url": "https://en.wikipedia.org/wiki?curid=2422", "title": "Ann Widdecombe", "text": "Ann Widdecombe\n\nAnn Noreen Widdecombe, (born 4 October 1947) is a former British Conservative Party politician. She is a Privy Councillor and was the Member of Parliament for Maidstone from 1987 to 1997 and for Maidstone and The Weald from 1997 to 2010. She was a social conservative and a member of the Conservative Christian Fellowship. She retired from politics at the 2010 general election. Since 2002 she has also made numerous television and radio appearances, including as a television presenter. She is a convert from Anglicanism to Roman Catholicism.\n\nAs an MP, Widdecombe was known for opposing the legality of abortion, her opposition to various issues of LGBT equality such as an equal age of consent and the repeal of Section 28, her support for the re-introduction of the death penalty, the retention of blasphemy laws and her opposition to fox hunting.\n\nBorn in Bath, Somerset, Widdecombe is the daughter of Rita Noreen (née Plummer; 1911-2007) and Ministry of Defence civil servant James Murray Widdecombe. Widdecombe's maternal grandfather, James Henry Plummer, was born to an Irish Catholic family of English descent in Crosshaven, County Cork in 1874. She attended the Royal Naval School in Singapore, and La Sainte Union Convent School in Bath. She then read Latin at the University of Birmingham and later attended Lady Margaret Hall, Oxford, to read Philosophy, Politics and Economics (PPE). She worked for Unilever (1973–75) and then as an administrator at the University of London (1975–87) before entering Parliament.\n\nFrom 1976 to 1978, Widdecombe was a councillor on Runnymede District Council in Surrey. She contested the seat of Burnley in Lancashire in the 1979 general election and then, against David Owen, the Plymouth Devonport seat in the 1983 general election.\n\nShe was first elected to the House of Commons in the 1987 general election as member for the constituency of Maidstone (which became Maidstone and The Weald in 1997).\n\nAs an MP, Widdecombe expressed conservative views, including opposition to abortion; it was understood during her time in frontline politics that she would not become Health Secretary as long as this involved responsibility for abortions. Although a committed Christian, she has characterised the issue as one of life and death on which her view had been the same when she was agnostic. Along with John Gummer MP, she converted from the Church of England to the Catholic Church following the decision of the Church of England on the Ordination of women as priests. In her speech at the 2000 Conservative conference, she called for a zero tolerance policy of prosecution, with the punishment of £100 fines for users of cannabis. This was well received by rank-and-file Conservative delegates.\n\nWiddecombe consistently opposed LGBT equality. On the issue of an equal age of consent, she said in 2000: \"I do not believe that issues of equality should override the imperatives of protecting the young.\" In 2003, Widdecombe proposed an amendment opposing repeal of Section 28 of the Local Government Act, which banned the promotion of homosexuality by local governments. Out of the 17 parliamentary votes considered by the Public Whip website to concern equal rights for homosexuals, Widdecombe took the opposing position in 15 cases, not being present at the other two votes. Widdecombe has also expressed her opposition to same-sex marriage, introduced by David Cameron's government in 2014, claiming that \"the state must have a preferred model\" and \"a union that is generally open to procreation\".\n\nShe is a committed animal lover and one of the few Conservative MPs to have consistently voted for the ban on fox hunting. Widdecombe was among more than 20 high-profile people who signed a letter to Members of Parliament in 2015 to oppose David Cameron's plan to amend the Hunting Act 2004.\n\nShe has expressed a variety of views on scientific issues such as climate change but has been opposed to legislation reducing emissions. Her views on the subject appear to have hardened over time. In 2007, she wrote that she did not want to belittle the issue but was sceptical of the claims that specific actions would prevent catastrophe, then in 2008 that her doubts had been \"crystalised\" by Nigel Lawson's book \"An Appeal to Reason\", before stating in 2009 that \"There is no climate change, hasn’t anybody looked out of their window recently?\" She was one of the five MPs who voted against the Climate Change Act 2008. In 2011 she expressed the view that \"climate change money should go to armed services\". The previous year, she voted to support a parliamentary motion supporting homeopathy, criticizing the Science and Technology Committee's Report on the subject.\n\nOver the years, Widdecombe has expressed her support for a reintroduction of the death penalty, which was abolished in the UK in 1965. She notably spoke of her support for its reintroduction for the worst cases of murder in the aftermath of the murder of two 10-year-old girls from Soham, Cambridgeshire, in August 2002, in the Soham murders. She supported the argument that the death penalty would have deterrent value, as within five years of its abolition the national murder rate had more than doubled.\n\nWiddecombe joined John Major's government as Parliamentary Under-Secretary of State for Social Security in 1990. In 1993, she was moved to the Department of Employment, and she was promoted to Minister of State the following year. In 1995, she joined the Home Office as Minister of State for Prisons and visited every prison in Britain.\n\nAfter the fall of the Conservative government to Labour in 1997, she served as Shadow Health Secretary between 1998 and 1999 and later as Shadow Home Secretary between 1999 and 2001 under William Hague.\n\nDuring the 2001 Conservative leadership election, she could not find sufficient support amongst Conservative MPs for her leadership candidacy. She first supported Michael Ancram, who was eliminated in the first round, and then Kenneth Clarke, who lost in the final round. She afterwards declined to serve in Iain Duncan Smith's Shadow Cabinet (although she indicated on the television programme \"When Louis Met...\", prior to the leadership contest, that she wished to retire to the backbenches anyway).\n\nIn the 2005 leadership election, she initially supported Kenneth Clarke again. Once he was eliminated, she turned support towards Liam Fox. Following Fox's subsequent elimination, she took time to reflect before finally declaring for David Davis. She expressed reservations over the eventual winner David Cameron, feeling that he did not, like the other candidates, have a proven track record, and she was later a leading figure in parliamentary opposition to his A-List policy, which she has said is \"an insult to women\". At the October 2006 Conservative Conference, she was Chief Dragon in a political version of the television programme \"Dragons' Den\", in which A-list candidates were invited to put forward a policy proposal, which was then torn apart by her team of Rachel Elnaugh, Oliver Letwin and Michael Brown.\n\nIn an interview with \"Metro\" in September 2006 she stated that if Parliament were of a normal length, it was likely she would retire at the next general election. She confirmed her intention to stand down to \"The Observer\"'s Pendennis diary in September 2007, and again in October 2007 after Prime Minister Gordon Brown quashed speculation of an autumn 2007 general election.\n\nIn November 2006, she moved into the house of an Islington Labour Councillor to experience life on a council estate, her response to her experience being \"Five years ago I made a speech in the House of Commons about the forgotten decents. I have spent the last week on estates in the Islington area finding out that they are still forgotten.\"\n\nWiddecombe was one of the 98 MPs who voted to keep their expense details secret. When the expenses claims were leaked, however, Widdecombe was described by \"The Daily Telegraph\" as one of the \"saints\" amongst all MPs.\n\nIn May 2009, following the resignation of Michael Martin as Speaker of the House of Commons, it was reported that Widdecombe was gathering support for election as interim Speaker until the next general election. On 11 June 2009, she confirmed her bid to be the Speaker. She made it through to the second ballot but came last and was eliminated.\n\nWiddecombe retired from politics at the 2010 general election. It was rumoured that she would be a Conservative candidate for Police and Crime Commissioner in 2012, but she refused. She has since spoken about her opposition to the Coalition Government and her surprise at not being given a peerage by David Cameron.\n\nIn 2016, she backed Britain's withdrawal from the European Union during the 2016 EU referendum and, following the resignation of David Cameron, endorsed Andrea Leadsom in her candidacy for election for the leadership of the governing Conservative Party.\n\nUntil her retirement at the 2010 general election, Widdecombe divided her time between her two homes – one in London and one in the village of Sutton Valence, Kent, in her constituency. She sold both of these properties, however, upon deciding to retire at the next general election. She shared her home in London with her widowed mother, Rita Widdecombe, until Rita's death, on 25 April 2007, aged 95. In March 2008, she purchased a house in Haytor Vale, on Dartmoor in Devon, to where she has now retired. Her brother, Malcolm (1937–2010), who was an Anglican Canon in Bristol, retired in May 2009 and died of metastatic oesophageal cancer on 12 October 2010. Her nephew, Roger Widdecombe, is an Anglican priest.\n\nShe has never married nor had any children. In November 2007 on BBC Radio 4 she described how a journalist once produced a profile on her with the assumption that she had had at least \"one sexual relationship\", to which Widdecombe replied: \"Be careful, that's the way you get sued\". When interviewer Jenni Murray asked if she had ever had a sexual relationship, Widdecombe laughed \"it's nobody else's business\".\n\nWiddecombe has a fondness for cats and has a section of her website devoted to all the pet cats with which she has shared her life. In an interview, Widdecombe talked about her appreciation of music despite describing herself as \"pretty well tone-deaf\".\n\nHer non-political accomplishments include being a popular novelist. Widdecombe also currently writes a weekly column for the \"Daily Express\".\n\nIn January 2011 Widdecombe was joint President of the North of England Education Conference in Blackpool. She shared the responsibility with a young person from the town. She has also become a patron of The Grace Charity for M.E.\n\nWiddecombe revealed, in an April 2012 interview with Matt Chorley of \"The Independent\", that she was writing her autobiography, which she described as \"rude about all and sundry, but an amount of truth is always necessary\".\n\nWiddecombe is a Patron of the charity Safe Haven for Donkeys in the Holy Land (SHADH) and in 2014 visited the SHADH Donkey Sanctuary in Palestine.\n\nWiddecombe is a practising Roman Catholic. She converted in 1993 after leaving the Church of England. Her reasons for leaving the latter were many, as she explained to reporters from the \"New Statesman\":\n\nIn October 2006, she pledged to boycott British Airways for suspending a worker who refused to hide her cross. The matter was resolved when the company reversed the suspension.\n\nIn 2010, Widdecombe turned down an offer to be Britain's next ambassador to the Holy See, being prevented from accepting by suffering a detached retina. She was made a Dame of the Order of St. Gregory the Great by Pope Benedict XVI for services to politics and public life on 31 January 2013.\n\nIn 1990, following the assassination of the Conservative politician Ian Gow by the Provisional Irish Republican Army (IRA), the Eastbourne by-election for his seat in the House of Commons was won by the Liberal Democrat David Bellotti. Upon the announcement, Widdecombe told the voters that the IRA would be \"toasting their success\".\n\nIn 1996, Widdecombe, as prisons minister, defended the Government's policy to shackle pregnant prisoners with handcuffs and chains when in hospital receiving ante-natal care. Widdecombe told the Commons the restrictions were needed to prevent prisoners from escaping. \"Some MPs may like to think that a pregnant woman would not or could not escape. Unfortunately this is not true. The fact is that hospitals are not secure places in which to keep prisoners, and since 1990, 20 women have escaped from hospitals\". Jack Straw, Labour's Home Affairs spokesman at the time, said it was \"degrading and unnecessary\" for a woman to be shackled at any stage.\n\nIn 1997, during the Conservative leadership election of William Hague, Widdecombe spoke out against Michael Howard, under whom she had served when he was Home Secretary. She remarked in the House of Commons that there is \"something of the night\" about him. The remark was considered to be antisemitic by some and was damaging to Howard, who came last in the first round, an opinion both former ministers share. Howard still became party leader in 2003, and Widdecombe then stated, \"I explained fully what my objections were in 1997 and I do not retract anything I said then. But ... we have to look to the future and not the past.\"\n\nIn 2001, when Michael Portillo was running for leader of the Conservative Party, Widdecombe described him and his allies as \"backbiters\". She went on to say that, should he be appointed leader, she would never give him her allegiance.\n\nIn 2002, she took part in the ITV programme \"Celebrity Fit Club\". Also in 2002 she took part in a Louis Theroux television documentary, depicting her life, both in and out of politics. In March 2004 she briefly became \"The Guardian\" newspaper's agony aunt, introduced with an Emma Brockes interview. In 2005 BBC Two showed six episodes of \"The Widdecombe Project\", an agony aunt television programme. In 2005, she appeared in a new series of \"Celebrity Fit Club\", but this time as a panel member dispensing wisdom and advice to the celebrities taking part. Also in 2005, she presented the show \"Ann Widdecombe to the Rescue\" in which she acted as an agony aunt, dispensing no-nonsense advice to disputing families, couples, and others across the UK. In 2005, she also appeared in a discussion programme on Five to discuss who had been England's greatest monarch since the Norman Conquest; her choice of monarch was Charles II.\n\nShe was the guest host of news quiz \"Have I Got News for You\" twice, in 2006 and 2007. Following her second appearance, Widdecombe vowed she would never appear on the show again because of comments made by panellist Jimmy Carr. She wrote, \"His idea of wit is a barrage of filth and the sort of humour most men grow out of in their teens... [T]here's no amount of money for which I would go through those two recording hours again. At one stage I nearly walked out.\" She did, however, stand by her appraisal of regular panellists Ian Hislop and Paul Merton, whom she has called \"the fastest wits in showbusiness\".\n\nIn 2007, she awarded the \"University Challenge\" trophy to the winners. In the same year, she was cast as herself in \"The Sound of Drums\", the 12th episode of the third series of the science-fiction drama \"Doctor Who\" supporting Mr Saxon, the alias of the Master.\n\nSince 2007, Widdecombe has fronted a television series called \"Ann Widdecombe Versus\", on ITV1, in which she speaks to various people about things related to her as an MP, with an emphasis on confronting those responsible for problems she wished to tackle. On 15 August 2007 she talked about prostitution, the next week about benefits and the week after that about truancy. A fourth episode was screened on 18 September 2008 in which she travelled around London and Birmingham talking to girl gangs.\n\nIn 2009, Widdecombe appeared with Archbishop John Onaiyekan in an \"Intelligence Squared\" debate in which they defended the motion that the Catholic Church was a force for good. Arguing against the motion were Stephen Fry and Christopher Hitchens, who won the debate overall.\n\nIn October 2010, she appeared on BBC One's \"Strictly Come Dancing\", partnered by Anton du Beke, winning the support of some viewers despite low marks from the judges. After nine weeks of routines strongly flavoured by comedy the couple had received enough support in the public vote to stay in the contest. Widdecombe was eliminated from the competition on Sunday 5 December after the public vote had been combined with the judges' score; she was with Scott Maslen of \"EastEnders\" in the bottom two.\n\nIn 2012, Widdecombe hosted a new quiz show with herself as questionmaster, for the Sky Atlantic channel, called \"Cleverdicks\". The show ran for one series with 30 one-hour episodes. It featured four contestants, usually high quality members of the UK national quiz circuit and ended with a money round for the winner of each show.\n\nOn 23 April 2012, Widdecombe presented an hour-long documentary for BBC Radio 5 Live, \"Drunk Again: Ann Widdecombe Investigates\", looking at how the British attitude to getting drunk has changed over the last few years.\n\nIt was revealed in October 2012, that the year's Children in Need's appeal night will feature a \"Strictly Come Dancing\" special with former show favourites Russell Grant and Ann Widdecombe.\n\nOn 4 November 2012, Ann presented guest hosted one episode of BBC's \"Songs of Praise\" programme about singleness.\n\nIn October 2014, she appeared in the BBC series \"Celebrity Antiques Road Trip\", partnered with expert Mark Stacey, where the pair beat the rival team of Craig Revel Horwood and Catherine Southon.\n\nWiddecombe was a part of television series \"24 Hours in the Past\", along with Colin Jackson, Alistair McGowan, Miquita Oliver, Tyger Drew-Honey and Zoe Lucker. The 4 -part series was aired from 28 April–19 May 2015 on BBC One. She took part in an episode of \"\" in 2016. In 2017, Widdecombe took part in ITV's \"Sugar Free Farm\".\n\nFollowing her retirement, Widdecombe made her stage debut, on 9 December 2011, at The Orchard Theatre, Dartford in the Christmas pantomime \"Snow White and the Seven Dwarfs\", alongside \"Strictly Come Dancing\" judge Craig Revel Horwood. In April 2012, she had a ten-minute non-singing cameo part in Gaetano Donizetti's comic opera \"La Fille Du Regiment\", playing the Duchesse de Crackentorp. Ann reprised her pantomime performance, again with Revel Horwood, at The Swan Theatre, High Wycombe in December 2012.\n\n\n\n\n"}
{"id": "2425", "url": "https://en.wikipedia.org/wiki?curid=2425", "title": "Aurangzeb", "text": "Aurangzeb\n\nAbu'l Muzaffar Muhi-ud-Din Muhammad (3 November 1618 – 3 March 1707), commonly known as Aurangzeb or by his regnal title Alamgir (Persian: \"Conqueror of the World\"), was the sixth, and widely considered the last effective Mughal emperor. His reign lasted for 49 years from 1658 until his death in 1707.\n\nAurangzeb was a notable expansionist and during his reign, the Mughal Empire reached its greatest extent, ruling over nearly all of the Indian subcontinent. During his lifetime, victories in the south expanded the Mughal Empire to 4 million square kilometres, and he ruled over a population estimated to be over 158 million subjects, with an annual yearly revenue of $450 million (more than ten times that of his contemporary Louis XIV of France), or £38,624,680 (2,879,469,894 rupees) in 1690. Under his reign, India surpassed China to become the world's largest economy, worth over $90 billion, nearly a quarter of world GDP in 1700.\n\nAurangzeb is considered one of India's most controversial kings. Some historians argue that his policies abandoned his predecessors' legacy of pluralism and religious tolerance, citing his destruction of Hindu temples and execution of a Sikh guru, while other historians question this, arguing that his destruction of temples has been exaggerated and were politically motivated, and noting that he built more temples than he destroyed, also destroyed Islamic mosques, paid for the maintenance of temples, employed significantly more Hindus in his imperial bureaucracy than his predecessors did, and opposed bigotry against Hindus and Shia Muslims.\n\nIt was at the end of his reign that the downfall of the Mughal Empire began. Rebellions and wars eventually led to the exhaustion of the imperial Mughal treasury and army. He was a strong-handed authoritarian ruler, and following his death the expansionary period of the Mughal Empire came to an end. Nevertheless, the contiguous territory of the Mughal Empire still remained intact more or less until the reign of Muhammad Shah.\n\nAurangzeb was born on 3 November 1618, in Dahod, Gujarat. He was the third son and sixth child of Shah Jahan and Mumtaz Mahal.\nIn June 1626, after an unsuccessful rebellion by his father, Aurangzeb and his brother Dara Shikoh were kept as hostages under their grandparents' (Nur Jahan and Jahangir) Lahore court. On 26 February 1628, Shah Jahan was officially declared the Mughal Emperor, and Aurangzeb returned to live with his parents at Agra Fort, where Aurangzeb received his formal education in Arabic and Persian. His daily allowance was fixed at Rs. 500 which he spent on religious education and the study of history.\nOn 28 May 1633, Aurangzeb escaped death when a powerful war elephant stampeded through the Mughal Imperial encampment. He rode against the elephant and struck its trunk with a lance, and successfully defended himself from being crushed. Aurangzeb's valour was appreciated by his father who conferred him the title of \"Bahadur\" (Brave) and had him weighed in gold and presented gifts worth Rs. 200,000. This event was celebrated in Persian and Urdu verses and Aurangzeb said:\n\nAurangzeb was nominally in charge of the force sent to Bundelkhand with the intent of subduing the rebellious ruler of Orchha, Jhujhar Singh, who had attacked another territory in defiance of Shah Jahan's policy and was refusing to atone for his actions. By arrangement, Aurangzeb stayed in the rear, away from the fighting, and took the advice of his generals as the Mughal Army gathered and commenced the Siege of Orchha in 1635.The campaign was successful and Singh was removed from power.\n\nAurangzeb was appointed viceroy of the Deccan in 1636. After Shah Jahan's vassals had been devastated by the alarming expansion of Ahmednagar during the reign of the Nizam Shahi boy-prince Murtaza Shah III, the emperor dispatched Aurangzeb, who in 1636 brought the Nizam Shahi dynasty to an end. In 1637, Aurangzeb married the Safavid princess Dilras Banu Begum, posthumously known as Rabia-ud-Daurani. She was his first wife and chief consort as well as his favourite. He also had an infatuation with a slave girl, Hira Bai, whose death at a young age greatly affected him. In his old age, he was under the charms of his concubine, Udaipuri Bai. The latter had formerly been a companion to Dara Shikoh. In the same year, 1637, Aurangzeb was placed in charge of annexing the small Rajput kingdom of Baglana, which he did with ease.\n\nIn 1644, Aurangzeb's sister, Jahanara, was burned when the chemicals in her perfume were ignited by a nearby lamp while in Agra. This event precipitated a family crisis with political consequences. Aurangzeb suffered his father's displeasure by not returning to Agra immediately but rather three weeks later. Shah Jahan had been nursing Jahanara back to health in that time and thousands of vassals had arrived in Agra to pay their respects. Shah Jahan was outraged to see Aurangzeb enter the interior palace compound in military attire and immediately dismissed him from his position of viceroy of the Deccan; Aurangzeb was also no longer allowed to use red tents or to associate himself with the official military standard of the Mughal emperor. Other sources tell us that Aurangzeb was dismissed from his position because Aurangzeb left the life of luxury and became a Faqir.\n\nIn 1645, he was barred from the court for seven months and mentioned his grief to fellow Mughal commanders. Thereafter, Shah Jahan appointed him governor of Gujarat where he served well and was rewarded for bringing stability.\n\nIn 1647, Shah Jahan moved Aurangzeb from Gujarat to be governor of Balkh, replacing a younger son, Murad Baksh, who had proved ineffective there. The area was under attack from Uzbek and Turkmen tribes. Whilst the Mughal artillery and muskets were a formidable force, so too were the skirmishing skills of their opponents. The two sides were in stalemate and Aurangzeb discovered that his army could not live off the land, which was devastated by war. With the onset of winter, he and his father had to make a largely unsatisfactory deal with the Uzbeks, giving away territory in exchange for nominal recognition of Mughal sovereignty. The Mughal force suffered still further with attacks by Uzbeks and other tribesmen as it retreated through snow to Kabul. By the end of this two-year campaign, into which Aurangzeb had been plunged at a late stage, a vast sum of money had been expended for little gain.\n\nFurther inauspicious military involvements followed, as Aurangzeb was appointed governor of Multan and Sindh. His efforts in 1649 and 1652 to dislodge the Safavids at Kandahar, which they had recently retaken after a decade of Mughal control, both ended in failure as winter approached. The logistical problems of supplying an army at the extremity of the empire, combined with the poor quality of armaments and the intransigence of the opposition have been cited by John Richards as the reasons for failure, and a third attempt in 1653, led by Dara Shikoh, met with the same outcome.\n\nAurangzeb became viceroy of the Deccan again after he was replaced by Dara Shikoh in the attempt to recapture Kandahar. Aurangzeb regretted this and harboured feelings that Shikoh had manipulated the situation to serve his own ends. Aurangbad's two \"jagirs\" (land grants) were moved there as a consequence of his return and, because the Deccan was a relatively impoverished area, this caused him to lose out financially. So poor was the area that grants were required from Malwa and Gujarat in order to maintain the administration and the situation caused ill-feeling between father and son. Shah Jahan insisted that things could be improved if Aurangzeb made efforts to develop cultivation. Aurangzeb appointed Murshid Quli Khan to extend to the Deccan the \"zabt\" revenue system used in northern India. Murshid Quli Khan organised a survey of agricultural land and a tax assessment on what it produced. To increase revenue, Murshid Quli Khan granted loans for seed, livestock, and irrigation infrastructure. The Deccan returned to prosperity, but too slowly to satisfy the emperor.\n\nAurangzeb proposed to resolve the situation by attacking the dynastic occupants of Golconda (the Qutb Shahis) and Bijapur (the Adil Shahis). As an adjunct to resolving the financial difficulties, the proposal would also extend Mughal influence by accruing more lands. Again, he was to feel that Dara had exerted influence on his father: believing that he was on the verge of victory in both instances, Aurangzeb was frustrated that Shah Jahan chose then to settle for negotiations with the opposing forces rather than pushing for complete victory.\n\nThe four sons of Shah Jahan all held governorships during their father's reign. The emperor favoured the eldest, Dara Shikoh. This had caused resentment among the younger three, who sought at various times to strengthen alliances between themselves and against Dara. There was no Mughal tradition of primogeniture, the systematic passing of rule, upon an emperor's death, to his eldest son. Instead it was customary for sons to overthrow their father and for brothers to war to the death among themselves. Historian Satish Chandra says that \"In the ultimate resort, connections among the powerful military leaders, and military strength and capacity [were] the real arbiters\". The contest for power was primarily between Dara Shikoh and Aurangzeb because, although all four sons had demonstrated competence in their official roles, it was around these two that the supporting cast of officials and other influential people mostly circulated. There were ideological differences — Dara was an intellectual and a religious liberal in the mould of Akbar, while Aurangzeb was much more conservative — but, as historians Barbara D. Metcalf and Thomas R. Metcalf say, \"To focus on divergent philosophies neglects the fact that Dara was a poor general and leader. It also ignores the fact that factional lines in the succession dispute were not, by and large, shaped by ideology.\" Marc Gaborieau, professor of Indian studies at l'École des Hautes Études en Sciences Sociales, explains that \"The loyalties of [officials and their armed contingents] seem to have been motivated more by their own interests, the closeness of the family relation and above all the charisma of the pretenders than by ideological divides.\" Muslims and Hindus did not divide along religious lines in their support for one pretender or the other nor, according to Chandra, is there much evidence to support the belief that Jahanara and other members of the royal family were split in their support. Jahanara, certainly, interceded at various times on behalf of all of the princes and was well-regarded by Aurangzeb even though she shared the religious outlook of Dara.\n\nIn 1656, a general under Qutb Shahi dynasty named Musa Khan led an army of 12,000 Musketeers to attack Aurangzeb, and later on the same campaign Aurangzeb in turn rode against an army consisting 8,000 horsemen and 20,000 Karnataka Musketeers\n\nHaving made clear that he wanted Dara to succeed him, Shah Jahan became ill with stranguary in 1657 and was closeted under the care of his favourite son in the newly built city of Shahjahanabad (Old Delhi). Rumours of the death of Shah Jahan abounded and the younger sons were concerned that Dara might be hiding it for Machiavellian reasons. Thus, they took action: Shah Shuja prepared to contest the throne from Bengal, where he had been governor since 1637, while Murad did the same in his governorship of Gujarat and Aurangzeb did so in the Deccan. It is not known whether these preparations were made in the mistaken belief that the rumours of death were true or whether the challengers were just taking advantage of the situation.\n\nAfter regaining some of his health, Shah Jahan moved to Agra and Dara urged him to send forces to challenge Shah Shuja and Murad, who had declared themselves rulers in their respective territories. While Shah Shuja was defeated at Banares in February 1658, the army sent to deal with Murad discovered to their surprise that he and Aurangzeb had combined their forces, the two brothers having agreed to partition the empire once they had gained control of it. The two armies clashed at Dharmat in April 1658, with Aurangzeb being the victor. Shuja was being chased through Bihar and the victory of Aurangzeb proved this to be a poor decision by Dara Shikoh, who now had a defeated force on one front and a successful force unnecessarily pre-occupied on another. Realising that his recalled Bihar forces would not arrive at Agra in time to resist the emboldened Aurangzeb's advance, Dara scrambled to form alliances in order but found that Aurangzeb had already courted key potential candidates. When Dara's disparate, hastily concocted army clashed with Aurangzeb's well-disciplined, battle-hardened force at the Battle of Samugarh in late May, neither Dara's men nor his generalship were any match for Aurangzeb. Dara had also become over-confident in his own abilities and, by ignoring advice not to lead in battle while his father was alive, he cemented the idea that he had usurped the throne. \"After the defeat of Dara, Shah Jahan was imprisoned in the fort of Agra where he spent eight long years under the care of his favourite daughter Jahanara.\"\n\nAurangzeb then broke his arrangement with Murad Baksh, which probably had been his intention all along. Instead of looking to partition the empire between himself and Murad, he had his brother arrested and imprisoned at Gwalior Fort. Murad was executed on 4 December 1661, ostensibly for the murder of the \"diwan\" of Gujarat some time earlier. The allegation was encouraged by Aurangzeb, who caused the \"diwan's\" son to seek retribution for the death under the principles of Sharia law. Meanwhile, Dara gathered his forces, and moved to the Punjab. The army sent against Shuja was trapped in the east, its generals Jai Singh and Dilir Khan submitted to Aurangzeb, but Dara's son, Suleiman Shikoh, escaped. Aurangzeb offered Shah Shuja the governorship of Bengal. This move had the effect of isolating Dara Shikoh and causing more troops to defect to Aurangzeb. Shah Shuja, who had declared himself emperor in Bengal began to annex more territory and this prompted Aurangzeb to march from Punjab with a new and large army that fought during the Battle of Khajwa, where Shah Shuja and his chain-mail armoured war elephants were routed by the forces loyal to Aurangzeb. Shah Shuja then fled to Arakan (in present-day Burma), where he was executed by the local rulers.\n\nWith Shuja and Murad disposed of, and with his father immured in Agra, Aurangzeb pursued Dara Shikoh, chasing him across the north-western bounds of the empire. Aurangzeb claimed that Dara was no longer a Muslim and accused him of poisoning the Mughal Grand Vizier Saadullah Khan. Both of these statements however lacked any evidence. After a series of battles, defeats and retreats, Dara was betrayed by one of his generals, who arrested and bound him. In 1658, Aurangzeb arranged his formal coronation in Delhi.\n\nOn 10 August 1659, Dara was executed on grounds of apostasy and his head was sent to Shahjahan. Having secured his position, Aurangzeb confined his frail father at the Agra Fort but did not mistreat him. Shah Jahan was cared for by Jahanara and died in 1666.\n\nAurangzeb's imperial bureaucracy employed significantly more Hindus than that of his predecessors. Between 1679 and 1707, the number of Hindu officials in the Mughal administration rose by half, many of them Marathas and Rajputs. His increasing employment of Hindus and Shia Muslims was deemed controversial at the time, with several of his fellow Sunni Muslim officials petitioning against it, which he rejected, and responded, \"What connection have earthly affairs with religion? And what right have administrative works to meddle with bigotry? 'For you is your religion and for me is mine.'\" He insisted on employment based on ability rather than religion.\n\nUnder Aurangzeb's reign, Hindus rose to represent 31.6% of Mughal nobility, the highest in the Mughal era. This was largely due to a substantial influx of Marathas, who played a key role in his successful Deccan campaign. During his time, the number of Hindu Mansabdars increased from 22% to over 31% in the Mughal administration, as he needed them to continue his fight in the Deccan. However, one of his Rajput nobles, Jaswant Singh of Jodhpur, Hindu ruler of Jodhpur, “destroyed mosques and built idol-temples in their stead” around 1658-1659, according to Aurangzeb. Despite this, relationships did not turn sour between the two, as they worked together for the next two decades up until Singh's death in the late 1670s.\n\nHistorian Katherine Brown has noted that \"The very name of Aurangzeb seems to act in the popular imagination as a signifier of politico-religious bigotry and repression, regardless of historical accuracy.\" The subject is controversial and, despite no proof, has resonated in modern times with popularly accepted claims that he intended to destroy the Bamiyan Buddhas. As a political and religious conservative, Aurangzeb chose not to follow the liberal religious viewpoints of his predecessors after his ascension. Shah Jahan had already moved away from the liberalism of Akbar, although in a token manner rather than with the intent of suppressing Hinduism, and Aurangzeb took the change still further. Though the approach to faith of Akbar, Jahangir and Shah Jahan was more syncretic than Babur, the founder of the empire, Aurangzeb's position is not so obvious. His emphasis on sharia competed, or was directly in conflict, with his insistence that \"zawabit\" or secular decrees could supersede sharia. Despite claims of sweeping edicts and policies, contradictory accounts exist. He sought to codify Hanafi law by the work of several hundred jurists, called Fatawa-e-Alamgiri. It is possible the War of Succession and continued incursions combined with Shah Jahan's spending made cultural expenditure impossible.\n\nAs emperor, Aurangzeb banned the drinking of alcohol, gambling, castration, servitude, eunuchs, music, nautch and narcotics in the Mughal Empire. He learnt that at Sindh, Multan, Thatta and particularly at Varanasi, the Hindu Brahmins attracted large numbers of indigenous local Muslims to their discourses. He ordered the Subahdars of these provinces to demolish the schools and the temples of non-Muslims. Aurangzeb also ordered Subahdars to punish Muslims who dressed like non-Muslims. The executions of the antinomian Sufi mystic Sarmad Kashani and the ninth Sikh Guru Tegh Bahadur bear testimony to Aurangzeb's religious policy; the former was beheaded on multiple accounts of heresy, the latter, according to Sikhs, because he objected to Aurangzeb's forced conversions.\n\nHe imposed Jizya, a military tax on non-Muslims who were not fighting for Mughal Empire in his second decade on ruling in the year 1679. Further, Aurangzeb levied discriminatory taxes on Hindu merchants at the rate of 5% as against 2.5% on Muslim merchants. He ordered to dismiss Hindu \"quanungos\" and \"patwaris\" from revenue administration. However, he also employed many Hindus as Jizya tax collectors.\n\nThe introduction of Jizya in 1679 was a response to several events shortly before its introduction: the great Rajput rebellion of 1678, the Maratha alliance with the Shia Golconda, and the Mughal expansion into the Deccan. However, the contemporary historian Khafi Khan (died 1733), whose family had served Aurangzeb, noted that Jizya could not be levied and remained largely a tax on paper only.\n\nDuring his reign, Aurangzeb generally maintained a similar policy on both Hindu temples and Islamic mosques. Like his predecessors, he issued land grants for the maintenance of Hindu temples. However, he also ordered the destruction of temples and mosques. For example, he ordered the destruction of Vishvanath Temple at Varanasi for being a centre of conspiracy against the state, and he ordered the destruction of the Jama Masjid at Golkunda after finding out that its ruler had built the mosque in order to hide revenues from the state. Aurangzeb also ordered a rescue raid on a temple, in order to rescue a Rajasthan minister's female family members who went there on a pilgrimage.\n\nAurangzeb's policy on temples was mixed: he destroyed many, but also built many, building more temples than he destroyed. During his reign, 15 temples were destroyed. Indian historian Harbans Mukhia wrote: \"In the end, as recently recorded in Richard Eaton's careful tabulation, some 80 temples were demolished between 1192 and 1760 (15 in Aurangzeb's reign) and he compares this figure with the claim of 60,000 demolitions, advanced rather nonchalantly by 'Hindu nationalist' propagandists, although even in that camp professional historians are slightly more moderate.\" Among the Hindu temples he demolished were three of the most sacred, the Kashi Vishwanath temple, Kesava Deo temple, and Somnath temple, and built large mosques in their place. In 1679, he ordered destruction of several prominent temples that had become associated with his enemies: these included the temples of Khandela, Udaipur, Chittor and Jodhpur. The historian Richard Eaton argues that the overall understanding of temples to be flawed. As early as the sixth century, temples became vital political landmarks as well as religious ones. He writes that, not only was temple desecration widely practised and accepted, it was a necessary part of political struggle.\n\nOther scholars point out that Aurangzeb also built many temples; Ian Copland says that he built more temples than he destroyed. Ram Puniyani states that Aurangzeb was not always fanatically anti-Hindu, and kept changing his policies depending on the needs of the situation. He banned the construction of new temples, but permitted the repair and maintenance of existing temples. He also made generous donations of \"jagirs\" to several temples to win the sympathies of his Hindu subjects. There are several \"firman\"s (orders) in his name, supporting temples and gurudwaras, including Mahakaleshwar temple of Ujjain, Balaji temple of Chitrakoot, Umananda Temple of Guwahati and the Shatrunjaya Jain temples.\n\nThe first prominent execution during the long reign of Aurangzeb started with that of his brother Prince Dara Shikoh, who was accused of being influenced by Hinduism although some sources argue it was done for political reasons. Aurangzeb had his allied brother Prince Murad Baksh held for murder, judged and then executed. Aurangzeb is accused of poisoning his imprisoned nephew Sulaiman Shikoh.\n\nLater, Sambhaji was executed during his reign. In a trial, he was found guilty of murder and violence, atrocities against the Muslims of Burhanpur and Bahadurpur in Berar by Marathas under his command. The atrocities that Sambhaji perpetrated included plunder, killing, rape, and torture, when he raided Burhanpur with 20,000 troops. The ulema of the Mughal Empire sentenced him to death for his atrocities against Muslims.\n\nThe Sikh leader Guru Tegh Bahadur was arrested on orders by Aurangzeb, found guilty of blasphemy by a Qadi's court and executed.\n\n32 nd Da'i al-Mutlaq (Absolute Missionary) of the Dawoodi Bohra sect of Musta‘lī Islam Syedna Qutubkhan Qutubuddin was executed by Aurangzeb, then governor of Gujarat, for heresy; on 27 Jumadil Akhir 1056 AH/ 1648 AD), Ahmedabad, India.\n\nThroughout his reign, Aurangzeb engaged in almost constant warfare. He built up a massive army and began a program of military expansion along all the boundaries of his empire. He pushed north-west into the Punjab and also drove south, conquering two further Muslim kingdoms - the Adil Shahis of Bijapur and Qutbshahis of Golconda — to add to the defeat of the Ahmednagar Sultanate that had been accomplished in 1636 while he had been viceroy of the Deccan. These new territories were administered by the Mughal Nawabs loyal to Aurangzeb.\n\nSoon after seizing the throne, Aurangzeb began advancements against the unruly Sultan of Bijapur and during 1657, the Mughals are known to have utilised rockets during the Siege of Bidar, against Sidi Marjan. Aurangzeb's forces discharged rockets and grenades while scaling the walls, and Sidi Marjan himself was mortally wounded after a rocket struck his large gunpowder depot. After twenty-seven days of hard fighting, Bidar was captured by the Mughals.\n\nIn 1663, during his visit to Ladakh, Aurangzeb established direct control over that part of the empire and loyal subjects such as Deldan Namgyal agreed to pledge tribute and loyalty. Deldan Namgyal is also known to have constructed a Grand Mosque in Leh, which he dedicated to Mughal rule.\n\nIn 1664, Aurangzeb appointed Shaista Khan subedar (governor) of Bengal. Shaista Khan eliminated Portuguese and Arakanese pirates from the region, and in 1666 recaptured the port of Chittagong from the Arakanese king, Sanda Thudhamma. Chittagong remained a key port throughout Mughal rule.\n\nIn 1685, Aurangzeb dispatched his son, Muhammad Azam Shah, with a force of nearly 50,000 men to capture Bijapur Fort and defeat Sikandar Adil Shah (the ruler of Bijapur) who refused to be a vassal. The Mughals could not make any advancements upon Bijapur Fort mainly because of the superior usage of cannon batteries on both sides. Outraged by the stalemate Aurangzeb himself arrived on 4 September 1686 and commanded the Siege of Bijapur; after eight days of fighting, the Mughals were victorious.\n\nOnly one remaining ruler, Abul Hasan Qutb Shah (the Qutbshahi ruler of Golconda), refused to surrender. He and his servicemen fortified themselves at Golconda and fiercely protected the Kollur Mine, which was then probably the world's most productive diamond mine, and an important economic asset. In 1687, Aurangzeb led his grand Mughal army against the Deccan Qutbshahi fortress during the Siege of Golconda. The Qutbshahis had constructed massive fortifications throughout successive generations on a granite hill over 400 ft high with an enormous eight-mile long wall enclosing the city. The main gates of Golconda had the ability to repulse any war elephant attack. Although the Qutbshahis maintained the impregnability of their walls, at night Aurangzeb and his infantry erected complex scaffolding that allowed them to scale the high walls. During the eight-month siege the Mughals faced many hardships including the death of their experienced commander Kilich Khan Bahadur. Eventually, Aurangzeb and his forces managed to penetrate the walls by capturing a gate, and their entry into the fort led Abul Hasan Qutb Shah to surrender peacefully.\n\nMughal cannon making skills advanced during the 17th century. One of the most impressive Mughal cannons is known as the Zafarbaksh, which is a very rare \"composite cannon\", that required skills in both wrought-iron forge welding and bronze-casting technologies and the in-depth knowledge of the qualities of both metals.\n\nAurangzeb military entourage consisted of 16 cannons including the \"Azdaha Paikar\" (which, was capable of firing a 33.5 kg ordnance) and \"Fateh Rahber\" (20 feet long with Persian and Arabic inscriptions).\n\nThe \"Ibrahim Rauza\" was also a famed cannon, which was well known for its multi-barrels. François Bernier, the personal physician to Aurangzeb, observed versatile Mughal gun-carriages each drawn by two horses.\n\nDespite these innovations, most soldiers used bows and arrows, the quality of sword manufacture was so poor that they preferred to use ones imported from England, and the operation of the cannons was entrusted not to Mughals but to European gunners. Other weapons used during the period included rockets, cauldrons of boiling oil, muskets and manjaniqs (stone-throwing catapults).\n\nInfantry who were later called Sepoy and who specialised in siege and artillery emerged during the reign of Aurangzeb\n\nIn 1703, the Mughal commander at Coromandel, Daud Khan Panni spent 10,500 coins to purchase 30 to 50 war elephants from Ceylon.\n\nAurangzeb was known to be of a more austere nature than his predecessors. Being religious he encouraged Islamic calligraphy. His reign also saw the building of the Lahore badshahi Mosque, and Bibi ka Maqbara in Aurangabad for his wife Rabia-ud-Daurani.\n\nThe Mughal Emperor Aurangzeb is known to have patronised works of Islamic Calligraphy during his reign particularly Syed Ali Tabrizi.\n\nUnlike his father, Aurangzeb was not much interested in architecture. Aurangzeb constructed a small marble mosque known as the Moti Masjid (Pearl Mosque) in the Red Fort complex in Delhi. He ordered the construction of the Badshahi Mosque in Lahore. He also constructed a mosque on Benares. The mosque he constructed in Srinagar is still the largest in Kashmir. The structure of Bibi Ka Maqbara in Aurangabad, which now is a historical monument was constructed by the sons of Aurangzeb in remembrance of their mother. The inspiration came from Taj mahal as is quite visible from its architecture.\n\nThe textile industry in the Mughal Empire emerged very firmly during the reign of the Mughal Emperor Aurangzeb and was particularly well noted by Francois Bernier, a French physician of the Mughal Emperor. Francois Bernier writes how \"Karkanahs\", or workshops for the artisans, particularly in textiles flourished by \"employing hundreds of embroiderers, who were superintended by a master\". He further writes how \"Artisans manufacture of silk, fine brocade, and other fine muslins, of which are made turbans, robes of gold flowers, and tunics worn by females, so delicately fine as to wear out in one night, and cost even more if they were well embroidered with fine needlework\".\n\nHe also explains the different techniques employed to produce such complicated textiles such as \"Himru\" (whose name is Persian for \"brocade\"), \"Paithani\" (whose pattern is identical on both sides), \"Mushru\" (satin weave) and how \"Kalamkari\", in which fabrics are painted or block-printed, was a technique that originally came from Persia. Francois Bernier provided some of the first, impressive descriptions of the designs and the soft, delicate texture of Pashmina Shawls also known as \"Kani\", which were very valued for their warmth and comfort among the Mughals, and how these textiles and shawls eventually began to find their way to France and England.\n\nAs soon as he became emperor, Aurangzeb sent some of the finest ornate gifts such as carpets, lamps, tiles and others to the Islamic shrines at Mecca and Medina. He also ordered the construction of very large ships in Surat that would transport these gifts and even pilgrims to the Hijaz. These annual expeditions organised by Aurangzeb were led by Mir Aziz Badakhshi who died in Mecca of natural causes but managed to deliver more than 45,000 silver coins and several thousand Kaftans of honour.\n\nSubhan Quli, Balkh's Uzbek ruler was the first to recognise him in 1658 and requested for a general alliance, he worked alongside the new Mughal Emperor since 1647, when Aurangzeb was the Subedar of Balkh.\n\nAurangzeb received the embassy of Abbas II of Persia in 1660 and returned them with gifts. However relations between the Mughal Empire and the Safavid dynasty were tense because the Persians attacked the Mughal army positioned near Kandahar. Aurangzeb prepared his armies in the Indus River Basin for a counteroffensive, but Abbas II's death in 1666 caused Aurangzeb to end all hostilities. Aurangzeb's rebellious son, Sultan Muhammad Akbar, sought refuge with Suleiman I of Persia, who had rescued him from the Imam of Musqat and later refused to assist him in any military adventures against Aurangzeb.\n\nIn 1667, the French East India Company ambassadors Le Gouz and Bebert presented Louis XIV of France's letter which urged the protection of French merchants from various rebels in the Deccan. In response to the letter Aurangzeb issued a Firman allowing the French to open a factory in Surat.\n\nIn the 1660s, the Sultan of the Maldives, Ibrahim Iskandar I, requested help from Aurangzeb's representative, the Faujdar of Balasore. The sultan was concerned about the impact of Dutch and English trading ships but the powers of Aurangzeb did not extend to the seas, the Maldives were not under his governance and nothing came of the request.\n\nIn 1688, the desperate Ottoman Sultan Suleiman II urgently requested for assistance against the rapidly advancing Austrians, during the Ottoman–Habsburg War. However, Aurangzeb and his forces were heavily engaged in the Deccan Wars against the Marathas to commit any formal assistance to their Ottoman allies.\n\nIn 1686, the English East India Company, which had unsuccessfully tried to obtain a firman, an imperial directive that would grant England regular trading privileges throughout the Mughal empire, initiated the so-called Child's War. This hostility against the empire ended in disaster for the English, particularly when Aurangzeb dispatched a strong fleet from Janjira commanded by the Sidi Yaqub and manned by Mappila loyal to Ali Raja Ali II and Abyssinian sailors firmly blockaded Bombay in 1689. In 1690, the company sent envoys to Aurangzeb's camp to plead for a pardon. The company's envoys had to prostrate themselves before the emperor, pay a large indemnity, and promise better behaviour in the future.\n\nIn September 1695, English pirate Henry Every perpetrated one of the most profitable pirate raids in history with his capture of a Grand Mughal convoy near Surat. The Indian ships had been returning home from their annual pilgrimage to Mecca when the pirates struck, capturing the \"Ganj-i-Sawai\", reportedly the greatest ship in the Muslim fleet, and its escorts in the process. When news of the piracy reached the mainland, a livid Aurangzeb nearly ordered an armed attack against the English-governed city of Bombay, though he finally agreed to compromise after the East India Company promised to pay financial reparations, estimated at £600,000 by the Mughal authorities. Meanwhile, Aurangzeb shut down four of the East India Company's factories, imprisoned the workers and captains (who were nearly lynched by a rioting mob), and threatened to put an end to all English trading in India until Every was captured. The Privy Council and East India Company offered a massive bounty for Every's apprehension, leading to the first worldwide manhunt in recorded history. However, Every successfully eluded capture.\n\nIn 1702, Aurangzeb sent Daud Khan Panni, the Mughal Empire's Subhedar of the Carnatic region, to besiege and blockade Fort St. George for more than three months. The governor of the fort Thomas Pitt was instructed by the English East India Company to sue for peace.\n\nAurangzeb's exchequer raised a record £100 million in annual revenue through various sources like taxes, customs and land revenue, \"et al.\" from 24 provinces. He had an annual yearly revenue of $450 million, more than ten times that of his contemporary Louis XIV of France.\n\nAurangzeb felt that verses from the \"Quran\" should not be stamped on coins, as done in former times, because they were constantly touched by the hands and feet of people. His coins had the name of the mint city and the year of issue on one face, and, the following couplet on other:\n\nBy 1700, the Marathas attacked the Mughal provinces from the Deccan and secessionist agendas from the Rajputs, Hindu Jats, Pashtuns and Sikhs rebelled against the Mughal Empire's administrative and economic systems.\n\nIn 1669, Hindu Jats began to organise a rebellion that is believed to have been caused by Aurangzeb's imposition of Jizya (a form of organised religious taxation). The Jats were led by \"Gokula\", a rebel landholder from Tilpat. By the year 1670 20,000 Jat rebels were quelled and the Mughal Army took control of Tilpat, Gokula's personal fortune amounted to 93,000 gold coins and hundreds of thousands of silver coins.\n\nGokula was caught and executed. But the Jats continued to terrorise the Mughals and attacked Akbar's mausoleum the gold, silver and fine carpets within the tomb . There are claims that Jats caused two large silver doors at the entrance of the Taj Mahal to be stolen and melted down. However, Jats later established their independent state of Bharatpur.\n\nIn 1657, while Aurangzeb attacked Golconda and Bijapur in the Deccan, the Hindu Maratha warrior aristocrat, Shivaji, used guerrilla tactics to take control of three Adil Shahi forts formerly under his father's command. With these victories, Shivaji assumed de facto leadership of many independent Maratha clans. The Marathas harried the flanks of the warring Adil Shahis and Mughals, gaining weapons, forts, and territory. Shivaji's small and ill-equipped army survived an all out Adil Shahi attack, and Shivaji personally killed the Adil Shahi general, Afzal Khan. With this event, the Marathas transformed into a powerful military force, capturing more and more Adil Shahi and Mughal territories. Shivaji went on to neutralise Mughal power in the region.\n\nIn 1659, Aurangzeb sent his trusted general and maternal uncle Shaista Khan, the Wali in Golconda to recover forts lost to the Maratha rebels. Shaista Khan drove into Maratha territory and took up residence in Pune. But in a daring raid on the governor's palace in Pune during a midnight wedding celebration, the Marathas killed Shaista Khan's son and maimed Shaista Khan by cutting off the fingers of his hand. Shaista Khan, however, survived and was re-appointed the administrator of Bengal going on to become a key commander in the war against the Ahoms.\n\nShivaji captured forts belonging to both Mughals and Bijapur. At last Aurangzeb ordered the armament of the Daulatabad Fort with two bombards (the Daulatabad Fort was later utilised as a Mughal bastion during the Deccan Wars). Aurangzeb also sent his general Raja Jai Singh of Amber, a Hindu Rajput, to attack the Marathas. Jai Singh won the fort of Purandar after fierce battle in which the Maratha commander Murarbaji fell. Foreseeing defeat, Shivaji agreed for a truce and a meeting with Aurangzeb at Delhi. Jai Singh also promised Shivaji his safety, placing him under the care of his own son, the future Raja Ram Singh I. However, circumstances at the Mughal court were beyond the control of the Raja, and when Shivaji and his son Sambhaji went to Agra to meet Aurangzeb, they were placed under house arrest, from which they managed to effect a daring escape.\n\nShivaji returned to the Deccan, and crowned himself \"Chhatrapati\" or the ruler of the Maratha Kingdom in 1674. While Aurangzeb continued to send troops against him, Shivaji expanded Maratha control throughout the Deccan until his death in 1680. Shivaji was succeeded by his son, Sambhaji. Militarily and politically, Mughal efforts to control the Deccan continued to fail.\n\nOn the other hand, Aurangzeb's third son Akbar left the Mughal court along with a few Muslim Mansabdar supporters and joined Muslim rebels in the Deccan. Aurangzeb in response moved his court to Aurangabad and took over command of the Deccan campaign. The rebels were defeated and Akbar fled south to seek refuge with Sambhaji, Shivaji's successor. More battles ensued, and Akbar fled to Persia and never returned.\n\nIn 1689, Aurangzeb's forces captured and executed Sambhaji. His successor Rajaram, later Rajaram's widow Tarabai and their Maratha forces fought individual battles against the forces of the Mughal Empire. Territory changed hands repeatedly during the years (1689–1707) of interminable warfare . As there was no central authority among the Marathas, Aurangzeb was forced to contest every inch of territory, at great cost in lives and money. Even as Aurangzeb drove west, deep into Maratha territory – notably conquering Satara — the Marathas expanded their attacks further into Mughal lands – Malwa, Hyderabad and Jinji in Tamil Nadu. Aurangzeb waged continuous war in the Deccan for more than two decades with no resolution. He thus lost about a fifth of his army fighting rebellions led by the Marathas in Deccan India. He travelled a long distance to the Deccan to conquer the Marathas and eventually died at the age of 90, still fighting the Marathas.\n\nAurangzeb's shift from conventional warfare to anti-insurgency in the Deccan region shifted the paradigm of Mughal military thought. There were conflicts between Marathas and Mughals in Pune, Jinji, Malwa and Vadodara. The Mughal Empire's port city of Surat was sacked twice by the Marathas during the reign of Aurangzeb and the valuable port was in ruins.\n\nWhile Aurangzeb and his brother Shah Shuja had been fighting against each other, the Hindu rulers of Kuch Behar and Assam took advantage of the disturbed conditions in the Mughal Empire, had invaded imperial dominions. For three years they were not attacked, but in 1660 Mir Jumla II, the viceroy of Bengal, was ordered to recover the lost territories.\n\nThe Mughals set out in November 1661, and within weeks occupied the capital of Kuch Behar after a few fierce skirmishes. The Kuch Behar was annexed, and the Mughal Army reorganised and began to retake their territories in Assam. Mir Jumla II's forces captured Pandu, Guwahati, and Kajali practically unopposed. In February 1662, Mir Jumla II initiated the Siege of Simalugarh and after the Mughal cannon breached the fortifications, the Ahoms abandoned the fort and escaped. Mir Jumla II then proceeded towards Garhgaon the capital of the Ahom kingdom, which was reached on 17 March 1662, although the ruler Raja Sutamla fled and the victorious Mughals captured 100 elephants, about 300,000 coins of silver, 8000 shields, 1000 ships, and 173 massive stores of rice.\n\nLater that year in December 1663, the aged Mir Jumla II died on his way back to Dacca of natural causes, but skirmishes continued between the Mughals and Ahoms after the rise of Chakradhwaj Singha, who refused to pay further indemnity to the Mughals and during the wars that continued the Mughals suffered great hardships. Munnawar Khan emerged as a leading figure and is known to have supplied food to vulnerable Mughal forces in the region near Mathurapur. Although the Mughals under the command of Syed Firoz Khan the Faujdar at Guwahati were overrun by two Ahom armies in the year 1667, but they continued to hold and maintain presence along their the eastern territories even after the Battle of Saraighat in the year 1671.\n\nThe Battle of Saraighat was fought in 1671 between the Mughal empire (led by the Kachwaha king, Raja Ramsingh I), and the Ahom Kingdom (led by Lachit Borphukan) on the Brahmaputra river at Saraighat, now in Guwahati. Although much weaker, the Ahom Army defeated the Mughal Army by brilliant uses of the terrain, clever diplomatic negotiations to buy time, guerrilla tactics, psychological warfare, military intelligence and by exploiting the sole weakness of the Mughal forces—its navy.\n\nThe Battle of Saraighat was the last battle in the last major attempt by the Mughals to extend their empire into Assam. Though the Mughals managed to regain Guwahati briefly after a later Borphukan deserted it, the Ahoms wrested control in the Battle of Itakhuli in 1682 and maintained it till the end of their rule.\n\nIn May 1672, the Satnami sect obeying the commandments of an \"old toothless woman\" (according to Mughal accounts) organised a massive revolt in the agricultural heartlands of the Mughal Empire. The Satnamis were known to have shaved off their heads and even eyebrows and had temples in many regions of Northern India. They began a large-scale rebellion 75 miles southwest of Delhi.\n\nThe Satnamis believed they were invulnerable to Mughal bullets and believed they could multiply in any region they entered. The Satnamis initiated their march upon Delhi and overran small-scale Mughal infantry units.\n\nAurangzeb responded by organising a Mughal army of 10,000 troops and artillery, and dispatched detachments of his own personal Mughal imperial guards to carry out several tasks. To boost Mughal morale, Aurangzeb wrote Islamic prayers, made amulets, and drew designs that would become emblems in the Mughal Army. This rebellion would have a serious aftermath effect on the Punjab.\n\nEarly in Aurangzeb's reign, various insurgent groups of Sikhs engaged Mughal troops in increasingly bloody battles. The ninth Sikh Guru, Guru Tegh Bahadur, like his predecessors was opposed to conversion of the local population as he considered it wrong. According to Sikh sources, approached by Kashmiri Pandits to help them retain their faith and avoid forced religious conversions, Guru Tegh Bahadur took on Aurangzeb. The emperor perceived the rising popularity of the Guru as a threat to his sovereignty and in 1670 had him executed, which infuriated the Sikhs. In response, Guru Tegh Bahadur's son and successor, Guru Gobind Singh, further militarised his followers, starting with the establishment of Khalsa in 1699, eight years before Aurangzeb's death. In 1705, Guru Gobind Singh sent a letter entitled \"Zafarnamah\" to Aurangzeb. This drew attention to Auranzeb's cruelty and how he had betrayed Islam. The letter caused him much distress and remorse. Guru Gobind Singh's formation of Khalsa in 1699 led to the establishment of the Sikh Confederacy and later Sikh Empire.\n\nThe Pashtun revolt in 1672 under the leadership of the warrior poet Khushal Khan Khattak of Kabul, was triggered when soldiers under the orders of the Mughal Governor Amir Khan allegedly molested women of the Pashtun tribes in modern-day Kunar Province of Afghanistan. The Safi tribes retaliated against the soldiers. This attack provoked a reprisal, which triggered a general revolt of most of tribes. Attempting to reassert his authority, Amir Khan led a large Mughal Army to the Khyber Pass, where the army was surrounded by tribesmen and routed, with only four men, including the Governor, managing to escape.\n\nAfter that the revolt spread, with the Mughals suffering a near total collapse of their authority in the Pashtun belt. The closure of the important Attock-Kabul trade route along the Grand Trunk road was particularly disastrous. By 1674, the situation had deteriorated to a point where Aurangzeb camped at Attock to personally take charge. Switching to diplomacy and bribery along with force of arms, the Mughals eventually split the rebels and partially suppressed the revolt, although they never managed to wield effective authority outside the main trade route.\n\nBy 1689, almost all of Southern India was a part of the Mughal Empire and after the conquest of Golconda, Aurangzeb may have been the richest and most powerful man alive. Mughal victories in the south expanded the Mughal Empire to 4 million square kilometres, with a population estimated to be over 158 million. But this supremacy was short-lived. Jos Gommans, Professor of Colonial and Global History at the University of Leiden, says that \"... the highpoint of imperial centralisation under emperor Aurangzeb coincided with the start of the imperial downfall.\"\n\nAurangzeb's vast imperial campaigns against rebellion-affected areas of the Mughal Empire caused his opponents to exaggerate the \"importance\" of their rebellions. The results of his campaigns were made worse by the incompetence of his regional Nawabs.\n\nMuslim views regarding Aurangzeb vary. Most Muslim historians believe that Aurangzeb was the last powerful ruler of an empire inevitably on the verge of decline. The major rebellions organised by the Sikhs and the Marathas had deep roots in the remote regions of the Mughal Empire.\n\nUnlike his predecessors, Aurangzeb considered the royal treasury to be held in trust for the citizens of his empire. He made caps and copied the Quran to earn money for his use. Aurangzeb constructed a small marble mosque known as the Moti Masjid (Pearl Mosque) in the Red Fort complex in Delhi. However, his constant warfare, especially with the Marathas, drove his empire to the brink of bankruptcy just as much as the wasteful personal spending and opulence of his predecessors. Aurangzeb knew he would not return to the throne after his final campaign against the Marathas in 1706, in which he was joined by newly emerging commanders in the Mughal army such as Syed Hassan Ali Khan Barha, Saadat Ali Khan and Asaf Jah I, and Daud Khan.\n\nThe Indologist Stanley Wolpert, emeritus professor at UCLA, says that:\n\nEven when ill and dying, Aurangzeb made sure that the populace knew he was still alive, for if they had thought otherwise then the turmoil of another war of succession was likely. He died in Ahmednagar on 20 February 1707 at the age of 88, having outlived many of his children. His modest open-air grave in Khuldabad expresses his deep devotion to his Islamic beliefs. It is sited in the courtyard of the shrine of the Sufi saint Shaikh Burhan-u'd-din Gharib, who was a disciple of Nizamuddin Auliya of Delhi.\n\nBrown writes that after his death, \"a string of weak emperors, wars of succession, and coups by noblemen heralded the irrevocable weakening of Mughal power\". She notes that the populist but \"fairly old-fashioned\" explanation for the decline is that there was a reaction to Aurangzeb's oppression. Aurangzeb's son, Bahadur Shah I, succeeded him and the empire, both because of Aurangzeb's over-extension and because of Bahadur Shah's weak military and leadership qualities, entered a period of terminal decline. Immediately after Bahadur Shah occupied the throne, the Maratha Empire – which Aurangzeb had held at bay, inflicting high human and monetary costs even on his own empire – consolidated and launched effective invasions of Mughal territory, seizing power from the weak emperor. Within decades of Aurangzeb's death, the Mughal Emperor had little power beyond the walls of Delhi.\n\nHis full imperial title was Al-Sultan al-Azam wal Khaqan al-Mukarram Hazrat Abul Muzaffar Muhy-ud-Din Muhammad Aurangzeb Bahadur Alamgir I, Badshah Ghazi, Shahanshah-e-Sultanat-ul-Hindiya Wal Mughaliya.\n\n\nNotes\n\nCitations\n\nBibliography\n\n\n"}
{"id": "2427", "url": "https://en.wikipedia.org/wiki?curid=2427", "title": "Alexandrine", "text": "Alexandrine\n\nAlexandrine is a name used for several distinct types of verse line with related metrical structures, most of which are ultimately derived from the classical French alexandrine. The line's name derives from its use in the Medieval French \"Roman d'Alexandre\" of 1170, although it had already been used several decades earlier in \"Le Pèlerinage de Charlemagne\". The foundation of most alexandrines consists of two hemistichs (half-lines) of six syllables each, separated by a caesura (a word break, though often realized as a stronger syntactic break):\n\nHowever, no tradition remains this simple. Each applies additional constraints (such as obligatory stress or nonstress on certain syllables) and options (such as a permitted or required additional syllable at the end of one or both hemistichs). Thus a line that is metrical in one tradition may be unmetrical in another.\n\nThe term \"alexandrine\" may be used with greater or lesser rigor. Peureux suggests that only French syllabic verse with a 6+6 structure is, strictly speaking, an alexandrine. Preminger \"et al\". allow a broader scope: \"Strictly speaking, the term 'alexandrine' is appropriate to French syllabic meters, and it may be applied to other metrical systems only where they too espouse syllabism as their principle, introduce phrasal accentuation, or rigorously observe the medial caesura, as in French.\" Common usage within the literatures of European languages is broader still, embracing lines syllabic, accentual-syllabic, and (inevitably) stationed ambivalently between the two; lines of 12, 13, or even 14 syllables; lines with obligatory, predominant, and optional caesurae.\n\nAlthough alexandrines occurred in French verse as early as the 12th century, they were slightly looser rhythmically, and vied with the \"décasyllabe\" and \"octosyllabe\" for cultural prominence and use in various genres. \"The alexandrine came into its own in the middle of the sixteenth century with the poets of the Pléiade and was firmly established in the seventeenth century.\" It became the preferred line for the prestigious genres of epic and tragedy. The structure of the classical French alexandrine is\n\nClassical alexandrines are always rhymed, often in couplets alternating masculine rhymes and feminine rhymes, though other configurations (such as quatrains and sonnets) are also common.\n\nVictor Hugo began the process of loosening the strict two-hemistich structure. While retaining the medial caesura, he often reduced it to a mere word-break, creating a three-part line (\"alexandrin ternaire\") with this structure:\n\nThe Symbolists further weakened the classical structure, sometimes eliminating any or all of these caesurae. However, at no point did the newer line \"replace\" the older; rather, they were used concurrently, often in the same poem. This loosening process eventually led to \"vers libéré\" and finally to \"vers libre\".\n\nIn English verse, \"alexandrine\" is typically used to mean \"iambic hexameter\":\n\nWhereas the French alexandrine is syllabic, the English is accentual-syllabic; and the central caesura (a defining feature of the French) is not always rigidly preserved in English.\n\nThough English alexandrines have occasionally provided the sole metrical line for a poem, for example in lyric poems by Henry Howard, Earl of Surrey and Sir Philip Sidney, and in two notable long poems, Michael Drayton's \"Poly-Olbion\" and Robert Browning's \"Fifine at the Fair\", they have more often featured alongside other lines. During the Middle Ages they typically occurred with heptameters (seven-beat lines), both exhibiting metrical looseness. Around the mid-16th century stricter alexandrines were popular as the first line of poulter's measure couplets, fourteeners (strict iambic heptameters) providing the second line.\n\nThe strict English alexandrine may be exemplified by a passage from \"Poly-Olbion\", which features a rare caesural enjambment (symbolized codice_1) in the first line:\n\n<poem style=\"margin-left:2em\">\nYe sacred Bards, that to ¦ your harps' melodious strings\nSung th'ancient Heroes' deeds (the monuments of Kings)\nAnd in your dreadful verse ingrav'd the prophecies,\nThe agèd world's descents, and geneaologies; (lines 31-34)\n</poem>\n\nThe Faerie Queene by Edmund Spenser, with its stanzas of eight iambic pentameter lines followed by one alexandrine, exemplifies what came to be its chief role: as a somewhat infrequent variant line in an otherwise iambic pentameter context. Alexandrines provide occasional variation in the blank verse of William Shakespeare and his contemporaries (but rarely; they constitute only about 1% of Shakespeare's blank verse). John Dryden and his contemporaries and followers likewise occasionally employed them as the second (rarely the first) line of heroic couplets, or even more distinctively as the third line of a triplet.\n\nThe Spanish \"alejandrino\" is a line of 7+7 syllables, probably developed in imitation of the French alexandrine.\n\nIt was used beginning about 1200 for \"mester de clerecía\" (clerical verse), typically occurring in the \"cuaderna vía\", a stanza of four \"alejandrinos\" all with a single end-rhyme.\n\nThe \"alejandrino\" was most prominent during the 13th and 14th centuries, after which time it was eclipsed by the metrically more flexible \"arte mayor\". Juan Ruiz's Book of Good Love is one of the best-known examples of \"cuaderna vía\", though other verse forms also appear in the work.\n\nThe mid-16th-century poet Jan van der Noot pioneered syllabic Dutch alexandrines on the French model, but within a few decades Dutch alexandrines had been transformed into strict iambic hexameters with a caesura after the third foot. From Holland the accentual-syllabic alexandrine spread to other continental literatures.\n\nSimilarly, in early 17th-century Germany, Georg Rudolf Weckherlin advocated for an alexandrine with free rhythms, reflecting French practice; whereas Martin Opitz advocated for a strict accentual-syllabic iambic alexandrine in imitation of contemporary Dutch practice — and German poets followed Opitz. The alexandrine (strictly iambic with a consistent medial caesura) became the dominant long line of the German baroque.\n\nUnlike many similar lines, the Polish alexandrine developed not from French verse but from Latin, specifically, the 13-syllable goliardic line:\n\nThough looser instances of this (nominally) 13-syllable line were occasionally used in Polish literature, it was Mikołaj Rej and Jan Kochanowski who, in the 16th century, introduced the syllabically strict line as a vehicle for major works.\n\nThe Czech alexandrine is a comparatively recent development, based on the French alexandrine and introduced by Karel Hynek Mácha in the 19th century. Its structure forms a halfway point between features usual in syllabic and in accentual-syllabic verse, being more highly constrained than most syllabic verse, and less so than most accentual-syllabic verse. Moreover, it equally encourages the very different rhythms of iambic hexameter and dactyllic tetrameter to emerge by preserving the constants of both measures:\n\nIn the comic book \"Asterix and Cleopatra\", the author Goscinny inserted a pun about alexandrines: when the Druid Panoramix (\"Getafix\" in the English translation) meets his Alexandrian (Egyptian) friend the latter exclaims \"Je suis, mon cher ami, || très heureux de te voir\" at which Panoramix observes \"C'est un Alexandrin\" (\"That's an alexandrine!\"/\"He's an Alexandrian!\"). The pun can also be heard in the theatrical adaptations. The English translation renders this as \"My dear old Getafix || How good to see you here\", with the reply \"Aha, an Alexandrine\".\n\n"}
{"id": "2428", "url": "https://en.wikipedia.org/wiki?curid=2428", "title": "Analog computer", "text": "Analog computer\n\nAn analog computer or analogue computer is a form of computer that uses the continuously changeable aspects of physical phenomena such as electrical, mechanical, or hydraulic quantities to model the problem being solved. In contrast, digital computers represent varying quantities symbolically, as their numerical values change. As an analog computer does not use discrete values, but rather continuous values, processes cannot be reliably repeated with exact equivalence, as they can with Turing machines. Unlike digital signal processing, analog computers do not suffer from the quantization noise, but are limited by analog noise.\n\nAnalog computers were widely used in scientific and industrial applications where digital computers of the time lacked sufficient performance. Analog computers can have a very wide range of complexity. Slide rules and nomographs are the simplest, while naval gunfire control computers and large hybrid digital/analog computers were among the most complicated. Systems for process control and protective relays used analog computation to perform control and protective functions.\n\nThe advent of digital computing made simple analog computers obsolete as early as the 1950s and 1960s, although analog computers remained in use in some specific applications, like the flight computer in aircraft, and for teaching control systems in universities. More complex applications, such as synthetic aperture radar, remained the domain of analog computing well into the 1980s, since digital computers were insufficient for the task.\n\nSetting up an analog computer required scale factors to be chosen, along with initial conditions—that is, starting values. Another essential was creating the required network of interconnections between computing elements. Sometimes it was necessary to re-think the structure of the problem so that the computer would function satisfactorily. No variables could be allowed to exceed the computer's limits, and differentiation was to be avoided, typically by rearranging the \"network\" of interconnects, using integrators in a different sense.\n\nRunning an electronic analog computer, assuming a satisfactory setup, started with the computer held with some variables fixed at their initial values. Moving a switch released the holds and permitted the problem to run. In some instances, the computer could, after a certain running time interval, repeatedly return to the initial-conditions state to reset the problem, and run it again.\n\nThis is a list of examples of early computation devices which are considered to be precursors of the modern computers. Some of them may even have been dubbed as 'computers' by the press, although they may fail to fit the modern definitions.\n\nThe south-pointing chariot, invented in ancient China during the first millennium BC, can be considered the earliest analog computer. It was a mechanical-geared wheeled vehicle used to discern the southern cardinal direction.\nThe Antikythera mechanism was an orrery and is claimed to be an early mechanical analog computer, according to Derek J. de Solla Price. It was designed to calculate astronomical positions. It was discovered in 1901 in the Antikythera wreck off the Greek island of Antikythera, between Kythera and Crete, and has been dated to \"circa\" 100 BC. Devices of a level of complexity comparable to that of the Antikythera mechanism would not reappear until a thousand years later.\n\nMany mechanical aids to calculation and measurement were constructed for astronomical and navigation use.\nThe planisphere was a star chart invented by Abū Rayḥān al-Bīrūnī in the early 11th century. The astrolabe was invented in the Hellenistic world in either the 1st or 2nd centuries BC and is often attributed to Hipparchus. A combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. An astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by Abi Bakr of Isfahan, Persia in 1235. Abū Rayhān al-Bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, \"circa\" 1000 AD. The castle clock, a hydropowered mechanical astronomical clock invented by Al-Jazari in 1206, was the first programmable analog computer.\n\nThe sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.\n\nThe planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.\nThe slide rule was invented around 1620–1630, shortly after the publication of the concept of the logarithm. It is a hand-operated analog computer for doing multiplication and division. As slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. Aviation is one of the few fields where slide rules are still in widespread use, particularly for solving time–distance problems in light aircraft.\n\nThe tide-predicting machine invented by Sir William Thomson in 1872 was of great utility to navigation in shallow waters. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.\n\nThe differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. In 1876 Lord Kelvin had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. The torque amplifier was the advance that allowed these machines to work. Starting in the 1920s, Vannevar Bush and others developed mechanical differential analyzers.\n\nThe Dumaresq was a mechanical calculating device invented around 1902 by Lieutenant John Dumaresq of the Royal Navy. It was an analog computer which related vital variables of the fire control problem to the movement of one's own ship and that of a target ship. It was often used with other devices, such as a Vickers range clock to generate range and deflection data so the gun sights of the ship could be continuously set. A number of versions of the Dumaresq were produced of increasing complexity as development proceeded.\n\nBy 1912 Arthur Pollen had developed an electrically driven mechanical analog computer for fire-control systems, based on the differential analyser. It was used by the Imperial Russian Navy in World War I.\n\nStarting in 1929, AC network analyzers were constructed to solve calculation problems related to electrical power systems that were too large to solve with numerical methods at the time. These were essentially scale models of the electrical properties of the full-size system. Since network analyzers could handle problems too large for analytic methods or hand computation, they were also used to solve problems in nuclear physics and in the design of structures. More than 50 large network analyzers were built by the end of the 1950s.\n\nWorld War II era gun directors, gun data computers, and bomb sights used mechanical analog computers. In 1941 Helmut Hölzer built a fully electronic general-purpose analog computer at Peenemünde Army Research Center. Mechanical analog computers were very important in gun fire control in World War II, The Korean War and well past the Vietnam War; they were made in significant numbers.\n\nThe FERMIAC was an analog computer invented by physicist Enrico Fermi in 1947 to aid in his studies of neutron transport. Project Cyclone was an analog computer developed by Reeves in 1950 for the analysis and design of dynamic systems. Project Typhoon was an analog computer developed by RCA in 1952. It consisted of over 4000 electron tubes and used 100 dials and 6000 plug-in connectors to program. The MONIAC Computer was a hydraulic model of a national economy first unveiled in 1949.\n\nComputer Engineering Associates was spun out of Caltech in 1950 to provide commercial services using the \"Direct Analogy Electric Analog Computer\" (\"the largest and most impressive general-purpose analyzer facility for the solution of field problems\") developed there by Gilbert D. McCann, Charles H. Wilts, and Bart Locanthi.\n\nEducational analog computers illustrated the principles of analog calculation. The Heathkit EC-1, a $199 educational analog computer, was made by the Heath Company, USA c. 1960. It was programmed using patch cords that connected nine operational amplifiers and other components. General Electric also marketed an \"educational\" analog computer kit of a simple design in the early 1960s consisting of a two transistor tone generator and three potentiometers wired such that the frequency of the oscillator was nulled when the potentiometer dials were positioned by hand to satisfy an equation. The relative resistance of the potentiometer was then equivalent to the formula of the equation being solved. Multiplication or division could be performed depending on which dials were considered inputs and which was the output. Accuracy and resolution was limited and a simple slide rule was more accurate; however, the unit did demonstrate the basic principle.\n\nIn industrial process control, thousands of analog loop controllers were used to automatically regulate temperature, flow, pressure, or other process conditions. The technology of these controllers ranged from purely mechanical integrators, through vacuum-tube and solid-state devices, to emulation of analog controllers by microprocessors.\n\nThe similarity between linear mechanical components, such as springs and dashpots (viscous-fluid dampers), and electrical components, such as capacitors, inductors, and resistors is striking in terms of mathematics. They can be modeled using equations of the same form.\n\nHowever, the difference between these systems is what makes analog computing useful. If one considers a simple mass–spring system, constructing the physical system would require making or modifying the springs and masses. This would be followed by attaching them to each other and an appropriate anchor, collecting test equipment with the appropriate input range, and finally, taking measurements. In more complicated cases, such as suspensions for racing cars, experimental construction, modification, and testing is both complicated and expensive.\n\nThe electrical equivalent can be constructed with a few operational amplifiers (op amps) and some passive linear components; all measurements can be taken directly with an oscilloscope. In the circuit, the (simulated) 'stiffness of the spring', for instance, can be changed by adjusting the parameters of a capacitor. The electrical system is an analogy to the physical system, hence the name, but it is less expensive to construct, generally safer, and typically much easier to modify.\n\nAs well, an electronic circuit can typically operate at higher frequencies than the system being simulated. This allows the simulation to run faster than real time (which could, in some instances, be hours, weeks, or longer). Experienced users of electronic analog computers said that they offered a comparatively intimate control and understanding of the problem, relative to digital simulations.\n\nThe drawback of the mechanical-electrical analogy is that electronics are limited by the range over which the variables may vary. This is called dynamic range. They are also limited by noise levels. Floating-point digital calculations have a comparatively huge dynamic range.\n\nThese electric circuits can also easily perform a wide variety of simulations. For example, voltage can simulate water pressure and electric current can simulate rate of flow in terms of cubic metres per second. An integrator can provide the total accumulated volume of liquid, using an input current proportional to the (possibly varying) flow rate.\n\nAnalog computers are especially well-suited to representing situations described by differential equations. Occasionally, they were used when a differential equation proved very difficult to solve by traditional means.\n\nThe accuracy of an analog computer is limited by its computing elements as well as quality of the internal power and electrical interconnections. The precision of the analog computer readout was limited chiefly by the precision of the readout equipment used, generally three or four significant figures. The precision of a digital computer is limited by the word size; arbitrary-precision arithmetic, while relatively slow, provides any practical degree of precision that might be needed.\n\nMany small computers dedicated to specific computations are still part of industrial regulation equipment, but from the 1950s to the 1970s, general-purpose analog computers were the only systems fast enough for real time simulation of dynamic systems, especially in the aircraft, military and aerospace field.\n\nIn the 1960s, the major manufacturer was Electronic Associates of Princeton, New Jersey, with its 231R Analog Computer (vacuum tubes, 20 integrators) and subsequently its 8800 Analog Computer (solid state operational amplifiers, 64 integrators). Its challenger was Applied Dynamics of Ann Arbor, Michigan.\n\nAlthough the basic technology for analog computers is usually operational amplifiers (also called \"continuous current amplifiers\" because they have no low frequency limitation), in the 1960s an attempt was made in the French ANALAC computer to use an alternative technology: medium frequency carrier and non dissipative reversible circuits.\n\nIn the 1970s every big company and administration concerned with problems in dynamics had a big analog computing center, for example:\n\nAnalog computing devices are fast, digital computing devices are more versatile and accurate, so the idea is to combine the two processes for the best efficiency. An example of such hybrid elementary device is the hybrid multiplier where one input is an analog signal, the other input is a digital signal and the output is analog. It acts as an analog potentiometer upgradable digitally. This kind of hybrid technique is mainly used for fast dedicated real time computation when computing time is very critical as signal processing for radars and generally for controllers in embedded systems.\n\nIn the early 1970s analog computer manufacturers tried to tie together their analog computer with a digital computer to get the advantages of the two techniques. In such systems, the digital computer controlled the analog computer, providing initial set-up, initiating multiple analog runs, and automatically feeding and collecting data. The digital computer may also participate to the calculation itself using analog-to-digital and digital-to-analog converters.\n\nThe largest manufacturer of hybrid computers was Electronics Associates. Their hybrid computer model 8900 was made of a digital computer and one or more analog consoles. These systems were mainly dedicated to large projects such as the Apollo program and Space Shuttle at NASA, or Ariane in Europe, especially during the integration step where at the beginning everything is simulated, and progressively real components replace their simulated part.\n\nOnly one company was known as offering general commercial computing services on its hybrid computers, CISI of France, in the 1970s.\n\nThe best reference in this field is the 100,000 simulations runs for each certification of the automatic landing systems of Airbus and Concorde aircraft.\n\nAfter 1980, purely digital computers progressed more and more rapidly and were fast enough to compete with analog computers.\nOne key to the speed of analog computers was their fully parallel computation, but this was also a limitation. The more equations required for a problem, the more analog components were needed, even when the problem wasn't time critical. \"Programming\" a problem meant interconnecting the analog operators; even with a removable wiring panel this was not very versatile. Today there are no more big hybrid computers, but only hybrid components.\n\nWhile a wide variety of mechanisms have been developed throughout history, some stand out because of their theoretical importance, or because they were manufactured in significant quantities.\n\nMost practical mechanical analog computers of any significant complexity used rotating shafts to carry variables from one mechanism to another. Cables and pulleys were used in a Fourier synthesizer, a tide-predicting machine, which summed the individual harmonic components. Another category, not nearly as well known, used rotating shafts only for input and output, with precision racks and pinions. The racks were connected to linkages that performed the computation. At least one US Naval sonar fire control computer of the later 1950s, made by Librascope, was of this type, as was the principal computer in the Mk. 56 Gun Fire Control System.\n\nOnline, there is a remarkably clear illustrated reference (OP 1140) that describes the fire control computer mechanisms.\nFor adding and subtracting, precision miter-gear differentials were in common use in some computers; the Ford Instrument Mark I Fire Control Computer contained about 160 of them.\n\nIntegration with respect to another variable was done by a rotating disc driven by one variable. Output came from a pickoff device (such as a wheel) positioned at a radius on the disc proportional to the second variable. (A carrier with a pair of steel balls supported by small rollers worked especially well. A roller, its axis parallel to the disc's surface, provided the output. It was held against the pair of balls by a spring.)\n\nArbitrary functions of one variable were provided by cams, with gearing to convert follower movement to shaft rotation.\n\nFunctions of two variables were provided by three-dimensional cams. In one good design, one of the variables rotated the cam. A hemispherical follower moved its carrier on a pivot axis parallel to that of the cam's rotating axis. Pivoting motion was the output. The second variable moved the follower along the axis of the cam. One practical application was ballistics in gunnery.\n\nCoordinate conversion from polar to rectangular was done by a mechanical resolver (called a \"component solver\" in US Navy fire control computers). Two discs on a common axis positioned a sliding block with pin (stubby shaft) on it. One disc was a face cam, and a follower on the block in the face cam's groove set the radius. The other disc, closer to the pin, contained a straight slot in which the block moved. The input angle rotated the latter disc (the face cam disc, for an unchanging radius, rotated with the other (angle) disc; a differential and a few gears did this correction).\n\nReferring to the mechanism's frame, the location of the pin corresponded to the tip of the vector represented by the angle and magnitude inputs. Mounted on that pin was a square block.\n\nRectilinear-coordinate outputs (both sine and cosine, typically) came from two slotted plates, each slot fitting on the block just mentioned. The plates moved in straight lines, the movement of one plate at right angles to that of the other. The slots were at right angles to the direction of movement. Each plate, by itself, was like a Scotch yoke, known to steam engine enthusiasts.\n\nDuring World War II, a similar mechanism converted rectilinear to polar coordinates, but it was not particularly successful and was eliminated in a significant redesign (USN, Mk. 1 to Mk. 1A).\n\nMultiplication was done by mechanisms based on the geometry of similar right triangles. Using the trigonometric terms for a right triangle, specifically opposite, adjacent, and hypotenuse, the adjacent side was fixed by construction. One variable changed the magnitude of the opposite side. In many cases, this variable changed sign; the hypotenuse could coincide with the adjacent side (a zero input), or move beyond the adjacent side, representing a sign change.\n\nTypically, a pinion-operated rack moving parallel to the (trig.-defined) opposite side would position a slide with a slot coincident with the hypotenuse. A pivot on the rack let the slide's angle change freely. At the other end of the slide (the angle, in trig, terms), a block on a pin fixed to the frame defined the vertex between the hypotenuse and the adjacent side.\n\nAt any distance along the adjacent side, a line perpendicular to it intersects the hypotenuse at a particular point. The distance between that point and the adjacent side is some fraction that is the product of \"1\" the distance from the vertex, and \"2\" the magnitude of the opposite side.\n\nThe second input variable in this type of multiplier positions a slotted plate perpendicular to the adjacent side. That slot contains a block, and that block's position in its slot is determined by another block right next to it. The latter slides along the hypotenuse, so the two blocks are positioned at a distance from the (trig.) adjacent side by an amount proportional to the product.\n\nTo provide the product as an output, a third element, another slotted plate, also moves parallel to the (trig.) opposite side of the theoretical triangle. As usual, the slot is perpendicular to the direction of movement. A block in its slot, pivoted to the hypotenuse block positions it.\n\nA special type of integrator, used at a point where only moderate accuracy was needed, was based on a steel ball, instead of a disc. It had two inputs, one to rotate the ball, and the other to define the angle of the ball's rotating axis. That axis was always in a plane that contained the axes of two movement-pickoff rollers, quite similar to the mechanism of a rolling-ball computer mouse (in this mechanism, the pickoff rollers were roughly the same diameter as the ball). The pickoff roller axes were at right angles.\n\nA pair of rollers \"above\" and \"below\" the pickoff plane were mounted in rotating holders that were geared together. That gearing was driven by the angle input, and established the rotating axis of the ball. The other input rotated the \"bottom\" roller to make the ball rotate.\n\nEssentially, the whole mechanism, called a component integrator, was a variable-speed drive with one motion input and two outputs, as well as an angle input. The angle input varied the ratio (and direction) of coupling between the \"motion\" input and the outputs according to the sine and cosine of the input angle.\n\nAlthough they did not accomplish any computation, electromechanical position servos were essential in mechanical analog computers of the \"rotating-shaft\" type for providing operating torque to the inputs of subsequent computing mechanisms, as well as driving output data-transmission devices such as large torque-transmitter synchros in naval computers.\n\nOther non-computational mechanisms included internal odometer-style counters with interpolating drum dials for indicating internal variables, and mechanical multi-turn limit stops.\n\nConsidering that accurately controlled rotational speed in analog fire-control computers was a basic element of their accuracy, there was a motor with its average speed controlled by a balance wheel, hairspring, jeweled-bearing differential, a twin-lobe cam, and spring-loaded contacts (ship's AC power frequency was not necessarily accurate, nor dependable enough, when these computers were designed).\n\nElectronic analog computers typically have front panels with numerous jacks (single-contact sockets) that permit patch cords (flexible wires with plugs at both ends) to create the interconnections which define the problem setup. In addition, there are precision high-resolution potentiometers (variable resistors) for setting up (and, when needed, varying) scale factors. In addition, there is likely to be a zero-center analog pointer-type meter for modest-accuracy voltage measurement. Stable, accurate voltage sources provide known magnitudes.\n\nTypical electronic analog computers contain anywhere from a few to a hundred or more operational amplifiers (\"op amps\"), named because they perform mathematical operations. Op amps are a particular type of feedback amplifier with very high gain and stable input (low and stable offset). They are always used with precision feedback components that, in operation, all but cancel out the currents arriving from input components. The majority of op amps in a representative setup are summing amplifiers, which add and subtract analog voltages, providing the result at their output jacks. As well, op amps with capacitor feedback are usually included in a setup; they integrate the sum of their inputs with respect to time.\n\nIntegrating with respect to another variable is the nearly exclusive province of mechanical analog integrators; it is almost never done in electronic analog computers. However, given that a problem solution does not change with time, time can serve as one of the variables.\n\nOther computing elements include analog multipliers, nonlinear function generators, and analog comparators.\n\nElectrical elements such as inductors and capacitors used in electrical analog computers had to be carefully manufactured to reduce non-ideal effects. For example, in the construction of AC power network analyzers, one motive for using higher frequencies for the calculator (instead of the actual power frequency) was that higher-quality inductors could be more easily made. Many general-purpose analog computers avoided the use of inductors entirely, re-casting the problem in a form that could be solved using only resistive and capacitive elements, since high-quality capacitors are relatively easy to make.\n\nThe use of electrical properties in analog computers means that calculations are normally performed in real time (or faster), at a speed determined mostly by the frequency response of the operational amplifiers and other computing elements. In the history of electronic analog computers, there were some special high-speed types.\n\nNonlinear functions and calculations can be constructed to a limited precision (three or four digits) by designing function generators—special circuits of various combinations of resistors and diodes to provide the nonlinearity. Typically, as the input voltage increases, progressively more diodes conduct.\n\nWhen compensated for temperature, the forward voltage drop of a transistor's base-emitter junction can provide a usably accurate logarithmic or exponential function. Op amps scale the output voltage so that it is usable with the rest of the computer.\n\nAny physical process which models some computation can be interpreted as an analog computer. Some examples, invented for the purpose of illustrating the concept of analog computation, include using a bundle of spaghetti as a model of sorting numbers; a board, a set of nails, and a rubber band as a model of finding the convex hull of a set of points; and strings tied together as a model of finding the shortest path in a network. These are all described in Dewdney (1984).\n\nAnalog computers often have a complicated framework, but they have, at their core, a set of key components which perform the calculations, which the operator manipulates through the computer's framework.\n\nKey hydraulic components might include pipes, valves and containers.\n\nKey mechanical components might include rotating shafts for carrying data within the computer, miter gear differentials, disc/ball/roller integrators, cams (2-D and 3-D), mechanical resolvers and multipliers, and torque servos.\n\nKey electrical/electronic components might include:\n\nThe core mathematical operations used in an electric analog computer are:\n\nIn some analog computer designs, multiplication is much preferred to division. Division is carried out with a multiplier in the feedback path of an Operational Amplifier.\n\nDifferentiation with respect to time is not frequently used, and in practice is avoided by redefining the problem when possible. It corresponds in the frequency domain to a high-pass filter, which means that high-frequency noise is amplified; differentiation also risks instability.\n\nIn general, analog computers are limited by non-ideal effects. An analog signal is composed of four basic components: DC and AC magnitudes, frequency, and phase. The real limits of range on these characteristics limit analog computers. Some of these limits include the operational amplifier offset, finite gain, and frequency response, noise floor, non-linearities, temperature coefficient, and parasitic effects within semiconductor devices. For commercially available electronic components, ranges of these aspects of input and output signals are always figures of merit.\n\nIn 1950s to 1970s, digital computers based on first vacuum tubes, transistors, integrated circuits and then micro-processors became more economical and precise. This led digital computers to largely replace analog computers. Even so, some research in analog computation is still being done. A few universities still use analog computers to teach control system theory. The American company Comdyna manufactures small analog computers. At Indiana University Bloomington, Jonathan Mills has developed the Extended Analog Computer based on sampling voltages in a foam sheet. At the Harvard Robotics Laboratory, analog computation is a research topic. Lyric Semiconductor's error correction circuits use analog probabilistic signals. Slide rules are still popular among aircraft personnel. \n\nWith the development of very-large-scale integration (VLSI) technology, Yannis Tsividis' group at Columbia University has been revisiting analog/hybrid computers design in standard CMOS process. Two VLSI chips have been developed, an 80th-order analog computer (250 nm) by Glenn Cowan in 2005 and an 4th-order hybrid computer (65 nm) developed by Ning Guo in 2015, both targeting at energy-efficient ODE/PDE applications. Glenn's chip contains 16 macros, in which there are 25 analog computing blocks, namely integrators, multipliers, fanouts, few nonlinear blocks. Ning's chip contains one macro block, in which there are 26 computing blocks including integrators, multipliers, fanouts, ADCs, SRAMs and DACs. Arbitrary nonlinear function generation is made possible by the ADC+SRAM+DAC chain, where the SRAM block stores the nonlinear function data. The experiments from the related publications revealed that VLSI analog/hybrid computers demonstrated about 1–2 orders magnitude of advantage in both solution time and energy while achieving accuracy within 5%, which points to the promise of using analog/hybrid computing techniques in the area of energy-efficient approximate computing.\n\nThese are examples of analog computers that have been constructed or practically used:\n\nAnalog (audio) synthesizers can also be viewed as a form of analog computer, and their technology was originally based in part on electronic analog computer technology. The ARP 2600's Ring Modulator was actually a moderate-accuracy analog multiplier.\n\nThe Simulation Council (or Simulations Council) was an association of analog computer users in USA. It is now known as The Society for Modeling and Simulation International. The Simulation Council newsletters from 1952 to 1963 are available online and show the concerns and technologies at the time, and the common use of analog computers for missilry.\n\nComputer theorists often refer to idealized analog computers as real computers (because they operate on the set of real numbers). Digital computers, by contrast, must first quantize the signal into a finite number of values, and so can only work with the rational number set (or, with an approximation of irrational numbers).\n\nThese idealized analog computers may \"in theory\" solve problems that are intractable on digital computers; however as mentioned, in reality, analog computers are far from attaining this ideal, largely because of noise minimization problems. \"In theory\", ambient noise is limited by quantum noise (caused by the quantum movements of ions). Ambient noise may be severely reduced – but never to zero – by using cryogenically cooled parametric amplifiers. Moreover, given unlimited time and memory, the (ideal) digital computer may also solve real number problems.\n\n\n\n"}
{"id": "2429", "url": "https://en.wikipedia.org/wiki?curid=2429", "title": "Audio", "text": "Audio\n\nAudio most commonly refers to sound. It may also refer to:\n\n\n\n"}
{"id": "2431", "url": "https://en.wikipedia.org/wiki?curid=2431", "title": "Minute and second of arc", "text": "Minute and second of arc\n\nA minute of arc, arcminute (arcmin), arc minute, or minute arc is a unit of angular measurement equal to of one degree. Since one degree is of a turn (or complete rotation), one minute of arc is of a turn (or, in radians, ). A second of arc, arcsecond (arcsec), or arc second is of an arcminute, of a degree, of a turn, and (about ) of a radian. These units originated in Babylonian astronomy as sexagesimal subdivisions of the degree; they are used in fields that involve very small angles, such as astronomy, optometry, ophthalmology, optics, navigation, land surveying and marksmanship.\n\nTo express even smaller angles, standard SI prefixes can be employed; the milliarcsecond (mas) and microarcsecond (μas), for instance, are commonly used in astronomy.\n\nThe number of square arcminutes in a complete sphere is formula_1 square arcminutes.\n\nThe standard symbol for marking the arcminute is the prime (′) (U+2032), though a single quote (') (U+0027) is commonly used where only ASCII characters are permitted. One arcminute is thus written 1′. It is also abbreviated as arcmin or amin or, less commonly, the prime with a circumflex over it (formula_2).\n\nThe standard symbol for the arcsecond is the double prime (″) (U+2033), though a double quote (\") (U+0022) is commonly used where only ASCII characters are permitted. One arcsecond is thus written 1″. It is also abbreviated as arcsec or asec.\n\nIn celestial navigation, seconds of arc are rarely used in calculations, the preference usually being for degrees, minutes and decimals of a minute, for example, written as 42° 25.32′ or 42° 25.322′. This notation has been carried over into marine GPS receivers, which normally display latitude and longitude in the latter format by default.\n\nAn arcsecond is approximately the angle subtended by a U.S. dime coin (18 mm) at a distance of .\n\nAn arcsecond is also the angle subtended by\n\nA milliarcsecond is about the size of a dime atop the Eiffel Tower as seen from New York City.\n\nA microarcsecond is about the size of a period at the end of a sentence in the Apollo mission manuals left on the Moon as seen from Earth.\n\nSince antiquity the arcminute and arcsecond have been used in astronomy. In the ecliptic coordinate system, latitude (β) and longitude (λ); in the horizon system, altitude (Alt) and azimuth (Az); and in the equatorial coordinate system, declination (δ), are all measured in degrees, arcminutes and arcseconds. The principal exception is Right ascension (RA) in equatorial coordinates, which is measured in time units of hours, minutes, and seconds.\n\nThe arcsecond is also often used to describe small astronomical angles such as the angular diameters of planets (e.g. the angular diameter of Venus which varies between 10″ and 60″), the proper motion of stars, the separation of components of binary star systems, and parallax, the small change of position of a star in the course of a year or of a solar system body as the Earth rotates. These small angles may also be written in milliarcseconds (mas), or thousandths of an arcsecond. The unit of distance, the parsec, named from the parallax of one arcsecond, was developed for such parallax measurements. It is the distance at which the mean radius of the Earth's orbit would subtend an angle of one arcsecond.\n\nThe ESA astrometric space probe Gaia is hoped to measure star positions to 20 microarcseconds (µas) when it begins producing catalog positions sometime after 2016. There are about 1.3 trillion µas in a turn. Currently the best catalog positions of stars actually measured are in terms of milliarcseconds, by the U.S. Naval Observatory.\n\nApart from the Sun, the star with the largest angular diameter from Earth is R Doradus, a red supergiant with a diameter of 0.05 arcsecond. Because of the effects of atmospheric seeing, ground-based telescopes will smear the image of a star to an angular diameter of about 0.5 arcsecond; in poor seeing conditions this increases to 1.5 arcseconds or even more. The dwarf planet Pluto has proven difficult to resolve because its angular diameter is about 0.1 arcsecond.\n\nSpace telescopes are not affected by the Earth's atmosphere but are diffraction limited. For example, the Hubble space telescope can reach an angular size of stars down to about 0.1″. Techniques exist for improving seeing on the ground. Adaptive optics, for example, can produce images around 0.05 arcsecond on a 10 m class telescope.\n\nMinutes (′) and seconds (″) of arc are also used in cartography and navigation. At sea level one minute of arc along the equator or a meridian (indeed, any great circle) equals exactly one geographical mile along the Earth's equator or approximately one nautical mile (1852 meters, or ≈1.15078 statute miles). A second of arc, one sixtieth of this amount, is roughly 30 meters or 100 feet. The exact distance varies along meridian arcs because the figure of the Earth is slightly oblate (bulges a third of a percent at the equator).\n\nPositions are traditionally given using degrees, minutes, and seconds of arcs for latitude, the arc north or south of the equator, and for longitude, the arc east or west of the Prime Meridian. Any position on or above the Earth's reference ellipsoid can be precisely given with this method. However, when it is inconvenient to use base-60 for minutes and seconds, positions are frequently expressed as decimal fractional degrees to an equal amount of precision. Degrees given to three decimal places ( of a degree) have about the precision of degrees-minutes-seconds ( of a degree) and specify locations within about 120 meters or 400 feet.\n\nRelated to cartography, property boundary surveying using the metes and bounds system relies on fractions of a degree to describe property lines' angles in reference to cardinal directions. A boundary \"mete\" is described with a beginning reference point, the cardinal direction North or South followed by an angle less than 90 degrees and a second cardinal direction, and a linear distance. The boundary runs the specified linear distance from the beginning point, the direction of the distance being determined by rotating the first cardinal direction the specified angle toward the second cardinal direction. For example, \"North 65° 39′ 18″ West 85.69 feet\" would describe a line running from the starting point 85.69 feet in a direction 65° 39′ 18″ (or 65.655°) away from north toward the west.\n\nThe arcminute is commonly found in the firearms industry and literature, particularly concerning the accuracy of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular with shooters familiar with the imperial measurement system because 1 MOA subtends 1.047 inches at 100 yards (approximately 3 cm at 100 m), a traditional distance on U.S. target ranges. The subtension is linear with the distance, for example, 500 yards = 5.235 inches, and 1000 yards = 10.47 inches. Since many modern telescopic sights are adjustable in half (), quarter (), or eighth () MOA increments, also known as \"clicks\", zeroing and adjustments are made by counting 2, 4 and 8 clicks per MOA respectively.\n\nFor example, if the point of impact is 3 inches high and 1.5 inches left of the point of aim at 100 yards (which for instance could be measured by using a spotting scope with a calibrated reticle), the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that \"click\" in fractions of MOA. This makes zeroing and adjustments much easier:\n\n\nAnother common system of measurement in firearm scopes is the milliradian. Zeroing a mil based scope is easy for users familiar with base ten systems. The most common adjustment value in mil based scopes is mil (which approximates MOA).\n\n\nOne thing to be aware of is that some MOA scopes, including some higher-end models, are calibrated such that an adjustment of 1 MOA on the scope knobs corresponds to exactly 1 inch of impact adjustment on a target at 100 yards, rather than the mathematically correct 1.047\". This is commonly known as the Shooter's MOA (SMOA) or Inches Per Hundred Yards (IPHY). While the difference between one true MOA and one SMOA is less than half of an inch even at 1000 yards, this error compounds significantly on longer range shots that may require adjustment upwards of 20-30 MOA to compensate for the bullet drop. If a shot requires an adjustment of 20 MOA or more, the difference between true MOA and SMOA will add up to 1 inch or more. In competitive target shooting, this might mean the difference between a hit and a miss.\n\nThe physical group size equivalent to \"m\" minutes of arc can be calculated as follows: group size = tan() × distance. In the example previously given, for 1 minute of arc, and substituting 3,600 inches for 100 yards, 3,600 tan() ≈ 1.047 inches. In metric units 1 MOA at 100 meters ≈ 2.908 centimeters.\n\nSometimes, a precision firearm's accuracy will be measured in MOA. This simply means that under ideal conditions i.e. no wind, match-grade ammo, clean barrel, and a vise or a benchrest used to eliminate shooter error, the gun is capable of producing a group of shots whose center points (center-to-center) fit into a circle, the average diameter of circles in several groups can be subtended by that amount of arc. For example, a \"1 MOA rifle\" should be capable, under ideal conditions, of shooting an average 1-inch groups at 100 yards. Most higher-end rifles are warrantied by their manufacturer to shoot under a given MOA threshold (typically 1 MOA or better) with specific ammunition and no error on the shooter's part. For example, Remington's M24 Sniper Weapon System is required to shoot 0.8 MOA or better, or be rejected.\n\nRifle manufacturers and gun magazines often refer to this capability as \"sub-MOA\", meaning it shoots under 1 MOA. This means that a single group of 3 to 5 shots at 100 yards, or the average of several groups, will measure less than 1 MOA between the two furthest shots in the group, i.e. all shots fall within 1 MOA. If larger samples are taken (i.e., more shots per group) then group size typically increases, however this will ultimately average out. If a rifle was truly a 1 MOA rifle, it would be just as likely that two consecutive shots land exactly on top of each other as that they land 1 MOA apart. For 5 shot groups, based on 95% confidence a rifle that normally shoots 1 MOA can be expected to shoot groups between 0.58 MOA and 1.47 MOA, although the majority of these groups will be under 1 MOA. What this means in practice is if a rifle that shoots 1-inch groups on average at 100 yards shoots a group measuring 0.7 inches followed by a group that is 1.3 inches this is not statistically abnormal.\n\nThe Metric System counterpart of the MOA is the milliradian or mil, being equal to one 1000th of the target range, laid out on a circle that has the observer as centre and the target range as radius. The number of mils on a full such circle therefore always is equal to 2 × × 1000, regardless the target range. Therefore, 1 MOA ≈ 0.2908 mil. This means that an object which spans 1 mil on the reticle is at a range that is in meters equal to the object's size in millimeters (e.g. an object of 100 mm @ 1 Milrad is 100 meters away). So there is no conversion factor required, contrary to the MOA system. A reticle with markings (hashes or dots) spaced with a one mil apart (or a fraction of a mil) are collectively called a mil reticle. If the markings are round they are called mil-dots.\n\nIn the table below conversions from mil to metric values are exact (e.g. 0.1 mil equals exactly 1 cm at 100 meters), while conversions of minutes of arc to both metric and imperial values are approximate.\n\n\nIn humans, 20/20 vision is the ability to resolve a spatial pattern separated by a visual angle of one minute of arc.\nA 20/20 letter subtends 5 minutes of arc total.\n\nThe deviation from parallelism between two surfaces, for instance in optical engineering, is usually measured in arcminutes or arcseconds.\nIn addition, arcseconds are sometimes used in rocking curve (ω-scan) x ray diffraction measurements of high-quality epitaxial thin films.\n\n\n"}
{"id": "2433", "url": "https://en.wikipedia.org/wiki?curid=2433", "title": "Alberto Giacometti", "text": "Alberto Giacometti\n\nAlberto Giacometti (; 10 October 1901 – 11 January 1966) was a Swiss sculptor, painter, draughtsman and printmaker.\nHe was born in the canton Graubünden's southerly alpine valley Val Bregaglia, as the eldest of four children to Giovanni Giacometti, a well-known post-Impressionist painter and Annetta Giacometti-Stampa. Coming from an artistic background, he was interested in art from an early age.\n\nGiacometti was born in Borgonovo, now part of the Switzerland municipality of Bregaglia, near the Italian border. He was a descendant of Protestant refugees escaping the inquisition. Alberto attended the Geneva School of Fine Arts. His brothers Diego (1902–85) and Bruno (1907–2012) would go on to become artists as well. Additionally, Zaccaria Giacometti, later professor of constitutional law and chancellor of the University of Zurich grew up together with them, having been orphaned at the age of 12 in 1905.\n\nIn 1922 he moved to Paris to study under the sculptor Antoine Bourdelle, an associate of Rodin. It was there that Giacometti experimented with cubism and surrealism and came to be regarded as one of the leading surrealist sculptors. Among his associates were Miró, Max Ernst, Picasso, Bror Hjorth and Balthus.\n\nBetween 1936 and 1940, Giacometti concentrated his sculpting on the human head, focusing on the sitter's gaze. He preferred models he was close to, his sister and the artist Isabel Rawsthorne (then known as Isabel Delmer). This was followed by a phase in which his statues of Isabel became stretched out; her limbs elongated. Obsessed with creating his sculptures exactly as he envisioned through his unique view of reality, he often carved until they were as thin as nails and reduced to the size of a pack of cigarettes, much to his consternation. A friend of his once said that if Giacometti decided to sculpt you, \"he would make your head look like the blade of a knife\". After his marriage to Annette Arm in 1946 his tiny sculptures became larger, but the larger they grew, the thinner they became. Giacometti said that the final result represented the sensation he felt when he looked at a woman.\n\nHis paintings underwent a parallel procedure. The figures appear isolated and severely attenuated, as the result of continuous reworking. Subjects were frequently revisited: one of his favorite models was his younger brother Diego Giacometti. A third brother, Bruno Giacometti, was a noted architect.\n\nIn 1958 Giacometti was asked to create a monumental sculpture for the Chase Manhattan Bank building in New York, which was beginning construction. Although he had for many years \"harbored an ambition to create work for a public square\", he \"had never set foot in New York, and knew nothing about life in a rapidly evolving metropolis. Nor had he ever laid eyes on an actual skyscraper\", according to his biographer James Lord. Giacometti's work on the project resulted in the four figures of standing women—his largest sculptures—entitled \"Grande femme debout\" I through IV (1960). The commission was never completed, however, because Giacometti was unsatisfied by the relationship between the sculpture and the site, and abandoned the project.\n\nIn 1962, Giacometti was awarded the grand prize for sculpture at the Venice Biennale, and the award brought with it worldwide fame. Even when he had achieved popularity and his work was in demand, he still reworked models, often destroying them or setting them aside to be returned to years later. The prints produced by Giacometti are often overlooked but the catalogue raisonné, \"Giacometti – The Complete Graphics and 15 Drawings by Herbert Lust\" (Tudor 1970), comments on their impact and gives details of the number of copies of each print. Some of his most important images were in editions of only 30 and many were described as rare in 1970.\n\nIn his later years Giacometti's works were shown in a number of large exhibitions throughout Europe. Riding a wave of international popularity, and despite his declining health, he travelled to the United States in 1965 for an exhibition of his works at the Museum of Modern Art in New York. As his last work he prepared the text for the book \"Paris sans fin\", a sequence of 150 lithographs containing memories of all the places where he had lived.\n\nGiacometti died in 1966 of heart disease (pericarditis) and chronic bronchitis at the Kantonsspital in Chur, Switzerland. His body was returned to his birthplace in Borgonovo, where he was interred close to his parents. In May 2007 the executor of his widow's estate, former French foreign minister Roland Dumas, was convicted of illegally selling Giacometti's works to a top auctioneer, Jacques Tajan, who was also convicted. Both were ordered to pay €850,000 to the Alberto and Annette Giacometti Foundation.\n\nRegarding Giacometti's sculptural technique and according to the Metropolitan Museum of Art: \"The rough, eroded, heavily worked surfaces of Three Men Walking (II), 1949, typify his technique. Reduced, as they are, to their very core, these figures evoke lone trees in winter that have lost their foliage. Within this style, Giacometti would rarely deviate from the three themes that preoccupied him—the walking man; the standing, nude woman; and the bust—or all three, combined in various groupings\".\"\"\n\nIn a letter to Pierre Matisse, Giacometti wrote: \"Figures were never a compact mass but like a transparent construction\". In the letter, Giacometti writes about how he looked back at the realist, classical busts of his youth with nostalgia, and tells the story of the existential crisis which precipitated the style he became known for.\n\n\"[I rediscovered] the wish to make compositions with figures. For this I had to make (quickly I thought; in passing), one or two studies from nature, just enough to understand the construction of a head, of a whole figure, and in 1935 I took a model. This study should take, I thought, two weeks and then I could realize my compositions...I worked with the model all day from 1935 to 1940...Nothing was as I imagined. A head, became for me an object completely unknown and without dimensions.\"\n\nSince Giacometti achieved exquisite realism with facility when he was executing busts in his early adolescence, Giacometti's difficulty in re-approaching the figure as an adult is generally understood as a sign of existential struggle for meaning, rather than as a technical deficit.\n\nGiacometti was a key player in the Surrealist art movement, but his work resists easy categorization. Some describe it as formalist, others argue it is expressionist or otherwise having to do with what Deleuze calls \"blocs of sensation\" (as in Deleuze's analysis of Francis Bacon). Even after his excommunication from the Surrealist group, while the intention of his sculpting was usually imitation, the end products were an expression of his emotional response to the subject. He attempted to create renditions of his models the way he saw them, and the way he thought they ought to be seen. He once said that he was sculpting not the human figure but \"the shadow that is cast\".\n\nScholar William Barrett in \"Irrational Man: A Study in Existential Philosophy\" (1962), argues that the attenuated forms of Giacometti's figures reflect the view of 20th century modernism and existentialism that modern life is increasingly empty and devoid of meaning. \"All the sculptures of today, like those of the past, will end one day in pieces...So it is important to fashion ones work carefully in its smallest recess and charge every particle of matter with life.\"\n\nA 2011-2012 exhibition at the Pinacothèque de Paris focussed on showing how Giacometti was inspired by Etruscan art.\n\nGiacometti's work has been the subject of numerous solo exhibitions including Pera Museum, Istanbul (2015) Pushkin Museum, Moscow (2008); “The Studio of Alberto Giacometti: Collection of the Fondation Alberto et Annette Giacometti”, Centre Pompidou, Paris (2007–2008); Kunsthal Rotterdam (2008); Fondation Beyeler, Basel (2009), Buenos Aires (2012); Kunsthalle Hamburg (2013), and the High Museum of Art, Atlanta (1970).\n\nThe National Portrait Gallery, London's first solo exhibition of Giacometti's work, \"Pure Presence\" opened to five star reviews on 13 October 2015 (to January 10, 2016, in honour of the fiftieth anniversary of the artist's death).\n\nGiacometti's work is displayed in numerous public collections, including:\n\nThe Fondation Alberto et Annette Giacometti, having received a bequest from Alberto Giacometti's widow Annette, holds a collection of circa 5,000 works, frequently displayed around the world through exhibitions and long-term loans. A public interest institution, the Foundation was created in 2003 and aims at promoting, disseminating, preserving and protecting Alberto Giacometti's work.\n\nThe Alberto Giacometti-Stiftung established in Zürich in 1965, holds a smaller collection of works acquired from the collection of the Pittsburgh industrialist G. David Thompson.\n\nIn November 2000 a Giacometti bronze, \"Grande Femme Debout I\", sold for $14.3 million. \"Grande Femme Debout II\" was bought by the Gagosian Gallery for $27.4 million at Christie's auction in New York City on May 6, 2008.\n\n\"L'Homme qui marche I\", a life-sized bronze sculpture of a man, became one of the most expensive works of art and the most expensive sculpture ever sold at auction on February 2, 2010, when it sold for £65 million (US$104.3 million) at Sotheby's, London. \"Grande tête mince\", a large bronze bust, sold for $53.3 million just three months later.\n\n\"L'Homme au doigt\" (\"Pointing Man\") sold for $126 million (£81314455.32), or $141.3 million with fees, in Christie's May 11, 2015 Looking Forward to the Past sale in New York, a record for a sculpture at auction. The work had been in the same private collection for 45 years.\n\nGiacometti created the monument on the grave of Gerda Taro at Père Lachaise Cemetery.\n\nIn 2001 he was included in the exhibition held at the National Portrait Gallery, London.\n\nGiacometti and his sculpture \"L'Homme qui marche I\" appear on the current 100 Swiss franc banknote.\n\nAccording to a lecture by Michael Peppiatt at Cambridge University on July 8, 2010, Giacometti, who had a friendship with author/playwright Samuel Beckett, created a tree for the set of a 1961 Paris production of \"Waiting for Godot\".\n\n\n\n"}
{"id": "2439", "url": "https://en.wikipedia.org/wiki?curid=2439", "title": "Anthem", "text": "Anthem\n\nAn anthem is a musical composition of celebration, usually used as a symbol for a distinct group, particularly the national anthems of countries. Originally, and in music theory and religious contexts, it also refers more particularly to short sacred choral work and still more particularly to a specific form of Anglican church music.\n\n\"Anthem\" is derived from the Greek (\"antíphōna\") via Old English . Both words originally referred to antiphons, a call-and-response style of singing. The adjectival form is \"anthemic\".\n\nAnthems were originally a form of liturgical music. In the Church of England, the rubric appoints them to follow the third collect at morning and evening prayer. Several anthems are included in the British coronation service. The words are selected from Holy Scripture or in some cases from the Liturgy and the music is generally more elaborate and varied than that of psalm or hymn tunes. Being written for a trained choir rather than the congregation, the Anglican anthem is analogous to the motet of the Roman Catholic and Lutheran Churches but represents an essentially English musical form. Anthems may be described as \"verse\", \"full\", or \"full with verse\", depending on whether they are intended for soloists, the full choir, or both.\n\nThe anthem developed as a replacement for the Catholic \"votive antiphon\" commonly sung as an appendix to the main office to the Blessed Virgin Mary or other saints. During the Elizabethan period, notable anthems were composed by Thomas Tallis, William Byrd, Tye, and Farrant but they were not mentioned in the Book of Common Prayer until 1662 when the famous rubric \"In quires and places where they sing here followeth the Anthem\" first appears. Early anthems tended to be simple and homophonic in texture, so that the words could be clearly heard. During the 17th century, notable anthems were composed by Orlando Gibbons, Henry Purcell, and John Blow, with the verse anthem becoming the dominant musical form of the Restoration. In the 18th century, famed anthems were composed by Croft, Boyce, James Kent, James Nares, Benjamin Cooke, and Samuel Arnold. In the 19th, Samuel Sebastian Wesley wrote anthems influenced by contemporary oratorio which stretch to several movements and last twenty minutes or longer. Later in the century, Charles Villiers Stanford used symphonic techniques to produce a more concise and unified structure. Many anthems have been composed since this time, generally by organists rather than professional composers and often in a conservative style. Major composers have usually composed anthems in response to commissions and for special occasions. Examples include Edward Elgar's 1912 \"Great is the Lord\" and 1914 \"Give unto the Lord\" (both with orchestral accompaniment), Benjamin Britten's 1943 \"Rejoice in the Lamb\" (a modern example of a multi-movement anthem, today heard mainly as a concert piece), and, on a much smaller scale, Ralph Vaughan Williams's 1952 \"O Taste and See\" written for the coronation of Queen Elizabeth II. With the relaxation of the rule, in England at least, that anthems should be only in English, the repertoire has been greatly enhanced by the addition of many works from the Latin repertoire.\n\nThe word \"anthem\" is now commonly used to describe any celebratory song or composition for a distinct group, as in national anthems. Many pop songs are used as sports anthems, notably including Queen's \"We Are the Champions\" and \"We Will Rock You\", and some sporting events have their own anthems, most notably including UEFA Champions League. Further, some songs are artistically styled as anthems, whether or not they are used as such, including Marilyn Manson's \"Irresponsible Hate Anthem\", Silverchair's \"Anthem for the Year 2000\", and Toto's \"Child's Anthem\".\n\n"}
{"id": "2440", "url": "https://en.wikipedia.org/wiki?curid=2440", "title": "Albrecht Altdorfer", "text": "Albrecht Altdorfer\n\nAlbrecht Altdorfer (c. 1480 – February 12, 1538) was a German painter, engraver and architect of the Renaissance working in Regensburg. Along with Lucas Cranach the Elder and Wolf Huber he is regarded to be the main representative of the so-called Danube School setting biblical and historical subjects against landscape backgrounds of expressive colours. As an artist also making small intricate engravings he is seen to belong to the Nuremberg Little Masters.\n\nAltdorfer was born in Regensburg or Altdorf around 1480.\n\nHe acquired an interest in art from his father, Ulrich Altdorfer, who was a painter and miniaturist. At the start of his career, he won public attention by creating small, intimate modestly scaled works in unconventional media and with eccentric subject matter. He settled in the free imperial city of Regensburg, a town located on the Danube River in 1505, eventually becoming the town architect and a town councillor. His first signed works date to c. 1506, including engravings and drawings such the \"Stygmata of St. Francis\" and \"St. Jerome\". His models were niellos and copper engravings from the workshops of Jacopo de Barbari and Albrecht Dürer.\n\nAround 1511 or earlier, he travelled down the river and south into the Alps, where the scenery moved him so deeply that he became the first landscape painter in the modern sense, making him the leader of the Danube School, a circle that pioneered landscape as an independent genre, in southern Germany. From 1513 he was at the service of Maximilian I in Innsbruck, where he received several commissions from the imperial court. During the turmoil of the Protestant Reformation, he dedicated mostly to architecture; paintings of the period, showing his increasing attention to architecture, include the \"Nativity of the Virgin\".\n\nIn 1529 he executed \"The Battle of Alexander at Issus\" for Duke William IV of Bavaria. In the 1520s he returned to Regensburg as a wealthy man, and became a member of the city's council. He was also responsible for the fortifications of Regensburg.\n\nIn that period his works are influenced by artists such as Giorgione and Lucas Cranach, as shown by his \"Crucifixion\". In 1535 he was in Vienna. He died at Regensburg in 1538.\n\nThe remains of Altdorfer's surviving work comprises 55 panels, 120 drawings, 125 woodcuts, 78 engravings, 36 etchings, 24 paintings on parchment, and fragments from a mural for the bathhouse of the Kaiserhof in Regensburg. This production extends at least over the period 1504–1537. He signed and dated each one of his works.\n\nAltdorfer was the pioneer painter of pure landscape, making them the subject of the painting, as well as compositions dominated by their landscape; these comprise much of his oeuvre. He believed that the human figure should not disrupt nature, but rather participate in it or imitate its natural processes. Taking and developing the landscape style of Lucas Cranach the Elder, he shows the hilly landscape of the Danube valley with thick forests of drooping and crumbling firs and larches hung with moss, and often dramatic colouring from a rising or setting sun. His \"Landscape with Footbridge\" (National Gallery, London) of 1518–1520 is claimed to be the first pure landscape in oil. In this painting, Altdorfer places a large tree that is cut off by the margins at the center of the landscape, making it the central axis and focus within the piece. He uses anthropomorphism to give the tree human qualities such as the drapery of its limbs. He also made many fine finished drawings, mostly landscapes, in pen and watercolour such as the \"Landscape with the Woodcutter\" in 1522. The drawing opens at ground level on a clearing surrounding an enormous tree that is placed in the center, dominating the picture. It poses and gesticulates as if it was human, splaying its branches out in every corner. Halfway up the tree trunk, hangs a gabled shrine. At the time, a shrine like this might shelter an image of the Crucifixion or the Virgin Mary, but since it is turned away from the viewer, we are not sure what it truly is. At the bottom of the tree, a tiny figure of a seated man, crossed legged, holds a knife and axe, declaring his status in society/occupation.\n\nAlso, he often painted scenes of historical and biblical subjects, set in atmospheric landscapes. His best religious scenes are intense, with their glistening lights and glowing colours sometimes verging on the expressionistic. They often depict moments of intimacy between Christ and his mother, or various saints. His sacral masterpiece and one of the most famous religious works of art of the later Middle Ages is \"The Legend of St. Sebastian\" and \"The Passion of Christ\" of the so-called \"Sebastian Altar\" in \"St. Florian's Priory\" (\"Stift Sankt Florian\") near Linz, Upper Austria. When closed the altarpiece displayed the four panels of the legend of St. Sebastian’s Martyrdom, while the opened wings displayed the Stations of the Cross. Today the altarpiece is dismantled and the predellas depicting the two final scenes, \"Entombment\" and \"Resurrection\" were sold to Kunsthistorisches Museum in Vienna in 1923 and 1930. Both these paintings share a similar formal structure that consists of an open landscape that is seen beyond and through the opening of a dark grotto. The date of completion on the resurrection panel is 1518.\n\nAltdorfer often distorts perspective to subtle effect. His donor figures are often painted completely out of scale with the main scene, as in paintings of the previous centuries. He also painted some portraits; overall his painted oeuvre was not large. In his later works, Altdorfer moved more towards mannerism and began to depict the human form to the conformity of the Italian model, as well as dominate the picture with frank colors.\n\nHis rather atypical \"Battle of Issus\" (or of \"Alexander\") of 1529 was commissioned by William IV, Duke of Bavaria as part of a series of eight historical battle scenes destined to hang in the Residenz in Munich. Albrecht Altdorfer's depiction of the moment in 333 BCE when Alexander the Great routed Darius III for supremacy in Asia Minor is vast in ambition, sweeping in scope, vivid in imagery, rich in symbols, and obviously heroic—the Iliad of painting, as literary critic Friedrich Schlegel suggested In the painting, a swarming cast of thousands of soldiers surround the central action: Alexander on his white steed, leading two rows of charging cavalrymen, dashes after a fleeing Darius, who looks anxiously over his shoulder from a chariot. The opposing armies are distinguished by the colors of their uniforms: Darius' army in red and Alexander's in blue. The upper half of \"The Battle of Alexander\" expands with unreal rapidity into an arcing panorama comprehending vast coiling tracts of globe and sky. The victory also lies on the planar surface; The sun outshone the moon just as the Imperial and allied army successfully repel the Turks.\nBy making the mass number of soldiers blend within the landscape/painting, it shows that he believed that the usage and depiction of landscape was just as significant as a historical event, such as a war. He renounced the office of \"Mayor of Regensburg\" to accept the commission. Few of his other paintings resemble this apocalyptic scene of two huge armies dominated by an extravagant landscape seen from a very high viewpoint, which looks south over the whole Mediterranean from modern Turkey to include the island of Cyprus and the mouths of the Nile and the Red Sea (behind the isthmus to the left) on the other side. However his style here is a development of that of a number of miniatures of battle-scenes he had done much earlier for Maximilian I in his illuminated manuscript \"Triumphal Procession\" in 1512-14. It is thought to be the earliest painting to show the curvature of the Earth from a great height.\n\nThe \"Battle\" is now in the Alte Pinakothek, which has the best collection of Altdorfer's paintings, including also his small \"St. George and the Dragon\" (1510), in oil on parchment, where the two figures are tiny and almost submerged in the lush, dense forest that towers over them. Altdorfer seems to exaggerate the measurements of the forest in comparison to the figures: the leaves appear to be larger than the horse, showing the significance of nature and landscape. He also emphasizes line within the work, by displaying the upward growth of the forest with the vertical and diagonal lines of the trunks. There is a small opening of the forest on the lower right hand corner that provides a rest for your eyes. It serves to create depth within the painting and is the only place you can see the characters. The human form is completely absorbed by the thickness of the forest. Fantastic light effects provide a sense of mystery and dissolve the outline of objects. Without the contrast of light, the figures would blend in with its surrounding environment. Altdorfer's figures are invariably the complement of his romantic landscapes; for them he borrowed Albrecht Dürer's inventive iconography, but the panoramic setting is personal and has nothing to do with the fantasy landscapes of the Netherlands A \"\" (1526) set outside an Italianate skyscraper of a palace shows his interest in architecture. Another small oil on parchment, \"Danube Landscape with Castle Wörth\" (c. 1520) is one of the earliest accurate topographical paintings of a particular building in its setting, of a type that was to become a cliché in later centuries.\n\nAltdorfer was a significant printmaker, with numerous engravings and about ninety-three woodcuts. These included some for the \"Triumphs of Maximilian\", where he followed the overall style presumably set by Hans Burgkmair, although he was able to escape somewhat from this in his depictions of the more disorderly baggage-train, still coming through a mountain landscape. However most of his best prints are etchings, many of landscapes; in these he was able most easily to use his drawing style. He was one of the most successful early etchers, and was unusual for his generation of German printmakers in doing no book illustrations. He often combined etching and engraving techniques in a single plate, and produced about 122 intaglio prints altogether. Many of Altdorfer's prints are quite small in size, and he is considered to be of the main members of the group of artists known as the Little Masters. Arthur Mayger Hind considers his graphical work to be somewhat lacking in technical skill but with an \"intimate personal touch\", and notes his characteristic feeling for landscape.\n\nAs the superintendent of the municipal buildings Altdorfer had overseen the construction of several commercial structures, such as a slaughterhouse and a building for wine storage, possibly even designing them. He was considered to be an outstanding politician of his day. In 1517 he was a member of the \"Ausseren Rates\", the council on external affairs, and in this capacity was involved in the expulsion of the Jews, the destruction of the synagogue and in its place the construction of a church and shrine to the Schöne Maria that occurred in 1519. Altdorfer made etchings of the interior of the synagogue and designed a woodcut of the cult image of the Schöne Maria. In 1529–1530 he was also charged with reinforcing certain city fortifications in response to the Turkish threat.\n\nAlbrecht's brother, Erhard Altdorfer, was also a painter and printmaker in woodcut and engraving, and a pupil of Lucas Cranach the Elder.\n\n\n"}
{"id": "2441", "url": "https://en.wikipedia.org/wiki?curid=2441", "title": "House of Ascania", "text": "House of Ascania\n\nThe House of Ascania () is a dynasty of German rulers. It is also known as the House of Anhalt, named after its longest-held possession, Anhalt.\n\nThe Ascanians are named after Ascania (or Ascaria) Castle, \"Schloss Askanien\", which is located near and named after Aschersleben. The castle was seat of the County of Ascania, a title that was later subsumed into the titles of the princes of Anhalt.\n\nThe earliest known member of the house, Esiko, Count of Ballenstedt, first appears in a document of 1036. He is assumed to have been a grandson (through his mother) of Odo I, Margrave of the Saxon Ostmark. From Odo, the Ascanians inherited large properties in the Saxon Eastern March.\n\nEsiko's grandson was Otto, Count of Ballenstedt, who died in 1123. By Otto's marriage to Eilika, daughter of Magnus, Duke of Saxony, the Ascanians became heirs to half of the property of the House of Billung, former dukes of Saxony.\n\nOtto's son, Albert the Bear, became, with the help of his mother's inheritance, the first Ascanian duke of Saxony in 1139. However, he soon lost control of Saxony to the rival House of Guelph. \n\nAlbert inherited the Margraviate of Brandenburg in 1157 from its last Wendish ruler, Pribislav, and he became the first Ascanian margrave. Albert, and his descendants of the House of Ascania, then made considerable progress in Christianizing and Germanizing the lands. As a borderland between German and Slavic cultures, the country was known as a march.\n\nIn 1237 and 1244, two towns, Cölln and Berlin, were founded during the rule of Otto and Johann, grandsons of Margrave Albert the Bear. Later, they were united into one city, Berlin. The emblem of the House of Ascania, a red eagle and bear, became the heraldic emblems of Berlin. In 1320, the Brandenburg Ascanian line came to an end.\n\nAfter the Emperor had deposed the Guelph rulers of Saxony in 1180, Ascanians returned to rule the Duchy of Saxony, which had been reduced to its eastern half by the Emperor. However, even in eastern Saxony, the Ascanians could establish control only in limited areas, mostly near the River Elbe.\n\nIn the 13th century, the Principality of Anhalt was split off from the Duchy of Saxony. Later, the remaining state was split into Saxe-Lauenburg and Saxe-Wittenberg. The Ascanian dynasties in the two Saxon states became extinct in 1689 and in 1422, respectively, but Ascanians continued to rule in the smaller state of Anhalt and its various subdivisions until the monarchy was abolished in 1918.\n\nCatherine the Great, Empress of Russia from 1762–1796, was a member of the House of Ascania, herself the daughter of Christian August, Prince of Anhalt-Zerbst.\n\n\n\n"}
{"id": "2443", "url": "https://en.wikipedia.org/wiki?curid=2443", "title": "Acceleration", "text": "Acceleration\n\nAcceleration, in physics, is the rate of change of velocity of an object with respect to time. An object's acceleration is the net result of any and all forces acting on the object, as described by Newton's Second Law. The SI unit for acceleration is metre per second squared Accelerations are vector quantities (they have magnitude and direction) and add according to the parallelogram law. As a vector, the calculated net force is equal to the product of the object's mass (a scalar quantity) and its acceleration.\n\nFor example, when a car starts from a standstill (zero relative velocity) and travels in a straight line at increasing speeds, it is accelerating in the direction of travel. If the car turns, an acceleration occurs toward the new-direction. In this example, we can call the forward acceleration of the car a \"linear acceleration\", which passengers in the car might experience as a force pushing them back into their seats. When changing direction, we might call this \"non-linear acceleration\", which passengers might experience as a sideways force. If the speed of the car decreases, this is an acceleration in the opposite direction from the direction of the vehicle, sometimes called deceleration. Passengers may experience deceleration as a force lifting them forwards. Mathematically, there is no separate formula for deceleration: both are changes in velocity. Each of these accelerations (linear, non-linear, deceleration) might be felt by passengers until their velocity (speed and direction) matches that of the car. \n\nAn object's average acceleration over a period of time is its change in velocity formula_1 divided by the duration of the period formula_2. Mathematically,\n\nInstantaneous acceleration, meanwhile, is the limit of the average acceleration over an infinitesimal interval of time. In the terms of calculus, instantaneous acceleration is the derivative of the velocity vector with respect to time:\n\nIt can be seen that the integral of the acceleration function is the velocity function ; that is, the area under the curve of an acceleration vs. time ( vs. ) graph corresponds to velocity.\n\nAs acceleration is defined as the derivative of velocity, , with respect to time and velocity is defined as the derivative of position, , with respect to time, acceleration can be thought of as the second derivative of with respect to :\n\nAcceleration has the dimensions of velocity (L/T) divided by time, i.e. L.T. The SI unit of acceleration is the metre per second squared (m s); or \"metre per second per second\", as the velocity in metres per second changes by the acceleration value, every second.\n\nAn object moving in a circular motion—such as a satellite orbiting the Earth—is accelerating due to the change of direction of motion, although its speed may be constant. In this case it is said to be undergoing \"centripetal\" (directed towards the center) acceleration.\n\nProper acceleration, the acceleration of a body relative to a free-fall condition, is measured by an instrument called an accelerometer.\n\nIn classical mechanics, for a body with constant mass, the (vector) acceleration of the body's center of mass is proportional to the net force vector (i.e. sum of all forces) acting on it (Newton's second law):\nwhere F is the net force acting on the body, \"m\" is the mass of the body, and a is the center-of-mass acceleration. As speeds approach the speed of light, relativistic effects become increasingly large.\n\nThe velocity of a particle moving on a curved path as a function of time can be written as:\n\nwith \"v\"(\"t\") equal to the speed of travel along the path, and\n\na unit vector tangent to the path pointing in the direction of motion at the chosen moment in time. Taking into account both the changing speed \"v(t)\" and the changing direction of u, the acceleration of a particle moving on a curved path can be written using the chain rule of differentiation for the product of two functions of time as:\n\nwhere u is the unit (inward) normal vector to the particle's trajectory (also called \"the principal normal\"), and r is its instantaneous radius of curvature based upon the osculating circle at time \"t\". These components are called the tangential acceleration and the normal or radial acceleration (or centripetal acceleration in circular motion, see also circular motion and centripetal force).\n\nGeometrical analysis of three-dimensional space curves, which explains tangent, (principal) normal and binormal, is described by the Frenet–Serret formulas.\n\n\"Uniform\" or \"constant\" acceleration is a type of motion in which the velocity of an object changes by an equal amount in every equal time period.\n\nA frequently cited example of uniform acceleration is that of an object in free fall in a uniform gravitational field. The acceleration of a falling body in the absence of resistances to motion is dependent only on the gravitational field strength \"g\" (also called \"acceleration due to gravity\"). By Newton's Second Law the force, \"F\", acting on a body is given by:\n\nBecause of the simple analytic properties of the case of constant acceleration, there are simple formulas relating the displacement, initial and time-dependent velocities, and acceleration to the time elapsed:\n\nwhere\n\nIn particular, the motion can be resolved into two orthogonal parts, one of constant velocity and the other according to the above equations. As Galileo showed, the net result is parabolic motion, which describes, e. g., the trajectory of a projectile in a vacuum near the surface of Earth.\n\nUniform circular motion, that is constant speed along a circular path, is an example of a body experiencing acceleration resulting in velocity of a constant magnitude but change of direction. In this case, because the direction of the object's motion is constantly changing, being tangential to the circle, the object's linear velocity vector also changes, but its speed does not. This acceleration is a radial acceleration since it is always directed toward the centre of the circle and takes the magnitude:\n\nwhere formula_24 is the object's linear speed along the circular path. Equivalently, the radial acceleration vector (formula_25) may be calculated from the object's angular velocity formula_26:\n\nwhere formula_28 is a vector directed from the centre of the circle and equal in magnitude to the radius. The negative shows that the acceleration vector is directed towards the centre of the circle (opposite to the radius).\n\nThe acceleration and the net force acting on a body in uniform circular motion are directed \"toward\" the centre of the circle; that is, it is centripetal. Whereas the so-called 'centrifugal force' appearing to act outward on the body is really a pseudo force experienced in the frame of reference of the body in circular motion, due to the body's linear momentum at a tangent to the circle.\n\nWith nonuniform circular motion, i.e., the speed along the curved path changes, a transverse acceleration is produced equal to the rate of change of the angular speed around the circle times the radius of the circle. That is,\n\nThe transverse (or tangential) acceleration is directed at right angles to the radius vector and takes the sign of the angular acceleration (formula_30).\n\nThe special theory of relativity describes the behavior of objects traveling relative to other objects at speeds approaching that of light in a vacuum. Newtonian mechanics is exactly revealed to be an approximation to reality, valid to great accuracy at lower speeds. As the relevant speeds increase toward the speed of light, acceleration no longer follows classical equations.\n\nAs speeds approach that of light, the acceleration produced by a given force decreases, becoming infinitesimally small as light speed is approached; an object with mass can approach this speed asymptotically, but never reach it.\n\nUnless the state of motion of an object is known, it is impossible to distinguish whether an observed force is due to gravity or to acceleration—gravity and inertial acceleration have identical effects. Albert Einstein called this the principle of equivalence, and said that only observers who feel no force at all—including the force of gravity—are justified in concluding that they are not accelerating.\n\n"}
{"id": "2444", "url": "https://en.wikipedia.org/wiki?curid=2444", "title": "Conservation-restoration of cultural heritage", "text": "Conservation-restoration of cultural heritage\n\nThe conservation-restoration of cultural heritage focuses on protection and care of tangible cultural heritage, including artworks, architecture, archaeology, and museum collections. Conservation activities include preventive conservation, examination, documentation, research, treatment, and education. This field is closely allied with conservation science, curators and registrars.\n\nConservation of cultural heritage involves protection and restoration using \"any methods that prove effective in keeping that property in as close to its original condition as possible for as long as possible.\" Conservation of cultural heritage is often associated with art collections and museums and involves collection care and management through tracking, examination, documentation, exhibition, storage, preventative conservation, and restoration.\n\nThe scope has widened from art conservation, involving protection and care of artwork and architecture, to conservation of cultural heritage, also including protection and care of a broad set of other cultural and historical works. Conservation of cultural heritage can be described as a type of ethical stewardship.\n\nConservation of cultural heritage applies simple ethical guidelines:\n\nOften there are compromises between preserving appearance, maintaining original design and material properties, and ability to reverse changes. Reversibility is now emphasized so as to reduce problems with future treatment, investigation, and use.\n\nIn order for conservators to decide upon an appropriate conservation strategy and apply their professional expertise accordingly, they must take into account views of the stakeholder, the values and meaning of the work, and the physical needs of the material.\n\nCesare Brandi in his \"Theory of Restoration\", describes restoration as \"the methodological moment in which the work of art is appreciated in its material form and in its historical and aesthetic duality, with a view to transmitting it to the future\".\n\nSome consider the tradition of conservation of cultural heritage in Europe to have begun in 1565 with the restoration of the Sistine Chapel frescoes, but more ancient examples include the work of Cassiodorus.\n\nThe care of cultural heritage has a long history, one that was primarily aimed at fixing and mending objects for their continued use and aesthetic enjoyment. Until the early 20th century, artists were normally the ones called upon to repair damaged artworks. During the 19th century, however, the fields of science and art became increasingly intertwined as scientists such as Michael Faraday began to study the damaging effects of the environment to works of art. Louis Pasteur carried out scientific analysis on paint as well. However, perhaps the first organized attempt to apply a theoretical framework to the conservation of cultural heritage came with the founding in the United Kingdom of the Society for the Protection of Ancient Buildings in 1877. The society was founded by William Morris and Philip Webb, both of whom were deeply influenced by the writings of John Ruskin. During the same period, a French movement with similar aims was being developed under the direction of Eugène Viollet-le-Duc, an architect and theorist, famous for his restorations of medieval buildings.\nConservation of cultural heritage as a distinct field of study initially developed in Germany, where in 1888 Friedrich Rathgen became the first chemist to be employed by a Museum, the Koniglichen Museen, Berlin (Royal Museums of Berlin). He not only developed a scientific approach to the care of objects in the collections, but disseminated this approach by publishing a Handbook of Conservation in 1898. The early development of conservation of cultural heritage in any area of the world is usually linked to the creation of positions for chemists within museums. In the United Kingdom, pioneering research into painting materials and conservation, ceramics, and stone conservation was conducted by Arthur Pillans Laurie, academic chemist and Principal of Heriot-Watt University from 1900. Laurie's interests were fostered by William Holman Hunt. In 1924 the chemist Harold Plenderleith began to work at the British Museum with Dr. Alexander Scott in the newly created Department of Scientific and Industrial Research, thus giving birth to the conservation profession in the UK. This department was created by the museum to address the deteriorating condition of objects in the collection, damages which were a result of their being stored in the London Underground tunnels during the First World War. The creation of this department moved the focus for the development of conservation theory and practice from Germany to Britain, and made the latter a prime force in this fledgling field. In 1956 Plenderleith wrote a significant handbook called The Conservation of Antiquities and Works of Art, which supplanted Rathgen's earlier tome and set new standards for the development of art and conservation science.\n\nIn the United States, the development of conservation of cultural heritage can be traced to the Fogg Art Museum, and Edward Waldo Forbes, its director from 1909 to 1944. He encouraged technical investigation, and was Chairman of the Advisory Committee for the first technical journal, Technical Studies in the Field of the Fine Arts, published by the Fogg from 1932 to 1942. Importantly he also brought onto the museum staff chemists. Rutherford John Gettens was the first of usch in the US to be permanently employed by an art museum. He worked with George L. Stout, the founder and first editor of Technical Studies. Gettens and Stout co-authored Painting Materials: A Short Encyclopaedia in 1942, reprinted in 1966. This compendium is still cited regularly. Only a few dates and descriptions in Gettens' and Stout's book are now outdated.\n\nGeorge T. Oliver, of Oliver Brothers Art Restoration and Art Conservation-Boston\n(Est. 1850 in New York City) invented the vacuum hot table for relining paintings in 1920s; he filed a patent for the table in 1937. Taylor's prototype table, which he designed and constructed, is still in operation. Oliver Brothers is believed to be the first and the oldest continuously operating art restoration company in the United States.\n\nThe focus of conservation development then accelerated in Britain and America, and it was in Britain that the first International Conservation Organisations developed. The International Institute for Conservation of Historic and Artistic Works (IIC) was incorporated under British law in 1950 as \"a permanent organization to co-ordinate and improve the knowledge, methods, and working standards needed to protect and preserve precious materials of all kinds.\" The rapid growth of conservation professional organizations, publications, journals, newsletters, both internationally and in localities, has spearheaded the development of the conservation profession, both practically and theoretically. Art historians and theorists such as Cesare Brandi have also played a significant role in developing conservation science theory. In recent years ethical concerns have been at the forefront of developments in conservation. Most significantly has been the idea of preventive conservation. This concept is based in part on the pioneering work by Garry Thomson CBE, and his book the Museum Environment, first published in 1978. Thomson was associated with the National Gallery in London; it was here that he established a set of guidelines or environmental controls for the best conditions in which objects could be stored and displayed within the museum environment. Although his exact guidelines are no longer rigidly followed, they did inspire this field of conservation.\n\nThe conservator's work is guided by ethical standards. These take the form of applied ethics. Ethical standards have been established across the world, and national and international ethical guidelines have been written. One such example is:\n\n\nConservation OnLine provides resources on ethical issues in conservation, including examples of codes of ethics and guidelines for professional conduct in conservation and allied fields; and charters and treaties pertaining to ethical issues involving the preservation of cultural property.\n\nAs well as standards of practice conservators deal with wider ethical concerns, such as the debates as to whether all art is worth preserving.\n\nMany cultural works are sensitive to environmental conditions such as temperature, humidity and exposure to visible light and ultraviolet radiation. These works must be protected in controlled environments where such variables are maintained within a range of damage-limiting levels. For example, watercolour paintings usually require shielding from sunlight to prevent fading of pigments.\n\nCollections care is an important element of museum policy. It is an essential responsibility of members of the museum profession to create and maintain a protective environment for the collections in their care, whether in store, on display, or in transit. A museum should carefully monitor the condition of collections to determine when an artifact requires conservation work and the services of a qualified conservator.\n\nA principal aim of a cultural conservator is to reduce the rate of deterioration of an object. Both non-interventive and interventive methodologies may be employed in pursuit of this goal. Interventive conservation refers to any direct interaction between the conservator and the material fabric of the object. Interventive actions are carried out for a variety of reasons, including aesthetic choices, stabilization needs for structural integrity, or cultural requirements for intangible continuity. Examples of interventive treatments include the removal of discolored varnish from a painting, the application of wax to a sculpture, and the washing and rebinding of a book. Ethical standards within the field require that the conservator fully justify interventive actions and carry out documentation before, during, and after the treatment.\n\nOne of the guiding principles of conservation of cultural heritage has traditionally been the idea of reversibility, that all interventions with the object should be fully reversible and that the object should be able to be returned to the state in which it was prior to the conservator's intervention. Although this concept remains a guiding principle of the profession, it has been widely critiqued within the conservation profession and is now considered by many to be \"a fuzzy concept.\" Another important principle of conservation is that all alterations should be well documented and should be clearly distinguishable from the original object.\n\nAn example of a highly publicized interventive conservation effort would be the conservation work conducted on the Sistine Chapel.\n\nConservators routinely use chemical and scientific analysis for the examination and treatment of cultural works. The modern conservation laboratory uses equipment such as microscopes, spectrometers, and various x-ray regime instruments to better understand objects and their components. The data thus collected helps in deciding the conservation treatments to be provided to the object.\n\nHeritage Preservation, in partnership with the Institute of Museum and Library Services, a U.S. federal agency, produced The Heritage Health Index. The results of this work was the report A Public Trust at Risk: The Heritage Health Index Report on the State of America's Collections, which was published in December 2005 and concluded that immediate action is needed to prevent the loss of 190 million artifacts that are in need of conservation treatment. The report made four recommendations:\n\nIn October 2006, the Department for Culture, Media and Sport, a governmental department, authored a document: \"Understanding the Future: Priorities for England's Museums\". This document was based on several years of consultation aimed to lay out the government's priorities for museums in the 21st century.\n\nThe document listed the following as priorities for the next decade:\n\n\nThe conservation profession response to this report was on the whole less than favourable, the Institute of Conservation (ICON) published their response under the title \"A Failure of Vision\". It had the following to say:\n\nConcluding: \n\nFurther to this the ICON website summary report lists the following specific recommendations:\n\n\nIn November 2008, the UK-based think tank Demos published an influential pamphlet entitled \"It's a material world: caring for the public realm\", in which they argue for integrating the public directly into efforts to conserve material culture, particularly that which is in the public, their argument, as stated on page 16, demonstrates their belief that society can benefit from conservation as a paradigm as well as a profession:\n\nTraining in conservation of cultural heritage for many years took the form of an apprenticeship, whereby an apprentice slowly developed the necessary skills to undertake their job. For some specializations within conservation this is still the case. However, it is more common in the field of conservation today that the training required to become a practicing conservator comes from a recognized university course in conservation of cultural heritage.\n\nThe University can rarely provide all the necessary training in first hand experience that an apprenticeship can, and therefore in addition to graduate level training the profession also tends towards encouraging conservation students to spend time as an intern.\n\nConservation of cultural heritage is an interdisciplinary field as conservators have backgrounds in the fine arts, sciences (including chemistry, biology, and materials science), and closely related disciplines, such as art history, archaeology, studio art, and anthropology. They also have design, fabrication, artistic, and other special skills necessary for the practical application of that knowledge.\n\nWithin the various schools that teach conservation of cultural heritage, the approach differs according to the educational and vocational system within the country, and the focus of the school itself. This is acknowledged by the American Institute for Conservation who advise \"Specific admission requirements differ and potential candidates are encouraged to contact the programs directly for details on prerequisites, application procedures, and program curriculum\".\n\nSocieties devoted to the care of cultural heritage have been in existence around the world for many years. One early example is the founding in 1877 of the Society for the Protection of Ancient Buildings in Britain to protect the built heritage, this society continues to be active today.\n\nThe built heritage was at the forefront of the growth of member based organizations in the United States. Preservation Virginia, founded in Richmond in 1889 as the Association for the Preservation of Virginia Antiquities, was the United States' first statewide historic preservation group.\n\nToday, professional conservators join and take part in the activities of numerous conservation associations and professional organizations with the wider field, and within their area of specialization.\n\nThese organizations exist to \"support the conservation professionals who preserve our cultural heritage\".\n\nThis involves upholding professional standards, promoting research and publications, providing educational opportunities, and fostering the exchange of knowledge among cultural conservators, allied professionals, and the public.\n\n\n\n\n\n\n\nExternal lists of international cultural heritage documents:\n"}
{"id": "2447", "url": "https://en.wikipedia.org/wiki?curid=2447", "title": "Anton Chekhov", "text": "Anton Chekhov\n\nAnton Pavlovich Chekhov (, ; 29 January 1860 – 15 July 1904) was a Russian playwright and short story writer, who is considered to be among the greatest writers of short fiction in history. His career as a playwright produced four classics and his best short stories are held in high esteem by writers and critics. Along with Henrik Ibsen and August Strindberg, Chekhov is often referred to as one of the three seminal figures in the birth of early modernism in the theatre. Chekhov practiced as a medical doctor throughout most of his literary career: \"Medicine is my lawful wife\", he once said, \"and literature is my mistress.\"\n\nChekhov renounced the theatre after the reception of \"The Seagull\" in 1896, but the play was revived to acclaim in 1898 by Konstantin Stanislavski's Moscow Art Theatre, which subsequently also produced Chekhov's \"Uncle Vanya\" and premiered his last two plays, \"Three Sisters\" and \"The Cherry Orchard\". These four works present a challenge to the acting ensemble as well as to audiences, because in place of conventional action Chekhov offers a \"theatre of mood\" and a \"submerged life in the text\".\n\nChekhov had at first written stories only for financial gain, but as his artistic ambition grew, he made formal innovations which have influenced the evolution of the modern short story. He made no apologies for the difficulties this posed to readers, insisting that the role of an artist was to ask questions, not to answer them.\n\nAnton Chekhov was born on the feast day of St. Anthony the Great (17 January Old Style) 29 January 1860, the third of six surviving children, in Taganrog, a port on the Sea of Azov in southern Russia. His father, Pavel Yegorovich Chekhov, the son of a former serf and his Ukrainian wife, were from the village Vilkhovatka near Kobeliaky (Poltava Region in modern-day Ukraine) and ran a grocery store. A director of the parish choir, devout Orthodox Christian, and physically abusive father, Pavel Chekhov has been seen by some historians as the model for his son's many portraits of hypocrisy. Chekhov's mother, Yevgeniya (Morozova), was an excellent storyteller who entertained the children with tales of her travels with her cloth-merchant father all over Russia. \"Our talents we got from our father,\" Chekhov remembered, \"but our soul from our mother.\"\nIn adulthood, Chekhov criticised his brother Alexander's treatment of his wife and children by reminding him of Pavel's tyranny: \"Let me ask you to recall that it was despotism and lying that ruined your mother's youth. Despotism and lying so mutilated our childhood that it's sickening and frightening to think about it. Remember the horror and disgust we felt in those times when Father threw a tantrum at dinner over too much salt in the soup and called Mother a fool.\"\n\nChekhov attended the Greek School in Taganrog and the Taganrog \"Gymnasium\" (since renamed the Chekhov Gymnasium), where he was kept down for a year at fifteen for failing an examination in Ancient Greek. He sang at the Greek Orthodox monastery in Taganrog and in his father's choirs. In a letter of 1892, he used the word \"suffering\" to describe his childhood and recalled:\n\nHe later became an atheist.\n\nIn 1876, Chekhov's father was declared bankrupt after overextending his finances building a new house, having been cheated by a contractor called Mironov. To avoid debtor's prison he fled to Moscow, where his two eldest sons, Alexander and Nikolay, were attending university. The family lived in poverty in Moscow, Chekhov's mother physically and emotionally broken by the experience. Chekhov was left behind to sell the family's possessions and finish his education.\n\nChekhov remained in Taganrog for three more years, boarding with a man called Selivanov who, like Lopakhin in \"The Cherry Orchard\", had bailed out the family for the price of their house. Chekhov had to pay for his own education, which he managed by private tutoring, catching and selling goldfinches, and selling short sketches to the newspapers, among other jobs. He sent every ruble he could spare to his family in Moscow, along with humorous letters to cheer them up. During this time, he read widely and analytically, including the works of Cervantes, Turgenev, Goncharov, and Schopenhauer, and wrote a full-length comic drama, \"Fatherless\", which his brother Alexander dismissed as \"an inexcusable though innocent fabrication.\" Chekhov also enjoyed a series of love affairs, one with the wife of a teacher.\n\nIn 1879, Chekhov completed his schooling and joined his family in Moscow, having gained admission to the medical school at I.M. Sechenov First Moscow State Medical University.\n\nChekhov now assumed responsibility for the whole family. To support them and to pay his tuition fees, he wrote daily short, humorous sketches and vignettes of contemporary Russian life, many under pseudonyms such as \"Antosha Chekhonte\" (Антоша Чехонте) and \"Man without a Spleen\" (Человек без селезенки). His prodigious output gradually earned him a reputation as a satirical chronicler of Russian street life, and by 1882 he was writing for \"Oskolki\" (\"Fragments\"), owned by Nikolai Leykin, one of the leading publishers of the time. Chekhov's tone at this stage was harsher than that familiar from his mature fiction.\n\nIn 1884, Chekhov qualified as a physician, which he considered his principal profession though he made little money from it and treated the poor free of charge.\n\nIn 1884 and 1885, Chekhov found himself coughing blood, and in 1886 the attacks worsened, but he would not admit his tuberculosis to his family or his friends. He confessed to Leykin, \"I am afraid to submit myself to be sounded by my colleagues.\" He continued writing for weekly periodicals, earning enough money to move the family into progressively better accommodations.\n\nEarly in 1886 he was invited to write for one of the most popular papers in St. Petersburg, \"Novoye Vremya\" (\"New Times\"), owned and edited by the millionaire magnate Alexey Suvorin, who paid a rate per line double Leykin's and allowed Chekhov three times the space. Suvorin was to become a lifelong friend, perhaps Chekhov's closest.\n\nBefore long, Chekhov was attracting literary as well as popular attention. The sixty-four-year-old Dmitry Grigorovich, a celebrated Russian writer of the day, wrote to Chekhov after reading his short story \"The Huntsman\" that \"You have \"real\" talent, a talent that places you in the front rank among writers in the new generation.\" He went on to advise Chekhov to slow down, write less, and concentrate on literary quality.\n\nChekhov replied that the letter had struck him \"like a thunderbolt\" and confessed, \"I have written my stories the way reporters write up their notes about fires — mechanically, half-consciously, caring nothing about either the reader or myself.\"\" The admission may have done Chekhov a disservice, since early manuscripts reveal that he often wrote with extreme care, continually revising. Grigorovich's advice nevertheless inspired a more serious, artistic ambition in the twenty-six-year-old. In 1888, with a little string-pulling by Grigorovich, the short story collection \"At Dusk\" (\"V Sumerkakh\") won Chekhov the coveted Pushkin Prize \"for the best literary production distinguished by high artistic worth.\"\n\nIn 1887, exhausted from overwork and ill health, Chekhov took a trip to Ukraine, which reawakened him to the beauty of the steppe. On his return, he began the novella-length short story \",\" which he called \"something rather odd and much too original,\" and which was eventually published in \"Severny Vestnik\" (\"The Northern Herald\"). In a narrative that drifts with the thought processes of the characters, Chekhov evokes a chaise journey across the steppe through the eyes of a young boy sent to live away from home, and his companions, a priest and a merchant. \"The Steppe\" has been called a \"dictionary of Chekhov's poetics\", and it represented a significant advance for Chekhov, exhibiting much of the quality of his mature fiction and winning him publication in a literary journal rather than a newspaper.\n\nIn autumn 1887, a theatre manager named Korsh commissioned Chekhov to write a play, the result being \"Ivanov\", written in a fortnight and produced that November. Though Chekhov found the experience \"sickening\" and painted a comic portrait of the chaotic production in a letter to his brother Alexander, the play was a hit and was praised, to Chekhov's bemusement, as a work of originality. Although Chekhov did not fully realize it at the time, Chekhov's plays, such as \"The Seagull\" (written in 1895), \"Uncle Vanya\" (written in 1897), \"The Three Sisters\" (written in 1900), and \"The Cherry Orchard\" (written in 1903) served as a revolutionary backbone to what is common sense to the medium of acting to this day: an effort to recreate and express the \"realism\" of how people truly act and speak with each other and translating it to the stage in order to manifest the human condition as accurately as possible in hopes to make the audience reflect upon their own definition of what it means to be human, warts and all.\n\nThis philosophy of approaching the art of acting has stood not only steadfast, but as the cornerstone of acting for much of the 20th century to this day. Mikhail Chekhov considered \"Ivanov\" a key moment in his brother's intellectual development and literary career. From this period comes an observation of Chekhov's that has become known as Chekhov's gun, a dramatic principle that requires that every element in a narrative be necessary and irreplaceable, and that everything else be removed.\nThe death of Chekhov's brother Nikolay from tuberculosis in 1889 influenced \"A Dreary Story\", finished that September, about a man who confronts the end of a life that he realises has been without purpose. Mikhail Chekhov, who recorded his brother's depression and restlessness after Nikolay's death, was researching prisons at the time as part of his law studies, and Anton Chekhov, in a search for purpose in his own life, himself soon became obsessed with the issue of prison reform.\n\nIn 1890, Chekhov undertook an arduous journey by train, horse-drawn carriage, and river steamer to the Russian Far East and the \"katorga\", or penal colony, on Sakhalin Island, north of Japan, where he spent three months interviewing thousands of convicts and settlers for a census. The letters Chekhov wrote during the two-and-a-half-month journey to Sakhalin are considered to be among his best. His remarks to his sister about Tomsk were to become notorious.\n\nThe inhabitants of Tomsk later retaliated by erecting a mocking statue of Chekhov.\n\nChekhov witnessed much on Sakhalin that shocked and angered him, including floggings, embezzlement of supplies, and forced prostitution of women. He wrote, \"There were times I felt that I saw before me the extreme limits of man's degradation.\" He was particularly moved by the plight of the children living in the penal colony with their parents. For example:\n\nChekhov later concluded that charity was not the answer, but that the government had a duty to finance humane treatment of the convicts. His findings were published in 1893 and 1894 as \"Ostrov Sakhalin\" (\"The Island of Sakhalin\"), a work of social science, not literature, that is worthy and informative rather than brilliant. Chekhov found literary expression for the \"Hell of Sakhalin\" in his long short story \",\" the last section of which is set on Sakhalin, where the murderer Yakov loads coal in the night while longing for home. Chekhov's writing on Sakhalin is the subject of brief comment and analysis in Haruki Murakami's novel 1Q84. It is also the subject of a poem by the Nobel Prize winner Seamus Heaney, \"Chekhov on Sakhalin\" (collected in the volume \"Station Island\").\n\nIn 1892, Chekhov bought the small country estate of Melikhovo, about forty miles south of Moscow, where he lived with his family until 1899. \"It's nice to be a lord,\" he joked to his friend Ivan Leontyev (who wrote humorous pieces under the pseudonym Shcheglov), but he took his responsibilities as a landlord seriously and soon made himself useful to the local peasants. As well as organising relief for victims of the famine and cholera outbreaks of 1892, he went on to build three schools, a fire station, and a clinic, and to donate his medical services to peasants for miles around, despite frequent recurrences of his tuberculosis.\n\nMikhail Chekhov, a member of the household at Melikhovo, described the extent of his brother's medical commitments:\n\nChekhov's expenditure on drugs was considerable, but the greatest cost was making journeys of several hours to visit the sick, which reduced his time for writing. However, Chekhov's work as a doctor enriched his writing by bringing him into intimate contact with all sections of Russian society: for example, he witnessed at first hand the peasants' unhealthy and cramped living conditions, which he recalled in his short story \"Peasants\". Chekhov visited the upper classes as well, recording in his notebook: \"Aristocrats? The same ugly bodies and physical uncleanliness, the same toothless old age and disgusting death, as with market-women.\"\n\nIn 1894, Chekhov began writing his play \"The Seagull\" in a lodge he had built in the orchard at Melikhovo. In the two years since he had moved to the estate, he had refurbished the house, taken up agriculture and horticulture, tended the orchard and the pond, and planted many trees, which, according to Mikhail, he \"looked after ... as though they were his children. Like Colonel Vershinin in his \"Three Sisters\", as he looked at them he dreamed of what they would be like in three or four hundred years.\"\n\nThe first night of \"The Seagull\", at the Alexandrinsky Theatre in St. Petersburg on 17 October 1896, was a fiasco, as the play was booed by the audience, stinging Chekhov into renouncing the theatre. But the play so impressed the theatre director Vladimir Nemirovich-Danchenko that he convinced his colleague Konstantin Stanislavski to direct a new production for the innovative Moscow Art Theatre in 1898. Stanislavski's attention to psychological realism and ensemble playing coaxed the buried subtleties from the text, and restored Chekhov's interest in playwriting. The Art Theatre commissioned more plays from Chekhov and the following year staged \"Uncle Vanya\", which Chekhov had completed in 1896.\n\nIn March 1897, Chekhov suffered a major hemorrhage of the lungs while on a visit to Moscow. With great difficulty he was persuaded to enter a clinic, where the doctors diagnosed tuberculosis on the upper part of his lungs and ordered a change in his manner of life.\n\nAfter his father's death in 1898, Chekhov bought a plot of land on the outskirts of Yalta and built a villa, into which he moved with his mother and sister the following year. Though he planted trees and flowers, kept dogs and tame cranes, and received guests such as Leo Tolstoy and Maxim Gorky, Chekhov was always relieved to leave his \"hot Siberia\" for Moscow or travels abroad. He vowed to move to Taganrog as soon as a water supply was installed there. In Yalta he completed two more plays for the Art Theatre, composing with greater difficulty than in the days when he \"wrote serenely, the way I eat pancakes now\". He took a year each over \"Three Sisters\" and \"The Cherry Orchard\".\n\nOn 25 May 1901, Chekhov married Olga Knipper quietly, owing to his horror of weddings. She was a former protegée and sometime lover of Nemirovich-Danchenko whom he had first met at rehearsals for \"The Seagull\". Up to that point, Chekhov, known as \"Russia's most elusive literary bachelor,\" had preferred passing liaisons and visits to brothels over commitment. He had once written to Suvorin:\n\nThe letter proved prophetic of Chekhov's marital arrangements with Olga: he lived largely at Yalta, she in Moscow, pursuing her acting career. In 1902, Olga suffered a miscarriage; and Donald Rayfield has offered evidence, based on the couple's letters, that conception may have occurred when Chekhov and Olga were apart, although Russian scholars have rejected that claim. The literary legacy of this long-distance marriage is a correspondence that preserves gems of theatre history, including shared complaints about Stanislavski's directing methods and Chekhov's advice to Olga about performing in his plays.\n\nIn Yalta, Chekhov wrote one of his most famous stories, \"The Lady with the Dog\" (also translated from the Russian as \"Lady with Lapdog\"), which depicts what at first seems a casual liaison between a cynical married man and an unhappy married woman who meet while vacationing in Yalta. Neither expects anything lasting from the encounter. Unexpectedly though, they gradually fall deeply in love and end up risking scandal and the security of their family lives. The story masterfully captures their feelings for each other, the inner transformation undergone by the disillusioned male protagonist as a result of falling deeply in love, and their inability to resolve the matter by either letting go of their families or of each other.\n\nBy May 1904, Chekhov was terminally ill with tuberculosis. Mikhail Chekhov recalled that \"everyone who saw him secretly thought the end was not far off, but the nearer [he] was to the end, the less he seemed to realise it.\" On 3 June, he set off with Olga for the German spa town of Badenweiler in the Black Forest, from where he wrote outwardly jovial letters to his sister Masha, describing the food and surroundings, and assuring her and his mother that he was getting better. In his last letter, he complained about the way German women dressed.\n\nChekhov's death has become one of \"the great set pieces of literary history,\" retold, embroidered, and fictionalised many times since, notably in the short story \"Errand\" by Raymond Carver. In 1908, Olga wrote this account of her husband's last moments:\n\nChekhov's body was transported to Moscow in a refrigerated railway car meant for oysters, a detail that offended Gorky. Some of the thousands of mourners followed the funeral procession of a General Keller by mistake, to the accompaniment of a military band. Chekhov was buried next to his father at the Novodevichy Cemetery.\n\nA few months before he died, Chekhov told the writer Ivan Bunin that he thought people might go on reading his writings for seven years. \"Why seven?\" asked Bunin. \"Well, seven and a half,\" Chekhov replied. \"That's not bad. I've got six years to live.\"\n\nChekhov's posthumous reputation greatly exceeded his expectations. The ovations for the play \"The Cherry Orchard\" in the year of his death served to demonstrate the Russian public's acclaim for the writer, which placed him second in literary celebrity only to Tolstoy, who outlived him by six years. Tolstoy was an early admirer of Chekhov's short stories and had a series that he deemed \"first quality\" and \"second quality\" bound into a book. In the first category were: \"Children\", \"The Chorus Girl\", \"A Play\", \"Home\", \"Misery\", \"The Runaway\", \"In Court\", \"Vanka\", \"Ladies\", \"A Malefactor\", \"The Boys\", \"Darkness\", \"Sleepy\", \"The Helpmate\", and \"The Darling\"\"; in the second: \"A Transgression\", \"Sorrow\", \"The Witch\", \"Verochka\", \"In a Strange Land\", \"The Cook's Wedding\", \"A Tedious Business\", \"An Upheaval\", \"Oh! The Public!\", \"The Mask\", \"A Woman's Luck\", \"Nerves\", \"The Wedding\", \"A Defenseless Creature\", and \"Peasant Wives.\"\n\nIn Chekhov's lifetime, British and Irish critics generally did not find his work pleasing; E. J. Dillon thought \"the effect on the reader of Chekhov's tales was repulsion at the gallery of human waste represented by his fickle, spineless, drifting people\" and R. E. C. Long said \"Chekhov's characters were repugnant, and that Chekhov reveled in stripping the last rags of dignity from the human soul\". After his death, Chekhov was reappraised. Constance Garnett's translations won him an English-language readership and the admiration of writers such as James Joyce, Virginia Woolf, and Katherine Mansfield, whose story \"The Child Who Was Tired\" is similar to Chekhov's \"Sleepy\". The Russian critic D. S. Mirsky, who lived in England, explained Chekhov's popularity in that country by his \"unusually complete rejection of what we may call the heroic values.\" In Russia itself, Chekhov's drama fell out of fashion after the revolution, but it was later incorporated into the Soviet canon. The character of Lopakhin, for example, was reinvented as a hero of the new order, rising from a modest background so as eventually to possess the gentry's estates.\n\nOne of the first non-Russians to praise Chekhov's plays was George Bernard Shaw, who subtitled his \"Heartbreak House\" \"A Fantasia in the Russian Manner on English Themes,\" and pointed out similarities between the predicament of the British landed class and that of their Russian counterparts as depicted by Chekhov: \"the same nice people, the same utter futility.\"\n\nIn the United States, Chekhov's reputation began its rise slightly later, partly through the influence of Stanislavski's system of acting, with its notion of subtext: \"Chekhov often expressed his thought not in speeches,\" wrote Stanislavski, \"but in pauses or between the lines or in replies consisting of a single word ... the characters often feel and think things not expressed in the lines they speak.\" The Group Theatre, in particular, developed the subtextual approach to drama, influencing generations of American playwrights, screenwriters, and actors, including Clifford Odets, Elia Kazan and, in particular, Lee Strasberg. In turn, Strasberg's Actors Studio and the \"Method\" acting approach influenced many actors, including Marlon Brando and Robert De Niro, though by then the Chekhov tradition may have been distorted by a preoccupation with realism. In 1981, the playwright Tennessee Williams adapted \"The Seagull\" as \"The Notebook of Trigorin\". One of Anton's nephews, Michael Chekhov would also contribute heavily to modern theatre, particularly through his unique acting methods which developed Stanislavski's ideas further.\n\nDespite Chekhov's reputation as a playwright, William Boyd asserts that his short stories represent the greater achievement. Raymond Carver, who wrote the short story \"Errand\" about Chekhov's death, believed that Chekhov was the greatest of all short story writers:\n\nErnest Hemingway, another writer influenced by Chekhov, was more grudging: \"Chekhov wrote about six good stories. But he was an amateur writer.\" And Vladimir Nabokov criticized Chekhov's \"medley of dreadful prosaisms, ready-made epithets, repetitions.\" But he also declared \"The Lady with the Dog\" \"one of the greatest stories ever written\" in its depiction of a problematic relationship, and described Chekhov as writing \"the way one person relates to another the most important things in his life, slowly and yet without a break, in a slightly subdued voice.\"\n\nFor the writer William Boyd, Chekhov's historical accomplishment was to abandon what William Gerhardie called the \"event plot\" for something more \"blurred, interrupted, mauled or otherwise tampered with by life.\"\n\nVirginia Woolf mused on the unique quality of a Chekhov story in \"The Common Reader\" (1925):\n\nWhile a Professor of Comparative Literature at Princeton University, Michael Goldman presented his view on defining the elusive quality of Chekhov's comedies stating: \"Having learned that Chekhov is comic ... Chekhov is comic in a very special, paradoxical way. His plays depend, as comedy does, on the vitality of the actors to make pleasurable what would otherwise be painfully awkward -- inappropriate speeches, missed connections, \"faux pas\", stumbles, childishness -- but as part of a deeper pathos; the stumbles are not pratfalls but an energized, graceful dissolution of purpose.\"\n\nAlan Twigg, the chief editor and publisher of the Canadian book review magazine \"BC Bookworld wrote,\nChekhov has also influenced the work of Japanese playwrights including Shimizu Kunio, Yōji Sakate, and Ai Nagai. Critics have noted similarities in how Chekhov and Shimizu use a mixture of light humor as well as an intense depictions of longing. Sakate adapted several of Chekhov's plays and transformed them in the general style of \"nō\". Nagai also adapted Chekhov's plays, including \"Three Sisters\", and transformed his dramatic style into Nagai's style of satirical realism while emphasizing the social issues depicted on the play.\n\nChekhov's works have been adapted for the screen, including Sidney Lumet's \"Sea Gull\" and Louis Malle's \"Vanya on 42nd Street\". Laurence Olivier's last film as director was an adaptation of the Three Sisters (UK 1970). It was released in the U.S. In 1974. His work has also served as inspiration or been referenced in numerous films. In Andrei Tarkovsky's 1975 film \"The Mirror\", characters discuss his short story \"Ward No. 6\". Woody Allen has been influenced by Chekhov and reference to his works are present in many of his films including Love and Death (1975), Interiors (1978) and Hannah and Her Sisters (1985). Plays by Chekhov are also referenced in Francois Truffaut's 1980 drama film \"The Last Metro\", which is set in a theater. A portion of a stage production of \"Three Sisters\" appears in the 2014 drama film \"Still Alice\".\n\n\nBiographical\nWorks\n"}
{"id": "2448", "url": "https://en.wikipedia.org/wiki?curid=2448", "title": "Action Against Hunger", "text": "Action Against Hunger\n\nAction Against Hunger is a global humanitarian organization committed to ending world hunger. The organization helps malnourished children whilst providing communities with access to safe water and sustainable solutions to hunger.\n\nIn 2014, Action Against Hunger worked in 49 different countries around the world with more than 6,000 employees and volunteers helping 13.6 million people in need.\n\nAction Against Hunger was established in 1979 by a group of French doctors, scientists, and writers. Nobel Prize-winning physicist Alfred Kastler served as the organization's first chairman.\n\nThe group initially provided assistance to Afghanistan refugees in Pakistan, famine-stricken Ugandan communities, and Cambodian refugees in Thailand. It expanded to address additional humanitarian concerns in Africa, the Middle East, Southeast Asia, the Balkans and elsewhere during the 1980s and 1990s. Action Against Hunger's Scientific Committee pioneered the therapeutic milk formula (F100), now used by all major humanitarian aid organizations to treat acute malnutrition. As a result, the global mortality rate of severely malnourished children under the age of five has been reduced from 25% to 5%. A few years later, therapeutic milk was repackaged as ready-to-use therapeutic foods (RUTFs), a peanut-based paste packaged like a power bar. These bars allow for the treatment of malnutrition at home, and do not require any preparation or refrigeration.\n\nThe international network currently has headquarters in five countries – France, Spain, the United States, Canada, and the UK. Its four main areas of work include nutrition, food security, water and sanitation, and advocacy.\n\nAction Against Hunger saves lives by preventing, detecting and treating severe acute malnutrition, particularly in emergency and conflicts situations. The organisation has an integrated approach with various sectors of intervention:\n\nAction Against Hunger partners with leaders from the food and beverage industry to bring attention to global hunger. Each year, several campaigns are ran by the network to raise funds and support the organisation's programs : Restaurants Against Hunger and Love Food Give Food.\n\nIn 2017, Action Against Hunger International Network is present in 51 countries:\n\nBurkina Faso, Burundi, Cameroun, Ivory Coast, Djibouti, Ethiopia, Kenya, Liberia, Malawi, Madagascar, Mali, Mauritania, Niger, Nigeria, Uganda, Central African Republic, Democratic Republic of the Congo, Senegal, Sierra Leone, Somalia, South Soudan, Tanzania, Chad, Zimbabwe\n\nBangladesh, Myanmar, Cambodia, India, Indonesia, Mongolia, Nepal, Pakistan, Philippines\n\nHaïti\n\nSouth Caucasus, Turkey, Ukraine\n\nAfghanistan, Azerbaijan, Egypt, Lebanon, Syria, Palestinian Occupied Territories, Yemen, Jordan, Iraq\n\nColombia, Guatemala, Nicaragua, Paraguay, Peru\n\nSince 1995 Action Against Hunger developed an international network to have a bigger global impact.\n\nThe Network has 5 headquarters in the world: France, Spain, the United Kingdom, the United States and Canada.\n\nAction Against Hunger has also a West Africa Regional Office (WARO) located in Dakar, a Training center in Nairobi and 5 logistic platforms (Lyon, Paris, Barcelona, Dubai, Panama).\n\nThis network increases the human and financial capacities and enables a specialization per headquarter.\n\n"}
{"id": "2452", "url": "https://en.wikipedia.org/wiki?curid=2452", "title": "AW", "text": "AW\n\nA&W, AW, Aw, aW or aw may refer to:\n\n\n\n\n\n"}

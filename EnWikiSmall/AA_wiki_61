{"id": "8227", "url": "https://en.wikipedia.org/wiki?curid=8227", "title": "Danish language", "text": "Danish language\n\nDanish (\"dansk\" ; \"dansk sprog\", ) is a North Germanic language spoken by around six million people, principally in Denmark and in the region of Southern Schleswig in northern Germany, where it has minority language status. There are also minor Danish-speaking communities in Norway, Sweden, Spain, the United States, Canada, Brazil and Argentina. Due to immigration and language shift in urban areas, around 15–20% of the population of Greenland speak Danish as their home language.\n\nAlong with the other North Germanic languages, Danish is a descendant of Old Norse, the common language of the Germanic peoples that lived in Scandinavia during the Viking Era. Danish, together with Swedish, derives from the East Norse dialect group, while the Middle Norwegian language before the influence of Danish and Norwegian Bokmål are classified as West Norse along with Faroese and Icelandic. A more recent classification based on mutual intelligibility separates modern spoken Danish, Norwegian and Swedish as \"Mainland Scandinavian\" while Icelandic and Faroese are classified as \"Insular Scandinavian\".\n\nUntil the 16th century, Danish was a continuum of dialects spoken from Schleswig to Scania with no standard variety or spelling conventions. With the Protestant Reformation and the introduction of printing, a standard language was developed which was based on the educated Copenhagen dialect. It spread through use in the education system and administration though German and Latin continued to be the most important written languages well into the 17th century. Following the loss of territory to Germany and Sweden, a nationalist movement adopted the language as a token of Danish identity, and the language experienced a strong surge in use and popularity with major works of literature produced in the 18th and 19th centuries. Today, traditional Danish dialects have all but disappeared, though there are regional variants of the standard language. The main differences in language are between generations, with youth language being particularly innovative.\n\nDanish has a very large vowel inventory comprising 27 phonemically distinctive vowels, and its prosody is characterized by the distinctive phenomenon \"stød\", a kind of laryngeal phonation type. Due to the many pronunciation differences that set apart Danish from its neighboring languages, particularly the vowels, difficult prosody and \"weakly\" pronounced consonants, it is sometimes considered to be a difficult language to learn and understand, and there is some evidence that small children are slower to acquire the phonological distinctions of Danish. The grammar is moderately inflective with strong (irregular) and weak (regular) conjugations and inflections. Nouns and demonstrative pronouns distinguish common and neutral gender. Like English, Danish only has remnants of a former case system, particularly in the pronouns. Unlike English it has lost all person marking on verbs. Its syntax is V2, with the finite verb always occupying the second slot in the sentence.\n\nDanish is a Germanic language of the North Germanic branch. Other names for this group are the Nordic or Scandinavian languages. Along with Swedish, Danish descends from the Eastern dialects of the Old Norse language; Danish and Swedish are also classified as East Scandinavian or East Nordic languages.\n\nScandinavian languages are often considered a dialect continuum, where there are no sharp dividing lines between the different vernacular languages.\n\nLike Norwegian and Swedish, Danish was significantly influenced by Low German in the Middle Ages, and has been influenced by English since the turn of the 20th century.\n\nDanish itself can be divided into three main dialect areas: West Danish (Jutlandic), Insular Danish (including the Standard variety), and East Danish (including Bornholmian and Scanian). Under the view that Scandinavian is a dialect continuum, East Danish can be considered intermediary between Danish and Swedish, while Scanian can be considered a Swedified East Danish dialect, and Bornholmsk is its closest relative.\n\nDanish is largely mutually intelligible with Norwegian and Swedish. Proficient speakers of any of the three languages can often understand the others fairly well, though studies have shown that speakers of Norwegian generally understand both Danish and Swedish far better than Swedes or Danes understand each other. Both Swedes and Danes also understand Norwegian better than they understand each other's languages. The reason Norwegian occupies a middle position in terms of intelligibility is because of its shared border with Sweden resulting in a similarity in pronunciation, combined with the long tradition of having Danish as a written language which has led to similarities in vocabulary. Among younger Danes, Copenhageners are worse at understanding Swedish than Danes from the provinces, and in general younger Danes are not as good at understanding the neighboring languages as are Norwegian and Swedish youths.\n\nBy the 8th century, the common Germanic language of Scandinavia, Proto-Norse, had undergone some changes and evolved into Old Norse.\nThis language was generally called the \"Danish tongue\" (\"Dǫnsk tunga\"), or \"Norse language\" (\"Norrœnt mál\"). Norse was written in the runic alphabet, first with the elder futhark and from the 9th century with the younger futhark.\n\nFrom the 7th century the common Norse language began to undergo changes that did not spread to all of Scandinavia, resulting in the appearance of two dialect areas, \"Old West Norse\" (Norway and Iceland) and \"Old East Norse\" (Denmark and Sweden). Most of the changes separating East Norse from West Norse started as innovations in Denmark, that spread through Scania into Sweden and by maritime contact to southern Norway. A change that separated Old East Norse (Runic Swedish/Danish) from Old West Norse was the change of the diphthong \"æi\" (Old West Norse \"ei\") to the monophthong \"e\", as in \"stæin\" to \"sten\". This is reflected in runic inscriptions where the older read \"stain\" and the later \"stin\". There was also a change of \"au\" as in \"dauðr\" into \"ø\" as in \"døðr\". This change is shown in runic inscriptions as a change from \"tauþr\" into \"tuþr\". Moreover, the \"øy\" (Old West Norse \"ey\") diphthong changed into \"ø\" as well, as in the Old Norse word for \"island\". This monophthongization started in Jutland and spread eastward, having spread throughout Denmark and most of Sweden by 1100.\n\nThrough Danish conquest, Old East Norse was once widely spoken in the northeast counties of England. Many words derived from Norse, such as \"gate\" () for street, still survive in Yorkshire, the East Midlands and East Anglia, parts of eastern England colonized by Danish Vikings. The city of York was once the Viking settlement of Jorvik. Several other English words derive from Old East Norse, for example \"are\" (), \"knife\" (), \"husband\" (), and \"egg\" (). The suffix \"-by\" for 'town' is common in place names in Yorkshire and the east Midlands, for example Selby, Whitby, Derby and Grimsby. The word \"dale\" meaning valley is common in Yorkshire and Derbyshire placenames.\n\nIn the medieval period Danish emerged as a separate language from Swedish. The main written language was Latin, and the few Danish language texts preserved from this period are written in the Latin alphabet, although the runic alphabet seems to have lingered in popular usage in some areas. The main text types written in this period are laws, which were formulated in the vernacular language to be accessible also to those who were not latinate. The Jutlandic Law and Scanian Law were written in vernacular Danish in the early 13th century. Beginning in 1350 Danish began to be used as a language of administration and new types of literature began to be written in the language, such as royal letters and testaments. The orthography in this period was not standardized nor was the spoken language, and the regional laws demonstrate the dialectal differences between the regions in which they were written.\n\nThroughout this period Danish was in contact with Low German, and many Low German loans were introduced in this period. With the Protestant Reformation in 1536, Danish also became the language of religion, which sparked a new interest in using Danish as a literary language. It is also in this period that Danish begins to take on the linguistic traits that differentiate it from Swedish and Norwegian, such as the stød the voicing of many stop consonants, and the weakening of many final vowels to /e/.\n\nThe first printed book in Danish dates from 1495, the \"\"Rimkrøniken\"\" (Rhyming Chronicle), a history book told in rhymed verses. The first complete translation of the Bible in Danish, the Bible of Christian II translated by Christiern Pedersen was published in 1550. Pedersen's orthographic choices set the de facto standard for subsequent writing in Danish.\n\nFollowing the first Bible translation the development of Danish as a written language, and as a language of religion, administration and public discourse sped up. In the second half of the 17th century a number of grammarians elaborated grammars of Danish, first among them Rasmus Bartholin's 1657 Latin grammar \"De studio lingvæ danicæ\"; then Laurids Olufsen Kock's 1660 grammar of the Zealand dialect \"Introductio ad lingvam Danicam puta selandicam\"; and in 1685 the first Danish grammar written in Danish, \"Den Danske Sprog-Kunst\" (\"The Art of the Danish Language\") by Peder Syv. Significant authors from this period are Thomas Kingo, poet and psalmist, and Leonora Christina Ulfeldt, whose novel Jammersminde (\"Remembered Woes\") is considered a literary masterpiece. Orthography was still not standardized and the principles for doing so were vigorously discussed among Danish philologists. The grammar of Jens Pedersen Høysgaard was the first to give a detailed analysis of Danish phonology and prosody, including a description of the stød. In this period scholars were also discussing whether it was best to \"write as one speaks\" or to \"speak as one writes\", including whether archaic grammatical forms that had fallen out of use in the vernacular, such as the plural form of verbs, should be conserved in writing (i.e. \"han er\" \"he is\" vs. \"de ere\" \"they are\").\n\nThe East Danish provinces were lost to Sweden after the Treaty of Brömsebro after which they were gradually Swedified; just as Norway was politically severed from Denmark, begininnig also a gradual end of Danish influence on Norwegian (influence through the shared written standard language remained). With the introduction of absolutism in 1660, the Danish state was further integrated, and the language of the chancellery, a Zealandic variety with German and French influence, became the de facto official standard language, especially in writing - this was the original so-called \"rigsdansk\" (\"Danish of the Realm\"). Also beginning in the mid 18th century, the \"skarre-R\", the uvular R sound (), began spreading through Denmark, probably through influence from Parisian French and German. It affected all of the areas where Danish had been influential, including all of Denmark, Southern Sweden and coastal southern Norway.\n\nIn the 18th century Danish philology was advanced by Rasmus Rask, who pioneered the disciplines of comparative and historical linguistics and wrote the first English language grammar of Danish. Literary Danish flourished with the works of Ludvig Holberg, whose plays and historical and scientific works laid the foundation for the Danish literary canon. With the Danish colonization of Greenland by Hans Egede, Danish became the administrative and religious language there, while Iceland and the Faroe Islands had the status of Danish colonies with Danish as an official language up until the mid 20th century.\n\nFollowing the loss of Schleswig to Germany, a sharp influx of German speakers moved into the area, eventually outnumbering the Danish speakers. The political loss of territory sparked a period of intense nationalism in Denmark, coinciding with the so-called \"Golden Age\" of Danish culture. Authors such as N.F.S. Grundtvig emphasized the role of language in creating national belonging. Some of the most cherished Danish language authors of this period are existential philosopher Søren Kierkegaard and prolific fairy tale author Hans Christian Andersen. The influence of popular literary role models, together with increased requirements of education did much to strengthen the Danish language, and also started a period of homogenization, whereby the Copenhagen standard language gradually displaced the regional vernacular languages. After the Schleswig referendum in 1920 a number of Danes remained as a minority within German territories. Throughout the 19th Century Danes emigrated, establishing small expatriate communities in the Americas, particularly in the US, Canada, and Argentina where memory and some use of Danish remains today.\nAfter the occupation of Denmark by Germany in World War II, the 1948 orthography reform dropped the German influenced rule of capitalizing nouns, and introduced the letter Å/å. Three 20th century Danish authors have become Nobel Prize laureates in Literature: Karl Gjellerup and Henrik Pontoppidan (joint recipients in 1917) and Johannes V. Jensen (awarded 1944).\n\nWith the exclusive use of \"rigsdansk\", the High Copenhagenian Standard, in national broadcasting, the traditional dialects came under increased pressure. In the 20th century they have all but disappeared, and the standard language has extended throughout the country. Minor regional pronunciation variation of the standard language, sometimes called \"regionssprog\" (\"regional languages\") remain, and are in some cases vital. Today the major varieties of Standard Danish are High Copenhagenian, associated with elderly, well to-do and well educated people of the capital, and low-Copenhagenian traditionally associated with the working class, but today adopted as the prestige variety of the younger generations. Also in the 21st century the influence of immigration has had linguistic consequences, such as the emergence of a so-called multiethnolect in the urban areas, an immigrant Danish variety (also known as Perkerdansk), combining elements of different immigrant languages such as Arabic, Turkish and Kurdish, as well as English and Danish.\n\nDanish is the national language of Denmark and one of two official languages of the Faroe Islands (alongside Faroese). Until 2009, it had also been one of two official languages of Greenland (alongside Greenlandic). Danish is widely spoken in Greenland now as \"lingua franca\", and an unknown portion of the native Greenlandic population has Danish as their first language; a large percentage of the native Greenlandic population speak Danish as a second language since its introduction into the education system as a compulsory language in 1928. Danish was an official language in Iceland until 1944, but is today still widely used and is a mandatory subject in school taught as a second foreign language after English.\nIn addition, there is a noticeable community of Danish speakers in Southern Schleswig, the portion of Germany bordering Denmark, where it is an officially recognized regional language, just as German is north of the border. Furthermore, Danish is one of the official languages of the European Union and one of the working languages of the Nordic Council. Under the Nordic Language Convention, Danish-speaking citizens of the Nordic countries have the opportunity to use their native language when interacting with official bodies in other Nordic countries without being liable for any interpretation or translation costs.\n\nThe more widespread of the two varieties of Norwegian, Bokmål, is very close to Danish, because standard Danish was used as the de facto administrative language until 1814. Bokmål is based on Danish unlike the other variety of Norwegian, Nynorsk, which is based on the Norwegian dialects, with Old Norwegian as an important reference point.\n\nThere is no law stipulating an official language for Denmark, making Danish the de facto language only. The Code of Civil Procedure does, however, lay down Danish as the language of the courts. Since 1997 public authorities have been obliged to observe the official spelling by way of the Orthography Law. In the 21st century there have been discussions regarding creating a language law that would make Danish the official language of Denmark.\n\nStandard Danish (\"rigsdansk\") is the language based on dialects spoken in and around the capital, Copenhagen. Unlike Swedish and Norwegian, Danish does not have more than one regional speech norm. More than 25% of all Danish speakers live in the metropolitan area of the capital, and most government agencies, institutions, and major businesses keep their main offices in Copenhagen, something that has resulted in a very homogeneous national speech norm.\n\nDanish dialects can be divided into the traditional dialects, which differ from modern Standard Danish in both phonology and grammar, and the Danish accents or regional languages, which are local varieties of the Standard language distinguished mostly by pronunciation and local vocabulary colored by traditional dialects. Traditional dialects are now mostly extinct in Denmark, with only the oldest generations still speaking them.\n\nDanish traditional dialects are divided into three main dialect areas: \n\nJutlandic is further divided into Southern Jutlandic and Northern Jutlandic, with Northern Jutlandic subdivided into North Jutlandic and West Jutlandic. Insular Danish is divided into Zealand, Funen, Møn and Lolland-Falster dialect areas - each with addition internal variation. The term \"Eastern Danish\" is occasionally used for Bornholmian, but including the dialects of Scania (particularly in a historical context). Jutlandic dialect, Insular Danish and Bornholmian. Bornholmian is the only Eastern Danish dialect spoken in Denmark, since the other Eastern Danish dialects were spoken in areas ceded to Sweden and subsequently swedified.\n\nTraditional dialects differ both in phonology, grammar and vocabulary from standard Danish. Phonologically, one of the most diagnostic differences is the presence or absence of stød. There are four main regional variants for the realization of stød: In Southeastern Jutlandic, Southernmost Funen, Southern Langeland and Ærø, there is no stød but instead a pitch accent. South of a line ( \"The Stød border\") going through central South Jutland, crossing Southern Funen and central Langeland and north of Lolland-Falster, Møn, Southern Zealand and Bornholm there is neither stød nor pitch accent. In most of Jutland and on Zealand there is stød, and in Zealandic traditional dialects and regional language there are often more stød occurrences than in the standard language. In Zealand the stød line divides Southern Zealand (without stød), an area which used to be directly under the Crown, from the rest of the Island that used to be the property of various noble estates.\n\nGrammatically, a dialectally significant feature is the number of grammatical genders. Standard Danish has two genders and the definite form of nouns is formed by the use of suffixes, while Western Jutlandic has only one gender and the definite form of nouns uses an article before the noun itself, in the same fashion as West Germanic languages. The Bornholmian dialect has maintained to this day many archaic features, such as a distinction between three grammatical genders. Insular Danish traditional dialects also conserved three grammatical genders. By 1900 Zealand insular dialects had been reduced to two genders under influence from the standard language, but other Insular varieties, such as Funen dialect had not. Besides using three genders, the old Insular or Funen dialect, could also use personal pronouns (like he and she) in certain cases, particularly referring to animals. A classic example in traditional Funen dialect is the sentence: \"Katti, han får unger\", literally \"The cat, he is having kittens\", because cat is a male noun, and thus are referred to as han (he), even if it is female cat.\n\nThe sound system of Danish is unusual among the world's languages, particularly in its large vowel inventory and in the unusual prosody. In informal or rapid speech the language is prone to considerable reduction of unstressed syllables, creating many vowel-less syllables with syllabic consonants, as well as reduction of final consonants. Furthermore, the language's prosody does not include many clues about the sentence structure, unlike many other languages, making it relatively more difficult to segment the speech flow into its constituent elements. These factors taken together make Danish pronunciation difficult to master for learners, and there are even indications that Danish children take slightly longer in learning to segment speech in early childhood.\n\nAlthough somewhat depending on analysis, most modern variants of Danish distinguish 12 long vowels, 13 short vowels and two schwa vowels, and that only occur in unstressed syllables. This gives a total of 27 different vowel phonemes - a very large number among the world's languages. At least 19 different diphthongs also occur, all with a short first vowel and the second segment being either , or . The table below shows the approximate distribution of the vowels as given by in Modern Standard Danish, with the symbols used in . Questions of analysis may give a slightly different inventory, for example based on whether r-colored vowels are considered distinct phonemes. gives 25 \"full vowels\", not counting the two unstressed schwa-vowels.\n\nThe consonant inventory is comparatively simple. distinguishes 16 non-syllabic consonant phonemes in Danish.\n\nMany of these phonemes have quite different allophones in onset and coda. Phonetically there is no voicing distinction among the stops, rather the distinction is one of aspiration and fortis vs. lenis. are aspirated in onset realized as , but not in coda. The pronunciation of \"t\", , is in between a simple aspirated and a fully affricated as has happened in German with many words that now contain \"z\". The stops /b d g/ are realized as in onset and as [b̥ ð̞ˠ̠, j/ʊ̯] in coda. In syllable onset the phonemes are contoid (having enough closure to produce friction), but in coda syllables they become vocoids, with no audible friction making them phonetically similar to vowels. For example, /v b/ is pronounced as a [w]-sound in syllable coda e.g. /grav, løb/ (\"grave, ran\") are pronounced .\n\nThe sound is found for example in the word /sjovˀ/ \"fun\" pronounced and /tjalˀ/ \"marijuana\" pronounced . Some analyses have posited it as a phoneme, but since it occurs only after or and doesn't occur after these phonemes, it can be analyzed as an allophone of , which is devoiced after voiceless alveolar frication. This makes it unnecessary to postulate a -phoneme in Danish.\n\nIn onset is realized as a uvu-pharyngeal approximant, , but in coda it is either realized as a non-syllabic low central vowel, or simply coalesces with the preceding vowel. The phenomenon is comparable to the \"r\" in German or in non-rhotic pronunciations of English. The Danish pronunciation of as a so-called skarre-r distinguishes the language from those varieties of Norwegian and Swedish that use trilled .\n\nDanish is characterized by a prosodic feature called \"stød\" (lit. \"thrust\"). This is a form of laryngealization or creaky voice. Some sources have described it as a glottal stop, but this is a very infrequent realization, and today phoneticians consider it a phonation type or a prosodic phenomenon. It has phonemic status, since it serves as the sole distinguishing feature of words with different meanings in minimal pairs such as \"bønder\" (\"peasants\") with stød, versus \"bønner\" (\"beans\") without stød. The distribution of stød in the vocabulary is related to the distribution of the common Scandinavian pitch accents found in most dialects of Norwegian and Swedish.\n\nStress is phonemic and distinguishes words such as \"billigst\" \"cheapest\" and \"bilist\" \"car driver\".\n\nSimilarly to the case of English, modern Danish grammar is the result of a gradual change from a typical Indo-European dependent marking pattern with a rich inflectional morphology and relatively free word order, to a mostly analytic pattern with little inflection, a fairly fixed SVO word order and a complex syntax. Some traits typical of Germanic languages persist in Danish, such as the distinction between irregularly inflected strong stems inflected through ablaut (i.e. changing the vowel of the stem, as in the pairs \"tager/tog\" (\"takes/took\") and \"fod/fødder\" (\"foot/feet\")) and weak stems inflected through affixation (such as \"elsker/elskede\" \"love/loved\", \"bil/biler\" \"car/cars\"). Vestiges of the Germanic case and gender system are found in the pronoun system. Typically for an Indo-European language, Danish follows accusative morphosyntactic alignment. Danish distinguishes at least seven major word classes: verbs, nouns, numerals, adjectives, adverbs, articles, prepositions, conjunctions, interjections and ideophones.\n\nNouns are inflected for number (singular vs. plural) and definiteness, and are classified into two grammatical genders. Only pronouns inflect for case, and the previous genitive case has become an enclitic. A distinctive feature of the Scandinavian languages, including Danish, is that the definite articles, which also mark noun gender, have developed into suffixes. Typically of Germanic languages plurals are either irregular or \"strong\" stems inflected through ablaut (i.e. changing the vowel of the stem (e.g. \"fod/fødder\" \"foot/feet\", \"mand/mænd\" \"man/men\") or \"weak\" stems inflected through affixation (e.g. \"skib/skibe\" \"ship/ships\", \"kvinde/kvinder\" \"woman/women\").\n\nStandard Danish has two nominal genders: \"common\" and \"neuter\"; the common gender arose as the historical feminine and masculine genders conflated into a single category. Some traditional dialects retain a three-way gender distinction, between masculine, feminine and neuter, and some dialects of Jutland have a masculine/feminine contrast. While the majority of Danish nouns (ca. 75%) have the \"common\" gender, and \"neuter\" is often used for inanimate objects, the genders of nouns are not generally predictable and must in most cases be memorized.The gender of a noun determines the form of adjectives that modify it, and the form of the definite suffixes. \n\nDefiniteness is marked by two mutually exclusive articles, a preposed demonstrative article which occurs with nouns that are modified by an adjective or a postposed enclitic. Neuter nouns take the clitic \"-et\", and common gender nouns take \"-en\". Indefinite nouns take the articles \"en\" (common gender) or \"et\" (neuter). Hence, the common gender noun \"en mand\" \"a man\" (indefinite) has the definite form \"manden\" \"the man\", whereas the neuter noun \"et hus\" \"a house\" (indefinite) has the definite form, \"the house\" (definite) \"huset\". \n\nIndefinite:\n\nDefinite with enclitic article:\n\nDefinite with preposed demonstrative article:\n\nThe plural definite ending is \"-(e)ne\" (e.g. \"drenge\" \"boys > \"drengene\" \"the boys\" and \"piger\" \"girls\" > \"pigerne\" \"the girls\"), and nouns ending in -\"ere\" lose the last \"-e\" before adding the -ne suffix (e.g. \"danskere\" \"Danes\" > \"danskerne\" \"the Danes\"). When the noun is modified by an adjective, the definiteness is marked by the definite article \"den\" (common) or \"det\" (neuter) and the definite/plural form of the adjective: \"den store mand\" \"the big man\", \"det store hus\" \"the big house\".\n\nThere are three different types of regular plurals: Class 1 forms the plural with the suffix -\"er\" (indefinite) and -\"erne\" (definite), Class 2 with the suffix \"-e\" (indefinite) and -\"ene\" (definite.), and Class 3 takes no suffix for the plural indefinite form and -\"ene\" for the plural definite.\n\nMost irregular nouns take an ablaut plural (with a change in the stem vowel), or combine ablaut stem-change with the suffix, and some have unique plural forms. Unique forms may be inherited (e.g. the plural of \"øje\" \"eye\", which is the old dual form \"øjne\"), or for loan words they may be borrowed from the donor language (e.g. the word \"konto\" \"account\" which is borrowed from Italian and uses the Italian masculine plural form \"konti\" \"accounts\").\n\nPossessive phrases are formed with the enclitic -\"s\", for example \"min fars hus\" \"my father's house\" where the noun \"far\" carries the possessive enclitic. This is however not a case of genitive case marking, because in the case of longer noun phrases the -s attaches to the last word in the phrase, which need not be the head-noun or even a noun at all. For example, the phrases \"kongen af Danmark's bolsjefabrik\" \"the king of Denmark's candy factory\", or \"det er pigen Uffe bor sammen meds datter\" \"that is the daughter of the girl that Uffe lives with\", where the enclitic attaches to a stranded preposition.\n\nAs does English, the Danish pronominal system retains a distinction between subjective and oblique case. The subjective case form of pronouns is used when pronouns occur as grammatical subject of a sentence, and oblique forms are used for all non-subjective occurrences including accusative, dative, predicative, comparative and other types of constructions. The third person singular pronouns also distinguish between and animate masculine (\"han\" \"he\"), animate feminine (\"hun\" \"she\") forms, as well as inanimate neuter (\"det\" \"it\") and inanimate common gender (\"den\" \"it\") \n\nPossessive pronouns have independent and adjectival forms. The adjectival form is used immediately preceding the possessed noun (\"det er min hest\" \"it is my horse\"), whereas the independent possessive pronoun is used in place of the possessed noun (\"den er min\" \"it is mine\"). In the third person singular \"sin\" is used when the owner is also the subject of the sentence, whereas \"hans\" (\"his\"), \"hendes\" (her) and \"dens/dets\" \"its\" is used when the owner is different from the grammatical subject.\n\nLike all Germanic languages, Danish forms compound nouns. These are represented in Danish orthography as one word, as in \"kvindehåndboldlandsholdet\", \"the female national handball team\". In some cases, nouns are joined with an extra \"s\", originally possessive in function, like \"landsmand\" (from \"land\", \"country\", and \"mand\", \"man\", meaning \"compatriot\"), but \"landmand\" (from same roots, meaning \"farmer\"). Some words are joined with an extra \"e\", like \"gæstebog\" (from \"gæst\" and \"bog\", meaning \"guest book\").\n\nDanish verbs are morphologically simple, marking very few grammatical categories. They do not mark person or number of subject, although the marking of plural subjects was still used in writing as late as the 19th century. Verbs have a past, non-past and infinitive form, past and present participle forms, and a passive, and an imperative.\n\nVerbs can be divided into two main classes, the strong/irregular verbs and the regular/weak verbs. The regular verbs are also divided into two classes, those that take the past suffix -\"te\" and those that take the suffix -\"ede\".\n\nThe infinitive always ends in a vowel, usually -e (pronounced ), infinitive forms are preceded by the article \"at\" (pronounced ). The non-past or present tense takes the suffix -\"r\", except for a few strong verbs that have irregular non-past forms. The past form does not necessarily mark past tense, but also counterfactuality or conditionality, and the non-past has many uses besides present tense time reference.\n\nThe present participle ends in -\"ende\" (e.g. \"løbende\" \"running\"), and the past participle ends in -\"et\" (e.g. \"løbet\" \"run\"), \"-t\" (e.g. købt \"bought\"). Additional composite tenses are constructed with auxiliary verbs (e.g. \"at være\" \"to be\" and \"at have\" \"to have\") and participial forms:\n\nThe passive form takes the suffix -s: \"avisen læses hver dag\" (\"the newspaper is read every day\"). Another passive construction uses the auxiliary verb \"at blive\" \"to become\": \"avisen bliver læst hver dag\".\n\nThe imperative mood is formed from the infinitive by removing the final schwa-vowel:\n\nDanish basic constituent order in simple sentences with both a subject and an object is Subject-Verb-Object. However, Danish is also a V2 language, which means that the verb must always be the second constituent of the sentence. Following the Danish grammarian Paul Diderichsen Danish grammar tends to be analyzed as consisting of slots or fields, and in which certain types of sentence material can be moved to the pre-verbal (or \"grounding\") field to achieve different pragmatic effects. Usually the sentence material occupying the preverbal slot has to be pragmatically marked, usually either new information or topics. There is no rule that subjects must occur in the preverbal slot, but since subject and topic often coincide, they often do. Therefore, whenever any sentence material that is not the subject occurs in the preverbal position the subject is demoted to postverbal position and the sentence order becomes VSO.\n\nbut\n\nWhen there is no pragmatically marked constituents in the sentence to take the preverbal slot (for example when all the information is new), the slot has to take a dummy subject \"der\".\n\n describes the basic order of sentence constituents in main clauses as comprising the following 8 positions:\n\nPosition 0 is not part of the sentence and can only contain sentential connectors (such as conjunctions or interjections). Position 1 can contain any sentence constituent. Position 2 can only contain the main verb. Position 3 is the subject position, unless the subject is fronted to occur in position 1. Position 4 can only contain light adverbs and the negation. Position 5 is for non-finite verbs, such as auxiliaries. Position 6 is the position of direct and indirect objects, and position 7 is for heavy adverbial constituents.\n\nQuestions with wh-words are formed differently from yes/no questions. In wh-questions the question word occupies the preverbal field, regardless of whether its grammatical role is subject or object or adverbial. In yes/no questions the preverbal field is empty, so that the sentence begins with the verb.\n\nWh-question:\n\nIn subordinate clauses, the syntax differs from that of main clauses. In the subordinate clause structure the verb is preceded by the subject and any light adverbial material (e.g. negation). Complement clauses begin with the particle \"at\" in the \"connector field\".\n\nRelative clauses are marked by the relative articles \"som\" or \"der\" which occupy the preverbal slot:\n\nAbout 2000 of Danish non-compound words are derived from the Old Norse language, and ultimately from Proto Indo-European. Of these 2000 words, 1200 are nouns, 500 are verbs, 180 are adjectives and the rest belong to other word classes. Danish has also absorbed a considerable number of loan words, most of which were borrowed from Middle Low German in the late medieval period. Out of the 500 most frequently used Words in Danish, 100 are Medieval loans from Middle Low German. In the 17th and 18th Centuries standard German and French superseded Low German influence and in the 20th Century English became the main supplier of loan words, especially after World War II. Although many old Nordic words remain, some were replaced with borrowed synonyms, as can be seen with \"æde\" (to eat) which became less common when the Low German \"spise\" came into fashion. As well as loan words, new words are freely formed by compounding existing words. In standard text in contemporary Danish, Middle Low German loans account for about 16-17% of the vocabulary, Graeco-Latin-loans 4-8 %, French 2-4 % and English about 1%.\n\nDanish and English are both Germanic languages, Danish a North Germanic language descended from Old Norse and English a West Germanic language descended from Old English, and Old Norse exerted a strong influence on Old English in the early medieval period. To see their shared Germanic heritage, one merely has to note the many common words that are very similar in the two languages. For example, commonly used Danish nouns and prepositions such as \"have\", \"over\", \"under\", \"for\", \"give\", \"flag,\" \"salt,\" and \"kat\" are easily recognizable in their written form to English speakers. Similarly, some other words are almost identical to their Scottish equivalents, e.g., \"kirke\" (Scottish \"kirk\", i.e., 'church') or \"barn\" (Scottish \"bairn\", i.e. 'child'). In addition, the word \"by\", meaning \"village\" or \"town\", occurs in many English place-names, such as \"Whitby\" and \"Selby\", as remnants of the Viking occupation. During the latter period, English adopted \"are\", the third person plural form of the verb \"to be\", as well as the corresponding personal pronoun form \"they\" from contemporary Old Norse.\n\nIn the word forms of numbers above 20, the units are stated before the tens, so 21 is rendered \"enogtyve\", literally \"one and twenty\".\n\nThe numeral \"halvanden\" means 1½ (literally \"half second\", implying \"one plus half of the second one\"). The numerals \"halvtredje\" (2½), \"halvfjerde\" (3½) and \"halvfemte\" (4½) are obsolete, but still implicitly used in the vigesimal system described below. Similarly, the temporal designation \"klokken halv tre\", literally \"half three o'clock\", is half past two.\n\nOne peculiar feature of the Danish language is the fact that numerals 50, 60, 70, 80 and 90 are (somewhat like the French numerals from 80 through 99) based on a vigesimal system, meaning that the score (20) is used as a base unit in counting. \"Tres\" (short for \"tre-sinds-tyve\", \"three times twenty\") means 60, while 50 is \"halvtreds\" (short for \"halvtredje-sinds-tyve\", \"half third times twenty\", implying two score plus half of the third score). The ending \"sindstyve\" meaning \"times twenty\" is no longer included in cardinal numbers, but still used in ordinal numbers. Thus, in modern Danish fifty-two is usually rendered as \"tooghalvtreds\" from the now obsolete \"tooghalvtredsindstyve\", whereas 52nd is either \"tooghalvtredsende\" or \"tooghalvtredsindstyvende\". Twenty is \"tyve\" (derived from old Danish \"tiughu\", a haplology of \"tuttiughu\", meaning 'two tens'), while thirty is \"tredive\" (Old Danish \"þrjatiughu\", \"three tens\"), and forty is \"fyrre\" (Old Danish \"fyritiughu\", \"four tens\" via \"fyrretyve\". Thus, the suffix \"-tyve\" should be understood as a plural of \"ti\" (10), though to modern Danes \"tyve\" means 20, making it hard to explain why \"fyrretyve\" is 40 (four tens) and not 80 (four times twenty).\n\nFor large numbers (one billion or larger), Danish uses the long scale, so that the short scale billion (1,000,000,000) is called \"milliard\", and the short scale trillion (1,000,000,000,000) is \"billion\".\n\nThe oldest preserved examples of written Danish (from the Iron and Viking Ages) are in the Runic alphabet. The introduction of Christianity also brought the Latin script to Denmark, and at the end of the High Middle Ages Runes had more or less been replaced by Latin letters.\n\nDanish orthography is highly conservative, still using most of the conventions established in the 16th century. The spoken language however has changed a lot since then, creating a severe gap between the spoken and written languages.\n\nThe modern Danish alphabet is similar to the English one, with three additional letters: \"æ\", \"ø\", and \"å\", which come at the end of the alphabet, in that order. A spelling reform in 1948 introduced the letter \"å\", already in use in Norwegian and Swedish, into the Danish alphabet to replace the digraph \"aa\". The old usage still occurs in some personal and geographical names (for example, the name of the city of \"Aalborg\" is spelled with Aa following a decision by the City Council in the 1970s and \"Aarhus\" decided to go back to Aa in 2011). When representing the \"å\" sound, \"aa\" is treated just like \"å\" in alphabetical sorting, even though it looks like two letters. When the letters are not available due to technical limitations (e.g., in URLs), they are often replaced by \"ae\" (Æ, æ), \"oe\" or \"o\" (Ø, ø), and \"aa\" (Å, å), respectively.\n\nThe same spelling reform changed the spelling of a few common words, such as the past tense \"vilde\" (would), \"kunde\" (could) and \"skulde\" (should), to their current forms of \"ville\", \"kunne\" and \"skulle\" (making them identical to the infinitives in writing, as they are in speech). Modern Danish and Norwegian use the same alphabet, though spelling differs slightly, particularly with the phonetic spelling of loanwords; for example the spelling of \"station\" and \"garage\" in Danish remains identical to other languages, whereas in Norwegian, they are transliterated as \"stasjon\" and \"garasje\".\n\n\nRealm languages:\n\nNordic languages:\n"}
{"id": "8228", "url": "https://en.wikipedia.org/wiki?curid=8228", "title": "Decade (Neil Young album)", "text": "Decade (Neil Young album)\n\nDecade is a compilation by Neil Young, originally released in 1977 as a triple album, now available on two compact discs. It contains 35 of Young's songs recorded between 1966 and 1976, among them five tracks that had been unreleased up to that point. It peaked at No. 43 on the \"Billboard\" Top Pop Albums chart, and was certified platinum by the RIAA in 1986.\n\nCompiled by Young himself, with his hand-written liner notes about each track, \"Decade\" represents almost every album from his career and various affiliations through 1977 with the exception of \"Four Way Street\" and \"Time Fades Away\". Of the previously unreleased songs, \"Down to the Wire\" features the New Orleans pianist Dr. John with Buffalo Springfield on an item from their shelved \"Stampede\" album; \"Love Is a Rose\" was a minor hit for Linda Ronstadt in 1975; \"Winterlong\" received a cover by Pixies on the Neil Young tribute album from 1989, \"\"; and \"Campaigner\" is a Young song critical of Richard Nixon. The track \"Long May You Run\" is a different mix to that found on the album of the same name, featuring the harmonies of the full Crosby Stills & Nash before David Crosby and Graham Nash left the recording sessions.\n\nFor many years, \"Decade\" was the only Neil Young compilation album available. A 1993 compilation called \"Lucky Thirteen\" was released, but it only covered Young's 1982–1988 output. It was not until 2004 that Reprise Records released a single-disc retrospective of his best-known tracks, titled \"Greatest Hits\". Throughout the 1980s and '90s, Young promised fans a follow-up to the original \"Decade\" collection, provisionally titled \"Decade II\"; eventually, this idea was scrapped in favor of a much more comprehensive anthology to be titled \"Archives\", spanning his entire career and ranging in size from a box set to an entire series of audio and/or video releases. The first release of archival material since \"Decade\" and \"Lucky Thirteen\" would appear in 2006, \"Live at the Fillmore East\", a recording from a 1970 concert featuring Crazy Horse with Danny Whitten. Several other archival live releases followed, and in 2009 the first of several planned multi-disc box sets, \"The Archives Vol. 1 1963–1972\", was issued. In April 2017 \"Decade\" was reissued on vinyl as a limited-edition Record Store Day release, with remastered vinyl and CD editions planned for general release in June 2017.\n\nInitially, \"Decade\" was to be released in 1976, but was pulled at the last minute by Young. It was shelved until the following year, where it appeared with two songs removed from the original track list (a live version of \"Don't Cry No Tears\" recorded in Japan in 1976, and a live version of \"Pushed It Over the End\" recorded in 1974). Also removed were the following comments on those two songs and \"Time Fades Away\", from Young's handwritten liner notes:\n\nThe album has been lauded in many quarters as one of the best examples of a career retrospective for a rock artist, and as a template for the box set collections that would follow in the 1980s and beyond. However, in the original article on Young from the first edition of the \"Rolling Stone Illustrated History of Rock and Roll\" and a subsequent article in the \"1983 Rolling Stone Record Guide\", critic Dave Marsh used this album to accuse Young of deliberately manufacturing a self-mythology, arguing that while his highlights could be seen to place him on a level with other artists from his generation like Bob Dylan or The Beatles, the particulars of his catalogue did not bear this out. The magazine has since excised the article from subsequent editions of the \"Illustrated History\" book.\n\nAll songs written by Neil Young.\n\n\n\n\n\n\n\nThe CD release combined sides 1-3 onto disc one, and sides 4-6 on disc two.\n\n\nAlbum\n"}
{"id": "8230", "url": "https://en.wikipedia.org/wiki?curid=8230", "title": "Demeter", "text": "Demeter\n\nIn ancient Greek religion and Greek mythology, Demeter (; Attic: \"Dēmḗtēr\", ; Doric: \"Dāmā́tēr\") is the goddess of the harvest and agriculture, who presided over grains and the fertility of the earth. Her cult titles include Sito (), \"she of the Grain\", as the giver of food or grain, and Thesmophoros (, \"thesmos\": divine order, unwritten law; , \"phoros\": bringer, bearer), \"Law-Bringer,\" as a mark of the civilized existence of agricultural society.\n\nThough Demeter is often described simply as the goddess of the harvest, she presided also over the sacred law, and the cycle of life and death. She and her daughter Persephone were the central figures of the Eleusinian Mysteries that predated the Olympian pantheon. In the Linear B Mycenean Greek tablets of c. 1400–1200 BC found at Pylos, the \"two mistresses and the king\" may be related with Demeter, Persephone and Poseidon. Her Roman equivalent is Ceres.\n\nIt is possible that Demeter appears in Linear A as \"da-ma-te\" on three documents (AR Zf 1 and 2, and KY Za 2), all three apparently dedicated in religious situations and all three bearing just the name (\"i-da-ma-te\" on AR Zf 1 and 2). It is unlikely that Demeter appears as \"da-ma-te\" in a Linear B (Mycenean Greek) inscription (PY En 609); the word , \"da-ma-te\", probably refers to \"households\". On the other hand, , \"si-to-po-ti-ni-ja\", \"Potnia of the Grain\", is regarded as referring to her Bronze Age predecessor or to one of her epithets.\n\nDemeter's character as mother-goddess is identified in the second element of her name \"meter\" () derived from Proto-Indo-European \"*méh₂tēr\" (mother). In antiquity, different explanations were already proffered for the first element of her name. It is possible that \"Da\" (), a word which corresponds to \"Ge\" () in Attic, is the Doric form of \"De\" (), \"earth\", the old name of the chthonic earth-goddess, and that Demeter is \"Mother-Earth\". This root also appears in the Linear B inscription \"E-ne-si-da-o-ne\", \"earth-shaker\", as an aspect of the god Poseidon. However, the \"dā\" element in the name of Demeter is not so simply equated with \"earth\" according to John Chadwick. \n\nThe element \"De\"- may be connected with \"Deo\", an epithet of Demeter probably derived from the Cretan word \"dea\" (), Ionic \"zeia\" ()—variously identified with emmer, spelt, rye, or other grains by modern scholars—so that she is the Mother and the giver of food generally. . \"Wanax\" (\"wa-na-ka\") was her male companion (Greek: Πάρεδρος, \"Paredros\") in Mycenean cult. The Arcadian cult links her to the god Poseidon, who probably substituted the male companion of the Great Goddess ; Demeter may therefore be related to a Minoan Great Goddess (Cybele). \n\nAn alternative Proto-Indo-European etymology comes through Potnia and Despoina, where \"Des-\" represents a derivative of PIE \"*dem\" (house, dome), and Demeter is \"mother of the house\" (from PIE \"*dems-méh₂tēr\").\n\nAccording to the Athenian rhetorician Isocrates, Demeter's greatest gifts to humankind were agriculture, particularly of cereals, and the Mysteries which give the initiate higher hopes in this life and the afterlife. These two gifts were intimately connected in Demeter's myths and mystery cults. In Homer's \"Odyssey\" she is the blond-haired goddess who separates the chaff from the grain. In Hesiod, prayers to Zeus-Chthonios (chthonic Zeus) and Demeter help the crops grow full and strong. Demeter's emblem is the poppy, a bright red flower that grows among the barley.\n\nIn Hesiod's Theogony, Demeter is the daughter of Cronus and Rhea. At the marriage of Cadmus and Harmonia, Demeter lured Iasion away from the other revelers. They had intercourse in a ploughed furrow in Crete, and she gave birth to a son, Ploutos. Her daughter by Zeus was Persephone, Queen of the Underworld.\n\nDemeter's two major festivals were sacred mysteries. Her Thesmophoria festival (11–13 October) was women-only. Her Eleusinian mysteries were open to initiates of any gender or social class. At the heart of both festivals were myths concerning Demeter as Mother and Persephone as her daughter.\n\nDemeter's virgin daughter Persephone was abducted to the underworld by Hades. Demeter searched for her ceaselessly, preoccupied with her loss and her grief. The seasons halted; living things ceased their growth, then began to die. Faced with the extinction of all life on earth, Zeus sent his messenger Hermes to the underworld to bring Persephone back. Hades agreed to release her if she had eaten nothing while in his realm; but Persephone had eaten a small number of pomegranate seeds. This bound her to Hades and the underworld for certain months of every year, either the dry Mediterranean summer, when plant life is threatened by drought, or the autumn and winter. There are several variations on the basic myth. In the Homeric hymn to Demeter, Hecate assists in the search and later becomes Persephone's underworld attendant. In another, Persephone willingly and secretly eats the pomegranate seeds, thinking to deceive Hades, but is discovered and made to stay. In all versions, Persephone's time in the underworld corresponds with the unfruitful seasons of the ancient Greek calendar, and her return to the upper world with springtime. Demeter's descent to retrieve Persephone from the underworld is connected to the Eleusinian Mysteries.\n\nDemeter and her daughter Persephone were usually called:\nIn Mycenaean Pylos, Demeter and Persephone were probably called \"queens\" (wa-na-ssoi).\n\nThe myth of the capture of Persephone seems to be pre-Greek. In the Greek version, Ploutos (πλούτος, wealth) represents the wealth of the corn that was stored in underground silos or ceramic jars (\"pithoi\"). Similar subterranean \"pithoi\" were used in ancient times for funerary practices. At the beginning of the autumn, when the corn of the old crop is laid on the fields, she ascends and is reunited with her mother Demeter, for at this time the old crop and the new meet each other.\n\nAccording to the personal mythology of Robert Graves, Persephone is not only the younger self of Demeter, she is in turn also one of three guises of the Triple Goddess – Kore (the youngest, the maiden, signifying green young grain), Persephone (in the middle, the nymph, signifying the ripe grain waiting to be harvested), and Hecate (the eldest of the three, the crone, the harvested grain), which to a certain extent reduces the name and role of Demeter to that of group name. Before her abduction, she is called Kore; and once taken she becomes Persephone ('she who brings destruction').\n\nDemeter's search for her daughter Persephone took her to the palace of Celeus, the King of Eleusis in Attica. She assumed the form of an old woman, and asked him for shelter. He took her in, to nurse Demophon and Triptolemus, his sons by Metanira. To reward his kindness, she planned to make Demophon immortal; she secretly anointed the boy with ambrosia and laid him in the flames of the hearth, to gradually burn away his mortal self. But Metanira walked in, saw her son in the fire and screamed in fright. Demeter abandoned the attempt. Instead, she taught Triptolemus the secrets of agriculture, and he in turn taught them to any who wished to learn them. Thus, humanity learned how to plant, grow and harvest grain. The myth has several versions; some are linked to figures such as Eleusis, Rarus and Trochilus. The Demophon element may be based on an earlier folk tale.\n\nDemeter and Poseidon's names appear in the earliest scratched notes in Linear B found at Mycenae and Mycenaean Pylos; \"e-ne-si-da-o-ne\" (earth-shaker) for Poseidon, and \"si-to-po-ti-ni-ja\", who is probably related with Demeter. Poseidon carries frequently the title \"wa-na-ka\" (\"wanax\") in Linear B inscriptions, as king of the underworld, and his title \" E-ne-si-da-o-ne\" indicates his chthonic nature. In the cave of Amnisos (Crete) \"Enesidaon\" is related with the cult of Eileithyia, the goddess of childbirth. She was related with the annual birth of the divine child. During the Bronze Age, a goddess of nature, dominated both in Minoan and Mycenean cult, and \"Wanax\" (\"wa-na-ka\") was her male companion (paredros) in Mycenean cult. She and her paredros survived in the Eleusinian cult, where the following words were uttered : \" Mighty Potnia bore a strong son\" However, there is no evidence that originally the name of Potnia was Demeter.\n\nTablets from Pylos record sacrificial goods destined for \"the Two Queens and Poseidon\" (\"to the Two Queens and the King\" :\"wa-na-ssoi\", \"wa-na-ka-te\"). The \"Two Queens\" may be related with Demeter and Persephone, or their precursors, goddesses who were not associated with Poseidon in later periods. An exception is the myth of isolated Arcadia in southern Greece. Despoina, is daughter of Demeter and Poseidon \"Hippios\", Horse-Poseidon. These myths seem to be connected with the first Greek-speaking people who came from the north during the Bronze age. Poseidon represents the river spirit of the underworld and he appears as a horse as it often happens in northern-European folklore. He pursues the mare-Demeter and she bears one daughter who obviously originally had the form or the shape of a mare too. Demeter and Despoina were closely connected with springs and animals, related to Poseidon as a God of waters and especially with Artemis, the mistress of the animals and the goddess of, among others, the Hunt.\n\nDemeter as mare-goddess was pursued by Poseidon, and hid from him among the horses of King Onkios, but could not conceal her divinity. In the form of a stallion, Poseidon caught and covered her. Demeter was furious (erinys) at Poseidon's assault; in this furious form, she is known as Demeter Erinys. But she washed away her anger in the River Ladon, becoming \"Demeter Lousia\", the \"bathed Demeter\". \"In her alliance with Poseidon,\" Karl Kerenyi noted, \"she was Earth, who bears plants and beasts, and could therefore assume the shape of an ear of grain or a mare.\" She bore a daughter Despoina (: the \"Mistress\"), whose name should not be uttered outside the Arcadian Mysteries, and a horse named Arion, with a black mane and tail.\n\nIn Arcadia, Demeter's mare-form was worshiped into historical times. Her \"xoanon\" of Phigaleia shows how the local cult interpreted her: a Medusa type with a horse's head with snaky hair, holding a dove and a dolphin, probably representing her power over air and water.\n\nDemeter's epithets show her many religious functions. She was the \"Corn-Mother\" who blesses the harvesters. Some cults interpreted her as \"Mother-Earth\". Demeter may be linked to goddess-cults of Minoan Crete, and embody aspects of a pre-Hellenic Mother Goddess. It is possible that the title \"Mistress of the labyrinth\", which appears in a Linear B inscription, belonged originally to \"Sito\" (\"[she] of the grain\"), the Great Mother Demeter and that in the Eleusinian mysteries this title was kept by her daughter Persephone (Kore or Despoina). However, there is no evidence that the name of Potnia in Eleusis was originally Demeter. Her other epithets include:\nDemeter might also be invoked in the guises of:\n\n\nTheocritus, wrote of an earlier role of Demeter as a poppy goddess:\n\nIn a clay statuette from Gazi (Heraklion Museum, Kereny 1976 fig 15), the Minoan poppy goddess wears the seed capsules, sources of nourishment and narcosis, in her diadem. \"It seems probable that the Great Mother Goddess, who bore the names Rhea and Demeter, brought the poppy with her from her Cretan cult to Eleusis, and it is certain that in the Cretan cult sphere, opium was prepared from poppies\" (Kerenyi 1976, p 24).\n\nMajor cults to Demeter are known at Eleusis in Attica, Hermion (in Crete), Megara, Celeae, Lerna, Aegila, Munychia, Corinth, Delos, Priene, Akragas, Iasos, Pergamon, Selinus, Tegea, Thoricus, Dion (in Macedonia) Lykosoura, Mesembria, Enna (Sicily), and Samothrace.\n\nAn ancient Amphictyony, probably the earliest centred on the cult of Demeter at Anthele (Ἀνθήλη), which lay on the coast of Malis south of Thessaly. This was the locality of Thermopylae.\n\nAfter the \"First Sacred War\", the Anthelan body was known thenceforth as the Delphic Amphictyony\n\nDemeter of Mysia had a seven-day festival at Pellené in Arcadia. Pausanias passed the shrine to Demeter at Mysia on the road from Mycenae to Argos but all he could draw out to explain the archaic name was a myth of an eponymous Mysius who venerated Demeter.\n\n\n\n\n"}
{"id": "8233", "url": "https://en.wikipedia.org/wiki?curid=8233", "title": "Death metal", "text": "Death metal\n\nDeath metal is an extreme subgenre of heavy metal music. It typically employs heavily distorted and low-tuned guitars, played with techniques such as palm muting and tremolo picking, deep growling vocals, aggressive, powerful drumming featuring double kick or blast beat techniques, minor keys or atonality, abrupt tempo, key, and time signature changes and chromatic chord progressions. The lyrical themes of death metal may invoke slasher film-stylized violence, religion (sometimes Satanism), occultism, Lovecraftian horror, nature, mysticism, mythology, philosophy, science fiction, and politics, and they may describe extreme acts, including mutilation, dissection, torture, rape, cannibalism, and necrophilia.\n\nBuilding from the musical structure of thrash metal and early black metal, death metal emerged during the mid-1980s. Bands such as Venom, Celtic Frost, Slayer, and Kreator were important influences on the genre's creation. Possessed and Death, along with bands such as Obituary, Autopsy and Morbid Angel, are often considered pioneers of the genre. In the late 1980s and early 1990s, death metal gained more media attention as popular genre niche record labels like Combat, Earache, and Roadrunner, began to sign death metal bands at a rapid rate.\n\nSince then, death metal has diversified, spawning several subgenres. Melodic death metal combines death metal elements with those of the new wave of British heavy metal. Technical death metal is a complex style, with uncommon time signatures, atypical rhythms and unusual harmonies and melodies. Death-doom combines the deep growled vocals and double-kick drumming of death metal with the slow tempos and melancholic atmosphere of doom metal. Deathgrind, goregrind and pornogrind mix the complexity of death metal with the intensity, speed, and brevity of grindcore. Deathcore combines death metal with metalcore traits. Death 'n' roll combines death metal's growled vocals and highly distorted, detuned guitar riffs with elements of 1970s hard rock and heavy metal.\n\nEnglish heavy metal band Venom, from Newcastle, crystallized the elements of what later became known as thrash metal, death metal and black metal, with their 1981 album \"Welcome to Hell\". Their dark, blistering sound, harsh vocals, and macabre, proudly Satanic imagery proved a major inspiration for extreme metal bands. Another highly influential band, Slayer, formed in 1981. Although the band was a thrash metal act, Slayer's music was more violent than their thrash contemporaries Metallica, Megadeth, and Anthrax. Their breakneck speed and instrumental prowess combined with lyrics about death, violence, war, and Satanism won Slayer a rabid cult following. According to AllMusic, their third album \"Reign in Blood\" inspired the entire death metal genre. It had a big impact on genre leaders such as Death, Obituary, and Morbid Angel.\n\nPossessed, a band that formed in the San Francisco Bay Area during 1983, is described by Allmusic as \"connecting the dots\" between thrash metal and death metal with their 1985 debut album, \"Seven Churches\". While attributed as having a Slayer influence, current and former members of the band had actually cited Venom and Motörhead, as well as early work by Exodus, as the main influences on their sound. Although the group had released only two studio albums and an EP in their formative years, they have been described by music journalists and musicians as either being \"monumental\" in developing the death metal style, or as being the first death metal band. Earache Records noted that \"the likes of Trey Azagthoth and Morbid Angel based what they were doing in their formative years on the Possessed blueprint laid down on the legendary \"Seven Churches\" recording. Possessed arguably did more to further the cause of 'Death Metal' than any of the early acts on the scene back in the mid-late 80's.\"\n\nDuring the same period as the dawn of Possessed, a second influential metal band was formed in Florida: Death. Death, originally called Mantas, was formed in 1983 by Chuck Schuldiner, Kam Lee, and Rick Rozz. In 1984 they released their first demo entitled \"Death by Metal\", followed by several more. The tapes circulated through the tape trader world, quickly establishing the band's name. With Death guitarist Schuldiner adopting vocal duties, the band made a major impact on the scene. The fast minor-key riffs and solos were complemented with fast drumming, creating a style that would catch on in tape trading circles. Schuldiner has been credited by Allmusic's Eduardo Rivadavia for being widely recognized as the \"Father of Death Metal\". Death's 1987 debut release, \"Scream Bloody Gore\", has been described by About.com's Chad Bowar as being the \"evolution from thrash metal to death metal\", and \"the first true death metal record\" by the \"San Francisco Chronicle\". Along with Possessed and Death, other pioneers of death metal in the United States include Macabre, Necrophagia, Master, Massacre, Immolation, Cannibal Corpse, and Post Mortem.\n\nBy 1989, many bands had been signed by eager record labels wanting to cash in on the subgenre, including Florida's Obituary, Morbid Angel and Deicide. This collective of death metal bands hailing from Florida are often labeled as \"Florida death metal\". Morbid Angel pushed the genre to its most extreme level, both musically and lyrically, with the release of their debut album \"Altars of Madness\" in 1989. The album \"redefined what it meant to be heavy while influencing an upcoming class of brutal death metal.\" Death metal spread to Sweden in the late 1980s, flourishing with pioneers such as Carnage, God Macabre, Entombed, Dismember and Unleashed. In the early 1990s, the rise of melodic death metal was recognized, with bands such as Dark Tranquillity, At the Gates, and In Flames.\n\nFollowing the original death metal innovators, new subgenres began by the end of the decade. British band Napalm Death became increasingly associated with death metal, in particular, on 1990s \"Harmony Corruption\". This album displays aggressive and fairly technical guitar riffing, complex rhythmics, a sophisticated growling vocal delivery by Mark \"Barney\" Greenway, and socially aware lyrical subjects, leading to a merging with the \"grindcore\" subgenre. Other bands contributing significantly to this early movement include Britain's Bolt Thrower and Carcass, and New York's Suffocation.\n\nTo close the circle, Death released their fourth album \"Human\" in 1991. Death's founder Schuldiner helped push the boundaries of uncompromising speed and technical virtuosity, mixing technical and intricate rhythm guitar work with complex arrangements and emotive guitar solos. Other examples are Carcass's \"Necroticism – Descanting the Insalubrious\", Suffocation's \"Effigy of the Forgotten\" and Entombed's \"Clandestine\" from 1991. At this point, all the above characteristics are present: abrupt tempo and count changes, on occasion extremely fast drumming, morbid lyrics and growling vocal delivery.\n\nEarache Records, Relativity Records and Roadrunner Records became the genre's most important labels, with Earache releasing albums by Carcass, Napalm Death, Morbid Angel, and Entombed, and Roadrunner releasing albums by Obituary, and Pestilence. Although these labels had not been death metal labels, initially, they became the genre's flagship labels in the beginning of the 1990s. In addition to these, other labels formed as well, such as Nuclear Blast, Century Media, and Peaceville. Many of these labels would go on to achieve successes in other genres of metal throughout the 1990s.\n\nIn September 1990, Death's manager Eric Greif held one of the first North American death metal festivals, \"Day of Death\", in Milwaukee suburb Waukesha, Wisconsin, and featured 26 bands including Autopsy, Broken Hope, Hellwitch, Obliveon, Revenant, Viogression, Immolation, Atheist, and Cynic.\n\nDeath metal's popularity achieved its initial peak between the 1992–93 era, with some bands such as Morbid Angel, Cannibal Corpse, as well as Obituary, enjoying mild commercial success. However, the genre as a whole never broke into the mainstream. The genre's mounting popularity may have been partly responsible for a strong rivalry between Norwegian black metal and Swedish death metal scenes. Fenriz of Darkthrone has noted that Norwegian black metal musicians were \"fed up with the whole death metal scene\" at the time. Death metal diversified in the 1990s, spawning a rich variety of subgenres which still have a large \"underground\" following at the present.\n\nThe setup most frequently used within the death metal genre is two guitarists, a bass player, a vocalist and a drummer often using \"hyper double-bass blast beats\". Although this is the standard setup, bands have been known to occasionally incorporate other instruments such as electronic keyboards. The genre is often identified by fast, heavily distorted and low tuned guitars, played with techniques such as palm muting and tremolo picking. The percussion is usually aggressive and powerful.\n\nDeath metal is known for its abrupt tempo, key, and time signature changes. Death metal may include chromatic chord progressions and a varied song structure. In some circumstances, the style will incorporate melodic riffs and harmonies for effect. This incorporation of melody and harmonious playing was even further used in the creation of melodic death metal. These compositions tend to emphasize an ongoing development of themes and motifs.\n\nDeath metal vocals are referred to as death growls; hoarse roars/snarls. Death growling is mistakenly thought to be a form of screaming using the lowest vocal register known as vocal fry, however vocal fry is actually a form of overtone screaming, and while growling can be performed this way by experienced vocalists who use the fry screaming technique, \"true\" death growling is in fact created by an altogether different technique. The three major methods of harsh vocalization used in the genre are often mistaken for each other, encompassing vocal fry screaming, false chord screaming, and \"true\" death growls. Growling is sometimes also referred to as Cookie Monster vocals, tongue-in-cheek, due to the vocal similarity to the voice of the popular \"Sesame Street\" character of the same name. Although often criticized, death growls serve the aesthetic purpose of matching death metal's aggressive lyrical content. High-pitched screaming is occasionally utilized in death metal, being heard in songs by Death, Aborted, Exhumed, Dying Fetus, Cannibal Corpse, and Deicide.\n\nThe lyrical themes of death metal may invoke slasher film-stylised violence, but may also extend to topics like Satanism, religion, occultism, Lovecraftian horror, nature, mysticism, philosophy, science fiction, and politics. Although violence may be explored in various other genres as well, death metal may elaborate on the details of extreme acts, including mutilation, dissection, torture, rape, cannibalism, and necrophilia. Sociologist Keith Kahn-Harris commented this apparent glamorisation of violence may be attributed to a \"fascination\" with the human body that all people share to some degree, a fascination which mixes desire and disgust. Heavy metal author Gavin Baddeley also stated there does seem to be a connection between \"how acquainted one is with their own mortality\" and \"how much they crave images of death and violence\" via the media. Additionally, contributing artists to the genre often defend death metal as little more than an extreme form of art and entertainment, similar to horror films in the motion picture industry. This explanation has brought such musicians under fire from activists internationally, who claim that this is often lost on a large number of adolescents, who are left with the glamorisation of such violence without social context or awareness of why such imagery is stimulating.\n\nAccording to Alex Webster, bassist of Cannibal Corpse, \"The gory lyrics are probably not, as much as people say, [what's keeping us] from being mainstream. Like, 'death metal would never go into the mainstream because the lyrics are too gory?' I think it's really the music, because violent entertainment is totally mainstream.\"\n\nThe most popular theory of the subgenre's christening is Possessed's 1984 demo, \"Death Metal\"; the song from the eponymous demo would also be featured on the band's 1985 debut album, \"Seven Churches\". Possessed vocalist/bassist Jeff Becerra said he coined the term in early 1983 for a high school English class assignment. Another possible origin is a fanzine called \"Death Metal\", started by Thomas Fischer and Martin Ain of Hellhammer and Celtic Frost. The name was later given to the 1984 compilation \"Death Metal\" released by Noise Records. The term might also have originated from other recordings, such as the demo released by Death in 1984, called \"Death by Metal\".\n\nCited examples are not necessarily exclusive to one particular style. Many bands can easily be placed in two or more of the following categories, and a band's specific categorization is often a source of contention due to personal opinion and interpretation.\n\n\n\n"}
{"id": "8237", "url": "https://en.wikipedia.org/wiki?curid=8237", "title": "Don Quixote", "text": "Don Quixote\n\nThe story follows the adventures of a hidalgo named Mr. Alonso Quixano who reads so many chivalric romances that he loses his sanity and decides to set out to revive chivalry, undo wrongs, and bring justice to the world, under the name \"Don Quixote de la Mancha\". He recruits a simple farmer, Sancho Panza, as his squire, who often employs a unique, earthy wit in dealing with Don Quixote's rhetorical orations on antiquated knighthood. Don Quixote, in the first part of the book, does not see the world for what it is and prefers to imagine that he is living out a knightly story. Throughout the novel, Cervantes uses such literary techniques as realism, metatheatre, and intertextuality. The book had a major influence on the literary community, as evidenced by direct references in Alexandre Dumas' \"The Three Musketeers\" (1844), Mark Twain's \"Adventures of Huckleberry Finn\" (1884), and Edmond Rostand's \"Cyrano de Bergerac\" (1897), as well as the word \"quixotic\" and the epithet \"Lothario\"; the latter refers to a character in \"El Curioso Impertinente\" (\"The Impertinently Curious Man\"), an intercalated story that appears in Part One, Book Four, chapters 33–35. Arthur Schopenhauer cited \"Don Quixote\" as one of the four greatest novels ever written, along with \"Tristram Shandy\", \"La Nouvelle Héloïse\", and \"Wilhelm Meister\".\n\nCervantes wrote that the first chapters were taken from \"The Archive of La Mancha\", and the rest were translated from Arabic by the Moorish author Cide Hamete Benengeli. This metafictional trick appears to give a greater credibility to the text, implying that Don Quixote is a real character and that the events related truly occurred several decades prior to the recording of this account. However, it was also common practice in that era for fictional works to make some pretense of being factual, such as the common opening line of fairy tales \"Once upon a time in a land far away...\"\n\nAlonso Quixano, the protagonist of the novel (though he is not given this name until much later in the book), is a Hidalgo (member of the lesser Spanish nobility), nearing 50 years of age, living in an unnamed section of La Mancha with his niece and housekeeper, as well as a boy who is never heard of again after the first chapter. Although Quixano is usually a rational man, in keeping with the humoral theory of the time, not sleeping adequately — because he was reading — has caused his brain to dry; Quixano's temperament is thus choleric, the hot and dry humor. As a result, he is easily given to anger and believes every word of these fictional books of chivalry to be true.\n\nImitating the protagonists of these books, he decides to become a knight-errant in search of adventure. To these ends, he dons an old suit of armour, renames himself \"Don Quixote\", names his exhausted horse \"Rocinante\", and designates Aldonza Lorenzo, a neighboring farm girl, as his lady love, renaming her Dulcinea del Toboso, while she knows nothing of this. Expecting to become famous quickly, he arrives at an inn, which he believes to be a castle; calls the prostitutes he meets \"ladies\" (\"doncellas\"); and asks the innkeeper, whom he takes as the lord of the castle, to dub him a knight. He spends the night holding vigil over his armor and becomes involved in a fight with muleteers who try to remove his armor from the horse trough so that they can water their mules. In a pretended ceremony, the innkeeper dubs him a knight to be rid of him and sends him on his way.\n\nDon Quixote next \"frees\" a young boy tied to a tree and beaten by his master, and makes his master swear to treat the boy fairly; but the boy's beating is continued as soon as Quixote leaves. Don Quixote then encounters traders from Toledo, who \"insult\" the imaginary Dulcinea. He attacks them, only to be severely beaten and left on the side of the road, and returned to his home by a neighbouring peasant.\n\nWhile Don Quixote is unconscious in his bed, his niece, the housekeeper, the parish curate and the local barber burn most of his chivalric and other books. A large part of this section consists of the priest deciding which books deserve to be burned and which to be saved. This gives an occasion for many comments on books Cervantes liked and disliked. For example, Cervantes' own pastoral novel \"La Galatea\" is saved, while the rather unbelievable romance \"Felixmarte de Hyrcania\" is burned. After the books are dealt with, they seal up the room which contained the library, later telling Don Quixote that it was the action of a wizard (\"encantador\").\n\nAfter a short period of feigning health, Don Quixote requests his neighbour, Sancho Panza, to be his squire, promising him a petty governorship (\"ínsula\"). Sancho is a poor and simple farmer but more practical than the head-in-the-clouds Don Quixote and agrees to the offer, sneaking away with Don Quixote in the early dawn. It is here that their famous adventures begin, starting with Don Quixote's attack on windmills that he believes to be ferocious giants.\n\nThe two next encounter a group of friars accompanying a lady in a carriage. Don Quixote takes the friars to be enchanters who hold the lady captive, knocks a friar from his horse, and is immediately challenged by an armed Basque traveling with the company. As he has no shield, the Basque uses a pillow to protect himself, which saves him when Don Quixote strikes him. Cervantes chooses this point, in the middle of the battle, to say that his source ends here. Soon, however, he resumes Don Quixote's adventures after a story about finding Arabic notebooks containing the rest of the story by Cid Hamet Ben Engeli. The combat ends with the lady leaving her carriage and commanding those traveling with her to \"surrender\" to Don Quixote.\n\nSancho and Don Quixote fall in with a group of goat herders. Don Quixote tells Sancho and the goat herders about the \"Golden Age\" of man, in which property does not exist and men live in peace. The goatherders invite the Knight and Sancho to the funeral of Grisóstomo, once a student who left his studies to become a shepherd after reading pastoral novels (paralleling Don Quixote's decision to become a knight), seeking the shepherdess Marcela. At the funeral Marcela appears, vindicating herself from the bitter verses written about her by Grisóstomo, and claiming her own autonomy and freedom from expectations put on her by pastoral clichés. She disappears into the woods, and Don Quixote and Sancho follow. Ultimately giving up, the two dismount by a pond to rest. Some Galicians arrive to water their ponies, and Rocinante (Don Quixote's horse) attempts to mate with the ponies. The Galicians hit Rocinante with clubs to dissuade him, whereupon Don Quixote tries to defend Rocinante. The Galicians beat Don Quixote and Sancho, leaving them in great pain.\n\nAfter escaping the musketeers, Don Quixote and Sancho ride to a nearby inn. Once again, Don Quixote imagines the inn is a castle, although Sancho is not quite convinced. Don Quixote is given a bed in a former hayloft, and Sancho sleeps on the rug next to the bed; they share the loft with a muleteer. When night comes, Don Quixote imagines the servant girl at the inn, Helen, to be a beautiful princess, and makes her sit on his bed with him, scaring her. Seeing what is happening, the muleteer attacks Don Quixote, breaking the fragile bed and leading to a large and chaotic fight in which Don Quixote and Sancho are once again badly hurt. Don Quixote's explanation for everything is that they fought with an enchanted Moor. He also believes that he can cure their wounds with a mixture he calls \"the balm of Firearbras\", which only makes them sick. Don Quixote and Sancho decide to leave the inn, but Quixote, following the example of the fictional knights, leaves without paying. Sancho, however, remains and ends up wrapped in a blanket and tossed up in the air (blanketed) by several mischievous guests at the inn, something that is often mentioned over the rest of the novel. After his release, he and Don Quixote continue their travels.\n\nAfter Don Quixote frees a group of galley slaves, he and Sancho wander into the Sierra Morena and there encounter the dejected Cardenio. Cardenio relates the first part of his story, in which he falls deeply in love with his childhood friend Luscinda, and is hired as the companion to the Duke's son, leading to his friendship with the Duke's younger son, Don Fernando. Cardenio confides in Don Fernando his love for Luscinda and the delays in their engagement, caused by Cardenio's desire to keep with tradition. After reading Cardenio's poems praising Luscinda, Don Fernando falls in love with her. Don Quixote interrupts when Cardenio suggests that his beloved may have become unfaithful after the formulaic stories of spurned lovers in chivalric novels.\n\nIn the course of their travels, the protagonists meet innkeepers, prostitutes, goatherders, soldiers, priests, escaped convicts and scorned lovers. The aforementioned characters sometimes tell tales that incorporate events from the real world, like the conquest of the Kingdom of Maynila or battles in the Eighty Years' War . Their encounters are magnified by Don Quixote's imagination into chivalrous quests. Don Quixote's tendency to intervene violently in matters irrelevant to himself, and his habit of not paying debts, result in privations, injuries and humiliations (with Sancho often the victim). Finally, Don Quixote is persuaded to return to his home village. The narrator hints that there was a third quest, but says that records of it have been lost.\n\nAlthough the two parts are now published as a single work, \"Don Quixote, Part Two\" was a sequel published ten years after the original novel. While \"Part One\" was mostly farcical, the second half is more serious and philosophical about the theme of deception.\n\nAs \"Part Two\" begins, it is assumed that the literate classes of Spain have all read the first part of the story. Cervantes's meta-fictional device was to make even the characters in the story familiar with the publication of \"Part One\", as well as with an actually published, fraudulent Part Two. When strangers encounter the duo in person, they already know their famous history. A Duke and Duchess, and others, deceive Don Quixote for entertainment, setting forth a string of imagined adventures resulting in a series of practical jokes. Some of them put Don Quixote's sense of chivalry and his devotion to Dulcinea through many tests. Pressed into finding Dulcinea, Sancho brings back three ragged peasant girls and tells Don Quixote that they are Dulcinea and her ladies-in-waiting. When Don Quixote only sees the peasant girls, Sancho pretends (reversing some incidents of \"Part One\") that their derelict appearance results from an enchantment.\n\nSancho later gets his comeuppance for this when, as part of one of the Duke and Duchess's pranks, the two are led to believe that the only method to release Dulcinea from her spell is for Sancho to give himself three thousand three hundred lashes. Sancho naturally resists this course of action, leading to friction with his master. Under the Duke's patronage, Sancho eventually gets a governorship, though it is false; and he proves to be a wise and practical ruler; though this ends in humiliation as well. Near the end, Don Quixote reluctantly sways towards sanity.\n\nThe lengthy untold \"history\" of Don Quixote's adventures in knight-errantry comes to a close after his battle with the Knight of the White Moon (a young man from Don Quixote's hometown who had previously posed as the Knight of Mirrors) on the beach in Barcelona, in which the reader finds him conquered. Bound by the rules of chivalry, Don Quixote submits to prearranged terms that the vanquished is to obey the will of the conqueror: here, it is that Don Quixote is to lay down his arms and cease his acts of chivalry for the period of one year (in which he may be cured of his madness).\n\nUpon returning to his village, Don Quixote announces his plan to retire to the countryside as a shepherd, but his housekeeper urges him to stay at home. Soon after, he retires to his bed with a deathly illness, and later awakes from a dream, having fully recovered his sanity. Sancho tries to restore his faith, but Quixano (his proper name) only renounces his previous ambition and apologizes for the harm he has caused. He dictates his will, which includes a provision that his niece will be disinherited if she marries a man who reads books of chivalry. After Alonso Quixano dies, the author emphasizes that there are no more adventures to relate and that any further books about Don Quixote would be spurious.\n\n\"Part Two\" of \"Don Quixote\" explores the concept of a character understanding that he is written about: an idea much explored in the 20th century.\n\nHarold Bloom says that \"Don Quixote\" is a work of radical nihilism and anarchism, which prefers the glory of fantasy over a real world, which includes imminent death, and is \"the first modern novel\".\n\nEdith Grossman, who wrote and published a highly acclaimed English translation of the novel in 2003, says that the book is mostly meant to move people into emotion using a systematic change of course, on the verge of both tragedy and comedy at the same time. Grossman has stated:The question is that Quixote has multiple interpretations [...] and how do I deal with that in my translation. I'm going to answer your question by avoiding it [...] so when I first started reading the Quixote I thought it was the most tragic book in the world, and I would read it and weep [...] As I grew older [...] my skin grew thicker [...] and so when I was working on the translation I was actually sitting at my computer and laughing out loud. This is done [...] as Cervantes did it [...] by never letting the reader rest. You are never certain that you truly got it. Because as soon as you think you understand something, Cervantes introduces something that contradicts your premise.\n\nThe novel's structure is episodic in form. It is written in the \"picaresco\" style of the late 16th century and features references to other picaresque novels including \"Lazarillo de Tormes\" and \"The Golden Ass\". The full title is indicative of the tale's object, as \"ingenioso\" (Spanish) means \"quick with inventiveness\", marking the transition of modern literature from dramatic to thematic unity. The novel takes place over a long period of time, including many adventures united by common themes of the nature of reality, reading, and dialogue in general.\n\nAlthough burlesque on the surface, the novel, especially in its second half, has served as an important thematic source not only in literature but also in much of art and music, inspiring works by Pablo Picasso and Richard Strauss. The contrasts between the tall, thin, fancy-struck and idealistic Quixote and the fat, squat, world-weary Panza is a motif echoed ever since the book's publication, and Don Quixote's imaginings are the butt of outrageous and cruel practical jokes in the novel.\n\nEven faithful and simple Sancho is forced to deceive him at certain points. The novel is considered a satire of orthodoxy, veracity and even nationalism. In exploring the individualism of his characters, Cervantes helped move beyond the narrow literary conventions of the chivalric romance literature that he spoofed, which consists of straightforward retelling of a series of acts that redound to the knightly virtues of the hero. The character of Don Quixote became so well known in its time that the word \"quixotic\" was quickly adopted by many languages. Characters such as Sancho Panza and Don Quixote's steed, Rocinante, are emblems of Western literary culture. The phrase \"tilting at windmills\" to describe an act of attacking imaginary enemies, derives from an iconic scene in the book.\n\nIt stands in a unique position between medieval chivalric romance and the modern novel. The former consist of disconnected stories featuring the same characters and settings with little exploration of the inner life of even the main character. The latter are usually focused on the psychological evolution of their characters. In Part I, Quixote imposes himself on his environment. By Part II, people know about him through \"having read his adventures\", and so, he needs to do less to maintain his image. By his deathbed, he has regained his sanity, and is once more \"Alonso Quixano the Good\".\n\nWhen first published, \"Don Quixote\" was usually interpreted as a comic novel. After the French Revolution, it was popular for its central ethic that individuals can be right while society is quite wrong and seen as disenchanting. In the 19th century, it was seen as a social commentary, but no one could easily tell \"whose side Cervantes was on\". Many critics came to view the work as a tragedy in which Don Quixote's idealism and nobility are viewed by the post-chivalric world as insane, and are defeated and rendered useless by common reality. By the 20th century, the novel had come to occupy a canonical space as one of the foundations of modern literature.\n\nSources for \"Don Quixote\" include the Castilian novel \"Amadis de Gaula\", which had enjoyed great popularity throughout the 16th century. Another prominent source, which Cervantes evidently admires more, is \"Tirant lo Blanch\", which the priest describes in Chapter VI of \"Quixote\" as \"the best book in the world.\" (However, the sense in which it was \"best\" is much debated among scholars. The passage is called since the 19th century \"the most difficult passage of \"Don Quixote\"\".)\nThe scene of the book burning gives us an excellent list of Cervantes's likes and dislikes about literature.\n\nCervantes makes a number of references to the Italian poem \"Orlando furioso\". In chapter 10 of the first part of the novel, Don Quixote says he must take the magical helmet of Mambrino, an episode from Canto I of \"Orlando\", and itself a reference to Matteo Maria Boiardo's \"Orlando innamorato\". The interpolated story in chapter 33 of Part four of the First Part is a retelling of a tale from Canto 43 of \"Orlando\", regarding a man who tests the fidelity of his wife.\n\nAnother important source appears to have been Apuleius's \"The Golden Ass\", one of the earliest known novels, a picaresque from late classical antiquity. The wineskins episode near the end of the interpolated tale \"The Curious Impertinent\" in chapter 35 of the first part of \"Don Quixote\" is a clear reference to Apuleius, and recent scholarship suggests that the moral philosophy and the basic trajectory of Apuleius's novel are fundamental to Cervantes's program. Similarly, many of both Sancho's adventures in Part II and proverbs throughout are taken from popular Spanish and Italian folklore.\n\nCervantes's experiences as a galley slave in Algiers also influenced \"Quixote\".\n\nIt is not certain when Cervantes began writing \"Part Two\" of \"Don Quixote\", but he had probably not proceeded much further than Chapter LIX by late July 1614. About September, however, a spurious Part Two, entitled \"Second Volume of the Ingenious Gentleman Don Quixote of La Mancha: by the Licenciado (doctorate) Alonso Fernández de Avellaneda, of Tordesillas\", was published in Tarragona by an unidentified Aragonese who was an admirer of Lope de Vega, rival of Cervantes.\n\nSome modern scholars suggest that Don Quixote's fictional encounter with Avellaneda in Chapter 59 of Part II should not be taken as the date that \"Cervantes\" encountered it, which may have been much earlier.\n\nAvellaneda's identity has been the subject of many theories, but there is no consensus as to who he was. In its prologue, the author gratuitously insulted Cervantes, who not surprisingly took offense and responded; the last half of Chapter LIX and most of the following chapters of Cervantes' \"Segunda Parte\" lend some insight into the effects upon him; Cervantes manages to work in some subtle digs at Avellaneda's own work, and in his preface to Part II, comes very near to criticizing Avellaneda directly.\n\nIn his introduction to \"The Portable Cervantes\", Samuel Putnam, a noted translator of Cervantes' novel, calls Avellaneda's version \"one of the most disgraceful performances in history\".\n\nThe second part of Cervantes' \"Don Quixote\", finished as a direct result of the Avellaneda book, has come to be regarded by some literary critics as superior to the first part, because of its greater depth of characterization, its discussions, mostly between Quixote and Sancho, on diverse subjects, and its philosophical insights.\n\n\"Don Quixote, Part One\" contains a number of stories which do not directly involve the two main characters, but which are narrated by some of the picaresque figures encountered by the Don and Sancho during their travels. The longest and best known of these is \"El Curioso Impertinente\" (the impertinently curious man), found in Part One, Book Four. This story, read to a group of travelers at an inn, tells of a Florentine nobleman, Anselmo, who becomes obsessed with testing his wife's fidelity, and talks his close friend Lothario into attempting to seduce her, with disastrous results for all.\n\nIn \"Part Two\", the author acknowledges the criticism of his digressions in \"Part One\" and promises to concentrate the narrative on the central characters (although at one point he laments that his narrative muse has been constrained in this manner). Nevertheless, \"Part Two\" contains several back narratives related by peripheral characters.\n\nSeveral abridged editions have been published which delete some or all of the extra tales in order to concentrate on the central narrative.\n\nCervantes wrote his work in an early modern form of Spanish, heavily borrowing from Old Castilian, the medieval form of the Spanish language. The language of \"Don Quixote\", although still containing archaisms, is far more understandable to modern Spanish readers than is, for instance, the completely medieval Spanish of the \"Poema de mio Cid\", a kind of Spanish that is as different from Cervantes's language as Middle English is from Modern English. The Old Castilian language was also used to show the higher class that came with being a knight errant.\n\nIn \"Don Quixote\", there are basically two different types of Castilian: Old Castilian is spoken only by Don Quixote, while the rest of the roles speak a modern version of Spanish. The Old Castilian of Don Quixote is a humoristic resource – he copies the language spoken in the chivalric books that made him mad; and many times, when he talks nobody is able to understand him because his language is too old. This humorous effect is more difficult to see nowadays because the reader must be able to distinguish the two old versions of the language, but when the book was published it was much celebrated. (English translations can get some sense of the effect by having Don Quixote use King James Bible or Shakespearian English, or even Middle English.)\n\nIn Old Castilian, the letter \"x\" represented the sound written \"sh\" in modern English, so the name was originally pronounced . However, as Old Castilian evolved towards modern Spanish, a sound change caused it to be pronounced with a voiceless velar fricative sound (like the Scottish or German \"ch\"), and today the Spanish pronunciation of \"Quixote\" is . The original pronunciation is reflected in languages such as Astur-Leonese, Galician, Catalan, Italian, Portuguese, and French, where it is pronounced with a \"sh\" or \"ch\" sound; the French opera \"Don Quichotte\" is one of the best-known modern examples of this pronunciation.\n\nToday, English speakers generally attempt something close to the modern Spanish pronunciation of \"Quixote\" (\"Quijote\"), as , although the traditional English spelling-based pronunciation with the value of the letter x in modern English is still sometimes used, resulting in or . In Australian English, the preferred pronunciation amongst members of the educated classes was until well into the 1970s, as part of a tendency for the upper class to \"anglicise its borrowing ruthlessly\". The traditional English rendering is preserved in the pronunciation of the adjectival form \"quixotic\", i.e., , defined by \"Merriam-Webster\" as the foolishly impractical pursuit of ideals, typically marked by rash and lofty romanticism.\n\nCervantes' story takes place on the plains of La Mancha, specifically the \"comarca\" of Campo de Montiel.\n\nThe story also takes place in El Toboso where Don Quixote goes to seek Dulcinea's blessings.\nThe location of the village to which Cervantes alludes in the opening sentence of \"Don Quixote\" has been the subject of debate since its publication over four centuries ago. Indeed, Cervantes deliberately omits the name of the village, giving an explanation in the final chapter:\n\nIn 2004, a multidisciplinary team of academics from Complutense University, led by Francisco Parra Luna, Manuel Fernández Nieto, and Santiago Petschen Verdaguer, deduced that the village was that of Villanueva de los Infantes. Their findings were published in a paper titled \"\"'El Quijote' como un sistema de distancias/tiempos: hacia la localización del lugar de la Mancha\"\", which was later published as a book: \"El enigma resuelto del Quijote\". The result was replicated in two subsequent investigations: \"\"La determinación del lugar de la Mancha como problema estadístico\"\" and \"The Kinematics of the Quixote and the Identity of the 'Place in La Mancha'\".\n\nResearchers Isabel Sanchez Duque and Francisco Javier Escudero have found relevant information regarding the possible sources of inspiration of Cervantes for writing Don Quixote. Cervantes was friend of the family Villaseñor, which was involved in a combat with Francisco de Acuña. Both sides combated disguised as medieval knights in the road from El Toboso to Miguel Esteban in 1581. They also found a person called Rodrigo Quijada, who bought the title of nobility of \"hidalgo\", and created diverse conflicts with the help of a squire.\n\nBecause of its widespread influence, \"Don Quixote\" also helped cement the modern Spanish language. The opening sentence of the book created a classic Spanish cliché with the phrase (\"whose name I do not wish to recall\"): (\"In a village of La Mancha, whose name I do not wish to recall, there lived, not very long ago, one of those gentlemen with a lance in the lance-rack, an ancient shield, a skinny old horse, and a fast greyhound.\")\n\nThe novel's farcical elements make use of punning and similar verbal playfulness. Character-naming in \"Don Quixote\" makes ample figural use of contradiction, inversion, and irony, such as the names \"Rocinante\" (a reversal) and \"Dulcinea\" (an allusion to illusion), and the word itself, possibly a pun on (jaw) but certainly (Catalan: thighs), a reference to a horse's rump.\n\nAs a military term, the word \"quijote\" refers to \"cuisses\", part of a full suit of plate armour protecting the thighs. The Spanish suffix \"-ote\" denotes the augmentative—for example, \"grande\" means large, but \"grandote\" means extra large. Following this example, \"Quixote\" would suggest 'The Great Quijano', a play on words that makes much sense in light of the character's delusions of grandeur.\n\n\"La Mancha\" is a region of Spain, but \"mancha\" (Spanish word) means spot, mark, stain. Translators such as John Ormsby have declared La Mancha to be one of the most desertlike, unremarkable regions of Spain, the least romantic and fanciful place that one would imagine as the home of a courageous knight.\n\nIn July 1604, Cervantes sold the rights of \"El ingenioso hidalgo don Quixote de la Mancha\" (known as \"Don Quixote, Part I\") to the publisher-bookseller Francisco de Robles for an unknown sum. License to publish was granted in September, the printing was finished in December, and the book came out on 16 January 1605.\n\nThe novel was an immediate success. The majority of the 400 copies of the first edition were sent to the New World, with the publisher hoping to get a better price in the Americas. Although most of them disappeared in a shipwreck near La Havana, approximately 70 copies reached Lima, from where they were sent to Cuzco in the heart of the defunct Inca Empire.\n\nNo sooner was it in the hands of the public than preparations were made to issue derivative (pirated) editions. \"Don Quixote\" had been growing in favour, and its author's name was now known beyond the Pyrenees. By August 1605, there were two Madrid editions, two published in Lisbon, and one in Valencia. Publisher Francisco de Robles secured additional copyrights for Aragon and Portugal for a second edition.\n\nSale of these publishing rights deprived Cervantes of further financial profit on \"Part One\". In 1607, an edition was printed in Brussels. Robles, the Madrid publisher, found it necessary to meet demand with a third edition, a seventh publication in all, in 1608. Popularity of the book in Italy was such that a Milan bookseller issued an Italian edition in 1610. Yet another Brussels edition was called for in 1611. Since then, numerous editions have been released and in total, the novel is believed to have sold more than 10 million copies worldwide. The work has been produced in numerous editions and languages, the Cervantes Collection, at the State Library of New South Wales includes over 1,100 editions. These were collected, by Dr Ben Haneman, over a period of thirty years.\n\nIn 1613, Cervantes published the \"Novelas Ejemplares\", dedicated to the Maecenas of the day, the Conde de Lemos. Eight and a half years after \"Part One\" had appeared, we get the first hint of a forthcoming \"Segunda Parte\" (Part Two). \"You shall see shortly,\" Cervantes says, \"the further exploits of Don Quixote and humours of Sancho Panza.\" \"Don Quixote, Part Two\", published by the same press as its predecessor, appeared late in 1615, and quickly reprinted in Brussels and Valencia (1616) and Lisbon (1617). Part two capitalizes on the potential of the first while developing and diversifying the material without sacrificing familiarity. Many people agree that it is richer and more profound. Parts One and Two were published as one edition in Barcelona in 1617. Historically, Cervantes's work has been said to have \"smiled Spain's chivalry away\", suggesting that Don Quixote as a chivalric satire contributed to the demise of Spanish Chivalry.\n\nThere are many translations of the book, and it has been adapted many times in shortened versions. Many derivative editions were also written at the time, as was the custom of envious or unscrupulous writers. Seven years after the \"Parte Primera\" appeared, \"Don Quixote\" had been translated into French, German, Italian, and English, with the first French translation of 'Part II' appearing in 1618, and the first English translation in 1620. One abridged adaptation, authored by Agustín Sánchez, runs slightly over 150 pages, cutting away about 750 pages.\n\nThomas Shelton's English translation of the \"First Part\" appeared in 1612 while Cervantes was still alive, although there is no evidence that Shelton had met the author. Although Shelton's version is cherished by some, according to John Ormsby and Samuel Putnam, it was far from satisfactory as a carrying over of Cervantes's text. Shelton's translation of the novel's \"Second Part\" appeared in 1620.\n\nNear the end of the 17th century, John Phillips, a nephew of poet John Milton, published what Putnam considered the worst English translation. The translation, as literary critics claim, was not based on Cervantes' text but mostly upon a French work by Filleau de Saint-Martin and upon notes which Thomas Shelton had written.\n\nAround 1700, a version by Pierre Antoine Motteux appeared. Motteux's translation enjoyed lasting popularity; it was reprinted as the Modern Library Series edition of the novel until recent times. Nonetheless, future translators would find much to fault in Motteux's version: Samuel Putnam criticized \"the prevailing slapstick quality of this work, especially where Sancho Panza is involved, the obtrusion of the obscene where it is found in the original, and the slurring of difficulties through omissions or expanding upon the text\". John Ormsby considered Motteux's version \"worse than worthless\", and denounced its \"infusion of Cockney flippancy and facetiousness\" into the original.\n\nThe proverb 'The proof of the pudding is in the eating' is widely attributed to Cervantes. The Spanish word for pudding, 'budín', however, doesn't appear in the original text but premieres in the Motteux translation. In Smolletts translation of 1755, he notes that the original text reads literally \"you will see when the eggs are fried\" meaning 'time will tell'.\n\nA translation by Captain John Stevens, which revised Thomas Shelton's version, also appeared in 1700, but its publication was overshadowed by the simultaneous release of Motteux's translation.\n\nIn 1742, the Charles Jervas translation appeared, posthumously. Through a printer's error, it came to be known, and is still known, as \"the Jarvis translation\". It was the most scholarly and accurate English translation of the novel up to that time, but future translator John Ormsby points out in his own introduction to the novel that the Jarvis translation has been criticized as being too stiff. Nevertheless, it became the most frequently reprinted translation of the novel until about 1885. Another 18th century translation into English was that of Tobias Smollett, himself a novelist, first published in 1755. Like the Jarvis translation, it continues to be reprinted today.\n\nMost modern translators take as their model the 1885 translation by John Ormsby. It is said that his translation was the most honest of all translations, without expansions upon the text or changing of the proverbs.\n\nAn expurgated children's version, under the title \"The Story of Don Quixote\", was published in 1922 (available on Project Gutenberg). It leaves out the risqué sections as well as chapters that young readers might consider dull, and embellishes a great deal on Cervantes's original text. The title page actually gives credit to the two editors as if they were the authors, and omits any mention of Cervantes.\n\nThe most widely read English-language translations of the mid-20th century are by Samuel Putnam (1949), J. M. Cohen (1950; Penguin Classics), and Walter Starkie (1957). The last English translation of the novel in the 20th century was by Burton Raffel, published in 1996. The 21st century has already seen four new translations of the novel into English. The first is by John D. Rutherford and the second by Edith Grossman. Reviewing the novel in the \"New York Times\", Carlos Fuentes called Grossman's translation a \"major literary achievement\" and another called it the \"most transparent and least impeded among more than a dozen English translations going back to the 17th century.\"\n\nIn 2005, the year of the novel's 400th anniversary, Tom Lathrop published a new English translation of the novel, based on a lifetime of specialized study of the novel and its history. The fourth translation of the 21st century was released in 2006 by former university librarian James Montgomery, 26 years after he had begun it, in an attempt to \"recreate the sense of the original as closely as possible, though not at the expense of Cervantes' literary style.\"\n\nSee list of works influenced by \"Don Quixote\"\".\"\n\nGeneral:\n\nhttps://www.academia.edu/32654689/What_is_Don_Quijote_Don_Quixote_And...And...And_The_Disjunctive_Synthesis_of_Cervantes_and_Kathy_Acker\n\n"}
{"id": "8239", "url": "https://en.wikipedia.org/wiki?curid=8239", "title": "Dylan", "text": "Dylan\n\nDylan may refer to:\n\n\n\n"}
{"id": "8240", "url": "https://en.wikipedia.org/wiki?curid=8240", "title": "Dada", "text": "Dada\n\nDada () or Dadaism was an art movement of the European avant-garde in the early 20th century, with early centers in Zürich, Switzerland at the Cabaret Voltaire (circa 1916); New York Dada began circa 1915, and after 1920 Dada flourished in Paris. Developed in reaction to World War I, the Dada movement consisted of artists who rejected the logic, reason, and aestheticism of modern capitalist society, instead expressing nonsense, irrationality, and anti-bourgeois protest in their works. The art of the movement spanned visual, literary, and sound media, including collage, sound poetry, cut-up writing, and sculpture. Dadaist artists expressed their discontent with violence, war, and nationalism, and maintained political affinities with the radical left.\nThere is no consensus on the origin of the movement's name; a common story is that the Austrian artist Richard Huelsenbeck plunged a knife at random into a dictionary, where it landed on \"dada\", a colloquial French term for a hobby horse. Others note that it suggests the first words of a child, evoking a childishness and absurdity that appealed to the group. Still others speculate that the word might have been chosen to evoke a similar meaning (or no meaning at all) in any language, reflecting the movement's internationalism.\n\nThe roots of Dada lay in pre-war avant-garde. The term anti-art, a precursor to Dada, was coined by Marcel Duchamp around 1913 to characterize works which challenge accepted definitions of art. Cubism and the development of collage and abstract art would inform the movement's detachment from the constraints of reality and convention. The work of French poets, Italian Futurists and the German Expressionists would influence Dada's rejection of the tight correlation between words and meaning. Works such as \"Ubu Roi\" (1896) by Alfred Jarry, and the ballet \"Parade\" (1916–17) by Erik Satie would also be characterized as proto-Dadaist works. The Dada movement's principles were first collected in Hugo Ball's in 1916.\n\nThe Dadaist movement included public gatherings, demonstrations, and publication of art/literary journals; passionate coverage of art, politics, and culture were topics often discussed in a variety of media. Key figures in the movement included Hugo Ball, Marcel Duchamp, Emmy Hennings, Hans Arp, Raoul Hausmann, Hannah Höch, Johannes Baader, Tristan Tzara, Francis Picabia, Huelsenbeck, George Grosz, John Heartfield, Man Ray, Beatrice Wood, Kurt Schwitters, Hans Richter, and Max Ernst, among others. The movement influenced later styles like the avant-garde and downtown music movements, and groups including surrealism, Nouveau Réalisme, pop art and Fluxus.\n\nDada was an informal international movement, with participants in Europe and North America. The beginnings of Dada correspond to the outbreak of World War I. For many participants, the movement was a protest against the bourgeois nationalist and colonialist interests, which many Dadaists believed were the root cause of the war, and against the cultural and intellectual conformity—in art and more broadly in society—that corresponded to the war.\n\nAvant-garde circles outside France knew of pre-war Parisian developments. They had seen (or participated in) Cubist exhibitions held at Galeries Dalmau, Barcelona (1912), Galerie Der Sturm in Berlin (1912), the Armory Show in New York (1913), SVU Mánes in Prague (1914), several Jack of Diamonds exhibitions in Moscow and at De Moderne Kunstkring, Amsterdam (between 1911 and 1915). Futurism developed in response to the work of various artists. Dada subsequently combined these approaches.\n\nMany Dadaists believed that the 'reason' and 'logic' of bourgeois capitalist society had led people into war. They expressed their rejection of that ideology in artistic expression that appeared to reject logic and embrace chaos and irrationality. For example, George Grosz later recalled that his Dadaist art was intended as a protest \"against this world of mutual destruction.\"\n\nAccording to Hans Richter Dada was not art: it was \"anti-art.\" Dada represented the opposite of everything which art stood for. Where art was concerned with traditional aesthetics, Dada ignored aesthetics. If art was to appeal to sensibilities, Dada was intended to offend.\n\nAs Hugo Ball expressed it, \"For us, art is not an end in itself ... but it is an opportunity for the true perception and criticism of the times we live in.\"\n\nA reviewer from the \"American Art News\" stated at the time that \"Dada philosophy is the sickest, most paralyzing and most destructive thing that has ever originated from the brain of man.\" Art historians have described Dada as being, in large part, a \"reaction to what many of these artists saw as nothing more than an insane spectacle of collective homicide.\"\n\nYears later, Dada artists described the movement as \"a phenomenon bursting forth in the midst of the postwar economic and moral crisis, a savior, a monster, which would lay waste to everything in its path... [It was] a systematic work of destruction and demoralization... In the end it became nothing but an act of sacrilege.\"\n\nTo quote Dona Budd's \"The Language of Art Knowledge\", Dada was born out of negative reaction to the horrors of the First World War. This international movement was begun by a group of artists and poets associated with the Cabaret Voltaire in Zürich. Dada rejected reason and logic, prizing nonsense, irrationality and intuition. The origin of the name Dada is unclear; some believe that it is a nonsensical word. Others maintain that it originates from the Romanian artists Tristan Tzara's and Marcel Janco's frequent use of the words \"da, da,\" meaning \"yes, yes\" in the Romanian language. Another theory says that the name \"Dada\" came during a meeting of the group when a paper knife stuck into a French–German dictionary happened to point to 'dada', a French word for 'hobbyhorse'. The movement primarily involved visual arts, literature, poetry, art manifestos, art theory, theatre, and graphic design, and concentrated its anti-war politics through a rejection of the prevailing standards in art through anti-art cultural works.\n\nIn 1916, Hugo Ball, Emmy Hennings, Tristan Tzara, Jean Arp, Marcel Janco, Richard Huelsenbeck, Sophie Taeuber, and Hans Richter, along with others, discussed art and put on performances in the Cabaret Voltaire expressing their disgust with the war and the interests that inspired it.\n\nSome sources state that Dada coalesced on October 6 at the Cabaret Voltaire. Other sources state that Dada did not originate fully in a Zürich literary salon but grew out of an already vibrant artistic tradition in Eastern Europe, particularly Romania, that transposed to Switzerland when a group of Jewish modernist artists (Tzara, Janco, Arthur Segal, and others) settled in Zürich. In the years prior to the First World War similar art had already risen in Bucharest and other Eastern European cities; it is likely that Dada's catalyst was the arrival in Zürich of artists like Tzara and Janco.\n\nHaving left Germany and Romania during the Great War, the artists found themselves in Switzerland, a country recognized for its neutrality. Inside this space of political neutrality they decided to use abstraction to fight against the social, political, and cultural ideas of that time. The dadaists believed those ideas to be a byproduct of bourgeois society, a society so apathetic it would rather fight a war against itself than challenge the \"status quo\".\n\nJanco recalled, \"We had lost confidence in our culture. Everything had to be demolished. We would begin again after the \"tabula rasa\". At the Cabaret Voltaire we began by shocking common sense, public opinion, education, institutions, museums, good taste, in short, the whole prevailing order.\" \n\nThe Cabaret closed its doors in early July and then at the first public soiree at Waag Hall on July 14, 1916, Ball recited the . In 1917, Tzara wrote a second considered one of the most important Dada writings, which was published in 1918. Other manifestos followed.\n\nA single issue of the magazine \"Cabaret Voltaire\" was the first publication to come out of the movement.\n\nAfter the cabaret closed down, Dada activities moved on to a new gallery, and Hugo Ball left for Bern. Tzara began a relentless campaign to spread Dada ideas. He bombarded French and Italian artists and writers with letters, and soon emerged as the Dada leader and master strategist. The Cabaret Voltaire re-opened, and is still in the same place at the Spiegelgasse 1 in the Niederdorf.\n\nZürich Dada, with Tzara at the helm, published the art and literature review \"Dada\" beginning in July 1917, with five editions from Zürich and the final two from Paris.\n\nOther artists, such as André Breton and Philippe Soupault, created “literature groups to help extend the influence of Dada.”\n\nAfter the fighting of the First World War had ended in the armistice of November 1918, most of the Zürich Dadaists returned to their home countries, and some began Dada activities in other cities. Others, such as the Swiss native Sophie Taeuber, would remain in Zürich into the 1920s.\n\n\"Berlin was a city of tightened stomachers, of mounting, thundering hunger, where hidden rage was transformed into a boundless money lust, and men's minds were concentrating more and more on questions of naked existence... Fear was in everybody's bones \"- Richard Hülsenbeck\n\nThe groups in Germany were not as strongly anti-art as other groups. Their activity and art were more political and social, with corrosive manifestos and propaganda, satire, public demonstrations and overt political activities. The intensely political and war-torn environment of Berlin had a dramatic impact on the ideas of Berlin Dadaists. Conversely, New York's geographic distance from the war spawned its more theoretically-driven, less political nature.\n\nIn February 1918, while the Great War was approaching its climax, Huelsenbeck gave his first Dada speech in Berlin, and he produced a Dada manifesto later in the year. Following the October Revolution in Russia, by then out of the war, Hannah Höch and George Grosz used Dada to express communist sympathies. Grosz, together with John Heartfield, Höch and Hausmann developed the technique of photomontage during this period. After the war, the artists published a series of short-lived political magazines and held the \"First International Dada Fair\", 'the greatest project yet conceived by the Berlin Dadaists', in the summer of 1920. As well as work by the main members of Berlin Dada – Grosz, Raoul Hausmann, Hannah Höch, Johannes Baader, Huelsenbeck and Heartfield – the exhibition also included the work of Otto Dix, Francis Picabia, Jean Arp, Max Ernst, Rudolf Schlichter, Johannes Baargeld and others. In all, over 200 works were exhibited, surrounded by incendiary slogans, some of which also ended up written on the walls of the Nazi's \"Entartete Kunst\" exhibition in 1937. Despite high ticket prices, the exhibition lost money, with only one recorded sale.\n\nThe Berlin group published periodicals such as \"Club Dada\", \"Der Dada\", \"Everyman His Own Football\", and \"Dada Almanach\".\n\nIn Cologne, Ernst, Baargeld, and Arp launched a controversial Dada exhibition in 1920 which focused on nonsense and anti-bourgeois sentiments. Cologne's Early Spring Exhibition was set up in a pub, and required that participants walk past urinals while being read lewd poetry by a woman in a communion dress. The police closed the exhibition on grounds of obscenity, but it was re-opened when the charges were dropped.\n\nLike Zürich, New York City was a refuge for writers and artists from the First World War. Soon after arriving from France in 1915, Marcel Duchamp and Francis Picabia met American artist Man Ray. By 1916 the three of them became the center of radical anti-art activities in the United States. American Beatrice Wood, who had been studying in France, soon joined them, along with Elsa von Freytag-Loringhoven. Arthur Cravan, fleeing conscription in France, was also in New York for a time. Much of their activity centered in Alfred Stieglitz's gallery, 291, and the home of Walter and Louise Arensberg.\n\nThe New Yorkers, though not particularly organized, called their activities \"Dada,\" but they did not issue manifestos. They issued challenges to art and culture through publications such as \"The Blind Man\", \"Rongwrong\", and \"New York Dada\" in which they criticized the traditionalist basis for \"museum\" art. New York Dada lacked the disillusionment of European Dada and was instead driven by a sense of irony and humor. In his book \"Adventures in the arts: informal chapters on painters, vaudeville and poets\" Marsden Hartley included an essay on \"\".\nDuring this time Duchamp began exhibiting \"readymades\" (everyday objects found or purchased and declared art) such as a bottle rack, and was active in the Society of Independent Artists. In 1917 he submitted the now famous \"Fountain\", a urinal signed R. Mutt, to the Society of Independent Artists exhibition but they rejected the piece. First an object of scorn within the arts community, the \"Fountain\" has since become almost canonized by some as one of the most recognizable modernist works of sculpture. Art world experts polled by the sponsors of the 2004 Turner Prize, Gordon's gin, voted it \"the most influential work of modern art\". As recent scholarship documents, the work is likely more collaborative than it has been given credit for in twentieth-century art history. Duchamp indicates in a 1917 letter to his sister that a female friend was centrally involved in the conception of this work. As he writes: \"One of my female friends who had adopted the pseudonym Richard Mutt sent me a porcelain urinal as a sculpture.\" The piece is more in line with the scatological aesthetics of Duchamp's friend and neighbour, the Baroness Elsa von Freytag-Loringhoven, than Duchamp's. In an attempt to \"pay homage to the spirit of Dada\" a performance artist named Pierre Pinoncelli made a crack in a replica of \"The Fountain\" with a hammer in January 2006; he also urinated on it in 1993.\n\nPicabia's travels tied New York, Zürich and Paris groups together during the Dadaist period. For seven years he also published the Dada periodical \"391\" in Barcelona, New York City, Zürich, and Paris from 1917 through 1924.\n\nBy 1921, most of the original players moved to Paris where Dada had experienced its last major incarnation.\n\nThe French avant-garde kept abreast of Dada activities in Zürich with regular communications from Tristan Tzara (whose pseudonym means \"sad in country,\" a name chosen to protest the treatment of Jews in his native Romania), who exchanged letters, poems, and magazines with Guillaume Apollinaire, André Breton, Max Jacob, Clément Pansaers, and other French writers, critics and artists.\n\nParis had arguably been the classical music capital of the world since the advent of musical Impressionism in the late 19th century. One of its practitioners, Erik Satie, collaborated with Picasso and Cocteau in a mad, scandalous ballet called \"Parade\". First performed by the Ballets Russes in 1917, it succeeded in creating a scandal but in a different way than Stravinsky's \"Le Sacre du Printemps\" had done almost five years earlier. This was a ballet that was clearly parodying itself, something traditional ballet patrons would obviously have serious issues with.\n\nDada in Paris surged in 1920 when many of the originators converged there. Inspired by Tzara, Paris Dada soon issued manifestos, organized demonstrations, staged performances and produced a number of journals (the final two editions of \"Dada\", \"Le Cannibale\", and \"Littérature\" featured Dada in several editions.)\n\nThe first introduction of Dada artwork to the Parisian public was at the Salon des Indépendants in 1921. Jean Crotti exhibited works associated with Dada including a work entitled, \"Explicatif\" bearing the word \"Tabu\". In the same year Tzara staged his Dadaist play \"The Gas Heart\" to howls of derision from the audience. When it was re-staged in 1923 in a more professional production, the play provoked a theatre riot (initiated by André Breton) that heralded the split within the movement that was to produce Surrealism. Tzara's last attempt at a Dadaist drama was his \"ironic tragedy\" \"Handkerchief of Clouds\" in 1924.\n\nIn the Netherlands the Dada movement centered mainly around Theo van Doesburg, best known for establishing the De Stijl movement and magazine of the same name. Van Doesburg mainly focused on poetry, and included poems from many well-known Dada writers in \"De Stijl\" such as Hugo Ball, Hans Arp and Kurt Schwitters. Van Doesburg and (a cordwainer in Drachten) became friends of Schwitters, and together they organized the so-called \"Dutch Dada campaign\" in 1923, where Van Doesburg promoted a leaflet about Dada (entitled \"What is Dada?\"), Schwitters read his poems, Vilmos Huszàr demonstrated a mechanical dancing doll and Nelly van Doesburg (Theo's wife), played avant-garde compositions on piano.\nVan Doesburg wrote Dada poetry himself in \"De Stijl\", although under a pseudonym, I.K. Bonset, which was only revealed after his death in 1931. 'Together' with I.K. Bonset, he also published a short-lived Dutch Dada magazine called \"Mécano\" (1922–3). Another Dutchman identified by K. Schippers in his study of the movement in the Netherlands was the Groningen typographer H. N. Werkman, who was in touch with Van Doesburg and Schwitters while editing his own magazine, \"The Next Call\" (1923–6). Two more artists mentioned by Schippers were German-born and eventually settled in the Netherlands. These were Otto van Rees, who had taken part in the liminal exhibitions at the Café Voltaire in Zürich, and Paul Citroen.\n\nAlthough Dada itself was unknown in Georgia until at least 1920, from 1917 until 1921 a group of poets called themselves \"41st Degree\" (referring both to the latitude of Tbilisi, Georgia and to the temperature of a high fever) organized along Dadaist lines. The most important figure in this group was Iliazd, whose radical typographical designs visually echo the publications of the Dadaists. After his flight to Paris in 1921, he collaborated with Dadaists on publications and events.\n\nIn Yugoslavia there was heavy Dada activity between 1920 and 1922, run mainly by Dragan Aleksić and including work by Mihailo S. Petrov, Zenitist's two brothers Ljubomir Micić and Branko Ve Poljanski. Aleksić used the term \"Yougo-Dada\" and is known to have been in contact with Raoul Hausmann, Kurt Schwitters, and Tristan Tzara.\n\nThe Dada movement in Italy, based in Mantua, was met with distaste and failed to make a significant impact in the world of art. It published a magazine for a short time and held an exhibition in Rome, featuring paintings, quotations from Tristan Tzara, and original epigrams such as \"True Dada is against Dada\". The most notable member of this group was Julius Evola, who went on to become an eminent scholar of occultism, as well as a right-wing philosopher and an assistant to Benito Mussolini.\n\nA prominent Dada group in Japan was , founded in July 1923 by Tomoyoshi Murayama and . Other prominent artists were Jun Tsuji, Eisuke Yoshiyuki, Shinkichi Takahashi and Katsue Kitasono.\n\nIn the Tsuburaya Productions's \"Ultra Series\", an alien named Dada was designed after the Dadaism movement, with said character first appearing in episode 28 of the 1966 tokusatsu series, \"Ultraman\", and was designed by character artist Toru Narita. Dada's design is primarily monochromatic, and features numerous sharp lines and alternating black and white stripes, as a reference to the movement. On May 19, 2016, in celebration to the 100 year anniversary of Dadaism in Tokyo, the Ultra Monster was invited to meet the Swiss Ambassador Urs Bucher.\n\nThe Russian literary group \"Nichevoki\" came close to the Dada ideologies. Members became famous for proposing that Vladimir Mayakovsky should go to the Pushkin monument at Tverskoy Boulevard and clean the shoes of anyone who asked, after he had declared that he would \"clean up Russian poetry\".\n\nDada was not confined to the visual and literary arts; its influence reached into sound and music. Kurt Schwitters developed what he called \"sound poems\", while Francis Picabia and Georges Ribemont-Dessaignes composed Dada music performed at the Festival Dada in Paris on 26 May 1920. Other composers such as Erwin Schulhoff, Hans Heusser and Alberto Savinio all wrote \"Dada music\", while members of Les Six collaborated with members of the Dada movement and had their works performed at Dada gatherings. Erik Satie also dabbled with Dadaist ideas during his career, although he is primarily associated with musical Impressionism.\n\nIn the very first Dada publication, Hugo Ball describes a \"balalaika orchestra playing delightful folk-songs.\" African music and jazz were common at Dada gatherings.\n\nMarc Lowenthal, in \"I Am a Beautiful Monster: Poetry, Prose, and Provocation\", writes:\nDada is the groundwork to abstract art and sound poetry, a starting point for performance art, a prelude to postmodernism, an influence on pop art, a celebration of antiart to be later embraced for anarcho-political uses in the 1960s and the movement that laid the foundation for Surrealism.\n\nWhile broadly based, the movement was unstable. By 1924 in Paris, Dada was melding into surrealism, and artists had gone on to other ideas and movements, including surrealism, social realism and other forms of modernism. Some theorists argue that Dada was actually the beginning of postmodern art.\n\nBy the dawn of the Second World War, many of the European Dadaists had emigrated to the United States. Some died in death camps under Adolf Hitler, who actively persecuted the kind of \"degenerate art\" that he considered Dada to represent. The movement became less active as post-war optimism led to the development of new movements in art and literature.\n\nDada is a named influence and reference of various anti-art and political and cultural movements, including the Situationist International and culture jamming groups like the Cacophony Society. Upon breaking up in July 2012, anarchist pop band Chumbawamba issued a statement which compared their own legacy with that of the Dada art movement.\n\nAt the same time that the Zürich Dadaists were making noise and spectacle at the Cabaret Voltaire, Lenin was planning his revolutionary plans for Russia in a nearby apartment. Tom Stoppard used this coincidence as a premise for his play \"Travesties\" (1974), which includes Tzara, Lenin, and James Joyce as characters. French writer Dominique Noguez imagined Lenin as a member of the Dada group in his tongue-in-cheek \"Lénine Dada\" (1989).\n\nThe former building of the Cabaret Voltaire fell into disrepair until it was occupied from January to March 2002, by a group proclaiming themselves Neo-Dadaists, led by Mark Divo. The group included Jan Thieler, Ingo Giezendanner, Aiana Calugar, Lennie Lee, and Dan Jones. After their eviction, the space was turned into a museum dedicated to the history of Dada. The work of Lee and Jones remained on the walls of the new museum.\n\nSeveral notable retrospectives have examined the influence of Dada upon art and society. In 1967, a large Dada retrospective was held in Paris. In 2006, the Museum of Modern Art in New York City mounted a Dada exhibition in partnership with the National Gallery of Art in Washington D.C. and the Centre Pompidou in Paris. The LTM label has released a large number of Dada-related sound recordings, including interviews with artists such as Tzara, Picabia, Schwitters, Arp, and Huelsenbeck, and musical repertoire including Satie, Ribemont-Dessaignes, Picabia, and Nelly van Doesburg.\n\nThe Dadaists imitated the techniques developed during the cubist movement through the pasting of cut pieces of paper items, but extended their art to encompass items such as transportation tickets, maps, plastic wrappers, etc. to portray aspects of life, rather than representing objects viewed as still life.\n\nCut-up technique is an extension of collage to words themselves, Tristan Tzara describes this in the Dada Manifesto:\n<poem style=\"margin-left: 2em;\">\nTO MAKE A DADAIST POEM\nTake a newspaper.\nTake some scissors.\nChoose from this paper an article of the length you want to make your poem.\nCut out the article.\nNext carefully cut out each of the words that makes up this article and put them all in a bag.\nShake gently.\nNext take out each cutting one after the other.\nCopy conscientiously in the order in which they left the bag.\nThe poem will resemble you.\nAnd there you are – an infinitely original author of charming sensibility, even though unappreciated by the vulgar herd.\n</poem>\n\nThe Dadaists – the \"monteurs\" (mechanics) – used scissors and glue rather than paintbrushes and paints to express their views of modern life through images presented by the media. A variation on the collage technique, photomontage utilized actual or reproductions of real photographs printed in the press. In Cologne, Max Ernst used images from the First World War to illustrate messages of the destruction of war.\n\nThe assemblages were three-dimensional variations of the collage – the assembly of everyday objects to produce meaningful or meaningless (relative to the war) pieces of work including war objects and trash. Objects were nailed, screwed or fastened together in different fashions. Assemblages could be seen in the round or could be hung on a wall.\n\nMarcel Duchamp began to view the manufactured objects of his collection as objects of art, which he called \"readymades\". He would add signatures and titles to some, converting them into artwork that he called \"readymade aided\" or \"rectified readymades\". Duchamp wrote: \"One important characteristic was the short sentence which I occasionally inscribed on the 'readymade.' That sentence, instead of describing the object like a title, was meant to carry the mind of the spectator towards other regions more verbal. Sometimes I would add a graphic detail of presentation which in order to satisfy my craving for alliterations, would be called 'readymade aided.'\" One such example of Duchamp's readymade works is the urinal that was turned onto its back, signed \"R. Mutt\", titled \"Fountain\", and submitted to the Society of Independent Artists exhibition that year, though it was not displayed.\n\n\n\nManifestos\n"}
{"id": "8242", "url": "https://en.wikipedia.org/wiki?curid=8242", "title": "Debian", "text": "Debian\n\nDebian ( or )) is a Unix-like computer operating system that is composed entirely of free software, most of which is under the GNU General Public License and packaged by a group of individuals participating in the Debian Project.\n\nThe Debian Project was first announced in 1993 by Ian Murdock, Debian 0.01 was released on September 15, 1993, and the first \"stable\" release was made in 1996.\n\nThe Debian \"stable\" release branch is the most popular Debian edition for personal computers and network servers, and has been used as a base for many other distributions.\n\nThe project's work is carried out over the Internet by a team of volunteers guided by the Debian Project Leader and three foundational documents: the Debian Social Contract, the Debian Constitution, and the Debian Free Software Guidelines. New distributions are updated continually, and the next candidate is released after a time-based freeze.\n\nAs one of the earliest operating systems based on the Linux kernel, it was decided that Debian was to be developed openly and freely distributed in the spirit of the GNU Project. This decision drew the attention and support of the Free Software Foundation, which sponsored the project for one year from November 1994 to November 1995. Upon the ending of the sponsorship, the Debian Project formed the non-profit organisation Software in the Public Interest. \n\nWhile Debian's main port, Debian GNU/Linux, uses the Linux kernel and GNU programs, other ports exist based on BSD kernels and the GNU HURD microkernel. All use the GNU userland and the GNU C library (glibc). \n\nDebian has access to online repositories that contain over 50,000 software packages making it the largest software compilation. Debian officially contains only free software, but non-free software can be downloaded and installed from the Debian repositories. Debian includes popular free programs such as LibreOffice, Firefox web browser, Evolution mail, K3b disc burner, VLC media player, GIMP image editor, and Evince document viewer. Debian is a popular choice for web servers (cf. LAMP).\n\nDebian supports Linux officially, offered kFreeBSD for version 7 but not 8, and GNU Hurd unofficially. GNU/kFreeBSD was released as a technology preview for IA-32 and x86-64 architectures, and lacked the amount of software available in Debian's Linux distribution. Official support for kFreeBSD was removed for version 8, which did not provide a kFreeBSD-based distribution.\n\nSeveral flavors of the Linux kernel exist for each port. For example, the i386 port has flavors for IA-32 PCs supporting Physical Address Extension and real-time computing, for older PCs, and for x86-64 PCs. The Linux kernel does not officially contain firmware without sources, although such firmware is available in non-free packages and alternative installation media.\n\nDebian offers DVD and CD images for installation that can be downloaded using BitTorrent or jigdo. Physical disks can also be bought from retailers. The full sets are made up of several discs (the amd64 port consists of 13 DVDs or 84 CDs), but only the first disc is required for installation, as the installer can retrieve software not contained in the first disc image from online repositories.\n\nDebian offers different network installation methods. A minimal install of Debian is available via the \"netinst\" CD, whereby Debian is installed with just a base and later added software can be downloaded from the Internet. Another option is to boot the installer from the network.\n\nInstallation images are hybrid on some architectures and can be used to create a bootable USB drive (Live USB).\n\nThe default bootstrap loader is GNU GRUB version 2, though the package name is simply grub, while version 1 was renamed to grub-legacy. This conflicts with e.g. Fedora, where grub version 2 is named grub2.\n\nThe default desktop may be chosen from the DVD boot menu among GNOME, KDE Software Compilation, Xfce and LXDE, and from special disc 1 CDs.\n\nDebian was first announced on August 16, 1993, by Ian Murdock, who initially called the system \"the Debian Linux Release\". The word \"Debian\" was formed as a portmanteau of the first name of his then-girlfriend Debra Lynn and his own first name. Before Debian's release, the Softlanding Linux System (SLS) had been a popular Linux distribution and the basis for Slackware. The perceived poor maintenance and prevalence of bugs in SLS motivated Murdock to launch a new distribution.\n\nDebian 0.01, released on September 15, 1993, was the first of several internal releases. Version 0.90 was the first public release, providing support through mailing lists hosted at Pixar. The release included the Debian Linux Manifesto, outlining Murdock's view for the new operating system. In it he called for the creation of a distribution to be maintained openly, in the spirit of Linux and GNU.\n\nThe Debian project released the 0.9x versions in 1994 and 1995. During this time it was sponsored by the Free Software Foundation for one year. Ian Murdock delegated the base system, the core packages of Debian, to Bruce Perens and Murdock focused on the management of the growing project. The first ports to non-IA-32 architectures began in 1995, and Debian 1.1 was released in 1996. By that time and thanks to Ian Jackson, the dpkg package manager was already an essential part of Debian.\n\nIn 1996, Bruce Perens assumed the project leadership. Perens was a controversial leader, regarded as authoritarian and strongly attached to Debian. He drafted a social contract and edited suggestions from a month-long discussion into the Debian Social Contract and the Debian Free Software Guidelines. After the FSF withdrew their sponsorship in the midst of the free software vs. open source debate, Perens initiated the creation of the legal umbrella organization Software in the Public Interest instead of seeking renewed involvement with the FSF. He led the conversion of the project from a.out to ELF. He created the BusyBox program to make it possible to run a Debian installer on a single floppy, and wrote a new installer. By the time Debian 1.2 was released, the project had grown to nearly two hundred volunteers. Perens left the project in 1998.\n\nIan Jackson became the leader in 1998. Debian 2.0 introduced the second official port, m68k. During this time the first port to a non-Linux kernel, Debian GNU/Hurd, was started. On December 2, the first Debian Constitution was ratified.\n\nFrom 1999, the project leader was elected yearly. The Advanced Packaging Tool was deployed with Debian 2.1. The amount of applicants was overwhelming and the project established the new member process. The first Debian derivatives, namely Libranet, Corel Linux and Stormix's Storm Linux, were started in 1999. The 2.2 release in 2000 was dedicated to Joel Klecker, a developer who died of Duchenne muscular dystrophy.\n\nIn late 2000, the project reorganized the archive with new package \"pools\" and created the \"Testing\" distribution, made up of packages considered stable, to reduce the freeze for the next release. In the same year, developers began holding an annual conference called DebConf with talks and workshops for developers and technical users. In May 2001, Hewlett-Packard announced plans to base its Linux development on Debian.\n\nIn July 2002, the project released version 3.0, code-named Woody, the first release to include cryptographic software, a free licensed KDE and internationalization. During these last release cycles, the Debian project drew considerable criticism from the free software community because of the long time between stable releases.\n\nSome events disturbed the project while working on Sarge, as Debian servers were attacked by fire and hackers. One of the most memorable was the Vancouver prospectus. After a meeting held in Vancouver, release manager Steve Langasek announced a plan to reduce the number of supported ports to four in order to shorten future release cycles. There was a large reaction because the proposal looked more like a decision and because such a drop would damage Debian's aim to be \"the universal operating system\".\n\nThe 3.1 Sarge release was made in June 2005. This release updated 73% of the software and included over 9,000 new packages. A new installer with a modular design, Debian-Installer, allowed installations with RAID, XFS and LVM support, improved hardware detection, made installations easier for novice users, and was translated into almost forty languages. An installation manual and release notes were in ten and fifteen languages respectively. The efforts of Skolelinux, Debian-Med and Debian-Accessibility raised the number of packages that were educational, had a medical affiliation, and ones made for people with disabilities.\nIn 2006, as a result of a much-publicized dispute, Mozilla software was rebranded in Debian, with Firefox forked as Iceweasel and Thunderbird as Icedove. The Mozilla Corporation stated that software with unapproved modifications could not be distributed under the Firefox trademark. Two reasons that Debian modifies the Firefox software are to change the non-free artwork and to provide security patches. In February 2016, it was announced that Mozilla and Debian had reached agreement and Iceweasel would revert to the name Firefox; similar agreement was anticipated for Icedove/Thunderbird.\n\nA fund-raising experiment, Dunc-Tank, was created to solve the release cycle problem and release managers were paid to work full-time; in response, unpaid developers slowed down their work and the release was delayed. Debian 4.0 (Etch) was released in April 2007, featuring the x86-64 port and a graphical installer. Debian 5.0 (Lenny) was released in February 2009, supporting Marvell's Orion platform and netbooks such as the Asus Eee PC. The release was dedicated to Thiemo Seufer, a developer who died in a car crash.\n\nIn July 2009, the policy of time-based development freezes on a two-year cycle was announced. Time-based freezes are intended to blend the predictability of time based releases with Debian's policy of feature based releases, and to reduce overall freeze time. The Squeeze cycle was going to be especially short; however, this initial schedule was abandoned. In September 2010, the backports service became official, providing more recent versions of some software for the stable release.\n\nDebian 6.0 (Squeeze) was released in February 2011, introduced Debian GNU/kFreeBSD as a technology preview, featured a dependency-based boot system, and moved problematic firmware to the non-free area. Debian 7.0 (Wheezy) was released in May 2013, featuring multiarch support and Debian 8.0 (Jessie) was released in April 2015, using systemd as the new init system. Debian 9.0 (Stretch) was released in June 2017. , Debian is still in development and new packages are uploaded to \"unstable\" every day.\n\nThroughout Debian's lifetime, both the Debian distribution and its website have won various awards from different organizations, including \"Server Distribution of the Year\" 2011, \"The best Linux distro of 2011\", and a \"Best of the Net\" award for October 1998.\n\nOn December 2, 2015, Microsoft announced that they would offer Debian GNU/Linux as an endorsed distribution on the Azure cloud platform.\n\nDebian offers CD images specifically built for GNOME (the default desktop), KDE Software Compilation, Xfce and LXDE. MATE is officially supported, while Cinnamon support was added with Debian 8.0 Jessie. Less common window managers such as Enlightenment, Openbox, Fluxbox, IceWM, Window Maker and others are available.\n\nThe default desktop environment of version 7.0 Wheezy was temporarily switched to Xfce, because GNOME 3 did not fit on the first CD of the set. The default for the version 8.0 Jessie was changed again to Xfce in November 2013, and back to GNOME in September 2014.\n\nDebian releases live install images for CDs, DVDs and USB thumb drives, for IA-32 and x86-64 architectures, and with a choice of desktop environments. These \"Debian Live\" images allow users to boot from removable media and run Debian without affecting the contents of their computer.\n\nA full install of Debian to the computer's hard drive can be initiated from the live image environment.\n\nPersonalized images can be built with the live-build tool for discs, USB drives and for network booting purposes.\n\nPackage management operations can be performed with different tools available on Debian, from the lowest level command to graphical front-ends like Synaptic. The recommended standard for administering packages on a Debian system is the toolset.\n\ndpkg provides the low-level infrastructure for package management. The dpkg database contains the list of installed software on the current system. The dpkg command tool does not know about repositories. The command can work with local .deb package files, and information from the dpkg database.\n\nAn Advanced Packaging Tool (APT) tool allows administering an installed Debian system to retrieve and resolve package dependencies from repositories. APT tools share dependency information and cached packages.\n\n\nGDebi is an APT tool which can be used in command-line and on the GUI. GDebi can install a local .deb file via the command line like the dpkg command, but with access to repositories to resolve dependencies. Other graphical front-ends for APT include Software Center, Synaptic and Apper.\n\nGNOME Software is a graphical front-end for PackageKit, which itself can work on top of various software packaging systems.\n\nThree branches of Debian (also called , or ) are regularly maintained:\n\n\nOther branches in Debian:\n\n\nThe archive provides older versions of the branches. They may be used to install a specific older version of some software.\n\n\"Stable\" and \"oldstable\" get minor updates, called ; , the \"stable\" release is version 9.0, and the \"oldstable\" release is version 8.8.\n\nThe numbering scheme for the point releases up to Debian 4.0 was to include the letter \"r\" (for \"revision\") after the main version number and then the number of the point release; for example, the latest point release of version 4.0 is 4.0r9. This scheme was chosen because a new dotted version would make the old one look obsolete and vendors would have trouble selling their CDs.\n\nFrom Debian 5.0, the numbering scheme of point releases was changed, conforming to the GNU version numbering standard; the first point release of Debian 5.0 was 5.0.1 instead of 5.0r1. The numbering scheme was once again changed for the first Debian 7 update, which was version 7.1. The \"r\" scheme is no longer in use, but point release announcements include a note about not throwing away old CDs.\n\nThe code names of Debian releases are names of characters from the \"Toy Story\" films. Debian 9 was named after the toy rubber octopus in \"Toy Story 3\". Debian 8 was named Jessie, after the cowgirl in \"Toy Story 2\" and \"Toy Story 3\". The \"Testing\" branch is currently named Buster, which is the real (not the toy) dog seen in \"Toy Story 2\" and \"3\". Debian 11 will be called \"Bullseye\". The \"unstable\" trunk is permanently nicknamed Sid, after the emotionally unstable boy next door who regularly destroyed toys.\n\nThis naming tradition came about because Bruce Perens was involved in the early development of Debian while working at Pixar.\n\nDebian Pure Blends are subsets of a Debian release configured out-of-the-box for users with particular skills and interests. For example, Debian Jr. is made for children, while Debian Science is for researchers and scientists. The complete Debian distribution includes all available Debian Pure Blends. \"Debian Blend\" (without \"Pure\") is a term for a Debian-based distribution that strives to become part of mainstream Debian, and have its extra features included in future releases.\n\nThe Debian \"swirl\" logo was designed by Raul Silva in 1999 as part of a contest to replace the semi-official logo that had been used. The winner of the contest received an @debian.org email address, and a set of Debian 2.1 install CDs for the architecture of their choice. There has been no official statement from the Debian project on the logo's meaning, but at the time of the logo's selection, it was suggested that the logo represented the magic smoke that made computers work.\n\nOne theory about the origin of the Debian logo is that Buzz Lightyear, the chosen character for the first named Debian release, has a swirl in his chin. Stefano Zacchiroli also suggested that this swirl is the Debian one.\n\nThe Debian Free Software Guidelines (DFSG) define the distinctive meaning of the word \"free\" as in \"free and open-source software\". Packages which comply with these guidelines, usually under the GNU General Public License, Modified BSD License or Artistic License, are included inside the area; otherwise, they are included inside the and areas. These last two areas are not distributed within the official installation media, but they can be adopted manually.\n\nNon-free includes packages which do not comply with the DFSG, such as documentation with invariant sections and proprietary software, and legally questionable packages. Contrib includes packages which do comply with the DFSG but fail other requirements. For example, they may depend on packages which are in non-free or requires such for building them.\n\nRichard Stallman and the Free Software Foundation have criticized the Debian project for hosting the non-free repository and because the contrib and non-free areas are easily accessible, an opinion echoed by some in Debian including the former project leader Wichert Akkerman. The internal dissent in the Debian project regarding the non-free section has persisted, but the last time it came to a vote in 2004, the majority decided to keep it.\n\nMultimedia support has been problematic in Debian regarding codecs threatened by possible patent infringements, without sources or under too restrictive licenses, and regarding technologies such as Adobe Flash. Even though packages with problems related to their distribution could go into the non-free area, software such as libdvdcss is not hosted at Debian.\n\nA notable third party repository exists, formerly named debian-multimedia.org, providing software not present in Debian such as Windows codecs, libdvdcss and the Adobe Flash Player. Even though this repository is maintained by Christian Marillat, a Debian developer, it is not part of the project and is not hosted on a Debian server. The repository provides packages already included in Debian, interfering with the official maintenance. Eventually, project leader Stefano Zacchiroli asked Marillat to either settle an agreement about the packaging or to stop using the \"Debian\" name. Marillat chose the latter and renamed the repository to deb-multimedia.org. The repository was so popular that the switchover was announced by the official blog of the Debian project.\n\nHardware requirements are at least those of the kernel and the GNU toolsets. Debian's recommended system requirements depend on the level of installation, which corresponds to increased numbers of installed components:\n\nThe real minimum memory requirements depend on the architecture and may be much less than the numbers listed in this table. It is possible to install Debian with 60 MB of RAM for x86-64; the installer will run in low memory mode and it is recommended to create a swap partition. The installer for z/Architecture requires about 20 MB of RAM, but relies on network hardware. Similarly, disk space requirements, which depend on the packages to be installed, can be reduced by manually selecting the packages needed. , no Pure Blend exists that would lower the hardware requirements easily.\n\nIt is possible to run graphical user interfaces on older or low-end systems, but the installation of window managers instead of desktop environments is recommended, as desktop environments are more resource-intensive. Requirements for individual software vary widely and must be considered, with those of the base operating environment.\n\n, the official ports are:\n\n\nUnofficial ports are available as part of the \"unstable\" distribution:\n\n\nDebian supports a variety of ARM-based NAS devices. The NSLU2 was supported by the installer in Debian 4.0 and 5.0, and Martin Michlmayr is providing installation tarballs since version 6.0. Other supported NAS devices are the Buffalo Kurobox Pro, GLAN Tank, Thecus N2100 and QNAP Turbo Stations.\n\nDevices based on the Kirkwood system on a chip (SoC) are supported too, such as the SheevaPlug plug computer and OpenRD products. There are efforts to run Debian on mobile devices, but this is not a project goal yet since the Debian Linux kernel maintainers would not apply the needed patches. Nevertheless, there are packages for resource-limited systems.\n\nThere are efforts to support Debian on wireless access points. Debian is known to run on set-top boxes. Work is ongoing to support the AM335x processor, which is used in electronic point of service solutions. Debian may be customized to run on cash machines.\n\nBeagleBoard, a low-power open-source hardware single-board computer (made by Texas Instruments) has switched to Debian Linux preloaded on its Beaglebone Black board's flash.\n\nSeveral parts of Debian are translated into languages other than American English, including package descriptions, configuration messages, documentation and the website. The level of software localization depends on the language, ranging from the highly supported German and French to the hardly translated Creek and Samoan. The installer is available in 73 languages.\n\nDebian provides packages made for virtual communities. The Facebook and Twitter application interfaces are available to programmers; the Pidgin messaging client used a custom plugin for Facebook until the networking site added support for XMPP. Debian 5.0 Lenny was the last release supporting Tencent QQ. Communication with Skype is possible using software in the contrib area.\n\nDebian is known for its manifesto, social contract, and policies. Debian's policies and team efforts focus on collaborative software development and testing processes. As a result of its policies, a new major release tends to occur every two years with revision releases that fix security issues and important problems.\n\nThe Debian project is a volunteer organization with three foundational documents:\n\n\nDebian developers are organized in a web of trust. There are about one thousand active Debian developers, but it is possible to contribute to the project without being an official developer.\n\nThe project maintains official mailing lists and conferences for communication and coordination between developers. For issues with single packages and other tasks, a public bug tracking system is used by developers and end users. Internet Relay Chat channels (primarily on the Open and Free Technology Community (OFTC) and freenode networks) are also used for communication among developers and to provide real time help.\n\nDebian is supported by donations made to organizations authorized by the leader. The largest supporter is Software in the Public Interest, the owner of the Debian trademark, manager of the monetary donations and umbrella organization for various other community free software projects.\n\nA Project Leader is elected once per year by the developers. The leader has special powers, but they are not absolute, and appoints delegates to perform specialized tasks. Delegates make decisions as they think is best, taking into account technical criteria and consensus. By way of a General Resolution, the developers may recall the leader, reverse a decision made by the leader or a delegate, amend foundational documents and make other binding decisions. The voting method is based on the Schulze method (Cloneproof Schwartz Sequential Dropping).\n\nProject leadership is distributed occasionally. Branden Robinson was helped by the Project Scud, a team of developers that assisted the leader, but there were concerns that such leadership would split Debian into two developer classes. Anthony Towns created a supplemental position, Second In Charge (2IC), that shared some powers of the leader. Steve McIntyre was 2IC and had a 2IC himself.\n\nOne important role in Debian's leadership is that of a release manager. The release team sets goals for the next release, supervises the processes and decides when to release. The team is led by the next release managers and stable release managers. Release assistants were introduced in 2003.\n\nThe Debian project has an influx of applicants wishing to become developers. These applicants must undergo a vetting process which establishes their identity, motivation, understanding of the project's principles, and technical competence. This process has become much harder throughout the years.\n\nDebian developers join the project for many reasons. Some that have been cited include:\n\n\nDebian developers may resign their positions at any time or, when deemed necessary, they can be expelled. Those who follow the retiring protocol are granted the \"emeritus\" status and they may regain their membership through a shortened new member process.\n\nEach software package has a that may be either one person or a team of Debian developers and non-developer maintainers. The maintainer keeps track of upstream releases, and ensures that the package coheres with the rest of the distribution and meets the standards of quality of Debian. Packages may include modifications introduced by Debian to achieve compliance with Debian Policy, even to fix non-Debian specific bugs, although coordination with upstream developers is advised.\n\nThe maintainer releases a new version by uploading the package to the \"incoming\" system, which verifies the integrity of the packages and their digital signatures. If the package is found to be valid, it is installed in the package archive into an area called the \"pool\" and distributed every day to hundreds of mirrors worldwide. The upload must be signed using OpenPGP-compatible software. All Debian developers have individual cryptographic key pairs. Developers are responsible for any package they upload even if the packaging was prepared by another contributor.\n\nInitially, an accepted package is only available in the \"unstable\" branch. For a package to become a candidate for the next release, it must migrate to the \"Testing\" branch by meeting the following:\n\n\nThus, a release-critical bug in a new version of a shared library on which many packages depend may prevent those packages from entering \"Testing\", because the updated library must meet the requirements too. From the branch viewpoint, the migration process happens twice per day, rendering \"Testing\" in perpetual beta.\n\nPeriodically, the release team publishes guidelines to the developers in order to ready the release. A new release occurs after a freeze, when all important software is reasonably up-to-date in the \"Testing\" branch and any other significant issues are solved. At that time, all packages in the \"testing\" branch become the new \"stable\" branch. Although freeze dates are time-based, release dates are not, which are announced by the release managers a couple of weeks beforehand.\n\nA version of a package can belong to more than one branch, usually \"testing\" and \"unstable\". It is possible for a package to keep the same version between stable releases and be part of \"oldstable\", \"stable\", \"testing\" and \"unstable\" at the same time. Each branch can be seen as a collection of pointers into the package \"pool\" mentioned above.\n\nThe Debian project handles security through public disclosure rather than through obscurity. Debian security advisories are compatible with the Common Vulnerabilities and Exposures dictionary, are usually coordinated with other free software vendors and are published the same day a vulnerability is made public. There used to be a security audit project that focused on packages in the stable release looking for security bugs; Steve Kemp, who started the project, retired in 2011 but resumed his activities and applied to rejoin in 2014.\n\nThe \"stable\" branch is supported by the Debian security team; \"oldstable\" is supported for one year. Although Squeeze is not officially supported, Debian is coordinating an effort to provide long-term support (LTS) until February 2016, five years after the initial release, but only for the IA-32 and x86-64 platforms. \"Testing\" is supported by the \"testing\" security team, but does not receive updates in as timely a manner as \"stable\". \"Unstable\"s security is left for the package maintainers.\n\nThe Debian project offers documentation and tools to harden a Debian installation both manually and automatically. Security-Enhanced Linux and AppArmor support is available but disabled by default. Debian provides an optional hardening wrapper, and does not harden all of its software by default using gcc features such as PIE and buffer overflow protection, unlike operating systems such as OpenBSD, but tries to build as many packages as possible with hardening flags.\n\nIn May 2008, it was revealed that a Debian developer discovered that the OpenSSL package distributed with Debian and derivatives such as Ubuntu, made a variety of security keys vulnerable to a random number generator attack, since only 32,767 different keys were generated. The security weakness was caused by changes made in 2006 by another Debian developer in response to memory debugger warnings. The complete resolution procedure was cumbersome because patching the security hole was not enough; it involved regenerating all affected keys and certificates.\n\nThe cost of developing all of the packages included in Debian 5.0 Lenny (323 million lines of code) has been estimated to be about , using one method based on the COCOMO model. , Black Duck Open Hub estimates that the current codebase (74 million lines of code) would cost about to develop, using a different method based on the same model.\n\nDebian is one of the most popular Linux distributions, and many other distributions have been created from the Debian codebase, including Ubuntu and Knoppix. , DistroWatch lists 126 active Debian derivatives. The Debian project provides its derivatives with guidelines for best practices and encourages derivatives to merge their work back into Debian.\n\n\n\n\n"}
{"id": "8243", "url": "https://en.wikipedia.org/wiki?curid=8243", "title": "Doonesbury", "text": "Doonesbury\n\nDoonesbury is a comic strip by American cartoonist Garry Trudeau that chronicles the adventures and lives of an array of characters of various ages, professions, and backgrounds, from the President of the United States to the title character, Michael Doonesbury, who has progressed from a college student to a youthful senior citizen over the decades.\n\nCreated in \"the throes of '60s and '70s counterculture,\" and frequently political in nature, \"Doonesbury\" features characters representing a range of affiliations, but the cartoon is noted for a liberal viewpoint. The name \"Doonesbury\" is a combination of the word \"doone\" (prep school slang for someone who is clueless, inattentive, or careless) and the surname of Charles Pillsbury, Trudeau's roommate at Yale University.\n\n\"Doonesbury\" is written and pencilled by Garry Trudeau, then inked and lettered by an assistant: Don Carlton\nthen Todd Pound. Sunday strips are colored in by George Corsillo. A daily strip through most of its existence, since February 2014 \"Doonesbury\" has run repeat strips Monday through Saturday, and new strips on Sunday.\n\n\"Doonesbury\" began as a continuation of \"Bull Tales\", which appeared in the Yale University student newspaper, the \"Yale Daily News\", from 1968 to 1970. It focused on local campus events at Yale.\n\n\"Doonesbury\" proper debuted as a daily strip in twenty-eight newspapers on October 26, 1970 (it being the first strip from Universal Press Syndicate). A Sunday strip began on March 21, 1971. Many of the early strips were reprints of the \"Bull Tales\" cartoons, with some changes to the drawings and plots. BD's helmet changed from having a \"Y\" (for Yale) to a star (for the fictional Walden College). Mike and BD started \"Doonesbury\" as roommates; they were not roommates in \"Bull Tales\".\n\n\"Doonesbury\" became known for its social and political commentary. As of the mid-2010s, it is currently syndicated in approximately 1,400 newspapers worldwide.\n\nIn May 1975, \"Doonesbury\" became the first daily comic strip to win a Pulitzer Prize, taking the award for Editorial Cartooning. That year, US President Gerald Ford told the Radio and Television Correspondents' Association at their annual dinner, \"There are only three major vehicles to keep us informed as to what is going on in Washington: the electronic media, the print media, and \"Doonesbury\", not necessarily in that order.\"\n\nIn 1977, Trudeau wrote a script for a 26-minute animated special, \"A Doonesbury Special\", which was produced and directed by Trudeau along with John Hubley (who died during the storyboarding stage) and Faith Hubley. The special was first broadcast by NBC on November 27, 1977. It won a Special Jury Award at the Cannes International Film Festival for best short film, and received an Academy Award nomination (for best animated short film), both in 1978. Voice actors for the special included Barbara Harris, William Sloane Coffin, Jr., Jack Gilford and Will Jordan. Also included were two songs \"sung\" by the character Jimmy Thudpucker (actually actor/singer/songwriter/producer James Allen \"Jimmy\" Brewer), entitled \"Stop in the Middle\" and \"I Do Believe\", also part of the \"Special\". While the compositions and performances were credited to \"Jimmy Thudpucker\", they were in fact co-written and sung by Brewer, who also co-wrote and provided the vocals for \"Ginny's Song\", a 1976 single on the Warner Bros. Label, and \"Jimmy Thudpucker's Greatest Hits\", an LP released by Windsong Records, John Denver's subsidiary of RCA Records.\n\nTrudeau took a 22-month hiatus, from January 1983 to October 1984. Before the break in the strip, the characters were eternal college students, living in a commune together near Walden College, which was modeled after Trudeau's alma mater, Yale. During the break, Trudeau helped create a Broadway musical of the strip, showing the graduation of the main characters. The Broadway adaptation opened at the Biltmore Theatre on November 21, 1983, and played 104 performances. Elizabeth Swados composed the music for Trudeau's book and lyrics.\n\nThe strip resumed some time after the events in the musical, with further changes having taken place after the end of the musical's plot. While Mike, Mark, Zonker, B.D., and Boopsie were all now graduates, B.D. and Boopsie were living in Malibu, California, where B.D. was a third-string quarterback for the Los Angeles Rams, and Boopsie was making a living from walk-on and cameo roles. Mark was living in Washington, DC, working for National Public Radio. Michael and J.J. had gotten married, and Mike had dropped out of business school to start work in an advertising agency in New York City. Zonker, still not ready for the \"real world\", was living with Mike and J.J. until he was accepted as a medical student at his Uncle Duke's \"Baby Doc College\" in Haiti.\n\nPrior to the hiatus, the strip's characters had aged at the tectonically slow rate standard for comic strips. But when Trudeau returned to \"Doonesbury,\" the characters began to age in something close to real time, as in \"Gasoline Alley\" and \"For Better or for Worse.\" Since then, the main characters' ages and career developments have tracked that of standard media portrayals of baby boomers, with jobs in advertising, law enforcement, and the dot-com boom. Current events are mirrored through the original characters, their offspring (the \"second generation\"), and occasional new characters.\n\nGarry Trudeau received the National Cartoonist Society Newspaper Comic Strip Award for 1994, and their Reuben Award for 1995 for his work on the strip.\n\n\"Doonesbury\"&apos;s syndicate, Universal Uclick, announced on May 29, 2013, that the comic strip would go on hiatus from June 10 to Labor Day of that year while Garry Trudeau worked on his streaming video comedy \"Alpha House\", which was picked up by Amazon Studios. \"Doonesbury Flashbacks\" were offered during those weeks, but due to the unusually long hiatus, some newspapers opted to run different comic strips instead. Sunday strips returned as scheduled, but the daily strip's hiatus was extended until November 2013.\nAfter \"Alpha House\" was retained for a second series in February 2014, Trudeau announced that he would now produce only Sunday strips for the foreseeable future. From March 3, 2014, the strip offers reruns starting from the very beginning of its history as opposed to the recent ones that re-run when Trudeau is on vacation.\n\nThough \"Alpha House\" was cancelled following its second season and has not been in production since 2014, Trudeau has not returned to creating new daily \"Doonesbury\" strips.\n\nWith the exception of Walden College, Trudeau has frequently used real-life settings, based on real scenarios, but with fictional results. Due to deadlines, some real-world events have rendered some of Trudeau's comics unusable, such as a 1973 series featuring John Ehrlichman, a 1989 series set in Tiananmen Square in Beijing, China, a 1993 series involving Zoë Baird, and a 2005 series involving Harriet Miers. Trudeau has also displayed fluency in various forms of jargon, including those of real estate agents, flight attendants, computer scientists, journalists, presidential aides, and soldiers in Iraq.\n\nThe unnamed college attended by the main characters was later given the name \"Walden College\", revealed to be in Connecticut (the same state as Yale), and depicted as devolving into a third-rate institution under the weight of grade inflation, slipping academic standards, and the end of tenure, issues that Trudeau has consistently revisited since the original characters graduated. Some of the second generation of \"Doonesbury\" characters have attended Walden, a venue Trudeau uses to advance his concerns about academic standards in America.\n\nPresident King, the leader of Walden College, was originally intended as a parody of Kingman Brewster, President of Yale, but all that remains of that is a certain physical resemblance.\n\nEven though \"Doonesbury\" frequently features real-life U.S. politicians, they are rarely depicted with their real faces. Originally, strips featuring the President of the United States would show an external view of the White House, with dialogue emerging from inside. During the Gerald Ford administration, characters would be shown speaking to Ford at press conferences, and fictional dialogue supposedly spoken by Ford would be written as coming \"off-panel\". Similarly, while having several characters as students in a class taught by Henry Kissinger, the dialogue made up for Kissinger would also come from \"off-panel\" (although Kissinger had earlier appeared as a character with his face shown in a 1972 series of strips in which he met Mark Slackmeyer while the latter was on a trip to Washington). Sometimes hands, or in rare cases, the back of heads would also be seen.\n\nLater, personal symbols reflecting some aspect of their character came into use. For example, during the 1980s, character Ron Headrest served as a doppelgänger for Ronald Reagan and was depicted as a computer-generated artificial-intelligence, an image based on the television character \"Max Headroom\". Members of the Bush family have been depicted as invisible. During his term as Vice President, George H. W. Bush was first depicted as completely invisible, his words emanating from a little \"voice box\" in the air. (In one strip, published March 20, 1988, the vice president almost materialized, but only made it to an outline before reverting to invisibility.)\n\nGeorge W. Bush was symbolized by a Stetson hat atop the same invisible point, because he was Governor of Texas prior to his presidency (Trudeau accused him of being \"all hat and no cattle\", reiterating the characterization of Bush by columnist Molly Ivins). The point became a giant asterisk (a la Roger Maris) following the 2000 presidential elections and the controversy over vote-counting. Later, President Bush's hat was changed to a Roman military helmet (again, atop an asterisk) representing imperialism. Towards the end of his first term, the helmet became battered, with the gilt work starting to come off and with clumps of bristles missing from the top. By late 2008, the helmet had been dented almost beyond recognition. No symbol for Barack Obama has appeared in the strip; the May 30, 2009, strip had Obama and an aide wondering what the reason for this might be (off panel).\n\nOther symbols include a waffle for Bill Clinton (chosen by popular vote—the other possibility had been a flipping coin), an unexploded (but sometimes lit) bomb for Newt Gingrich, a feather for Dan Quayle, and a giant groping hand for Arnold Schwarzenegger (who is addressed by other characters as \"Herr Gröpenfuhrer\", a reference to accusations of sexual assault against Schwarzenegger). Many less well-known politicians have also been represented as icons over the years, like a swastika for David Duke, but only for the purposes of a gag strip or two. Trudeau has made his use of icons something of an in joke to readers, where the first appearance of a new one is often a punchline in itself.\n\nThe long career of the series and continual use of real-life political figures, analysts note, have led to some uncanny cases of the cartoon foreshadowing a national shift in the politicians’ political fortunes. Tina Gianoulis in \"St. James Encyclopedia of Popular Culture\" observes that \"In 1971, well before the conservative Reagan years, a forward-looking BD called Ronald Reagan his 'hero.' In 1984, almost ten years before Congressman Newt Gingrich became Speaker of the House, another character worried that he would 'wake up someday in a country run by Newt Gingrich.'\" In its 2003 series \"John Kerry: A Candidate in the Making\" on the 2004 presidential race, the \"Boston Globe\" reprinted and discussed 1971 \"Doonesbury\" cartoons of the young Kerry's Vietnam War protest speeches.\n\n\"Doonesbury\" has a large group of recurring characters, with 24 currently listed at the strip's website. There, it notes that \"readers new to \"Doonesbury\" sometimes experience a temporary bout of character shock,\" as the sheer number of characters (and the historical connections among them) can be overwhelming.\n\nThe main characters are a group who attended the fictional Walden College during the strip's first 12 years, and moved into a commune together in April 1972. Most of the other characters first appeared as family members, friends, or other acquaintances. The original Walden Commune residents were Mike Doonesbury, Zonker Harris, Mark Slackmeyer, Nicole, Bernie, and DiDi. In September 1972, Joanie Caucus joined the comic, meeting Mike and Mark in Colorado and eventually moving into the commune. They were later joined by B.D. and his girlfriend (later wife) Boopsie, upon B.D.'s return from Vietnam. Nicole, DiDi, and Bernie were mostly phased out in subsequent years, and Zonker's Uncle Duke was introduced as the most prominent character outside the Walden group, and the main link to many secondary characters.\n\nThe Walden students graduated in 1983, after which the strip began to progress in something closer to real time. Their spouses and developing families became more important after this: Joanie's daughter J.J. Caucus married Mike and they had a daughter, Alex Doonesbury. They divorced, Mike remarried Kim Rosenthal, a Vietnamese refugee (who had appeared in the strip as a baby adopted by a Jewish family just after the fall of Saigon, see Operation Babylift), and J.J. married Zeke Brenner, her former boyfriend and Uncle Duke's former groundskeeper. Joanie married Rick Redfern, and they had a son, Jeff. Uncle Duke and Roland Hedley have also appeared often, frequently in more topical settings unconnected to the main characters. In more recent years the second generation has taken prominence as they have grown to college age: Jeff Redfern, Alex Doonesbury, Zonker's nephew Zipper Harris, and Uncle Duke's son Earl.\n\n\"Doonesbury\" has delved into a number of political and social issues, causing controversies and breaking new ground on the comics pages. Among the controversies:\n\n\nCharles M. Schulz of Peanuts called Trudeau \"unprofessional\" for taking a long sabbatical. (See also, similar comments by Schulz about sabbaticals taken by Bill Watterson.) Nor was the return of the strip itself greeted with universal acclaim; in 1985, \"Saturday Review\" listed Trudeau as one of the country's \"Most Overrated People in American Arts and Letters,\" commenting that the \"most publicized return since MacArthur's has produced a strip that is predictable, mean-spirited, and not as funny as before.\"\n\n\"Doonesbury\" has angered, irritated, or been rebuked by many of the political figures that have appeared or been referred to in the strip over the years. A 1984 series of strips showing then Vice President George H.W. Bush placing his manhood in a blind trust—in parody of Bush's use of that financial instrument to fend off concerns that his governmental decisions would be influenced by his investment holdings—brought the politician to complain, \"\"Doonesbury\"&apos;s carrying water for the opposition. Trudeau is coming out of deep left field.\"\n\n\n\n\n"}
{"id": "8244", "url": "https://en.wikipedia.org/wiki?curid=8244", "title": "Dice", "text": "Dice\n\nDice (singular die or dice; from Old French \"dé\"; from Latin \"datum\" \"something which is given or played\") are small throwable objects with multiple resting positions, used for generating random numbers. Dice are suitable as gambling devices for games like craps and are also used in non-gambling tabletop games.\n\nA traditional die is a cube, with each of its six faces showing a different number of dots (pips) from 1 to 6. When thrown or rolled, the die comes to rest showing on its upper surface a random integer from one to six, each value being equally likely. A variety of similar devices are also described as dice; such specialized dice may have polyhedral or irregular shapes and may have faces marked with symbols instead of numbers. They may be used to produce results other than one through six. Loaded and crooked dice are designed to favor some results over others for purposes of cheating or amusement.\n\nA dice tray, a tray used to contain thrown dice, is sometimes used for gambling or board games, in particular to allow dice throws which do not interfere with other game pieces.\n\nDice have been used since before recorded history, and it is uncertain where they originated. The oldest known dice were excavated as part of a backgammon-like game set at the Burnt City, an archeological site in south-eastern Iran, estimated to be from between 2800–2500 BCE. Other excavations from ancient tombs in the Indus Valley civilization indicate a South Asian origin.\n\nThe Egyptian game of Senet was played with dice. Senet was played before 3000 BC and up to the 2nd century AD. It was likely a racing game, but there is no scholarly consensus on the rules of Senet. Dicing is mentioned as an Indian game in the \"Rigveda\", \"Atharvaveda\" and the early Buddhist games list. There are several biblical references to \"casting lots\", as in Psalm 22, indicating that dicing (or a related activity) was commonplace when the psalm was composed. It is theorized that dice developed from the practice of fortunetelling with the talus of hoofed animals, colloquially known as \"knucklebones\", but knucklebones is not the oldest divination technique that incorporates randomness. Knucklebones was a game of skill played by women and children; a derivative form had the four sides of the bone receive different values and count as modern dice.\nAlthough gambling was illegal, many Romans were passionate gamblers who enjoyed dicing, which was known as \"aleam ludere\" (\"to play at dice\"). Dicing was even a popular pastime of emperors. Letters by Augustus to Tacitus and his daughter recount his hobby of dicing. There were two sizes of Roman dice. \"Tali\" were large dice inscribed with one, three, four, and six on four sides. \"Tesserae\" were smaller dice with sides numbered from one to six. Twenty-sided dice date back to the 2nd century AD and from Ptolemaic Egypt as early as the 2nd century BC.\n\nDominoes and playing cards originated in China as developments from dice. The transition from dice to playing cards occurred in China around the Tang dynasty, and coincides with the technological transition from rolls of manuscripts to block printed books. In Japan, dice were used to play a popular game called sugoroku. There are two types of sugoroku. \"Ban-sugoroku\" is similar to backgammon and dates to the Heian period, while \"e-sugoroku\" is a racing game.\n\nDice are thrown onto a flat surface either from the hand or from a container designed for this (such as a dice cup). The face of the die that is uppermost when it comes to rest provides the value of the throw. One typical dice game today is craps, where two dice are thrown simultaneously and wagers are made on the total value of the two dice. Dice are frequently used to randomize moves in board games, usually by deciding the distance through which a piece will move along the board; examples of this are backgammon and \"Monopoly\".\n\nThe result of a die roll is determined by the way it is thrown, according to the laws of classical mechanics. A die roll is made random by uncertainty in minor factors such as tiny movements in the thrower's hand; They are thus a crude form of hardware random number generator. Perhaps to mitigate against concerns that the pips on the faces of certain styles of dice cause a small bias, casinos use precision dice with flush markings.\n\nCommon dice are small cubes most commonly across, whose faces are numbered from one to six, usually by patterns of round dots called pips. (While the use of Hindu-Arabic numerals is occasionally seen, such dice are less common.)\n\nOpposite sides of a modern die traditionally add up to seven, implying that the 1, 2 and 3 faces share a vertex. The faces of a die may be placed clockwise or counterclockwise about this vertex. If the 1, 2 and 3 faces run counterclockwise, the die is called \"right-handed\", and if those faces run clockwise, the die is called \"left-handed\". Western dice are normally right-handed, and Chinese dice are normally left-handed.\n\nThe pips on dice are arranged in specific patterns as shown. Asian style dice bear similar patterns to Western ones, but the pips are closer to the center of the face; in addition, the pips are differently sized on Asian style dice, and the pips are colored red on the 1 and 4 sides. One possible explanation is that red fours are of Indian origin. In some older sets, the \"one\" pip is a colorless depression.\n\nNon-precision dice are manufactured via the plastic injection molding process. The pips or numbers on the die are a part of the mold. The coloring for numbering is achieved by submerging the die entirely in paint, which is allowed to dry. The die is then polished via a tumble finishing process similar to rock polishing. The abrasive agent scrapes off all of the paint except for the indents of the numbering. A finer abrasive is then used to polish the die. This process also creates the smoother, rounded edges on the dice.\n\nPrecision casino dice may have a polished or sand finish, making them transparent or translucent respectively. Casino dice have their pips drilled, then filled flush with a paint of the same density as the material used for the dice, such that the center of gravity of the dice is as close to the geometric center as possible. All such dice are stamped with a serial number to prevent potential cheaters from substituting a die. Precision backgammon dice are made the same way; they tend to be slightly smaller and have rounded corners and edges, to allow better movement inside the dice cup and stop forceful rolls from damaging the playing surface.\n\nWhile the terms \"ace\", \"deuce\", \"trey\", \"cater\", \"cinque\" and \"sice\" have been made obsolete by one to six, they are still used by some professional gamblers to designate different sides of the dice. \"Ace\" is from the Latin \"as\", meaning \"a unit\"; the others are 2 to 6 in old French.\n\nUsing Unicode characters, the faces ⚀ ⚁ ⚂ ⚃ ⚄ ⚅, can be shown in text using the range U+2680 to U+2685 or using decimal codice_1 to codice_2.\n\nA loaded, weighted, or crooked die is one that has been tampered with so that it will land with a specific side facing upwards more or less often than a fair die would. There are several methods for creating loaded dice, including rounded faces, off-square faces and weights. Transparent acetate dice are used by casinos as they are harder to tamper with than other dice.\n\nAround the end of the 1960s, non-cubical dice became popular among players of wargames, and since have been employed extensively in role-playing games and trading card games. The numerals 6 and 9, which are reciprocally symmetric through rotation, are distinguished with a dot or underline.\n\nDice are often sold in sets, matching in color, of six different shapes. Five of the dice are shaped like the Platonic solids, whose faces are regular polygons. Aside from the cube, the other four Platonic solids have 4, 8, 12, and 20 faces, allowing for those number ranges to be generated. The only other common non-cubical die is the 10-sided die, a pentagonal trapezohedron die, whose faces are ten kites, each with two different edge lengths, three different angles, and two different kinds of vertices. Such sets frequently include a second 10-sided die either of contrasting color or numbered by tens, allowing for a pair of 10-sided dice to generate numbers between 1 and 100.\n\nUsing these dice in various ways, games can closely approximate the real probability distributions of the events they simulate. For instance, 10-sided dice can be rolled in pairs to produce a uniform distribution of random percentages, and summing the values of multiple dice will produce approximations to normal distributions. \n\nUnlike other common dice, a four-sided die does not have a side that faces upward when it is at rest on a surface, so it has to be read in a different way. Many such dice have the numbers printed around the points, so that when it settles, the numbers at the vertex pointing up are the same and are read. Alternatively, the numbers on a tetrahedral die can be placed at the middles of the edges, in which case the numbers around the base are read.\n\nNormally, the faces on a die will be placed so opposite faces will add up to one more than the number of faces (this is not possible with 4-sided dice and dice with an odd-number of faces). Some dice, such as those with 10 sides, are usually numbered sequentially beginning with 0, in which case the opposite faces will add to one less than the number of faces.\n\n\"Uniform fair dice\" are dice where all faces have equal probability of outcome, which follows from the symmetry of the die (as it is face-transitive), and include:\n\nA variation on the standard die is known as the \"average\" die. These are six-sided dice with sides numbered codice_3, which results in the same average result as a standard die (3.5 for a single die, 7 for a pair of dice), but have a narrower range of possible values (2 through 5 for one, 4 through 10 for a pair). They are used in some table-top wargames, where a narrower range of numbers is required. \n\nDice with an odd number of flat faces can be made as \"long dice\". They are based on an infinite set of prisms. All the (rectangular) faces they may actually land on are congruent, so they are equally fair. (The other 2 sides of the prism are rounded or capped with a pyramid, designed so that the die never actually rests on those faces.)\n\nThe faces of most dice are labelled using sequences of whole numbers, usually starting at one, expressed with either pips or digits. However, there are some applications that require results other than numbers. Examples include letters for Boggle, directions for \"Warhammer Fantasy Battle\", Fudge dice, playing card symbols for poker dice, and instructions for sexual acts using sex dice.\n\nA die can be constructed in the shape of a sphere, with the addition of an internal cavity in the shape of the dual polyhedron of the desired die shape and an internal weight. The weight will settle in one of the points of the internal cavity, causing it to settle with one of the numbers uppermost. For instance, a sphere with an octahedral cavity and a small internal weight will settle with one of the 6 points of the cavity held downwards by the weight.\n\nPolyhedral dice are commonly used in role-playing games. The fantasy role-playing game \"Dungeons & Dragons\" (D&D) is largely credited with popularizing dice in such games. Some games use only one type, like \"Exalted\" which uses only ten-sided dice. Others use numerous types for different game purposes, such as D&D, which makes use of all common polyhedral dice. Dice are usually used to determine the outcome of events. Games typically determine results either as a total on one or more dice above or below a fixed number, or a certain number of rolls above a certain number on one or more dice. Due to circumstances or character skill, the initial roll may have a number added to or subtracted from the final result, or have the player roll extra or fewer dice. To keep track of rolls easily, dice notation is frequently used.\n\nMany board games use dice to randomize how far pieces move or to settle conflicts. Typically, this has meant that rolling higher numbers is better. Some games, such as Axis & Allies, have inverted this system by making the lower values more potent. In the modern age, a few games and game designers have approached dice in a different way by making each side of the die similarly valuable. In Castles of Burgundy, players spend their dice to take actions based on the die's value. In this game, a six is not better than a one, or vice versa. In Quarriors (and its descendent, Dicemasters), different sides of the dice can offer completely different abilities. Several sides often give resources while others grant the player useful actions.\n\nDice can be used for divination and using dice for such a purpose is called cleromancy. A pair of common dice is usual, though other forms of polyhedra can be used. Tibetan Buddhists sometimes use this method of divination. It is highly likely that the Pythagoreans used the Platonic solids as dice. They referred to such dice as \"the dice of the gods\" and they sought to understand the universe through an understanding of geometry in polyhedra.\n\nAstrological dice are a specialized set of three 12-sided dice for divination; the first die represents planets, the Sun, the Moon, and the nodes of the Moon, the second die represents the 12 zodiac signs, and the third represents the 12 houses. A specialized icosahedron die provides the answers of the Magic 8-Ball, conventionally used to provide answers to yes-or-no questions.\n\nIn many gaming contexts, especially tabletop role-playing games, shorthand notations representing different dice rolls are used. A \"d\" or \"D\" is used to indicate a die with a specific number of sides; for example, codice_4 denotes a four-sided die. If several dice of the same type are to be rolled, this is indicated by a leading number specifying the number of dice. Hence, codice_5 means the player should roll six eight-sided dice and add the results. Modifiers to a die roll can also be indicated as desired. For example, codice_6 instructs the player to roll three six-sided dice, calculate the total, and add four to it.\n\n\n"}
{"id": "8246", "url": "https://en.wikipedia.org/wiki?curid=8246", "title": "Dumpster diving", "text": "Dumpster diving\n\nDumpster diving, commonly referred to in the UK and many parts of Europe as totting, skipping, skip diving or skip salvage, is a popular form of modern salvaging of waste in large commercial, residential, industrial and construction containers to find items that have been discarded by their owners, but that may prove useful to the picker. It is not confined to dumpsters specifically, and may cover standard household waste containers, landfills or small dumps.\n\nDifferent terms are used to refer to different forms of this activity. For picking materials from the curbside trash collection, curb shopping, trash picking or street scavenging are sometimes used. When seeking primarily metal to be recycled, one is scrapping. When picking the leftover food from traditional or industrial farming left in the fields one is gleaning. It is viewed as an effective modern foraging technique. Other related forms exist and are referred to by other terms.\n\nPeople may often dumpster dive for useful items such as clothing, furniture, food, and similar items in good working condition. Some people do this out of necessity due to poverty, while others do so professionally and systematically for large profits.\n\nThe term \"dumpster diving\" emerged in the 1980s, combining \"diving\" with \"dumpster\", a large commercial trash bin. The term \"Dumpster\" itself comes from the Dempster Dumpster, a brand of bins manufactured by Dempster Brothers beginning in 1937. \"Dumpster\" became genericized by the 1970s. According to the \"Oxford English Dictionary\", the term \"dumpster diving\" is chiefly found in American English and first appeared in print in 1983, with the verb \"dumpster-dive\" appearing a few years later. In British English, the practice may be known as \"skipping\", from skip, another term for this type of container.\n\nAlternative names for the practice include bin-diving, containering, D-mart, dumpstering, totting, and skipping. In Australia, garbage picking is called \"skip dipping.\"\n\nThe term \"binner\" is often used to describe individuals who collect recyclable materials for their deposit value. For example, in Vancouver, British Columbia, binners, or bottle collectors, search garbage cans and dumpsters for recyclable materials that can be redeemed for their deposit value. On average, these binners earn about $40 a day for several garbage bags full of discarded containers.\n\nThe karung guni, Zabbaleen, the rag and bone man, waste picker, junk man or bin hoker are terms for people who make their living by sorting and trading trash. A similar process known as gleaning was practised in rural areas and some ancient agricultural societies, where the residue from farmers' fields was collected.\n\nSome dumpster divers, who self-identify as freegans, aim to reduce their ecological footprint by living from dumpster-dived-goods, sometimes exclusively.\n\nThe organization Same Day Dumpsters has written, \"Traditionally, most people who resorted to dumpster-diving were forced to do so out of economic necessity, but this is not the case today.\" However, the activity is performed by people out of necessity in the developing world. Some scavengers perform in organized groups, and some organize on various internet forums and social networking websites. By reusing, or repurposing, resources destined for the landfill, dumpster diving may be environmentalist endeavor (and is thus practiced by many pro-green communities). The wastefulness of consumer society and throw-away culture compels some individuals to rescue usable items (for example, computers) from destruction and divert them to those who can make use of the items.\n\nA wide variety of things may be disposed while still repairable or in working condition, making salvage of them a source of potentially free items for personal use, or to sell for profit. Irregular, blemished or damaged items that are still otherwise functional are regularly thrown away. Discarded food that might have slight imperfections, near its expiration date, or that is simply being replaced by newer stock is often tossed out despite being still edible. Many retailers are reluctant to sell this stock at reduced prices because of the risks that people will buy it instead of the higher-priced newer stock, that extra handling time is required, and that there are liability risks. In the United Kingdom, cookery books have been written on the cooking and consumption of such foods, which has contributed to the popularity of skipping. Artists often use discarded materials retrieved from trash receptacles to create works of found art or assemblage.\n\nStudents have been known to partake in dumpster diving to obtain high tech items for technical projects, or simply to indulge their curiosity for unusual items. Dumpster diving can additionally be used in support of academic research. Garbage picking serves as the main tool for garbologists, who study the sociology and archeology of trash in modern life. Private and government investigators may pick through garbage to obtain information for their inquiries. Illegal cigarette consumption may be deduced from discarded packages.\n\nDumpster diving can be hazardous, due to potential exposure to biohazardous matter, broken glass, and overall unsanitary conditions that may exist in dumpsters.\n\nArguments against garbage picking often focus on the health and cleanliness implications of people rummaging in trash. This exposes the dumpster divers to potential health risks, and, especially if the dumpster diver does not return the non-usable items to their previous location, may leave trash scattered around. Divers can also be seriously injured or killed by garbage collection vehicles; in January 2012, in La Jolla, Swiss-American gentleman Alfonso de Bourbon was killed by a truck while dumpster diving. Further, there are also concerns around the legality of taking items that may still technically belong to the person who threw them away (or to the waste management operator), and whether the taking of some items like discarded documents is a violation of privacy. In general a legal concept called abandonment of property covers this question of the subject of ownership of property that is disposed of.\n\nDiscarded billing records may be used for identity theft. As a privacy violation, discarded medical records as trash led to a $140,000 penalty against Massachusetts billing company Goldthwait Associates and a group of pathology offices in 2013 and a $400,000 settlement between Midwest Women’s Healthcare Specialists and 1,532 clients in Kansas City in 2014.\n\nSince dumpsters are usually located on private premises, divers may occasionally get in trouble for trespassing while dumpster diving, though the law is enforced with varying degrees of rigor. Some businesses may lock dumpsters to prevent pickers from congregating on their property, vandalism to their property, and to limit potential liability if a dumpster diver is injured while on their property. Dumpster diving is often not prohibited by law. Abandonment of property is another principle of law that applies to recovering materials via dumpster diving.\n\nPolice searches of discarded waste as well as similar methods are also generally not considered violations; evidence seized in this way has been permitted in many criminal trials. In the United States this has been affirmed by many courts including and up to the Supreme Court, in the decision \"California v. Greenwood\". The doctrine is not as well established in regards to civil litigation.\n\nCompanies run by private investigators specializing in such techniques have emerged as a result of the need for discreet, undetected retrieval of documents and evidence for civil and criminal trials. Private investigators have also written books on \"P.I. technique\" in which dumpster diving or its equivalent \"wastebasket recovery\" figures prominently.\n\nIn 2009, a Belgian dumpster diver and eco-activist nicknamed Ollie was detained for a month for taking food out of a garbage can, and was accused of theft and burglary. On February 25, 2009, he was arrested for taking food from a garbage can at an AD Delhaize supermarket in Bruges. Ollie's trial evoked protests in Belgium against restrictions from taking discarded food items.\n\nIn Ontario, Canada, the Trespass to Property Act—legislation dating back to the British North America Act of 1867—grants property owners and security guards the power to ban anyone from their premises, for any reason, permanently. This is done by issuing a notice to the intruder, who will only be breaking the law upon return. Similar laws exist in Prince Edward Island and Saskatchewan. A recent case in Canada, which involved a police officer who retrieved a discarded weapon from a trash receptacle as evidence, created some controversy. The judge ruled the policeman's actions as legal although there was no warrant present, which led some to speculate the event as validation for any Canadian citizen to raid garbage disposals.\n\nSkipping in England and Wales may qualify as theft within the Theft Act 1968 or as common-law theft in Scotland, though there is very little enforcement in practice.\n\nIn Germany, dumpster diving has been referred to as \"containern\", and a waste container's contents are regarded as the property of the container's owner. Therefore, taking items from such a container is viewed as theft. Be that as it may, the police will routinely disregard the illegality of garbage picking seeing as the items found are generally of low value. There has only been one known instance where people were to be prosecuted: the individuals were arrested on assumed burglary as they had surmounted a supermarket's fence which was then followed by a theft complaint by the owner.\n\nIn the United States, the 1988 \"California v. Greenwood\" case in the U.S. Supreme Court held that there is no common law expectation of privacy for discarded materials. There are, however, limits to what can legally be taken from a company's refuse. In a 1983 Minnesota case involving the theft of customer lists from a garbage can, \"Tennant Company v. Advance Machine Company\" (355 N.W.2d 720), the owner of the discarded information was awarded $500,000 in damages.\n\nDumpster diving is practiced differently in developed countries than in developing countries.\n\n\n\nIn the 1960s, Jerry Schneider, using recovered instruction manuals from The Pacific Telephone & Telegraph Company, used the company's own procedures to acquire hundreds of thousands of dollars' worth of telephone equipment over several years until his arrest.\n\nThe \"Castle Infinity\" videogame, after its shutdown in 2005, was brought back from the dead by rescuing its servers from the trash.\n\nFood Not Bombs is an anti-hunger organization that gets a significant amount of its food from dumpster diving from the dumpsters at small markets and corporate grocery stores in the US and UK.\n\nIn October 2013, in North London, three men were arrested and charged under the 1824 Vagrancy Act when they were caught taking discarded food: tomatoes, mushrooms, cheese and cakes from bins behind an Iceland supermarket. The charges were dropped on 29 January 2014 after much public criticism as well as a request by Iceland's chief executive, Malcolm Walker.\n\n\n\n\n\n"}
{"id": "8247", "url": "https://en.wikipedia.org/wiki?curid=8247", "title": "Digital synthesizer", "text": "Digital synthesizer\n\nA digital synthesizer is a synthesizer that uses digital signal processing (DSP) techniques to make musical sounds. This in contrast to older analog synthesizers, which produce music using analog electronics, and samplers, which play back digital recordings of acoustic, electric, or electronic instruments. Some digital synthesizers emulate analog synthesizers others include sampling capability in addition to digital synthesis.\n\nThe very earliest digital synthesis experiments were made with computers, as part of academic research into sound generation. In 1973, the Japanese company Yamaha licensed the algorithms for frequency modulation synthesis (FM synthesis) from John Chowning, who had experimented with it at Stanford University since 1971. Yamaha's engineers began adapting Chowning's algorithm for use in a commercial digital synthesizer, adding improvements such as the \"key scaling\" method to avoid the introduction of distortion that normally occurred in analog systems during frequency modulation, though it would take several years before Yamaha were to release their FM digital synthesizers. In the 1970s, Yamaha were granted a number of patents, under the company's former name \"Nippon Gakki Seizo Kabushiki Kaisha\", evolving Chowning's early work on FM synthesis technology. Yamaha built the first prototype digital synthesizer in 1974.\n\nReleased in 1979, the Casio VL-1 was the first commercial digital synthesizer, selling for $69.95. Yamaha eventually commercialized their FM synthesis technology and released the first FM digital synthesizer in 1980, the Yamaha GS-1, but at an expensive retail price of $16,000.\n\nEarly commercial digital synthesizers used simple hard-wired digital circuitry to implement techniques such as additive synthesis and FM synthesis. Other techniques, such as wavetable synthesis and physical modeling, only became possible with the advent of high-speed microprocessor and digital signal processing technology. Two other early commercial digital synthesizers were the Fairlight CMI, introduced in 1979, and the New England Digital Synclavier II, introduced in 1980. The Fairlight CMI was a sampling synthesizer, while the Synclavier originally used FM synthesis technology licensed from Yamaha, before adding sampling synthesis later in the 1980s. The Fairlight CMI and the Synclavier were both expensive systems, retailing for more than $20,000 in the early 1980s. The cost of digital synthesizers began falling rapidly in the early 1980s. E-mu Systems introduced the Emulator sampling synthesizer in 1982 at a retail price of $7,900. Although not as flexible or powerful as either the Fairlight CMI or the Synclavier, its lower cost and portability made it popular.\n\nIntroduced in 1983, the Yamaha DX7 was the breakthrough digital synthesizer to have a major impact, both innovative and affordable, and thus spelling the decline of analog synthesizers. It used FM synthesis and, although it was incapable of the sampling synthesis of the Fairlight CMI, its price was around $2,000, putting it within range of a much larger number of musicians. The DX-7 was also known for its \"key scaling\" method to avoid distortion and for its recognizabley bright tonality that was partly due to its high sampling rate of 57 kHz. It became indispensable to many music artists of the 1980s, and would become one of the best-selling synthesizers of all time.\n\nIn 1987, Roland released its own influential synthesizer of the time : the D-50. This popular synth broke new ground in affordably combining short samples and digital oscillators, as well as the innovation of built-in digital effects (reverb., chorus, equalizer). Roland called this Linear Arithmetic (LA) synthesis. This instrument is responsible for some of the very recognisable preset synthesizer sounds of the late 1980s, such as the Pizzagogo sound used on Enya's \"Orinoco Flow.\"\n\nIt gradually became feasible to include high quality samples of existing instruments as opposed to synthesizing them. In 1988, Korg introduced the last of the hugely popular trio of digital synthesizers of the 1980s after the DX7 and D50, the M1. This heralded both the increasing popularisation of digital sample-based synthesis, and the rise of 'workstation' synthesizers. After this time, many popular modern digital synthesizers have been described as not being full synthesizers in the most precise sense, as they play back samples stored in their memory. However, they still include options to shape the sounds through use of envelopes, LFOs, filters and effects such as reverb. The Yamaha Motif and Roland Fantom series of keyboards are typical examples of this type, described as 'ROMplers' ; at the same time, they are also examples of \"workstation\" synthesizers.\nWith the addition of sophisticated sequencers on board, now added to built-in effects and other features, the 'workstation' synthesizer had been born. These always include a multi-track sequencer, and can often record and playback samples, and in later years full audio tracks, to be used to record an entire song. These are usually also ROMplers, playing back samples, to give a wide variety of realistic instrument and other sounds such as drums, string instruments and wind instruments to sequence and compose songs, along with popular keyboard instrument sounds such as electric pianos and organs.\n\nAs there was still interest in analog synthesizers, and with the increase of computing power, over the 1990s another type of synthesizer arose : the analog modeling, or \"virtual analog\" synthesizer. These use computing power to simulate traditional analog waveforms and circuitry such as envelopes and filters, with the most popular examples of this type of instrument including the Nord Lead and Access Virus.\n\nAs the cost of processing power and memory fell, new types of synthesizers emerged, offering a variety of novel sound synthesis options. The Korg Oasys was one such example, packaging multiple digital synthesizers into a single unit.\n\nDigital synthesizers can now be completely emulated in software (\"softsynth\"), and run on conventional PC hardware. Such soft implementations require careful programming and a fast CPU to get the same latency response as their dedicated equivalents. To reduce latency, some professional sound card manufacturers have developed specialized Digital Signal Processing ([DSP]) hardware. Dedicated digital synthesizers have the advantage of a performance-friendly user interface (physical controls like buttons for selecting features and enabling functionality, and knobs for setting variable parameters). On the other hand, software synthesizers \nhave the advantages afforded by a rich graphical display.\n\nWith focus on performance-oriented keyboards and digital computer technology, manufacturers of commercial electronic instruments created some of the earliest digital synthesizers for studio and experimental use with computers being able to handle built-in sound synthesis algorithms.\n\nThe main difference is that a digital synthesizer uses digital processors and analog synthesizers use analog circuitry. A digital synthesizer is in essence a computer with (often) a piano-keyboard and a LCD as an interface. An analog synthesizer is made up of sound-generating circuitry and modulators. Because computer technology is rapidly advancing, it is often possible to offer more features in a digital synthesizer than in an analog synthesizer at a given price. However, both technologies have their own merit. Some forms of synthesis, such as, for instance, sampling and additive synthesis are not feasible in analog synthesizers, while on the other hand, many musicians prefer the character of analog synthesizers over their digital equivalent.\n\nThe New wave era of the 1980s first brought the digital synthesizer to the public ear. Bands like Talking Heads and Duran Duran used the digitally made sounds on some of their most popular albums. Other more pop-inspired bands like Hall & Oates began incorporating the digital synthesizer into their sound in the 1980s. Through breakthroughs in technology in the 1990s many modern synthesizers use DSP.\n\nWorking in more or less the same way, every digital synthesizer appears similar to a computer. At a steady sample rate, digital synthesis produces a stream of numbers. Sound from speakers is then produced by a conversion to analog form. Through signal generation, voice and instrument-level processing, a signal flow is created and controlled either by MIDI capabilities or voice and instrument-level controls.\n\n"}
{"id": "8249", "url": "https://en.wikipedia.org/wiki?curid=8249", "title": "Definition of music", "text": "Definition of music\n\nA definition of music is a definition, or statement of the meaning of, the term \"music\". An accurate and concise definition of music is fundamental to being able to discuss, categorize, and otherwise consider what we understand as being music. \"Explications of the concept of music usually begin with the idea that music is organized sound. They go on to note that this characterization is too broad, since there are many examples of organized sound that are not music, such as human speech, and the sounds non-human animals and machines make\" . Many authorities have suggested definitions, but defining music turns out to be more difficult than might first be imagined. As this article will demonstrate, there is ongoing controversy about how to define music.\n\nThe \"Concise Oxford Dictionary\" defines music as \"the art of combining vocal or instrumental sounds (or both) to produce beauty of form, harmony, and expression of emotion\" . However, the music genres known as Noise music and Musique concrète, for instance, challenge these ideas about what constitutes music's essential attributes by using sounds not widely considered as musical, like randomly produced electronic distortion, feedback, static, cacophony, and compositional processes using indeterminacy (; ).\n\nA famous example of the dilemma in defining music is modern composer John Cage’s composition titled \"4'33\"\". The written score has three movements and directs the performer(s) to appear on stage, indicate by gesture or other means when the piece begins, then make no sound and only mark sections and the end by gesture. What is heard are only whatever ambient sounds may occur in the room. Some argue this is not music because, for example, it contains no sounds that are conventionally considered \"musical\" and the composer and performer(s) exert no control over the organization of the sounds heard . Others argue it is music because the conventional definitions of musical sounds are unnecessarily and arbitrarily limited, and control over the organization of the sounds is achieved by the composer and performer(s) through their gestures that divide what is heard into specific sections and a comprehensible form .\n\nThe problem of defining music is further complicated by different conceptions of music in different cultures.\n\nBecause of differing fundamental concepts of music, the languages of many cultures do not contain a word that can be accurately translated as \"music,\" as that word is generally understood by Western cultures . Inuit and most North American Indian languages do not have a general term for music. Among the Aztecs, the ancient Mexican theory of rhetorics, poetry, dance, and instrumental music used the Nahuatl term \"In xochitl-in kwikatl\" to refer to a complex mix of music and other poetic verbal and non-verbal elements, and reserve the word \"Kwikakayotl\" (or cuicacayotl) only for the sung expressions . In Africa there is no term for music in Tiv, Yoruba, Igbo, Efik, Birom, Hausa, Idoma, Eggon or Jarawa. Many other languages have terms which only partly cover what Western culture typically means by the term \"music\" (). The Mapuche of Argentina do not have a word for \"music\", but they do have words for instrumental versus improvised forms (\"kantun\"), European and non-Mapuche music (\"kantun winka\"), ceremonial songs (\"öl\"), and \"tayil\" .\n\nWhile some languages in West Africa have no term for music, some West African languages accept the general concepts of music (). \"Musiqi\" is the Persian word for the science and art of music, \"muzik\" being the sound and performance of music (), though some things European-influenced listeners would include, such as Quran chanting, are excluded.\n\nBen Watson points out that Ludwig van Beethoven's \"Grosse Fuge\" (1825) \"sounded like noise\" to his audience at the time. Indeed, Beethoven's publishers persuaded him to remove it from its original setting as the last movement of a string quartet. He did so, replacing it with a sparkling \"Allegro\". They subsequently published it separately . Musicologist Jean-Jacques Nattiez considers the difference between noise and music nebulous, explaining that \"The border between music and noise is always culturally defined—which implies that, even within a single society, this border does not always pass through the same place; in short, there is rarely a consensus ... By all accounts there is no \"single\" and \"intercultural\" universal concept defining what music might be\" .\n\nAn often-cited definition of music is that it is \"organized sound\", a term originally coined by modernist composer Edgard Varèse in reference to his own musical aesthetic. Varèse's concept of music as \"organized sound\" fits into his vision of \"sound as living matter\" and of \"musical space as open rather than bounded\" . He conceived the elements of his music in terms of \"sound-masses\", likening their organization to the natural phenomenon of crystallization . Varèse thought that \"to stubbornly conditioned ears, anything new in music has always been called noise\", and he posed the question, \"what is music but organized noises?\" .\n\nThe fifteenth edition of the \"Encyclopædia Britannica\" states that \"while there are no sounds that can be described as inherently unmusical, musicians in each culture have tended to restrict the range of sounds they will admit.\" A human organizing element is often felt to be implicit in music (sounds produced by non-human agents, such as waterfalls or birds, are often described as \"musical\", but perhaps less often as \"music\"). The composer R. Murray states that the sound of classical music \"has decays; it is granular; it has attacks; it fluctuates, swollen with impurities—and all this creates a musicality that comes before any 'cultural' musicality.\" However, in the view of semiologist Jean-Jacques Nattiez, \"just as music is whatever people choose to recognize as such, noise is whatever is recognized as disturbing, unpleasant, or both\" . (See \"music as social construct\" below.)\"\"'\n\nLevi R. Bryant defines music not as a language, but as a marked-based, problem-solving method such as mathematics .\n\nMost definitions of music include a reference to sound and a list of universals of music can be generated by stating the elements (or aspects) of sound: pitch, timbre, loudness, duration, spatial location and texture (). However, in terms more specifically relating to music: following Wittgenstein, cognitive psychologist Eleanor Rosch proposes that categories are not clean cut but that something may be more or less a member of a category . As such the search for musical universals would fail and would not provide one with a valid definition . This is primarily because other cultures have different understandings in relation to the sounds that English language writers refer to as music.\n\nMany people do, however, share a general idea of music. The Websters definition of music is a typical example: \"the science or art of ordering tones or sounds in succession, in combination, and in temporal relationships to produce a composition having unity and continuity\" (\"Webster's Collegiate Dictionary\", online edition).\n\nThis approach to the definition focuses not on the \"construction\" but on the \"experience\" of music. An extreme statement of the position has been articulated by the Italian composer Luciano Berio: “Music is everything that one listens to with the intention of listening to music” . This approach permits the boundary between music and noise to change over time as the conventions of musical interpretation evolve within a culture, to be different in different cultures at any given moment, and to vary from person to person according to their experience and proclivities. It is further consistent with the subjective reality that even what would commonly be considered music is experienced as nonmusic if the mind is concentrating on other matters and thus not perceiving the sound's \"essence\" \"as music\" .\n\nIn his 1983 book, \"Music as Heard\", which sets out from the phenomenological position of Husserl, Merleau-Ponty, and Ricœur, Thomas Clifton defines music as \"an ordered arrangement of sounds and silences whose meaning is presentative rather than denotative. . . . This definition distinguishes music, as an end in itself, from compositional technique, and from sounds as purely physical objects.\" More precisely, \"music is the actualization of the possibility of any sound whatever to present to some human being a meaning which he experiences with his body—that is to say, with his mind, his feelings, his senses, his will, and his metabolism\" . It is therefore \"a certain reciprocal relation established between a person, his behavior, and a sounding object\" .\n\nClifton accordingly differentiates music from non-music on the basis of the human behavior involved, rather than on either the nature of compositional technique or of sounds as purely physical objects. Consequently, the distinction becomes a question of what is meant by musical behavior: \"a musically behaving person is one whose very being is absorbed in the significance of the sounds being experienced.\" However, \"It is not altogether accurate to say that this person is listening \"to\" the sounds. First, the person is doing more than listening: he is perceiving, interpreting, judging, and feeling. Second, the preposition 'to' puts too much stress on the sounds as such. Thus, the musically behaving person experiences musical significance by means of, or through, the sounds\" .\n\nIn this framework, Clifton finds that there are two things that separate music from non-music: (1) musical meaning is presentative, and (2) music and non-music are distinguished in the idea of personal involvement. \"It is the notion of personal involvement which lends significance to the word \"ordered\" in this definition of music\" . This is not to be understood, however, as a sanctification of extreme relativism, since \"it is precisely the 'subjective' aspect of experience which lured many writers earlier in this century down the path of sheer opinion-mongering. Later on this trend was reversed by a renewed interest in 'objective,' scientific, or otherwise non-introspective musical analysis. But we have good reason to believe that a musical experience is not a purely private thing, like seeing pink elephants, and that reporting about such an experience need not be subjective in the sense of it being a mere matter of opinion\" .\n\nClifton's task, then, is to describe musical experience and the objects of this experience which, together, are called \"phenomena,\" and the activity of describing phenomena is called \"phenomenology\" . It is important to stress that this definition of music says nothing about aesthetic standards. Music is not a fact or a thing in the world, but a meaning constituted by human beings. . . . To talk about such experience in a meaningful way demands several things. First, we have to be willing to let the composition speak to us, to let it reveal its own order and significance. . . . Second, we have to be willing to question our assumptions about the nature and role of musical materials. . . . Last, and perhaps most important, we have to be ready to admit that describing a meaningful experience is itself meaningful. \n\n\"Music, often an art/entertainment, is a total social fact whose definitions vary according to era and culture,\" according to Jean . It is often contrasted with noise. According to musicologist Jean-Jacques Nattiez: \"The border between music and noise is always culturally defined—which implies that, even within a single society, this border does not always pass through the same place; in short, there is rarely a consensus... By all accounts there is no \"single\" and \"intercultural\" universal concept defining what music might be\" . Given the above demonstration that \"there is no limit to the number or the genre of variables that might intervene in a definition of the musical,\" an organization of definitions and elements is necessary.\n\nNattiez (1990, 17) describes definitions according to a tripartite semiological scheme similar to the following:\nThere are three levels of description, the poietic, the neutral, and the esthesic:\n\nTable describing types of definitions of music :\nBecause of this range of definitions, the study of music comes in a wide variety of forms. There is the study of sound and vibration or acoustics, the cognitive study of music, the study of music theory and performance practice or music theory and ethnomusicology and the study of the reception and history of music, generally called musicology.\n\nComposer Iannis Xenakis in \"Towards a Metamusic\" (chapter 7 of \"Formalized Music\") defined music in the following way :\n\n\n\n"}
{"id": "8253", "url": "https://en.wikipedia.org/wiki?curid=8253", "title": "Dayton, Ohio", "text": "Dayton, Ohio\n\nDayton (; local pronunciation: ) is the sixth-largest city in the state of Ohio and is the county seat of Montgomery County. A small portion of the city extends into Greene County. In the 2010 census, the population was 141,527, and the Dayton metropolitan area had 799,232 residents, making it Ohio's fourth-largest metropolitan area, after Cleveland, Cincinnati, and Columbus and the 63rd-largest in the United States. The Dayton-Springfield-Greenville Combined Statistical Area had a population of 1,080,044 in 2010, making it the 43rd-largest in the United States. Dayton is within Ohio's Miami Valley region, just north of the Cincinnati–Northern Kentucky metropolitan area.\n\nOhio's borders are within of roughly 60 percent of the country's population and manufacturing infrastructure, making the Dayton area a logistical centroid for manufacturers, suppliers, and shippers. Dayton also hosts significant research and development in fields like industrial, aeronautical, and astronautical engineering that have led to many technological innovations. Much of this innovation is due in part to Wright-Patterson Air Force Base and its place within the community. With the decline of heavy manufacturing, Dayton's businesses have diversified into a service economy that includes insurance and legal sectors as well as healthcare and government sectors.\n\nOther than defense and aerospace, healthcare accounts for much of the Dayton area's economy. Hospitals in the Greater Dayton area have an estimated combined employment of nearly 32,000 and a yearly economic impact of $6.8 billion. It is estimated that Premier Health Partners, a hospital network, contributes more than $2 billion a year to the region through operating, employment, and capital expenditures. In 2011, Dayton was rated the #3 city in the nation by HealthGrades for excellence in healthcare. Many hospitals in the Dayton area are consistently ranked by \"Forbes\", \"U.S. News & World Report\", and HealthGrades for clinical excellence.\n\nDayton is also noted for its association with aviation; the city is home to the National Museum of the United States Air Force and is the birthplace of Orville Wright. Other well-known individuals born in the city include poet Paul Laurence Dunbar and entrepreneur John H. Patterson. Dayton is also known for its many patents, inventions, and inventors that have come from the area, most notably the Wright brothers' invention of powered flight. In 2008, 2009, and 2010, \"Site Selection\" magazine ranked Dayton the #1 mid-sized metropolitan area in the nation for economic development. Also in 2010, Dayton was named one of the best places in the United States for college graduates to find a job.\n\nDayton was founded on April 1, 1796, by 12 settlers known as the Thompson Party. They traveled in March from Cincinnati up the Great Miami River by pirogue and landed at what is now St. Clair Street, where they found two small camps of Native Americans. Among the Thompson Party was Benjamin Van Cleve, whose memoirs provide insights into the Ohio Valley's history. Two other groups traveling overland arrived several days later.\n\nIn 1797, Daniel C. Cooper laid out Mad River Road, the first overland connection between Cincinnati and Dayton, opening the \"Mad River Country\" to settlement. Ohio was admitted into the Union in 1803, and the city of Dayton was incorporated in 1805. The city was named after Jonathan Dayton, a captain in the American Revolutionary War who signed the U.S. Constitution and owned a significant amount of land in the area. In 1827, construction on the Dayton-Cincinnati canal began, which would provide a better way to transport goods from Dayton to Cincinnati and contribute significantly to Dayton's economic growth during the 1800s.\n\nDayton has been the home for many patents and inventions since the 1870s. According to the National Park Service, citing information from the U.S. Patent Office, Dayton had granted more patents per capita than any other U.S. city in 1890 and ranked fifth in the nation as early as 1870. The Wright brothers, inventors of the airplane, and Charles F. Kettering, world-renowned for his numerous inventions, hailed from Dayton. The city was also home to James Ritty's Incorruptible Cashier, the first mechanical cash register, and Arthur E. Morgan's hydraulic jump, a flood prevention mechanism that helped pioneer hydraulic engineering. Paul Laurence Dunbar, an African-American poet and novelist, penned his most famous works in the late 19th century and became an integral part of the city's history.\nInnovation led to business growth in the region. In 1884, John Henry Patterson acquired James Ritty's National Manufacturing Company along with his cash register patents and formed the National Cash Register Company (NCR). The company manufactured the first mechanical cash registers and played a crucial role in the shaping of Dayton's reputation as an epicenter for manufacturing in the early 1900s. In 1906, Charles F. Kettering, a leading engineer at the company, helped develop the first electric cash register, which propelled NCR into the national spotlight. NCR also helped develop the US Navy Bombe, a code-breaking machine that helped crack the Enigma machine cipher during World War II.\n\nA catastrophic flood in March 1913, known as the Great Dayton Flood, led to the creation of the Miami Conservancy District, a series of dams and hydraulic jumps installed around Dayton, in 1914. Like other cities across the country, Dayton was heavily involved in the war effort during World War II. Several locations around the city hosted the Dayton Project, a branch of the larger Manhattan Project, to develop polonium triggers used in early atomic bombs. The war efforts led to a manufacturing boom throughout the city, including high demand for housing and other services. At one point, emergency housing was put into place due to a housing shortage in the region, much of which is still in use today.\n\nBetween the 1940s and the 1970s, the city saw significant growth in suburban areas from population migration. Veterans were returning from military service in large numbers seeking industrial and manufacturing jobs, a part of the local industry that was expanding rapidly. Advancements in architecture also contributed to the suburban boom. New, modernized shopping centers and the Interstate Highway System allowed workers to commute greater distances and families to live further from the downtown area. More than 127,000 homes were built in Montgomery County during the 1950s.\n\nSince the 1980s, however, Dayton's population has declined, mainly due to the loss of manufacturing jobs and decentralization of metropolitan areas, as well as the national housing crisis that began in 2008. While much of the state has suffered for similar reasons, the impact on Dayton has been greater than most. Dayton had the third-greatest percentage loss of population in the state since the 1980s, behind Cleveland and Youngstown. Despite this, Dayton has begun diversifying its workforce from manufacturing into other growing sectors such as healthcare and education.\n\nDowntown expansion that began in the 2000s has helped revitalize the city and encourage growth. Fifth Third Field, home of the Dayton Dragons, was built in 2000. The highly successful minor league baseball team has been an integral part of Dayton's culture. In 2001, the city's public park system, Five Rivers MetroParks, built RiverScape MetroPark , an outdoor entertainment venue that attracts more than 400,000 visitors each year. A new performance arts theater, the Schuster Center, opened in 2003. A large health network in the region, Premier Health Partners, expanded its Miami Valley Hospital with a 12-story tower addition.\n\nIn 2010, the Downtown Dayton Partnership, in cooperation with the City of Dayton and community leaders, introduced the Greater Downtown Dayton Plan. It focuses on job creation and retention, infrastructure improvements, housing, recreation, and collaboration. The plan is to be implemented through the year 2020.\n\nIn 1995, the Dayton Agreement, a peace accord between the parties to the hostilities of the conflict in Bosnia-Herzegovina and the former Yugoslavia, was negotiated at Wright-Patterson Air Force Base, near Fairborn, Ohio, from November 1 to 21.\n\nRichard Holbrooke wrote about this event in his memoirs:\n\nDayton is known as the \"Gem City\". The nickname's origin is uncertain, but several theories exist. In the early 19th century, a well-known racehorse named Gem hailed from Dayton. In 1845, an article published in the \"Cincinnati Daily Chronicle\" by an author known as T stated: \nIn the late 1840s, Major William D. Bickham of the \"Dayton Journal\" began a campaign to nickname Dayton the \"Gem City\". The name was adopted by the city's Board of Trade several years later. Paul Laurence Dunbar referred to the nickname in his poem, \"Toast to Dayton\", as noted in the following excerpt:\n<poem>\nShe shall ever claim our duty,\nFor she shines—the brightest gem\nThat has ever decked with beauty\n</poem>\n\nDayton also plays a role in a nickname given to the state of Ohio, \"Birthplace of Aviation\". Dayton is the hometown of the Wright brothers, aviation pioneers who are credited with inventing and building the world's first successful airplane. After their first manned flights in Kitty Hawk, North Carolina, which they had chosen due to its ideal weather and climate conditions, the Wrights returned to Dayton and continued testing at nearby Huffman Prairie.\n\nAdditionally, Dayton is colloquially referred to as \"Little Detroit\". This nickname comes from Dayton's prominence as a Midwestern manufacturing center.\n\nAccording to the United States Census Bureau, the city has a total area of , of which is land and is water.\n\nDayton's climate features hot, muggy summers and cold, dry winters, and is either classified as a humid subtropical climate (Köppen \"Cfa\"), using the isotherm of the original Köppen scheme, or a humid continental climate (Köppen \"Dfa\"), using the isotherm preferred by some climatologists. Unless otherwise noted, all normal figures quoted within the text below are from the official climatology station, Dayton International Airport, at an elevation of about to the north of downtown Dayton, which lies within the valley of the Miami River; thus temperatures there are typically cooler than in downtown.\n\nAt the airport, monthly mean temperatures range from in January to in July. The highest temperature ever recorded in Dayton was on July 22, 1901, and the coldest was on February 13 during the Great Blizzard of 1899. On average, there are 14 days of + highs and 4.5 nights of sub- lows annually. Snow is moderate, with a normal seasonal accumulation of , usually occurring from November to March, occasionally April, and rarely October. Precipitation averages annually, with total rainfall peaking in May.\n\nDayton is subject to severe weather typical of the Midwestern United States. Tornadoes are possible from the spring to the fall. Floods, blizzards, and severe thunderstorms can also occur.\n\nDayton's population declined significantly from a peak of 262,332 residents in 1960 to only 141,527 in 2010. This was in part due to the slowdown of the region's manufacturing and the growth of Dayton's affluent suburbs including Oakwood, Englewood, Beavercreek, Springboro, Miamisburg, Kettering, and Centerville. The city's most populous ethnic group, white, declined from 78.1% in 1960 to 51.7% by 2010. However, recent census estimates show a 1.3% population increase since 2010, the first increase in five decades.\n\nAs of the 2000 census, the median income for a household in the city was $27,523, and the median income for a family was $34,978. Males had a median income of $30,816 versus $24,937 for females. The per capita income for the city was $34,724. About 18.2% of families and 23.0% of the population were below the poverty line, including 32.0% of those under age 18 and 15.3% of those age 65 or over.\n\nAs of the 2010 census, there were 141,527 people, 58,404 households, and 31,064 families residing in the city. The population density was . There were 74,065 housing units at an average density of . The racial makeup of the city was 51.7% White, 42.9% African American, 0.3% Native American, 0.9% Asian, 1.3% from other races, and 2.9% from two or more races. Hispanic or Latino of any race were 3.0% of the population.\n\nThere were 58,404 households, of which 28.3% had children under the age of 18 living with them, 25.9% were married couples living together, 21.4% had a female householder with no husband present, 5.9% had a male householder with no wife present, and 46.8% were non-families. 38.8% of all households were made up of individuals and 11.2% had someone living alone who was 65 years of age or older. The average household size was 2.26, and the average family size was 3.03.\n\nThe median age in the city was 34.4 years. 22.9% of residents were under the age of 18; 14.2% were between the ages of 18 and 24; 25.3% were from 25 to 44; 25.8% were from 45 to 64; and 11.8% were 65 years of age or older. The gender makeup of the city was 48.7% male and 51.3% female.\n\nThe 2013 census population estimate showed an increasing city of Dayton population for the first time in five decades, attributed to revitalization efforts downtown and the increasing downtown population. However, the 2014 population estimate indicates a net decrease of 897 individuals from 2013's estimate.\n\nDayton's economy is relatively diversified and vital to the overall economy of the state of Ohio. In 2008 and 2009, \"Site Selection\" magazine ranked Dayton the #1 medium-sized metropolitan area in the U.S. for economic development. Dayton is also among the top 100 metropolitan areas in both exports and export-related jobs, ranked 16 and 14 respectively by the Brookings Institution. The 2010 report placed the value of exports at $4.7 billion and the number of export-related jobs at 44,133. The Dayton Metropolitan Statistical Area ranks 4th in Ohio's Gross Domestic Product with a 2008 industry total of $33.78 billion. Additionally, Dayton ranks third among 11 major metropolitan areas in Ohio for exports to foreign countries. The Dayton Development Coalition is attempting to leverage the region's large water capacity, estimated to be 1.5 trillion gallons of renewable water aquifers, to attract new businesses. Moody's Investment Services revised Dayton's bond rating from A1 to the stronger rating of Aa2 as part of its global recalibration process. Standard & Poor's upgraded Dayton's rating from A+ to AA- in the summer of 2009.\n\n\"Bloomberg Businessweek\" ranked Dayton in 2010 as one of the best places in the U.S. for college graduates looking for a job. Companies such as Reynolds and Reynolds, CareSource, DPL, LexisNexis, Kettering Health Network, Premier Health Partners, and Standard Register have their headquarters in Dayton. It is also the former home of the Speedwell Motor Car Company, MeadWestvaco (formerly known as the Mead Paper Company), and NCR. NCR was headquartered in Dayton for over 125 years and was a major innovator in computer technology.\n\nThe Dayton region gave birth to aviation and is known for its high concentration of aerospace and aviation technology. In 2009, Governor Ted Strickland designated Dayton as Ohio's aerospace innovation hub, the state's first such technology hub. Two major United States research and development organizations have leveraged Dayton's historical leadership in aviation and maintain their headquarters in the area: The National Air and Space Intelligence Center (NASIC) and the Air Force Research Laboratory (AFRL). NASIC is the U.S. military's primary producer of intelligence on foreign air and space forces, weapons, and systems, while the AFRL provides leading-edge warfighting capabilities. Both have their headquarters at Wright-Patterson Air Force Base. Wright-Patterson Air Force Base is one of the Air Force's largest air base wings. The installation generated a total economic impact in the Dayton area of $4.67 billion in fiscal year 2011, a decline from $5.1 billion in fiscal year 2009. In addition, state officials are working to make the Dayton region a hub and a leader for UAV research and manufacturing.\nSeveral research organizations support NASIC, AFRL, and the Dayton community. The Advanced Technical Intelligence Center is a confederation of government, academic, and industry partners that leverage advanced technical intelligence expertise. daytaOhio is a non-profit organization based at Wright State University in Dayton, which also hosts five Ohio Centers of Excellence, one of which is the Knowledge Enabled Computing (Kno.e.sis) center, which specializes in making technical advances in computer science areas such as semantics and big data. The University of Dayton Research Institute (UDRI) is led by the University of Dayton. In 2004 and 2005, UDRI was ranked #2 in the nation by the National Science Foundation in federal and industry-funded materials research. The Cognitive Technologies Division (CTD) of Applied Research Associates, Inc., which carries out human-centered research and design, is headquartered in the Dayton suburb of Fairborn. The city of Dayton has started Tech Town, a development project to attract technology-based firms and revitalize the downtown area. Tech Town is home to the world's first RFID business incubator. The University of Dayton-led Institute for Development & Commercialization of Sensor Technologies (IDCAST) at TechTown is a world-class center for excellence in remote sensing and sensing technology. It is one of Dayton's technology business incubators housed in The Entrepreneurs Center building.\n\nThe Kettering Health Network and Premier Health Partners have a major role on the Dayton area's economy. Hospitals in the Greater Dayton area have an estimated combined employment of nearly 32,000 and a yearly economic impact of $6.8 billion. In addition, several Dayton area hospitals consistently earn top national ranking and recognition including the \"U.S. News & World Report\"'s list of \"America's Best Hospitals\" as well as many of HealthGrades top ratings. The most notable hospitals are Miami Valley Hospital and Kettering Medical Center. In 2011, the Dayton area was rated number three in the nation by HealthGrades for excellence in healthcare. Also in 2011, Dayton was ranked the fourth best in the nation for emergency medicine care. Then in 2013, HealthGrades ranked the Dayton region number one in the nation for the lowest hospital mortality rate.\n\nThe Dayton region has several key institutes and centers for health care. The Center for Tissue Regeneration and Engineering at Dayton focuses on the science and development of human tissue regeneration. The National Center for Medical Readiness (NCMR) is also in the Dayton area. The center includes Calamityville, which is a state-of-the-art disaster training facility. Over a period of five years, Calamityville is estimated to have a regional economic impact of $374 million. Also, the Neurological Institute at Miami Valley Hospital is an institute focused on the diagnosis, treatment, and research of neurological disorders.\n\nAccording to Dayton's 2011 Comprehensive Annual Financial Report, the top employers in the city proper are:\n\nThe Dayton City Commission is composed of the mayor and four city commissioners. Each city commission member is elected at-large on a non-partisan basis for four-year, overlapping terms. All policy items are decided by the City Commission, which is empowered by the City Charter to pass ordinances and resolutions, adopt regulations, and appoint the city manager. The city manager is responsible for budgeting and implementing policies and initiatives. Dayton was the first large American city to adopt the city manager form of municipal government, in 1913.\n\nUnlike many Midwestern cities its age, Dayton has very broad and straight downtown streets (generally two or three full lanes in each direction) that improved access to the downtown even after the automobile became popular. The main reason for the broad streets was that Dayton was a marketing and shipping center from its beginning; streets were broad to enable wagons drawn by teams of three to four pairs of oxen to turn around. In addition, some of today's streets were once barge canals flanked by draw-paths.\nA courthouse building was built in downtown Dayton in 1888 to supplement Dayton's original Neoclassical courthouse, which still stands. This second, \"new\" courthouse has since been replaced with new facilities as well as a park. The Old Court House has been a favored political campaign stop. On September 17, 1859, Abraham Lincoln delivered an address on the building's steps. Eight other presidents have visited the courthouse, either as presidents or during presidential campaigns. They are Andrew Johnson, James Garfield, John F. Kennedy, Lyndon B. Johnson, Richard Nixon, Gerald Ford, Ronald Reagan, and Bill Clinton.\n\nIn 2009, the CareSource Management Group finished construction of a $55 million corporate headquarters in downtown Dayton. The , 10-story building was downtown's first new office tower in more than a decade.\n\nThe Dayton skyline's two tallest buildings are the Kettering Tower at and the KeyBank Tower at . Kettering Tower was originally Winters Tower, the headquarters of Winters Bank. The building was renamed after Virginia Kettering when Winters was merged into BankOne. KeyBank Tower was known as the MeadWestvaco Tower before KeyBank gained naming rights to the building in 2008.\n\nTed Rall said in 2015 that over the last five decades Dayton has been demolishing some of its architecturally significant buildings to reduce the city's rental vacancy rate and thus increase the occupancy rate.\n\nDayton's ten historic neighborhoods — Oregon District, Wright Dunbar, Dayton View, Grafton Hill, McPherson Town, Webster Station, Huffman, Kenilworth, St. Anne's Hill, and South Park — feature mostly single-family houses and mansions in the Neoclassical, Jacobethan, Tudor Revival, English Gothic, Chateauesque, Craftsman, Queen Anne, Georgian Revival, Colonial Revival, Renaissance Revival Architecture, Shingle Style Architecture, Prairie, Mission Revival, Eastlake/Italianate, American Foursquare, and Federal styles of architecture. Downtown Dayton is also a large area that encompasses several neighborhoods itself and has seen a recent uplift and revival.\n\nDayton's suburbs with a population of 10,000 or more include Beavercreek, Centerville, Clayton, Englewood, Fairborn, Harrison Township, Huber Heights, Kettering, Miami Township, Miamisburg, Oakwood, Riverside, Springboro (partial), Trotwood, Vandalia, Washington Township, West Carrollton, and Xenia.\n\nThe Dayton Region ranked within the top 10% in the nation in arts and culture. In 2012, Dayton ranked #2 in the country as an arts destination, ranking higher than larger cities such as Atlanta, St. Louis, and Cincinnati. Dayton is the home of the Dayton Art Institute.\n\nThe Benjamin and Marian Schuster Performing Arts Center in downtown Dayton is a world-class performing arts center and the home venue of the Dayton Philharmonic Orchestra, Dayton Opera, and the Dayton Ballet. In addition to philharmonic and opera performances, the Schuster Center hosts concerts, lectures, and traveling Broadway shows, and is a popular spot for weddings and other events. The historic Victoria Theatre in downtown Dayton hosts concerts, traveling Broadway shows, ballet, a summertime classic film series, and more. The Loft Theatre, also downtown, is the home of the Human Race Theatre Company. The Dayton Playhouse, in West Dayton, is the site of numerous plays and theatrical productions. Between 1957 and 1995, the Kenley Players presented live theater productions in Dayton. In 2013, John Kenley was inducted into the Dayton Theatre Hall of Fame.\n\nDayton is the home to several ballet companies including:\n\nThe city's fine dining restaurants include The Pine Club, a nationally known steakhouse. Dayton is home to a variety of pizza chains that have become woven into local culture, the most notable of which are Cassano's and Marion's Piazza. Notable Dayton-based restaurant chains include Hot Head Burritos.\n\nIn addition to restaurants, the city is also home to Esther Price Candies, a candy and chocolate company, and Mike-sells, the oldest potato chip company in the United States.\n\nMany major religions are represented in Dayton. Christianity is represented in Dayton by dozens of denominations and their respective churches. Notable Dayton churches include the First Lutheran Church, Sacred Heart Church, and Ginghamsburg Church. Dayton's Muslim community is largely represented by the Islamic Society of Greater Dayton (ISGD), a Muslim community that includes a mosque on Josie Street. Dayton is also home to the United Theological Seminary, one of 13 seminaries affiliated with the United Methodist Church. Judaism is represented by Temple Israel. Hinduism is represented by the Hindu Temple of Dayton.\n\nTourists visiting Montgomery County accounted for $1.7 billion in business activity in 2007. Tourism also accounts for one out of every 14 private sector jobs in the county. Tourism in the Dayton region is led by the National Museum of the United States Air Force at Wright-Patterson Air Force Base. It is the largest and oldest military aviation museum in the world. The museum draws over 1.3 million visitors per year and is one of the most-visited tourist attractions in Ohio. The museum houses the National Aviation Hall of Fame.\n\nOther museums also play significant roles in the tourism and economy of the Dayton area. The Dayton Art Institute, a museum of fine arts, owns collections containing more than 20,000 objects spanning 5,000 years of art and archaeological history. The Dayton Art Institute was rated one of the top 10 best art museums in the United States for children. The Boonshoft Museum of Discovery is a children's museum of science with numerous exhibits, one of which includes an indoor zoo with nearly 100 different animals.\n\nThere are also some notable historical museums in the region. The Dayton Aviation Heritage National Historical Park, operated by the National Park Service, commemorates the lives and achievements of Dayton natives Orville and Wilbur Wright and Paul Laurence Dunbar. The Wright brothers' famous Wright Flyer III aircraft is housed in a museum at Carillon Historical Park. Dayton is also home to America's Packard Museum, which contains many restored historical Packard vehicles. SunWatch Indian Village/Archaeological Park, a partially reconstructed 12th-century prehistoric American Indian village, is on the south end of Dayton; it is organized around a central plaza dominated by wood posts forming an astronomical calendar. The park includes a museum where visitors can learn about the Indian history of the Miami Valley.\n\nThe Vectren Dayton Air Show is an annual air show that takes place at the Dayton International Airport. The Vectren Dayton Airshow is one of the largest air shows in the United States.\n\nThe Dayton area is served by Five Rivers MetroParks, encompassing over 23 facilities for year-round recreation, education, and conservation. In cooperation with the Miami Conservancy District, the MetroParks maintains over of paved, multi-use scenic trails that connect Montgomery County with Greene, Miami, Warren, and Butler counties. From 1996 to 1998, Dayton hosted the National Folk Festival. Since then, the annual Cityfolk Festival has continued to bring folk, ethnic, and world music and arts to Dayton. The Five Rivers MetroParks also owns and operates the PNC Second Street Market near downtown Dayton. The market has more than 50 vendors selling items such as produce, cooked foods, baked goods, crafts, and flowers.\n\nThe Dayton area hosts several arenas and venues. South of Dayton in Kettering is the Fraze Pavilion, which hosts many nationally and internationally known musicians. Several notable performances have included the Backstreet Boys, Boston, and Steve Miller Band. South of downtown, on the banks of the Great Miami River, is the University of Dayton Arena, home venue for the University of Dayton Flyers basketball teams and the location of various other events and concerts. It also hosts the Winter Guard International championships, at which hundreds of percussion and color guard ensembles from around the world compete. North of Dayton is the Hara Arena, which frequently hosts expo events and concerts. In addition, the Dayton Amateur Radio Association hosts the annual Dayton Hamvention, North America's largest hamfest, at Hara Arena. Up to 25,000 amateur radio operators attend this convention. The Nutter Center, which is just east of Dayton in the suburb of Fairborn, is the home arena for athletics of Wright State University and the former Dayton Bombers hockey team. This venue is used for many concerts, community events, and various national traveling shows and performances.\n\nThe Oregon District is a historic residential and commercial district in southeast downtown Dayton. The district is populated with art galleries, specialty shops, pubs, nightclubs, and coffee houses.\n\nThe city of Dayton is also host to yearly festivals, notably the Dayton Celtic Festival and the City Folk Festival. The Dayton Celtic Festival attracts more than 30,000 people yearly and has Irish dancing, food, crafts, and performers such as Gaelic Storm. Other festivals held in the city of Dayton include the Dayton Blues Festival, Dayton Music Fest, Urban Nights, Women in Jazz, the African American and Cultural Festival, and the Dayton Reggae Fest.\n\nThe Dayton area is home to several minor league and semi pro teams, as well as NCAA Division I sports programs.\nThe Dayton Dragons professional baseball team is the minor league affiliate for the Cincinnati Reds. The Dayton Dragons are the first (and only) team in minor league baseball history to sell out an entire season before it began and was voted as one of the top 10 hottest tickets to get in all of professional sports by Sports Illustrated. The Dayton Dragons 815 consecutive sellouts surpassed the NBA's Portland Trail Blazers for the longest sellout streak across all professional sports in the U.S.\n\nThe Gem City Rollergirls flat track roller derby league is the first (and only) WFTDA league in Dayton, Ohio. The team was established in 2006, and began a rapid climb in the national ranks in 2015. At present, the league hosts double-header bouts at Hara Arena, playing their A-Team (The Purple Reign) and their B-Team (The Violet Femmes) against visiting teams. The league is skater-owned and skater-run.\n\nThe University of Dayton and Wright State University both host NCAA basketball. The University of Dayton Arena has hosted more games in the NCAA men's basketball tournament over its history than any other venue. UD Arena is also the site of the First Round games of the NCAA Tournament. In 2012, eight teams competed for the final four spots in the NCAA Basketball Tournament. Wright State University's NCAA men's basketball is the Wright State Raiders and the University of Dayton's NCAA men's basketball team is the Dayton Flyers.\n\nThe Dayton Gems was a minor league ice hockey team in the International Hockey League from 1964 to 1977, 1979–1980, and most recently 2009 to 2012.\n\nThe Dayton Bombers were an ECHL ice hockey team that most recently played the North Division of the ECHL's American Conference. In June 2009, it was announced the Bombers would turn in their membership back to the league. However, hockey remained in Dayton as the Dayton Gems of the International Hockey League we reformed in the fall of 2009 at Hara Arena. The Gems folded after the 2011–12 season. Shortly after the Gems folded, it was announced a new team, the Dayton Demonz, would begin play in 2012 in the Federal Hockey League (FHL). The Demonz folded in 2015 would be immediately replaced by the Dayton Demolition, also in the FHL. However, the Demolition would cease operations after only one season when Hara Arena decided to close due to financial difficulties.\n\nDayton hosted the first American Professional Football Association game (precursor to the NFL). The game was played at Triangle Park between the Dayton Triangles and the Columbus Panhandles on October 3, 1920, and is considered one of the first professional football games ever played. Football teams in the Dayton area include the Dayton Flyers and the Dayton Sharks.\n\nThe Dayton region is also known for the many golf courses and clubs that it hosts. The Miami Valley Golf Club, Moraine Country Club, NCR Country Club, and the Pipestone Golf Course are some of the more notable courses. In addition, several PGA Championships have been held at area golf courses. The Miami Valley Golf Club hosted the 1957 PGA Championship, the Moraine Country Club hosted the 1945 PGA Championship, and the NCR Country club hosted the 1969 PGA Championship.Additionally, NCR CC hosted the 1986 U.S. Women's Open and the 2005 U.S. Senior Open. Other notable courses include the Yankee Trace Golf Club, the Beavercreek Golf Club, Dayton Meadowbrook Country Club, Sycamore Creek Country Club, Heatherwoode Golf Club, Community Golf Course, and Kitty Hawk Golf Course.\n\nThe city of Dayton is the home to the Dayton Area Rugby Club. As of 2010, the club fields three squads and play their home games at Eastwood Metropark.\n\nDayton is served in print by \"The Dayton Daily News\", the city's sole remaining daily newspaper. The \"Dayton Daily News\" is owned by Cox Enterprises. The Dayton region's main business newspaper is the \"Dayton Business Journal\". Nielsen Media Research ranked the 11-county Dayton television market as the No. 62 market in the United States. The market is served by stations affiliated with major American networks including: WKEF, Channel 22 – ABC, operated by Sinclair Broadcasting, WHIO-TV, Channel 7 – CBS, operated by Cox Media Group, WPTD, Channel 16 – PBS, operated by ThinkTV, which also operates WPTO, assigned to Oxford, WDTN, Channel 2 – NBC, operated by Media General, WBDT, Channel 26 – The CW, operated by Acme Television, and WRGT-TV, Channel 45 – Fox/My Network TV, operated under a local marketing agreement by Sinclair Broadcasting. The nationally syndicated morning talk show \"The Daily Buzz\" originated from WBDT-TV, the Acme property in Miamisburg, before moving to its current home in Florida. Dayton is also served by 42 AM and FM radio stations directly, and numerous other stations are heard from elsewhere in southwest Ohio, which serve outlying suburbs and adjoining counties.\n\nThe Greater Dayton Regional Transit Authority (RTA) operates public bus routes in the Dayton metro area. In addition to routes covered by traditional diesel-powered buses, RTA has a number of electric trolley bus routes. The Dayton trolleybus system is the second longest-running of the six remaining trolleybus systems in the U.S., having entered service in 1933. It is the present manifestation of an electric transit service that has operated continuously in Dayton since 1888.\n\nDayton operates a Greyhound Station which provides inter-city bus transportation to and from Dayton. The hub is in the Greater Dayton Regional Transit Authority North-West hub in Trotwood.\n\nAir transportation is available just north of Dayton proper, via Dayton International Airport in Vandalia, Ohio. The airport offers service to 21 markets through 10 airlines. In 2008, it served 2.9 million passengers. The Dayton International Airport is also a significant regional air freight hub hosting FedEx Express, UPS Airlines, United States Postal Service, and major commercial freight carriers.\n\nThe Dayton area also has several regional airports. The Dayton–Wright Brothers Airport is a general aviation airport owned by the City of Dayton south of the central business district of Dayton on Springboro Pike in Miami Township. It serves as the reliever airport for Dayton International Airport. The airport primarily serves corporate and personal aircraft users. The Dahio Trotwood Airport, also known as Dayton-New Lebanon Airport, is a privately owned, public-use airport west of the central business district of Dayton. The Moraine Airpark is a privately owned, public-use airport southwest of the city of Dayton.\n\nThe Dayton region is primarily served by three interstates:\n\nOther major routes for the region include:\n\nAs of 2010, The Ohio Department of Transportation (ODOT) is in the process of $533 million of construction to modify and reconstruct I-75 through downtown Dayton. ODOT is upgrading and widening I-75 from Edwin C Moses Blvd. to Stanley Avenue.\n\nDayton hosts several inter-modal freight railroad terminals. Two Class I railroads, CSX and Norfolk Southern Railway, operate switching yards in the city.\n\nIn cooperation with the Miami Conservancy District, Five Rivers MetroParks maintains over of paved scenic trails for cycling and other activities. In 2010, the city of Troy was named \"bike friendly\" by the League of American Bicyclists, which gave the city the organization's bronze designation. The honorable mention made Dayton one of two cities in Ohio to receive the award, the other being Columbus, and one of 15 cities nationwide.\n\nThe Dayton Public Schools operates 34 schools that serve 16,855 students, including:\n\nThe city of Dayton has more than 35 private schools within the city, including:\n\nDayton has 33 charter schools. Three of the top five charter schools named in 2011 are K-8 schools managed by National Heritage Academies. Notable charter schools include:\n\nThe Dayton area was ranked tenth for higher education among metropolitan areas in the United States by \"Forbes\" in 2009. The city is home to two major universities. The University of Dayton is a private, Catholic institution founded in 1850 by the Marianist order. It has the only American Bar Association (ABA)-approved law school in the Dayton area. The University of Dayton is Ohio's largest private university and is also home to the University of Dayton Research Institute, which ranks third in the nation for sponsored materials research, and the Center for Tissue Regeneration and Engineering at Dayton, which focuses on human tissue regeneration.\n\nThe public Wright State University became a state university in 1967. Wright State University established the National Center for Medical Readiness, a national training program for disaster preparedness and relief. Wright State's Boonshoft School of Medicine is the Dayton area's only medical school and is a leader in biomedical research.\n\nDayton is also home to Sinclair Community College, the largest community college at a single location in Ohio and one of the nation's largest community colleges. Sinclair is acclaimed as one of the country's best community colleges. Sinclair was founded as the YMCA college in 1887.\n\nOther schools just outside Dayton that shape the educational landscape are Antioch College and Antioch University, both in Yellow Springs, Kettering College of Medical Arts and School of Advertising Art in Kettering, DeVry University in Beavercreek, and Clark State Community College in Springfield. The Air Force Institute of Technology, which was founded in 1919 and serves as a graduate school for the United States Air Force, is at the nearby Wright-Patterson Air Force Base.\n\n\nDayton consistently has had one of the highest crime rates among US cities. Dayton has experienced an improving public safety environment since 2003, with crime declining in key categories according to FBI Uniform Crime Reports and Dayton Police Department data. In 2009, crime continued to fall in the city of Dayton. Crime in the categories of forcible rape, aggravated assault, property crime, motor vehicle theft, robbery, burglary, theft and arson all showed declines for 2009. Overall, crime in Dayton dropped 40% over the previous year. The Dayton Police Department reported a total of 39 murders in 2016, which marked a 39.3% increase in homicides from 2015.\n\nAlso notable, John Dillinger, a famous bank robber during the early 1930s, was captured and arrested by Dayton city police while visiting his girlfriend at a high-class boarding house in downtown Dayton.\n\n\n\n"}
{"id": "8254", "url": "https://en.wikipedia.org/wiki?curid=8254", "title": "Diode", "text": "Diode\n\nIn electronics, a diode is a two-terminal electronic component that conducts primarily in one direction (asymmetric conductance); it has low (ideally zero) resistance to the current in one direction, and high (ideally infinite) resistance in the other. A semiconductor diode, the most common type today, is a crystalline piece of semiconductor material with a p–n junction connected to two electrical terminals. A vacuum tube diode has two electrodes, a plate (anode) and a heated cathode. Semiconductor diodes were the first semiconductor electronic devices. The discovery of crystals' rectifying abilities was made by German physicist Ferdinand Braun in 1874. The first semiconductor diodes, called cat's whisker diodes, developed around 1906, were made of mineral crystals such as galena. Today, most diodes are made of silicon, but other semiconductors such as selenium and germanium are sometimes used.\n\nThe most common function of a diode is to allow an electric current to pass in one direction (called the diode's \"forward\" direction), while blocking current in the opposite direction (the \"reverse\" direction). Thus, the diode can be viewed as an electronic version of a check valve. This unidirectional behavior is called rectification, and is used to convert alternating current (AC) to direct current (DC), including extraction of modulation from radio signals in radio receivers—these diodes are forms of rectifiers.\n\nHowever, diodes can have more complicated behavior than this simple on–off action, because of their nonlinear current-voltage characteristics. Semiconductor diodes begin conducting electricity only if a certain threshold voltage or cut-in voltage is present in the forward direction (a state in which the diode is said to be \"forward-biased\"). The voltage drop across a forward-biased diode varies only a little with the current, and is a function of temperature; this effect can be used as a temperature sensor or as a voltage reference.\n\nA semiconductor diode's current–voltage characteristic can be tailored by selecting the semiconductor materials and the doping impurities introduced into the materials during manufacture. These techniques are used to create special-purpose diodes that perform many different functions. For example, diodes are used to regulate voltage (Zener diodes), to protect circuits from high voltage surges (avalanche diodes), to electronically tune radio and TV receivers (varactor diodes), to generate radio-frequency oscillations (tunnel diodes, Gunn diodes, IMPATT diodes), and to produce light (light-emitting diodes). Tunnel, Gunn and IMPATT diodes exhibit negative resistance, which is useful in microwave and switching circuits.\n\nDiodes, both vacuum and semiconductor, can be used as shot-noise generators.\n\nThermionic (vacuum tube) diodes and solid state (semiconductor) diodes were developed separately, at approximately the same time, in the early 1900s, as radio receiver detectors. Until the 1950s vacuum tube diodes were used more frequently in radios because the early point-contact type semiconductor diodes were less stable. In addition, most receiving sets had vacuum tubes for amplification that could easily have the thermionic diodes included in the tube (for example the 12SQ7 double diode triode), and vacuum tube rectifiers and gas-filled rectifiers were capable of handling some high voltage/high current rectification tasks better than the semiconductor diodes (such as selenium rectifiers) which were available at that time.\n\nIn 1873, Frederick Guthrie discovered the basic principle of operation of thermionic diodes. Guthrie discovered that a positively charged electroscope could be discharged by bringing a grounded piece of white-hot metal close to it (but not actually touching it). The same did not apply to a negatively charged electroscope, indicating that the current flow was only possible in one direction.\n\nThomas Edison independently rediscovered the principle on February 13, 1880. At the time, Edison was investigating why the filaments of his carbon-filament light bulbs nearly always burned out at the positive-connected end. He had a special bulb made with a metal plate sealed into the glass envelope. Using this device, he confirmed that an invisible current flowed from the glowing filament through the vacuum to the metal plate, but only when the plate was connected to the positive supply.\n\nEdison devised a circuit where his modified light bulb effectively replaced the resistor in a DC voltmeter. Edison was awarded a patent for this invention in 1884. Since there was no apparent practical use for such a device at the time, the patent application was most likely simply a precaution in case someone else did find a use for the so-called Edison effect.\n\nAbout 20 years later, John Ambrose Fleming (scientific adviser to the Marconi Company\nand former Edison employee) realized that the Edison effect could be used as a precision radio detector. Fleming patented the first true thermionic diode, the Fleming valve, in Britain on November 16, 1904 (followed by in November 1905).\n\nIn 1874 German scientist Karl Ferdinand Braun discovered the \"unilateral conduction\" of crystals. Braun patented the crystal rectifier in 1899. Copper oxide and selenium rectifiers were developed for power applications in the 1930s.\n\nIndian scientist Jagadish Chandra Bose was the first to use a crystal for detecting radio waves in 1894. The crystal detector was developed into a practical device for wireless telegraphy by Greenleaf Whittier Pickard, who invented a silicon crystal detector in 1903 and received a patent for it on November 20, 1906. Other experimenters tried a variety of other substances, of which the most widely used was the mineral galena (lead sulfide). Other substances offered slightly better performance, but galena was most widely used because it had the advantage of being cheap and easy to obtain. The crystal detector in these early crystal radio sets consisted of an adjustable wire point-contact, often made of gold or platinum because of their incorrodible nature (the so-called \"cat's whisker\"), which could be manually moved over the face of the crystal in search of a portion of that mineral with rectifying qualties. This troublesome device was superseded by thermionic diodes (vacuum tubes) by the 1920s, but after high purity semiconductor materials became available, the crystal detector returned to dominant use with the advent, in the 1950s, of inexpensive fixed-germanium diodes. Bell Labs also developed a germanium diode for microwave reception, and AT&T used these in their microwave towers that criss-crossed the nation starting in the late 1940s, carrying telephone and network television signals. Bell Labs did not develop a satisfactory thermionic diode for microwave reception.\n\nAt the time of their invention, such devices were known as rectifiers. In 1919, the year tetrodes were invented, William Henry Eccles coined the term diode from the Greek roots \"di\" (from \"δί\"), meaning 'two', and \"ode\" (from \"ὁδός\"), meaning 'path'. (However, the word \"diode\" itself, as well as \"triode, tetrode, pentode, hexode\", were already in use as terms of multiplex telegraphy; see, for example, \"The telegraphic journal and electrical review\", September 10, 1886, p. 252).\n\nAlthough all diodes \"rectify\", the term 'rectifier' is normally reserved for higher currents and voltages than would normally be found in the rectification of lower power signals; examples include: \n\nResearchers from the University of Georgia and Ben-Gurion University of the Negev (BGU) have developed a diode made from a molecule of DNA. Professor Bingqian Xu from the College of Engineering at the University of Georgia and his team took a single DNA molecule made from 11 base pairs and connected it to an electronic circuit a few nanometers in size. When layers of coralyne were inserted between layers of DNA, the current jumped up to 15 times larger negative versus positive, which is necessary for a nano diode.\n\nA thermionic diode is a thermionic-valve device (also known as a vacuum tube, tube, or valve), consisting of a sealed evacuated glass envelope containing two electrodes: a cathode heated by a filament, and a plate (anode). Early examples were fairly similar in appearance to incandescent light bulbs.\n\nIn operation, a current flows through the filament (heater)—a high resistance wire made of nichrome—and heats the cathode red hot (800–1000 °C). This causes the cathode to release electrons into the vacuum, a process called thermionic emission. (Some valves use \"direct heating\", in which a tungsten filament acts as both heater and cathode.) The alternating voltage to be rectified is applied between the cathode and the concentric plate electrode. When the plate has a positive voltage with respect to the cathode, it electrostatically attracts the electrons from the cathode, so a current of electrons flows through the tube from cathode to plate. However, when the polarity is reversed and the plate has a negative voltage, no current flows, because the cathode electrons are not attracted to it. The plate, being unheated, does not emit any electrons. So electrons can only flow through the tube in one direction, from the cathode to the anode plate.\n\nThe cathode is coated with oxides of alkaline earth metals, such as barium and strontium oxides. These have a low work function, meaning that they more readily emit electrons than would the uncoated cathode.\n\nIn a mercury-arc valve, an arc forms between a refractory conductive anode and a pool of liquid mercury acting as cathode. Such units were made with ratings up to hundreds of kilowatts, and were important in the development of HVDC power transmission. Some types of smaller thermionic rectifiers had mercury vapor fill to reduce their forward voltage drop and to increase current rating over thermionic hard-vacuum devices.\n\nThroughout the vacuum tube era, valve diodes were used in analog signal applications and as rectifiers in DC power supplies in consumer electronics such as radios, televisions, and sound systems. They were replaced in power supplies beginning in the 1940s by selenium rectifiers and then by semiconductor diodes by the 1960s. Today they are still used in a few high power applications where their ability to withstand transient voltages and their robustness gives them an advantage over semiconductor devices. The recent (2012) resurgence of interest among audiophiles and recording studios in old valve audio gear such as guitar amplifiers and home audio systems has provided a market for the legacy consumer diode valves.\n\nThe symbol used for a semiconductor diode in a circuit diagram specifies the type of diode. There are alternative symbols for some types of diodes, though the differences are minor. The triangle in the symbols points to the forward direction, i.e. in the direction of conventional current flow.\n\nA point-contact diode works the same as the junction diodes described below, but its construction is simpler. A pointed metal wire is placed in contact with an n-type semiconductor. Some metal migrates into the semiconductor to make a small p-type region around the contact. The 1N34 germanium version is still used in radio receivers as a detector and occasionally in specialized analog electronics.\n\nA p–n junction diode is made of a crystal of semiconductor, usually silicon, but germanium and gallium arsenide are also used. Impurities are added to it to create a region on one side that contains negative charge carriers (electrons), called an n-type semiconductor, and a region on the other side that contains positive charge carriers (holes), called a p-type semiconductor. When the n-type and p-type materials are attached together, a momentary flow of electrons occur from the n to the p side resulting in a third region between the two where no charge carriers are present. This region is called the depletion region because there are no charge carriers (neither electrons nor holes) in it. The diode's terminals are attached to the n-type and p-regions. The boundary between these two regions, called a p–n junction, is where the action of the diode takes place. When a sufficiently higher electrical potential is applied to the P side (the anode) than to the N side (the cathode), it allows electrons to flow through the depletion region from the N-type side to the P-type side. The junction does not allow the flow of electrons in the opposite direction when the potential is applied in reverse, creating, in a sense, an electrical check valve.\n\nAnother type of junction diode, the Schottky diode, is formed from a metal–semiconductor junction rather than a p–n junction, which reduces capacitance and increases switching speed.\n\nA semiconductor diode's behavior in a circuit is given by its current–voltage characteristic, or I–V graph (see graph below). The shape of the curve is determined by the transport of charge carriers through the so-called \"depletion layer\" or \"depletion region\" that exists at the p–n junction between differing semiconductors. When a p–n junction is first created, conduction-band (mobile) electrons from the N-doped region diffuse into the P-doped region where there is a large population of holes (vacant places for electrons) with which the electrons \"recombine\". When a mobile electron recombines with a hole, both hole and electron vanish, leaving behind an immobile positively charged donor (dopant) on the N side and negatively charged acceptor (dopant) on the P side. The region around the p–n junction becomes depleted of charge carriers and thus behaves as an insulator.\n\nHowever, the width of the depletion region (called the depletion width) cannot grow without limit. For each electron–hole pair recombination made, a positively charged dopant ion is left behind in the N-doped region, and a negatively charged dopant ion is created in the P-doped region. As recombination proceeds and more ions are created, an increasing electric field develops through the depletion zone that acts to slow and then finally stop recombination. At this point, there is a \"built-in\" potential across the depletion zone.\n\nIf an external voltage is placed across the diode with the same polarity as the built-in potential, the depletion zone continues to act as an insulator, preventing any significant electric current flow (unless electron–hole pairs are actively being created in the junction by, for instance, light; see photodiode). This is called the \"reverse bias\" phenomenon.\n\nHowever, if the polarity of the external voltage opposes the built-in potential, recombination can once again proceed, resulting in a substantial electric current through the p–n junction (i.e. substantial numbers of electrons and holes recombine at the junction). For silicon diodes, the built-in potential is approximately 0.7 V (0.3 V for germanium and 0.2 V for Schottky). Thus, if an external voltage greater than and opposite to the built-in voltage is applied, a current will flow and the diode is said to be \"turned on\" as it has been given an external \"forward bias\". The diode is commonly said to have a forward \"threshold\" voltage, above which it conducts and below which conduction stops. However, this is only an approximation as the forward characteristic is according to the Shockley equation absolutely smooth (see graph below).\n\nA diode's I–V characteristic can be approximated by four regions of operation:\n\n\nIn a small silicon diode operating at its rated currents, the voltage drop is about 0.6 to 0.7 volts. The value is different for other diode types—Schottky diodes can be rated as low as 0.2 V, germanium diodes 0.25 to 0.3 V, and red or blue light-emitting diodes (LEDs) can have values of 1.4 V and 4.0 V respectively.\n\nAt higher currents the forward voltage drop of the diode increases. A drop of 1 V to 1.5 V is typical at full rated current for power diodes.\n\nThe \"Shockley ideal diode equation\" or the \"diode law\" (named after the bipolar junction transistor co-inventor William Bradford Shockley) gives the I–V characteristic of an ideal diode in either forward or reverse bias (or no bias). The following equation is called the \"Shockley ideal diode equation\" when \"n\", the ideality factor, is set equal to 1 :\n\nwhere\n\nThe thermal voltage \"V\" is approximately 25.85 mV at 300 K, a temperature close to \"room temperature\" commonly used in device simulation software. At any temperature it is a known constant defined by:\n\nwhere \"k\" is the Boltzmann constant, \"T\" is the absolute temperature of the p–n junction, and \"q\" is the magnitude of charge of an electron (the elementary charge).\n\nThe reverse saturation current, \"I\", is not constant for a given device, but varies with temperature; usually more significantly than \"V\", so that \"V\" typically decreases as \"T\" increases.\n\nThe \"Shockley ideal diode equation\" or the \"diode law\" is derived with the assumption that the only processes giving rise to the current in the diode are drift (due to electrical field), diffusion, and thermal recombination–generation (R–G) (this equation is derived by setting n = 1 above). It also assumes that the R–G current in the depletion region is insignificant. This means that the \"Shockley ideal diode equation\" doesn't account for the processes involved in reverse breakdown and photon-assisted R–G. Additionally, it doesn't describe the \"leveling off\" of the I–V curve at high forward bias due to internal resistance. Introducing the ideality factor, n, accounts for recombination and generation of carriers.\n\nUnder \"reverse bias\" voltages the exponential in the diode equation is negligible, and the current is a constant (negative) reverse current value of −\"I\". The reverse \"breakdown region\" is not modeled by the Shockley diode equation.\n\nFor even rather small \"forward bias\" voltages the exponential is very large, since the thermal voltage is very small in comparison. The subtracted '1' in the diode equation is then negligible and the forward diode current can be approximated by\n\nThe use of the diode equation in circuit problems is illustrated in the article on diode modeling.\n\nFor circuit design, a small-signal model of the diode behavior often proves useful. A specific example of diode modeling is discussed in the article on small-signal circuits.\n\nFollowing the end of forward conduction in a p–n type diode, a reverse current can flow for a short time. The device does not attain its blocking capability until the mobile charge in the junction is depleted.\n\nThe effect can be significant when switching large currents very quickly. A certain amount of \"reverse recovery time\" t (on the order of tens of nanoseconds to a few microseconds) may be required to remove the reverse recovery charge Q from the diode. During this recovery time, the diode can actually conduct in the reverse direction. This might give rise to a large constant current in the reverse direction for a short time while the diode is reverse biased. The magnitude of such a reverse current is determined by the operating circuit (i.e., the series resistance) and the diode is said to be in the storage-phase. In certain real-world cases it is important to consider the losses that are incurred by this non-ideal diode effect. However, when the slew rate of the current is not so severe (e.g. Line frequency) the effect can be safely ignored. For most applications, the effect is also negligible for Schottky diodes.\n\nThe reverse current ceases abruptly when the stored charge is depleted; this abrupt stop is exploited in step recovery diodes for generation of extremely short pulses.\n\nThere are several types of p–n junction diodes, which emphasize either a different physical aspect of a diode often by geometric scaling, doping level, choosing the right electrodes, are just an application of a diode in a special circuit, or are really different devices like the Gunn and laser diode and the MOSFET:\n\nNormal (p–n) diodes, which operate as described above, are usually made of doped silicon or, more rarely, germanium. Before the development of silicon power rectifier diodes, cuprous oxide and later selenium was used. Their low efficiency required a much higher forward voltage to be applied (typically 1.4 to 1.7 V per \"cell\", with multiple cells stacked so as to increase the peak inverse voltage rating for application in high voltage rectifiers), and required a large heat sink (often an extension of the diode's metal substrate), much larger than the later silicon diode of the same current ratings would require. The vast majority of all diodes are the p–n diodes found in CMOS integrated circuits, which include two diodes per pin and many other internal diodes.\n\n\nOther uses for semiconductor diodes include the sensing of temperature, and computing analog logarithms (see Operational amplifier applications#Logarithmic output).\n\nThere are a number of common, standard and manufacturer-driven numbering and coding schemes for diodes; the two most common being the EIA/JEDEC standard and the European Pro Electron standard:\n\nThe standardized 1N-series numbering \"EIA370\" system was introduced in the US by EIA/JEDEC (Joint Electron Device Engineering Council) about 1960. Most diodes have a 1-prefix designation (e.g., 1N4003). Among the most popular in this series were: 1N34A/1N270 (germanium signal), 1N914/1N4148 (silicon signal), 1N400x (silicon 1A power rectifier), and 1N580x (silicon 3A power rectifier).\n\nThe JIS semiconductor designation system has all semiconductor diode designations starting with \"1S\".\n\nThe European Pro Electron coding system for active components was introduced in 1966 and comprises two letters followed by the part code. The first letter represents the semiconductor material used for the component (A = germanium and B = silicon) and the second letter represents the general function of the part (for diodes, A = low-power/signal, B = variable capacitance, X = multiplier, Y = rectifier and Z = voltage reference); for example:\n\n\nOther common numbering / coding systems (generally manufacturer-driven) include:\n\n\nAs well as these common codes, many manufacturers or organisations have their own systems toofor example:\n\n\nIn optics, an equivalent device for the diode but with laser light would be the Optical isolator, also known as an Optical Diode, that allows light to only pass in one direction. It uses a Faraday rotator as the main component.\n\nThe first use for the diode was the demodulation of amplitude modulated (AM) radio broadcasts. The history of this discovery is treated in depth in the radio article. In summary, an AM signal consists of alternating positive and negative peaks of a radio carrier wave, whose amplitude or envelope is proportional to the original audio signal. The diode (originally a crystal diode) rectifies the AM radio frequency signal, leaving only the positive peaks of the carrier wave. The audio is then extracted from the rectified carrier wave using a simple filter and fed into an audio amplifier or transducer, which generates sound waves.\n\nRectifiers are constructed from diodes, where they are used to convert alternating current (AC) electricity into direct current (DC). Automotive alternators are a common example, where the diode, which rectifies the AC into DC, provides better performance than the commutator or earlier, dynamo. Similarly, diodes are also used in \"Cockcroft–Walton voltage multipliers\" to convert AC into higher DC voltages.\n\nDiodes are frequently used to conduct damaging high voltages away from sensitive electronic devices. They are usually reverse-biased (non-conducting) under normal circumstances. When the voltage rises above the normal range, the diodes become forward-biased (conducting). For example, diodes are used in (stepper motor and H-bridge) motor controller and relay circuits to de-energize coils rapidly without the damaging voltage spikes that would otherwise occur. (A diode used in such an application is called a flyback diode). Many integrated circuits also incorporate diodes on the connection pins to prevent external voltages from damaging their sensitive transistors. Specialized diodes are used to protect from over-voltages at higher power (see Diode types above).\n\nDiodes can be combined with other components to construct AND and OR logic gates. This is referred to as diode logic.\n\nIn addition to light, mentioned above, semiconductor diodes are sensitive to more energetic radiation. In electronics, cosmic rays and other sources of ionizing radiation cause noise pulses and single and multiple bit errors.\nThis effect is sometimes exploited by particle detectors to detect radiation. A single particle of radiation, with thousands or millions of electron volts of energy, generates many charge carrier pairs, as its energy is deposited in the semiconductor material. If the depletion layer is large enough to catch the whole shower or to stop a heavy particle, a fairly accurate measurement of the particle's energy can be made, simply by measuring the charge conducted and without the complexity of a magnetic spectrometer, etc.\nThese semiconductor radiation detectors need efficient and uniform charge collection and low leakage current. They are often cooled by liquid nitrogen. For longer-range (about a centimetre) particles, they need a very large depletion depth and large area. For short-range particles, they need any contact or un-depleted semiconductor on at least one surface to be very thin. The back-bias voltages are near breakdown (around a thousand volts per centimetre). Germanium and silicon are common materials. Some of these detectors sense position as well as energy.\nThey have a finite life, especially when detecting heavy particles, because of radiation damage. Silicon and germanium are quite different in their ability to convert gamma rays to electron showers.\n\nSemiconductor detectors for high-energy particles are used in large numbers. Because of energy loss fluctuations, accurate measurement of the energy deposited is of less use.\n\nA diode can be used as a temperature measuring device, since the forward voltage drop across the diode depends on temperature, as in a silicon bandgap temperature sensor. From the Shockley ideal diode equation given above, it might \"appear\" that the voltage has a \"positive\" temperature coefficient (at a constant current), but usually the variation of the reverse saturation current term is more significant than the variation in the thermal voltage term. Most diodes therefore have a \"negative\" temperature coefficient, typically −2 mV/˚C for silicon diodes. The temperature coefficient is approximately constant for temperatures above about 20 kelvins. Some graphs are given for 1N400x series, and CY7 cryogenic temperature sensor.\n\nDiodes will prevent currents in unintended directions. To supply power to an electrical circuit during a power failure, the circuit can draw current from a battery. An uninterruptible power supply may use diodes in this way to ensure that current is only drawn from the battery when necessary. Likewise, small boats typically have two circuits each with their own battery/batteries: one used for engine starting; one used for domestics. Normally, both are charged from a single alternator, and a heavy-duty split-charge diode is used to prevent the higher-charge battery (typically the engine battery) from discharging through the lower-charge battery when the alternator is not running.\n\nDiodes are also used in electronic musical keyboards. To reduce the amount of wiring needed in electronic musical keyboards, these instruments often use keyboard matrix circuits. The keyboard controller scans the rows and columns to determine which note the player has pressed. The problem with matrix circuits is that, when several notes are pressed at once, the current can flow backwards through the circuit and trigger \"phantom keys\" that cause \"ghost\" notes to play. To avoid triggering unwanted notes, most keyboard matrix circuits have diodes soldered with the switch under each key of the musical keyboard. The same principle is also used for the switch matrix in solid-state pinball machines.\n\nDiodes can be used to limit the positive or negative excursion of a signal to a prescribed voltage.\n\nA diode clamp circuit can take a periodic alternating current signal that oscillates between positive and negative values, and vertically displace it such that either the positive, or the negative peaks occur at a prescribed level. The clamper does not restrict the peak-to-peak excursion of the signal, it moves the whole signal up or down so as to place the peaks at the reference level.\n\nDiodes are usually referred to as \"D\" for diode on PCBs. Sometimes the abbreviation \"CR\" for \"crystal rectifier\" is used.\n\n\n\n\n"}
{"id": "8256", "url": "https://en.wikipedia.org/wiki?curid=8256", "title": "Drexel University", "text": "Drexel University\n\nDrexel University is a private research university with three campuses in Philadelphia. It was founded in 1891 by Anthony J. Drexel, a noted financier and philanthropist. Founded as Drexel Institute of Art, Science, and Industry; it was renamed Drexel Institute of Technology in 1936, before assuming the name Drexel University in 1970.\n\nAs of 2015, more than 26,000 students are enrolled in over 70 undergraduate programs and more than 100 master's, doctoral, and professional programs at the university. Drexel's cooperative education program (co-op) is a unique aspect of the school's degree programs, offering students the opportunity to gain up to 18 months of paid, full-time work experience in a field relevant to their undergraduate major or graduate degree program prior to graduation.\n\nDrexel University was founded in 1891 as the Drexel Institute of Art, Science and Industry, by Philadelphia financier and philanthropist Anthony J. Drexel. The original mission of the institution was to provide educational opportunities in the \"practical arts and sciences\" for women and men of all backgrounds. The institution became known as the Drexel Institute of Technology in 1936, and in 1970 the Drexel Institute of Technology gained university status, becoming Drexel University.\n\nAlthough there were many changes during its first century, the university's identity has been held constant as a privately controlled, non-sectarian, coeducational center of higher learning, distinguished by a commitment to practical education and hands-on experience in an occupational setting. The central aspect of Drexel University's focus on career preparation, in the form of its cooperative education program, was introduced in 1919. The program became integral to the university's unique educational experience. Participating students alternate periods of classroom-based study with periods of full-time, practical work experience related to their academic major and career interests.\n\nBetween 1995 and 2009, Drexel University underwent a period of significant change to its programs, enrollment, and facilities under the leadership of Dr. Constantine Papadakis, the university's president during that time. Papadakis oversaw Drexel's largest expansion in its history, with a 471 percent increase in its endowment and a 102 percent increase in student enrollment. His leadership also guided the university toward improved performance in collegiate rankings, a more selective approach to admissions, and a more rigorous academic program at all levels. It was during this period of expansion that Drexel acquired and assumed management of the former MCP Hahnemann University, creating the Drexel University College of Medicine in 2002. In 2006, the university established the Thomas R. Kline School of Law, and in 2011 the School of Law achieved full accreditation by the American Bar Association.\n\nDr. Constantine Papadakis died of pneumonia in April 2009 while still employed as the university's president. His successor, John Anderson Fry, was formerly the president of Franklin & Marshall College and served as the Executive Vice President of the University of Pennsylvania. Under Fry's leadership, Drexel has continued its expansion, including the July 2011 acquisition of The Academy of Natural Sciences.\n\nThe College of Arts and Sciences was formed in 1990 when Drexel merged the two existing College of Sciences and College of Humanities together.\n\nThe College of Media Arts and design \"fosters the study, exploration and management of the arts: media, design, the performing and visual\". The college offers sixteen undergraduate programs, and 6 graduate programs, in modern art and design fields that range from graphic design and dance to fashion design and television management. Its wide range of programs has helped the college earn full accreditation from the National Association of Schools of Art & Design, the National Architectural Accrediting Board, and the Council for Interior Design Accreditation.\n\nThe Bennett S. LeBow College of Business history dates to the founding in 1891 of the Drexel Institute, that later became Drexel University, and of its Business Department in 1896. Today LeBow offers thirteen undergraduate majors, eight graduate programs, and two doctoral programs; 22 percent of Drexel University's undergraduate students are enrolled in a LeBow College of Business program. \n\nThe LeBow College of Business has been ranked as the 38th best private business school in the nation. Its online MBA program is ranked 14th in the world by the \"Financial Times\"; the publication also ranks the undergraduate business program at LeBow as 19th in the United States. The part-time MBA program ranks 1st in academic quality in the 2015 edition of \"Business Insider's\" rankings. Undergraduate and graduate entrepreneurship programs are ranked 19th in the country by the \"Princeton Review\".\n\nEconomics programs at the LeBow College of Business are housed within the School of Economics. In addition to the undergraduate program in economics, the school is home to a recently launched M.S. in Economics program as well as a PhD program in economics. Faculty members in the School of Economics have been published in the \"American Economic Review\", \"Rand Journal of Economics\", and\"Review of Economics and Statistics.\" The school has been ranked among the best in the world for its extensive research into matters of international trade.\n\nDrexel's College of Engineering is one of its oldest and largest academic colleges, and served as the original focus of the career-oriented school upon its founding in 1891. The College of Engineering is home to several notable alumni, including two astronauts; financier Bennett S. LeBow, for whom the university's College of Business is named; and Paul Baran, inventor of the packet-switched network. Today, Drexel University's College of Engineering, which is home to 19 percent of the undergraduate student body, is known for creating the world's first engineering degree in appropriate technology. The college is also one of only 17 U.S. universities to offer a bachelor's degree in architectural engineering, and only one of five private institutions to do so.\n\nThe 2006 edition of U.S. News ranks the undergraduate engineering program #57 in the country and the 2007 edition of graduate schools ranks the graduate program #61. The 2008 edition ranks the University Engineering Program at #55 and in the 2009 US News Ranking, the university has moved up to the #52 position.\n\nThe engineering curriculum used by the school was originally called E4 (Enhanced Educational Experience for Engineers) which was established in 1986 and funded in part by the Engineering Directorate of the National Science Foundation. In 1988 the program evolved into tDEC (the Drexel Engineering Curriculum) which is composed of two full years of rigorous core engineering courses which encompass the freshman and sophomore years of the engineering student. The College of Engineering hasn't used the tDEC curriculum since approximately 2005.\n\nThe College of Computing and Informatics is a recent addition to Drexel University, though its programs have been offered to students for many years. The college was formed by the consolidation of the former College of Information Science & Technology (often called the \"iSchool\"), the Department of Computer Science, and the Computing and Security Technology program. Undergraduate and graduate programs in computer science, software engineering, information systems, and computer security are offered by the college.\n\nThe Drexel University College of Medicine is a recent addition to the colleges and schools of the university, having been formed upon the acquisition of MCP Hahnemann University in 2002. The College of Medicine was ranked #83 in the \"Best Medical Schools: Research\" category by U.S. News & World Report in 2015. In addition to its M.D. program, the College of Medicine offers several graduate programs in professional studies and biomedical sciences.\n\nThe Graduate School of Biomedical Sciences and Professional studies offers both Master of Science and Doctor of Philosophy degree programs in fields like biochemistry, biotechnology, clinical research, and forensic science. The school also serves as the center for biomedical research at Drexel University.\n\nFounded to combine Drexel's College of Medicine academic principles with its rigorous College of Engineering curriculum, the School of Biomedical Engineering, Science and Health Systems focuses on the emerging field of biomedical science at the undergraduate, graduate, and doctoral levels. Primary research areas within the school include bioinformatics, biomechanics, biomaterials, and cardiovascular engineering.\n\nFormed in 2002 along with the College of Medicine, Drexel's College of Nursing and Health Professions offers more than 25 programs to undergraduate and graduate students in the fields of nursing, nutrition, health sciences, health services, and radiologic technology. The college's research into matters of nutrition and rehabilitation have garnered approximately $2.9 million in external research funding on an annual basis. The physician assistant program at Drexel's College of Nursing and Health Professions is ranked in the top 15 such programs in the United States; its anesthesia programs and physical therapy programs are, respectively, ranked as top-50 programs nationwide.\n\nEstablished in 1892, the department now known as the College of Professional Studies has focused exclusively on educational programs and pursuits for nontraditional adult learners. Today, the Goodwin College of Professional Studies offers several options designed for adult learners at all stages of career and educational development. Bachelor of Science degree completion programs are offered in part-time evening or weekend formats; graduate programs and doctoral programs are offered at the graduate level, as are self-paced \"continuing education\" courses and nearly a dozen self-paced certification programs.\n\nThe Pennoni Honors College, named for Drexel alumnus and trustee Dr. C.R. \"Chuck\" Pennoni '63, '66, Hon. '92, and his wife Annette, recognizes and promotes excellence among Drexel students. Students admitted to the Honors College live together and take many of the same classes; the college provides these students with access to unique cultural and social activities and a unique guest speaker series. Students are also involved in the university's Honors Student Advisory Committee and have the opportunity to take part in Drexel's \"Alternative Spring Break\", an international study tour held each spring.\n\nUpon its founding in 2006, the Thomas R. Kline School of Law, originally known as the Earle Mack School of Law, was the first law school founded in Philadelphia in more than three decades. The School of Law offers L.L.M. and Master of Legal Studies degrees, in addition to the flagship Juris Doctorate program, and uniquely offers cooperative education as part of its curriculum across all programs. In 2015, \"Bloomberg Business\" ranked the Kline School of Law as the second most underrated law school in the United States.\n\nOne of the oldest schools within Drexel University, the modern School of Education dates back to the 1891 founding of the school. Originally, the Department of Education offered teacher training to women as one of its original, career-focused degree programs. Today, the School of Education offers a coeducational approach to teacher training at the elementary and secondary levels for undergraduates. Other undergraduate programs include those focused on the intersection between learning and technology, teacher certification for non-education majors, and a minor in education for students with an interest in instruction. Graduate degrees offered by the School of Education include those in administration and leadership, special education, higher education, mathematics education, international education, and educational creativity and innovation. Doctoral degrees are offered in educational leadership and learning technologies.\n\nThe School of Public Health states that its mission is to \"provide education, conduct research, and partner with communities and organizations to improve the health of populations\". To that end, the school offers both a B.S. and a minor in public health for undergraduate students as well as several options for students pursuing graduate and doctoral degrees in the field. At the graduate level, the Dornsife School offers both a Master of Public Health and an Executive Master of Public Health, as well as an M.S. in biostatistics and an M.S. in epidemiology. Two Doctor of Public Health degrees are also offered, as isa Doctor of Philosophy in epidemiology. The school's graduate and doctoral students are heavily invested in the research activities of the Dornsife School of Public Health, which has helped the school attract annual funding for its four research centers.\n\nThe Center for Hospitality and Sport Management was formed in 2013, in an effort to house and consolidate academic programs in hospitality, tourism management, the culinary arts, and sport management. Academic programs combine the unique skills required of the sports and hospitality industries with the principles and curriculum espoused by the management programs within Drexel's LeBow College of Business.\n\nFocusing specifically on the skills required to successfully start and launch a business, the Charles D. Close School of Entrepreneurship is the first and only freestanding school of entrepreneurship in the United States. Undergraduate students take part in a B.A. program in entrepreneurship and innovation, while graduate students a combined Master of Science degree in biomedicine and entrepreneurship. Minors in entrepreneurship are also offered to undergraduate students.\n\nHoused within the Close School is the Baiada Institute for Entrepreneurship. The institute serves as an incubator for Drexel student startups, providing resources and mentorships to students who are starting their own business while enrolled in one of the Close School's degree programs or academic minors.\n\nDrexel University launched its first Internet-based education program, a master's degree in Library & Information Science, in 1996. In 2001, Drexel created its wholly owned, for-profit online education subsidiary, Drexel e-Learning, Inc., better known as Drexel University Online. It was announced in October 2013 that Drexel University Online would no longer be a for-profit venture, but rather become an internal division within the university to better serve its online student population. Although headquartered in Philadelphia, Drexel announced a new Washington, D.C., location in December 2012 to serve as both an academic and outreach center, catering to the online student population.\n\nIn an effort to create greater awareness of distance learning and to recognize exceptional leaders and best practices in the field, Drexel University Online founded National Distance Learning Week, in conjunction with the United States Distance Learning Association, in 2007. In September 2010, Drexel University Online received the Sloan-C award for institution-wide excellence in online education indicating that it had exceptional programs of \"demonstrably high quality\" at the regional and national levels and across disciplines. Drexel University Online won the 2008 United States Distance Learning Association's Best Practices Awards for Distance Learning Programming. In 2007, the online education subsidiary had a revenue of $40 million. In March 2013, Drexel Online had more than 7,000 unique students from all 50 states and more than 20 countries pursuing a bachelor's, master's, or certificate. As of December 2013, Drexel University Online offers more than 100 fully accredited master's degrees, bachelor's degrees and certificate programs.\n\nDrexel's longstanding cooperative education, or \"co-op\" program is one of the largest and oldest in the United States. Drexel has a fully internet-based job database, where students can submit résumés and request interviews with any of the thousands of companies that offer positions. They interview with employers during three rounds of applications: A round, B round, and C round. Students also have the option of obtaining an internship via independent search. A student graduating from Drexel's 5-year degree program typically has a total of 18 months of internship with up to three different companies. The majority of co-ops are paid, averaging $15,912 per 6-month period, however this figure changes with major. About one third of Drexel graduates are offered full-time positions by their co-op employers right after graduation.\n\nDrexel's knowledge community of researchers and scholars are socially, professionally and intellectually diverse. Research Centers and Institutes at Drexel include:\n\n\nIn its 2017 rankings, \"U.S. News & World Report\" ranked Drexel tied for 96th among national universities in the United States, and tied for 14th in the \"Most Innovative Schools\" category. The publication also ranked the Library and Information Studies program tied for 10th in the nation for 2017.\n\nIn 2016, \"Bloomberg Businessweek\" ranked the undergraduate business program 78th in the country. In 2014, Business Insider ranked Drexel's graduate business school 19th in the country for networking.\n\nThe Department of Materials Science and Engineering was ranked 18th of 88 programs in the 2011 National Research Council survey rankings.\n\nThe Physician Assistant program is ranked tied for 13th in the nation by \"U.S. News & World Report\" in its 2017 rankings.\n\nIn 2014, \"The Princeton Review\" ranked Drexel 20th in its list of worst college libraries.\n\nDrexel University's programs are divided across three Philadelphia-area campuses: the University City Campus, the Center City Hahnemann Campus including Hahnemann University Hospital, and the Queen Lane College of Medicine Campus.\nThe University City Main Campus of Drexel University is located just west of the Schuylkill River in the University City district of Philadelphia. It is Drexel's largest and oldest campus; the campus contains the university's administrative offices and serves as the main academic center for students. The northern, residential portion of the main campus is located in the Powelton Village section of West Philadelphia. The two prominent performing stages at Drexel University are the Mandell Theater and the Main Auditorium. The Main Auditorium dates back to the founding of Drexel and construction of its main hall. It features over 1000 seats, and a pipe organ installed in 1928. The organ was purchased by Saturday Evening Post publisher Cyrus H. K. Curtis after he had donated a similar organ, the Curtis Organ, to nearby University of Pennsylvania and it was suggested that he do the same for Drexel. The 424-seat Mandell Theater was built in 1973 and features a more performance-oriented stage, including a full fly system, modern stage lighting facilities, stadium seating, and accommodations for wheelchairs. It is used for the semiannual spring musical, as well as various plays and many events.\n\nThe Queen Lane Medical Campus was purchased in 2003 by Drexel University as part of its acquisition of MCP Hahnemann University. It is located in the East Falls neighborhood of northwest Philadelphia and is primarily utilized by first- and second-year medical students. A free shuttle is available, connecting the Queen Lane Campus to the Center City Hahnemann and University City Main campuses.\n\nThe Center City Hahnemann Campus is in the middle of Philadelphia, straddling the Vine Street Expressway and centered on Hahnemann University Hospital. Shuttle service is offered between the Center City Hahnemann Campus and both the University City and Queen Lane campuses of the university.\n\nIn 2011, The Academy of Natural Sciences entered into an agreement to become a subsidiary of Drexel University. Founded in 1812, the Academy of Natural Sciences is America's oldest natural history museum and is a world leader in biodiversity and environmental research.\n\nOn January 5, 2009, Drexel University opened the Center for Graduate Studies in Sacramento, California. Eventually renamed Drexel University Sacramento upon the addition of an undergraduate program in business administration, the campus also offered an Ed.D. program in Educational Leadership and Management and master's degree programs in Business Administration, Finance, Higher Education, Human Resource Development, Public Health, and Interdepartmental Medical Science. On March 5, 2015, Drexel University announced the closure of the Sacramento campus, with an 18-month \"phase out\" period designed to allow current students to complete their degrees.\n\nThe Undergraduate Student Government Association of Drexel University works with administrators to solve student problems and tries to promote communication between the students and the administration.\n\nThe Graduate Student Association \"advocates the interests and addresses concerns of graduate students at Drexel; strives to enhance graduate student life at the University in all aspects, from academic to campus security; and provides a formal means of communication between graduate students and the University community\".\n\nThe Campus Activities Board (CAB) is an undergraduate, student-run event planning organization. CAB creates events for the undergraduate population. To assist with planning and organization, the Campus Activities Board is broken down into 5 committees: Special Events, Traditions, Marketing, Culture and Discovery, and Performing and Fine Arts.\n\nWKDU is Drexel's student-run FM radio station, with membership open to all undergraduate students. Its status as an 800-watt, non-commercial station in a major market city has given it a wider audience and a higher profile than many other college radio stations.\n\nDUTV is Drexel's Philadelphia cable television station. The student operated station is part of the Paul F. Harron Studios at Drexel University. The purpose of DUTV is to provide \"the people of Philadelphia with quality educational television, and providing Drexel students the opportunity to gain experience in television management and production\". The Programing includes an eclectic variety of shows from a bi-monthly news show, DNews, to old films, talk shows dealing with important current issues and music appreciation shows.\n\n\"The Triangle\" has been the university's newspaper since 1926 and currently publishes on a weekly basis every Friday. The yearbook was first published in 1911 and named the Lexerd in 1913. Prior to the publishing of a campus wide yearbook in 1911 \"The Hanseatic\" and \"The Eccentric\" were both published in 1896 as class books. Other publications include \"MAYA\", the undergraduate student literary and artistic magazine; \"D&M Magazine\", Design & Merchandising students crafted magazine; \"The Smart Set from Drexel University\", an online magazine founded in 2005; and \"The Drexelist\" a blog-style news source founded in 2010.\n\nThe Drexel Publishing Group serves as a medium for literary publishing on campus. The Drexel Publishing Group oversees \"ASK\" (The Journal of the College of Arts and Sciences at Drexel University), \"Painted Bride Quarterly\", a 36-year-old national literary magazine housed at Drexel; \"The 33rd\", an annual anthology of student and faculty writing at Drexel; \"DPG Online Magazine\", and \"Maya\", the undergraduate literary and artistic magazine. The Drexel Publishing Group also serves as a pedagogical organization by allowing students to intern and work on its publications.\n\nDrexel requires all non-commuting first- and second-year students to live in one of its ten residence halls or in \"university approved housing\". First year students must live in one of the residence halls designated specifically for first-years. These residence halls include Millennium, Calhoun, Kelly, Myers, Towers, Van Rensselaer and Race Halls. Kelly, Myers, Towers, and Calhoun Halls are traditional residence halls (a bedroom shared with one or more roommate(s) and one bathroom per floor), while Race and Van Rensselaer Halls are suite-style residence halls (shared bedrooms, private bathrooms, kitchens, and common area within the suite). Millennium Hall, Drexel's newest residence hall, is a modified suite (a bedroom shared with one roommate, and bathrooms and showers that look like closets with open sinks in the hallway).\n\nEach residence hall is designed to facilitate the Freshman Experience in a slightly different way. Calhoun, Kelly and Towers Halls are all typical residence halls. Myers Hall offers \"Living Learning Communities\" where a group of students who share common interests such as language or major live together. Most of Millennium Hall is reserved for students of the Pennoni Honors College, although some floors are occupied by other students.\n\nSecond-year students have the option of living in a residence hall designated for upperclassmen, or \"university approved housing\". The residence halls for upperclassmen are North and Caneris Halls. North Hall operates under the For Students By Students Residential Experience Engagement Model, developed by the Residential Living Office. There are many apartments that are university approved that second-year students can choose to live in. Three of the largest apartment buildings that fit this description are Chestnut Square, University Crossings, and The Summit, all owned by American Campus Communities. Many other students live in smaller apartment buildings or individual townhouse-style apartments in Powelton Village. A second-year student can choose one of the already listed university approved housing options or petition the university to add a new property to the approved list. While living in a university approved apartment offers the freedom of living outside a residence hall, due to the Drexel co-op system, many students end up in the residence halls because they operate on a quarter to quarter basis, and don't require students to be locked into leases.\n\nGraduate students can live in Stiles Hall.\n\nAll residence halls except Caneris Hall, University Crossings, and Stiles Memorial Hall are located north of Arch Street between 34th Street and 32nd Street in the Powelton Village area.\n\nDrexel University recognizes over 250 student organizations in the following categories:\n\nThe following groups are recognized as honors or professional organizations under the Office of Campus Activities and are not considered part of social Greek life at Drexel University.\n\nApproximately 12 percent of Drexel's undergraduate population are members of a social Greek-letter organization. There are currently fourteen Interfraternity Council (IFC) chapters, seven Panhellenic Council (PHC) chapters and thirteen Multi-cultural Greek Council (MGC) chapters.\n\nThree IFC chapters have been awarded Top Chapters in 2008 by their respective national organizations; Tau Kappa Epsilon, Pi Kappa Alpha, and Alpha Chi Rho. In 2013, Sigma Phi Epsilon and Alpha Epsilon Pi were awarded the Top Chapter award by their respective national headquarters.\n\n\nDrexel's school mascot is a dragon known, as \"Mario the Magnificent\", named in honor of alumnus and Board of Trustees member Mario V. Mascioli. The Dragon has been the mascot of the school since around the mid-1920s; the first written reference to the Dragons occurred in 1928, when the football team was called \"The Dragons in The Triangle\". Before becoming known as the Dragons, the athletic teams had been known by such names as the Blue & Gold, the Engineers, and the Drexelites. The school's sports teams, now known as the Drexel Dragons, participate in the NCAA's Division I as a member of the Colonial Athletic Association. They do not currently field a varsity football team.\n\nIn addition to its NCAA Division I teams, Drexel University is home to 33 active club teams including lacrosse, water polo, squash, triathlon, and cycling. Other club teams include soccer, baseball, rugby, field hockey, and roller hockey. The club teams operate under the direction of the Club Sports Council and the Recreational Sports Office.\n\nTradition suggests that rubbing the toe of the bronze \"Waterboy\" statue, located in the Main Building atrium, can result in receiving good grades on exams. Although the rest of the bronze statue has developed a dark brown patina over the years, the toe has remained highly polished and shines like new.\n\nFrustrated by unresponsive university administrators, students throughout Drexel's history have spoken of a \"Drexel Shaft\" to describe their interactions with the administration during their academic career at the school. The \"Drexel Shaft\" was once associated with the Flame of Knowledge fountain, now located in front of North Hall. As the legend of the Drexel Shaft grew larger, however, the \"shaft\" itself grew alongside the legend. Eventually, the Penn Coach Yards smokestack, located just east of 32nd Street on the University City main campus, came to embody the unresponsive treatment that frustrated many students during their time at Drexel. The smokestack was demolished, to cheers by students and faculty members alike, in November 15, 2009, in what the university community hopes will be a transformation of both the campus' aesthetics and the legend of the \"Drexel Shaft\" itself.\n\nDrexel has appeared in news and television media several times. In 2006 Drexel served as the location for ABC Family's reality show \"Back on Campus\". Also in 2006, the Epsilon Zeta chapter of Delta Zeta won ABC Daytime's Summer of Fun contest. As a result, the sorority was featured in national television spots for a week and hosted an ABC party on campus, which was attended by cast members from \"General Hospital\" and \"All My Children\".\n\nJohn Langdon, adjunct professor in the Antoinette Westphal College of Media Arts & Design, created the ambigram featured on the cover of Dan Brown's Angels & Demons; a number of other ambigrams served as the central focus of the book and its corresponding film. It is believed Prof. Langdon was the inspiration for the name of the lead character, played by Tom Hanks in the film adaptation.\n\nHoward Benson, a Drexel alumnus and a music producer associated with Hoobastank, Creed and Kelly Clarkson, teaches a music production master class at Drexel.\n\nDrexel University was a sponsor of Matthew Quick's novel \"Silver Linings Playbook,\" which was made into a movie in 2012. Matthew Quick held several lectures at Drexel University.\n\nIn 2007, Drexel was the host of the 2008 Democratic Presidential candidate debate in Philadelphia, televised by MSNBC. The university hosted the US Table Tennis Olympic Trials between January 10 and January 13, 2008. Drexel University also hosted the 2011 U.S. Open Squash Championships from October 1–6, 2011, as well as the 2012 U.S. Open Squash Championships from October 4–12, 2012.\n\nIn the U.S. TV Series \"House of Cards\", Congressman Peter Russo (played by Corey Stoll) is a graduate of Drexel University.\n\nSince its founding the university has graduated over 100,000 alumni. Certificate-earning alumni such as artist Violet Oakley and illustrator Frank Schoonover reflect the early emphasis on art as part of the university's curriculum. With World War II, the university's technical programs swelled, and as a result Drexel graduated alumni such as Paul Baran, one of the founding fathers of the Internet and one of the inventors of the packet switching network, and Norman Joseph Woodland the inventor of barcode technology. In addition to its emphasis on technology Drexel has graduated several notable athletes such as National Basketball Association (NBA) basketball players Michael Anderson and Malik Rose, and several notable business people such as Raj Gupta, former President and Chief executive officer (CEO) of Rohm and Haas, and Kenneth C. Dahlberg, former CEO of Science Applications International Corporation (SAIC). Alassane Dramane Ouattara President of the Republic of Ivory Coast.\n\nIn 1991, the university's centennial anniversary, Drexel created an association called the Drexel 100, for alumni who have demonstrated excellence work, philanthropy, or public service. After the creation of the association 100 alumni were inducted in 1992 and since then the induction process has been on a biennial basis. In 2006 164 total alumni had been inducted into the association.\n\nDrexel University created the annual $100,000 Anthony J. Drexel Exceptional Achievement Award to recognize a faculty member from a U.S. institution whose work transforms both research and the society it serves. The first recipient was bioengineer James J. Collins of Boston University (now at MIT) and the Howard Hughes Medical Institute.\n\nIn 2004, in conjunction with BAYADA Home Health Care, Drexel University's College of Nursing and Health Professions created the BAYADA Award for Technological Innovation in Nursing Education and Practice. The award honors nursing educators and practicing nurses whose innovation leads to improved patient care or improved nursing education.\n\n"}
{"id": "8258", "url": "https://en.wikipedia.org/wiki?curid=8258", "title": "Daedalus", "text": "Daedalus\n\nIn Greek mythology, Daedalus (; \"Daidalos\" \"cunningly wrought\", perhaps related to δαιδάλλω \"to work artfully\"; ; Etruscan: \"Taitale\") was a skillful craftsman and artist. He is the father of Icarus, the uncle of Perdix, and possibly also the father of Iapyx, although this is unclear.\n\nHis parentage was supplied as a later addition to the \"mythos\", providing him with a father in Metion, Eupalamus, or Palamaon, and a mother, Alcippe, Iphinoe, or Phrasmede. Daedalus had two sons: Icarus and Iapyx, along with a nephew either Talus or Perdix.\n\nAthenians transferred Cretan Daedalus to make him Athenian-born, the grandson of the ancient king Erechtheus, claiming that Daedalus fled to Crete after killing his nephew Talos. Over time, other stories were told of Daedalus.\n\nDaedalus is first mentioned by Homer as the creator of a wide dancing-ground for Ariadne. He also created the Labyrinth on Crete, in which the Minotaur (part man, part bull) was kept. In the story of the labyrinth as told by the Hellenes, the Athenian hero Theseus is challenged to kill the Minotaur, finding his way with the help of Ariadne's thread. Daedalus' appearance in Homer is in an extended metaphor, \"plainly not Homer's invention\", Robin Lane Fox observes: \"He is a point of comparison and so he belongs in stories which Homer's audience already recognized.\" In Bronze Age Crete, an inscription \"da-da-re-jo-de\" has been read as referring to a place at Knossos, and a place of worship.\n\nIn Homer's language, \"daidala\" refers to finely crafted objects. They are mostly objects of armor, but fine bowls and furnishings are \"daidala\", and on one occasion so are the \"bronze-working\" of \"clasps, twisted brooches, earrings and necklaces\" made by Hephaestus while cared for in secret by the goddesses of the sea.\n\nIgnoring Homer, later writers envisaged the Labyrinth as an edifice rather than a single dancing path to the center and out again, and gave it numberless winding passages and turns that opened into one another, seeming to have neither beginning nor end. Ovid, in his \"Metamorphoses\", suggests that Daedalus constructed the Labyrinth so cunningly that he himself could barely escape it after he built it. Daedalus built the labyrinth for King Minos, who needed it to imprison his wife's son the Minotaur. The story is told that Poseidon had given a white bull to Minos so that he might use it as a sacrifice. Instead, Minos kept it for himself; and in revenge, Poseidon, with the help of Aphrodite, made Pasiphaë, King Minos's wife, lust for the bull For Pasiphaë, as Greek mythologers interpreted it, Daedalus also built a wooden cow so she could mate with the bull, for the Greeks imagined the Minoan bull of the sun to be an actual, earthly bull, the slaying of which later required a heroic effort by Theseus.\n\nThis story thus encourages others to consider the long-term consequences of their own inventions with great care, lest those inventions do more harm than good. As in the tale of Icarus' wings, Daedalus is portrayed assisting in the creation of something that has subsequent negative consequences, in this case with his creation of the monstrous Minotaur's almost impenetrable Labyrinth, which made slaying the beast an endeavour of legendary difficulty.\n\nThe most familiar literary telling explaining Daedalus' wings is a late one, that of Ovid: in his \"Metamorphoses\" (VIII:183-235) Daedalus was shut up in a tower to prevent the knowledge of his Labyrinth from spreading to the public. He could not leave Crete by sea, as the king kept a strict watch on all vessels, permitting none to sail without being carefully searched. Since Minos controlled the land and sea routes, Daedalus set to work to fabricate wings for himself and his young son Icarus. He tied feathers together, from smallest to largest so as to form an increasing surface. He secured the feathers at their midpoints with string and at their bases with wax, and gave the whole a gentle curvature like the wings of a bird. When the work was done, the artist, waving his wings, found himself buoyed upward and hung suspended, poising himself on the beaten air. He next equipped his son in the same manner, and taught him how to fly. When both were prepared for flight, Daedalus warned Icarus not to fly too high, because the heat of the sun would melt the wax, nor too low, because the sea foam would soak the feathers.\n\nThey had passed Samos, Delos and Lebynthos by the time the boy, forgetting himself, began to soar upward toward the sun. The blazing sun softened the wax that held the feathers together and they came off. Icarus quickly fell in the sea and drowned. His father cried, bitterly lamenting his own arts, and called the land near the place where Icarus fell into the ocean Icaria in memory of his child. Some time later, the goddess Athena visited Daedalus and gave him wings, telling him to fly like a god.\n\nAn early image of winged Daedalus appears on an Etruscan jug of ca 630 BC found at Cerveteri, where a winged figure captioned \"Taitale\" appears on one side of the vessel, paired on the other side, uniquely, with \"Metaia\", Medea: \"its linking of these two mythical figures is unparalleled,\" Robin Lane Fox observes: \"The link was probably based on their wondrous, miraculous art. Magically, Daedalus could fly, and magically Medea was able to rejuvenate the old (the scene on the jug seems to show her doing just this)\". The image of Daedalus demonstrates that he was already well known in the West.\n\nFurther to the west Daedalus arrived safely in Sicily, in the care of King Cocalus of Kamikos on the island's south coast; there Daedalus built a temple to Apollo, and hung up his wings, an offering to the god. In an invention of Virgil (\"Aeneid\" VI), Daedalus flies to Cumae and founds his temple there, rather than in Sicily; long afterward Aeneas confronts the sculpted golden doors of the temple.\n\nMinos, meanwhile, searched for Daedalus by traveling from city to city asking a riddle. He presented a spiral seashell and asked for a string to be run through it. When he reached Kamikos, King Cocalus, knowing Daedalus would be able to solve the riddle, privately fetched the old man to him. He tied the string to an ant which, lured by a drop of honey at one end, walked through the seashell stringing it all the way through. Minos then knew Daedalus was in the court of King Cocalus and demanded he be handed over. Cocalus managed to convince Minos to take a bath first, where Cocalus' daughters killed Minos. In some versions, Daedalus himself poured boiling water on Minos and killed him.\n\nThe anecdotes are literary and late; however, in the founding tales of the Greek colony of Gela, founded in the 680s on the southwest coast of Sicily, a tradition was preserved that the Greeks had seized cult images wrought by Daedalus from their local predecessors, the Sicani.\n\nDaedalus was so proud of his achievements that he could not bear the idea of a rival. His sister had placed her son, named variously as Perdix, Talus, or Calos, under his charge to be taught the mechanical arts. He was an art scholar and showed striking evidence of ingenuity. Walking on the seashore, he picked up the spine of a fish. According to Ovid, imitating it, he took a piece of iron and notched it on the edge, and thus invented the saw. He put two pieces of iron together, connecting them at one end with a rivet, and sharpening the other ends, and made a pair of compasses. Daedalus was so envious of his nephew's accomplishments that he took an opportunity and caused him to fall from the Acropolis. Athena turned Perdix into a partridge and left a scar that looked like a partridge on Daedalus' right shoulder and Daedalus left Athens due to this.\n\nSuch anecdotal details as these were embroideries upon the reputation of Daedalus as an innovator in many arts. In Pliny's Natural History (7.198) he is credited with inventing carpentry \"and with it the saw, axe, plumb-line, drill, glue, and isinglass\". Pausanias, in travelling around Greece, attributed to Daedalus numerous archaic wooden cult figures (see \"xoana\") that impressed him: \"All the works of this artist, though somewhat uncouth to look at, nevertheless have a touch of the divine in them.\"\n\nIt is said he first conceived masts and sails for ships for the navy of Minos. He is said to have carved statues so well they looked as if alive; even possessing self-motion. They would have escaped if not for the chain that bound them to the wall.\n\nDaedalus gave his name, eponymously, to any Greek artificer and to many Greek contraptions that represented dextrous skill. At Plataea there was a festival, the Daedala, in which a temporary wooden altar was fashioned, and an effigy was made from an oak-tree and dressed in bridal attire. It was carried in a cart with a woman who acted as bridesmaid. The image was called \"Daedale\" and the archaic ritual given an explanation through a myth to the purpose\n\nIn the period of Romanticism, Daedalus came to denote the classic artist, a skilled mature craftsman, while Icarus symbolized the romantic artist, whose impetuous, passionate and rebellious nature, as well as his defiance of formal aesthetic and social conventions, may ultimately prove to be self-destructive. Stephen Dedalus, in Joyce's \"Portrait of the Artist as a Young Man\" envisages his future artist-self \"a winged form flying above the waves [...] a hawk-like man flying sunward above the sea, a prophecy of the end he had been born to serve”.\n\n\n\n"}
{"id": "8259", "url": "https://en.wikipedia.org/wiki?curid=8259", "title": "Deception Pass", "text": "Deception Pass\n\nDeception Pass is a strait separating Whidbey Island from Fidalgo Island, in the northwest part of the U.S. state of Washington. It connects Skagit Bay, part of Puget Sound, with the Strait of Juan de Fuca. A pair of bridges known collectively as Deception Pass Bridge cross Deception Pass, and the bridges are on the National Register of Historic Places.\n\nThe Deception Pass area has been home to various Coast Salish tribes for thousands of years. The first Europeans to see Deception Pass were members of the 1790 expedition of Manuel Quimper on the \"Princesa Real\". The Spanish gave it the name \"Boca de Flon\". A group of sailors led by Joseph Whidbey, part of the Vancouver Expedition, found and mapped Deception Pass on June 7, 1792. George Vancouver gave it the name \"Deception\" because it had misled him into thinking Whidbey Island was a peninsula. The \"deception\" was heightened due to Whidbey's failure to find the strait at first. In May 1792, Vancouver was anchored near the southern end of Whidbey Island. He sent Joseph Whidbey to explore the waters east of Whidbey Island, now known as Saratoga Passage, using small boats. Whidbey reached the northern end of Saratoga Passage and explored eastward into Skagit Bay, which is shallow and difficult to navigate. He returned south to rejoin Vancouver without having found Deception Pass. It appeared that Skagit Bay was a dead-end and that Whidbey Island and Fidalgo Island were a long peninsula attached to the mainland. In June the expedition sailed north along the west coast of Whidbey Island. Vancouver sent Joseph Whidbey to explore inlets leading to the east. The first inlet turned out to be a \"very narrow and intricate channel, which...abounded with rocks above and beneath the surface of the water\". This channel led to Skagit Bay, thus separating Whidbey Island from the mainland. Vancouver apparently felt he and Joseph Whidbey had been deceived by the tricky strait. Vancouver wrote of Whidbey's efforts: \"This determined [the shore they had been exploring] to be an island, which, in consequence of Mr. Whidbey’s circumnavigation, I distinguished by the name of Whidbey’s Island: and this northern pass, leading into [Skagit Bay], Deception Passage\".\nIn the waters of Deception Pass, just east of the present-day Deception Pass Bridge, is a small island known as Ben Ure Island. The island became infamous for its activity of human smuggling of migrant Chinese people for local labor. Ben Ure and his partner Lawrence \"Pirate\" Kelly were quite profitable at their human smuggling business and played hide-and-seek with the United States Customs Department for years. Ure's own operation at Deception Pass in the late 1880s consisted of Ure and his Native-American wife. Local tradition has it that his wife would camp on the nearby Strawberry Island (which was visible from the open sea) and signal him with a fire on the island's summit to alert him to whether or not it was safe to attempt to bring the human cargo he illegally transported ashore. For transport, Ure would tie the people up in burlap bags so that if customs agents were to approach he could easily toss the people in bags overboard. The tidal currents would carry the entrapped drowned migrants' bodies to San Juan Island to the north and west of the pass and many ended up in what became known as Dead Man's Bay.\n\nBetween the years 1910 and 1914, a prison rock quarry was operated on the Fidalgo Island side of the pass. Nearby barracks housed some 40 prisoners, members of an honors program out of Walla Walla State Penitentiary and the prison population was made up of several types of prisoners, including those convicted of murder. Guards stood watch at the quarry as the prisoners cut the rock into gravel and loaded it onto barges located at the base of the cliff atop the pass's waters. The quarried rock was then taken by barge to the Seattle waterfront. The camp was dismantled in 1924 and although abandoned as a quarry, the remains of the camp can still be found. The location, however, is hazardous and over the years there have been several fatal accidents when visitors have ventured onto the steep cliffs.\n\nUpon completion on July 31, 1935, the span Deception Pass Bridge connected Whidbey Island to the tiny Pass Island, and Pass Island to Fidalgo Island. Prior to the bridge, travellers and businessmen would use an inter-island ferry to commute between Fidalgo and Whidbey islands.\n\nDeception Pass is a dramatic seascape where the tidal flow and whirlpools beneath the twin bridges connecting Fidalgo Island to Whidbey Island move quickly. During ebb and flood tide current speed reaches about , flowing in opposite directions between ebb and flood. This swift current can lead to standing waves, large whirlpools, and roiling eddies. This swift current phenomenon can be viewed from the twin bridges' pedestrian walkways or from the trail leading below the larger south bridge from the parking lot on the Whidbey Island side. Boats can be seen waiting on either side of the pass for the current to stop or change direction before going through. Thrill-seeking kayakers go there during large tide changes to surf the standing waves and brave the class 2 and 3 rapid conditions.\n\nDiving Deception Pass is dangerous and only for the most competent and prepared divers. There are a few times each year that the tides are right for a drift dive from the cove, under the bridge, and back to the cove as the tide changes. These must be planned well in advance by divers who know how to read currents and are aware of the dangerous conditions. However, because of the large tidal exchange, Deception Pass hosts some of the most spectacular colors and life in the Pacific Northwest. The walls and bottom are covered in colorful invertebrates, lingcod, greenlings, and barnacles everywhere.\n\nDeception Pass is today surrounded by Deception Pass State Park, the most-visited park in Washington with over 2 million visitors each year. The park was officially established in 1923, when the original of a military reserve was transferred to Washington State Parks. The park's facilities were greatly enhanced in the 1930s when the Civilian Conservation Corps (CCC) built roads, trails, and buildings in order to develop the park.\n\nThe road to West Beach was created in 1950, opening up a stretch of beach to hordes of vehicles. The former fish hatchery at Bowman Bay became a part of the park in the early 1970s. The old entrance to the park was closed in 1997 when a new entrance was created at the intersection of Highway 20 and Cornet Bay road, improving access into and out of the park.\n\nDeception Pass State Park has a number of recreational opportunities, including three campgrounds, several hiking trails, beaches, and tidepools. Several miles of the Pacific Northwest Trail are within the park, most notably including the section that crosses Deception Pass on the Highway 20 bridge. In addition, the Cornet Bay Retreat Center provides cabins and dining and recreation facilities. Cornet Bay offers boat launches and fishing opportunities, while Bowman Bay has an interpretive center that explains the story of the Civilian Conservation Corps throughout Washington state. Near the center is a CCC honor statue, which can be found in 30 different states in the country. Fishing is popular in Pass Lake, on the north side of the bridge. Boat rentals and guided tours of the park are also offered.\n\nIncluded in the park are ten islands: Northwest Island, Deception Island, Pass Island, Strawberry, Ben Ure, Kiket, Skagit, Hope, and Big and Little Deadman Islands. Ben Ure Island is partially privately owned. The island is not open to the public except for a small rentable cabin available via the state park, which is only accessible by rowboat.\n\nThe 2002 horror movie \"The Ring\" was in part filmed near the pass.\n\nThe bridge is fictionalized as a toll bridge named \"Desolation Bridge\" in season one of The Killing.\n\nSeattle shoegaze act The Sight Below filmed the 2008 video for their track \"Further Away\" at Deception Pass, with Deception Island's scenic imagery prominently featured.\n\nSeattle grunge band Mudhoney named a song on their 1993 EP Five Dollar Bob's Mock Cooter Stew \"Deception Pass.\"\n\nSeattle progressive rock band Queensrÿche filmed scenes of their video \"Anybody Listening\" near Deception Pass and Deception Island.\n\n\n"}
{"id": "8262", "url": "https://en.wikipedia.org/wiki?curid=8262", "title": "Dominoes", "text": "Dominoes\n\nDominoes is a family of games played with rectangular \"domino\" tiles. Each domino is a rectangular tile with a line dividing its face into two square \"ends\". Each end is marked with a number of spots (also called \"pips\", \"nips\", or \"dobs\") or is blank. The backs of the dominoes in a set are indistinguishable, either blank or having some common design. The domino gaming pieces (colloquially nicknamed \"bones\", \"cards\", \"tiles\", \"tickets\", \"stones\", \"chips\", or \"spinners\") make up a domino set, sometimes called a \"deck\" or \"pack\". The traditional Sino-European domino set consists of 28 dominoes, featuring all combinations of spot counts between zero and six. A domino set is a generic gaming device, similar to playing cards or dice, in that a variety of games can be played with a set.\n\nThe earliest mention of dominoes is from Song dynasty China found in the text \"Former Events in Wulin\" by Zhou Mi (1232–1298). Modern dominoes first appeared in Italy during the 18th century, but how Chinese dominoes developed into the modern game is unknown. Italian missionaries in China may have brought the game to Europe.\n\nThe name \"domino\" is most likely from the resemblance to a kind of carnival costume worn during the Venetian Carnival, often consisting of a black-hooded robe and a white mask. Contrary to the coinage of the word polyomino as a generalization, there is no connection between the word \"domino\" and the number 2 in any language.\n\nEuropean-style dominoes are traditionally made of bone or ivory, or a dark hardwood such as ebony, with contrasting black or white pips (inlaid or painted). Alternatively, domino sets have been made from many different natural materials: stone (e.g., marble, granite or soapstone); other hardwoods (e.g., ash, oak, redwood, and cedar); metals (e.g., brass or pewter); ceramic clay, or even frosted glass or crystal. These sets have a more novel look, and the often heavier weight makes them feel more substantial; also, such materials and the resulting products are usually much more expensive than polymer materials. \n\nModern commercial domino sets are usually made of synthetic materials, such as ABS or polystyrene plastics, or Bakelite and other phenolic resins; many sets approximate the look and feel of ivory while others use colored or even translucent plastics to achieve a more contemporary look. Modern sets also commonly use a different color for the dots of each different end value (one-spots might have black pips while two-spots might be green, three red, etc.) to facilitate finding matching ends. Occasionally, one may find a domino set made of card stock like that for playing cards. Such sets are lightweight, compact, and inexpensive, and like cards are more susceptible to minor disturbances such as a sudden breeze. Sometimes, dominoes have a metal pin (called a spinner or pivot) in the middle.\n\nThe traditional set of dominoes contains one unique piece for each possible combination of two ends with zero to six spots, and is known as a double-six set because the highest-value piece has six pips on each end (the \"double six\"). The spots from one to six are generally arranged as they are on six-sided dice, but because blank ends having no spots are used, seven faces are possible, allowing 28 unique pieces in a double-six set.\n\nHowever, this is a relatively small number especially when playing with more than four people, so many domino sets are \"extended\" by introducing ends with greater numbers of spots, which increases the number of unique combinations of ends and thus of pieces. Each progressively larger set increases the maximum number of pips on an end by three, so the common extended sets are double-nine, double-12, double-15, and double-18. Larger sets such as double-21 can theoretically exist, but are rarely seen in retail stores, as identifying the number of pips on each domino becomes difficult, and a double-21 set would have 253 pieces, far more than is normally necessary for most domino games even with eight players.\n\nThe oldest confirmed written mention of dominoes in China comes from the \"Former Events in Wulin\" (i.e. the capital Hangzhou) written by the Yuan Dynasty (1271–1368) author Zhou Mi (1232–1298), who listed \"pupai\" (gambling plaques or dominoes), as well as dice as items sold by peddlers during the reign of Emperor Xiaozong of Song (r. 1162–1189). Andrew Lo asserts that Zhou Mi meant dominoes when referring to \"pupai\", since the Ming author Lu Rong (1436–1494) explicitly defined \"pupai\" as dominoes (in regard to a story of a suitor who won a maiden's hand by drawing out four winning \"pupai\" from a set).\n\nThe earliest known manual written about dominoes is the \"(Manual of the Xuanhe Period)\" written by Qu You (1341–1437), but some Chinese scholars believe this manual is a forgery from a later time.\n\nIn the \"Encyclopedia of a Myriad of Treasures\", Zhang Pu (1602–1641) described the game of laying out dominoes as \"pupai\", although the character for \"pu\" had changed, yet retained the same pronunciation. Traditional Chinese domino games include \"Tien Gow, Pai Gow, Che Deng\", and others. The 32-piece Chinese domino set, made to represent each possible face of two thrown dice and thus have no blank faces, differs from the 28-piece domino set found in the West during the mid 18th century. Chinese dominoes with blank faces were known during the 17th century.\n\nMany different domino sets have been used for centuries in various parts of the world to play a variety of domino games. Each domino originally represented one of the 21 results of throwing two six-sided dice (2d6). One half of each domino is set with the pips from one die and the other half contains the pips from the second die. Chinese sets also introduce duplicates of some throws and divide the dominoes into two suits: military and civil. Chinese dominoes are also longer than typical European dominoes.\n\nThe early 18th century had dominoes making their way to Europe, making their first appearance in Italy. The game changed somewhat in the translation from Chinese to the European culture. European domino sets contain neither suit distinctions nor the duplicates that went with them. Instead, European sets contain seven additional dominoes, with six of these representing the values that result from throwing a single die with the other half of the tile left blank, and the seventh domino representing the blank-blank (0–0) combination.\n\nIvory dominoes were routinely used in 19th-century rural England in the settling of disputes over traditional grazing boundaries, and were commonly referred to as \"bonesticks\".\n\nDomino tiles, also known as bones, are twice as long as they are wide and usually have a line in the middle dividing them into two squares. The value of either side is the number of spots or pips. In the most common variant (double-six), the values range from blank or no pips to six. The sum of the two values, i.e. the total number of pips, may be referred to as the rank or weight of a tile, and a tile with more pips may be called heavier than a lighter tile with fewer pips.\n\nTiles are generally named after their two values; e.g. deuce-five or five-deuce (2–5 or 5–2) are alternative ways of describing the tile with the values two and five. Tiles that have the same value on both ends are called doubles, and are typically referred to as double-zero, double-one, etc. Tiles with two different values are called singles.\n\nEvery tile belongs to the two suits of its two values, e.g. 0–3 belongs both to the blank suit (or 0 suit) and to the 3 suit. Naturally the doubles form an exception in that each double belongs to only one suit. In 42, the doubles can be treated as an additional suit of doubles, so the double-six (6–6) belongs both to the six suit and the suit of doubles.\n\nThe most common domino sets commercially available are double six (with 28 tiles) and double nine (with 55 tiles). Larger sets exist and are popular for games involving several players or for players looking for long domino games. The number of tiles in a set has the formula formula_1 for a double-\"n\" set.\n\nThe most popular type of play are layout games, which fall into two main categories, blocking games and scoring games.\n\n\nThe most basic domino variant is for two players and requires a double-six set. The 28 tiles are shuffled face down and form the \"stock\" or \"boneyard\". Each player draws seven tiles; the remainder are not used. Once the players begin drawing tiles, they are typically placed on-edge in front of the players, so each player can see their own tiles, but none can see the value of other players' tiles. Every player can thus see how many tiles remain in the opponent's hands at all times during gameplay.\n\nOne player begins by downing (playing the first tile) one of their tiles. This tile starts the line of play, in which values of adjacent pairs of tile ends must match. The players alternately extend the line of play with one tile at one of its two ends; if a player is unable to place a valid tile, they must keep on pulling tiles from the stock until they can. The game ends when one player wins by playing their last tile, or when the game is blocked because neither player can play. If that occurs, whoever caused the block gets all of the remaining player points not counting their own.\n\nPlayers accrue points during game play for certain configurations, moves, or emptying one's hand. Most scoring games use variations of the draw game. If a player does not call \"domino\" before the tile is laid on the table, and another player says domino after the tile is laid, the first player must pick up an extra domino.\n\nIn a draw game (blocking or scoring), players are additionally allowed to draw as many tiles as desired from the stock before playing a tile, and they are not allowed to pass before the stock is (nearly) empty. The score of a game is the number of pips in the losing player's hand plus the number of pips in the stock. Most rules prescribe that two tiles need to remain in the stock. The draw game is often referred to as simply \"dominoes\".\n\nAdaptations of both games can accommodate more than two players, who may play individually or in teams.\n\nThe line of play is the configuration of played tiles on the table. It starts with a single tile and typically grows in two opposite directions when players add matching tiles. In practice, players often play tiles at right angles when the line of play gets too close to the edge of the table.\n\nThe rules for the line of play often differ from one variant to another. In many rules, the doubles serve as spinners, i.e., they can be played on all four sides, causing the line of play to branch. Sometimes, the first tile is required to be a double, which serves as the only spinner. In some games such as Chicken Foot, all sides of a spinner must be occupied before anybody is allowed to play elsewhere. Matador has unusual rules for matching. Bendomino uses curved tiles, so one side of the line of play (or both) may be blocked for geometrical reasons.\n\nIn Mexican Train and other train games, the game starts with a spinner from which various trains branch off. Most trains are owned by a player and in most situations players are allowed to extend only their own train.\n\nIn blocking games, scoring happens at the end of the game. After a player has emptied his hand, thereby winning the game for the team, the score consists of the total pip count of the losing team's hands. In some rules, the pip count of the remaining stock is added. If a game is blocked because no player can move, the winner is often determined by adding the pips in players' hands.\n\nIn scoring games, each individual can potentially add to the score. For example, in Bergen, players score two points whenever they cause a configuration in which both open ends have the same value and three points if additionally one open end is formed by a double. In Muggins, players score by ensuring the total pip count of the open ends is a multiple of a certain number. In variants of Muggins, the line of play may branch due to spinners.\n\nIn British public houses and social clubs, a scoring version of \"5s-and-3s\" is used. The game is normally played in pairs (two against two) and is played as a series of \"ends\". In each \"end\", the objective is for players to attach a domino from their hand to one end of those already played so that the sum of the end dominoes is divisible by five or three. One point is scored for each time five or three can be divided into the sum of the two dominoes, i.e. four at one end and five at the other makes nine, which is divisible by three three times, resulting in three points. Double five at one end and five at the other makes 15, which is divisible by three five times (five points) and divisible by five three times (three points) for a total of eight points.\n\nAn \"end\" stops when one of the players is out, i.e., has played all of his dominoes. In the event no player is able to empty his hand, then the player with the lowest domino left in hand is deemed to be out and scores one point. A game consists of any number of ends with points scored in the ends accumulating towards a total. The game ends when one of the pair's total score exceeds a set number of points. A running total score is often kept on a cribbage board. 5s-and-3s is played in a number of competitive leagues in the British Isles.\n\nFor 40 years the game has been played by four people, with the winner being the first player to score 150 points, in multiples of five, by using 27 bones, using mathematical strategic defenses and explosive offense. At times, it has been played with pairs of partners. The double-six set is the preferred deck with the lowest denomination of game pieces, with 28 dominoes.\n\nIn many versions of the game, the player with the highest double leads with that double, for example \"double-six\". If no one has it, the next-highest double is called: \"double-five?\", then \"double-four?\", etc. until the highest double in any of the players' hands is played. If no player has an \"opening\" double, the next heaviest domino in the highest suit is called - \"six-five?\", \"six-four?\". In some variants, players take turns picking dominoes from the stock until an opening double is picked and played. In other variants, the hand is reshuffled and each player picks seven dominoes. After the first hand, the winner (or winning team) of the previous hand is allowed to pick first and begins by playing any domino in his or her hand.\n\nPlaying the first bone of a hand is sometimes called setting, leading, downing, or posing the first bone. Dominoes aficionados often call this procedure smacking down the bone. After each hand, bones are shuffled and each player draws the number of bones required, normally seven. Play proceeds clockwise. Players, in turn, must play a bone with an end that matches one of the open ends of the layouts.\n\nIn some versions of the games, the pips or points on the end, and the section to be played next to it must add up to a given number. For example, in a double-six set, the \"sum\" would be six, requiring a blank to be played next to a six, an ace (one) next to a five, a deuce (two) next to a four, etc.\n\nThe stock of bones left behind, if any, is called the bone yard, and the bones therein are said to be sleeping. In draw games, players take part in the bone selection, typically drawing from the bone yard when they do not have a \"match\" in their hands.\n\nIf a player inadvertently picks up and sees one or more extra dominoes, those dominoes become part of his or her hand.\n\nA player who can play a tile may be allowed to pass anyway. Passing can be signalled by tapping twice on the table or by saying \"go\" or \"pass\".\n\nPlay continues until one of the players has played all the dominoes in his or her hand, calls \"Out!\", \"I win\", or \"Domino!\" and wins the hand, or until all players are blocked and no legal plays remain. This is sometimes referred to as locked down or sewed up. In a common version of the game, the next player after the block picks up all the dominoes in the bone yard as if trying to find a (nonexistent) match. If all the players are blocked, or locked out, the player with the lowest hand (pip count) wins. In team play, the team with the lowest individual hand wins. In the case of a tie, the first of tied players or the first \"team\" in the play rotation wins.\n\nIn games where points accrue, the winning player scores a point for each pip on each bone still held by each opponent or the opposing team. If no player went out, the win is determined by the lightest hand, sometimes only the excess points held by opponents.\n\nA game is generally played to 100 points, the tally being kept on paper. In more common games, mainly urban rules, games are played to 150, 200, or 250 points.\n\nIn some games, the tally is kept by creating , where the beginning of the house (the first 10 points) is a large +, the next 10 points are O, and scoring with a five is a /, and are placed in the four corners of the house. One house is equal to 50 points.\n\nIn some versions, if a lock down occurs, the first person to call a lock-down gains the other players bones and adds the amount of the pips to his house. If a person who calls rocks after a call of lock-down or domino finds the number of pips a player called is incorrect, those points become his.\n\nWhen a player plays out of turn or draws another domino or knocks when he could have played and someone calls bogus play, the other person is awarded 50 points.\n\nApart from the usual blocking and scoring games, also domino games of a very different character are played, such as solitaire or trick-taking games. Most of these are adaptations of card games and were once popular in certain areas to circumvent religious proscriptions against playing cards.\nA very simple example is a Concentration variant played with a double-six set; two tiles are considered to match if their total pip count is 12.\n\nA popular domino game in Texas is 42. The game is similar to the card game spades. It is played with four players paired into teams. Each player draws seven dominoes, and the dominoes are played into tricks. Each trick counts as one point, and any domino with a multiple of five dots counts toward the total of the hand. These 35 points of \"five count\" and seven tricks equals 42 points, hence the name.\n\nDominoes is played at a professional level, similar to poker. Numerous organisations and clubs of amateur domino players exist around the world. Some organizations, including the \"Fédération Internationale de Domino (FIDO)\", organize international competitions. The 2008 and 2009 Double FIDO domino world champion from the UK is Darren Elhindi.\n\nBesides playing games, another use of dominoes is the domino show, which involves standing them on end in long lines so that when the first tile is toppled, it topples the second, which topples the third, etc., resulting in all of the tiles falling. By analogy, the phenomenon of small events causing similar events leading to eventual catastrophe is called the domino effect.\n\nArrangements of millions of tiles have been made that have taken many minutes, even hours to fall. For large and elaborate arrangements, special blockages (also known as firebreaks) are employed at regular distances to prevent a premature toppling from undoing more than a section of the dominoes while still being able to be removed without damage.\n\nThe phenomenon also has some theoretical relevance (amplifier, digital signal, information processing), and this amounts to the theoretical possibility of building domino computers. Dominoes are also commonly used as components in Rube Goldberg machines.\n\nThe Netherlands has hosted an annual domino-toppling exhibition called Domino Day since 1986. The event held on 18 November 2005 knocked over 4 million dominoes by a team from Weijers Domino Productions. On Domino Day 2008 (14 November 2008), the Weijers Domino Productions team attempted to set 10 records:\nThis record attempt was held in the WTC Expo hall in Leeuwarden. The artist who toppled the first stone was the Finnish acrobat Salima Peippo.\n\nAt one time, Pressman Toys manufactured a product called Domino Rally that contained tiles and mechanical devices for setting up toppling exhibits.\n\nIn Berlin on 9 November 2009, giant dominoes were toppled in a 20th-anniversary commemoration of the fall of the Berlin Wall. Former Polish president and Solidarity leader Lech Wałęsa set the toppling in motion.\n\nSince April 2008, the character encoding standard Unicode includes characters that represent the double-six domino tiles in various orientations. All combinations of blank through six pips on the left or right provides 49 glyphs, the same combinations vertically for another 49, and also a horizontal and a vertical \"back\" for a total of 100 glyphs. In this arrangement, both orientations are present: horizontally both tiles [1|6] and [6|1] exist, while a regular game set only has one such tile. The Unicode range for dominoes is U+1F030–U+1F09F. The naming pattern in Unicode is, by example, . Few fonts are known to support these glyphs. While the complete domino set has only 28 tiles, for printing layout reasons, the Unicode set needs both horizontal and vertical forms for each tile, plus the 01-03 (plain) 03-01 (reversed) pairs, and generic backsides.\n\n\n\n\n"}
{"id": "8263", "url": "https://en.wikipedia.org/wiki?curid=8263", "title": "Dissociation constant", "text": "Dissociation constant\n\nIn chemistry, biochemistry, and pharmacology, a dissociation constant (formula_1) is a specific type of equilibrium constant that measures the propensity of a larger object to separate (dissociate) reversibly into smaller components, as when a complex falls apart into its component molecules, or when a salt splits up into its component ions. The dissociation constant is the inverse of the association constant. In the special case of salts, the dissociation constant can also be called an ionization constant.\n\nFor a general reaction:\n\n</ce>\n\nin which a complex formula_2 breaks down into \"x\" A subunits and \"y\" B subunits, the dissociation constant is defined\n\nwhere [A], [B], and [AB] are the concentrations of A, B, and the complex AB, respectively.\n"}
{"id": "8267", "url": "https://en.wikipedia.org/wiki?curid=8267", "title": "Dimensional analysis", "text": "Dimensional analysis\n\nIn engineering and science, dimensional analysis is the analysis of the relationships between different physical quantities by identifying their base quantities (such as length, mass, time, and electric charge) and units of measure (such as miles vs. kilometers, or pounds vs. kilograms vs. grams) and tracking these dimensions as calculations or comparisons are performed. Converting from one dimensional unit to another is often somewhat complex. Dimensional analysis, or more specifically the factor-label method, also known as the unit-factor method, is a widely used technique for such conversions using the rules of algebra.\n\nThe concept of physical dimension was introduced by Joseph Fourier in 1822. Physical quantities that are of the same kind (also called \"commensurable\") have the same dimension (length, time, mass) and can be directly compared to each other, even if they are originally expressed in differing units of measure (such as inches and meters, or pounds and newtons). If physical quantities have different dimensions (such as length vs. mass), they cannot be expressed in terms of similar units and cannot be compared in quantity (also called \"incommensurable\"). For example, asking whether a kilogram is greater than, equal to, or less than an hour is meaningless.\n\nAny physically meaningful equation (and likewise any inequality and inequation) will have the same dimensions on its left and right sides, a property known as \"dimensional homogeneity\". Checking for dimensional homogeneity is a common application of dimensional analysis, serving as a plausibility check on derived equations and computations. It also serves as a guide and constraint in deriving equations that may describe a physical system in the absence of a more rigorous derivation.\n\nMany parameters and measurements in the physical sciences and engineering are expressed as a concrete number – a numerical quantity and a corresponding dimensional unit. Often a quantity is expressed in terms of several other quantities; for example, speed is a combination of length and time, e.g. 60 miles per hour or 1.4 kilometers per second. Compound relations with \"per\" are expressed with division, e.g. 60 mi/1 h. Other relations can involve multiplication (often shown with ⋅ or juxtaposition), powers (like m for square meters), or combinations thereof.\n\nA set of base units for a system of measurement is a conventionally chosen set of units, none of which can be expressed as a combination of the others, and in terms of which all the remaining units if the system can be expressed. For example, units for length and time are normally chosen as base units. Units for volume, however, can be factored into the base units of length (m), thus they are considered derived or compound units.\n\nSometimes the names of units obscure that they are derived units. For example, an ampere is a unit of electric current, which is equivalent to electric charge per unit time and is measured in coulombs (a unit of electrical charge) per second, so . Similarly, one newton is 1 kg⋅m/s.\n\nPercentages are dimensionless quantities, since they are ratios of two quantities with the same dimensions. In other words, the % sign can be read as \"1/100\", since .\n\nDerivatives with respect to a quantity add the dimensions of the variable one is differentiating with respect to on the denominator. Thus:\n\nIn economics, one distinguishes between stocks and flows: a stock has units of \"units\" (say, widgets or dollars), while a flow is a derivative of a stock, and has units of \"units/time\" (say, dollars/year).\n\nIn some contexts, dimensional quantities are expressed as dimensionless quantities or percentages by omitting some dimensions. For example, debt-to-GDP ratios are generally expressed as percentages: total debt outstanding (dimension of currency) divided by annual GDP (dimension of currency) – but one may argue that in comparing a stock to a flow, annual GDP should have dimensions of currency/time (dollars/year, for instance), and thus Debt-to-GDP should have units of years, which indicates that Debt-to-GDP is the number of years needed for a constant GDP to pay the debt, if all GDP is spent on the debt and the debt is otherwise unchanged.\n\nIn dimensional analysis, a ratio which converts one unit of measure into another without changing the quantity is called a conversion factor. For example, kPa and bar are both units of pressure, and . The rules of algebra allow both sides of an equation to be divided by the same expression, so this is equivalent to . Since any quantity can be multiplied by 1 without changing it, the expression \"\" can be used to convert from bars to kPa by multiplying it with the quantity to be converted, including units. For example, because , and bar/bar cancels out, so .\n\nThe most basic rule of dimensional analysis is that of dimensional homogeneity. Only commensurable quantities (physical quantities having the same dimension) may be \"compared,\" \"equated,\" \"added,\" or \"subtracted.\"\nHowever, the dimensions form a group under multiplication, so:\n\nFor example, it makes no sense to ask whether 1 hour is more, the same, or less than 1 kilometer, as these have different dimensions, nor to add 1 hour to 1 kilometer. However, it makes perfect sense to ask whether 1 mile is more, the same, or less than 1 kilometer being the same dimension of physical quantity even though the units are different. On the other hand, if an object travels 100 km in 2 hours, one may divide these and conclude that the object's average speed was 50 km/h.\n\nThe rule implies that in a physically meaningful \"expression\" only quantities of the same dimension can be added, subtracted, or compared. For example, if \"m\", \"m\" and \"L\" denote, respectively, the mass of some man, the mass of a rat and the length of that man, the dimensionally homogeneous expression is meaningful, but the heterogeneous expression is meaningless. However, \"m\"/\"L\" is fine. Thus, dimensional analysis may be used as a sanity check of physical equations: the two sides of any equation must be commensurable or have the same dimensions.\n\nEven when two physical quantities have identical dimensions, it may nevertheless be meaningless to compare or add them. For example, although torque and energy share the dimension , they are fundamentally different physical quantities.\n\nTo compare, add, or subtract quantities with the same dimensions but expressed in different units, the standard procedure is first to convert them all to the same units. For example, to compare 32 metres with 35 yards, use 1 yard = 0.9144 m to convert 35 yards to 32.004 m.\n\nA related principle is that any physical law that accurately describes the real world must be independent of the units used to measure the physical variables. For example, Newton's laws of motion must hold true whether distance is measured in miles or kilometers. This principle gives rise to the form that conversion factors must take between units that measure the same dimension: multiplication by a simple constant. It also ensures equivalence; for example, if two buildings are the same height in feet, then they must be the same height in meters.\n\nThe factor-label method is the sequential application of conversion factors expressed as fractions and arranged so that any dimensional unit appearing in both the numerator and denominator of any of the fractions can be cancelled out until only the desired set of dimensional units is obtained. For example, 10 miles per hour can be converted to meters per second by using a sequence of conversion factors as shown below:\n\nIt can be seen that each conversion factor is equivalent to the value of one. For example, starting with 1 mile = 1609.344 meters and dividing both sides of the equation by 1 mile yields 1 mile / 1 mile = 1609.344 meters / 1 mile, which when simplified yields 1 = 1609.344 meters / 1 mile.\n\nSo, when the units \"mile\" and \"hour\" are cancelled out and the arithmetic is done, 10 miles per hour converts to 4.4704 meters per second.\n\nAs a more complex example, the concentration of nitrogen oxides (i.e., formula_2) in the flue gas from an industrial furnace can be converted to a mass flow rate expressed in grams per hour (i.e., g/h) of formula_3 by using the following information as shown below:\n\n\nAfter cancelling out any dimensional units that appear both in the numerators and denominators of the fractions in the above equation, the NOx concentration of 10 ppm converts to mass flow rate of 24.63 grams per hour.\n\nThe factor-label method can also be used on any mathematical equation to check whether or not the dimensional units on the left hand side of the equation are the same as the dimensional units on the right hand side of the equation. Having the same units on both sides of an equation does not ensure that the equation is correct, but having different units on the two sides (when expressed in terms of base units) of an equation does allow one to conclude that the equation is wrong.\n\nFor example, check the Universal Gas Law equation of , when:\n\nAs can be seen, when the dimensional units appearing in the numerator and denominator of the equation's right hand side are cancelled out, both sides of the equation have the same dimensional units.\n\nThe factor-label method can convert only unit quantities for which the units are in a linear relationship intersecting at 0. Most units fit this paradigm. An example for which it cannot be used is the conversion between degrees Celsius and kelvins (or degrees Fahrenheit). Between degrees Celsius and kelvins, there is a constant difference rather than a constant ratio, while between degrees Celsius and degrees Fahrenheit there is neither a constant difference nor a constant ratio. There is, however, an affine transform (formula_6, rather than a linear transform formula_7) between them.\n\nFor example, the freezing point of water is 0 °C and 32 °F, and a 5 °C change is the same as a 9 °F change. Thus, to convert from units of Fahrenheit to units of Celsius, one subtracts 32 °F (the offset from the point of reference), divides by 9 °F and multiplies by 5 °C (scales by the ratio of units), and adds 0 °C (the offset from the point of reference). Reversing this yields the formula for obtaining a quantity in units of Celsius from units of Fahrenheit; one could have started with the equivalence between 100 °C and 212 °F, though this would yield the same formula at the end.\n\nHence, to convert the numerical quantity value of a temperature \"T\"[F] in degrees Fahrenheit to a numerical quantity value \"T\"[C] in degrees Celsius, this formula may be used:\n\nTo convert \"T\"[C] in degrees Celsius to \"T\"[F] in degrees Fahrenheit, this formula may be used:\n\nDimensional analysis is most often used in physics and chemistry – and in the mathematics thereof – but finds some applications outside of those fields as well.\n\nA simple application of dimensional analysis to mathematics is in computing the form of the volume of an \"n\"-ball (the solid ball in \"n\" dimensions), or the area of its surface, the \"n\"-sphere: being an \"n\"-dimensional figure, the volume scales as formula_8 while the surface area, being formula_9-dimensional, scales as formula_10 Thus the volume of the \"n\"-ball in terms of the radius is formula_11 for some constant formula_12 Determining the constant takes more involved mathematics, but the form can be deduced and checked by dimensional analysis alone.\n\nIn finance, economics, and accounting, dimensional analysis is most commonly referred to in terms of the distinction between stocks and flows. More generally, dimensional analysis is used in interpreting various financial ratios, economics ratios, and accounting ratios.\n\nCommon dimensionless groups in fluid mechanics include:\n\n\nThe origins of dimensional analysis have been disputed by historians. The 19th-century French mathematician Joseph Fourier is generally credited with having made important contributions based on the idea that physical laws like should be independent of the units employed to measure the physical variables. This led to the conclusion that meaningful laws must be homogeneous equations in their various units of measurement, a result which was eventually formalized in the Buckingham π theorem. However, the first application of dimensional analysis has been credited to the Italian scholar François Daviet de Foncenex (1734–1799). It was published in 1761, 61 years before the publication of Fourier’s work.\nJames Clerk Maxwell played a major role in establishing modern use of dimensional analysis by distinguishing mass, length, and time as fundamental units, while referring to other units as derived. Although Maxwell defined length, time and mass to be \"the three fundamental units\", he also noted that gravitational mass can be derived from length and time by assuming a form of Newton's law of universal gravitation in which the gravitational constant \"G\" is taken as unity, thereby defining . By assuming a form of Coulomb's law in which Coulomb's constant \"k\" is taken as unity, Maxwell then determined that the dimensions of an electrostatic unit of charge were , which, after substituting his equation for mass, results in charge having the same dimensions as mass, viz. .\n\nDimensional analysis is also used to derive relationships between the physical quantities that are involved in a particular phenomenon that one wishes to understand and characterize. It was used for the first time in this way in 1872 by Lord Rayleigh, who was trying to understand why the sky is blue. Rayleigh first published the technique in his 1877 book \"The Theory of Sound\".\n\nThe original meaning of the word \"dimension\", in Fourier's \"Theorie de la Chaleur\", was the numerical value of the exponents of the base units. For example, acceleration was considered to have the dimension 1 with respect to the unit of length, and the dimension −2 with respect to the unit of time. This was slightly changed by Maxwell, who said the dimensions of acceleration are LT, instead of just the exponents.\n\nThe Buckingham π theorem describes how every physically meaningful equation involving \"n\" variables can be equivalently rewritten as an equation of dimensionless parameters, where \"m\" is the rank of the dimensional matrix. Furthermore, and most importantly, it provides a method for computing these dimensionless parameters from the given variables.\n\nA dimensional equation can have the dimensions reduced or eliminated through nondimensionalization, which begins with dimensional analysis, and involves scaling quantities by characteristic units of a system or natural units of nature. This gives insight into the fundamental properties of the system, as illustrated in the examples below.\n\nThe dimension of a physical quantity can be expressed as a product of the basic physical dimensions length, mass, time, electric charge, and absolute temperature, represented by sans-serif roman symbols L, M, T, Q, and Θ, respectively, each raised to a rational power.\n\nThe SI standard recommends the usage of the following dimensions and corresponding symbols: length (L), mass (M), time (T), electric current (I), absolute temperature (Θ), amount of substance (N) and luminous intensity (J).\n\nThe \"dimension\" of a physical quantity is more fundamental than some \"scale\" unit used to express the amount of that physical quantity. For example, \"mass\" is a dimension, while the kilogram is a particular scale unit chosen to express a quantity of mass. Except for natural units, the choice of scale is cultural and arbitrary.\n\nAs examples, the dimension of the physical quantity speed is \"length\"/\"time\" (L/T, or LT), and the dimension of the physical quantity force is \"mass × acceleration\" or \"mass × (length/time)/time\" (ML/T, or MLT). Other physical quantity could be defined as the base quantities (such as momentum or energy or electric current) instead of some of those shown above. Temperature, Θ, need not be treated as a base quantity, since it may be regarded as the average energy per degree of freedom of a system of particles, which therefore can be expressed in terms of energy (or mass, length, and time). Some systems may not treat electric current, I, as a separate base quantity of physical quantity, such as the cgs system where it has been expressed in terms of mass, length, and time by defining Coulomb's constant as dimensionless. There are also physicists that have cast doubt on the very existence of incompatible fundamental dimensions of physical quantity, although this does not invalidate the usefulness of dimensional analysis.\n\nThe unit chosen to express a physical quantity and its dimension are related, but not identical concepts. The units of a physical quantity are defined by convention and related to some standard; e.g., length may have units of metres, feet, inches, miles or micrometres; but any length always has a dimension of L, no matter what units of length are chosen to express it. Two different units of the same physical quantity have conversion factors that relate them. For example, 1 in = 2.54 cm; in this case (2.54 cm/in) is the conversion factor, which is itself dimensionless and equal to 1. Therefore, multiplying by that conversion factor does not change a physical quantity. Dimensional symbols do not have conversion factors.\n\nThe dimensions that can be formed from a given collection of basic physical dimensions, such as M, L, and T, form an abelian group: The identity is written as 1; , and the inverse to L is 1/L or L. L raised to any rational power \"p\" is a member of the group, having an inverse of L or 1/L. The operation of the group is multiplication, having the usual rules for handling exponents ().\n\nThis group can be described as a vector space over the rational numbers, with for example dimensional symbol MLT corresponding to the vector . When physical measured quantities (be they like-dimensioned or unlike-dimensioned) are multiplied or divided by one other, their dimensional units are likewise multiplied or divided; this corresponds to addition or subtraction in the vector space. When measurable quantities are raised to a rational power, the same is done to the dimensional symbols attached to those quantities; this corresponds to scalar multiplication in the vector space.\n\nA basis for such a vector space of dimensional symbols is called a set of base quantities, and all other vectors are called derived units. As in any vector space, one may choose different bases, which yields different systems of units (e.g., choosing whether the unit for charge is derived from the unit for current, or vice versa).\n\nThe group identity 1, the dimension of dimensionless quantities, corresponds to the origin in this vector space.\n\nThe set of units of the physical quantities involved in a problem correspond to a set of vectors (or a matrix). The kernel describes some number (e.g., \"m\") of ways in which these vectors can be combined to produce a zero vector. These correspond to producing (from the measurements) a number of dimensionless quantities, {π, ..., π}. (In fact these ways completely span the null subspace of another different space, of powers of the measurements.) Every possible way of multiplying (and exponentiating) together the measured quantities to produce something with the same units as some derived quantity \"X\" can be expressed in the general form\n\nConsequently, every possible commensurate equation for the physics of the system can be rewritten in the form\n\nKnowing this restriction can be a powerful tool for obtaining new insight into the system.\n\nThe dimension of physical quantities if interest in mechanics can be expressed in terms of base dimensions M, L, and T – these form a 3-dimensional vector space. This is not the only valid choice of base dimensions, but it is the one most commonly used. For example, one might choose force, length and mass as the base dimensions (as some have done), with associated dimensions F, L, M; this corresponds to a different basis, and one may convert between these representations by a change of basis. The choice of the base set of dimensions is thus a convention, with the benefit of increased utility and familiarity. The choice of base dimensions is not arbitrary, because the dimensions must form a basis: they must span the space, and be linearly independent.\n\nFor example, F, L, M form a set of fundamental dimensions because they form a basis that is equivalent to M, L, T: the former can be expressed as [F = ML/T], L, M, while the latter can be expressed as M, L, [T = (ML/F)].\n\nOn the other hand, length, velocity and time do not form a set of as base dimensions, for two reasons:\n\nDepending on the field of physics, it may be advantageous to choose one or another extended set of dimensional symbols. In electromagnetism, for example, it may be useful to use dimensions of M, L, T, and Q, where Q represents the dimension of electric charge. In thermodynamics, the base set of dimensions is often extended to include a dimension for temperature, Θ. In chemistry the number of moles of substance (the number of molecules divided by Avogadro's constant, ≈ 6.02 × 10) is defined as a base unit as well.\nIn the interaction of relativistic plasma with strong laser pulses, a dimensionless relativistic similarity parameter, connected with the symmetry properties of the collisionless Vlasov equation, is constructed from the plasma-, electron- and critical-densities in addition to the electromagnetic vector potential. The choice of the dimensions or even the number of dimensions to be used in different fields of physics is to some extent arbitrary, but consistency in use and ease of communications are common and necessary features.\n\nScalar arguments to transcendental functions such as exponential, trigonometric and logarithmic functions, or to inhomogeneous polynomials, must be dimensionless quantities. (Note: this requirement is somewhat relaxed in Siano's orientational analysis described below, in which the square of certain dimensioned quantities are dimensionless.)\nWhile most mathematical identities about dimensionless numbers translate in a straightforward manner to dimensional quantities, care must be taken with logarithms of ratios: the identity log(a/b) = log a − log b, where the logarithm is taken in any base, holds for dimensionless numbers a and b, but it does \"not\" hold if a and b are dimensional, because in this case the left-hand side is well-defined but the right-hand side is not.\n\nSimilarly, while one can evaluate monomials (\"x\") of dimensional quantities, one cannot evaluate polynomials of mixed degree with dimensionless coefficients on dimensional quantities: for \"x\", the expression (3 m) = 9 m makes sense (as an area), while for \"x\" + \"x\", the expression (3 m) + 3 m = 9 m + 3 m does not make sense.\n\nHowever, polynomials of mixed degree can make sense if the coefficients are suitably chosen physical quantities that are not dimensionless. For example,\n\nThis is the height to which an object rises in time \"t\" if the acceleration of gravity is 32 feet per second per second and the initial upward speed is 500 feet per second. It is not even necessary for \"t\" to be in \"seconds\". For example, suppose \"t\" = 0.01 minutes. Then the first term would be\n\nThe value of a dimensional physical quantity \"Z\" is written as the product of a unit [\"Z\"] within the dimension and a dimensionless numerical factor, \"n\".\n\nWhen like-dimensioned quantities are added or subtracted or compared, it is convenient to express them in consistent units so that the numerical values of these quantities may be directly added or subtracted. But, in concept, there is no problem adding quantities of the same dimension expressed in different units. For example, 1 meter added to 1 foot is a length, but one cannot derive that length by simply adding 1 and 1. A conversion factor, which is a ratio of like-dimensioned quantities and is equal to the dimensionless unity, is needed:\n\nThe factor formula_23 is identical to the dimensionless 1, so multiplying by this conversion factor changes nothing. Then when adding two quantities of like dimension, but expressed in different units, the appropriate conversion factor, which is essentially the dimensionless 1, is used to convert the quantities to identical units so that their numerical values can be added or subtracted.\n\nOnly in this manner is it meaningful to speak of adding like-dimensioned quantities of differing units.\n\nSome discussions of dimensional analysis implicitly describe all quantities as mathematical vectors. (In mathematics scalars are considered a special case of vectors; vectors can be added to or subtracted from other vectors, and, inter alia, multiplied or divided by scalars. If a vector is used to define a position, this assumes an implicit point of reference: an origin. While this is useful and often perfectly adequate, allowing many important errors to be caught, it can fail to model certain aspects of physics. A more rigorous approach requires distinguishing between position and displacement (or moment in time versus duration, or absolute temperature versus temperature change).\n\nConsider points on a line, each with a position with respect to a given origin, and distances among them. Positions and displacements all have units of length, but their meaning is not interchangeable:\nThis illustrates the subtle distinction between \"affine\" quantities (ones modeled by an affine space, such as position) and \"vector\" quantities (ones modeled by a vector space, such as displacement).\n\nProperly then, positions have dimension of \"affine\" length, while displacements have dimension of \"vector\" length. To assign a number to an \"affine\" unit, one must not only choose a unit of measurement, but also a point of reference, while to assign a number to a \"vector\" unit only requires a unit of measurement.\n\nThus some physical quantities are better modeled by vectorial quantities while others tend to require affine representation, and the distinction is reflected in their dimensional analysis.\n\nThis distinction is particularly important in the case of temperature, for which the numeric value of absolute zero is not the origin 0 in some scales. For absolute zero,\nbut for temperature differences,\n(Here °R refers to the Rankine scale, not the Réaumur scale).\nUnit conversion for temperature differences is simply a matter of multiplying by, e.g., 1 °F / 1 K (although the ratio is not a constant value). But because some of these scales have origins that do not correspond to absolute zero, conversion from one temperature scale to another requires accounting for that. As a result, simple dimensional analysis can lead to errors if it is ambiguous whether 1 K means the absolute temperature equal to −273.15 °C, or the temperature difference equal to 1 °C.\n\nSimilar to the issue of a point of reference is the issue of orientation: a displacement in 2 or 3 dimensions is not just a length, but is a length together with a \"direction\". (This issue does not arise in 1 dimension, or rather is equivalent to the distinction between positive and negative.) Thus, to compare or combine two dimensional quantities in a multi-dimensional space, one also needs an orientation: they need to be compared to a frame of reference.\n\nThis leads to the extensions discussed below, namely Huntley's directed dimensions and Siano's orientational analysis.\n\nWhat is the period of oscillation of a mass attached to an ideal linear spring with spring constant suspended in gravity of strength ? That period is the solution for of some dimensionless equation in the variables , , , and .\nThe four quantities have the following dimensions: [T]; [M]; [M/T]; and [L/T]. From these we can form only one dimensionless product of powers of our chosen variables, formula_24 = formula_25 , and putting formula_26 for some dimensionless constant gives the dimensionless equation sought. The dimensionless product of powers of variables is sometimes referred to as a dimensionless group of variables; here the term \"group\" means \"collection\" rather than mathematical group. They are often called dimensionless numbers as well.\n\nNote that the variable does not occur in the group. It is easy to see that it is impossible to form a dimensionless product of powers that combines with , , and , because is the only quantity that involves the dimension L. This implies that in this problem the is irrelevant. Dimensional analysis can sometimes yield strong statements about the \"irrelevance\" of some quantities in a problem, or the need for additional parameters. If we have chosen enough variables to properly describe the problem, then from this argument we can conclude that the period of the mass on the spring is independent of : it is the same on the earth or the moon. The equation demonstrating the existence of a product of powers for our problem can be written in an entirely equivalent way: formula_27, for some dimensionless constant κ (equal to formula_28 from the original dimensionless equation).\n\nWhen faced with a case where dimensional analysis rejects a variable (, here) that one intuitively expects to belong in a physical description of the situation, another possibility is that the rejected variable is in fact relevant, but that some other relevant variable has been omitted, which might combine with the rejected variable to form a dimensionless quantity. That is, however, not the case here.\n\nWhen dimensional analysis yields only one dimensionless group, as here, there are no unknown functions, and the solution is said to be \"complete\" – although it still may involve unknown dimensionless constants, such as .\n\nConsider the case of a vibrating wire of length \"ℓ\" (L) vibrating with an amplitude \"A\" (L). The wire has a linear density \"ρ\" (M/L) and is under tension \"s\" (ML/T), and we want to know the energy \"E\" (ML/T) in the wire. Let \"π\" and \"π\" be two dimensionless products of powers of the variables chosen, given by\nThe linear density of the wire is not involved. The two groups found can be combined into an equivalent form as an equation\n\nwhere \"F\" is some unknown function, or, equivalently as\n\nwhere \"f\" is some other unknown function. Here the unknown function implies that our solution is now incomplete, but dimensional analysis has given us something that may not have been obvious: the energy is proportional to the first power of the tension. Barring further analytical analysis, we might proceed to experiments to discover the form for the unknown function \"f\". But our experiments are simpler than in the absence of dimensional analysis. We'd perform none to verify that the energy is proportional to the tension. Or perhaps we might guess that the energy is proportional to \"ℓ\", and so infer that . The power of dimensional analysis as an aid to experiment and forming hypotheses becomes evident.\n\nThe power of dimensional analysis really becomes apparent when it is applied to situations, unlike those given above, that are more complicated, the set of variables involved are not apparent, and the underlying equations hopelessly complex. Consider, for example, a small pebble sitting on the bed of a river. If the river flows fast enough, it will actually raise the pebble and cause it to flow along with the water. At what critical velocity will this occur? Sorting out the guessed variables is not so easy as before. But dimensional analysis can be a powerful aid in understanding problems like this, and is usually the very first tool to be applied to complex problems where the underlying equations and constraints are poorly understood. In such cases, the answer may depend on a dimensionless number such as the Reynolds number, which may be interpreted by dimensional analysis.\n\nConsider the case of a thin, solid, parallel-sided rotating disc of axial thickness \"t\" (L) and radius \"R\" (L). The disc has a density \"ρ\" (M/L), rotates at an angular velocity \"ω\" (T) and this leads to a stress \"S\" (MT in the material. There is a theoretical linear elastic solution, given by Lame, to this problem when the disc is thin relative to its radius, the faces of the disc are free to move axially, and the plane stress constitutive relations can be assumed to be valid. As the disc becomes thicker relative to the radius then the plane stress solution breaks down. If the disc is restrained axially on its free faces then a state of plane strain will occur. However, if this is not the case then the state of stress may only be determined though consideration of three-dimensional elasticity and there is no known theoretical solution for this case. An engineer might, therefore, be interested in establishing a relationship between the five variables. Dimensional analysis for this case leads to the following (5 − 3 = 2) non-dimensional groups:\n\nThrough the use of numerical experiments using, for example, the finite element method, the nature of the relationship between the two non-dimensional groups can be obtained as shown in the figure. As this problem only involves two non-dimensional groups, the complete picture is provided in a single plot and this can be used as a design/assessment chart for rotating discs \n\nHuntley has pointed out that it is sometimes productive to refine our concept of dimension. Two possible refinements are:\n\nAs an example of the usefulness of the first refinement, suppose we wish to calculate the distance a cannonball travels when fired with a vertical velocity component formula_32 and a horizontal velocity component formula_33, assuming it is fired on a flat surface. Assuming no use of directed lengths, the quantities of interest are then formula_33, formula_32, both dimensioned as LT, , the distance travelled, having dimension L, and the downward acceleration of gravity, with dimension LT.\n\nWith these four quantities, we may conclude that the equation for the range may be written:\n\nOr dimensionally\n\nfrom which we may deduce that formula_38 and formula_39, which leaves one exponent undetermined. This is to be expected since we have two fundamental dimensions L and T, and four parameters, with one equation.\n\nIf, however, we use directed length dimensions, then formula_33 will be dimensioned as LT, formula_32 as LT, as L and as LT. The dimensional equation becomes:\n\nand we may solve completely as formula_43, formula_44 and formula_45. The increase in deductive power gained by the use of directed length dimensions is apparent.\n\nIn a similar manner, it is sometimes found useful (e.g., in fluid mechanics and thermodynamics) to distinguish between mass as a measure of inertia (inertial mass), and mass as a measure of quantity (substantial mass). For example, consider the derivation of Poiseuille's Law. We wish to find the rate of mass flow of a viscous fluid through a circular pipe. Without drawing distinctions between inertial and substantial mass we may choose as the relevant variables\n\nThere are three fundamental variables so the above five equations will yield two dimensionless variables which we may take to be formula_48 and formula_49 and we may express the dimensional equation as\n\nwhere and are undetermined constants. If we draw a distinction between inertial mass with dimension formula_51 and substantial mass with dimension formula_52, then mass flow rate and density will use substantial mass as the mass parameter, while the pressure gradient and coefficient of viscosity will use inertial mass. We now have four fundamental parameters, and one dimensionless constant, so that the dimensional equation may be written:\n\nwhere now only is an undetermined constant (found to be equal to formula_54 by methods outside of dimensional analysis). This equation may be solved for the mass flow rate to yield Poiseuille's law.\n\nHuntley's extension has some serious drawbacks:\n\n\nIt also is often quite difficult to assign the L, L, L, L, symbols to the physical variables involved in the problem of interest. He invokes a procedure that involves the \"symmetry\" of the physical problem. This is often very difficult to apply reliably: It is unclear as to what parts of the problem that the notion of \"symmetry\" is being invoked. Is it the symmetry of the physical body that forces are acting upon, or to the points, lines or areas at which forces are being applied? What if more than one body is involved with different symmetries? Consider the spherical bubble attached to a cylindrical tube, where one wants the flow rate of air as a function of the pressure difference in the two parts. What are the Huntley extended dimensions of the viscosity of the air contained in the connected parts? What are the extended dimensions of the pressure of the two parts? Are they the same or different? These difficulties are responsible for the limited application of Huntley's addition to real problems.\nAngles are, by convention, considered to be dimensionless variables, and so the use of angles as physical variables in dimensional analysis can give less meaningful results. As an example, consider the projectile problem mentioned above. Suppose that, instead of the x- and y-components of the initial velocity, we had chosen the magnitude of the velocity and the angle at which the projectile was fired. The angle is, by convention, considered to be dimensionless, and the magnitude of a vector has no directional quality, so that no dimensionless variable can be composed of the four variables , , , and . Conventional analysis will correctly give the powers of and , but will give no information concerning the dimensionless angle .\n\nNote that the orientational symbols form a group (the Klein four-group or \"Viergruppe\"). In this system, scalars always have the same orientation as the identity element, independent of the \"symmetry of the problem\". Physical quantities that are vectors have the orientation expected: a force or a velocity in the z-direction has the orientation of . For angles, consider an angle that lies in the z-plane. Form a right triangle in the z-plane with being one of the acute angles. The side of the right triangle adjacent to the angle then has an orientation and the side opposite has an orientation . Then, since we conclude that an angle in the xy-plane must have an orientation , which is not unreasonable. Analogous reasoning forces the conclusion that has orientation while has orientation 1. These are different, so one concludes (correctly), for example, that there are no solutions of physical equations that are of the form , where and are real scalars. Note that an expression such as formula_56 is not dimensionally inconsistent since it is a special case of the sum of angles formula and should properly be written:\n\nwhich for formula_58 and formula_59 yields formula_60. Physical quantities may be expressed as complex numbers (e.g. formula_61) which imply that the complex quantity has an orientation equal to that of the angle it is associated with ( in the above example).\n\nThe assignment of orientational symbols to physical quantities and the requirement that physical equations be orientationally homogeneous can actually be used in a way that is similar to dimensional analysis to derive a little more information about acceptable solutions of physical problems. In this approach one sets up the dimensional equation and solves it as far as one can. If the lowest power of a physical variable is fractional, both sides of the solution is raised to a power such that all powers are integral. This puts it into \"normal form\". The orientational equation is then solved to give a more restrictive condition on the unknown powers of the orientational symbols, arriving at a solution that is more complete than the one that dimensional analysis alone gives. Often the added information is that one of the powers of a certain variable is even or odd.\n\nAs an example, for the projectile problem, using orientational symbols, θ, being in the xy-plane will thus have dimension and the range of the projectile will be of the form:\n\nDimensional homogeneity will now correctly yield and , and orientational homogeneity requires that be an odd integer. In fact the required function of theta will be which is a series of odd powers of .\n\nIt is seen that the Taylor series of and are orientationally homogeneous using the above multiplication table, while expressions like and are not, and are (correctly) deemed unphysical.\nIt should be clear that the multiplication rule used for the orientational symbols is not the same as that for the cross product of two vectors. The cross product of two identical vectors is zero, while the product of two identical orientational symbols is the identity element.\n\nThe dimensionless constants that arise in the results obtained, such as the C in the Poiseuille's Law problem and the formula_63 in the spring problems discussed above come from a more detailed analysis of the underlying physics, and often arises from integrating some differential equation. Dimensional analysis itself has little to say about these constants, but it is useful to know that they very often have a magnitude of order unity. This observation can allow one to sometimes make \"back of the envelope\" calculations about the phenomenon of interest, and therefore be able to more efficiently design experiments to measure it, or to judge whether it is important, etc.\n\nParadoxically, dimensional analysis can be a useful tool even if all the parameters in the underlying theory are dimensionless, e.g., lattice models such as the Ising model can be used to study phase transitions and critical phenomena. Such models can be formulated in a purely dimensionless way. As we approach the critical point closer and closer, the distance over which the variables in the lattice model are correlated (the so-called correlation length, formula_64 ) becomes larger and larger. Now, the correlation length is the relevant length scale related to critical phenomena, so one can, e.g., surmise on \"dimensional grounds\" that the non-analytical part of the free energy per lattice site should be formula_65 where formula_66 is the dimension of the lattice.\n\nIt has been argued by some physicists, e.g., M. J. Duff, that the laws of physics are inherently dimensionless. The fact that we have assigned incompatible dimensions to Length, Time and Mass is, according to this point of view, just a matter of convention, borne out of the fact that before the advent of modern physics, there was no way to relate mass, length, and time to each other. The three independent dimensionful constants: \"c\", \"ħ\", and \"G\", in the fundamental equations of physics must then be seen as mere conversion factors to convert Mass, Time and Length into each other.\n\nJust as in the case of critical properties of lattice models, one can recover the results of dimensional analysis in the appropriate scaling limit; e.g., dimensional analysis in mechanics can be derived by reinserting the constants \"ħ\", \"c\", and \"G\" (but we can now consider them to be dimensionless) and demanding that a nonsingular relation between quantities exists in the limit formula_67, formula_68 and formula_69. In problems involving a gravitational field the latter limit should be taken such that the field stays finite.\n\nFollowing are tables of commonly occurring expressions in physics, related to the dimensions of energy, momentum, and force.\n\nIf , where \"c\" is the speed of light and \"ħ\" is the reduced Planck constant, and a suitable fixed unit of energy is chosen, then all quantities of length \"L\", mass \"M\" and time \"T\" can be expressed (dimensionally) as a power of energy \"E\", because length, mass and time can be expressed using speed \"v\", action \"S\", and energy \"E\":\n\nthough speed and action are dimensionless ( and ) – so the only remaining quantity with dimension is energy. In terms of powers of dimensions:\n\nThis is particularly useful in particle physics and high energy physics, in which case the energy unit is the electron volt (eV). Dimensional checks and estimates become very simple in this system.\n\nHowever, if electric charges and currents are involved, another unit to be fixed is for electric charge, normally the electron charge \"e\" though other choices are possible.\n\n\n\n\n\n"}
{"id": "8270", "url": "https://en.wikipedia.org/wiki?curid=8270", "title": "December 25", "text": "December 25\n\n\n"}
{"id": "8271", "url": "https://en.wikipedia.org/wiki?curid=8271", "title": "Digital television", "text": "Digital television\n\nDigital television (DTV) is the transmission of audio and video by digitally processed and multiplexed signal, in contrast to the totally analog and channel separated signals used by analog television. Digital TV can support more than one program in the same channel bandwidth. It is an innovative service that represents the first significant evolution in television technology since color television in the 1950s. Several regions of the world are in different stages of adaptation and are implementing different broadcasting standards. Below are the different widely used digital television broadcasting standards (DTB):\n\nDigital TV's roots have been tied very closely to the availability of inexpensive, high performance computers. It wasn't until the 1990s that digital TV became a real possibility.\n\nIn the mid-1980s, as Japanese consumer electronics firms forged ahead with the development of HDTV technology, and as the MUSE analog format was proposed by NHK, a Japanese company, Japanese advancements were seen as pacesetters that threatened to eclipse U.S. electronics companies. Until June 1990, the Japanese MUSE standard—based on an analog system—was the front-runner among the more than 23 different technical concepts under consideration. Then, an American company, General Instrument, demonstrated the feasibility of a digital television signal. This breakthrough was of such significance that the FCC was persuaded to delay its decision on an ATV standard until a digitally based standard could be developed.\n\nIn March 1990, when it became clear that a digital standard was feasible, the FCC made a number of critical decisions. First, the Commission declared that the new ATV standard must be more than an enhanced analog signal, but be able to provide a genuine HDTV signal with at least twice the resolution of existing television images. Then, to ensure that viewers who did not wish to buy a new digital television set could continue to receive conventional television broadcasts, it dictated that the new ATV standard must be capable of being \"simulcast\" on different channels. The new ATV standard also allowed the new DTV signal to be based on entirely new design principles. Although incompatible with the existing NTSC standard, the new DTV standard would be able to incorporate many improvements.\n\nThe final standard adopted by the FCC did not require a single standard for scanning formats, aspect ratios, or lines of resolution. This outcome resulted from a dispute between the consumer electronics industry (joined by some broadcasters) and the computer industry (joined by the film industry and some public interest groups) over which of the two scanning processes—interlaced or progressive—is superior. Interlaced scanning, which is used in televisions worldwide, scans even-numbered lines first, then odd-numbered ones. Progressive scanning, which is the format used in computers, scans lines in sequences, from top to bottom. The computer industry argued that progressive scanning is superior because it does not \"flicker\" in the manner of interlaced scanning. It also argued that progressive scanning enables easier connections with the Internet, and is more cheaply converted to interlaced formats than vice versa. The film industry also supported progressive scanning because it offers a more efficient means of converting filmed programming into digital formats. For their part, the consumer electronics industry and broadcasters argued that interlaced scanning was the only technology that could transmit the highest quality pictures then (and currently) feasible, i.e., 1,080 lines per picture and 1,920 pixels per line. Broadcasters also favored interlaced scanning because their vast archive of interlaced programming is not readily compatible with a progressive format.\n\nDigital television supports many different picture formats defined by the broadcast television systems which are a combination of size and aspect ratio (width to height ratio).\n\nWith digital terrestrial television (DTT) broadcasting, the range of formats can be broadly divided into two categories: high definition television (HDTV) for the transmission of high-definition video and standard-definition television (SDTV). These terms by themselves are not very precise, and many subtle intermediate cases exist.\n\nOne of several different HDTV formats that can be transmitted over DTV is: 1280 × 720 pixels in progressive scan mode (abbreviated \"720p\") or 1920 × 1080 pixels in interlaced video mode (\"1080i\"). Each of these uses a aspect ratio. (Some televisions are capable of receiving an HD resolution of 1920 × 1080 at a 60 Hz progressive scan frame rate — known as 1080p.) HDTV cannot be transmitted over analog television channels because of channel capacity issues.\n\nStandard definition TV (SDTV), by comparison, may use one of several different formats taking the form of various aspect ratios depending on the technology used in the country of broadcast. In terms of square pixels, NTSC countries can deliver a 640 x 480 resolution in 4:3 and 854 x 480 in , while PAL can give 768 x 576 in and 1024 x 576 in . However, broadcasters may choose to reduce these resolutions to reduce bit rate (e.g., many DVB-T channels in the United Kingdom use a horizontal resolution of 544 or 704 pixels per line).\n\nEach commercial broadcasting terrestrial television DTV channel in North America is permitted to be broadcast at a bit rate up to 19 megabits per second. However, the broadcaster does not need to use this entire bandwidth for just one broadcast channel. Instead the broadcast can use the channel to include PSIP and can also subdivide across several video subchannels (a.k.a. feeds) of varying quality and compression rates, including non-video datacasting services that allow one-way high-bit-rate streaming of data to computers like National Datacast.\n\nA broadcaster may opt to use a standard-definition (SDTV) digital signal instead of an HDTV signal, because current convention allows the bandwidth of a DTV channel (or \"multiplex\") to be subdivided into multiple digital subchannels, (similar to what most FM radio stations offer with HD Radio), providing multiple feeds of entirely different television programming on the same channel. This ability to provide either a single HDTV feed or multiple lower-resolution feeds is often referred to as distributing one's \"bit budget\" or multicasting. This can sometimes be arranged automatically, using a statistical multiplexer (or \"stat-mux\"). With some implementations, image resolution may be less directly limited by bandwidth; for example in DVB-T, broadcasters can choose from several different modulation schemes, giving them the option to reduce the transmission bit rate and make reception easier for more distant or mobile viewers.\n\nThere are several different ways to receive digital television. One of the oldest means of receiving DTV (and TV in general) is from terrestrial transmitters using an antenna (known as an \"aerial\" in some countries). This way is known as Digital terrestrial television (DTT). With DTT, viewers are limited to channels that have a terrestrial transmitter in range of their antenna.\n\nOther ways have been devised to receive digital television. Among the most familiar to people are digital cable and digital satellite. In some countries where transmissions of TV signals are normally achieved by microwaves, digital MMDS is used. Other standards, such as Digital multimedia broadcasting (DMB) and DVB-H, have been devised to allow handheld devices such as mobile phones to receive TV signals. Another way is IPTV, that is receiving TV via Internet Protocol, relying on digital subscriber line (DSL) or optical cable line. Finally, an alternative way is to receive digital TV signals via the open Internet (Internet television), whether from a central streaming service or a P2P (peer-to-peer) system.\n\nSome signals carry encryption and specify use conditions (such as \"may not be recorded\" or \"may not be viewed on displays larger than 1 m in diagonal measure\") backed up with the force of law under the World Intellectual Property Organization Copyright Treaty (WIPO Copyright Treaty) and national legislation implementing it, such as the U.S. Digital Millennium Copyright Act. Access to encrypted channels can be controlled by a removable smart card, for example via the Common Interface (DVB-CI) standard for Europe and via Point Of Deployment (POD) for IS or named differently CableCard.\n\nDigital television signals must not interfere with each other, and they must also coexist with analog television until it is phased out.\nThe following table gives allowable signal-to-noise and signal-to-interference ratios for various interference scenarios. This table is a crucial regulatory tool for controlling the placement and power levels of stations. Digital TV is more tolerant of interference than analog TV, and this is the reason a smaller range of channels can carry an all-digital set of television stations.\n\nPeople can interact with a DTV system in various ways. One can, for example, browse the electronic program guide. Modern DTV systems sometimes use a return path providing feedback from the end user to the broadcaster. This is possible with a coaxial or fiber optic cable, a dialup modem, or Internet connection but is not possible with a standard antenna.\n\nSome of these systems support video on demand using a communication channel localized to a neighborhood rather than a city (terrestrial) or an even larger area (satellite).\n\n1seg (1-segment) is a special form of ISDB. Each channel is further divided into 13 segments. The 12 segments of them are allocated for HDTV and remaining segment, the 13th, is used for narrow-band receivers such as mobile television or cell phone.\n\nDTV has several advantages over analog TV, the most significant being that digital channels take up less bandwidth, and the bandwidth needs are continuously variable, at a corresponding reduction in image quality depending on the level of compression as well as the resolution of the transmitted image. This means that digital broadcasters can provide more digital channels in the same space, provide high-definition television service, or provide other non-television services such as multimedia or interactivity. DTV also permits special services such as multiplexing (more than one program on the same channel), electronic program guides and additional languages (spoken or subtitled). The sale of non-television services may provide an additional revenue source.\n\nDigital and analog signals react to interference differently. For example, common problems with analog television include ghosting of images, noise from weak signals, and many other potential problems which degrade the quality of the image and sound, although the program material may still be watchable. With digital television, the audio and video must be synchronized digitally, so reception of the digital signal must be very nearly complete; otherwise, neither audio nor video will be usable. Short of this complete failure, \"blocky\" video is seen when the digital signal experiences interference.\n\nAnalog TV started off with monophonic sound, and later evolved to stereophonic sound with two independent audio signal channels. DTV will allow up to 5 audio signal channels plus a sub-woofer bass channel, with broadcasts similar in quality to movie theaters and DVDs.\n\nDTV images have some picture defects that are not present on analog television or motion picture cinema, because of present-day limitations of bit rate and compression algorithms such as MPEG-2. This defect is sometimes referred to as \"mosquito noise\".\n\nBecause of the way the human visual system works, defects in an image that are localized to particular features of the image or that come and go are more perceptible than defects that are uniform and constant. However, the DTV system is designed to take advantage of other limitations of the human visual system to help mask these flaws, e.g. by allowing more compression artifacts during fast motion where the eye cannot track and resolve them as easily and, conversely, minimizing artifacts in still backgrounds that may be closely examined in a scene (since time allows).\n\nChanges in signal reception from factors such as degrading antenna connections or changing weather conditions may gradually reduce the quality of analog TV. The nature of digital TV results in a perfectly decodable video initially, until the receiving equipment starts picking up interference that overpowers the desired signal or if the signal is too weak to decode. Some equipment will show a garbled picture with significant damage, while other devices may go directly from perfectly decodable video to no video at all or lock up. This phenomenon is known as the digital cliff effect.\n\nFor remote locations, distant channels that, as analog signals, were previously usable in a snowy and degraded state may, as digital signals, be perfectly decodable or may become completely unavailable. The use of higher frequencies will add to these problems, especially in cases where a clear line-of-sight from the receiving antenna to the transmitter is not available.\n\nTelevision sets with only analog tuners cannot decode digital transmissions. When analog broadcasting over the air ceases, users of sets with analog-only tuners may use other sources of programming (e.g. cable, recorded media) or may purchase set-top converter boxes to tune in the digital signals. In the United States, a government-sponsored coupon was available to offset the cost of an external converter box. Analog switch-off (of full-power stations) took place on December 11, 2006 in The Netherlands, June 12, 2009 in the United States for full-power stations, and later for Class-A Stations on September 1, 2016, July 24, 2011 in Japan, August 31, 2011 in Canada, February 13, 2012 in Arab states, May 1, 2012 in Germany, October 24, 2012 in the United Kingdom and Ireland, October 31, 2012 in selected Indian cities, and December 10, 2013 in Australia. Completion of analog switch-off is scheduled for December 31, 2017 in the whole of India, December 2018 in Costa Rica and around 2020 for the Philippines.\n\nPrior to the conversion to digital TV, analog television broadcast audio for TV channels on a separate FM carrier signal from the video signal. This FM audio signal could be heard using standard radios equipped with the appropriate tuning circuits.\n\nHowever, after the transition of many countries to digital TV, no portable radio manufacturer has yet developed an alternative method for portable radios to play just the audio signal of digital TV channels. (DTV radio is not the same thing.)\n\nThe adoption of a broadcast standard incompatible with existing analog receivers has created the problem of large numbers of analog receivers being discarded during digital television transition. One superintendent of Public Works was quoted in 2009 as saying, \"Some of the studies I’ve read in the trade magazines say up to a quarter of American households could be throwing a TV out in the next two years following the regulation change\". In 2009, an estimated 99 million analog TV receivers were sitting unused in homes in the US alone and, while some obsolete receivers are being retrofitted with converters, many more are simply dumped in landfills where they represent a source of toxic metals such as lead as well as lesser amounts of materials such as barium, cadmium and chromium.\n\nAccording to one campaign group, a CRT computer monitor or TV contains an average of of lead. According to another source, the lead in glass of a CRT varies from 1.08 lb to 11.28 lb, depending on screen size and type, but the lead is in the form of \"stable and immobile\" lead oxide mixed into the glass. It is claimed that the lead can have long-term negative effects on the environment if dumped as landfill. However, the glass envelope can be recycled at suitably equipped facilities. Other portions of the receiver may be subject to disposal as hazardous material.\n\nLocal restrictions on disposal of these materials vary widely; in some cases second-hand stores have refused to accept working color television receivers for resale due to the increasing costs of disposing of unsold TVs. Those thrift stores which are still accepting donated TVs have reported significant increases in good-condition working used television receivers abandoned by viewers who often expect them not to work after digital transition.\n\nIn Michigan in 2009, one recycler estimated that as many as one household in four would dispose of or recycle a TV set in the following year. The digital television transition, migration to high-definition television receivers and the replacement of CRTs with flatscreens are all factors in the increasing number of discarded analog CRT-based television receivers.\n\n\n\n"}
{"id": "8274", "url": "https://en.wikipedia.org/wiki?curid=8274", "title": "Declaration of Arbroath", "text": "Declaration of Arbroath\n\nThe Declaration of Arbroath is a declaration of Scottish independence, made in 1320. It is in the form of a letter in Latin submitted to Pope John XXII, dated 6 April 1320, intended to confirm Scotland's status as an independent, sovereign state and defending Scotland's right to use military action when unjustly attacked.\n\nGenerally believed to have been written in the Arbroath Abbey by Bernard of Kilwinning, then Chancellor of Scotland and Abbot of Arbroath, and sealed by fifty-one magnates and nobles, the letter is the sole survivor of three created at the time. The others were a letter from the King of Scots, Robert I, and a letter from four Scottish bishops which all presumably made similar points.\n\nThe Declaration was part of a broader diplomatic campaign which sought to assert Scotland's position as an independent kingdom, rather than being a feudal land controlled by England's Norman kings, as well as lift the excommunication of Robert the Bruce. The Pope had recognised Edward I of England's claim to overlordship of Scotland in 1305 and Bruce was excommunicated by the Pope for murdering John Comyn before the altar in Greyfriars Church in Dumfries in 1306.\n\nThe Declaration made a number of points: that Scotland had always been independent, indeed for longer than England; that Edward I of England had unjustly attacked Scotland and perpetrated atrocities; that Robert the Bruce had delivered the Scottish nation from this peril; and, most controversially, that the independence of Scotland was the prerogative of the Scottish people, rather than the King of Scots. In fact it stated that the nobility would choose someone else to be king if Bruce proved to be unfit in maintaining Scotland's independence.\n\nSome have interpreted this last point as an early expression of 'popular sovereignty' – that government is contractual and that kings can be chosen by the community rather than by God alone. Modern Scottish nationalists point to the “Declaration\" as evidence of the long-term persistence of the Scots as a distinct national community, giving a very early date for the emergence of nationalism. However \"the overwhelming majority of academics challenge this vision. Scholars point out that definitions change with time. The meaning ascribed to words similar to nation during the ancient and medieval periods was often quite different than it is today.\"\n\nIt has also been argued that the Declaration was not a statement of popular sovereignty (and that its signatories would have had no such concept) but a statement of royal propaganda supporting Bruce's faction. A justification had to be given for the rejection of King John Balliol in whose name William Wallace and Andrew de Moray had rebelled in 1297. The reason given in the Declaration is that Bruce was able to defend Scotland from English aggression whereas, by implication, King John could not.\n\nWhatever the true motive, the idea of a contract between King and people was advanced to the Pope as a justification for Bruce's coronation whilst John de Balliol still lived in Papal custody.\n\nThere are 39 names—eight earls and thirty one barons—at the start of the document, all of whom may have had their seals appended, probably over the space of some weeks and months, with nobles sending in their seals to be used. On the extant copy of the Declaration there are only 19 seals, and of those 19 people only 12 are named within the document. It is thought likely that at least 11 more seals than the original 39 might have been appended. The Declaration was then taken to the papal court at Avignon by Bishop Kininmund, Sir Adam Gordon and Sir Odard de Maubuisson.\nThe Pope heeded the arguments contained in the Declaration, influenced by the offer of support from the Scots for his long-desired crusade if they no longer had to fear English invasion. He exhorted Edward II in a letter to make peace with the Scots, but the following year was again persuaded by the English to take their side and issued six bulls to that effect.\n\nOn 1 March 1328 the new English king, Edward III signed a peace treaty between Scotland and England, the Treaty of Edinburgh-Northampton. In this treaty, which was in effect for five years until 1333, Edward renounced all English claims to Scotland. Eight months later, in October 1328, the interdict on Scotland, and the excommunication of its king, were removed by the Pope.\n\nThe original copy of the Declaration that was sent to Avignon is lost. A copy of the Declaration survives among Scotland's state papers, held by the National Archives of Scotland in Edinburgh. The most widely known English language translation was made by Sir James Fergusson, formerly Keeper of the Records of Scotland, from text that he reconstructed using this extant copy and early copies of the original draft. One passage in particular, strongly suggesting Sallust (86–35 BC) as the direct source, is often quoted from the Fergusson translation:\n\nHere are the signatories of the Declaration of Arbroath in 1320. They are an interesting list; although it includes several consistent Bruce loyalists, it includes others who had opposed Bruce, or whom Bruce tried for plotting against him a few months later, and some shadowy figures of whom little is known.\n\nThe declaration itself is written in Latin. It uses the Latin versions of the signatories' titles, and in some cases the spelling of names has changed over the years. This list generally uses the titles of the signatories' Wikipedia biographies.\n\nDuncan, Earl of Fife (changed sides in 1332)\n<br>Thomas Randolph, Earl of Moray (important Bruce supporter although briefly fought for the English in the past)\n<br>Patrick Dunbar, Earl of March (or Earl of Dunbar) (changed sides a few times)\n<br>Malise, Earl of Strathearn (Bruce loyalist) \n<br>Malcolm, Earl of Lennox (Bruce loyalist)\n<br>William, Earl of Ross (earlier betrayed Bruce's female relatives to the English)\n<br>Magnús Jónsson, Earl of Orkney\n<br>William de Moravia, Earl of Sutherland\n<br>Walter, High Steward of Scotland (Bruce loyalist)\n<br>William de Soules, Butler of Scotland (later imprisoned for plotting against Bruce) \n<br>Sir James Douglas (leading Bruce loyalist)\n<br>Roger Mowbray\n<br>David, Lord of Brechin (later executed for plotting against Bruce)\n<br>David Graham\n<br>Ingram de Umfraville (fought on the English side at Bannockburn)\n<br>John de Menteith, guardian of the earldom of Menteith (earlier betrayed William Wallace to the English)\n<br>Alexander Fraser of Touchfraser and Cowie \n<br>Gilbert de la Hay, Constable of Scotland (Bruce loyalist) \n<br>Robert Keith, Marischal of Scotland (Bruce loyalist) \n<br>Henry Sinclair\n<br>John Graham\n<br>David Lindsay\n<br>William Oliphant (briefly fought for the English) \n<br>Patrick Graham\n<br>John Fenton\n<br>William Abernethy\n<br>David Wemyss \n<br>William Mushet\n<br>Fergus of Ardrossan\n<br>Eustace Maxwell\n<br>William Ramsay \n<br>Lachlan MacLean\n<br>William de Monte Alto\n<br>Alan Murray\n<br>Donald Campbell\n<br>John Cameron\n<br>Reginald le Chen\n<br>Alexander Seton \n<br>Andrew Leslie \n<br>Alexander Straiton\n\nIn addition, the names of the following do not appear in the document's text, but their names are written on seal tags and their seals are present:\n\nAlexander de Lamberton (became a supporter of Edward Balliol after the Battle of Dupplin Moor, 1332)\n<br>Edward Keith (subsequently Marischal of Scotland; d. 1346)\n<br>Arthur Campbell (Bruce loyalist)\n<br>Thomas de Menzies (Bruce loyalist)\n<br>John de Inchmartin (became a supporter of Edward Balliol after the Battle of Dupplin Moor, 1332; d. after 1334)\n<br>John Duraunt\n<br>Thomas de Morham\n\nUS Senate Resolution 155 of 10 November 1997 states that the Declaration of Arbroath, the Scottish Declaration of Independence [sic], was signed on April 6, 1320 and the American Declaration of Independence was modeled on that inspirational document. However, although this influence is accepted by some historians, it is disputed by others. Even advocates of the link concede that it is speculative and not based on any verifiable sources.\n\nIn 2016 the Declaration of Arbroath was placed on UNESCO's Memory of the World register.\n\n\n\n"}
{"id": "8276", "url": "https://en.wikipedia.org/wiki?curid=8276", "title": "Digital data", "text": "Digital data\n\nDigital data, in information theory and information systems, are discrete, discontinuous representations of information or works, as contrasted with continuous, or analog signals which behave in a continuous manner, or represent information using a continuous function.\n\nAlthough digital representations are the subject matter of discrete mathematics, the information represented can be either discrete, such as numbers and letters, or it can be continuous, such as sounds, images, and other measurements.\n\nThe word \"digital\" comes from the same source as the words digit and \"digitus\" (the Latin word for \"finger\"), as fingers are often used for discrete counting. Mathematician George Stibitz of Bell Telephone Laboratories used the word \"digital\" in reference to the fast electric pulses emitted by a device designed to aim and fire anti-aircraft guns in 1942. The term is most commonly used in computing and electronics, especially where real-world information is converted to binary numeric form as in digital audio and digital photography.\n\nSince symbols (for example, alphanumeric characters) are not continuous, representing symbols digitally is rather simpler than conversion of continuous or analog information to digital. Instead of sampling and quantization as in analog-to-digital conversion, such techniques as polling and encoding are used.\n\nA symbol input device usually consists of a group of switches that are polled at regular intervals to see which switches are switched. Data will be lost if, within a single polling interval, two switches are pressed, or a switch is pressed, released, and pressed again. This polling can be done by a specialized processor in the device to prevent burdening the main CPU. When a new symbol has been entered, the device typically sends an interrupt, in a specialized format, so that the CPU can read it.\n\nFor devices with only a few switches (such as the buttons on a joystick), the status of each can be encoded as bits (usually 0 for released and 1 for pressed) in a single word. This is useful when combinations of key presses are meaningful, and is sometimes used for passing the status of modifier keys on a keyboard (such as shift and control). But it does not scale to support more keys than the number of bits in a single byte or word.\n\nDevices with many switches (such as a computer keyboard) usually arrange these switches in a scan matrix, with the individual switches on the intersections of x and y lines. When a switch is pressed, it connects the corresponding x and y lines together. Polling (often called scanning in this case) is done by activating each x line in sequence and detecting which y lines then have a signal, thus which keys are pressed. When the keyboard processor detects that a key has changed state, it sends a signal to the CPU indicating the scan code of the key and its new state. The symbol is then encoded, or converted into a number, based on the status of modifier keys and the desired character encoding.\n\nA custom encoding can be used for a specific application with no loss of data. However, using a standard encoding such as ASCII is problematic if a symbol such as 'ß' needs to be converted but is not in the standard.\n\nIt is estimated that in the year 1986 less than 1% of the world's technological capacity to store information was digital and in 2007 it was already 94%. The year 2002 is assumed to be the year when human kind was able to store more information in digital than in analog format (the \"beginning of the digital age\").\n\nAll digital information possesses common properties that distinguish it from analog data with respect to communications:\n\nEven though digital signals are generally associated with the binary electronic digital systems used in modern electronics and computing, digital systems are actually ancient, and need not be binary or electronic.\n\n"}
{"id": "8278", "url": "https://en.wikipedia.org/wiki?curid=8278", "title": "Deduction", "text": "Deduction\n\nDeduction may refer to:\n\n\n\n"}
{"id": "8280", "url": "https://en.wikipedia.org/wiki?curid=8280", "title": "Demon", "text": "Demon\n\nA demon (from Koine Greek \"daimónion\") is a supernatural and often malevolent being prevalent in religion, occultism, literature, fiction, mythology and folklore.\n\nThe original Greek word \"daimon\" does not carry the negative connotation initially understood by implementation of the Koine (\"daimonion\"), and later ascribed to any cognate words sharing the root.\n\nIn Ancient Near Eastern religions as well as in the Abrahamic traditions, including ancient and medieval Christian demonology, a demon is considered a harmful spiritual entity, below the heavenly planes which may cause demonic possession, calling for an exorcism. In Western occultism and Renaissance magic, which grew out of an amalgamation of Greco-Roman magic, Jewish Aggadah and Christian demonology, a demon is believed to be a spiritual entity that may be conjured and controlled.\n\nThe Ancient Greek word \"daimōn\" denotes a spirit or divine power, much like the Latin \"genius\" or \"numen\". \"Daimōn\" most likely came from the Greek verb \"daiesthai\" (to divide, distribute). The Greek conception of a \"daimōn\" notably appears in the works of Plato, where it describes the divine inspiration of Socrates. To distinguish the classical Greek concept from its later Christian interpretation, the former is anglicized as either \"daemon\" or \"daimon\" rather than \"demon\".\n\nThe Greek terms do not have any connotations of evil or malevolence. In fact, \"eudaimonia\", (literally good-spiritedness) means happiness. By the early Roman Empire, cult statues were seen, by pagans and their Christian neighbors alike, as inhabited by the numinous presence of the gods: \"Like pagans, Christians still sensed and saw the gods and their power, and as something, they had to assume, lay behind it, by an easy traditional shift of opinion they turned these pagan \"daimones\" into malevolent 'demons', the troupe of Satan... Far into the Byzantine period Christians eyed their cities' old pagan statuary as a seat of the demons' presence. It was no longer beautiful, it was infested.\" The term had first acquired its negative connotations in the Septuagint translation of the Hebrew Bible into Greek, which drew on the mythology of ancient Semitic religions. This was then inherited by the Koine text of the New Testament. The Western medieval and neo-medieval conception of a \"demon\" derives seamlessly from the ambient popular culture of Late Antiquity. The Hellenistic \"daemon\" eventually came to include many Semitic and Near Eastern gods as evaluated by Christianity.\n\nThe supposed existence of demons remains an important concept in many modern religions and occultist traditions. Demons are still feared largely due to their alleged power to possess living creatures. In the contemporary Western occultist tradition (perhaps epitomized by the work of Aleister Crowley), a demon (such as Choronzon, which is Crowley's interpretation of the so-called 'Demon of the Abyss') is a useful metaphor for certain inner psychological processes (inner demons), though some may also regard it as an objectively real phenomenon. Some scholars believe that large portions of the demonology (see Asmodai) of Judaism, a key influence on Christianity and Islam, originated from a later form of Zoroastrianism, and were transferred to Judaism during the Persian era.\n\nAccording to the Jewish Encyclopedia, \"In Chaldean mythology the seven evil deities were known as \"shedu\", storm-demons, represented in ox-like form.\" They were represented as winged bulls, derived from the colossal bulls used as protective jinn of royal palaces.\n\nFrom Chaldea, the term \"shedu\" traveled to the Israelites. The writers of the Tanach applied the word as a dialogism to Canaanite deities.\n\nThere are indications that demons in popular Hebrew mythology were believed to come from the nether world. Various diseases and ailments were ascribed to them, particularly those affecting the brain and those of internal nature. Examples include catalepsy, headache, epilepsy and nightmares. There also existed a demon of blindness, \"Shabriri\" (lit. \"dazzling glare\") who rested on uncovered water at night and blinded those who drank from it.\n\nDemons supposedly entered the body and caused the disease while overwhelming or \"seizing\" the victim. To cure such diseases, it was necessary to draw out the evil demons by certain incantations and talismanic performances, at which the Essenes excelled. Josephus, who spoke of demons as \"spirits of the wicked which enter into men that are alive and kill them\", but which could be driven out by a certain root, witnessed such a performance in the presence of the Emperor Vespasian and ascribed its origin to King Solomon. In mythology, there were few defences against Babylonian demons. The mythical mace Sharur had the power to slay demons such as Asag, a legendary gallu or edimmu of hideous strength.\n\nAs referring to the existence or non-existence of \"shedim\" (Hebr. for \"demons\", \"spirits\") there are converse opinions in Judaism. There are \"practically nil\" roles assigned to demons in the Jewish Bible. In Judaism today, beliefs in \"shedim\" (\"demons\" or \"evil spirits\") are either midot hasidut (Hebr. for \"customs of the pious\"), and therefore not halachah, or notions based on a superstition that are non-essential, non-binding parts of Judaism, and therefore not normative Jewish practice. In conclusion, Jews are not obligated to believe in the existence of \"shedim\", as posek rabbi David Bar-Hayim points out.\n\nThe word \"shedim\" (Hebr. for \"demons\" or \"spirits\") appears only in two places in the Tanakh (, ). In both places, the term appears in a scriptural context of animal or child sacrifice to non-existent false gods that are called \"shedim\".\n\nIn the Jerusalem Talmud notions of \"shedim\" (\"demons\" or \"evil spirits\") are almost unknown or occur only very rarely, whereas in the Babylon Talmud there are many references to \"shedim\" and magical incantations. The existence of \"shedim\" in general was not questioned by most of the Babylonian Talmudists. As a consequence of the rise of influence of the Babylonian Talmud over that of the Jerusalem Talmud, late rabbis in general took as fact the existence of \"shedim\", nor did most of the medieval thinkers question their reality. However, rationalists like Maimonides, Saadia Gaon and Abraham ibn Ezra and others explicitly denied their existence, and completely rejected concepts of demons, evil spirits, negative spiritual influences, attaching and possessing spirits. Their point of view eventually became mainstream Jewish understanding.\n\nSome benevolent \"shedim\" were used in kabbalistic ceremonies (as with the \"golem\" of Rabbi Yehuda Loevy) and malevolent \"shedim\" (\"mazikin\", from the root meaning \"to damage\") were often credited with possession.\n\nAggadic tales from the Persian tradition describe the \"shedim\", the \" mazziḳim\" (\"harmers\"), and the \" ruḥin\" (\"spirits\"). There were also \"lilin\" (\"night spirits\"), \" ṭelane\" (\"shade\", or \"evening spirits\"), \" ṭiharire\" (\"midday spirits\"), and \" ẓafrire\" (\"morning spirits\"), as well as the \"demons that bring famine\" and \"such as cause storm and earthquake\". According to some aggadic stories about demons is told that they were under the dominion of a king or chief, either Asmodai or, in the older Aggadah, Samael (\"the angel of death\"), who killed via poison. Stories in the fashion of this kind of folklore never became an essential feature of Jewish theology. Although occasionally an angel is called \"satan\" in the Babylon Talmud, this does not refer to a demon: \"Stand not in the way of an ox when coming from the pasture, for Satan dances between his horns\".\n\nTo the Qumran community during the Second Temple period this apotropaic prayer was assigned, stating: \"And, I the Sage, declare the grandeur of his radiance in order to frighten and terri[fy] all the spirits of the ravaging angels and the bastard spirits, demons, Liliths, owls\" (\"Dead Sea Scrolls\", \"Songs of the Sage,\" Lines 4–5).\n\nIn the Dead Sea Scrolls, there exists a fragment entitled \"Curses of Belial\" (\"Curses of Belial (Dead Sea Scrolls, 394, 4Q286(4Q287, fr. 6)=4QBerakhot)\"). This fragment holds much rich language that reflects the sentiment shared between the Qumran towards Belial. In many ways this text shows how these people thought Belial influenced sin through the way they address him and speak of him. By addressing \"Belial and all his guilty lot,\" (4Q286:2) they make it clear that he is not only impious, but also guilty of sins. Informing this state of uncleanliness are both his \"hostile\" and \"wicked design\" (4Q286:3,4). Through this design, Belial poisons the thoughts of those who are not necessarily sinners. Thus a dualism is born from those inclined to be wicked and those who aren't. It is clear that Belial directly influences sin by the mention of \"abominable plots\" and \"guilty inclination\" (4Q286:8,9). These are both mechanisms by which Belial advances his evil agenda that the Qumran have exposed and are calling upon God to protect them from. There is a deep sense of fear that Belial will \"establish in their heart their evil devices\" (4Q286:11,12). This sense of fear is the stimulus for this prayer in the first place. Without the worry and potential of falling victim to Belial's demonic sway, the Qumran people would never feel impelled to craft a curse. This very fact illuminates the power Belial was believed to hold over mortals, and the fact that sin proved to be a temptation that must stem from an impure origin.\n\nIn Jubilees 1:20, Belial's appearance continues to support the notion that sin is a direct product of his influence. Moreover, Belial's presence acts as a placeholder for all negative influences or those that would potentially interfere with God's will and a pious existence. Similarly to the \"gentiles ... [who] cause them to sin against you\" (Jubilees 1:19), Belial is associated with a force that drives one away from God. Coupled in this plea for protection against foreign rule, in this case the Egyptians, is a plea for protection from \"the spirit of Belial\" (Jubilees 1:19). Belial's tendency is to \"ensnare [you] from every path of righteousness\" (Jubilees 1:19). This phrase is intentionally vague, allowing room for interpretation. Everyone, in one way or another, finds themselves straying from the path of righteousness and by pawning this transgression off on Belial, he becomes a scapegoat for all misguidance, no matter what the cause. By associating Belial with all sorts of misfortune and negative external influence, the Qumran people are henceforth allowed to be let off for the sins they commit.\n\nBelial's presence is found throughout the War Scrolls, located in the Dead Sea Scrolls, and is established as the force occupying the opposite end of the spectrum of God. In Col. I, verse 1, the very first line of the document, it is stated that \"the first attack of the Sons of Light shall be undertaken against the forces of the Sons of Darkness, the army of Belial\" (1Q33;1:1). This dichotomy sheds light on the negative connotations that Belial held at the time. Where God and his Sons of Light are forces that protect and promote piety, Belial and his Sons of Darkness cater to the opposite, instilling the desire to sin and encouraging destruction. This opposition is only reinforced later in the document; it continues to read that the \"holy ones\" will \"strike a blow at wickedness\", ultimately resulting in the \"annihilation of the Sons of Darkness\" (1Q33:1:13). This epic battle between good and evil described in such abstract terms, however it is also applicable to everyday life and serves as a lens through which the Qumran see the world. Every day is the Sons of Light battle evil and call upon God to help them overcome evil in ways small and large.\n\nBelial's influence is not taken lightly. In Col. XI, verse 8, the text depicts God conquering the \"hordes of Belial\" (1Q33;11:8). This defeat is indicative of God's power over Belial and his forces of temptation. However the fact that Belial is the leader of hordes is a testament to how persuasive he can be. If Belial was obviously an arbiter of wrongdoing and was blatantly in the wrong, he wouldn’t be able to amass an army. This fact serves as a warning message, reasserting God’s strength, while also making it extremely clear the breadth of Belial's prowess. Belial's \"council is to condemn and convict\", so the Qumran feel strongly that their people are not only aware of his purpose, but also equipped to combat his influence (1Q33;13:11).\n\nIn the Damascus Document, Belial also makes a prominent appearance, being established as a source of evil and an origin of several types of sin. In Column 4, the first mention of Belial reads: \"Belial shall be unleashed against Israel\" (4Q266). This phrase is able to be interpreted myriad different ways. Belial is characterized in a wild and uncontrollable fashion, making him seem more dangerous and unpredictable. The notion of being unleashed is such that once he is free to roam; he is unstoppable and able to carry out his agenda uninhibited. The passage then goes to enumerate the \"three nets\" (4Q266;4:16) by which Belial captures his prey and forces them to sin. \"Fornication ..., riches ..., [and] the profanation of the temple\" (4Q266;4:17,18) make up the three nets. These three temptations were three agents by which people were driven to sin, so subsequently, the Qumran people crafted the nets of Belial to rationalize why these specific temptations were so toxic. Later in Column 5, Belial is mentioned again as one of \"the removers of bound who led Israel astray\" (4Q266;5:20). This statement is a clear display of Belial's influence over man regarding sin. The passage goes on to state: \"they preached rebellion against ... God\" (4Q266;5:21,22). Belial's purpose is to undermine the teachings of God, and he achieves this by imparting his nets on humans, or the incentive to sin.\n\nIn the War of the Sons of Light Against the Sons of Darkness, Belial controls scores of demons, which are specifically allotted to him by God for the purpose of performing evil. Belial, despite his malevolent disposition, is considered an angel.\n\nDemons in the Old Testament of the Christian Bible are of two classes: the \"satyrs\" or \"shaggy goats\" (from Hebr. \"se'irim\" \"hairy beings\" and Greek Old Testament σάτυρος \"satyros\", \"satyr\"; , ) and the \"demons\" (from Hebr. \"shedim\", and Koine Greek δαιμόνιον \"daimonion\"; , ).\n\nThe term \"demon\" (from the Greek New Testament δαιμόνιον \"daimonion\") appears 63 times in the New Testament of the Christian Bible.\n\nDemons are sometimes included into biblical interpretation. In the story of Passover, the Bible tells the story as \"the Lord struck down all the firstborn in Egypt\" (Exodus 12:21–29). In the Book of Jubilees, which is considered canonical only by the Ethiopian Orthodox Church, this same event is told slightly differently: \"All the powers of [the demon] Mastema had been let loose to slay all the first-born in the land of Egypt...And the powers of the Lord did everything according as the Lord commanded them\" (Jubilees 49:2–4).\n\nIn the Genesis flood narrative the author explains how God was noticing \"how corrupt the earth had become, for all the people on earth had corrupted their ways\" (Genesis 6:12). In Jubilees the sins of man are attributed to \"the unclean demons [who] began to lead astray the children of the sons of Noah, and to make to err and destroy them\" (Jubilees 10:1). In Jubilees Mastema questions the loyalty of Abraham and tells God to \"bid him offer him as a burnt offering on the altar, and Thou wilt see if he will do this command\" (Jubilees 17:16). The discrepancy between the story in Jubilees and the story in Genesis 22 exists with the presence of Mastema. In Genesis, God tests the will of Abraham merely to determine whether he is a true follower, however; in Jubilees Mastema has an agenda behind promoting the sacrifice of Abraham's son, \"an even more demonic act than that of the Satan in Job.\" In Jubilees, where Mastema, an angel tasked with the tempting of mortals into sin and iniquity, requests that God give him a tenth of the spirits of the children of the watchers, demons, in order to aid the process. These demons are passed into Mastema’s authority, where once again, an angel is in charge of demonic spirits.\nThe sources of demonic influence were thought to originate from the Watchers or Nephilim, who are first mentioned in Genesis 6 and are the focus of 1 Enoch Chapters 1–16, and also in Jubilees 10. The Nephilim were seen as the source of the sin and evil on earth because they are referenced in Genesis 6:4 before the story of the Flood. In Genesis 6:5, God sees evil in the hearts of men. The passage states, \"the wickedness of humankind on earth was great\", and that \"Every inclination of the thoughts of their hearts was only continually evil\" (Genesis 5). The mention of the Nephilim in the preceding sentence connects the spread of evil to the Nephilim. Enoch is a very similar story to Genesis 6:4–5, and provides further description of the story connecting the Nephilim to the corruption of humans. In Enoch, sin originates when angels descend from heaven and fornicate with women, birthing giants as tall as 300 cubits. The giants and the angels' departure of Heaven and mating with human women are also seen as the source of sorrow and sadness on Earth. The book of Enoch shows that these fallen angels can lead humans to sin through direct interaction or through providing forbidden knowledge. In Enoch, Semyaz leads the angels to mate with women. Angels mating with humans is against God's commands and is a cursed action, resulting in the wrath of God coming upon Earth. Azazel indirectly influences humans to sin by teaching them divine knowledge not meant for humans. Asael brings down the \"stolen mysteries\" (Enoch 16:3). Asael gives the humans weapons, which they use to kill each other. Humans are also taught other sinful actions such as beautification techniques, alchemy, astrology and how to make medicine (considered forbidden knowledge at the time). Demons originate from the evil spirits of the giants that are cursed by God to wander the earth. These spirits are stated in Enoch to \"corrupt, fall, be excited, and fall upon the earth, and cause sorrow\" (Enoch 15:11).\n\nThe Book of Jubilees conveys that sin occurs when Cainan accidentally transcribes astrological knowledge used by the Watchers (Jubilees 8). This differs from Enoch in that it does not place blame on the Angels. However, in Jubilees 10:4 the evil spirits of the Watchers are discussed as evil and still remain on earth to corrupt the humans. God binds only 90 percent of the Watchers and destroys them, leaving 10 percent to be ruled by Mastema. Because the evil in humans is great, only 10 percent would be needed to corrupt and lead humans astray. These spirits of the giants also referred to as \"the bastards\" in the Apotropaic prayer Songs of the Sage, which lists the names of demons the narrator hopes to expel.\n\nIn Christianity, demons are regarded as fallen angels or descendants from union between angels and human. Often deities of other religions are interpreted or created as \"demons\" (from the Greek Old Testament δαιμόνιον \"daimonion\"). The evolution of the Christian Devil and pentagram are examples of early rituals and images that showcase evil qualities, as seen by the Christian churches.\n\nSince Early Christianity, demonology has developed from a simple acceptance of demons to a complex study that has grown from the original ideas taken from Jewish demonology and Christian scriptures. Christian demonology is studied in depth within the Roman Catholic Church, although many other Christian churches affirm and discuss the existence of demons.\n\nBuilding upon the few references to \"daemons\" in the New Testament, especially the poetry of the Book of Revelation, Christian writers of apocrypha from the 2nd century onwards created a more complicated tapestry of beliefs about \"demons\" that was largely independent of Christian scripture.\n\nThe contemporary Roman Catholic Church unequivocally teaches that angels and demons are real beings rather than just symbolic devices. The Catholic Church has a cadre of officially sanctioned exorcists which perform many exorcisms each year. The exorcists of the Catholic Church teach that demons attack humans continually but that afflicted persons can be effectively healed and protected either by the formal rite of exorcism, authorized to be performed only by bishops and those they designate, or by prayers of deliverance, which any Christian can offer for themselves or others.\n\nAt various times in Christian history, attempts have been made to classify demons according to various proposed demonic hierarchies.\n\nIn the Gospels, particularly the Gospel of Mark, Jesus cast out many demons from those afflicted with various ailments. He also lent this power to some of his disciples ().\n\nApuleius, by Augustine of Hippo, is ambiguous as to whether \"daemons\" had become \"demonized\" by the early 5th century:\n\nHe [Apulieus] also states that the blessed are called in Greek \"eudaimones\", because they are good souls, that is to say, good demons, confirming his opinion that the souls of men are demons.\n\nThe numerous mentions of jinn in the Quran and testimony of both pre-Islamic and Islamic literature indicate that the belief in spirits was prominent in pre-Islamic Bedouin religion. There is evidence that the word jinn is derived from Aramaic, where it was used by Christians to designate pagan gods reduced to the status of demons, and was introduced into Arabic folklore only late in the pre-Islamic era. Julius Wellhausen has observed that such spirits were thought to inhabit desolate, dingy and dark places and that they were feared.\n\nIn Islam and Islamic folklore, demons or supernatural creatures on earth are called Jinn. They include different kinds and appearances of supernatural beings:\n\nIslam offers different possible origins of the jinn. One account considers them offspring of Iblis, after he was cast down to earth. Other accounts claim the jinn already lived on earth, before humans and before the fall of Iblis, but were once almost extinct or banished into the invisible realm.\n\nHindu beliefs include numerous varieties of spirits that might be classified as demons, including Vetalas, Bhutas and Pishachas. Rakshasas and Asuras are often also taken as demons.\n\nOriginally, \"Asura\", in the earliest hymns of the Rig Veda, meant any supernatural spirit, either good or bad. Since the /s/ of the Indic linguistic branch is cognate with the /h/ of the Early Iranian languages, the word \"Asura\", representing a category of celestial beings, became the word \"Ahura\" (Mazda), the Supreme God of the monotheistic Zoroastrians. Ancient Hinduism tells that Devas (also called \"suras\") and Asuras are half-brothers, sons of the same father Kashyapa; although some of the Devas, such as Varuna, are also called Asuras. Later, during Puranic age, Asura and Rakshasa came to exclusively mean any of a race of anthropomorphic, powerful, possibly evil beings. Daitya (lit. sons of the mother \"Diti\"), Rakshasa (lit. from \"harm to be guarded against\"), and Asura are incorrectly translated into English as \"demon\".\n\nPost Vedic, Hindu scriptures, pious, highly enlightened Asuras, such as Prahlada and Vibhishana, are not uncommon. The Asura are not fundamentally against the gods, nor do they tempt humans to fall. Many people metaphorically interpret the Asura as manifestations of the ignoble passions in the human mind and as a symbolic devices. There were also cases of power-hungry Asuras challenging various aspects of the Gods, but only to be defeated eventually and seek forgiveness—see Surapadman and Narakasura.\n\nHinduism advocates the reincarnation and transmigration of souls according to one's karma. Souls (Atman) of the dead are adjudged by the Yama and are accorded various purging punishments before being reborn. Humans that have committed extraordinary wrongs are condemned to roam as lonely, often evil, spirits for a length of time before being reborn. Many kinds of such spirits (Vetalas, Pishachas, Bhūta) are recognized in the later Hindu texts. These beings, in a limited sense, can be called demons.\n\nIn the Bahá'í Faith, demons are not regarded as independent evil spirits as they are in some faiths. Rather, evil spirits described in various faiths' traditions, such as Satan, fallen angels, demons and jinns, are metaphors for the base character traits a human being may acquire and manifest when he turns away from God and follows his lower nature. Belief in the existence of ghosts and earthbound spirits is rejected and considered to be the product of superstition.\n\nWhile some people fear demons, or attempt to exorcise them, others willfully attempt to summon them for knowledge, assistance, or power. The ceremonial magician usually consults a grimoire, which gives the names and abilities of demons as well as detailed instructions for conjuring and controlling them. Grimoires aren't limited to demons – some give the names of angels or spirits which can be called, a process called theurgy. The use of ceremonial magic to call demons is also known as goetia, the name taken from a section in the famous grimoire the \"Lesser Key of Solomon\".\n\nAccording to Rosemary Ellen Guiley, \"Demons are not courted or worshipped in contemporary Wicca and Paganism. The existence of negative energies is acknowledged.\"\n\nPsychologist Wilhelm Wundt remarked that \"among the activities attributed by myths all over the world to demons, the harmful predominate, so that in popular belief bad demons are clearly older than good ones.\" Sigmund Freud developed this idea and claimed that the concept of demons was derived from the important relation of the living to the dead: \"The fact that demons are always regarded as the spirits of those who have died \"recently\" shows better than anything the influence of mourning on the origin of the belief in demons.\"\n\nM. Scott Peck, an American psychiatrist, wrote two books on the subject, \"People of the Lie: The Hope For Healing Human Evil\" and \"Glimpses of the Devil: A Psychiatrist's Personal Accounts of Possession, Exorcism, and Redemption\". Peck describes in some detail several cases involving his patients. In \"People of the Lie\" he provides identifying characteristics of an evil person, whom he classified as having a character disorder. In \"Glimpses of the Devil\" Peck goes into significant detail describing how he became interested in exorcism in order to debunk the \"myth\" of possession by evil spirits – only to be convinced otherwise after encountering two cases which did not fit into any category known to psychology or psychiatry. Peck came to the conclusion that possession was a rare phenomenon related to evil, and that possessed people are not actually evil; rather, they are doing battle with the forces of evil.\n\nAlthough Peck's earlier work was met with widespread popular acceptance, his work on the topics of evil and possession has generated significant debate and derision. Much was made of his association with (and admiration for) the controversial Malachi Martin, a Roman Catholic priest and a former Jesuit, despite the fact that Peck consistently called Martin a liar and manipulator. Richard Woods, a Roman Catholic priest and theologian, has claimed that Dr. Peck misdiagnosed patients based upon a lack of knowledge regarding dissociative identity disorder (formerly known as multiple personality disorder), and had apparently transgressed the boundaries of professional ethics by attempting to persuade his patients into accepting Christianity. Father Woods admitted that he has never witnessed a genuine case of demonic possession in all his years.\n\nAccording to S. N. Chiu, God is shown sending a demon against Saul in 1 Samuel 16 and 18 in order to punish him for the failure to follow God's instructions, showing God as having the power to use demons for his own purposes, putting the demon under his divine authority. According to the \"Britannica Concise Encyclopedia\", demons, despite being typically associated with evil, are often shown to be under divine control, and not acting of their own devices.\n\n\n\n"}
{"id": "8286", "url": "https://en.wikipedia.org/wiki?curid=8286", "title": "Domino effect", "text": "Domino effect\n\nA domino effect or chain reaction is the cumulative effect produced when one event sets off a chain of similar events. The term is best known as a mechanical effect, and is used as an analogy to a falling row of dominoes. It typically refers to a linked sequence of events where the time between successive events is relatively small. It can be used literally (an observed series of actual collisions) or metaphorically (causal linkages within systems such as global finance or politics).\n\n\nRelevant physical theory:\n\nMathematical theory\n\nPolitical theory\n\nSocial\n\n\n"}
{"id": "8293", "url": "https://en.wikipedia.org/wiki?curid=8293", "title": "Diffusion pump", "text": "Diffusion pump\n\nDiffusion pumps use a high speed jet of vapor to direct gas molecules in the pump throat down into the bottom of the pump and out the exhaust. Invented in 1915 by Wolfgang Gaede using mercury vapor, and improved by Irving Langmuir and W. Crawford, they were the first type of high vacuum pumps operating in the regime of free molecular flow, where the movement of the gas molecules can be better understood as diffusion than by conventional fluid dynamics. Gaede used the name \"diffusion pump\" since his design was based on the finding that gas cannot diffuse against the vapor stream, but will be carried with it to the exhaust. However, the principle of operation might be more precisely described as gas-jet pump, since diffusion plays a role also in other high vacuum pumps. In modern text books, the diffusion pump is categorized as a momentum transfer pump.\n\nThe diffusion pump is widely used in both industrial and research applications. Most modern diffusion pumps use silicone oil or polyphenyl ethers as the working fluid. Cecil Reginald Burch discovered the possibility of using silicone oil in 1928.\n\nAn oil diffusion pump is used to achieve higher vacuum (lower pressure) than is possible by use of positive displacement pumps alone. Although its use has been mainly associated within the high-vacuum range (down to 10 mbar), diffusion pumps today can produce pressures approaching 10 mbar when properly used with modern fluids and accessories. The features that make the diffusion pump attractive for high and ultra-high vacuum use are its high pumping speed for all gases and low cost per unit pumping speed when compared with other types of pump used in the same vacuum range. Diffusion pumps cannot discharge directly into the atmosphere, so a mechanical forepump is typically used to maintain an outlet pressure around 0.1 mbar.\n\nThe oil diffusion pump is operated with an oil of low vapor pressure. The high speed jet is generated by boiling the fluid and directing the vapor through a jet assembly. Note that the oil is gaseous when entering the nozzles. Within the nozzles, the flow changes from laminar, to supersonic and molecular. Often, several jets are used in series to enhance the pumping action. The outside of the diffusion pump is cooled using either air flow or a water line. As the vapor jet hits the outer cooled shell of the diffusion pump, the working fluid condenses and is recovered and directed back to the boiler. The pumped gases continue flowing to the base of the pump at increased pressure, flowing out through the diffusion pump outlet, where they are compressed to ambient pressure by the secondary mechanical forepump and exhausted. \n\nUnlike turbomolecular pumps and cryopumps, diffusion pumps have no moving parts and as a result are quite durable and reliable. They can function over pressure ranges of 10 to 10 mbar. They are driven only by convection and thus have a very low energy efficiency.\n\nOne major disadvantage of diffusion pumps is the tendency to backstream oil into the vacuum chamber. This oil can contaminate surfaces inside the chamber or upon contact with hot filaments or electrical discharges may result in carbonaceous or siliceous deposits. Due to backstreaming, oil diffusion pumps are not suitable for use with highly sensitive analytical equipment or other applications which require an extremely clean vacuum environment, but mercury diffusion pumps may be in the case of ultra high vacuum chambers used for metal deposition. Often cold traps and baffles are used to minimize backstreaming, although this results in some loss of pumping ability.\n\nThe oil of a diffusion pump cannot be exposed to the atmosphere when hot. If this occurs, the oil will burn and has to be replaced.\n\n \nThe steam ejector is a popular form of diffusion pump for vacuum distillation and freeze-drying. A jet of steam entrains the vapour that must be removed from the vacuum chamber. Steam ejectors can have single or multiple stages, with and without condensers in between the stages.\n\nOne class of diffusion vacuum pumps is the multistage compressed-air driven ejector. It is very popular in applications where objects are moved around using suction cups and vacuum lines.\n\n\n"}
{"id": "8299", "url": "https://en.wikipedia.org/wiki?curid=8299", "title": "Domenico Alberti", "text": "Domenico Alberti\n\nDomenico Alberti (c. 1710 – 14 October 1740) was an Italian singer, harpsichordist, and composer.\n\nAlberti was born in Venice and studied music with Antonio Lotti. He wrote operas, songs, and sonatas for keyboard instruments, for which he is best known today. These sonatas frequently employ a particular kind of arpeggiated accompaniment in the left hand that is now known as the \"Alberti bass\". It consists of regular broken chords, with the lowest note sounding first, then the highest, then the middle and then the highest again. This pattern is repeated. Today, Alberti is regarded as a minor composer, and his works are played or recorded only irregularly. The Alberti bass was used by many later composers, and it became an important element in much keyboard music of the Classical music era.\n\nAn example of Alberti bass (Mozart's \"Piano Sonata, K 545\"):\n\nIn his own lifetime, Alberti was known as a singer. He often used to accompany himself on the harpsichord. In 1736, he served as a page for Pietro Andrea Cappello, the Venetian ambassador to Spain. While at the Spanish court, the famous castrato singer Farinelli heard him sing. Farinelli was said to have been impressed, although Alberti was an amateur.\n\nAlberti's best known pieces are his keyboard sonatas, although even they are very rarely performed. It is thought he wrote around 36 sonatas, of which 14 have survived. They all have two movements, each in binary form.\n\nIt is probable that Mozart's first violin sonatas, written at the age of seven, were modeled on Alberti's work.\n\nAlberti died in 1740 in Rome.\n"}
{"id": "8300", "url": "https://en.wikipedia.org/wiki?curid=8300", "title": "Doris Day", "text": "Doris Day\n\nDoris Day (born Doris Mary Ann Kappelhoff; April 3, 1922) is a retired American actress, singer, and animal welfare activist. After she began her career as a big band singer in 1939, her popularity increased with her first hit recording \"Sentimental Journey\" (1945). After leaving Les Brown & His Band of Renown to embark on a solo career, she recorded more than 650 songs from 1947 to 1967, which made her one of the most popular and acclaimed singers of the 20th century.\n\nDay's film career began with the 1948 film \"Romance on the High Seas\", and its success sparked her twenty-year career as a motion picture actress. She starred in a series of successful films, including musicals, comedies, and dramas. She played the title role in \"Calamity Jane\" (1953), and starred in Hitchock's \"The Man Who Knew Too Much\" (1956) with James Stewart. Her most successful films were the \"pioneering\" bedroom comedies she made co-starring Rock Hudson and James Garner, such as \"Pillow Talk\" (1959) and \"Move Over, Darling\" (1963), respectively. She also co-starred in films with such leading men as Clark Gable, Cary Grant, David Niven, and Rod Taylor. After her final film in 1968, she went on to star in the successful CBS sitcom \"The Doris Day Show\" (1968–73).\n\nShe was usually one of the top ten singers between 1951 and 1966. As an actress, she became the biggest female film star in the early 1960s, and ranked sixth among the box office performers by 2012. In 2011, she released her 29th studio album, \"My Heart\", which became a UK Top 10 album featuring new material. Among her awards, Day has received the Grammy Lifetime Achievement Award and a Legend Award from the Society of Singers. In 1960, she was nominated for the Academy Award for Best Actress, and in 1989 was given the Cecil B. DeMille Award for lifetime achievement in motion pictures. In 2004, she was awarded the Presidential Medal of Freedom by President George W. Bush followed in 2011 by the Los Angeles Film Critics Association's Career Achievement Award.\n\nDoris Mary Ann Kappelhoff was born on April 3, 1922, in Cincinnati, Ohio, the daughter of Alma Sophia (née Welz), a housewife, and William Joseph Kappelhoff, a music teacher and choir master. All of her grandparents were German immigrants. For most of her life, Day reportedly believed she had been born in 1924 and reported her age accordingly; it was not until her 95th birthday, when the Associated Press found her birth certificate, showing a 1922 date, that she learned otherwise.\n\nThe youngest of three siblings, she had two older brothers: Richard (who died before her birth) and Paul, 2–3 years older. Due to her father's alleged infidelity, her parents separated. She developed an early interest in dance, and in the mid-1930s formed a dance duo with Jerry Doherty that performed locally in Cincinnati. A car accident on October 13, 1937, injured her right leg and curtailed her prospects as a professional dancer.\n\nWhile recovering, Day started to sing along with the radio and discovered a talent she did not know she had. Day said: \"During this long, boring period, I used to while away a lot of time listening to the radio, sometimes singing along with the likes of Benny Goodman, Duke Ellington, Tommy Dorsey, and Glenn Miller [...]. But the one radio voice I listened to above others belonged to Ella Fitzgerald. There was a quality to her voice that fascinated me, and I'd sing along with her, trying to catch the subtle ways she shaded her voice, the casual yet clean way she sang the words.\"\n\nObserving her daughter sing rekindled Alma's interest in show business, and she decided to give Doris singing lessons. She engaged a teacher, Grace Raine. After three lessons, Raine told Alma that young Doris had \"tremendous potential\"; Raine was so impressed that she gave Doris three lessons a week for the price of one. Years later, Day said that Raine had the biggest effect on her singing style and career.\n\nDuring the eight months she was taking singing lessons, Day had her first professional jobs as a vocalist, on the WLW radio program \"Carlin's Carnival\", and in a local restaurant, Charlie Yee's Shanghai Inn. During her radio performances, Day first caught the attention of Barney Rapp, who was looking for a girl vocalist and asked if Day would like to audition for the job. According to Rapp, he had auditioned about 200 singers when Day got the job.\n\nWhile working for Rapp in 1939, she adopted the stage surname \"Day\", at Rapp's suggestion. Rapp felt that \"Kappelhoff\" was too long for marquees, and he admired her rendition of the song \"Day After Day\". After working with Rapp, Day worked with bandleaders Jimmy James, Bob Crosby, and Les Brown.\n\nWhile working with Brown, Day scored her first hit recording, \"Sentimental Journey\", released in early 1945. It soon became an anthem of the desire of World War II demobilizing troops to return home. This song is still associated with Day, and she rerecorded it on several occasions, including a version in her 1971 television special. During 1945–46, Day (as vocalist with the Les Brown Band) had six other top ten hits on the\" Billboard\" chart: \"My Dreams Are Getting Better All the Time\", \"'Tain't Me\", \"Till The End of Time\", \"You Won't Be Satisfied (Until You Break My Heart)\", \"The Whole World is Singing My Song\", and \"I Got the Sun in the Mornin'\". In the 1950s she had become the most popular and one of the highest paid singers in America.\n\nWhile singing with the Les Brown band and for nearly two years on Bob Hope's weekly radio program, she toured extensively across the United States. Her popularity as a radio performer and vocalist, which included a second hit record \"My Dreams Are Getting Better All the Time\", led directly to a career in films. In 1941, Day appeared as a singer in a short film with the Les Brown band.\n\nHer performance of the song \"Embraceable You\" impressed songwriter Jule Styne and his partner, Sammy Cahn, and they recommended her for a role in \"Romance on the High Seas\" (1948). Day got the part after auditioning for Michael Curtiz. She was shocked at being offered the role in that film, and admitted to Curtiz that she was a singer without acting experience. But he said he liked that \"she was honest,\" not afraid to admit it. And he wanted someone who \"looked like the All-American Girl,\" which he felt she did. She was the discovery he was most proud of during his career.\n\nThe film provided her with a #2 hit recording as a soloist, \"It's Magic\", which followed by two months her first #1 hit (\"Love Somebody\" in 1948) recorded as a duet with Buddy Clark. Day recorded \"Someone Like You,\" before the 1949 film \"My Dream Is Yours\", which featured the song.\n\nIn 1950, U.S. servicemen in Korea voted her their favorite star. She continued to make minor and frequently nostalgic period musicals such as \"On Moonlight Bay\", \"By the Light of the Silvery Moon\", and \"Tea For Two\" for Warner Brothers. \n\nHer most commercially successful film for Warners was \"I'll See You in My Dreams\" (1951), which broke box-office records of 20 years. The film is a musical biography of lyricist Gus Kahn. It was Day's fourth film directed by Curtiz.\n\nIn 1953, Day appeared as the title character in the comedic western-themed musical, \"Calamity Jane\", winning the Academy Award for Best Original Song for \"Secret Love\" (her recording of which became her fourth #1 hit single in the U.S.).\n\nBetween 1950 and 1953, the albums from six of her movie musicals charted in the Top 10, three of them at #1. After filming \"Lucky Me\" with Bob Cummings and \"Young at Heart\" (both 1954) with Frank Sinatra, Day chose not to renew her contract with Warner Brothers.\n\nHaving become primarily recognized as a musical-comedy actress, Day gradually took on more dramatic roles to broaden her range. Her dramatic star-turn as singer Ruth Etting in \"Love Me or Leave Me\" (1955), co-starring James Cagney, received critical and commercial success, becoming Day's biggest hit thus far. Day said it was her best film performance. Producer Joe Pasternak said, \"I was stunned that Doris did not get an Oscar nomination.\" The soundtrack album from that movie was a No. 1 hit.\n\nDay starred in Alfred Hitchcock's suspense film, \"The Man Who Knew Too Much\" (1956) with James Stewart. She sang two songs in the film, \"Que Sera, Sera (Whatever Will Be, Will Be)\", which won an Academy Award for Best Original Song, and \"We'll Love Again\". The film was Day's 10th movie to be in the Top 10 at the box office. In 1956, Day played the title role in the thriller/noir \"Julie\" with Louis Jourdan.\n\nAfter three successive dramatic films, Day returned to her musical/comedic roots in 1957's \"The Pajama Game\" with John Raitt. The film was based on the Broadway play of the same name. She worked with Paramount Pictures for the comedy \"Teacher's Pet\" (1958), alongside Clark Gable and Gig Young. She co-starred with Richard Widmark and Gig Young in the romantic comedy film, \"The Tunnel of Love\" (1958), but found scant success opposite Jack Lemmon in \"It Happened to Jane\" (1959).\n\n\"Billboard\" annual nationwide poll of disc jockeys had ranked Day as the No. 1 female vocalist nine times in ten years (1949 through 1958), but her success and popularity as a singer was now being overshadowed by her box-office appeal.\n\nIn 1959, Day entered her most successful phase as a film actress with a series of romantic comedies. This success began with \"Pillow Talk\" (1959), co-starring Rock Hudson, who became a lifelong friend, and Tony Randall. Day received a nomination for an Academy Award for Best Actress. Day, Hudson, and Randall made two more films together, \"Lover Come Back\" (1961) and \"Send Me No Flowers\" (1964).\n\nShe starred with David Niven and Janis Paige in the hit \"Please Don't Eat the Daisies\". In 1962, Day appeared with Cary Grant in the comedy \"That Touch of Mink\", the first film in history ever to gross $1 million in one theatre (Radio City Music Hall). During 1960 and the 1962 to 1964 period, she ranked number one at the box office, the second woman to be number one four times. She set an unprecedented record that has yet to be equaled, receiving seven consecutive Laurel Awards as the top female box office star.\n\nDay teamed up with James Garner, starting with \"The Thrill of It All\", followed by \"Move Over, Darling\" (both 1963). The film's theme song, \"Move Over Darling\", co-written by her son, reached #8 in the U.K. In between these comedic roles, Day co-starred with Rex Harrison in the movie thriller \"Midnight Lace\" (1960), an updating of the classic stage thriller, \"Gaslight\".\n\nBy the late 1960s, the sexual revolution of the baby boomer generation had refocused public attitudes about sex. Times changed, but Day's films did not. Day's next film, \"Do Not Disturb\" (1965), was popular with audiences, but her popularity soon waned. Critics and comics dubbed Day \"The World's Oldest Virgin\", and audiences began to shy away from her films. As a result, she slipped from the list of top box-office stars, last appearing in the top ten in 1966 with the hit film \"The Glass Bottom Boat\". One of the roles she turned down was that of \"Mrs. Robinson\" in \"The Graduate\", a role that eventually went to Anne Bancroft. In her published memoirs, Day said she had rejected the part on moral grounds: she found the script \"vulgar and offensive\".\n\nShe starred in the western film \"The Ballad of Josie\" (1967). That same year, Day recorded \"The Love Album\", although it was not released until 1994. The following year (1968), she starred in the comedy film \"Where Were You When the Lights Went Out?\" which centers on the Northeast blackout of November 9, 1965. Her final feature, the comedy \"With Six You Get Eggroll\", was released in 1968.\n\nFrom 1959-70, Day received nine Laurel Award nominations (and won four times) for best female performance in eight comedies and one drama. From 1959 through 1969, she received six Golden Globe nominations for best female performance in three comedies, one drama (\"Midnight Lace\"), one musical (\"Jumbo\"), and her television series.\n\nWhen her third husband Martin Melcher died on April 20, 1968, a shocked Day discovered that Melcher and his business partner Jerome Bernard Rosenthal had squandered her earnings, leaving her deeply in debt. Rosenthal had been her attorney since 1949, when he represented her in her uncontested divorce action against her second husband, saxophonist George W. Weidler. Day filed suit against Rosenthal in February 1969, won a successful decision in 1974, but did not receive compensation until a settlement in 1979.\n\nDay also learned to her displeasure that Melcher had committed her to a television series, which became \"The Doris Day Show\".\n\nDay hated the idea of performing on television, but felt obliged to it. The first episode of \"The Doris Day Show\" aired on September 24, 1968, and, from 1968 to 1973, employed \"Que Sera, Sera\" as its theme song. Day grudgingly persevered (she needed the work to help pay off her debts), but only after CBS ceded creative control to her and her son. The successful show enjoyed a five-year run, and functioned as a curtain raiser for the popular \"Carol Burnett Show\". It is remembered today for its abrupt season-to-season changes in casting and premise.\n\nBy the end of its run in 1973, public tastes had changed and her firmly established persona was regarded as passé. She largely retired from acting after \"The Doris Day Show\", but did complete two television specials, \"The Doris Mary Anne Kappelhoff Special\" (1971) and \"Doris Day to Day\" (1975). She appeared in a John Denver TV special in 1974.\n\nIn the 1985–86 season, Day hosted her own television talk show, \"Doris Day's Best Friends\", on CBN. The network canceled the show after 26 episodes, despite the worldwide publicity it received.\n\nIn October 1985, the California Supreme Court rejected Rosenthal's appeal of the multimillion-dollar judgment against him for legal malpractice, and upheld conclusions of a trial court and a Court of Appeal that Rosenthal acted improperly. In April 1986, the U.S. Supreme Court refused to review the lower court's judgment. In June 1987, Rosenthal filed a $30 million lawsuit against lawyers he claimed cheated him out of millions of dollars in real estate investments. He named Day as a co-defendant, describing her as an \"unwilling, involuntary plaintiff whose consent cannot be obtained\". Rosenthal claimed that millions of dollars Day lost were in real estate sold after Melcher died in 1968, in which Rosenthal asserted that the attorneys gave Day bad advice, telling her to sell, at a loss, three hotels, in Palo Alto, California, Dallas, Texas and Atlanta, Georgia and some oil leases in Kentucky and Ohio.\n\nRosenthal claimed he had made the investments under a long-term plan, and did not intend to sell them until they appreciated in value. Two of the hotels sold in 1970 for about $7 million, and their estimated worth in 1986 was $50 million. In July 1984, after a hearing panel of the State Bar Court, after 80 days of testimony and consideration of documentary evidence, the panel accused Rosenthal of 13 separate acts of misconduct and urged his disbarment in a 34-page unsigned opinion. The State Bar Court's review department upheld the panel's findings, which asked the justices to order Rosenthal's disbarment. He continued representing clients in federal courts until the U.S. Supreme Court ruled against him on March 21, 1988. Disbarment by the Ninth U.S. Circuit Court of Appeals followed on August 19, 1988. The Supreme Court of California, in affirming the disbarment, held that Rosenthal had engaged in transactions involving undisclosed conflicts of interest, took positions adverse to his former clients, overstated expenses, double-billed for legal fees, failed to return client files, failed to provide access to records, failed to give adequate legal advice, failed to provide clients with an opportunity to obtain independent counsel, filed fraudulent claims, gave false testimony, engaged in conduct designed to harass his clients, delayed court proceedings, obstructed justice and abused legal process. Rosenthal died August 15, 2007, at the age of 96.\n\nTerry Melcher stated that his adoptive father's premature death saved Day from financial ruin. It remains unresolved whether Marty Melcher had himself also been duped. Day stated publicly that she believed her husband innocent of any deliberate wrongdoing, stating that he \"simply trusted the wrong person\".\n\nAccording to Day's autobiography, as told to A. E. Hotchner, the usually athletic and healthy Martin Melcher had an enlarged heart. Most of the interviews on the subject given to Hotchner (and included in Day's autobiography) paint an unflattering portrait of Melcher. Author David Kaufman asserts that one of Day's costars, actor Louis Jourdan, maintained that Day herself disliked her husband, but Day's public statements regarding Melcher appear to contradict that assertion.\n\nDay was scheduled to present, along with Patrick Swayze and Marvin Hamlisch, the Best Original Score Oscar at the 61st Annual Academy Awards (March 1989) but she suffered a deep leg cut and was unable to attend. She had been walking through the gardens of her hotel when she cut her leg on a sprinkler. The cut required stitches.\n\nDay was inducted into the Ohio Women's Hall of Fame in 1981 and received the Cecil B. DeMille Award for career achievement in 1989. In 1994, Day's Greatest Hits album became another entry into the British charts. The song \"Perhaps, Perhaps, Perhaps\" was included in the soundtrack of the Australian film \"Strictly Ballroom\", the theme song for the British TV show \"Coupling\", with Mari Wilson performing the song for the title sequence.\n\nDay has participated in interviews and celebrations of her birthday with an annual Doris Day music marathon. In July 2008, she appeared on the Southern California radio show of longtime friend, newscaster George Putnam.\n\nDay turned down a tribute offer from the American Film Institute and from the Kennedy Center Honors because they require attendance in person. In 2004, she was awarded the Presidential Medal of Freedom by President George W. Bush for her achievements in the entertainment industry and for her work on behalf of animals. President Bush stated:\n\nColumnist Liz Smith and film critic Rex Reed have mounted vigorous campaigns to gather support for an honorary Academy Award for Day to herald her film career and her status as the top female box-office star of all time. Day received a Grammy for Lifetime Achievement in Music in 2008, albeit again in absentia.\n\nShe received three Grammy Hall of Fame Awards, in 1998, 1999 and 2012 for her recordings of \"Sentimental Journey\", \"Secret Love\", and \"Que Sera, Sera\", respectively. Day was inducted into the Hit Parade Hall of Fame in 2007, and in 2010 received the first Legend Award ever presented by the Society of Singers.\n\nDay, aged 89, released \"My Heart\" in the United Kingdom on September 5, 2011, her first new album in nearly two decades, since the release of \"The Love Album\", which, although recorded in 1967, was not released until 1994. The album is a compilation of previously unreleased recordings produced by Day's son, Terry Melcher, before his death in 2004. Tracks include the 1970s Joe Cocker hit \"You Are So Beautiful\", The Beach Boys' \"Disney Girls\" and jazz standards such as \"My Buddy\", which Day originally sang in her 1951 film \"I'll See You in My Dreams\".\n\nAfter the disc was released in the US it soon climbed to No. 12 on Amazon's bestseller list, and helped raise funds for the Doris Day Animal League. Day became the oldest artist to score a UK Top 10 with an album featuring new material.\n\nIn January 2012, the Los Angeles Film Critics Association presented Day with a Lifetime Achievement Award.\n\nSince her retirement from films, Day has lived in Carmel-by-the-Sea, California. She has many pets and adopts stray animals. She granted an ABC telephone interview on her birthday in 2016, which was accompanied by photos of her life and career.\n\nDay is a lifelong Republican, and supported George W. Bush's presidential campaign in 2000. Her only child, music producer and songwriter Terry Melcher, who had a hit in the 1960s with \"Hey Little Cobra\" under the name The Rip Chords, died of melanoma in 2004, about five months after Day had received the Presidential Medal of Freedom. She owns a hotel in Carmel-by-the-Sea, the Cypress Inn, which Melcher had co-owned with Day.\n\nIn 1975, Day published her autobiography, \"Doris Day: Her Own Story\", an \"as-told-to\" work with A. E. Hotchner. The book detailed her first three marriages:\n\nAfter publishing her autobiography, Day remarried:\n\nDay's interest in animal welfare and related issues apparently dates to her teen years. While recovering from an automobile accident, she took her dog Tiny for a walk without a leash. Tiny ran into the street and was killed by a passing car. Day later confessed guilt and loneliness about Tiny's untimely death. In 1971, she co-founded Actors and Others for Animals, and appeared in a series of newspaper advertisements denouncing the wearing of fur, alongside Mary Tyler Moore, Angie Dickinson, and Jayne Meadows. Day's friend, Cleveland Amory, wrote about these events in \"Man Kind? Our Incredible War on Wildlife\" (1974).\n\nIn 1978, Day founded the Doris Day Pet Foundation, now the Doris Day Animal Foundation (DDAF). A non-profit 501(c)(3) grant-giving public charity, DDAF funds other non-profit causes throughout the US that share DDAF's mission of helping animals and the people who love them. The DDAF continues to operate independently under Day's personal supervision.\n\nTo complement the Doris Day Animal Foundation, Day formed the Doris Day Animal League (DDAL) in 1987, a national non-profit citizen's lobbying organization whose mission is to reduce pain and suffering and protect animals through legislative initiatives. Day actively lobbied the United States Congress in support of legislation designed to safeguard animal welfare on a number of occasions and in 1995 she originated the annual Spay Day USA. The DDAL merged into The Humane Society of the United States (HSUS) in 2006. The HSUS now manages World Spay Day, the annual one-day spay/neuter event that Day originated.\n\nA facility to help abused and neglected horses opened in 2011 and bears her name—the Doris Day Horse Rescue and Adoption Center, located in Murchison, Texas, on the grounds of an animal sanctuary started by her late friend, author Cleveland Amory. Day contributed $250,000 towards the founding of the center.\n\n\n"}
{"id": "8301", "url": "https://en.wikipedia.org/wiki?curid=8301", "title": "Distillation", "text": "Distillation\n\nDistillation is the process of separating the component or substances from a liquid mixture by selective evaporation and condensation. Distillation may result in essentially complete separation (nearly pure components), or it may be a partial separation that increases the concentration of selected components of the mixture. In either case the process exploits differences in the volatility of the mixture's components. In industrial chemistry, distillation is a unit operation of practically universal importance, but it is a physical separation process and not a chemical reaction.\n\nCommercially, distillation has many applications. For example:\n\nAn installation for distillation, especially of alcohol, is a distillery. The distillation equipment is a still.\n\nDistillation is a very old method of artificial desalination.\n\nDistillation was known in the ancient Indian subcontinent, evident from baked clay retorts and receivers found at Taxila and Charsadda in modern Pakistan, dating back to the early centuries of the Common Era. These \"Gandhara stills\" were only capable of producing very weak liquor, as there was no efficient means of collecting the vapors at low heat.\n\nEvidence of distillation also comes from alchemists working in Alexandria, Roman Egypt, in the 1st century. Distilled water has been known since at least c. 200, when Alexander of Aphrodisias described the process. Work on distilling other liquids continued in early Byzantine Egypt, under Zosimus of Panopolis in the 3rd century. Distillation in China could have begun during the Eastern Han dynasty (1st–2nd centuries), but the distillation of beverages began in the Jin (12th–13th centuries) and Southern Song (10th–13th centuries) dynasties according to archaeological evidence.\n\nClear evidence of the distillation of alcohol comes from the Arab chemist Al-Kindi, in 9th-century Iraq. The process later spread to Italy, where it was described by the School of Salerno in the 12th century. Fractional distillation was developed by Tadeo Alderotti in the 13th century. A still was found in an archaeological site in Qinglong, Hebei province, in China, dating to the 12th century. Distilled beverages were common during the Yuan dynasty (13th–14th centuries).\n\nIn 1500, German alchemist Hieronymus Braunschweig published \"Liber de arte destillandi\" (The Book of the Art of Distillation) the first book solely dedicated to the subject of distillation, followed in 1512 by a much expanded version. In 1651, John French published The Art of Distillation the first major English compendium of practice, though it has been claimed that much of it derives from Braunschweig's work. This includes diagrams with people in them showing the industrial rather than bench scale of the operation.\n\nAs alchemy evolved into the science of chemistry, vessels called retorts became used for distillations. Both alembics and retorts are forms of glassware with long necks pointing to the side at a downward angle which acted as air-cooled condensers to condense the distillate and let it drip downward for collection. Later, copper alembics were invented. Riveted joints were often kept tight by using various mixtures, for instance a dough made of rye flour. These alembics often featured a cooling system around the beak, using cold water for instance, which made the condensation of alcohol more efficient. These were called pot stills. Today, the retorts and pot stills have been largely supplanted by more efficient distillation methods in most industrial processes. However, the pot still is still widely used for the elaboration of some fine alcohols such as cognac, Scotch whisky, Irish whiskey, tequila and some vodkas. Pot stills made of various materials (wood, clay, stainless steel) are also used by bootleggers in various countries. Small pot stills are also sold for the domestic production of flower water or essential oils.\n\nEarly forms of distillation were batch processes using one vaporization and one condensation. Purity was improved by further distillation of the condensate. Greater volumes were processed by simply repeating the distillation. Chemists were reported to carry out as many as 500 to 600 distillations in order to obtain a pure compound.\n\nIn the early 19th century the basics of modern techniques including pre-heating and reflux were developed. In 1822, Anthony Perrier developed one of the first continuous stills. In 1826, Robert Stein improved that design to make his patent still. In 1830, Aeneas Coffey got a patent for improving that design. Coffey's continuous still may be regarded as the archetype of modern petrochemical units. The French engineer Armand Savalle developed his steam regulator around 1846. In 1877, Ernest Solvay was granted a U.S. Patent for a tray column for ammonia distillation and the same and subsequent years saw developments of this theme for oil and spirits.\n\nWith the emergence of chemical engineering as a discipline at the end of the 19th century, scientific rather than empirical methods could be applied. The developing petroleum industry in the early 20th century provided the impetus for the development of accurate design methods such as the McCabe–Thiele method and the Fenske equation. The availability of powerful computers has also allowed direct computer simulation of distillation columns.\n\nThe application of distillation can roughly be divided in four groups: laboratory scale, industrial distillation, distillation of herbs for perfumery and medicinals (herbal distillate), and food processing. The latter two are distinctively different from the former two in that in the processing of beverages and herbs, the distillation is not used as a true purification method but more to transfer all volatiles from the source materials to the distillate.\n\nThe main difference between laboratory scale distillation and industrial distillation is that laboratory scale distillation is often performed batch-wise, whereas industrial distillation often occurs continuously. In batch distillation, the composition of the source material, the vapors of the distilling compounds and the distillate change during the distillation. In batch distillation, a still is charged (supplied) with a batch of feed mixture, which is then separated into its component fractions which are collected sequentially from most volatile to less volatile, with the bottoms (remaining least or non-volatile fraction) removed at the end. The still can then be recharged and the process repeated.\n\nIn continuous distillation, the source materials, vapors, and distillate are kept at a constant composition by carefully replenishing the source material and removing fractions from both vapor and liquid in the system. This results in a better control of the separation process.\n\nThe boiling point of a liquid is the temperature at which the vapor pressure of the liquid equals the pressure around the liquid, enabling bubbles to form without being crushed. A special case is the normal boiling point, where the vapor pressure of the liquid equals the ambient atmospheric pressure.\n\nIt is a common misconception that in a liquid mixture at a given pressure, each component boils at the boiling point corresponding to the given pressure and the vapors of each component will collect separately and purely. This, however, does not occur even in an idealized system. Idealized models of distillation are essentially governed by Raoult's law and Dalton's law, and assume that vapor–liquid equilibria are attained.\n\nRaoult's law states that the vapor pressure of a solution is dependent on 1) the vapor pressure of each chemical component in the solution and 2) the fraction of solution each component makes up a.k.a. the mole fraction. This law applies to ideal solutions, or solutions that have different components but whose molecular interactions are the same as or very similar to pure solutions.\n\nDalton's law states that the total pressure is the sum of the partial pressures of each individual component in the mixture. When a multi-component liquid is heated, the vapor pressure of each component will rise, thus causing the total vapor pressure to rise. When the total vapor pressure reaches the pressure surrounding the liquid, boiling occurs and liquid turns to gas throughout the bulk of the liquid. Note that a mixture with a given composition has one boiling point at a given pressure, when the components are mutually soluble. A mixture of constant composition does not have multiple boiling points.\n\nAn implication of one boiling point is that lighter components never cleanly \"boil first\". At boiling point, all volatile components boil, but for a component, its percentage in the vapor is the same as its percentage of the total vapor pressure. Lighter components have a higher partial pressure and thus are concentrated in the vapor, but heavier volatile components also have a (smaller) partial pressure and necessarily evaporate also, albeit being less concentrated in the vapor. Indeed, batch distillation and fractionation succeed by varying the composition of the mixture. In batch distillation, the batch evaporates, which changes its composition; in fractionation, liquid higher in the fractionation column contains more lights and boils at lower temperatures. Therefore, starting from a given mixture, it appears to have a boiling range instead of a boiling \"point\", although this is because its composition changes: each intermediate mixture has its own, singular boiling point.\n\nThe idealized model is accurate in the case of chemically similar liquids, such as benzene and toluene. In other cases, severe deviations from Raoult's law and Dalton's law are observed, most famously in the mixture of ethanol and water. These compounds, when heated together, form an azeotrope, which is a composition with a boiling point higher or lower than the boiling point of each separate liquid. Virtually all liquids, when mixed and heated, will display azeotropic behaviour. Although there are computational methods that can be used to estimate the behavior of a mixture of arbitrary components, the only way to obtain accurate vapor–liquid equilibrium data is by measurement.\n\nIt is not possible to \"completely\" purify a mixture of components by distillation, as this would require each component in the mixture to have a zero partial pressure. If ultra-pure products are the goal, then further chemical separation must be applied. When a binary mixture is evaporated and the other component, e.g. a salt, has zero partial pressure for practical purposes, the process is simpler and is called evaporation in engineering.\n\nHeating an ideal mixture of two volatile substances A and B (with A having the higher volatility, or lower boiling point) in a batch distillation setup (such as in an apparatus depicted in the opening figure) until the mixture is boiling results in a vapor above the liquid which contains a mixture of A and B. The ratio between A and B in the vapor will be different from the ratio in the liquid: the ratio in the liquid will be determined by how the original mixture was prepared, while the ratio in the vapor will be enriched in the more volatile compound, A (due to Raoult's Law, see above). The vapor goes through the condenser and is removed from the system. This in turn means that the ratio of compounds in the remaining liquid is now different from the initial ratio (i.e., more enriched in B than the starting liquid).\n\nThe result is that the ratio in the liquid mixture is changing, becoming richer in component B. This causes the boiling point of the mixture to rise, which in turn results in a rise in the temperature in the vapor, which results in a changing ratio of A : B in the gas phase (as distillation continues, there is an increasing proportion of B in the gas phase). This results in a slowly changing ratio A : B in the distillate.\n\nIf the difference in vapor pressure between the two components A and B is large (generally expressed as the difference in boiling points), the mixture in the beginning of the distillation is highly enriched in component A, and when component A has distilled off, the boiling liquid is enriched in component B.\n\nContinuous distillation is an ongoing distillation in which a liquid mixture is continuously (without interruption) fed into the process and separated fractions are removed continuously as output streams occur over time during the operation. Continuous distillation produces a minimum of two output fractions, including at least one volatile distillate fraction, which has boiled and been separately captured as a vapor, and then condensed to a liquid. There is always a bottoms (or residue) fraction, which is the least volatile residue that has not been separately captured as a condensed vapor.\n\nContinuous distillation differs from batch distillation in the respect that concentrations should not change over time. Continuous distillation can be run at a steady state for an arbitrary amount of time. For any source material of specific composition, the main variables that affect the purity of products in continuous distillation are the reflux ratio and the number of theoretical equilibrium stages, in practice determined by the number of trays or the height of packing. Reflux is a flow from the condenser back to the column, which generates a recycle that allows a better separation with a given number of trays. Equilibrium stages are ideal steps where compositions achieve vapor–liquid equilibrium, repeating the separation process and allowing better separation given a reflux ratio. A column with a high reflux ratio may have fewer stages, but it refluxes a large amount of liquid, giving a wide column with a large holdup. Conversely, a column with a low reflux ratio must have a large number of stages, thus requiring a taller column.\n\nBoth batch and continuous distillations can be improved by making use of a fractionating column on top of the distillation flask. The column improves separation by providing a larger surface area for the vapor and condensate to come into contact. This helps it remain at equilibrium for as long as possible. The column can even consist of small subsystems ('trays' or 'dishes') which all contain an enriched, boiling liquid mixture, all with their own vapor–liquid equilibrium.\n\nThere are differences between laboratory-scale and industrial-scale fractionating columns, but the principles are the same. Examples of laboratory-scale fractionating columns (in increasing efficiency) include\n\nLaboratory scale distillations are almost exclusively run as batch distillations. The device used in distillation, sometimes referred to as a \"still\", consists at a minimum of a reboiler or \"pot\" in which the source material is heated, a condenser in which the heated vapour is cooled back to the liquid state, and a receiver in which the concentrated or purified liquid, called the distillate, is collected. Several laboratory scale techniques for distillation exist (see also ).\n\nIn simple distillation, the vapor is immediately channeled into a condenser. Consequently, the distillate is not pure but rather its composition is identical to the composition of the vapors at the given temperature and pressure. That concentration follows Raoult's law.\n\nAs a result, simple distillation is effective only when the liquid boiling points differ greatly (rule of thumb is 25 °C) or when separating liquids from non-volatile solids or oils. For these cases, the vapor pressures of the components are usually different enough that the distillate may be sufficiently pure for its intended purpose.\n\nFor many cases, the boiling points of the components in the mixture will be sufficiently close that Raoult's law must be taken into consideration. Therefore, fractional distillation must be used in order to separate the components by repeated vaporization-condensation cycles within a packed fractionating column. This separation, by successive distillations, is also referred to as rectification.\n\nAs the solution to be purified is heated, its vapors rise to the fractionating column. As it rises, it cools, condensing on the condenser walls and the surfaces of the packing material. Here, the condensate continues to be heated by the rising hot vapors; it vaporizes once more. However, the composition of the fresh vapors are determined once again by Raoult's law. Each vaporization-condensation cycle (called a \"theoretical plate\") will yield a purer solution of the more volatile component. In reality, each cycle at a given temperature does not occur at exactly the same position in the fractionating column; \"theoretical plate\" is thus a concept rather than an accurate description.\n\nMore theoretical plates lead to better separations. A spinning band distillation system uses a spinning band of Teflon or metal to force the rising vapors into close contact with the descending condensate, increasing the number of theoretical plates.\n\nLike vacuum distillation, steam distillation is a method for distilling compounds which are heat-sensitive. The temperature of the steam is easier to control than the surface of a heating element, and allows a high rate of heat transfer without heating at a very high temperature. This process involves bubbling steam through a heated mixture of the raw material. By Raoult's law, some of the target compound will vaporize (in accordance with its partial pressure). The vapor mixture is cooled and condensed, usually yielding a layer of oil and a layer of water.\n\nSteam distillation of various aromatic herbs and flowers can result in two products; an essential oil as well as a watery herbal distillate. The essential oils are often used in perfumery and aromatherapy while the watery distillates have many applications in aromatherapy, food processing and skin care.\n\nSome compounds have very high boiling points. To boil such compounds, it is often better to lower the pressure at which such compounds are boiled instead of increasing the temperature. Once the pressure is lowered to the vapor pressure of the compound (at the given temperature), boiling and the rest of the distillation process can commence. This technique is referred to as vacuum distillation and it is commonly found in the laboratory in the form of the rotary evaporator.\n\nThis technique is also very useful for compounds which boil beyond their decomposition temperature at atmospheric pressure and which would therefore be decomposed by any attempt to boil them under atmospheric pressure.\n\nMolecular distillation is vacuum distillation below the pressure of 0.01 torr. 0.01 torr is one order of magnitude above high vacuum, where fluids are in the free molecular flow regime, i.e. the mean free path of molecules is comparable to the size of the equipment. The gaseous phase no longer exerts significant pressure on the substance to be evaporated, and consequently, rate of evaporation no longer depends on pressure. That is, because the continuum assumptions of fluid dynamics no longer apply, mass transport is governed by molecular dynamics rather than fluid dynamics. Thus, a short path between the hot surface and the cold surface is necessary, typically by suspending a hot plate covered with a film of feed next to a cold plate with a line of sight in between. Molecular distillation is used industrially for purification of oils.\n\nSome compounds have high boiling points as well as being air sensitive. A simple vacuum distillation system as exemplified above can be used, whereby the vacuum is replaced with an inert gas after the distillation is complete. However, this is a less satisfactory system if one desires to collect fractions under a reduced pressure. To do this a \"cow\" or \"pig\" adaptor can be added to the end of the condenser, or for better results or for very air sensitive compounds a Perkin triangle apparatus can be used.\n\nThe Perkin triangle, has means via a series of glass or Teflon taps to allows fractions to be isolated from the rest of the still, without the main body of the distillation being removed from either the vacuum or heat source, and thus can remain in a state of reflux. To do this, the sample is first isolated from the vacuum by means of the taps, the vacuum over the sample is then replaced with an inert gas (such as nitrogen or argon) and can then be stoppered and removed. A fresh collection vessel can then be added to the system, evacuated and linked back into the distillation system via the taps to collect a second fraction, and so on, until all fractions have been collected.\n\nShort path distillation is a distillation technique that involves the distillate travelling a short distance, often only a few centimeters, and is normally done at reduced pressure. A classic example would be a distillation involving the distillate travelling from one glass bulb to another, without the need for a condenser separating the two chambers. This technique is often used for compounds which are unstable at high temperatures or to purify small amounts of compound. The advantage is that the heating temperature can be considerably lower (at reduced pressure) than the boiling point of the liquid at standard pressure, and the distillate only has to travel a short distance before condensing. A short path ensures that little compound is lost on the sides of the apparatus. The Kugelrohr is a kind of a short path distillation apparatus which often contain multiple chambers to collect distillate fractions.\n\nZone distillation is a distillation process in long container with partial melting of refined matter in moving liquid zone and condensation of vapor in the solid phase at condensate pulling in cold area. The process is worked in theory. When zone heater is moving from the top to the bottom of the container then solid condensate with irregular impurity distribution is forming. Then most pure part of the condensate may be extracted as product. The process may be iterated many times by moving (without turnover) the received condensate to the bottom part of the container on the place of refined matter. The irregular impurity distribution in the condensate (that is efficiency of purification) increases with number of repetitions of the process.\nZone distillation is a distillation analog of zone recrystallization. Impurity distribution in the condensate is described by known equations of zone recrystallization with various numbers of iteration of process – with replacement distribution efficient k of crystallization on separation factor α of distillation.\n\n\nThe unit process of evaporation may also be called \"distillation\":\n\nOther uses:\n\nInteractions between the components of the solution create properties unique to the solution, as most processes entail nonideal mixtures, where Raoult's law does not hold. Such interactions can result in a constant-boiling azeotrope which behaves as if it were a pure compound (i.e., boils at a single temperature instead of a range). At an azeotrope, the solution contains the given component in the same proportion as the vapor, so that evaporation does not change the purity, and distillation does not effect separation. For example, ethyl alcohol and water form an azeotrope of 95.6% at 78.1 °C.\n\nIf the azeotrope is not considered sufficiently pure for use, there exist some techniques to break the azeotrope to give a pure distillate. This set of techniques are known as azeotropic distillation. Some techniques achieve this by \"jumping\" over the azeotropic composition (by adding another component to create a new azeotrope, or by varying the pressure). Others work by chemically or physically removing or sequestering the impurity. For example, to purify ethanol beyond 95%, a drying agent (or desiccant, such as potassium carbonate) can be added to convert the soluble water into insoluble water of crystallization. Molecular sieves are often used for this purpose as well.\n\nImmiscible liquids, such as water and toluene, easily form azeotropes. Commonly, these azeotropes are referred to as a low boiling azeotrope because the boiling point of the azeotrope is lower than the boiling point of either pure component. The temperature and composition of the azeotrope is easily predicted from the vapor pressure of the pure components, without use of Raoult's law. The azeotrope is easily broken in a distillation set-up by using a liquid–liquid separator (a decanter) to separate the two liquid layers that are condensed overhead. Only one of the two liquid layers is refluxed to the distillation set-up.\n\nHigh boiling azeotropes, such as a 20 weight percent mixture of hydrochloric acid in water, also exist. As implied by the name, the boiling point of the azeotrope is greater than the boiling point of either pure component.\n\nTo break azeotropic distillations and cross distillation boundaries, such as in the DeRosier Problem, it is necessary to increase the composition of the light key in the distillate.\n\nThe boiling points of components in an azeotrope overlap to form a band. By exposing an azeotrope to a vacuum or positive pressure, it's possible to bias the boiling point of one component away from the other by exploiting the differing vapour pressure curves of each; the curves may overlap at the azeotropic point, but are unlikely to be remain identical further along the pressure axis either side of the azeotropic point. When the bias is great enough, the two boiling points no longer overlap and so the azeotropic band disappears.\n\nThis method can remove the need to add other chemicals to a distillation, but it has two potential drawbacks.\n\nUnder negative pressure, power for a vacuum source is needed and the reduced boiling points of the distillates requires that the condenser be run cooler to prevent distillate vapours being lost to the vacuum source. Increased cooling demands will often require additional energy and possibly new equipment or a change of coolant.\n\nAlternatively, if positive pressures are required, standard glassware can not be used, energy must be used for pressurization and there is a higher chance of side reactions occurring in the distillation, such as decomposition, due to the higher temperatures required to effect boiling.\n\nA unidirectional distillation will rely on a pressure change in one direction, either positive or negative.\n\nPressure-swing distillation is essentially the same as the unidirectional distillation used to break azeotropic mixtures, but here both positive and negative pressures may be employed.\n\nThis improves the selectivity of the distillation and allows a chemist to optimize distillation by avoiding extremes of pressure and temperature that waste energy. This is particularly important in commercial applications.\n\nOne example of the application of pressure-swing distillation is during the industrial purification of ethyl acetate after its catalytic synthesis from ethanol.\n\nLarge scale industrial distillation applications include both batch and continuous fractional, vacuum, azeotropic, extractive, and steam distillation. The most widely used industrial applications of continuous, steady-state fractional distillation are in petroleum refineries, petrochemical and chemical plants and natural gas processing plants.\n\nTo control and optimize such industrial distillation, a standardized laboratory method, ASTM D86, is established. This test method extends to the atmospheric distillation of petroleum products using a laboratory batch distillation unit to quantitatively determine the boiling range characteristics of petroleum products.\n\nIndustrial distillation is typically performed in large, vertical cylindrical columns known as distillation towers or distillation columns with diameters ranging from about 65 centimeters to 16 meters and heights ranging from about 6 meters to 90 meters or more. When the process feed has a diverse composition, as in distilling crude oil, liquid outlets at intervals up the column allow for the withdrawal of different \"fractions\" or products having different boiling points or boiling ranges. The \"lightest\" products (those with the lowest boiling point) exit from the top of the columns and the \"heaviest\" products (those with the highest boiling point) exit from the bottom of the column and are often called the bottoms.\nIndustrial towers use reflux to achieve a more complete separation of products. Reflux refers to the portion of the condensed overhead liquid product from a distillation or fractionation tower that is returned to the upper part of the tower as shown in the schematic diagram of a typical, large-scale industrial distillation tower. Inside the tower, the downflowing reflux liquid provides cooling and condensation of the upflowing vapors thereby increasing the efficiency of the distillation tower. The more reflux that is provided for a given number of theoretical plates, the better the tower's separation of lower boiling materials from higher boiling materials. Alternatively, the more reflux that is provided for a given desired separation, the fewer the number of theoretical plates required. Chemical engineers must choose what combination of reflux rate and number of plates is both economically and physically feasible for the products purified in the distillation column.\n\nSuch industrial fractionating towers are also used in cryogenic air separation, producing liquid oxygen, liquid nitrogen, and high purity argon. Distillation of chlorosilanes also enables the production of high-purity silicon for use as a semiconductor.\nDesign and operation of a distillation tower depends on the feed and desired products. Given a simple, binary component feed, analytical methods such as the McCabe–Thiele method or the Fenske equation can be used. For a multi-component feed, simulation models are used both for design and operation. Moreover, the efficiencies of the vapor–liquid contact devices (referred to as \"plates\" or \"trays\") used in distillation towers are typically lower than that of a theoretical 100% efficient equilibrium stage. Hence, a distillation tower needs more trays than the number of theoretical vapor–liquid equilibrium stages. A variety of models have been postulated to estimate tray efficiencies.\n\nIn modern industrial uses, a packing material is used in the column instead of trays when low pressure drops across the column are required. Other factors that favor packing are: vacuum systems, smaller diameter columns, corrosive systems, systems prone to foaming, systems requiring low liquid holdup, and batch distillation. Conversely, factors that favor plate columns are: presence of solids in feed, high liquid rates, large column diameters, complex columns, columns with wide feed composition variation, columns with a chemical reaction, absorption columns, columns limited by foundation weight tolerance, low liquid rate, large turn-down ratio and those processes subject to process surges.\n\nThis packing material can either be random dumped packing (1–3\" wide) such as Raschig rings or structured sheet metal. Liquids tend to wet the surface of the packing and the vapors pass across this wetted surface, where mass transfer takes place. Unlike conventional tray distillation in which every tray represents a separate point of vapor–liquid equilibrium, the vapor–liquid equilibrium curve in a packed column is continuous. However, when modeling packed columns, it is useful to compute a number of \"theoretical stages\" to denote the separation efficiency of the packed column with respect to more traditional trays. Differently shaped packings have different surface areas and void space between packings. Both of these factors affect packing performance.\n\nAnother factor in addition to the packing shape and surface area that affects the performance of random or structured packing is the liquid and vapor distribution entering the packed bed. The number of theoretical stages required to make a given separation is calculated using a specific vapor to liquid ratio. If the liquid and vapor are not evenly distributed across the superficial tower area as it enters the packed bed, the liquid to vapor ratio will not be correct in the packed bed and the required separation will not be achieved. The packing will appear to not be working properly. The height equivalent to a theoretical plate (HETP) will be greater than expected. The problem is not the packing itself but the mal-distribution of the fluids entering the packed bed. Liquid mal-distribution is more frequently the problem than vapor. The design of the liquid distributors used to introduce the feed and reflux to a packed bed is critical to making the packing perform to it maximum efficiency. Methods of evaluating the effectiveness of a liquid distributor to evenly distribute the liquid entering a packed bed can be found in references. Considerable work as been done on this topic by Fractionation Research, Inc. (commonly known as FRI).\n\nThe goal of multi-effect distillation is to increase the energy efficiency of the process, for use in desalination, or in some cases one stage in the production of ultrapure water. The number of effects is inversely proportional to the kW·h/m of water recovered figure, and refers to the volume of water recovered per unit of energy compared with single-effect distillation. One effect is roughly 636 kW·h/m.\n\n\nThere are many other types of multi-effect distillation processes, including one referred to as simply multi-effect distillation (MED), in which multiple chambers, with intervening heat exchangers, are employed.\n\nCarbohydrate-containing plant materials are allowed to ferment, producing a dilute solution of ethanol in the process. Spirits such as whiskey and rum are prepared by distilling these dilute solutions of ethanol. Components other than ethanol, including water, esters, and other alcohols, are collected in the condensate, which account for the flavor of the beverage. Some of these beverages are then stored in barrels or other containers to acquire more flavor compounds and characteristic flavors.\n\n\n\n"}
{"id": "8302", "url": "https://en.wikipedia.org/wiki?curid=8302", "title": "David Hilbert", "text": "David Hilbert\n\nDavid Hilbert (; 23 January 1862 – 14 February 1943) was a German mathematician. He is recognized as one of the most influential and universal mathematicians of the 19th and early 20th centuries. Hilbert discovered and developed a broad range of fundamental ideas in many areas, including invariant theory and the axiomatization of geometry. He also formulated the theory of Hilbert spaces, one of the foundations of functional analysis.\n\nHilbert adopted and warmly defended Georg Cantor's set theory and transfinite numbers. A famous example of his leadership in mathematics is his 1900 presentation of a collection of problems that set the course for much of the mathematical research of the 20th century.\n\nHilbert and his students contributed significantly to establishing rigor and developed important tools used in modern mathematical physics. Hilbert is known as one of the founders of proof theory and mathematical logic, as well as for being among the first to distinguish between mathematics and metamathematics.\n\nHilbert the first of two children of Otto and Maria Therese (Erdtmann) Hilbert, was born in the Province of Prussia, Kingdom of Prussia, either in Königsberg (according to Hilbert's own statement) or in Wehlau (known since 1946 as Znamensk) near Königsberg where his father worked at the time of his birth.\n\nIn late 1872, Hilbert entered the Friedrichskolleg Gymnasium (\"Collegium fridericianum\", the same school that Immanuel Kant had attended 140 years before); but, after an unhappy period, he transferred to (late 1879) and graduated from (early 1880) the more science-oriented Wilhelm Gymnasium. Upon graduation, in autumn 1880, Hilbert enrolled at the University of Königsberg, the \"Albertina\". In early 1882, Hermann Minkowski (two years younger than Hilbert and also a native of Königsberg but so talented he had graduated early from his gymnasium and gone to Berlin for three semesters), returned to Königsberg and entered the university. \"Hilbert knew his luck when he saw it. In spite of his father's disapproval, he soon became friends with the shy, gifted Minkowski\".\n\nIn 1884, Adolf Hurwitz arrived from Göttingen as an Extraordinarius (i.e., an associate professor). An intense and fruitful scientific exchange among the three began, and Minkowski and Hilbert especially would exercise a reciprocal influence over each other at various times in their scientific careers. Hilbert obtained his doctorate in 1885, with a dissertation, written under Ferdinand von Lindemann, titled \"Über invariante Eigenschaften spezieller binärer Formen, insbesondere der Kugelfunktionen\" (\"On the invariant properties of special binary forms, in particular the spherical harmonic functions\").\n\nHilbert remained at the University of Königsberg as a \"Privatdozent\" (senior lecturer) from 1886 to 1895. In 1895, as a result of intervention on his behalf by Felix Klein, he obtained the position of Professor of Mathematics at the University of Göttingen. During the Klein and Hilbert years, Göttingen became the preeminent institution in the mathematical world. He remained there for the rest of his life.\n\nAmong Hilbert's students were Hermann Weyl, chess champion Emanuel Lasker, Ernst Zermelo, and Carl Gustav Hempel. John von Neumann was his assistant. At the University of Göttingen, Hilbert was surrounded by a social circle of some of the most important mathematicians of the 20th century, such as Emmy Noether and Alonzo Church.\n\nAmong his 69 Ph.D. students in Göttingen were many who later became famous mathematicians, including (with date of thesis): Otto Blumenthal (1898), Felix Bernstein (1901), Hermann Weyl (1908), Richard Courant (1910), Erich Hecke (1910), Hugo Steinhaus (1911), and Wilhelm Ackermann (1925). Between 1902 and 1939 Hilbert was editor of the \"Mathematische Annalen\", the leading mathematical journal of the time.\n\nAround 1925, Hilbert developed pernicious anemia, a then-untreatable vitamin deficiency whose primary symptom is exhaustion; his assistant Eugene Wigner describes him as subject to \"enormous fatigue\" and how he \"seemed quite old\", and that even after eventually being diagnosed and treated, he \"was hardly a scientist after 1925, and certainly not a Hilbert.\"\n\nHilbert lived to see the Nazis purge many of the prominent faculty members at University of Göttingen in 1933. Those forced out included Hermann Weyl (who had taken Hilbert's chair when he retired in 1930), Emmy Noether and Edmund Landau. One who had to leave Germany, Paul Bernays, had collaborated with Hilbert in mathematical logic, and co-authored with him the important book \"Grundlagen der Mathematik\" (which eventually appeared in two volumes, in 1934 and 1939). This was a sequel to the Hilbert-Ackermann book \"Principles of Mathematical Logic\" from 1928. Hermann Weyl's successor was Helmut Hasse.\n\nAbout a year later, Hilbert attended a banquet and was seated next to the new Minister of Education, Bernhard Rust. Rust asked whether \"the \"Mathematical Institute\" really suffered so much because of the departure of the Jews\". Hilbert replied,\n\"Suffered? It doesn't exist any longer, does it!\"\nBy the time Hilbert died in 1943, the Nazis had nearly completely restaffed the university, as many of the former faculty had either been Jewish or married to Jews. Hilbert's funeral was attended by fewer than a dozen people, only two of whom were fellow academics, among them Arnold Sommerfeld, a theoretical physicist and also a native of Königsberg. News of his death only became known to the wider world six months after he had died.\n\nThe epitaph on his tombstone in Göttingen consists of the famous lines he spoke at the conclusion of his retirement address to the Society of German Scientists and Physicians on 8 September 1930. The words were given in response to the Latin maxim: \"Ignoramus et ignorabimus\" or \"We do not know, we shall not know\":\n\nIn English:\n\nThe day before Hilbert pronounced these phrases at the 1930 annual meeting of the Society of German Scientists and Physicians, Kurt Gödel—in a round table discussion during the Conference on Epistemology held jointly with the Society meetings—tentatively announced the first expression of his incompleteness theorem. Gödel's incompleteness theorems show that even elementary axiomatic systems such as Peano arithmetic are either self-contradicting or contain logical propositions that are impossible to prove or disprove.\n\nIn 1892, Hilbert married Käthe Jerosch (1864–1945), \"the daughter of a Königsberg merchant, an outspoken young lady with an independence of mind that matched his own\". While at Königsberg they had their one child, Franz Hilbert (1893–1969).\n\nHilbert's son Franz suffered throughout his life from an undiagnosed mental illness. His inferior intellect was a terrible disappointment to his father and this misfortune was a matter of distress to the mathematicians and students at Göttingen.\n\nHilbert considered the mathematician Hermann Minkowski to be his \"best and truest friend\".\n\nHilbert was baptized and raised a Calvinist in the Prussian Evangelical Church. He later on left the Church and became an agnostic. He also argued that mathematical truth was independent of the existence of God or other \"a priori\" assumptions.\n\nHilbert's first work on invariant functions led him to the demonstration in 1888 of his famous \"finiteness theorem\". Twenty years earlier, Paul Gordan had demonstrated the theorem of the finiteness of generators for binary forms using a complex computational approach. Attempts to generalize his method to functions with more than two variables failed because of the enormous difficulty of the calculations involved. In order to solve what had become known in some circles as \"Gordan's Problem\", Hilbert realized that it was necessary to take a completely different path. As a result, he demonstrated \"Hilbert's basis theorem\", showing the existence of a finite set of generators, for the invariants of quantics in any number of variables, but in an abstract form. That is, while demonstrating the existence of such a set, it was not a constructive proof — it did not display \"an object\" — but rather, it was an existence proof and relied on use of the law of excluded middle in an infinite extension.\n\nHilbert sent his results to the \"Mathematische Annalen\". Gordan, the house expert on the theory of invariants for the \"Mathematische Annalen\", could not appreciate the revolutionary nature of Hilbert's theorem and rejected the article, criticizing the exposition because it was insufficiently comprehensive. His comment was:\n\nKlein, on the other hand, recognized the importance of the work, and guaranteed that it would be published without any alterations. Encouraged by Klein, Hilbert extended his method in a second article, providing estimations on the maximum degree of the minimum set of generators, and he sent it once more to the \"Annalen\". After having read the manuscript, Klein wrote to him, saying:\n\nLater, after the usefulness of Hilbert's method was universally recognized, Gordan himself would say:\n\nFor all his successes, the nature of his proof stirred up more trouble than Hilbert could have imagined at the time. Although Kronecker had conceded, Hilbert would later respond to others' similar criticisms that \"many different constructions are subsumed under one fundamental idea\" — in other words (to quote Reid): \"Through a proof of existence, Hilbert had been able to obtain a construction\"; \"the proof\" (i.e. the symbols on the page) \"was\" \"the object\". Not all were convinced. While Kronecker would die soon afterwards, his constructivist philosophy would continue with the young Brouwer and his developing intuitionist \"school\", much to Hilbert's torment in his later years. Indeed, Hilbert would lose his \"gifted pupil\" Weyl to intuitionism — \"Hilbert was disturbed by his former student's fascination with the ideas of Brouwer, which aroused in Hilbert the memory of Kronecker\". Brouwer the intuitionist in particular opposed the use of the Law of Excluded Middle over infinite sets (as Hilbert had used it). Hilbert would respond:\n\nThe text \"Grundlagen der Geometrie\" (tr.: \"Foundations of Geometry\") published by Hilbert in 1899 proposes a formal set, called Hilbert's axioms, substituting for the traditional axioms of Euclid. They avoid weaknesses identified in those of Euclid, whose works at the time were still used textbook-fashion. It is difficult to specify the axioms used by Hilbert without referring to the publication history of the \"Grundlagen\" since Hilbert changed and modified them several times. The original monograph was quickly followed by a French translation, in which Hilbert added V.2, the Completeness Axiom. An English translation, authorized by Hilbert, was made by E.J. Townsend and copyrighted in 1902. This translation incorporated the changes made in the French translation and so is considered to be a translation of the 2nd edition. Hilbert continued to make changes in the text and several editions appeared in German. The 7th edition was the last to appear in Hilbert's lifetime. New editions followed the 7th, but the main text was essentially not revised.\nHilbert's approach signaled the shift to the modern axiomatic method. In this, Hilbert was anticipated by Moritz Pasch's work from 1882. Axioms are not taken as self-evident truths. Geometry may treat \"things\", about which we have powerful intuitions, but it is not necessary to assign any explicit meaning to the undefined concepts. The elements, such as point, line, plane, and others, could be substituted, as Hilbert is reported to have said to Schoenflies and Kötter, by tables, chairs, glasses of beer and other such objects. It is their defined relationships that are discussed.\n\nHilbert first enumerates the undefined concepts: point, line, plane, lying on (a relation between points and lines, points and planes, and lines and planes), betweenness, congruence of pairs of points (line segments), and congruence of angles. The axioms unify both the plane geometry and solid geometry of Euclid in a single system.\n\nHilbert put forth a most influential list of 23 unsolved problems at the International Congress of Mathematicians in Paris in 1900. This is generally reckoned the most successful and deeply considered compilation of open problems ever to be produced by an individual mathematician.\n\nAfter re-working the foundations of classical geometry, Hilbert could have extrapolated to the rest of mathematics. His approach differed, however, from the later 'foundationalist' Russell-Whitehead or 'encyclopedist' Nicolas Bourbaki, and from his contemporary Giuseppe Peano. The mathematical community as a whole could enlist in problems, which he had identified as crucial aspects of the areas of mathematics he took to be key.\n\nThe problem set was launched as a talk \"The Problems of Mathematics\" presented during the course of the Second International Congress of Mathematicians held in Paris. The introduction of the speech that Hilbert gave said:\n\nHe presented fewer than half the problems at the Congress, which were published in the acts of the Congress. In a subsequent publication, he extended the panorama, and arrived at the formulation of the now-canonical 23 Problems of Hilbert. See also Hilbert's twenty-fourth problem. The full text is important, since the exegesis of the questions still can be a matter of inevitable debate, whenever it is asked how many have been solved.\n\nSome of these were solved within a short time. Others have been discussed throughout the 20th century, with a few now taken to be unsuitably open-ended to come to closure. Some even continue to this day to remain a challenge for mathematicians.\n\nIn an account that had become standard by the mid-century, Hilbert's problem set was also a kind of manifesto, that opened the way for the development of the formalist school, one of three major schools of mathematics of the 20th century. According to the formalist, mathematics is manipulation of symbols according to agreed upon formal rules. It is therefore an autonomous activity of thought. There is, however, room to doubt whether Hilbert's own views were simplistically formalist in this sense.\n\nIn 1920 he proposed explicitly a research project (in \"metamathematics\", as it was then termed) that became known as Hilbert's program. He wanted mathematics to be formulated on a solid and complete logical foundation. He believed that in principle this could be done, by showing that:\n\n\nHe seems to have had both technical and philosophical reasons for formulating this proposal. It affirmed his dislike of what had become known as the \"ignorabimus\", still an active issue in his time in German thought, and traced back in that formulation to Emil du Bois-Reymond.\n\nThis program is still recognizable in the most popular philosophy of mathematics, where it is usually called \"formalism\". For example, the Bourbaki group adopted a watered-down and selective version of it as adequate to the requirements of their twin projects of (a) writing encyclopedic foundational works, and (b) supporting the axiomatic method as a research tool. This approach has been successful and influential in relation with Hilbert's work in algebra and functional analysis, but has failed to engage in the same way with his interests in physics and logic.\n\nHilbert wrote in 1919:\n\nHilbert published his views on the foundations of mathematics in the 2-volume work Grundlagen der Mathematik.\n\nHilbert and the mathematicians who worked with him in his enterprise were committed to the project. His attempt to support axiomatized mathematics with definitive principles, which could banish theoretical uncertainties, ended in failure.\n\nGödel demonstrated that any non-contradictory formal system, which was comprehensive enough to include at least arithmetic, cannot demonstrate its completeness by way of its own axioms. In 1931 his incompleteness theorem showed that Hilbert's grand plan was impossible as stated. The second point cannot in any reasonable way be combined with the first point, as long as the axiom system is genuinely finitary.\n\nNevertheless, the subsequent achievements of proof theory at the very least \"clarified\" consistency as it relates to theories of central concern to mathematicians. Hilbert's work had started logic on this course of clarification; the need to understand Gödel's work then led to the development of recursion theory and then mathematical logic as an autonomous discipline in the 1930s. The basis for later theoretical computer science, in Alonzo Church and Alan Turing, also grew directly out of this 'debate'.\n\nAround 1909, Hilbert dedicated himself to the study of differential and integral equations; his work had direct consequences for important parts of modern functional analysis. In order to carry out these studies, Hilbert introduced the concept of an infinite dimensional Euclidean space, later called Hilbert space. His work in this part of analysis provided the basis for important contributions to the mathematics of physics in the next two decades, though from an unanticipated direction.\nLater on, Stefan Banach amplified the concept, defining Banach spaces. Hilbert spaces are an important class of objects in the area of functional analysis, particularly of the spectral theory of self-adjoint linear operators, that grew up around it during the 20th century.\n\nUntil 1912, Hilbert was almost exclusively a \"pure\" mathematician. When planning a visit from Bonn, where he was immersed in studying physics, his fellow mathematician and friend Hermann Minkowski joked he had to spend 10 days in quarantine before being able to visit Hilbert. In fact, Minkowski seems responsible for most of Hilbert's physics investigations prior to 1912, including their joint seminar in the subject in 1905.\n\nIn 1912, three years after his friend's death, Hilbert turned his focus to the subject almost exclusively. He arranged to have a \"physics tutor\" for himself. He started studying kinetic gas theory and moved on to elementary radiation theory and the molecular theory of matter. Even after the war started in 1914, he continued seminars and classes where the works of Albert Einstein and others were followed closely.\n\nBy 1907 Einstein had framed the fundamentals of the theory of gravity, but then struggled for nearly 8 years with a confounding problem of putting the theory into final form. By early summer 1915, Hilbert's interest in physics had focused on general relativity, and he invited Einstein to Göttingen to deliver a week of lectures on the subject. Einstein received an enthusiastic reception at Göttingen. Over the summer Einstein learned that Hilbert was also working on the field equations and redoubled his own efforts. During November 1915 Einstein published several papers culminating in \"The Field Equations of Gravitation\" (see Einstein field equations). Nearly simultaneously David Hilbert published \"The Foundations of Physics\", an axiomatic derivation of the field equations (see Einstein–Hilbert action). Hilbert fully credited Einstein as the originator of the theory, and no public priority dispute concerning the field equations ever arose between the two men during their lives. See more at priority.\n\nAdditionally, Hilbert's work anticipated and assisted several advances in the mathematical formulation of quantum mechanics. His work was a key aspect of Hermann Weyl and John von Neumann's work on the mathematical equivalence of Werner Heisenberg's matrix mechanics and Erwin Schrödinger's wave equation and his namesake Hilbert space plays an important part in quantum theory. In 1926 von Neumann showed that if atomic states were understood as vectors in Hilbert space, then they would correspond with both Schrödinger's wave function theory and Heisenberg's matrices.\n\nThroughout this immersion in physics, Hilbert worked on putting rigor into the mathematics of physics. While highly dependent on higher math, physicists tended to be \"sloppy\" with it. To a \"pure\" mathematician like Hilbert, this was both \"ugly\" and difficult to understand. As he began to understand physics and how physicists were using mathematics, he developed a coherent mathematical theory for what he found, most importantly in the area of integral equations. When his colleague Richard Courant wrote the now classic \"Methoden der mathematischen Physik\" (Methods of Mathematical Physics) including some of Hilbert's ideas, he added Hilbert's name as author even though Hilbert had not directly contributed to the writing. Hilbert said \"Physics is too hard for physicists\", implying that the necessary mathematics was generally beyond them; the Courant-Hilbert book made it easier for them.\n\nHilbert unified the field of algebraic number theory with his 1897 treatise \"Zahlbericht\" (literally \"report on numbers\"). He also resolved a significant number-theory problem formulated by Waring in 1770. As with the finiteness theorem, he used an existence proof that shows there must be solutions for the problem rather than providing a mechanism to produce the answers. He then had little more to publish on the subject; but the emergence of Hilbert modular forms in the dissertation of a student means his name is further attached to a major area.\n\nHe made a series of conjectures on class field theory. The concepts were highly influential, and his own contribution lives on in the names of the Hilbert class field and of the Hilbert symbol of local class field theory. Results were mostly proved by 1930, after work by Teiji Takagi.\n\nHilbert did not work in the central areas of analytic number theory, but his name has become known for the Hilbert–Pólya conjecture, for reasons that are anecdotal.\n\nHis collected works (\"Gesammelte Abhandlungen\") have been published several times. The original versions of his papers contained \"many technical errors of varying degree\"; when the collection was first published, the errors were corrected and it was found that this could be done without major changes in the statements of the theorems, with one exception—a claimed proof of the continuum hypothesis. The errors were nonetheless so numerous and significant that it took Olga Taussky-Todd three years to make the corrections.\n\n\n\n"}
{"id": "8303", "url": "https://en.wikipedia.org/wiki?curid=8303", "title": "Down syndrome", "text": "Down syndrome\n\nDown syndrome (DS or DNS), also known as trisomy 21, is a genetic disorder caused by the presence of all or part of a third copy of chromosome 21. It is typically associated with physical growth delays, characteristic facial features and mild to moderate intellectual disability. The average IQ of a young adult with Down syndrome is 50, equivalent to the mental ability of an 8- or 9-year-old child, but this can vary widely.\nThe parents of the affected individual are typically genetically normal. The extra chromosome occurs by chance. The possibility increases from less than 0.1% in 20-year-old mothers to 3% in those age 45. There is no known behavioral activity or environmental factor that changes the possibility. Down syndrome can be identified during pregnancy by prenatal screening followed by diagnostic testing or after birth by direct observation and genetic testing. Since the introduction of screening, pregnancies with the diagnosis are often terminated. Regular screening for health problems common in Down syndrome is recommended throughout the person's life.\nThere is no cure for Down syndrome. Education and proper care have been shown to improve quality of life. Some children with Down syndrome are educated in typical school classes, while others require more specialized education. Some individuals with Down syndrome graduate from high school and a few attend post-secondary education. In adulthood, about 20% in the United States do paid work in some capacity with many requiring a sheltered work environment. Support in financial and legal matters is often needed. Life expectancy is around 50 to 60 years in the developed world with proper health care.\nDown syndrome is one of the most common chromosome abnormalities in humans. It occurs in about one per 1000 babies born each year. In 2015, Down syndrome was present in 5.4 million individuals and resulted in 27,000 deaths down from 43,000 deaths in 1990. It is named after John Langdon Down, the British doctor who fully described the syndrome in 1866. Some aspects of the condition were described earlier by Jean-Étienne Dominique Esquirol in 1838 and Édouard Séguin in 1844. In 1957, the genetic cause of Down syndrome, an extra copy of chromosome 21, was discovered.\n\nThose with Down syndrome nearly always have physical and intellectual disabilities. As adults, their mental abilities are typically similar to those of an 8- or 9-year-old. They also typically have poor immune function and generally reach developmental milestones at a later age. They have an increased risk of a number of other health problems, including congenital heart defect, epilepsy, leukemia, thyroid diseases, and mental disorders, among others.\n\nPeople with Down syndrome may have some or all of these physical characteristics: a small chin, slanted eyes, poor muscle tone, a flat nasal bridge, a single crease of the palm, and a protruding tongue due to a small mouth and relatively large tongue. These airway changes lead to obstructive sleep apnea in around half of those with Down syndrome. Other common features include: a flat and wide face, a short neck, excessive joint flexibility, extra space between big toe and second toe, abnormal patterns on the fingertips and short fingers. Instability of the atlantoaxial joint occurs in about 20% and may lead to spinal cord injury in 1–2%. Hip dislocations may occur without trauma in up to a third of people with Down syndrome.\n\nGrowth in height is slower, resulting in adults who tend to have short stature—the average height for men is 154 cm (5 ft 1 in) and for women is 142 cm (4 ft 8 in). Individuals with Down syndrome are at increased risk for obesity as they age. Growth charts have been developed specifically for children with Down syndrome.\n\nMost individuals with Down syndrome have mild (IQ: 50–69) or moderate (IQ: 35–50) intellectual disability with some cases having severe (IQ: 20–35) difficulties. Those with mosaic Down syndrome typically have IQ scores 10–30 points higher. As they age, people with Down syndrome typically perform less well than their same-age peers. Some after 30 years of age may lose their ability to speak. This syndrome causes about a third of cases of intellectual disability. Many developmental milestones are delayed with the ability to crawl typically occurring around 8 months rather than 5 months and the ability to walk independently typically occurring around 21 months rather than 14 months.\n\nCommonly, individuals with Down syndrome have better language understanding than ability to speak. Between 10 and 45% have either a stutter or rapid and irregular speech, making it difficult to understand them. They typically do fairly well with social skills. Behavior problems are not generally as great an issue as in other syndromes associated with intellectual disability. In children with Down syndrome, mental illness occurs in nearly 30% with autism occurring in 5–10%. People with Down syndrome experience a wide range of emotions. While people with Down syndrome are generally happy, symptoms of depression and anxiety may develop in early adulthood.\n\nChildren and adults with Down syndrome are at increased risk of epileptic seizures, which occur in 5–10% of children and up to 50% of adults. This includes an increased risk of a specific type of seizure called infantile spasms. Many (15%) who live 40 years or longer develop Alzheimer disease. In those who reach 60 years of age, 50–70% have the disease.\n\nHearing and vision disorders occur in more than half of people with Down syndrome. \n\nVision problems occur in 38 to 80%. Between 20 and 50% have strabismus, in which the two eyes do not move together. Cataracts (cloudiness of the lens of the eye) occur in 15%, and may be present at birth. Keratoconus (a thin, cone-shaped cornea) and glaucoma (increased eye pressure) are also more common, as are refractive errors requiring glasses or contacts. Brushfield spots (small white or grayish/brown spots on the outer part of the iris) are present in 38 to 85% of individuals.\nHearing problems are found in 50–90% of children with Down syndrome. This is often the result of otitis media with effusion which occurs in 50–70% and chronic ear infections which occur in 40 to 60%. Ear infections often begin in the first year of life and are partly due to poor eustachian tube function. Excessive ear wax can also cause hearing loss due to obstruction of the outer ear canal. Even a mild degree of hearing loss can have negative consequences for speech, language understanding, and academics. Additionally, it is important to rule out hearing loss as a factor in social and cognitive deterioration. Age-related hearing loss of the sensorineural type occurs at a much earlier age and affects 10–70% of people with Down syndrome.\n\nThe rate of congenital heart disease in newborns with Down syndrome is around 40%. Of those with heart disease, about 80% have an atrioventricular septal defect or ventricular septal defect with the former being more common. Mitral valve problems become common as people age, even in those without heart problems at birth. Other problems that may occur include tetralogy of Fallot and patent ductus arteriosus. People with Down syndrome have a lower risk of hardening of the arteries.\n\nAlthough the overall risk of cancer is not changed, the risk of leukemia and testicular cancer is increased and risk of solid cancers is reduced. Solid cancers are believed to be less common due to increased expression of tumor suppressor genes present on chromosome 21.\n\nCancers of the blood are 10 to 15 times more common in children with Down syndrome. In particular, acute lymphoblastic leukemia is 20 times more common and the megakaryoblastic form of acute myeloid leukemia is 500 times more common. Transient myeloproliferative disease, a disorder of blood cell production that does not occur outside of Down syndrome, affects 3–10% of infants. The disorder is typically not serious but occasionally can be. It resolves most times without treatment; however, in those who have had it, a 20 to 30% risk of developing acute lymphoblastic leukemia at a later time exists.\n\nProblems of the thyroid gland occur in 20–50% of individuals with Down syndrome. Low thyroid is the most common form, occurring in almost half of all individuals. Thyroid problems can be due to a poorly or nonfunctioning thyroid at birth (known as congenital hypothyroidism) which occurs in 1% or can develop later due to an attack on the thyroid by the immune system resulting in Graves' disease or autoimmune hypothyroidism. Type 1 diabetes mellitus is also more common.\n\nConstipation occurs in nearly half of people with Down syndrome and may result in changes in behavior. One potential cause is Hirschsprung's disease, occurring in 2–15%, which is due to a lack of nerve cells controlling the colon. Other frequent congenital problems include duodenal atresia, pyloric stenosis, Meckel diverticulum, and imperforate anus. Celiac disease affects about 7–20% and gastroesophageal reflux disease is also more common.\n\nIndividuals with Down syndrome tend to be more susceptible to gingivitis as well as early, severe periodontal disease, necrotising ulcerative gingivitis, and early tooth loss, especially in the lower front teeth. While plaque and poor oral hygiene are contributing factors, the severity of these periodontal disease cannot be explained solely by external factors. Research suggests that the severity is likely a result of a weakened immune system. The weakened immune system also contributes to increased incidence of yeast infections in the mouth (from Candida albicans).\n\nIndividuals with Down syndrome also tend to have a more alkaline saliva resulting in a greater resistance to tooth decay, despite decreased quantities of saliva, less effective oral hygiene habits and higher plaque indexes.\n\nHigher rates of tooth wear and bruxism are also common. Other common oral manifestations of Down syndrome include enlarged hypotonic tongue, crusted and hypotonic lips, mouth breathing, narrow palate with crowded teeth, class III malocclusion with an underdeveloped maxilla and posterior crossbite, delayed exfoliation of baby teeth and delayed eruption of adult teeth, shorter roots on teeth, and often missing and malformed (usually smaller) teeth. Less common manifestations include cleft lip and palate, enamel hypocalcification (20% prevalence).\n\nMales with Down syndrome usually do not father children, while females have lower rates of fertility relative to those who are unaffected. Fertility is estimated to be present in 30–50% of females. Menopause typically occurs at an earlier age. The poor fertility in males is thought to be due to problems with sperm development; however, it may also be related to not being sexually active. As of 2006, three instances of males with Down syndrome fathering children and 26 cases of females having children have been reported. Without assisted reproductive technologies, around half of the children of someone with Down syndrome will also have the syndrome.\n\nDown syndrome is caused by having three copies of the genes on chromosome 21, rather than the usual two. The parents of the affected individual are typically genetically normal. Those who have one child with Down syndrome have about a 1% risk of having a second child with the syndrome, if both parents are found to have normal karyotypes.\n\nThe extra chromosome content can arise through several different ways. The most common cause (about 92–95% of cases) is a complete extra copy of chromosome 21, resulting in trisomy 21. In 1.0 to 2.5% of cases, some of the cells in the body are normal and others have trisomy 21, known as mosaic Down syndrome. The other common mechanisms that can give rise to Down syndrome include: a Robertsonian translocation, isochromosome, or ring chromosome. These contain additional material from chromosome 21 and occur in about 2.5% of cases. An isochromosome results when the two long arms of a chromosome separate together rather than the long and short arm separating together during egg or sperm development.\n\nTrisomy 21 (also known by the karyotype 47,XX,+21 for females and 47,XY,+21 for males) is caused by a failure of the 21st chromosome to separate during egg or sperm development. As a result, a sperm or egg cell is produced with an extra copy of chromosome 21; this cell thus has 24 chromosomes. When combined with a normal cell from the other parent, the baby has 47 chromosomes, with three copies of chromosome 21. About 88% of cases of trisomy 21 result from nonseparation of the chromosomes in the mother, 8% from nonseparation in the father, and 3% after the egg and sperm have merged.\n\nThe extra chromosome 21 material may also occur due to a Robertsonian translocation in 2–4% of cases. In this situation, the long arm of chromosome 21 is attached to another chromosome, often chromosome 14. In a male affected with Down syndrome, it results in a karyotype of 46XY,t(14q21q). This may be a new mutation or previously present in one of the parents. The parent with such a translocation is usually normal physically and mentally; however, during production of egg or sperm cells, a higher chance of creating reproductive cells with extra chromosome 21 material exists. This results in a 15% chance of having a child with Down syndrome when the mother is affected and a less than 5% probability if the father is affected. The probability of this type of Down syndrome is not related to the mother's age. Some children without Down syndrome may inherit the translocation and have a higher probability of having children of their own with Down syndrome. In this case it is sometimes known as familial Down syndrome.\n\nThe extra genetic material present in DS results in overexpression of a portion of the 310 genes located on chromosome 21. This overexpression has been estimated at around 50%. Some research has suggested the Down syndrome critical region is located at bands 21q22.1–q22.3, with this area including genes for amyloid, superoxide dismutase, and likely the ETS2 proto oncogene. Other research, however, has not confirmed these findings. microRNAs is also proposed to be involved.\n\nThe dementia which occurs in Down syndrome is due to an excess of amyloid beta peptide produced in the brain and is similar to Alzheimer's disease. This peptide is processed from amyloid precursor protein, the gene for which is located on chromosome 21. Senile plaques and neurofibrillary tangles are present in nearly all by 35 years of age, though dementia may not be present. Those with DS also lack a normal number of lymphocytes and produce less antibodies which contributes to their increased risk of infection.\n\nDown syndrome is associated with an increased risk of many chronic diseases that are typically associated with older age such as Alzheimer's disease. The accelerated aging suggest that trisomy 21 increases the biological age of tissues, but molecular evidence for this hypothesis is sparse. According to a biomarker of tissue age known as epigenetic clock, trisomy 21 increases the age of blood and brain tissue (on average by 6.6 years).\n\nGuidelines recommend screening for Down syndrome to be offered to all pregnant women, regardless of age. A number of tests are used, with varying levels of accuracy. They are typically used in combination to increase the detection rate. None can be definitive, thus if screening is positive, either amniocentesis or chorionic villous sampling is required to confirm the diagnosis. Screening in both the first and second trimesters is better than just screening in the first trimester. The different screening techniques in use are able to pick up 90 to 95% of cases with a false-positive rate of 2 to 5%.\n\nUltrasound imaging can be used to screen for Down syndrome. Findings that indicate increased risk when seen at 14 to 24 weeks of gestation include a small or no nasal bone, large ventricles, nuchal fold thickness, and an abnormal right subclavian artery, among others. The presence or absence of many markers is more accurate. Increased fetal nuchal translucency (NT) indicates an increased risk of Down syndrome picking up 75–80% of cases and being falsely positive in 6%.\n\nSeveral blood markers can be measured to predict the risk of Down syndrome during the first or second trimester. Testing in both trimesters is sometimes recommended and test results are often combined with ultrasound results. In the second trimester, often two or three tests are used in combination with two or three of: α-fetoprotein, unconjugated estriol, total hCG, and free βhCG detecting about 60–70% of cases.\n\nTesting of the mother's blood for fetal DNA is being studied and appears promising in the first trimester. The International Society for Prenatal Diagnosis considers it a reasonable screening option for those women whose pregnancies are at a high risk for trisomy 21. Accuracy has been reported at 98.6% in the first trimester of pregnancy. Confirmatory testing by invasive techniques (amniocentesis, CVS) is still required to confirm the screening result.\n\nWhen screening tests predict a high risk of Down syndrome, a more invasive diagnostic test (amniocentesis or chorionic villus sampling) is needed to confirm the diagnosis. If Down syndrome occurs in one in 500 pregnancies and the test used has a 5% false-positive rate, this means, of 26 women who test positive on screening, only one will have Down syndrome confirmed. If the screening test has a 2% false-positive rate, this means one of eleven who test positive on screening have a fetus with DS. Amniocentesis and chorionic villus sampling are more reliable tests, but they increase the risk of miscarriage between 0.5 and 1%. The risk of limb problems is increased in the offspring due to the procedure. The risk from the procedure is greater the earlier it is performed, thus amniocentesis is not recommended before 15 weeks gestational age and chorionic villus sampling before 10 weeks gestational age.\n\nAbout 92% of pregnancies in Europe with a diagnosis of Down syndrome are terminated. In the United States, termination rates are around 67%, but this rate varied from 61% to 93% among different populations evaluated. When nonpregnant people are asked if they would have a termination if their fetus tested positive, 23–33% said yes, when high-risk pregnant women were asked, 46–86% said yes, and when women who screened positive are asked, 89–97% say yes.\n\nThe diagnosis can often be suspected based on the child's physical appearance at birth. An analysis of the child's chromosomes is needed to confirm the diagnosis, and to determine if a translocation is present, as this may help determine the risk of the child's parents having further children with Down syndrome. Parents generally wish to know the possible diagnosis once it is suspected and do not wish pity.\n\nEfforts such as early childhood intervention, screening for common problems, medical treatment where indicated, a good family environment, and work-related training can improve the development of children with Down syndrome. Education and proper care can improve quality of life. Raising a child with Down syndrome is more work for parents than raising an unaffected child. Typical childhood vaccinations are recommended.\n\nA number of health organizations have issued recommendations for screening those with Down syndrome for particular diseases. This is recommended to be done systematically.\n\nAt birth, all children should get an electrocardiogram and ultrasound of the heart. Surgical repair of heart problems may be required as early as three months of age. Heart valve problems may occur in young adults, and further ultrasound evaluation may be needed in adolescents and in early adulthood. Due to the elevated risk of testicular cancer, some recommend checking the person's testicles yearly.\n\nHearing aids or other amplification devices can be useful for language learning in those with hearing loss. Speech therapy may be useful and is recommended to be started around 9 months of age. As those with Down syndrome typically have good hand-eye coordination, learning sign language may be possible. Augmentative and alternative communication methods, such as pointing, body language, objects, or pictures, are often used to help with communication. Behavioral issues and mental illness are typically managed with counseling or medications.\nEducation programs before reaching school age may be useful. School-age children with Down syndrome may benefit from inclusive education (whereby students of differing abilities are placed in classes with their peers of the same age), provided some adjustments are made to the curriculum. Evidence to support this, however, is not very strong. In the United States, the Individuals with Disabilities Education Act of 1975 requires public schools generally to allow attendance by students with Down syndrome.\nIndividuals with Down syndrome may learn better visually. Drawing may help with language, speech, and reading skills. Children with Down syndrome still often have difficulty with sentence structure and grammar, as well as developing the ability to speak clearly. Several types of early intervention can help with cognitive development. Efforts to develop motor skills include physical therapy, speech and language therapy, and occupational therapy. Physical therapy focuses specifically on motor development and teaching children to interact with their environment. Speech and language therapy can help prepare for later language. Lastly, occupational therapy can help with skills needed for later independence.\n\nTympanostomy tubes are often needed and often more than one set during the person's childhood. Tonsillectomy is also often done to help with sleep apnea and throat infections. Surgery, however, does not always address the sleep apnea and a continuous positive airway pressure (CPAP) machine may be useful. Physical therapy and participation in physical education may improve motor skills. Evidence to support this in adults, however, is not very good.\n\nEfforts to prevent respiratory syncytial virus (RSV) infection with human monoclonal antibodies should be considered, especially in those with heart problems. In those who develop dementia there is no evidence for memantine, donepezil, rivastigmine, or galantamine.\n\nPlastic surgery has been suggested as a method of improving the appearance and thus the acceptance of people with Down syndrome. It has also been proposed as a way to improve speech. Evidence, however, does not support a meaningful difference in either of these outcomes. Plastic surgery on children with Down syndrome is uncommon, and continues to be controversial. The U.S. National Down Syndrome Society views the goal as one of mutual respect and acceptance, not appearance.\n\nMany alternative medical techniques are used in Down syndrome; however, they are poorly supported by evidence. These include: dietary changes, massage, animal therapy, chiropractics and naturopathy, among others. Some proposed treatments may also be harmful.\n\nBetween 5 and 15% of children with Down syndrome in Sweden attend regular school. Some graduate from high school; however, most do not. Of those with intellectual disability in the United States who attended high school about 40% graduated. Many learn to read and write and some are able to do paid work. In adulthood about 20% in the United States do paid work in some capacity. In Sweden, however, less than 1% have regular jobs. Many are able to live semi-independently, but they often require help with financial, medical, and legal matters. Those with mosaic Down syndrome usually have better outcomes.\n\nIndividuals with Down syndrome have a higher risk of early death than the general population. This is most often from heart problems or infections. Following improved medical care, particularly for heart and gastrointestinal problems, the life expectancy has increased. This increase has been from 12 years in 1912, to 25 years in the 1980s, to 50 to 60 years in the developed world in the 2000s. Currently between 4 and 12% die in the first year of life. The probability of long-term survival is partly determined by the presence of heart problems. In those with congenital heart problems 60% survive to 10 years and 50% survive to 30 years of age. In those without heart problems 85% survive to 10 years and 80% survive to 30 years of age. About 10% live to 70 years of age. The National Down Syndrome Society have developed information regarding the positive aspects of life with Down syndrome.\n\nGlobally, as of 2010, Down syndrome occurs in about 1 per 1000 births and results in about 17,000 deaths. More children are born with Down syndrome in countries where abortion is not allowed and in countries where pregnancy more commonly occurs at a later age. About 1.4 per 1000 live births in the United States and 1.1 per 1000 live births in Norway are affected. In the 1950s, in the United States, it occurred in 2 per 1000 live births with the decrease since then due to prenatal screening and abortions. The number of pregnancies with Down syndrome is more than two times greater with many spontaneously aborting. It is the cause of 8% of all congenital disorders.\n\nMaternal age affects the chances of having a pregnancy with Down syndrome. At age 20, the chance is one in 1441; at age 30, it is one in 959; at age 40, it is one in 84; and at age 50 it is one in 44. Although the probability increases with maternal age, 70% of children with Down syndrome are born to women 35 years of age and younger, because younger people have more children. The father's older age is also a risk factor in women older than 35, but not in women younger than 35, and may partly explain the increase in risk as women age.\n\nEnglish physician John Langdon Down first described Down syndrome in 1862, recognizing it as a distinct type of mental disability, and again in a more widely published report in 1866. Édouard Séguin described it as separate from cretinism in 1944. By the 20th century, Down syndrome had become the most recognizable form of mental disability.\n\nIn antiquity, many infants with disabilities were either killed or abandoned. A number of historical pieces of art are believed to portray Down syndrome, including pottery from AD 500 from South America and the 16th-century painting \"The Adoration of the Christ Child\".\n\nIn the 20th century, many individuals with Down syndrome were institutionalized, few of the associated medical problems were treated, and most died in infancy or early adult life. With the rise of the eugenics movement, 33 of the then 48 U.S. states and several countries began programs of forced sterilization of individuals with Down syndrome and comparable degrees of disability. Action T4 in Nazi Germany made public policy of a program of systematic involuntary euthanization.\n\nWith the discovery of karyotype techniques in the 1950s, it became possible to identify abnormalities of chromosomal number or shape. In 1959, Jérôme Lejeune reported the discovery that Down syndrome resulted from an extra chromosome. However, Lejeune's claim to the discovery has been disputed, and in 2014, the Scientific Council of the French Federation of Human Genetics unanimously awarded its Grand Prize to his colleague Marthe Gautier for her role in this discovery. The discovery was in the laboratory of Raymond Turpin at the Hôpital Trousseau in Paris, France. Jérôme Lejeune and Marthe Gautier were both his students.\n\nAs a result of this discovery, the condition became known as trisomy 21. Even before the discovery of its cause, the presence of the syndrome in all races, its association with older maternal age, and its rarity of recurrence had been noticed. Medical texts had assumed it was caused by a combination of inheritable factors that had not been identified. Other theories had focused on injuries sustained during birth.\nDue to his perception that children with Down syndrome shared facial similarities with those of Blumenbach's Mongolian race, John Langdon Down used the term \"mongoloid\". He felt that the existence of Down syndrome confirmed that all peoples were genetically related. In the 1950s with discovery of the underlying cause as being related to chromosomes, concerns about the race-based nature of the name increased.\n\nIn 1961, 19 scientists suggested that \"mongolism\" had \"misleading connotations\" and had become \"an embarrassing term\". The World Health Organization (WHO) dropped the term in 1965 after a request by the delegation from the Mongolian People's Republic. While the term mongoloid (also mongolism, Mongolian imbecility or idiocy) continued to be used until the early 1980s, it is now considered unacceptable and is no longer in common use.\n\nIn 1975, the United States National Institutes of Health (NIH) convened a conference to standardize the naming and recommended replacing the possessive form, \"Down's syndrome\" with \"Down syndrome\". However, both the possessive and nonpossessive forms remain in use by the general population. The term \"trisomy 21\" is also used frequently.\n\nSome obstetricians argue that not offering screening for Down syndrome is unethical. As it is a medically reasonable procedure, per informed consent, people should at least be given information about it. It will then be the woman's choice, based on her personal beliefs, how much or how little screening she wishes. When results from testing become available, it is also considered unethical not to give the results to the person in question.\n\nSome bioethicists deem it reasonable for parents to select a child who would have the highest well-being. One criticism of this reasoning is that it often values those with disabilities less. Some parents argue that Down syndrome shouldn't be prevented or cured and that eliminating Down syndrome amounts to genocide. The disability rights movement does not have a position on screening, although some members consider testing and abortion discriminatory. Some in the United States who are pro-life support abortion if the fetus is disabled, while others do not. Of a group of 40 mothers in the United States who have had one child with Down syndrome, half agreed to screening in the next pregnancy.\n\nWithin the US, some Protestants denominations see abortion as acceptable when a fetus has Down syndrome, while Orthodox Christians and Roman Catholics often do not. Some of those against screening refer to it as a form of \"eugenics\". Disagreement exists within Islam regarding the acceptability of abortion in those carrying a fetus with Down syndrome. Some Islamic countries allow abortion, while others do not. Women may face stigmatization whichever decision they make.\n\nAdvocacy groups for individuals with Down syndrome began to be formed after the Second World War. These were organizations advocating for the inclusion of people with Down syndrome into the general school system and for a greater understanding of the condition among the general population, as well as groups providing support for families with children living with Down syndrome. Before this individuals with Down syndrome were often placed in mental hospitals or asylums. Organizations included the Royal Society for Handicapped Children and Adults founded in the UK in 1946 by Judy Fryd, Kobato Kai founded in Japan in 1964, the National Down Syndrome Congress founded in the United States in 1973 by Kathryn McGee and others, and the National Down Syndrome Society founded in 1979 in the United States.\n\nThe first World Down Syndrome Day was held on 21 March 2006. The day and month were chosen to correspond with 21 and trisomy, respectively. It was recognized by the United Nations General Assembly in 2011.\n\nEfforts are underway to determine how the extra chromosome 21 material causes Down syndrome, as currently this is unknown, and to develop treatments to improve intelligence in those with the syndrome. One hope is to use stem cells. Other methods being studied include the use of antioxidants, gamma secretase inhibition, adrenergic agonists, and memantine. Research is often carried out on an animal model, the Ts65Dn mouse.\n\n"}
{"id": "8305", "url": "https://en.wikipedia.org/wiki?curid=8305", "title": "Dyslexia", "text": "Dyslexia\n\nDyslexia, also known as reading disorder, is characterized by trouble with reading despite normal intelligence. Different people are affected to varying degrees. Problems may include difficulties in spelling words, reading quickly, writing words, \"sounding out\" words in the head, pronouncing words when reading aloud and understanding what one reads. Often these difficulties are first noticed at school. When someone who previously could read loses their ability, it is known as alexia. The difficulties are involuntary and people with this disorder have a normal desire to learn.\nDyslexia is believed to be caused by both genetic and environmental factors. Some cases run in families. It often occurs in people with attention deficit hyperactivity disorder (ADHD) and is associated with similar difficulties with numbers. It may begin in adulthood as the result of a traumatic brain injury, stroke, or dementia. The underlying mechanisms of dyslexia are problems within the brain's language processing. Dyslexia is diagnosed through a series of tests of memory, spelling, vision, and reading skills. Dyslexia is separate from reading difficulties caused by hearing or vision problems or by insufficient teaching.\nTreatment involves adjusting teaching methods to meet the person's needs. While not curing the underlying problem, it may decrease the degree of symptoms. Treatments targeting vision are not effective. Dyslexia is the most common learning disability and occurs in all areas of the world. It affects 3–7% of the population, however, up to 20% may have some degree of symptoms. While dyslexia is more often diagnosed in men, it has been suggested that it affects men and women equally. Some believe that dyslexia should be best considered as a different way of learning, with both benefits and downsides.\nDyslexia is thought to have two types of cause, one related to language processing and another to visual processing. It is considered a cognitive disorder, not a problem with intelligence. However, emotional problems often arise because of it. Some published definitions are purely descriptive, whereas others propose causes. The latter usually cover a variety of reading skills and deficits, and difficulties with distinct causes rather than a single condition. The National Institute of Neurological Disorders and Stroke definition describes dyslexia as \"difficulty with phonological processing (the manipulation of sounds), spelling, and/or rapid visual-verbal responding\". The British Dyslexia Association definition describes dyslexia as \"a learning difficulty that primarily affects the skills involved in accurate and fluent word reading and spelling\" and is characterized by \"difficulties in phonological awareness, verbal memory and verbal processing speed\".\n\nAcquired dyslexia or alexia may be caused by brain damage due to stroke or atrophy. Forms of alexia include pure alexia, surface dyslexia, semantic dyslexia, phonological dyslexia, and deep dyslexia.\n\nThere is some variability in the definition of dyslexia. Some sources, such as the U.S. National Institutes of Health, define it specifically as a learning disorder. Other sources, however, define it simply as an inability to read in the context of normal intelligence, and distinguish between \"developmental dyslexia\" (a learning disorder) and \"acquired dyslexia\" (loss of the ability to read caused by brain damage). ICD 10, the manual of medical diagnosis used in much of the world, includes separate diagnoses for \"developmental dyslexia\" (81.0) and for \"dyslexia and alexia\" (48.0). DSM 5, the manual of psychiatric diagnosis used in the United States, does not specifically define dyslexia, justifying this decision by stating that \"the many definitions of dyslexia and dyscalculia meant those terms would not be useful as disorder names or in the diagnostic \ncriteria\". Instead it includes dyslexia in a category called specific learning disorders.\n\nIn early childhood, symptoms that correlate with a later diagnosis of dyslexia include delayed onset of speech, difficulty distinguishing left from right, difficulty with direction, and a lack of phonological awareness, as well as being easily distracted by background noise. A common myth closely associates dyslexia with mirror writing and reading letters or words backwards. These behaviors are seen in many children as they learn to read and write, and are not considered to be defining characteristics of dyslexia.\n\nSchool-age children with dyslexia may exhibit signs of difficulty in identifying or generating rhyming words, or counting the number of syllables in words – both of which depend on phonological awareness. They may also show difficulty in segmenting words into individual sounds or may blend sounds when producing words, indicating reduced phonemic awareness. Difficulties with word retrieval or naming things is also associated with dyslexia. People with dyslexia are commonly poor spellers, a feature sometimes called dysorthographia or dysgraphia, which depends on orthographic coding.\n\nProblems persist into adolescence and adulthood and may accompany difficulties with summarizing stories, memorization, reading aloud, or learning foreign languages. Adults with dyslexia can often read with good comprehension, though they tend to read more slowly than others without a learning difficulty and perform worse in spelling tests or when reading nonsense words – a measure of phonological awareness.\n\nThe orthographic complexity of a language directly impacts how difficult learning to read the language is. English and French have comparatively \"deep\" phonemic orthographies within the Latin alphabet writing system, with complex structures employing spelling patterns on several levels: letter-sound correspondence, syllables, and morphemes. Languages such as Spanish, Italian and Finnish have mostly alphabetic orthographies, which primarily employ letter-sound correspondence – so-called shallow orthographies – which for dyslexics makes them easier to learn. Logographic writing systems, such as Chinese characters, have extensive symbol use, and pose problems for dyslexic learners.\n\nDyslexia is often accompanied by several learning disabilities, but it is unclear whether they share underlying neurological causes. These associated disabilities include:\n\nResearchers have been trying to find the neurobiological basis of dyslexia since the condition was first identified in 1881. For example, some have tried to associate the common problem among dyslexics of not being able to see letters clearly to abnormal development of their visual nerve cells.\n\nModern neuroimaging techniques such as functional magnetic resonance imaging (fMRI) and positron emission tomography (PET) have shown a correlation between both functional and structural differences in the brains of children with reading difficulties. Some dyslexics show less electrical activation in parts of the left hemisphere of the brain involved with reading, such as the inferior frontal gyrus, inferior parietal lobule, and the middle and ventral temporal cortex. Over the past decade, brain activation studies using PET to study language have produced a breakthrough in the understanding of the neural basis of language. Neural bases for the visual lexicon and for auditory verbal short-term memory components have been proposed, with some implication that the observed neural manifestation of developmental dyslexia is task-specific (i.e. functional rather than structural). fMRIs in dyslexics have provided important data which point to the interactive role of the cerebellum and cerebral cortex as well as other brain structures.\n\nThe cerebellar theory of dyslexia proposes that impairment of cerebellum-controlled muscle movement affects the formation of words by the tongue and facial muscles, resulting in the fluency problems that are characteristic of some dyslexics. The cerebellum is also involved in the automatization of some tasks, such as reading. The fact that some dyslexic children have motor task and balance impairments has been used as evidence for a cerebellar role in their reading difficulties. However, the cerebellar theory is not supported by controlled research studies.\n\nResearch into potential genetic causes of dyslexia has its roots in post-autopsy examination of the brains of people with dyslexia. Observed anatomical differences in the language centers of such brains include microscopic cortical malformations known as ectopias, more rarely, vascular micro-malformations, and microgyrus. The previously cited studies and others suggest that abnormal cortical development presumed to occur before or during the sixth month of fetal brain development was the cause of the abnormalities. Abnormal cell formations in dyslexics have also been reported in non-language cerebral and subcortical brain structures. Several genes have been associated with dyslexia, including DCDC2 and KIAA0319 on chromosome 6, and DYX1C1 on chromosome 15.\n\nThe contribution of gene–environment interaction to reading disability has been intensely studied using twin studies, which estimate the proportion of variance associated with a person's environment and the proportion associated with their genes. Studies examining the influence of environmental factors such as parental education and teacher quality have determined that genetics have greater influence in supportive, rather than less optimal, environments. However, more optimal conditions may just allow those genetic risk factors to account for more of the variance in outcome because the environmental risk factors have been minimized. As environment plays a large role in learning and memory, it is likely that epigenetic modifications play an important role in reading ability. Animal experiments and measures of gene expression and methylation in the human periphery are used to study epigenetic processes; however, both types of study have many limitations in the extrapolation of results for application to the human brain.\n\nThe dual-route theory of reading aloud was first described in the early 1970s. This theory suggests that two separate mental mechanisms, or cognitive routes, are involved in reading aloud. One mechanism is the lexical route, which is the process whereby skilled readers can recognize known words by sight alone, through a \"dictionary\" lookup procedure. The other mechanism is the nonlexical or sublexical route, which is the process whereby the reader can \"sound out\" a written word. This is done by identifying the word's constituent parts (letters, phonemes, graphemes) and applying knowledge of how these parts are associated with each other, for example, how a string of neighboring letters sound together. The dual-route system could explain the different rates of dyslexia occurrence between different languages (e.g. the Spanish language dependence on phonological rules accounts for the fact that Spanish-speaking children show a higher level of performance in non-word reading, when compared to English-speakers).\n\nDyslexia disorder is not caused by mutation in one gene; in fact, it appears to involve the combined effects of several genes. Studying the cognitive problems associated with other disorders helps to better understand the genotype-phenotype link of dyslexia. Neurophysiological and imaging procedures are being used to ascertain phenotypic characteristics in dyslexics, thus identifying the effects of certain genes.\n\nThere are tests that can indicate with high probability whether a person is a dyslexic. If diagnostic testing indicates that a person may be dyslexic, such tests are often followed up with a full diagnostic assessment to determine the extent and nature of the disorder. Tests can be administered by a teacher or computer. Some test results indicate how to carry out teaching strategies.\n\nCentral dyslexias include surface dyslexia, semantic dyslexia, phonological dyslexia, and deep dyslexia. ICD-10 reclassified the previous distinction between dyslexia (315.02 in ICD-9) and alexia (315.01 in ICD-9) into a single classification as R48.0. The terms are applied to developmental dyslexia and inherited dyslexia along with developmental aphasia and inherited alexia, which are considered synonymous.\n\nIn surface dyslexia, words with regular pronunciations (highly consistent with their spelling, e.g. \"mint\") are read more accurately than words with irregular pronunciation, such as \"colonel\". Difficulty distinguishing homophones is a diagnostic used for some forms of surface dyslexia. This disorder is usually accompanied by surface agraphia and fluent aphasia. Acquired surface dyslexia arises when a previously literate person experiences brain damage, which results in pronunciation errors that indicate impairment of the lexical route.\n\nIn phonological dyslexia, sufferers can read familiar words but have difficulty with unfamiliar words, such as invented pseudo-words. Phonological dyslexia is associated with lesions in the parts of the brain supplied with blood by the middle cerebral artery. The superior temporal lobe is often also involved. Furthermore, dyslexics compensate by overusing a front-brain region called Broca's area, which is associated with aspects of language and speech. The Lindamood Phoneme Sequencing Program (LiPS) is used to treat phonological dyslexia. This system is based on a three-way sensory feedback process, using auditory, visual, and oral skills to learn to recognize words and word patterns. Case studies with a total of three patients found a significant improvement in spelling and reading ability after using LiPS.\n\nIndividuals with deep dyslexia experience both semantic paralexia (para-dyslexia) and phonological dyslexia, which causes the person to read a word and then say a related meaning instead of the denoted meaning. Deep alexia is associated with clear phonological processing impairments. Deep dyslexia is caused by widespread damage to the brain that often includes the left hemisphere. The \"continuum\" hypothesis claims that deep dyslexia develops from phonological dyslexia.\n\nPeripheral dyslexias have been described as affecting the visual analysis of letters as a result of brain injury. Hemianopsia, a visual field loss on the left/right side of the vertical midline, is associated with this condition.\n\nPure, or phonologically-based, dyslexia, also known as agnosic dyslexia, dyslexia without agraphia, and pure word blindness, is dyslexia due to difficulty in recognizing written sequences of letters (such as words), or sometimes even letters. It is considered '\"pure\" because it is not accompanied by other significant language-related impairments. Pure dyslexia does not affect speech, handwriting style, language or comprehension impairments. Pure dyslexia is caused by lesions on the visual word form area (VWFA). The VWFA is composed of the left lateral occipital sulcus and is activated during reading. A lesion in the VWFA stops transmission between the visual cortex and the left angular gyrus. It can also be caused by a lesion involving the left occipital lobe or the splenium. It is usually accompanied by a homonymous hemianopsia in the right side of the visual field. Multiple oral re-reading (MOR) is a treatment for pure dyslexia. It is considered a top-down processing technique in which affected individuals read and reread texts a predetermined number of times or until reading speed or accuracy improves a predetermined amount.\n\nHemianopic dyslexia is commonly considered to derive from visual field loss due to damage to the primary visual cortex. Sufferers may complain of abnormally slow reading but are able to read individual words normally. This is the most common form of peripheral alexia, and the form with the best evidence of effective treatments.\n\nIn neglect dyslexia, some letters, most commonly those at the beginning or left side of a word, are skipped or misread during reading. This alexia is associated with right parietal lesions. The use of prism glasses has been shown to substantially mitigate this condition.\n\nPeople with attentional dyslexia complain of letter-crowding or migration, sometimes blending elements of two words into one. Sufferers read better when words are presented in isolation rather than flanked by other words and letters. Using a large magnifying glass may help mitigate this condition by reducing the effects of flanking from nearby words; however, no trials of this or indeed any other therapy for left parietal syndromes have been published as of 2014.\n\nThrough the use of compensation strategies, therapy and educational support, dyslexic individuals can learn to read and write. There are techniques and technical aids which help to manage or conceal symptoms of the disorder. Removing stress and anxiety alone can sometimes improve written comprehension. For dyslexia intervention with alphabet-writing systems, the fundamental aim is to increase a child's awareness of correspondences between graphemes (letters) and phonemes (sounds), and to relate these to reading and spelling by teaching how sounds blend into words. It has been found that reinforced collateral training focused on reading and spelling yields longer-lasting gains than oral phonological training alone. Early intervention that is done for children at a young age can be successful in reducing reading failure.\n\nThere is some evidence that the use of specially-tailored fonts may help with dyslexia. These fonts, which include Dyslexie, OpenDyslexic, and Lexia Readable, were created based on the idea that many of the letters of the Latin alphabet are visually similar and may, therefore, confuse people with dyslexia. Dyslexie and OpenDyslexic both put emphasis on making each letter more distinctive in order to be more easily identified. The benefits, however, might simply be due to the added spacing between words.\n\nThere have been many studies conducted regarding intervention in dyslexia. Among these studies one meta-analysis found that there was functional activation as a result.\n\nThere is no evidence demonstrating that the use of music education is effective in improving dyslexic adolescents' reading skills.\n\nDyslexic children require special instruction for word analysis and spelling from an early age. While there are fonts that may help people with dyslexia better understand writing, this might simply be due to the added spacing between words. The prognosis, generally speaking, is positive for individuals who are identified in childhood and receive support from friends and family.\n\nThe percentage of people with dyslexia is unknown, but it has been estimated to be as low as 5% and as high as 17% of the population. While it is diagnosed more often in males, some believe that it affects males and females equally.\n\nThere are different definitions of dyslexia used throughout the world, but despite significant differences in writing systems, dyslexia occurs in different populations. Dyslexia is not limited to difficulty in converting letters to sounds, and Chinese dyslexics may have difficulty converting Chinese characters into their meanings. The Chinese vocabulary uses logographic, monographic, non-alphabet writing where one character can represent an individual phoneme.\n\nThe phonological-processing hypothesis attempts to explain why dyslexia occurs in a wide variety of languages. Furthermore, the relationship between phonological capacity and reading appears to be influenced by orthography.\n\nDyslexia was identified by Oswald Berkhan in 1881, but the term \"dyslexia\" was coined in 1887 by Rudolf Berlin, an ophthalmologist in Stuttgart. He used the term to refer to the case of a young boy who had a severe impairment in learning to read and write, despite showing typical intelligence and physical abilities in all other respects. In 1896, W. Pringle Morgan, a British physician from Seaford, East Sussex, published a description of a reading-specific learning disorder in a report to the \"British Medical Journal\" titled \"Congenital Word Blindness\". The distinction between phonological and surface types of dyslexia is only descriptive, and without any etiological assumption as to the underlying brain mechanisms. However, studies have alluded to potential differences due to variation in performance.\n\nThe majority of currently available dyslexia research relates to alphabetic writing systems, and especially to European languages. However, substantial research is also available regarding dyslexics who speak Arabic, Chinese, Hebrew, or other languages.\n\nAs is the case with any disorder, society often makes an assessment based on incomplete information. Before the 1980s, dyslexia was thought to be a consequence of education, rather than a basic disability. As a result, society often misjudges those with the disorder. There is also sometimes a workplace stigma and negative attitude towards those with dyslexia. If a dyslexic's instructors lack the necessary training to support a child with the condition, there is often a negative effect on the student's learning participation.\n\n\n"}
{"id": "8308", "url": "https://en.wikipedia.org/wiki?curid=8308", "title": "Delft", "text": "Delft\n\nDelft () is a city and a municipality in the Netherlands. It is located in the province of South Holland, to the north of Rotterdam and south of The Hague.\n\nDelft is known for its historic town centre with canals, Delft Blue pottery, the Delft University of Technology, jurist Hugo Grotius, painter Johannes Vermeer and scientist Antony van Leeuwenhoek, and its association with the royal House of Orange-Nassau.\n\nThe city of Delft came into being aside a canal, the 'Delf', which comes from the word \"delven\", meaning delving or digging, and led to the name Delft. It presumably started around the 11th century as a landlord court.\n\nFrom a rural village in the early Middle Ages, Delft developed to a city, that in the 13th century (1246) received its charter. (For some more information about the early development, see Gracht).\"\n\nThe town's association with the House of Orange started when William of Orange (Willem van Oranje), nicknamed William the Silent (Willem de Zwijger), took up residence in 1572. At the time he was the leader of growing national Dutch resistance against Spanish occupation, known as the Eighty Years' War. By then Delft was one of the leading cities of Holland and it was equipped with the necessary city walls to serve as a headquarters. An attack by Spanish forces in October of that year was repelled.\n\nAfter the Act of Abjuration was proclaimed in 1581, Delft became the \"de facto\" capital of the newly independent Netherlands, as the seat of the Prince of Orange.\n\nWhen William was shot dead in 1584, by Balthazar Gerards in the hall of the Prinsenhof, the family's traditional burial place in Breda was still in the hands of the Spanish. Therefore, he was buried in the Delft Nieuwe Kerk (New Church), starting a tradition for the House of Orange that has continued to the present day.\n\nThe Delft Explosion, also known in history as the Delft Thunderclap, occurred on 12 October 1654 when a gunpowder store exploded, destroying much of the city. Over a hundred people were killed and thousands were wounded.\n\nAbout of gunpowder were stored in barrels in a magazine in a former Clarissen convent in the Doelenkwartier district. Cornelis Soetens, the keeper of the magazine, opened the store to check a sample of the powder and a huge explosion followed. Luckily, many citizens were away, visiting a market in Schiedam or a fair in The Hague.\n\nToday, the explosion is remembered primarily for killing Rembrandt's most promising pupil, Carel Fabritius, and destroying almost his entire oeuvre; a pivotal event in Donna Tartt's Pulitzer Prize-winning 2013 novel \"The Goldfinch\".\n\nDelft artist Egbert van der Poel painted several pictures of Delft showing the devastation.\n\nThe city centre retains a large number of monumental buildings, whereas in many streets there are canals of which the borders are connected by typical bridges, altogether making this city a notable tourist destination.\n\nHistorical buildings and other sights of interest include:\n\nDelft is well known for the Delft pottery ceramic products which were styled on the imported Chinese porcelain of the 17th century. The city had an early start in this area since it was a home port of the Dutch East India Company. It can still be seen at the pottery factories De Koninklijke Porceleyne Fles (or Royal Delft) and De Delftse Pauw.\n\nThe painter Johannes Vermeer (1632–1675) was born in Delft. Vermeer used Delft streets and home interiors as the subject or background of his paintings.\nSeveral other famous painters lived and worked in Delft at that time, such as Pieter de Hoogh, Carel Fabritius, Nicolaes Maes, Gerard Houckgeest and Hendrick Cornelisz. van Vliet. They all were members of the Delft School. The Delft School is known for its images of domestic life, views of households, church interiors, courtyards, squares and the streets of Delft. The painters also produced pictures showing historic events, flower paintings, portraits for patrons and the court, and decorative pieces of art.\n\nDelft University of Technology (TU Delft) is one of four universities of technology in the Netherlands. It was founded as an academy for civil engineering in 1842 by King William II. Today just under 20,000 students are enrolled.\n\nThe UNESCO-IHE Institute for Water Education, providing postgraduate education for people from developing countries, draws on the strong tradition in water management and hydraulic engineering of the Delft university.\n\nIn the local economic field essential elements are:\n\nEast of Delft a relatively vast nature and recreation area called the \"Delftse Hout\" (\"Delft Wood\") is situated. Apart from a forest, through which bike-, horseride- and footpaths are leading, it also comprises a vast lake (suitable for swimming and windsurfing), narrow beaches, a restaurant, community gardens, plus campground and other recreational and sports facilities. (There is a possibility to rent bikes at the station).\n\nInside the city apart from a central park there are also several smaller town parks, like \"Nieuwe Plantage\", \"Agnetapark\", \"Kalverbos\" and others.\nFurthermore, there's a Botanical Garden of the TU and an arboretum in Delftse Hout.\n\nDelft was the birthplace of:\n\nBefore 1900\nAfter 1900\n\nOtherwise related\n\n\nDelft is twinned with:\n\nTrains stopping at these stations connect Delft with, among others, nearby cities of Rotterdam and The Hague, up to every five minutes, for most of the day.\n\nThere are several bus routes from Delft to similar destinations. Trams frequently travel between Delft and The Hague via special double tracks crossing the city. One of those two lines (19) is still under construction inside Delft and is meant to connect The Hague with a science park, which being developed on the southern (Rotterdam) side of Delft and is a joint project by the Delft and Rotterdam municipalities.\n\n\n\n"}
{"id": "8309", "url": "https://en.wikipedia.org/wiki?curid=8309", "title": "Duesberg hypothesis", "text": "Duesberg hypothesis\n\nThe Duesberg hypothesis is the claim, associated with University of California, Berkeley professor Peter Duesberg, that various noninfectious factors such as but not limited to, recreational and pharmaceutical drug use are the cause of AIDS, and that HIV (human immunodeficiency virus) is merely a harmless passenger virus. The most prominent supporters of this hypothesis are Duesberg himself, biochemist and vitamin proponent David Rasnick, and journalist Celia Farber. The scientific community contends that Duesberg's arguments are the result of cherry-picking predominantly outdated scientific data and selectively ignoring evidence in favor of HIV's role in AIDS. The scientific consensus is that the Duesberg hypothesis is incorrect and that HIV is the cause of AIDS.\n\nDuesberg argues that there is a statistical correlation between trends in recreational drug use and trends in AIDS cases. He argues that the epidemic of AIDS cases in the 1980s corresponds to a supposed epidemic of recreational drug use in the United States and Europe during the same time frame.\n\nThese claims are not supported by epidemiologic data. The average yearly increase in opioid-related deaths from 1990 to 2002 was nearly three times the yearly increase from 1979–90, with the greatest increase in 2000–02, yet AIDS cases and deaths fell dramatically during the mid-to-late-1990s. Duesberg's claim that recreational drug use, rather than HIV, was the cause of AIDS has been specifically examined and found to be false. Cohort studies have found that only HIV-positive drug users develop opportunistic infections; HIV-negative drug users do not develop such infections, indicating that HIV rather than drug use is the cause of AIDS.\n\nDuesberg has also argued that nitrite inhalants were the cause of the epidemic of Kaposi sarcoma (KS) in gay men. However, this argument has been described as an example of the fallacy of a statistical confounding effect; it is now known that a herpesvirus, potentiated by HIV, is responsible for AIDS-associated KS.\n\nMoreover, in addition to recreational drugs, Duesberg argues that anti-HIV drugs such as zidovudine (AZT) can cause AIDS. Duesberg's claim that antiviral medication causes AIDS is regarded as disproven by the scientific community. Placebo-controlled studies have found that AZT as a single agent produces modest and short-lived improvements in survival and delays the development of opportunistic infections; it certainly did not cause AIDS, which develops in both treated and untreated study patients. With the subsequent development of protease inhibitors and highly active antiretroviral therapy, numerous studies have documented the fact that anti-HIV drugs prevent the development of AIDS and substantially prolong survival, further disproving the claim that these drugs \"cause\" AIDS.\n\nSeveral studies have specifically addressed Duesberg's claim that recreational drug abuse or sexual promiscuity were responsible for the manifestations of AIDS. An early study of his claims, published in \"Nature\" in 1993, found Duesberg's drug abuse-AIDS hypothesis to have \"no basis in fact.\"\n\nA large prospective study followed a group of 715 homosexual men in the Vancouver, Canada, area; approximately half were HIV-seropositive or became so during the follow-up period, and the remainder were HIV-seronegative. After more than 8 years of follow-up, despite similar rates of drug use, sexual contact, and other supposed risk factors in both groups, only the HIV-positive group suffered from opportunistic infections. Similarly, CD4 counts dropped in the patients who were HIV-infected, but remained stable in the HIV-negative patients, despite similar rates of risk behavior. The authors concluded that \"the risk-AIDS hypothesis ... is clearly rejected by our data,\" and that \"the evidence supports the hypothesis that HIV-1 has an integral role in the CD4 depletion and progressive immune dysfunction that characterise AIDS.\"\n\nSimilarly, the Multicenter AIDS Cohort Study (MACS) and the Women's Interagency HIV Study (WIHS)—which between them observed more than 8,000 Americans—demonstrated that \"the presence of HIV infection is the only factor that is strongly and consistently associated with the conditions that define AIDS.\" A 2008 study found that recreational drug use (including cannabis, cocaine, poppers, and amphetamines) had no effect on CD4 or CD8 T-cell counts, providing further evidence against a role of recreational drugs as a cause of AIDS.\n\nDuesberg argued in 1989 that a significant number of AIDS victims had died without proof of HIV infection. However, with the use of modern culture techniques and polymerase chain reaction testing, HIV can be demonstrated in virtually all patients with AIDS. Since AIDS is now defined partially by the presence of HIV, Duesberg claims it is impossible by definition to offer evidence that AIDS doesn't require HIV. However, the first definitions of AIDS mentioned no cause and the first AIDS diagnoses were made before HIV was discovered. The addition of HIV positivity to surveillance criteria as an absolutely necessary condition for case reporting occurred only in 1993, after a scientific consensus was established that HIV caused AIDS.\n\nAccording to the Duesberg hypothesis, AIDS is not found in Africa. What Duesberg calls \"the myth of an African AIDS epidemic,\" among people\" exists for several reasons, including:\n\nDuesberg states that African AIDS cases are \"a collection of long-established, indigenous diseases, such as chronic fevers, weight loss, alias \"slim disease,\" diarrhea, and tuberculosis\" that result from malnutrition and poor sanitation. African AIDS cases, though, have increased in the last three decades as HIV's prevalence has increased but as malnutrition percentages and poor sanitation have declined in many African regions. In addition, while HIV and AIDS are more prevalent in urban than in rural settings in Africa, malnutrition and poor sanitation are found more commonly in rural than in urban settings.\n\nAccording to Duesberg, common diseases are easily misdiagnosed as AIDS in Africa because \"the diagnosis of African AIDS is arbitrary\" and does not include HIV testing. A definition of AIDS agreed upon in 1985 by the World Health Organization in Bangui did not require a positive HIV test, but since 1985, many African countries have added positive HIV tests to the Bangui criteria for AIDS or changed their definitions to match those of the U.S. Centers for Disease Control. One of the reasons for using more HIV tests despite their expense is that, rather than overestimating AIDS as Duesberg suggests, the Bangui definition alone excluded nearly half of African AIDS patients.\"\n\nDuesberg notes that diseases associated with AIDS differ between African and Western populations, concluding that the causes of immunodeficiency must be different. Tuberculosis is much more commonly diagnosed among AIDS patients in Africa than in Western countries, while PCP conforms to the opposite pattern. Tuberculosis, though, had higher prevalence in Africa than in the West before the spread of HIV. In Africa and the United States, HIV has spurred a similar percentage increase in tuberculosis cases. PCP may be underestimated in Africa: since machinery \"required for accurate testing is relatively rare in many resource-poor areas, including large parts of Africa, PCP is likely to be underdiagnosed in Africa. Consistent with this hypothesis, studies that report the highest rates of PCP in Africa are those that use the most advanced diagnostic methods\" Duesberg also claims that Kaposi's Sarcoma is \"exclusively diagnosed in male homosexual risk groups using nitrite inhalants and other psychoactive drugs as aphrodisiacs\", but the cancer is fairly common among heterosexuals in some parts of Africa, and is found in heterosexuals in the United States as well.\n\nBecause reported AIDS cases in Africa and other parts of the developing world include a larger proportion of people who do not belong to Duesberg's preferred risk groups of drug addicts and male homosexuals, Duesberg writes on his website that \"There are no risk groups in Africa, like drug addicts and homosexuals.\" However, many studies have addressed the issue of risk groups in Africa and concluded that the risk of AIDS is not equally distributed. In addition, AIDS in Africa largely kills sexually active working-age adults.\nDuesberg argues that retroviruses like HIV must be harmless to survive: they do not kill cells and they do not cause cancer, he maintains. Duesberg writes, \"retroviruses do not kill cells because they depend on viable cells for the replication of their RNA from viral DNA integrated into cellular DNA.\" Duesberg elsewhere states that \"the typical virus reproduces by entering a living cell and commandeering the cell's resources in order to make new virus particles, a process that ends with the disintegration of the dead cell.\"\n\nDuesberg also rejects the involvement of retroviruses and other viruses in cancer. To him, virus-associated cancers are \"freak accidents of nature\" that do not warrant research programs such as the War on Cancer. Duesberg rejects a role in cancer for numerous viruses, including leukemia viruses, Epstein-Barr Virus, Human Papilloma Virus, Hepatitis B, Feline Leukemia Virus, and Human T-lymphotropic virus.\n\nDuesberg claims that the supposedly innocuous nature of all retroviruses is supported by what he considers to be their normal mode of proliferation: infection from mother to child \"in utero\". Duesberg does not suggest that HIV is an endogenous retrovirus, a virus integrated into the germ line and genetically heritable:\n\nThe consensus in the scientific community is that the Duesberg hypothesis has been refuted by a large and growing mass of evidence showing that HIV causes AIDS, that the amount of virus in the blood correlates with disease progression, that a plausible mechanism for HIV's action has been proposed, and that anti-HIV medication decreases mortality and opportunistic infection in people with AIDS.\n\nIn the 9 December 1994 issue of \"Science\" (Vol. 266, No. 5191), Duesberg's methods and claims were evaluated in a group of articles. The authors concluded that\n\nThe vast majority of people with AIDS have never received antiretroviral drugs, including those in developed countries prior to the licensure of AZT (zidovudine) in 1987, and people in developing countries today where very few individuals have access to these medications.\n\nThe NIAID reports that \"in the mid-1980s, clinical trials enrolling patients with AIDS found that AZT given as single-drug therapy conferred a modest survival advantage compared [with] placebo. Among HIV-infected patients who had not yet developed AIDS, placebo-controlled trials found that AZT given as single-drug therapy delayed, for a year or two, the onset of AIDS-related illnesses. Significantly, long-term follow-up of these trials did not show a prolonged benefit of AZT, but also did not indicate that the drug increased disease progression or mortality. The lack of excess AIDS cases and death in the AZT arms of these placebo-controlled trials in effect counters the argument that AZT causes AIDS. Subsequent clinical trials found that patients receiving two-drug combinations had up to 50 percent improvements in time to progression to AIDS and in survival when compared with people receiving single-drug therapy. In more recent years, three-drug combination therapies have produced another 50 to 80 percent improvement in progression to AIDS and in survival when compared with two-drug regimens in clinical trials.\" \"Use of potent anti-HIV combination therapies has contributed to dramatic reductions in the incidence of AIDS and AIDS-related deaths in populations where these drugs are widely available, an effect which clearly would not be seen if antiretroviral drugs caused AIDS.\"\n\nDuesberg claims as support for his idea that many drug-free HIV-positive people have not yet developed AIDS; HIV/AIDS scientists note that many drug-free HIV-positive people have developed AIDS, and that, in the absence of medical treatment or rare genetic factors postulated to delay disease progression, it is very likely that nearly all HIV-positive people will eventually develop AIDS. Scientists also note that HIV-negative drug users do not suffer from immune system collapse.\n\n\n"}
{"id": "8310", "url": "https://en.wikipedia.org/wiki?curid=8310", "title": "DSL (disambiguation)", "text": "DSL (disambiguation)\n\nDSL or digital subscriber line is a family of technologies that provide digital data transmission over the wires of a local telephone network.\n\nDSL may also refer to:\n"}
{"id": "8311", "url": "https://en.wikipedia.org/wiki?curid=8311", "title": "Dinosaur", "text": "Dinosaur\n\nDinosaurs are a diverse group of reptiles of the clade Dinosauria that first appeared during the Triassic period. Although the exact origin and timing of the evolution of dinosaurs is the subject of active research, the current scientific consensus places their origin between 231 and 243 million years ago. They became the dominant terrestrial vertebrates after the Triassic–Jurassic extinction event 201 million years ago. Their dominance continued through the Jurassic and Cretaceous periods and ended when the Cretaceous–Paleogene extinction event led to the extinction of most dinosaur groups 66 million years ago.\n\nThe fossil record indicates that birds are modern feathered dinosaurs, having evolved from theropod ancestors during the Jurassic Period. As such, birds were the only dinosaur lineage to survive the mass extinction event. Throughout the remainder of this article, the term \"dinosaur\" is sometimes used generically to refer to the combined group of avian dinosaurs (birds) and non-avian dinosaurs; at other times it is used to refer to the non-avian dinosaurs specifically, while the avian dinosaurs are sometimes simply referred to as \"birds\". This article deals primarily with non-avian dinosaurs.\n\nDinosaurs are a varied group of animals from taxonomic, morphological and ecological standpoints. Birds, at over 10,000 living species, are the most diverse group of vertebrates besides perciform fish. Using fossil evidence, paleontologists have identified over 500 distinct genera and more than 1,000 different species of non-avian dinosaurs. Dinosaurs are represented on every continent by both extant species (birds) and fossil remains. Through the first half of the 20th century, before birds were recognized to be dinosaurs, most of the scientific community believed dinosaurs to have been sluggish and cold-blooded. Most research conducted since the 1970s, however, has indicated that all dinosaurs were active animals with elevated metabolisms and numerous adaptations for social interaction. Some are herbivorous, others carnivorous. Evidence suggests that egg laying and nest building are additional traits shared by all dinosaurs.\n\nWhile dinosaurs were ancestrally bipedal, many extinct groups included quadrupedal species, and some were able to shift between these stances. Elaborate display structures such as horns or crests are common to all dinosaur groups, and some extinct groups developed skeletal modifications such as bony armor and spines. While the dinosaurs' modern-day surviving avian lineage (birds) are generally small due to the constraints of flight, many prehistoric dinosaurs (non-avian and avian) were large-bodied—the largest sauropod dinosaurs are estimated to have reached lengths of and heights of and were the largest land animals of all time. Still, the idea that non-avian dinosaurs were uniformly gigantic is a misconception based in part on preservation bias, as large, sturdy bones are more likely to last until they are fossilized. Many dinosaurs were quite small: \"Xixianykus\", for example, was only about long.\n\nSince the first dinosaur fossils were recognized in the early 19th century, mounted fossil dinosaur skeletons have been major attractions at museums around the world, and dinosaurs have become an enduring part of world culture. The large sizes of some dinosaur groups, as well as their seemingly monstrous and fantastic nature, have ensured dinosaurs' regular appearance in best-selling books and films, such as \"Jurassic Park\". Persistent public enthusiasm for the animals has resulted in significant funding for dinosaur science, and new discoveries are regularly covered by the media.\n\nThe taxon Dinosauria was formally named in 1842 by paleontologist Sir Richard Owen, who used it to refer to the \"distinct tribe or sub-order of Saurian Reptiles\" that were then being recognized in England and around the world. The term is derived from the Greek words δεινός (\"deinos\", meaning \"terrible\", \"potent\", or \"fearfully great\") and σαῦρος (\"sauros\", meaning \"lizard\" or \"reptile\"). Though the taxonomic name has often been interpreted as a reference to dinosaurs' teeth, claws, and other fearsome characteristics, Owen intended it merely to evoke their size and majesty.\n\nOther prehistoric animals, including mosasaurs, ichthyosaurs, pterosaurs, plesiosaurs, and \"Dimetrodon\", while often popularly conceived of as dinosaurs, are not taxonomically classified as dinosaurs.\n\nUnder phylogenetic nomenclature, dinosaurs are usually defined as the group consisting of \"Triceratops\", Neornithes, their most recent common ancestor (MRCA), and all descendants. It has also been suggested that Dinosauria be defined with respect to the MRCA of \"Megalosaurus\" and \"Iguanodon\", because these were two of the three genera cited by Richard Owen when he recognized the Dinosauria. Both definitions result in the same set of animals being defined as dinosaurs: \"Dinosauria = Ornithischia + Saurischia\", encompassing ankylosaurians (armored herbivorous quadrupeds), stegosaurians (plated herbivorous quadrupeds), ceratopsians (herbivorous quadrupeds with horns and frills), ornithopods (bipedal or quadrupedal herbivores including \"duck-bills\"), theropods (mostly bipedal carnivores and birds), and sauropodomorphs (mostly large herbivorous quadrupeds with long necks and tails).\n\nBirds are now recognized as being the sole surviving lineage of theropod dinosaurs. In traditional taxonomy, birds were considered a separate class that had evolved from dinosaurs, a distinct superorder. However, a majority of contemporary paleontologists concerned with dinosaurs reject the traditional style of classification in favor of phylogenetic taxonomy; this approach requires that, for a group to be natural, all descendants of members of the group must be included in the group as well. Birds are thus considered to be dinosaurs and dinosaurs are, therefore, not extinct. Birds are classified as belonging to the subgroup Maniraptora, which are coelurosaurs, which are theropods, which are saurischians, which are dinosaurs.\n\nResearch by Matthew Baron, David B. Norman, and Paul M. Barrett in 2017 suggested a radical revision of dinosaurian systematics. Phylogenetic analysis by Baron \"et al.\" recovered the Ornithischia as being closer to the Theropoda than the Sauropodomorpha, as opposed to the traditional union of theropods with sauropodomorphs. They resurrected the clade Ornithoscelida to refer to the group containing Ornithischia and Theropoda. Dinosauria itself was re-defined to as the last common ancestor of \"Triceratops horridus\", \"Passer domesticus\", \"Diplodocus carnegii\", and all of its descendants, to ensure that sauropods and kin remain included as dinosaurs.\n\nUsing one of the above definitions, dinosaurs can be generally described as archosaurs with hind limbs held erect beneath the body. Many prehistoric animal groups are popularly conceived of as dinosaurs, such as ichthyosaurs, mosasaurs, plesiosaurs, pterosaurs, and pelycosaurs (especially \"Dimetrodon\"), but are not classified scientifically as dinosaurs, and none had the erect hind limb posture characteristic of true dinosaurs. Dinosaurs were the dominant terrestrial vertebrates of the Mesozoic, especially the Jurassic and Cretaceous periods. Other groups of animals were restricted in size and niches; mammals, for example, rarely exceeded the size of a domestic cat, and were generally rodent-sized carnivores of small prey.\n\nDinosaurs have always been an extremely varied group of animals; according to a 2006 study, over 500 non-avian dinosaur genera have been identified with certainty so far, and the total number of genera preserved in the fossil record has been estimated at around 1850, nearly 75% of which remain to be discovered. An earlier study predicted that about 3400 dinosaur genera existed, including many that would not have been preserved in the fossil record. By September 17, 2008, 1047 different species of dinosaurs had been named.\n\nIn 2016, the estimated number of dinosaur species that existed in the Mesozoic era was estimated to be 1,543–2,468. Some are herbivorous, others carnivorous, including seed-eaters, fish-eaters, insectivores, and omnivores. While dinosaurs were ancestrally bipedal (as are all modern birds), some prehistoric species were quadrupeds, and others, such as \"Ammosaurus\" and \"Iguanodon\", could walk just as easily on two or four legs. Cranial modifications like horns and crests are common dinosaurian traits, and some extinct species had bony armor. Although known for large size, many Mesozoic dinosaurs were human-sized or smaller, and modern birds are generally small in size. Dinosaurs today inhabit every continent, and fossils show that they had achieved global distribution by at least the early Jurassic period. Modern birds inhabit most available habitats, from terrestrial to marine, and there is evidence that some non-avian dinosaurs (such as \"Microraptor\") could fly or at least glide, and others, such as spinosaurids, had semi-aquatic habits.\n\nWhile recent discoveries have made it more difficult to present a universally agreed-upon list of dinosaurs' distinguishing features, nearly all dinosaurs discovered so far share certain modifications to the ancestral archosaurian skeleton, or are clear descendants of older dinosaurs showing these modifications. Although some later groups of dinosaurs featured further modified versions of these traits, they are considered typical for Dinosauria; the earliest dinosaurs had them and passed them on to their descendants. Such modifications, originating in the most recent common ancestor of a certain taxonomic group, are called the synapomorphies of such a group.\n\nA detailed assessment of archosaur interrelations by Sterling Nesbitt confirmed or found the following twelve unambiguous synapomorphies, some previously known:\n\nNesbitt found a number of further potential synapomorphies, and discounted a number of synapomorphies previously suggested. Some of these are also present in silesaurids, which Nesbitt recovered as a sister group to Dinosauria, including a large anterior trochanter, metatarsals II and IV of subequal length, reduced contact between ischium and pubis, the presence of a cnemial crest on the tibia and of an ascending process on the astragalus, and many others.\n\nA variety of other skeletal features are shared by dinosaurs. However, because they are either common to other groups of archosaurs or were not present in all early dinosaurs, these features are not considered to be synapomorphies. For example, as diapsids, dinosaurs ancestrally had two pairs of temporal fenestrae (openings in the skull behind the eyes), and as members of the diapsid group Archosauria, had additional openings in the snout and lower jaw. Additionally, several characteristics once thought to be synapomorphies are now known to have appeared before dinosaurs, or were absent in the earliest dinosaurs and independently evolved by different dinosaur groups. These include an elongated scapula, or shoulder blade; a sacrum composed of three or more fused vertebrae (three are found in some other archosaurs, but only two are found in \"Herrerasaurus\"); and a perforate acetabulum, or hip socket, with a hole at the center of its inside surface (closed in \"Saturnalia\", for example). Another difficulty of determining distinctly dinosaurian features is that early dinosaurs and other archosaurs from the late Triassic are often poorly known and were similar in many ways; these animals have sometimes been misidentified in the literature.\n\nDinosaurs stand with their hind limbs erect in a manner similar to most modern mammals, but distinct from most other reptiles, whose limbs sprawl out to either side. This posture is due to the development of a laterally facing recess in the pelvis (usually an open socket) and a corresponding inwardly facing distinct head on the femur. Their erect posture enabled early dinosaurs to breathe easily while moving, which likely permitted stamina and activity levels that surpassed those of \"sprawling\" reptiles. Erect limbs probably also helped support the evolution of large size by reducing bending stresses on limbs. Some non-dinosaurian archosaurs, including rauisuchians, also had erect limbs but achieved this by a \"pillar erect\" configuration of the hip joint, where instead of having a projection from the femur insert on a socket on the hip, the upper pelvic bone was rotated to form an overhanging shelf.\n\nDinosaurs diverged from their archosaur ancestors during the middle to late Triassic period, roughly 20 million years after the Permian–Triassic extinction event wiped out an estimated 95% of all life on Earth. Radiometric dating of the rock formation that contained fossils from the early dinosaur genus \"Eoraptor\" at 231.4 million years old establishes its presence in the fossil record at this time. Paleontologists think that \"Eoraptor\" resembles the common ancestor of all dinosaurs; if this is true, its traits suggest that the first dinosaurs were small, bipedal predators. The discovery of primitive, dinosaur-like ornithodirans such as \"Marasuchus\" and \"Lagerpeton\" in Argentinian Middle Triassic strata supports this view; analysis of recovered fossils suggests that these animals were indeed small, bipedal predators. Dinosaurs may have appeared as early as 243 million years ago, as evidenced by remains of the genus \"Nyasasaurus\" from that period, though known fossils of these animals are too fragmentary to tell if they are dinosaurs or very close dinosaurian relatives.\n\nWhen dinosaurs appeared, they were not the dominant terrestrial animals. The terrestrial habitats were occupied by various types of archosauromorphs and therapsids, like cynodonts and rhynchosaurs. Their main competitors were the pseudosuchia, such as aetosaurs, ornithosuchids and rauisuchians, which were more successful than the dinosaurs. Most of these other animals became extinct in the Triassic, in one of two events. First, at about 215 million years ago, a variety of basal archosauromorphs, including the protorosaurs, became extinct. This was followed by the Triassic–Jurassic extinction event (about 200 million years ago), that saw the end of most of the other groups of early archosaurs, like aetosaurs, ornithosuchids, phytosaurs, and rauisuchians. Rhynchosaurs and dicynodonts survived (at least in some areas) at least as late as early-mid Norian and early Rhaetian, respectively, and the exact date of their extinction is uncertain. These losses left behind a land fauna of crocodylomorphs, dinosaurs, mammals, pterosaurians, and turtles. The first few lines of early dinosaurs diversified through the Carnian and Norian stages of the Triassic, possibly by occupying the niches of the groups that became extinct.\n\nDinosaur evolution after the Triassic follows changes in vegetation and the location of continents. In the late Triassic and early Jurassic, the continents were connected as the single landmass Pangaea, and there was a worldwide dinosaur fauna mostly composed of coelophysoid carnivores and early sauropodomorph herbivores. Gymnosperm plants (particularly conifers), a potential food source, radiated in the late Triassic. Early sauropodomorphs did not have sophisticated mechanisms for processing food in the mouth, and so must have employed other means of breaking down food farther along the digestive tract. The general homogeneity of dinosaurian faunas continued into the middle and late Jurassic, where most localities had predators consisting of ceratosaurians, spinosauroids, and carnosaurians, and herbivores consisting of stegosaurian ornithischians and large sauropods. Examples of this include the Morrison Formation of North America and Tendaguru Beds of Tanzania. Dinosaurs in China show some differences, with specialized sinraptorid theropods and unusual, long-necked sauropods like \"Mamenchisaurus\". Ankylosaurians and ornithopods were also becoming more common, but prosauropods had become extinct. Conifers and pteridophytes were the most common plants. Sauropods, like the earlier prosauropods, were not oral processors, but ornithischians were evolving various means of dealing with food in the mouth, including potential cheek-like organs to keep food in the mouth, and jaw motions to grind food. Another notable evolutionary event of the Jurassic was the appearance of true birds, descended from maniraptoran coelurosaurians.\n\nBy the early Cretaceous and the ongoing breakup of Pangaea, dinosaurs were becoming strongly differentiated by landmass. The earliest part of this time saw the spread of ankylosaurians, iguanodontians, and brachiosaurids through Europe, North America, and northern Africa. These were later supplemented or replaced in Africa by large spinosaurid and carcharodontosaurid theropods, and rebbachisaurid and titanosaurian sauropods, also found in South America. In Asia, maniraptoran coelurosaurians like dromaeosaurids, troodontids, and oviraptorosaurians became the common theropods, and ankylosaurids and early ceratopsians like \"Psittacosaurus\" became important herbivores. Meanwhile, Australia was home to a fauna of basal ankylosaurians, hypsilophodonts, and iguanodontians. The stegosaurians appear to have gone extinct at some point in the late early Cretaceous or early late Cretaceous. A major change in the early Cretaceous, which would be amplified in the late Cretaceous, was the evolution of flowering plants. At the same time, several groups of dinosaurian herbivores evolved more sophisticated ways to orally process food. Ceratopsians developed a method of slicing with teeth stacked on each other in batteries, and iguanodontians refined a method of grinding with tooth batteries, taken to its extreme in hadrosaurids. Some sauropods also evolved tooth batteries, best exemplified by the rebbachisaurid \"Nigersaurus\".\n\nThere were three general dinosaur faunas in the late Cretaceous. In the northern continents of North America and Asia, the major theropods were tyrannosaurids and various types of smaller maniraptoran theropods, with a predominantly ornithischian herbivore assemblage of hadrosaurids, ceratopsians, ankylosaurids, and pachycephalosaurians. In the southern continents that had made up the now-splitting Gondwana, abelisaurids were the common theropods, and titanosaurian sauropods the common herbivores. Finally, in Europe, dromaeosaurids, rhabdodontid iguanodontians, nodosaurid ankylosaurians, and titanosaurian sauropods were prevalent. Flowering plants were greatly radiating, with the first grasses appearing by the end of the Cretaceous. Grinding hadrosaurids and shearing ceratopsians became extremely diverse across North America and Asia. Theropods were also radiating as herbivores or omnivores, with therizinosaurians and ornithomimosaurians becoming common.\n\nThe Cretaceous–Paleogene extinction event, which occurred approximately 66 million years ago at the end of the Cretaceous period, caused the extinction of all dinosaur groups except for the neornithine birds. Some other diapsid groups, such as crocodilians, sebecosuchians, turtles, lizards, snakes, sphenodontians, and choristoderans, also survived the event.\n\nThe surviving lineages of neornithine birds, including the ancestors of modern ratites, ducks and chickens, and a variety of waterbirds, diversified rapidly at the beginning of the Paleogene period, entering ecological niches left vacant by the extinction of Mesozoic dinosaur groups such as the arboreal enantiornithines, aquatic hesperornithines, and even the larger terrestrial theropods (in the form of \"Gastornis\", eogruiids, bathornithids, ratites, geranoidids, mihirungs, and \"terror birds\"). It is often cited that mammals out-competed the neornithines for dominance of most terrestrial niches but many of these groups co-existed with rich mammalian faunas for most of the Cenozoic. Terror birds and bathornithids occupied carnivorous guilds alongside predatory mammals, and ratites are still being fairly successful as mid-sized herbivores; eogruiids similarly lasted from the Eocene to Pliocene, only becoming extinct very recently after over 20 million years of co-existence with many mammal groups.\n\nDinosaurs belong to a group known as archosaurs, which also includes modern crocodilians. Within the archosaur group, dinosaurs are differentiated most noticeably by their gait. Dinosaur legs extend directly beneath the body, whereas the legs of lizards and crocodilians sprawl out to either side.\n\nCollectively, dinosaurs as a clade are divided into two primary branches, Saurischia and Ornithischia. Saurischia includes those taxa sharing a more recent common ancestor with birds than with Ornithischia, while Ornithischia includes all taxa sharing a more recent common ancestor with \"Triceratops\" than with Saurischia. Anatomically, these two groups can be distinguished most noticeably by their pelvic structure. Early saurischians—\"lizard-hipped\", from the Greek \"sauros\" (σαῦρος) meaning \"lizard\" and \"ischion\" (ἰσχίον) meaning \"hip joint\"—retained the hip structure of their ancestors, with a pubis bone directed cranially, or forward. This basic form was modified by rotating the pubis backward to varying degrees in several groups (\"Herrerasaurus\", therizinosauroids, dromaeosaurids, and birds). Saurischia includes the theropods (exclusively bipedal and with a wide variety of diets) and sauropodomorphs (long-necked herbivores which include advanced, quadrupedal groups).\n\nBy contrast, ornithischians—\"bird-hipped\", from the Greek \"ornitheios\" (ὀρνίθειος) meaning \"of a bird\" and \"ischion\" (ἰσχίον) meaning \"hip joint\"—had a pelvis that superficially resembled a bird's pelvis: the pubic bone was oriented caudally (rear-pointing). Unlike birds, the ornithischian pubis also usually had an additional forward-pointing process. Ornithischia includes a variety of species which were primarily herbivores. (NB: the terms \"lizard hip\" and \"bird hip\" are misnomers – birds evolved from dinosaurs with \"lizard hips\".)\n\nThe following is a simplified classification of dinosaur groups based on their evolutionary relationships, and organized based on the list of Mesozoic dinosaur species provided by Holtz (2007). A more detailed version can be found at Dinosaur classification.\nThe dagger (†) is used to signify groups with no living members.\n\n\nKnowledge about dinosaurs is derived from a variety of fossil and non-fossil records, including fossilized bones, feces, trackways, gastroliths, feathers, impressions of skin, internal organs and soft tissues. Many fields of study contribute to our understanding of dinosaurs, including physics (especially biomechanics), chemistry, biology, and the earth sciences (of which paleontology is a sub-discipline). Two topics of particular interest and study have been dinosaur size and behavior.\n\nCurrent evidence suggests that dinosaur average size varied through the Triassic, early Jurassic, late Jurassic and Cretaceous periods. Predatory theropod dinosaurs, which occupied most terrestrial carnivore niches during the Mesozoic, most often fall into the category when sorted by estimated weight into categories based on order of magnitude, whereas recent predatory carnivoran mammals peak in the category. The mode of Mesozoic dinosaur body masses is between one and ten metric tonnes. This contrasts sharply with the size of Cenozoic mammals, estimated by the National Museum of Natural History as about .\n\nThe sauropods were the largest and heaviest dinosaurs. For much of the dinosaur era, the smallest sauropods were larger than anything else in their habitat, and the largest were an order of magnitude more massive than anything else that has since walked the Earth. Giant prehistoric mammals such as \"Paraceratherium\" (the largest land mammal ever) were dwarfed by the giant sauropods, and only modern whales approach or surpass them in size. There are several proposed advantages for the large size of sauropods, including protection from predation, reduction of energy use, and longevity, but it may be that the most important advantage was dietary. Large animals are more efficient at digestion than small animals, because food spends more time in their digestive systems. This also permits them to subsist on food with lower nutritive value than smaller animals. Sauropod remains are mostly found in rock formations interpreted as dry or seasonally dry, and the ability to eat large quantities of low-nutrient browse would have been advantageous in such environments.\n\nScientists will probably never be certain of the largest and smallest dinosaurs to have ever existed. This is because only a tiny percentage of animals ever fossilize, and most of these remain buried in the earth. Few of the specimens that are recovered are complete skeletons, and impressions of skin and other soft tissues are rare. Rebuilding a complete skeleton by comparing the size and morphology of bones to those of similar, better-known species is an inexact art, and reconstructing the muscles and other organs of the living animal is, at best, a process of educated guesswork.\nThe tallest and heaviest dinosaur known from good skeletons is \"Giraffatitan brancai\" (previously classified as a species of \"Brachiosaurus\"). Its remains were discovered in Tanzania between 1907 and 1912. Bones from several similar-sized individuals were incorporated into the skeleton now mounted and on display at the Museum für Naturkunde Berlin; this mount is tall and long, and would have belonged to an animal that weighed between and  kilograms ( and  lb). The longest complete dinosaur is the long \"Diplodocus\", which was discovered in Wyoming in the United States and displayed in Pittsburgh's Carnegie Natural History Museum in 1907.\n\nThere were larger dinosaurs, but knowledge of them is based entirely on a small number of fragmentary fossils. Most of the largest herbivorous specimens on record were discovered in the 1970s or later, and include the massive \"Argentinosaurus\", which may have weighed to  kilograms (90 to 110 short tons); some of the longest were the long \"Diplodocus hallorum\" (formerly \"Seismosaurus\") and the long \"Supersaurus\"; and the tallest, the tall \"Sauroposeidon\", which could have reached a sixth-floor window. The heaviest and longest dinosaur may have been \"Amphicoelias fragillimus\", known only from a now lost partial vertebral neural arch described in 1878. Extrapolating from the illustration of this bone, the animal may have been long and weighed kg ( lb). However, as no further evidence of sauropods of this size has been found, and the discoverer, Edward Cope, had made typographic errors before, it is likely to have been an extreme overestimation. The largest known carnivorous dinosaur was \"Spinosaurus\", reaching a length of , and weighing 7–20.9 tonnes (7.7–23 short tons). Other large carnivorous theropods included \"Giganotosaurus\", \"Carcharodontosaurus\" and \"Tyrannosaurus\". \"Therizinosaurus\" and \"Deinocheirus\" were among the tallest of the theropods.\n\nThe smallest dinosaur known is the bee hummingbird, with a length of only and mass of around . The smallest known non-avialan dinosaurs were about the size of pigeons and were those theropods most closely related to birds. For example, \"Anchiornis huxleyi\" is currently the smallest non-avialan dinosaur described from an adult specimen, with an estimated weight of 110 grams and a total skeletal length of . The smallest herbivorous non-avialan dinosaurs included \"Microceratus\" and \"Wannanosaurus\", at about long each.\n\nMany modern birds are highly social, often found living in flocks. There is general agreement that some behaviors that are common in birds, as well as in crocodiles (birds' closest living relatives), were also common among extinct dinosaur groups. Interpretations of behavior in fossil species are generally based on the pose of skeletons and their habitat, computer simulations of their biomechanics, and comparisons with modern animals in similar ecological niches.\n\nThe first potential evidence for herding or flocking as a widespread behavior common to many dinosaur groups in addition to birds was the 1878 discovery of 31 \"Iguanodon bernissartensis\", ornithischians that were then thought to have perished together in Bernissart, Belgium, after they fell into a deep, flooded sinkhole and drowned. Other mass-death sites have been discovered subsequently. Those, along with multiple trackways, suggest that gregarious behavior was common in many early dinosaur species. Trackways of hundreds or even thousands of herbivores indicate that duck-bills (hadrosaurids) may have moved in great herds, like the American bison or the African Springbok. Sauropod tracks document that these animals traveled in groups composed of several different species, at least in Oxfordshire, England, although there is no evidence for specific herd structures. Congregating into herds may have evolved for defense, for migratory purposes, or to provide protection for young. There is evidence that many types of slow-growing dinosaurs, including various theropods, sauropods, ankylosaurians, ornithopods, and ceratopsians, formed aggregations of immature individuals. One example is a site in Inner Mongolia that has yielded the remains of over 20 \"Sinornithomimus\", from one to seven years old. This assemblage is interpreted as a social group that was trapped in mud. The interpretation of dinosaurs as gregarious has also extended to depicting carnivorous theropods as pack hunters working together to bring down large prey. However, this lifestyle is uncommon among modern birds, crocodiles, and other reptiles, and the taphonomic evidence suggesting mammal-like pack hunting in such theropods as \"Deinonychus\" and \"Allosaurus\" can also be interpreted as the results of fatal disputes between feeding animals, as is seen in many modern diapsid predators.\nThe crests and frills of some dinosaurs, like the marginocephalians, theropods and lambeosaurines, may have been too fragile to be used for active defense, and so they were likely used for sexual or aggressive displays, though little is known about dinosaur mating and territorialism. Head wounds from bites suggest that theropods, at least, engaged in active aggressive confrontations.\n\nFrom a behavioral standpoint, one of the most valuable dinosaur fossils was discovered in the Gobi Desert in 1971. It included a \"Velociraptor\" attacking a \"Protoceratops\", providing evidence that dinosaurs did indeed attack each other. Additional evidence for attacking live prey is the partially healed tail of an \"Edmontosaurus\", a hadrosaurid dinosaur; the tail is damaged in such a way that shows the animal was bitten by a tyrannosaur but survived. Cannibalism amongst some species of dinosaurs was confirmed by tooth marks found in Madagascar in 2003, involving the theropod \"Majungasaurus\".\n\nComparisons between the scleral rings of dinosaurs and modern birds and reptiles have been used to infer daily activity patterns of dinosaurs. Although it has been suggested that most dinosaurs were active during the day, these comparisons have shown that small predatory dinosaurs such as dromaeosaurids, \"Juravenator\", and \"Megapnosaurus\" were likely nocturnal. Large and medium-sized herbivorous and omnivorous dinosaurs such as ceratopsians, sauropodomorphs, hadrosaurids, ornithomimosaurs may have been cathemeral, active during short intervals throughout the day, although the small ornithischian \"Agilisaurus\" was inferred to be diurnal.\n\nBased on current fossil evidence from dinosaurs such as \"Oryctodromeus\", some ornithischian species seem to have led a partially fossorial (burrowing) lifestyle. Many modern birds are arboreal (tree climbing), and this was also true of many Mesozoic birds, especially the enantiornithines. While some early bird-like species may have already been arboreal as well (including dromaeosaurids such as \"Microraptor\") most non-avialan dinosaurs seem to have relied on land-based locomotion. A good understanding of how dinosaurs moved on the ground is key to models of dinosaur behavior; the science of biomechanics, pioneered by Robert McNeill Alexander, has provided significant insight in this area. For example, studies of the forces exerted by muscles and gravity on dinosaurs' skeletal structure have investigated how fast dinosaurs could run, whether diplodocids could create sonic booms via whip-like tail snapping, and whether sauropods could float.\n\nModern birds are known to communicate using visual and auditory signals, and the wide diversity of visual display structures among fossil dinosaur groups, such as horns, frills, crests, sails and feathers, suggests that visual communication has always been important in dinosaur biology. Reconstruction of the plumage color of \"Anchiornis huxleyi\", suggest the importance of color in visual communication in non-avian dinosaurs. The evolution of dinosaur vocalization is less certain. Paleontologist Phil Senter suggests that non-avian dinosaurs relied mostly on visual displays and possibly non-vocal acoustic sounds like hissing, jaw grinding or clapping, splashing and wing beating (possible in winged maniraptoran dinosaurs). He states they were unlikely to have been capable of vocalizing since their closest relatives, crocodilians and birds, use different means to vocalize, the former via the larynx and the latter through the unique syrinx, suggesting they evolved independently and their common ancestor was mute.\n\nThe earliest remains of a syrinx, which has enough mineral content for fossilization, was found in a specimen of the duck-like \"Vegavis iaai\" dated 69-66 million year ago, and this organ is unlikely to have existed in non-avian dinosaurs. However, in contrast to Senter, the researchers have suggested that dinosaurs could vocalize and that the syrinx-based vocal system of birds evolved from a larynx-based one, rather than the two systems evolving independently. A 2016 study suggests that dinosaurs produced closed mouth vocalizations like cooing, which occur in both crocodilians and birds as well as other reptiles. Such vocalizations evolved independently in extant archosaurs numerous times, following increases in body size. The crests of the Lambeosaurini and nasal chambers of ankylosaurids have been suggested to function in vocal resonance, though Senter states that the presence of resonance chambers in some dinosaurs is not necessarily evidence of vocalization as modern snakes have such chambers which intensify their hisses.\n\nAll dinosaurs lay amniotic eggs with hard shells made mostly of calcium carbonate. Eggs are usually laid in a nest. Most species create somewhat elaborate nests, which can be cups, domes, plates, beds scrapes, mounds, or burrows. Some species of modern bird have no nests; the cliff-nesting common guillemot lays its eggs on bare rock, and male emperor penguins keep eggs between their body and feet. Primitive birds and many non-avialan dinosaurs often lay eggs in communal nests, with males primarily incubating the eggs. While modern birds have only one functional oviduct and lay one egg at a time, more primitive birds and dinosaurs had two oviducts, like crocodiles. Some non-avialan dinosaurs, such as \"Troodon\", exhibited iterative laying, where the adult might lay a pair of eggs every one or two days, and then ensured simultaneous hatching by delaying brooding until all eggs were laid.\n\nWhen laying eggs, females grow a special type of bone between the hard outer bone and the marrow of their limbs. This medullary bone, which is rich in calcium, is used to make eggshells. A discovery of features in a \"Tyrannosaurus rex\" skeleton provided evidence of medullary bone in extinct dinosaurs and, for the first time, allowed paleontologists to establish the sex of a fossil dinosaur specimen. Further research has found medullary bone in the carnosaur \"Allosaurus\" and the ornithopod \"Tenontosaurus\". Because the line of dinosaurs that includes \"Allosaurus\" and \"Tyrannosaurus\" diverged from the line that led to \"Tenontosaurus\" very early in the evolution of dinosaurs, this suggests that the production of medullary tissue is a general characteristic of all dinosaurs.\nAnother widespread trait among modern birds is parental care for young after hatching. Jack Horner's 1978 discovery of a \"Maiasaura\" (\"good mother lizard\") nesting ground in Montana demonstrated that parental care continued long after birth among ornithopods, suggesting this behavior might also have been common to all dinosaurs. There is evidence that other non-theropod dinosaurs, like Patagonian titanosaurian sauropods, also nested in large groups. A specimen of the Mongolian oviraptorid \"Citipati osmolskae\" was discovered in a chicken-like brooding position in 1993, which may indicate that they had begun using an insulating layer of feathers to keep the eggs warm. Parental care being a trait common to all dinosaurs is supported by other finds. For example, a dinosaur embryo (pertaining to the prosauropod \"Massospondylus\") was found without teeth, indicating that some parental care was required to feed the young dinosaurs. Trackways have also confirmed parental behavior among ornithopods from the Isle of Skye in northwestern Scotland. Nests and eggs have been found for most major groups of dinosaurs, and it appears likely that all dinosaurs cared for their young to some extent either before or shortly after hatching.\n\nBecause both modern crocodilians and birds have four-chambered hearts (albeit modified in crocodilians), it is likely that this is a trait shared by all archosaurs, including all dinosaurs. While all modern birds have high metabolisms and are \"warm blooded\" (endothermic), a vigorous debate has been ongoing since the 1960s regarding how far back in the dinosaur lineage this trait extends. Scientists disagree as to whether non-avian dinosaurs were endothermic, ectothermic, or some combination of both.\n\nAfter non-avian dinosaurs were discovered, paleontologists first posited that they were ectothermic. This supposed \"cold-bloodedness\" was used to imply that the ancient dinosaurs were relatively slow, sluggish organisms, even though many modern reptiles are fast and light-footed despite relying on external sources of heat to regulate their body temperature. The idea of dinosaurs as ectothermic and sluggish remained a prevalent view until Robert T. \"Bob\" Bakker, an early proponent of dinosaur endothermy, published an influential paper on the topic in 1968.\n\nModern evidence indicates that even non-avian dinosaurs and birds thrived in cooler temperate climates, and that at least some early species must have regulated their body temperature by internal biological means (aided by the animals' bulk in large species and feathers or other body coverings in smaller species). Evidence of endothermy in Mesozoic dinosaurs includes the discovery of polar dinosaurs in Australia and Antarctica as well as analysis of blood-vessel structures within fossil bones that are typical of endotherms. Scientific debate continues regarding the specific ways in which dinosaur temperature regulation evolved.\n\nIn saurischian dinosaurs, higher metabolisms were supported by the evolution of the avian respiratory system, characterized by an extensive system of air sacs that extended the lungs and invaded many of the bones in the skeleton, making them hollow. Early avian-style respiratory systems with air sacs may have been capable of sustaining higher activity levels than mammals of similar size and build could sustain. In addition to providing a very efficient supply of oxygen, the rapid airflow would have been an effective cooling mechanism, which is essential for animals that are active but too large to get rid of all the excess heat through their skin.\n\nLike other reptiles, dinosaurs are primarily uricotelic, that is, their kidneys extract nitrogenous wastes from their bloodstream and excrete it as uric acid instead of urea or ammonia via the ureters into the intestine. In most living species, uric acid is excreted along with feces as a semisolid waste. However, at least some modern birds (such as hummingbirds) can be facultatively ammonotelic, excreting most of the nitrogenous wastes as ammonia. They also excrete creatine, rather than creatinine like mammals. This material, as well as the output of the intestines, emerges from the cloaca. In addition, many species regurgitate pellets, and fossil pellets that may have come from dinosaurs are known from as long ago as the Cretaceous period.\n\nThe possibility that dinosaurs were the ancestors of birds was first suggested in 1868 by Thomas Henry Huxley. After the work of Gerhard Heilmann in the early 20th century, the theory of birds as dinosaur descendants was abandoned in favor of the idea of their being descendants of generalized thecodonts, with the key piece of evidence being the supposed lack of clavicles in dinosaurs. However, as later discoveries showed, clavicles (or a single fused wishbone, which derived from separate clavicles) were not actually absent; they had been found as early as 1924 in \"Oviraptor\", but misidentified as an interclavicle. In the 1970s, John Ostrom revived the dinosaur–bird theory, which gained momentum in the coming decades with the advent of cladistic analysis, and a great increase in the discovery of small theropods and early birds. Of particular note have been the fossils of the Yixian Formation, where a variety of theropods and early birds have been found, often with feathers of some type. Birds share over a hundred distinct anatomical features with theropod dinosaurs, which are now generally accepted to have been their closest ancient relatives.\nThey are most closely allied with maniraptoran coelurosaurs. A minority of scientists, most notably Alan Feduccia and Larry Martin, have proposed other evolutionary paths, including revised versions of Heilmann's basal archosaur proposal, or that maniraptoran theropods are the ancestors of birds but themselves are not dinosaurs, only convergent with dinosaurs.\n\nFeathers are one of the most recognizable characteristics of modern birds, and a trait that was shared by all other dinosaur groups. Based on the current distribution of fossil evidence, it appears that feathers were an ancestral dinosaurian trait, though one that may have been selectively lost in some species. Direct fossil evidence of feathers or feather-like structures has been discovered in a diverse array of species in many non-avian dinosaur groups, both among saurischians and ornithischians. Simple, branched, feather-like structures are known from heterodontosaurids, primitive neornithischians and theropods, and primitive ceratopsians. Evidence for true, vaned feathers similar to the flight feathers of modern birds has been found only in the theropod subgroup Maniraptora, which includes oviraptorosaurs, troodontids, dromaeosaurids, and birds. Feather-like structures known as pycnofibres have also been found in pterosaurs, suggesting the possibility that feather-like filaments may have been common in the bird lineage and evolved before the appearance of dinosaurs themselves. Research into the genetics of American alligators has also revealed that crocodylian scutes do possess feather-keratins during embryonic development, but these keratins are not expressed by the animals before hatching.\n\n\"Archaeopteryx\" was the first fossil found that revealed a potential connection between dinosaurs and birds. It is considered a transitional fossil, in that it displays features of both groups. Brought to light just two years after Darwin's seminal \"The Origin of Species\", its discovery spurred the nascent debate between proponents of evolutionary biology and creationism. This early bird is so dinosaur-like that, without a clear impression of feathers in the surrounding rock, at least one specimen was mistaken for \"Compsognathus\". Since the 1990s, a number of additional feathered dinosaurs have been found, providing even stronger evidence of the close relationship between dinosaurs and modern birds. Most of these specimens were unearthed in the lagerstätte of the Yixian Formation, Liaoning, northeastern China, which was part of an island continent during the Cretaceous. Though feathers have been found in only a few locations, it is possible that non-avian dinosaurs elsewhere in the world were also feathered. The lack of widespread fossil evidence for feathered non-avian dinosaurs may be because delicate features like skin and feathers are not often preserved by fossilization and thus are absent from the fossil record.\n\nThe description of feathered dinosaurs has not been without controversy; perhaps the most vocal critics have been Alan Feduccia and Theagarten Lingham-Soliar, who have proposed that some purported feather-like fossils are the result of the decomposition of collagenous fiber that underlaid the dinosaurs' skin, and that maniraptoran dinosaurs with vaned feathers were not actually dinosaurs, but convergent with dinosaurs. However, their views have for the most part not been accepted by other researchers, to the point that the scientific nature of Feduccia's proposals has been questioned.\n\nIn 2016, it was reported that a dinosaur tail with feathers had been found enclosed in amber. The fossil is about 99 million years old.\n\nBecause feathers are often associated with birds, feathered dinosaurs are often touted as the missing link between birds and dinosaurs. However, the multiple skeletal features also shared by the two groups represent another important line of evidence for paleontologists. Areas of the skeleton with important similarities include the neck, pubis, wrist (semi-lunate carpal), arm and pectoral girdle, furcula (wishbone), and breast bone. Comparison of bird and dinosaur skeletons through cladistic analysis strengthens the case for the link.\n\nLarge meat-eating dinosaurs had a complex system of air sacs similar to those found in modern birds, according to a 2005 investigation led by Patrick M. O'Connor. The lungs of theropod dinosaurs (carnivores that walked on two legs and had bird-like feet) likely pumped air into hollow sacs in their skeletons, as is the case in birds. \"What was once formally considered unique to birds was present in some form in the ancestors of birds\", O'Connor said. In 2008, scientists described \"Aerosteon riocoloradensis\", the skeleton of which supplies the strongest evidence to date of a dinosaur with a bird-like breathing system. CT-scanning of \"Aerosteon\"'s fossil bones revealed evidence for the existence of air sacs within the animal's body cavity.\n\nFossils of the troodonts \"Mei\" and \"Sinornithoides\" demonstrate that some dinosaurs slept with their heads tucked under their arms. This behavior, which may have helped to keep the head warm, is also characteristic of modern birds. Several deinonychosaur and oviraptorosaur specimens have also been found preserved on top of their nests, likely brooding in a bird-like manner. The ratio between egg volume and body mass of adults among these dinosaurs suggest that the eggs were primarily brooded by the male, and that the young were highly precocial, similar to many modern ground-dwelling birds.\n\nSome dinosaurs are known to have used gizzard stones like modern birds. These stones are swallowed by animals to aid digestion and break down food and hard fibers once they enter the stomach. When found in association with fossils, gizzard stones are called gastroliths.\n\nThe discovery that birds are a type of dinosaur showed that dinosaurs in general are not, in fact, extinct as is commonly stated. However, all non-avian dinosaurs as well as many groups of birds did suddenly become extinct approximately 66 million years ago. It has been suggested that because small mammals, squamata and birds occupied the ecological niches suited for small body size, non-avian dinosaurs never evolved a diverse fauna of small-bodied species, which led to their downfall when large-bodied terrestrial tetrapods were hit by the mass extinction event. Many other groups of animals also became extinct at this time, including ammonites (nautilus-like mollusks), mosasaurs, plesiosaurs, pterosaurs, and many groups of mammals. Significantly, the insects suffered no discernible population loss, which left them available as food for other survivors. This mass extinction is known as the Cretaceous–Paleogene extinction event. The nature of the event that caused this mass extinction has been extensively studied since the 1970s; at present, several related theories are supported by paleontologists. Though the consensus is that an impact event was the primary cause of dinosaur extinction, some scientists cite other possible causes, or support the idea that a confluence of several factors was responsible for the sudden disappearance of dinosaurs from the fossil record.\n\nThe asteroid collision theory, which was brought to wide attention in 1980 by Walter Alvarez and colleagues, links the extinction event at the end of the Cretaceous period to a bolide impact approximately 66 million years ago. Alvarez \"et al.\" proposed that a sudden increase in iridium levels, recorded around the world in the period's rock stratum, was direct evidence of the impact. The bulk of the evidence now suggests that a bolide wide hit in the vicinity of the Yucatán Peninsula (in southeastern Mexico), creating the approximately Chicxulub Crater and triggering the mass extinction. Scientists are not certain whether dinosaurs were thriving or declining before the impact event. Some scientists propose that the meteorite impact caused a long and unnatural drop in Earth's atmospheric temperature, while others claim that it would have instead created an unusual heat wave. The consensus among scientists who support this theory is that the impact caused extinctions both directly (by heat from the meteorite impact) and also indirectly (via a worldwide cooling brought about when matter ejected from the impact crater reflected thermal radiation from the sun). Although the speed of extinction cannot be deduced from the fossil record alone, various models suggest that the extinction was extremely rapid, being down to hours rather than years.\n\nBefore 2000, arguments that the Deccan Traps flood basalts caused the extinction were usually linked to the view that the extinction was gradual, as the flood basalt events were thought to have started around 68 million years ago and lasted for over 2 million years. However, there is evidence that two thirds of the Deccan Traps were created in only 1 million years about 66 million years ago, and so these eruptions would have caused a fairly rapid extinction, possibly over a period of thousands of years, but still longer than would be expected from a single impact event.\n\nThe Deccan Traps in India could have caused extinction through several mechanisms, including the release into the air of dust and sulfuric aerosols, which might have blocked sunlight and thereby reduced photosynthesis in plants. In addition, Deccan Trap volcanism might have resulted in carbon dioxide emissions, which would have increased the greenhouse effect when the dust and aerosols cleared from the atmosphere. Before the mass extinction of the dinosaurs, the release of volcanic gases during the formation of the Deccan Traps \"contributed to an apparently massive global warming. Some data point to an average rise in temperature of in the last half million years before the impact [at Chicxulub].\"\n\nIn the years when the Deccan Traps theory was linked to a slower extinction, Luis Alvarez (who died in 1988) replied that paleontologists were being misled by sparse data. While his assertion was not initially well-received, later intensive field studies of fossil beds lent weight to his claim. Eventually, most paleontologists began to accept the idea that the mass extinctions at the end of the Cretaceous were largely or at least partly due to a massive Earth impact. However, even Walter Alvarez has acknowledged that there were other major changes on Earth even before the impact, such as a drop in sea level and massive volcanic eruptions that produced the Indian Deccan Traps, and these may have contributed to the extinctions.\n\nNon-avian dinosaur remains are occasionally found above the Cretaceous–Paleogene boundary. In 2001, paleontologists Zielinski and Budahn reported the discovery of a single hadrosaur leg-bone fossil in the San Juan Basin, New Mexico, and described it as evidence of Paleocene dinosaurs. The formation in which the bone was discovered has been dated to the early Paleocene epoch, approximately 64.5 million years ago. If the bone was not re-deposited into that stratum by weathering action, it would provide evidence that some dinosaur populations may have survived at least a half million years into the Cenozoic Era. Other evidence includes the finding of dinosaur remains in the Hell Creek Formation up to above the Cretaceous–Paleogene boundary, representing  years of elapsed time. Similar reports have come from other parts of the world, including China. Many scientists, however, dismissed the supposed Paleocene dinosaurs as re-worked, that is, washed out of their original locations and then re-buried in much later sediments. Direct dating of the bones themselves has supported the later date, with U–Pb dating methods resulting in a precise age of 64.8 ± 0.9 million years ago. If correct, the presence of a handful of dinosaurs in the early Paleocene would not change the underlying facts of the extinction.\n\nDinosaur fossils have been known for millennia, although their true nature was not recognized. The Chinese, whose modern word for dinosaur is \"kǒnglóng\" (恐龍, or \"terrible dragon\"), considered them to be dragon bones and documented them as such. For example, \"Hua Yang Guo Zhi\", a book written by Chang Qu during the Western Jin Dynasty (265–316), reported the discovery of dragon bones at Wucheng in Sichuan Province. Villagers in central China have long unearthed fossilized \"dragon bones\" for use in traditional medicines, a practice that continues today. In Europe, dinosaur fossils were generally believed to be the remains of giants and other biblical creatures.\n\nScholarly descriptions of what would now be recognized as dinosaur bones first appeared in the late 17th century in England. Part of a bone, now known to have been the femur of a \"Megalosaurus\", was recovered from a limestone quarry at Cornwell near Chipping Norton, Oxfordshire, in 1676. The fragment was sent to Robert Plot, Professor of Chemistry at the University of Oxford and first curator of the Ashmolean Museum, who published a description in his \"Natural History of Oxfordshire\" in 1677. He correctly identified the bone as the lower extremity of the femur of a large animal, and recognized that it was too large to belong to any known species. He therefore concluded it to be the thigh bone of a giant human similar to those mentioned in the Bible. In 1699, Edward Lhuyd, a friend of Sir Isaac Newton, was responsible for the first published scientific treatment of what would now be recognized as a dinosaur when he described and named a sauropod tooth, \"Rutellum implicatum\", that had been found in Caswell, near Witney, Oxfordshire.\nBetween 1815 and 1824, the Rev William Buckland, a professor of geology at Oxford, collected more fossilized bones of \"Megalosaurus\" and became the first person to describe a dinosaur in a scientific journal. The second dinosaur genus to be identified, \"Iguanodon\", was discovered in 1822 by Mary Ann Mantell – the wife of English geologist Gideon Mantell. Gideon Mantell recognized similarities between his fossils and the bones of modern iguanas. He published his findings in 1825.\n\nThe study of these \"great fossil lizards\" soon became of great interest to European and American scientists, and in 1842 the English paleontologist Richard Owen coined the term \"dinosaur\". He recognized that the remains that had been found so far, \"Iguanodon\", \"Megalosaurus\" and \"Hylaeosaurus\", shared a number of distinctive features, and so decided to present them as a distinct taxonomic group. With the backing of Prince Albert, the husband of Queen Victoria, Owen established the Natural History Museum, London, to display the national collection of dinosaur fossils and other biological and geological exhibits.\n\nIn 1858, William Parker Foulke discovered the first known American dinosaur, in marl pits in the small town of Haddonfield, New Jersey. (Although fossils had been found before, their nature had not been correctly discerned.) The creature was named \"Hadrosaurus foulkii\". It was an extremely important find: \"Hadrosaurus\" was one of the first nearly complete dinosaur skeletons found (the first was in 1834, in Maidstone, England), and it was clearly a bipedal creature. This was a revolutionary discovery as, until that point, most scientists had believed dinosaurs walked on four feet, like other lizards. Foulke's discoveries sparked a wave of dinosaur mania in the United States.\n\nDinosaur mania was exemplified by the fierce rivalry between Edward Drinker Cope and Othniel Charles Marsh, both of whom raced to be the first to find new dinosaurs in what came to be known as the Bone Wars. The feud probably originated when Marsh publicly pointed out that Cope's reconstruction of an \"Elasmosaurus\" skeleton was flawed: Cope had inadvertently placed the plesiosaur's head at what should have been the animal's tail end. The fight between the two scientists lasted for over 30 years, ending in 1897 when Cope died after spending his entire fortune on the dinosaur hunt. Marsh 'won' the contest primarily because he was better funded through a relationship with the US Geological Survey. Unfortunately, many valuable dinosaur specimens were damaged or destroyed due to the pair's rough methods: for example, their diggers often used dynamite to unearth bones (a method modern paleontologists would find appalling). Despite their unrefined methods, the contributions of Cope and Marsh to paleontology were vast: Marsh unearthed 86 new species of dinosaur and Cope discovered 56, a total of 142 new species. Cope's collection is now at the American Museum of Natural History in New York, while Marsh's is on display at the Peabody Museum of Natural History at Yale University.\n\nAfter 1897, the search for dinosaur fossils extended to every continent, including Antarctica. The first Antarctic dinosaur to be discovered, the ankylosaurid \"Antarctopelta oliveroi\", was found on James Ross Island in 1986, although it was 1994 before an Antarctic species, the theropod \"Cryolophosaurus ellioti\", was formally named and described in a scientific journal.\n\nCurrent dinosaur \"hot spots\" include southern South America (especially Argentina) and China. China in particular has produced many exceptional feathered dinosaur specimens due to the unique geology of its dinosaur beds, as well as an ancient arid climate particularly conducive to fossilization.\n\nThe field of dinosaur research has enjoyed a surge in activity that began in the 1970s and is ongoing. This was triggered, in part, by John Ostrom's discovery of \"Deinonychus\", an active predator that may have been warm-blooded, in marked contrast to the then-prevailing image of dinosaurs as sluggish and cold-blooded. Vertebrate paleontology has become a global science. Major new dinosaur discoveries have been made by paleontologists working in previously unexploited regions, including India, South America, Madagascar, Antarctica, and most significantly China (the amazingly well-preserved feathered dinosaurs in China have further consolidated the link between dinosaurs and their living descendants, modern birds). The widespread application of cladistics, which rigorously analyzes the relationships between biological organisms, has also proved tremendously useful in classifying dinosaurs. Cladistic analysis, among other modern techniques, helps to compensate for an often incomplete and fragmentary fossil record.\n\nOne of the best examples of soft-tissue impressions in a fossil dinosaur was discovered in Pietraroia, Italy. The discovery was reported in 1998, and described the specimen of a small, very young coelurosaur, \"Scipionyx samniticus\". The fossil includes portions of the intestines, colon, liver, muscles, and windpipe of this immature dinosaur.\n\nIn the March 2005 issue of \"Science\", the paleontologist Mary Higby Schweitzer and her team announced the discovery of flexible material resembling actual soft tissue inside a 68-million-year-old \"Tyrannosaurus rex\" leg bone from the Hell Creek Formation in Montana. After recovery, the tissue was rehydrated by the science team. When the fossilized bone was treated over several weeks to remove mineral content from the fossilized bone-marrow cavity (a process called demineralization), Schweitzer found evidence of intact structures such as blood vessels, bone matrix, and connective tissue (bone fibers). Scrutiny under the microscope further revealed that the putative dinosaur soft tissue had retained fine structures (microstructures) even at the cellular level. The exact nature and composition of this material, and the implications of Schweitzer's discovery, are not yet clear.\n\nIn 2009, a team including Schweitzer announced that, using even more careful methodology, they had duplicated their results by finding similar soft tissue in a duck-billed dinosaur, \"Brachylophosaurus canadensis\", found in the Judith River Formation of Montana. This included even more detailed tissue, down to preserved bone cells that seem even to have visible remnants of nuclei and what seem to be red blood cells. Among other materials found in the bone was collagen, as in the \"Tyrannosaurus\" bone. The type of collagen an animal has in its bones varies according to its DNA and, in both cases, this collagen was of the same type found in modern chickens and ostriches.\n\nThe extraction of ancient DNA from dinosaur fossils has been reported on two separate occasions; upon further inspection and peer review, however, neither of these reports could be confirmed. However, a functional peptide involved in the vision of a theoretical dinosaur has been inferred using analytical phylogenetic reconstruction methods on gene sequences of related modern species such as reptiles and birds. In addition, several proteins, including hemoglobin, have putatively been detected in dinosaur fossils.\n\nIn 2015, researchers reported finding structures similar to blood cells and collagen fibers, preserved in the bone fossils of six Cretaceous dinosaur specimens, which are approximately 75 million years old.\n\nBy human standards, dinosaurs were creatures of fantastic appearance and often enormous size. As such, they have captured the popular imagination and become an enduring part of human culture. Entry of the word \"dinosaur\" into the common vernacular reflects the animals' cultural importance: in English, \"dinosaur\" is commonly used to describe anything that is impractically large, obsolete, or bound for extinction.\n\nPublic enthusiasm for dinosaurs first developed in Victorian England, where in 1854, three decades after the first scientific descriptions of dinosaur remains, a menagerie of lifelike dinosaur sculptures were unveiled in London's Crystal Palace Park. The Crystal Palace dinosaurs proved so popular that a strong market in smaller replicas soon developed. In subsequent decades, dinosaur exhibits opened at parks and museums around the world, ensuring that successive generations would be introduced to the animals in an immersive and exciting way. Dinosaurs' enduring popularity, in its turn, has resulted in significant public funding for dinosaur science, and has frequently spurred new discoveries. In the United States, for example, the competition between museums for public attention led directly to the Bone Wars of the 1880s and 1890s, during which a pair of feuding paleontologists made enormous scientific contributions.\n\nThe popular preoccupation with dinosaurs has ensured their appearance in literature, film, and other media. Beginning in 1852 with a passing mention in Charles Dickens \"Bleak House\", dinosaurs have been featured in large numbers of fictional works. Jules Verne's 1864 novel \"Journey to the Center of the Earth\", Sir Arthur Conan Doyle's 1912 book \"The Lost World\", the iconic 1933 film \"King Kong\", the 1954 \"Godzilla\" and its many sequels, the best-selling 1990 novel \"Jurassic Park\" by Michael Crichton and its 1993 film adaptation are just a few notable examples of dinosaur appearances in fiction. Authors of general-interest non-fiction works about dinosaurs, including some prominent paleontologists, have often sought to use the animals as a way to educate readers about science in general. Dinosaurs are ubiquitous in advertising; numerous companies have referenced dinosaurs in printed or televised advertisements, either in order to sell their own products or in order to characterize their rivals as slow-moving, dim-witted, or obsolete.\n\n\n\nGeneral\n\nImages\n\nVideo\n\nPopular\n\nTechnical\n"}
{"id": "8315", "url": "https://en.wikipedia.org/wiki?curid=8315", "title": "Diamagnetism", "text": "Diamagnetism\n\nDiamagnetic materials are repelled by a magnetic field; an applied magnetic field creates an induced magnetic field in them in the opposite direction, causing a repulsive force. In contrast, paramagnetic and ferromagnetic materials are attracted by a magnetic field. Diamagnetism is a quantum mechanical effect that occurs in all materials; when it is the only contribution to the magnetism the material is called diamagnetic. In paramagnetic and ferromagnetic substances the weak diamagnetic force is overcome by the attractive force of magnetic dipoles in the material. The magnetic permeability of diamagnetic materials is less than μ, the permeability of vacuum. In most materials diamagnetism is a weak effect which can only be detected by sensitive laboratory instruments, but a superconductor acts as a strong diamagnet because it repels a magnetic field entirely from its interior.\n\nDiamagnetism was first discovered when Sebald Justinus Brugmans observed in 1778 that bismuth and antimony were repelled by magnetic fields. In 1845, Michael Faraday demonstrated that it was a property of matter and concluded that every material responded (in either a diamagnetic or paramagnetic way) to an applied magnetic field. On a suggestion by William Whewell, Faraday first referred to the phenomenon as \"diamagnetic\" (the prefix \"dia-\" meaning \"through\" or \"across\"), then later changed it to \"diamagnetism\".\n\nDiamagnetism, to a greater or lesser degree, is a property of all materials and always makes a weak contribution to the material's response to a magnetic field. For materials that show some other form of magnetism (such as ferromagnetism or paramagnetism), the diamagnetic contribution becomes negligible. Substances that mostly display diamagnetic behaviour are termed diamagnetic materials, or diamagnets. Materials called diamagnetic are those that laypeople generally think of as \"non-magnetic\", and include water, wood, most organic compounds such as petroleum and some plastics, and many metals including copper, particularly the heavy ones with many core electrons, such as mercury, gold and bismuth. The magnetic susceptibility values of various molecular fragments are called Pascal's constants.\n\nDiamagnetic materials, like water, or water-based materials, have a relative magnetic permeability that is less than or equal to 1, and therefore a magnetic susceptibility less than or equal to 0, since susceptibility is defined as . This means that diamagnetic materials are repelled by magnetic fields. However, since diamagnetism is such a weak property, its effects are not observable in everyday life. For example, the magnetic susceptibility of diamagnets such as water is . The most strongly diamagnetic material is bismuth, , although pyrolytic carbon may have a susceptibility of in one plane. Nevertheless, these values are orders of magnitude smaller than the magnetism exhibited by paramagnets and ferromagnets. Note that because χ is derived from the ratio of the internal magnetic field to the applied field, it is a dimensionless value.\n\nAll conductors exhibit an effective diamagnetism when they experience a changing magnetic field. The Lorentz force on electrons causes them to circulate around forming eddy currents. The eddy currents then produce an induced magnetic field opposite the applied field, resisting the conductor's motion.\n\nSuperconductors may be considered perfect diamagnets (), because they expel all fields (except in a thin surface layer) due to the Meissner effect.\n\nIf a powerful magnet (such as a supermagnet) is covered with a layer of water (that is thin compared to the diameter of the magnet) then the field of the magnet significantly repels the water. This causes a slight dimple in the water's surface that may be seen by its reflection.\n\nDiamagnets may be levitated in stable equilibrium in a magnetic field, with no power consumption. Earnshaw's theorem seems to preclude the possibility of static magnetic levitation. However, Earnshaw's theorem applies only to objects with positive susceptibilities, such as ferromagnets (which have a permanent positive moment) and paramagnets (which induce a positive moment). These are attracted to field maxima, which do not exist in free space. Diamagnets (which induce a negative moment) are attracted to field minima, and there can be a field minimum in free space.\n\nA thin slice of pyrolytic graphite, which is an unusually strong diamagnetic material, can be stably floated in a magnetic field, such as that from rare earth permanent magnets. This can be done with all components at room temperature, making a visually effective demonstration of diamagnetism.\n\nThe Radboud University Nijmegen, the Netherlands, has conducted experiments where water and other substances were successfully levitated. Most spectacularly, a live frog (see figure) was levitated.\n\nIn September 2009, NASA's Jet Propulsion Laboratory in Pasadena, California announced it had successfully levitated mice using a superconducting magnet, an important step forward since mice are closer biologically to humans than frogs. JPL said it hopes to perform experiments regarding the effects of microgravity on bone and muscle mass.\n\nRecent experiments studying the growth of protein crystals have led to a technique using powerful magnets to allow growth in ways that counteract Earth's gravity.\n\nA simple homemade device for demonstration can be constructed out of bismuth plates and a few permanent magnets that levitate a permanent magnet.\n\nThe electrons in a material generally circulate in orbitals, with effectively zero resistance and act like current loops. Thus it might be imagined that diamagnetism effects in general would be very, very common, since any applied magnetic field would generate currents in these loops that would oppose the change, in a similar way to superconductors, which are essentially perfect diamagnets. However, since the electrons are rigidly held in orbitals by the charge of the protons and are further constrained by the Pauli exclusion principle, many materials exhibit diamagnetism, but typically respond very little to the applied field.\n\nThe Bohr–van Leeuwen theorem proves that there cannot be any diamagnetism or paramagnetism in a purely classical system. However, the classical theory for Langevin diamagnetism gives the same prediction as the quantum theory. The classical theory is given below.\n\nThe Langevin theory of diamagnetism applies to materials containing atoms with closed shells (see dielectrics). A field with intensity , applied to an electron with charge and mass , gives rise to Larmor precession with frequency . The number of revolutions per unit time is , so the current for an atom with electrons is (in SI units)\n\nThe magnetic moment of a current loop is equal to the current times the area of the loop. Suppose the field is aligned with the axis. The average loop area can be given as formula_2, where formula_3 is the mean square distance of the electrons perpendicular to the axis. The magnetic moment is therefore\n\nIf the distribution of charge is spherically symmetric, we can suppose that the distribution of coordinates are independent and identically distributed. Then formula_5, where formula_6 is the mean square distance of the electrons from the nucleus. Therefore, formula_7. If formula_8 is the number of atoms per unit volume, the diamagnetic susceptibility in SI units is\n\nThe Langevin theory does not apply to metals because they have non-localized electrons. The theory for the diamagnetism of a free electron gas is called Landau diamagnetism and instead considers the weak counter-acting field that forms when their trajectories are curved due to the Lorentz force. Landau diamagnetism, however, should be contrasted with Pauli paramagnetism, an effect associated with the polarization of delocalized electrons' spins. For the bulk case of a 3D system and low magnetic fields it can be calculated using Landau quantization, in SI units is:\n\nwhere formula_11 is the Fermi energy. This is equivalent to formula_12 exactly minus a third of Pauli paramagnetic susceptibility, where formula_13 is the Bohr magneton and formula_14 is the density of states.\n\n\n"}
{"id": "8317", "url": "https://en.wikipedia.org/wiki?curid=8317", "title": "Duke of Marlborough (title)", "text": "Duke of Marlborough (title)\n\nDuke of Marlborough ( ) is a title in the Peerage of England. It was created by Queen Anne in 1702 for John Churchill, 1st Earl of Marlborough (1650–1722), the noted military leader, and indeed an unqualified reference to the Duke of Marlborough in a historical text will almost certainly refer to him. The name of the dukedom refers to Marlborough in Wiltshire. It is one of the few titles in the peerage which allows for \"suo jure\" female inheritance, and the only current dukedom to do so.\n\nThe earldom of Marlborough was held by the family of Ley from its creation 1626 until its extinction with the death of the 4th earl in 1679. The title was recreated 10 years later for John Churchill (in 1689).\n\nChurchill had been made \"Lord Churchill of Eyemouth\" (1682) in the Scottish peerage, and \"Baron Churchill\" of Sandridge (1685) and \"Earl of Marlborough\" (1689) in the Peerage of England. Shortly after her accession to the throne in 1702, Queen Anne made Churchill the first \"Duke of Marlborough\" and granted him the subsidiary title \"Marquess of Blandford\".\n\nIn 1678, Churchill married Sarah Jennings (1660–1744), a courtier and influential favourite of the queen. They had seven children, of whom four daughters married into some of the most important families in Great Britain; one daughter and one son died in infancy. He was pre-deceased by his son, John Churchill, Marquess of Blandford, in 1703; so, to prevent the extinction of the titles, a special Act of Parliament was passed. When the 1st Duke of Marlborough died in 1722 his title as \"Lord Churchill of Eyemouth\" in the Scottish peerage became extinct and the Marlborough titles passed, according to the Act, to his eldest daughter Henrietta (1681–1733), the 2nd Duchess of Marlborough. She was married to the 2nd Earl of Godolphin and had a son who predeceased her.\n\nWhen Henrietta died in 1733, the Marlborough titles passed to her nephew Charles Spencer (1706–1758), the third son of her late sister Anne (1683–1716), who had married the 3rd Earl of Sunderland in 1699. After his older brother's death in 1729, Charles Spencer had already inherited the Spencer family estates and the titles of \"Earl of Sunderland\" (1643) and \"Baron Spencer\" of Wormleighton (1603), all in the Peerage of England. Upon his maternal aunt Henrietta's death in 1733, Charles Spencer succeeded to the Marlborough family estates and titles and became the 3rd Duke. When he died in 1758, his titles passed to his eldest son George (1739–1817), who was succeeded by his eldest son George, the 5th Duke (1766–1840). In 1815, Francis Spencer (the younger son of the 4th Duke) was created \"Baron Churchill\" in the Peerage of the United Kingdom. In 1902, his grandson, the 3rd Baron Churchill, was created \"Viscount Churchill\".\n\nIn 1817, the 5th Duke obtained permission to assume and bear the surname of Churchill in addition to his surname of Spencer, to perpetuate the name of his illustrious great-great-grandfather. At the same time he received Royal Licence to quarter the coat of arms of Churchill with his paternal arms of Spencer. The modern Dukes thus originally bore the surname \"Spencer\": the double-barrelled surname of \"Spencer-Churchill\" as used since 1817 remains in the family, though some members have preferred to style themselves \"Churchill\".\n\nThe 7th Duke was the paternal grandfather of the British Prime Minister Sir Winston Churchill, born at Blenheim Palace on 30 November 1874.\n\nThe 11th duke, John Spencer-Churchill died in 2014, having assumed the title in 1972. The 12th and present duke is Charles James Spencer-Churchill.\n\nThe family seat is Blenheim Palace in Woodstock, Oxfordshire.\n\nAfter his leadership in the victory against the French in the Battle of Blenheim on 13 August 1704, the 1st Duke was honoured by Queen Anne granting him the royal manor of Woodstock, and building him a house at her expense to be called Blenheim. Construction started in 1705 and the house was completed in 1722, the year of the 1st Duke's death. Blenheim Palace has since remained in the Churchill and Spencer-Churchill family.\n\nWith the exception of the 10th Duke and his first wife, the Dukes and Duchesses of Marlborough are buried in Blenheim Palace's chapel. Most other members of the Spencer-Churchill family are interred in St. Martin's parish churchyard at Bladon, a short distance from the palace.\n\nThe dukedom is the only one in the United Kingdom that can still pass through a female line. However, unlike the remainder to heirs general found in most other peerages that allow male-preference primogeniture, the grant does not allow for abeyance and follows a more restrictive Semi-Salic formula designed to keep succession wherever possible in the male line. The succession is as follows:\n\n\nSuccession to the title under the first and second contingencies have lapsed; holders of the title from the 3rd Duke trace their status from the third contingency.\n\nIt is now very unlikely that the Dukedom will be passed to a woman or through a woman, since all the male-line descendants of the 1st Duke's second daughter Anne Spencer, Countess of Sunderland—including the lines of the Viscounts Churchill and Barons Churchill of Whichwood and of the Earls Spencer and of the entire Spencer-Churchill and Spencer family—would have to become extinct.\n\nIf that were to happen, the Churchill titles would pass to the Earl of Jersey and his family, the heir-male of the 1st Duke's granddaughter Anne Villiers, Countess of Jersey, daughter of Elizabeth Egerton, Duchess of Bridgewater, the third daughter of the first Duke.\n\nThe next heir would be the Duke of Buccleuch and his family, the heir-male of the 1st Duke's great-granddaughter Elizabeth Montagu, Duchess of Buccleuch, the daughter of Mary Montagu, Duchess of Montagu (1766 creation), the daughter of the 1st Duke's youngest daughter Mary, Duchess of Montagu (1705 creation).\n\nThe fourth surviving line is represented by the Earl of Chichester and his family, the heir-male of the 1st Duke's most senior great-great-granddaughter Mary Henrietta Osborne, Countess of Chichester, daughter of Francis Osborne, 5th Duke of Leeds, only child of Mary Godolphin, Duchess of Leeds, daughter of the 1st Duke's eldest daughter Henrietta Godolphin, 2nd Duchess of Marlborough by her husband Francis Godolphin, 2nd Earl of Godolphin.\n\nThe Duke holds subsidiary titles: \"Marquess of Blandford\" (created in 1702 for John Churchill), \"Earl of Sunderland\" (created in 1643 for the Spencer family), \"Earl of Marlborough\" (created in 1689 for John Churchill), \"Baron Spencer\" of Wormleighton (created in 1603 for the Spencer family), and \"Baron Churchill\" of Sandridge (created in 1685 for John Churchill), all in the Peerage of England.\n\nThe title \"Marquess of Blandford\" is used as the courtesy title for the Duke's eldest son and heir. The Duke's eldest son's eldest son can use the courtesy title \"Earl of Sunderland\", and the duke's eldest son's eldest son's eldest son (not necessarily the eldest great-grandson) the title \"Lord Spencer of Wormleighton\" (not to be confused with Earl Spencer).\n\nThe title of \"Earl of Marlborough\", created for John Churchill in 1689, had previously been created for James Ley, in 1626, becoming extinct in 1679.\n\nThe 1st Duke was honoured with land and titles in the Holy Roman Empire: Emperor Joseph I created him a Prince in 1704, and in 1705 he was given the principality of Mindelheim (once the lordship of the noted soldier Georg von Frundsberg). He was obliged to surrender Mindelheim in 1714 by the Treaty of Utrecht, which returned it to Bavaria. He tried to obtain Nellenburg in Austria in exchange, which at that time was only a county ('Landgrafschaft'), but this failed, partially because Austrian law did not allow for Nellenburg being converted into a sovereign principality. Some authors misread the name of the county as Mellenburg. The 1st Duke's principality title of Mindelheim became extinct either on the return of the land to Bavaria or on his death, as the Empire operated Salic Law, which prevented female succession.\n\nThe original arms of Sir Winston Churchill (1620–1688), father of the 1st Duke of Marlborough, were simple and in use by his own father in 1619. The shield was Sable a lion rampant Argent, debruised by a bendlet Gules. The addition of a canton of Saint George (see below) rendered the distinguishing mark of the bendlet unnecessary.\n\nThe Churchill crest is blazoned as a lion couchant guardant Argent, supporting with its dexter forepaw a banner Gules, charged with a dexter hand appaumée of the first, staff Or.\n\nIn recognition of Sir Winston's services to King Charles I as Captain of the Horse, and his loyalty to King Charles II as a Member of Parliament, he was awarded an augmentation of honour to his arms around 1662. This rare mark of royal favour took the form of a canton of Saint George. At the same time, he was authorised to omit the bendlet, which had served the purpose of distinguishing this branch of the Churchill family from others which bore an undifferenced lion.\n\nSir Winston's shield and crest were inherited by his son John Churchill, 1st Duke of Marlborough. Minor modifications reflected the bearer's social rise: the helm was now shown in profile and had a closed grille to signify the bearer's rank as a peer, and there were now supporters placed on either side of the shield. They were the mythical Griffin (part lion, part eagle) and Wyvern (a dragon without hind legs). The supporters were derived from the arms of the family of the 1st Duke's mother, Drake of Ash (Argent, a wyvern gules; these arms can be seen on the monument in Musbury Church to Sir Bernard Drake, d.1586).\n\nThe motto was \"Fiel pero desdichado\" (Spanish for \"Faithful but unfortunate\"). The 1st Duke was also entitled to a coronet indicating his rank.\n\nWhen the 1st Duke was made a Prince of the Holy Roman Empire in 1705, two unusual features were added: the Imperial Eagle and a Princely Coronet. His estates in Germany, such as Mindelheim, were represented in his arms by additional quarterings.\n\nIn 1817, the 5th Duke received Royal Licence to place the quarter of Churchill ahead of his paternal arms of Spencer. The shield of the Spencer family arms is: quarterly Argent and Gules, in the second and third quarters a fret Or, over all on a bend Sable three escallops of the first. The Spencer crest is: out of a ducal coronet Or, a griffin's head between two wings expanded Argent, gorged with a collar gemel and armed Gules. Paul Courtenay observes that \"It would be normal in these circumstances for the paternal arms (Spencer) to take precedence over the maternal (Churchill), but because the Marlborough dukedom was senior to the Sunderland earldom, the procedure was reversed in this case.\"\n\nAlso in 1817, a further augmentation of honour was added to his armorial achievement. This incorporated the bearings from the standard of the Manor of Woodstock and was borne on an escutcheon, displayed over all in the centre chief point, as follows: Argent a cross of Saint George surmounted by an inescutcheon Azure, charged with three fleurs-de-lys Or, two over one. This inescutcheon represents the royal arms of France.\n\nThese quartered arms, incorporating the two augmentations of honour, have been the arms of all subsequent Dukes of Marlborough.\n\nThe motto \"Fiel pero desdichado\" is Spanish for \"Faithful though unhappy\". \"Desdichado\" means without happiness or without joy, alluding to the first Duke's father, Winston, who was a royalist and faithful supporter of the king during the English Civil War but was not compensated for his losses after the restoration. Charles II knighted Winston Churchill and other Civil War royalists but did not compensate them for their wartime losses, thereby inducing Winston to adopt the motto. It is unusual for the motto of an Englishman of the era to be in Spanish rather than Latin, and it is not known why this is the case.\n\nThe earldom of Marlborough was held by the family of Ley from 1626 to 1679. James Ley, the 1st Earl (c. 1550-1629), was lord chief justice of the King’s Bench in Ireland and then in England; he was an English member of parliament and was lord high treasurer from 1624 to 1628. In 1624 he was created Baron Ley and in 1626 Earl of Marlborough. The 3rd earl was his grandson James (1618–1665), a naval officer who was killed in action with the Dutch. James was succeeded by his uncle William, a younger son of the 1st earl, on whose death in 1679 the earldom became extinct.\n\n\n\nThe heir apparent to the Dukedom is George John Godolphin Spencer-Churchill, Marquess of Blandford (b. 1992), eldest son of the 12th Duke.\n\n \n<section begin=FamilyTree />\n\n<section end=FamilyTree />\n\n\n"}
{"id": "8322", "url": "https://en.wikipedia.org/wiki?curid=8322", "title": "December 17", "text": "December 17\n\n\n\n"}
{"id": "8324", "url": "https://en.wikipedia.org/wiki?curid=8324", "title": "Difference engine", "text": "Difference engine\n\nA difference engine is an automatic mechanical calculator designed to tabulate polynomial functions. The name derives from the method of divided differences, a way to interpolate or tabulate functions by using a small set of polynomial coefficients. Most mathematical functions commonly used by engineers, scientists and navigators, including logarithmic and trigonometric functions, can be approximated by polynomials, so a difference engine can compute many useful tables of numbers.\n\nThe historical difficulty in producing error-free tables by teams of mathematicians and human \"computers\" spurred Charles Babbage's desire to build a mechanism to automate the process.\n\nJ. H. Müller, an engineer in the Hessian army, conceived of the idea of a difference machine. This was described in a book published in 1786, but Müller was unable to obtain funding to progress with the idea.\n\nCharles Babbage began to construct a small difference engine in 1819 and had completed it by 1822 (Difference Engine 0). He announced his invention on June 14, 1822, in a paper to the Royal Astronomical Society, entitled \"Note on the application of machinery to the computation of astronomical and mathematical tables\". This machine used the decimal number system and was powered by cranking a handle. The British government was interested, since producing tables was time-consuming and expensive and they hoped the difference engine would make the task more economical.\n\nIn 1823, the British government gave Babbage £1700 to start work on the project. Although Babbage's design was feasible, the metalworking techniques of the era could not economically make parts in the precision and quantity required. Thus the implementation proved to be much more expensive and doubtful of success than the government's initial estimate. In 1832 Babbage and Joseph Clement produced a small working model (1/7 of the calculating section of Difference Engine No. 1, which was intended to operate on 20-digit numbers and sixth-order differences) which operated on 6-digit numbers and second-order differences. Lady Byron described seeing the working prototype in 1833: \"We both went to see the thinking machine (for so it seems) last Monday. It raised several Nos. to the 2nd and 3rd powers, and extracted the root of a Quadratic equation.\" Work on the larger engine was suspended in 1833.\n\nBy the time the government abandoned the project in 1842, Babbage had received and spent over £17,000 on development, which still fell short of achieving a working engine. The government valued only the machine's output (economically produced tables), not the development (at unknown and unpredictable cost to complete) of the machine itself. Babbage did not, or was unwilling to, recognize that predicament. Meanwhile, Babbage's attention had moved on to developing an analytical engine, further undermining the government’s confidence in the eventual success of the difference engine. By improving the concept as an analytical engine, Babbage had made the difference engine concept obsolete, and the project to implement it an utter failure in the view of the government.\n\nInspired by Babbage's difference engine plans, Per Georg Scheutz, with his son Edvard, built several difference engines from 1840 onwards (up to 15-digit numbers and fourth-order differences from 1853 onwards), one of which was sold to the British government in 1859. Martin Wiberg improved Scheutz's construction but used his device only for producing and publishing printed logarithmic tables.\n\nBabbage went on to design his much more general analytical engine, but later produced an improved \"Difference Engine No. 2\" design (31-digit numbers and seventh-order differences), between 1846 and 1849. Babbage was able to take advantage of ideas developed for the analytical engine to make the new difference engine calculate more quickly while using fewer parts.\n\nDuring the 1980s, Allan G. Bromley, an associate professor at the University of Sydney, Australia, studied Babbage's original drawings for the Difference and Analytical Engines at the Science Museum library in London. This work led the Science Museum to construct a working difference engine No. 2 from 1989 to 1991, under Doron Swade, the then Curator of Computing. This was to celebrate the 200th anniversary of Babbage's birth in 2001. In 2000, the printer which Babbage originally designed for the difference engine was also completed. The conversion of the original design drawings into drawings suitable for engineering manufacturers' use revealed some minor errors in Babbage's design (possibly introduced as a protection in case the plans were stolen), which had to be corrected. Once completed, both the engine and its printer worked flawlessly, and still do. The difference engine and printer were constructed to tolerances achievable with 19th-century technology, resolving a long-standing debate as to whether Babbage's design would actually have worked. (One of the reasons formerly advanced for the non-completion of Babbage's engines had been that engineering methods were insufficiently developed in the Victorian era.)\n\nThe printer's primary purpose is to produce stereotype plates for use in printing presses, which it does by pressing type into soft plaster to create a flong. Babbage intended that the Engine's results be conveyed directly to mass printing, having recognized that many errors in previous tables were not the result of human calculating mistakes but from error in the manual typesetting process. The printer's paper output is mainly a means of checking the Engine's performance.\n\nIn addition to funding the construction of the output mechanism for the Science Museum's Difference Engine No. 2, Nathan Myhrvold commissioned the construction of a second complete Difference Engine No. 2, which was on exhibit at the Computer History Museum in Mountain View, California until 31 January 2016.\nIt has since been transferred to Intellectual Ventures in Seattle where it is on display just outside the main lobby.\n\nThe difference engine consists of a number of columns, numbered from 1 to N. The machine is able to store one decimal number in each column. The machine can only add the value of a column \"n\" + 1 to column \"n\" to produce the new value of \"n\". Column \"N\" can only store a constant, column 1 displays (and possibly prints) the value of the calculation on the current iteration.\n\nThe engine is programmed by setting initial values to the columns. Column 1 is set to the value of the polynomial at the start of computation. Column 2 is set to a value derived from the first and higher derivatives of the polynomial at the same value of X. Each of the columns from 3 to \"N\" is set to a value derived from the formula_1 first and higher derivatives of the polynomial.\n\nIn the Babbage design, one iteration (i.e., one full set of addition and carry operations) happens for each rotation of the main shaft. Odd and even columns alternately perform an addition in one cycle. The sequence of operations for column formula_2 is thus:\n\n\nSteps 1,2,3,4 occur for every odd column, while steps 3,4,1,2 occur for every even column.\n\nWhile Babbage's original design placed the crank directly on the main shaft, it was later realized that the force required to crank the machine would have been too great for a human to handle comfortably. Therefore, the two models that were built incorporate a 4:1 reduction gear at the crank, and four revolutions of the crank are required to perform one full cycle.\n\nEach iteration creates a new result, and is accomplished in four steps corresponding to four complete turns of the handle shown at the far right in the picture below. The four steps are:\n\n\nThe engine represents negative numbers as ten's complements. Subtraction amounts to addition of a negative number. This works in the same manner that modern computers perform subtraction, known as two's complement.\n\nThe principle of a difference engine is Newton's method of divided differences. If the initial value of a polynomial (and of its finite differences) is calculated by some means for some value of X, the difference engine can calculate any number of nearby values, using the method generally known as the method of finite differences. For example, consider the quadratic polynomial\n\nwith the goal of tabulating the values \"p\"(0), \"p\"(1), \"p\"(2), \"p\"(3), \"p\"(4), and so forth. The table below is constructed as follows: the second column contains the values of the polynomial, the third column contains the differences of the two left neighbors in the second column, and the fourth column contains the differences of the two neighbors in the third column:\n\nThe numbers in the third values-column are constant. In fact, by starting with any polynomial of degree \"n\", the column number \"n\" + 1 will always be constant. This is the crucial fact behind the success of the method.\n\nThis table was built from left to right, but it is possible to continue building it from right to left down a diagonal in order to compute more values. To calculate \"p\"(5) use the values from the lowest diagonal. Start with the fourth column constant value of 4 and copy it down the column. Then continue the third column by adding 4 to 11 to get 15. Next continue the second column by taking its previous value, 22 and adding the 15 from the third column. Thus \"p\"(5) is 22 + 15 = 37. In order to compute \"p\"(6), we iterate the same algorithm on the \"p\"(5) values: take 4 from the fourth column, add that to the third column's value 15 to get 19, then add that to the second column's value 37 to get 56, which is \"p\"(6). This process may be continued ad infinitum. The values of the polynomial are produced without ever having to multiply. A difference engine only needs to be able to add. From one loop to the next, it needs to store 2 numbers—in this example (the last elements in the first and second columns). To tabulate polynomials of degree \"n\", one needs sufficient storage to hold \"n\" numbers.\n\nBabbage's difference engine No. 2, finally built in 1991, could hold 8 numbers of 31 decimal digits each and could thus tabulate 7th degree polynomials to that precision. The best machines from Scheutz could store 4 numbers with 15 digits each.\n\nThe initial values of columns can be calculated by first manually calculating N consecutive values of the function and by backtracking, i.e. calculating the required differences.\n\nCol formula_6 gets the value of the function at the start of computation formula_7. Col formula_8 is the difference between formula_9 and formula_7…\n\nIf the function to be calculated is a polynomial function, expressed as\nthe initial values can be calculated directly from the constant coefficients \"a\", \"a\",\"a\", …, \"a\" without calculating any data points. The initial values are thus:\n\n\nMany commonly used functions are analytic functions, which can be expressed as power series, for example as a Taylor series. The initial values can be calculated to any degree of accuracy; if done correctly the engine will give exact results for first N steps. After that, the engine will only give an approximation of the function.\n\nThe Taylor series expresses the function as a sum obtained from its derivatives at one point. For many functions the higher derivatives are trivial to obtain; for instance, the sine function at 0 has values of 0 or formula_19 for all derivatives. Setting 0 as the start of computation we get the simplified Maclaurin series\n\nThe same method of calculating the initial values from the coefficients can be used as for polynomial functions. The polynomial constant coefficients will now have the value\n\nThe problem with the methods described above is that errors will accumulate and the series will tend to diverge from the true function. A solution which guarantees a constant maximum error is to use curve fitting. A minimum of \"N\" values are calculated evenly spaced along the range of the desired calculations. Using a curve fitting technique like Gaussian reduction an \"N\"−1th degree polynomial interpolation of the function is found. With the optimized polynomial, the initial values can be calculated as above.\n\n\n\n"}
{"id": "8326", "url": "https://en.wikipedia.org/wiki?curid=8326", "title": "Draupnir", "text": "Draupnir\n\nIn Norse mythology, Draupnir (Old Norse \"the dripper\") is a gold ring possessed by the god Odin with the ability to multiply itself: Every ninth night, eight new rings 'drip' from Draupnir, each one of the same size and weight as the original.\n\nDraupnir was forged by the dwarven brothers Brokkr and Eitri (or Sindri). Brokkr and Eitri made this ring as one of a set of three gifts which included Mjöllnir and Gullinbursti. They made these gifts in accordance with a wager Loki made saying that Brokk and Eitri could not make better gifts than the three made by the Sons of Ivaldi. In the end, Mjöllnir, Thor's hammer, won the contest for Brokkr and Eitri. Loki used a loophole to get out of the wager for his head (the wager was for Loki's head only, but he argued that, to remove his head, they would have to injure his neck, which was not in the bargain) and Brokkr punished him by sealing his lips shut with wire.\n\nThe ring was placed by Odin on the funeral pyre of his son Baldr:\n\nOdin laid upon the pyre the gold ring called Draupnir; this quality attended it: that every ninth night there fell from it eight gold rings of equal weight. (from the \"Gylfaginning\").\nThe ring was subsequently retrieved by Hermóðr. It was offered as a gift by Freyr's servant Skírnir in the wooing of Gerðr, which is described in the poem \"Skírnismál\".\n\n\"DRAUPNIR\" was revealed as the password to a website that Neal Caffrey and Mozzie used to view their stolen Nazi U-boat treasure in \"Taking Account\", the seventh episode of the third season of \"White Collar\".\n\nDraupnir is represented as a card in the Yu-Gi-Oh Trading Card Game. It has an effect that mimics the multiplication ability of the mythological version. If it is destroyed by another card's effect, you can add another \"Nordic Relic\" card to your hand. The art represents it as an arm brace, with another brace seemingly growing from it, once again mimicking the story.\n\nIt also appeared in episode 11 of \"\" as a tool to seal Loki's spirit.\n\n"}
{"id": "8328", "url": "https://en.wikipedia.org/wiki?curid=8328", "title": "Divergence", "text": "Divergence\n\nIn vector calculus, divergence is a vector operator that produces a scalar field giving the quantity of a vector field's source at each point. More technically, the divergence represents the volume density of the outward flux of a vector field from an infinitesimal volume around a given point.\n\nAs an example, consider air as it is heated or cooled. The velocity of the air at each point defines a vector field. While air is heated in a region, it expands in all directions, and thus the velocity field points outward from that region. The divergence of the velocity field in that region would thus have a positive value. While the air is cooled and thus contracting, the divergence of the velocity has a negative value.\n\nIn physical terms, the divergence of a three-dimensional vector field is the extent to which the vector field flow behaves like a source at a given point. It is a local measure of its \"outgoingness\" – the extent to which there is more of some quantity exiting an infinitesimal region of space than entering it. If the divergence is nonzero at some point then there must be a source or sink at that position. (Note that we are imagining the vector field to be like the velocity vector field of a fluid (in motion) when we use the terms \"flow\", \"source\" and so on.)\n\nMore rigorously, the divergence of a vector field at a point can be defined as the limit of the net flow of across the smooth boundary of a three-dimensional region divided by the volume of as shrinks to . Formally,\n\nwhere is the volume of , is the boundary of , and the integral is a surface integral with being the outward unit normal to that surface. The result, , is a function of . From this definition it also becomes obvious that can be seen as the \"source density\" of the flux of .\n\nIn light of the physical interpretation, a vector field with zero divergence everywhere is called \"incompressible\" or \"solenoidal\" – in which case any closed surface has no net flow across it.\n\nThe intuition that the sum of all sources minus the sum of all sinks should give the net flow outwards of a region is made precise by the divergence theorem.\n\nLet , , be a system of Cartesian coordinates in 3-dimensional Euclidean space, and let , , be the corresponding basis of unit vectors. The divergence of a continuously differentiable vector field is defined as the scalar-valued function:\n\nAlthough expressed in terms of coordinates, the result is invariant under rotations, as the physical interpretation suggests. More generally, the trace of the Jacobian matrix of an -dimensional vector field in -dimensional space is invariant under any invertible linear transformation.\n\nThe common notation for the divergence is a convenient mnemonic, where the dot denotes an operation reminiscent of the dot product: take the components of the operator (see del), apply them to the corresponding components of , and sum the results. Because applying an operator is different from multiplying the components, this is considered an abuse of notation.\n\nThe divergence of a continuously differentiable second-order tensor field is a first-order tensor field:\n\nFor a vector expressed in cylindrical coordinates as\nwhere is the unit vector in direction , the divergence is\n\nIn spherical coordinates, with the angle with the axis and the rotation around the axis, the divergence is\n\nIt can be shown that any stationary flux that is at least twice continuously differentiable in and vanishes sufficiently fast for can be decomposed into an \"irrotational part\" and a \"source-free part\" . Moreover, these parts are explicitly determined by the respective \"source densities\" (see above) and \"circulation densities\" (see the article Curl):\n\nFor the irrotational part one has\n\nwith\n\nThe source-free part, , can be similarly written: one only has to replace the \"scalar potential\" by a \"vector potential\" and the terms by , and the source density \nby the circulation density .\n\nThis \"decomposition theorem\" is a by-product of the stationary case of electrodynamics. It is a special case of the more general Helmholtz decomposition which works in dimensions greater than three as well.\n\nThe following properties can all be derived from the ordinary differentiation rules of calculus. Most importantly, the divergence is a linear operator, i.e.\n\nfor all vector fields and and all real numbers and .\n\nThere is a product rule of the following type: if is a scalar-valued function and is a vector field, then\n\nor in more suggestive notation\n\nAnother product rule for the cross product of two vector fields and in three dimensions involves the curl and reads as follows:\n\nor\n\nThe Laplacian of a scalar field is the divergence of the field's gradient:\n\nThe divergence of the curl of any vector field (in three dimensions) is equal to zero: \n\nIf a vector field with zero divergence is defined on a ball in , then there exists some vector field on the ball with . For regions in more topologically complicated than this, the latter statement might be false (see Poincaré lemma). The degree of \"failure\" of the truth of the statement, measured by the homology of the chain complex\n\nserves as a nice quantification of the complicatedness of the underlying region . These are the beginnings and main motivations of de Rham cohomology.\n\nOne can express the divergence as a particular case of the exterior derivative, which takes a 2-form to a 3-form in . Define the current two-form as\nIt measures the amount of \"stuff\" flowing through a surface per unit time in a \"stuff fluid\" of density moving with local velocity . Its exterior derivative is then given by\n\nThus, the divergence of the vector field can be expressed as:\nHere the superscript is one of the two musical isomorphisms, and is the Hodge dual. Working with the current two-form and the exterior derivative is usually easier than working with the vector field and divergence, because unlike the divergence, the exterior derivative commutes with a change of (curvilinear) coordinate system.\n\nThe divergence of a vector field can be defined in any number of dimensions. If \n\nin a Euclidean coordinate system with coordinates , define\n\nThe appropriate expression is more complicated in curvilinear coordinates.\n\nIn the case of one dimension, reduces to a regular function, and the divergence reduces to the derivative.\n\nFor any , the divergence is a linear operator, and it satisfies the \"product rule\"\n\nfor any scalar-valued function .\n\nThe divergence of a vector field extends naturally to any differentiable manifold of dimension that has a volume form (or density) , e.g. a Riemannian or Lorentzian manifold. Generalising the construction of a two-form for a vector field on , on such a manifold a vector field defines an -form obtained by contracting with . The divergence is then the function defined by\n\nStandard formulas for the Lie derivative allow us to reformulate this as\n\nThis means that the divergence measures the rate of expansion of a volume element as we let it flow with the vector field.\n\nOn a pseudo-Riemannian manifold, the divergence with respect to the metric volume form can be computed in terms of the Levi-Civita connection :\n\nwhere the second expression is the contraction of the vector field valued 1-form with itself and the last expression is the traditional coordinate expression from Ricci calculus.\n\nAn equivalent expression without using connection is\n\nwhere is the metric and denotes the partial derivative with respect to coordinate .\n\nDivergence can also be generalised to tensors. In Einstein notation, the divergence of a contravariant vector is given by\n\nwhere denotes the covariant derivative.\n\nEquivalently, some authors define the divergence of a mixed tensor by using the musical isomorphism : if is a -tensor ( for the contravariant vector and for the covariant one), then we define the \"divergence of \" to be the -tensor\n\nthat is, we take the trace over the \"first two\" covariant indices of the covariant derivative.\n\n\n"}
{"id": "8334", "url": "https://en.wikipedia.org/wiki?curid=8334", "title": "December 18", "text": "December 18\n\n\n\n"}
{"id": "8336", "url": "https://en.wikipedia.org/wiki?curid=8336", "title": "Decision problem", "text": "Decision problem\n\nIn computability theory and computational complexity theory, a decision problem is a problem that can be posed as a yes-no question of the input values. Decision problems typically appear in mathematical questions of decidability, that is, the question of the existence of an effective method to determine the existence of some object or its membership in a set; some of the most important problems in mathematics are undecidable.\n\nFor example, the problem \"given two numbers \"x\" and \"y\", does \"x\" evenly divide \"y\"?\" is a decision problem. The answer can be either 'yes' or 'no', and depends upon the values of \"x\" and \"y\". A method for solving a decision problem, given in the form of an algorithm, is called a decision procedure for that problem. A decision procedure for the decision problem \"given two numbers \"x\" and \"y\", does \"x\" evenly divide \"y\"?\" would give the steps for determining whether \"x\" evenly divides \"y\", given \"x\" and \"y\". One such algorithm is long division, taught to many school children. If the remainder is zero the answer produced is 'yes', otherwise it is 'no'. A decision problem which can be solved by an algorithm, such as this example, is called \"decidable\".\n\nThe field of computational complexity categorizes \"decidable\" decision problems by how difficult they are to solve. \"Difficult\", in this sense, is described in terms of the computational resources needed by the most efficient algorithm for a certain problem. The field of recursion theory, meanwhile, categorizes \"undecidable\" decision problems by Turing degree, which is a measure of the noncomputability inherent in any solution.\n\nA \"decision problem\" is any arbitrary yes-or-no question on an infinite set of inputs. Because of this, it is traditional to define the decision problem equivalently as: the set of possible inputs together with the set of inputs for which the problem returns \"yes\".\n\nThese inputs can be natural numbers, but may also be values of some other kind, such as strings over the binary alphabet {0,1} or over some other finite set of symbols. The subset of strings for which the problem returns \"yes\" is a formal language, and often decision problems are defined in this way as formal languages.\n\nAlternatively, using an encoding such as Gödel numberings, any string can be encoded as a natural number, via which a decision problem can be defined as a subset of the natural numbers.\n\nA classic example of a decidable decision problem is the set of prime numbers. It is possible to effectively decide whether a given natural number is prime by testing every possible nontrivial factor. Although much more efficient methods of primality testing are known, the existence of any effective method is enough to establish decidability.\n\nA decision problem \"A\" is called \"decidable\" or \"effectively solvable\" if \"A\" is a recursive set. A problem is called \"partially decidable\", \"semidecidable\", \"solvable\", or \"provable\" if \"A\" is a recursively enumerable set. Problems that are not decidable are called \"undecidable\".\n\nThe halting problem is an important undecidable decision problem; for more examples, see list of undecidable problems.\n\nDecision problems can be ordered according to many-one reducibility and related to feasible reductions such as polynomial-time reductions. A decision problem \"P\" is said to be \"complete\" for a set of decision problems \"S\" if \"P\" is a member of \"S\" and every problem in \"S\" can be reduced to \"P\". Complete decision problems are used in computational complexity to characterize complexity classes of decision problems. For example, the Boolean satisfiability problem is complete for the class NP of decision problems under polynomial-time reducibility.\n\nDecision problems are closely related to function problems, which can have answers that are more complex than a simple 'yes' or 'no'. A corresponding function problem is \"given two numbers \"x\" and \"y\", what is \"x\" divided by \"y\"?\".\n\nA function problem consists of a partial function \"f\"; the informal \"problem\" is to compute the values of \"f\" on the inputs for which it is defined.\n\nEvery function problem can be turned into a decision problem; the decision problem is just the graph of the associated function. (The graph of a function \"f\" is the set of pairs (\"x\",\"y\") such that \"f\"(\"x\") = \"y\".) If this decision problem were effectively solvable then the function problem would be as well. This reduction does not respect computational complexity, however. For example, it is possible for the graph of a function to be decidable in polynomial time (in which case running time is computed as a function of the pair (\"x\",\"y\") ) when the function is not computable in polynomial time (in which case running time is computed as a function of \"x\" alone). The function \"f\"(\"x\") = \"2\" has this property.\n\nEvery decision problem can be converted into the function problem of computing the characteristic function of the set associated to the decision problem. If this function is computable then the associated decision problem is decidable. However, this reduction is more liberal than the standard reduction used in computational complexity (sometimes called polynomial-time many-one reduction); for example, the complexity of the characteristic functions of an NP-complete problem and its co-NP-complete complement is exactly the same even though the underlying decision problems may not be considered equivalent in some typical models of computation.\n\nUnlike decision problems, for which there is only one correct answer for each input, optimization problems are concerned with finding the \"best\" answer to a particular input. Optimization problems arise naturally in many applications, such as the traveling salesman problem and many questions in linear programming.\n\nThere are standard techniques for transforming function and optimization problems into decision problems. For example, in the traveling salesman problem, the optimization problem is to produce a tour with minimal weight. The associated decision problem is: for each \"N\", to decide whether the graph has any tour with weight less than \"N\". By repeatedly answering the decision problem, it is possible to find the minimal weight of a tour.\n\nBecause the theory of decision problems is very well developed, research in complexity theory has typically focused on decision problems. Optimization problems themselves are still of interest in computability theory, as well as in fields such as operations research.\n\n\n"}
{"id": "8339", "url": "https://en.wikipedia.org/wiki?curid=8339", "title": "Domain Name System", "text": "Domain Name System\n\nThe Domain Name System (DNS) is a hierarchical decentralized naming system for computers, services, or other resources connected to the Internet or a private network. It associates various information with domain names assigned to each of the participating entities. Most prominently, it translates more readily memorized domain names to the numerical IP addresses needed for locating and identifying computer services and devices with the underlying network protocols. By providing a worldwide, distributed directory service, the Domain Name System is an essential component of the functionality on the Internet, that has been in use since 1985.\n\nThe Domain Name System delegates the responsibility of assigning domain names and mapping those names to Internet resources by designating authoritative name servers for each domain. Network administrators may delegate authority over sub-domains of their allocated name space to other name servers. This mechanism provides distributed and fault tolerant service and was designed to avoid a single large central database.\n\nThe Domain Name System also specifies the technical functionality of the database service that is at its core. It defines the DNS protocol, a detailed specification of the data structures and data communication exchanges used in the DNS, as part of the Internet Protocol Suite. Historically, other directory services preceding DNS were not scalable to large or global directories as they were originally based on text files, prominently the HOSTS.TXT resolver.\n\nThe Internet maintains two principal namespaces, the domain name hierarchy and the Internet Protocol (IP) address spaces. The Domain Name System maintains the domain name hierarchy and provides translation services between it and the address spaces. Internet name servers and a communication protocol implement the Domain Name System. A DNS name server is a server that stores the DNS records for a domain; a DNS name server responds with answers to queries against its database.\n\nThe most common types of records stored in the DNS database are for Start of Authority (SOA), IP addresses (A and AAAA), SMTP mail exchangers (MX), name servers (NS), pointers for reverse DNS lookups (PTR), and domain name aliases (CNAME). Although not intended to be a general purpose database, DNS can store records for other types of data for either automatic lookups, such as DNSSEC records, or for human queries such as \"responsible person\" (RP) records. As a general purpose database, the DNS has also been used in combating unsolicited email (spam) by storing a real-time blackhole list. The DNS database is traditionally stored in a structured zone file.\n\nAn often-used analogy to explain the Domain Name System is that it serves as the phone book for the Internet by translating human-friendly computer hostnames into IP addresses. For example, the domain name www.example.com translates to the addresses 93.184.216.119 (IPv4) and 2606:2800:220:6d:26bf:1447:1097:aa7 (IPv6). Unlike a phone book, DNS can be quickly updated, allowing a service's location on the network to change without affecting the end users, who continue to use the same host name. Users take advantage of this when they use meaningful Uniform Resource Locators (URLs), and e-mail addresses without having to know how the computer actually locates the services.\n\nAn important and ubiquitous function of DNS is its central role in distributed Internet services such as cloud services and content delivery networks. When a user accesses a distributed Internet service using a URL, the domain name of the URL is translated to the IP address of a server that is proximal to the user. The key functionality of DNS exploited here is that different users can \"simultaneously\" receive different translations for the \"same\" domain name, a key point of divergence from a traditional phone-book view of the DNS. This process of using the DNS to assign proximal servers to users is key to providing faster and more reliable responses on the Internet and is widely used by most major Internet services.\n\nThe DNS reflects the structure of administrative responsibility in the Internet. Each subdomain is a zone of administrative autonomy delegated to a manager. For zones operated by a registry, administrative information is often complemented by the registry's RDAP and WHOIS services. That data can be used to gain insight on, and track responsibility for, a given host on the Internet.\n\nUsing a simpler, more memorable name in place of a host's numerical address dates back to the ARPANET era. The Stanford Research Institute (now SRI International) maintained a text file named HOSTS.TXT that mapped host names to the numerical addresses of computers on the ARPANET. Maintenance of numerical addresses, called the Assigned Numbers List, was handled by Jon Postel at the University of Southern California's Information Sciences Institute (ISI), whose team worked closely with SRI.\n\nAddresses were assigned manually. To request a host name and an address and add a computer to the master file, users contacted the SRI's Network Information Center (NIC), directed by Elizabeth Feinler, by telephone during business hours.\n\nBy the early 1980s, maintaining a single, centralized host table had become slow and unwieldy and the emerging network required an automated naming system to address technical and personnel issues. Postel directed the task of forging a compromise between five competing proposals of solutions to Paul Mockapetris. Mockapetris instead created the Domain Name System.\n\nThe Internet Engineering Task Force published the original specifications in RFC 882 and RFC 883 in November 1983.\n\nIn 1984, four UC Berkeley students, Douglas Terry, Mark Painter, David Riggle, and Songnian Zhou, wrote the first Unix name server implementation for the Berkeley Internet Name Domain, commonly referred to as BIND. In 1985, Kevin Dunlap of DEC substantially revised the DNS implementation. Mike Karels, Phil Almquist, and Paul Vixie have maintained BIND since then. In the early 1990s, BIND was ported to the Windows NT platform. It was widely distributed, especially on Unix systems, and is still the most widely used DNS software on the Internet.\n\nIn November 1987, RFC 1034 and RFC 1035 superseded the 1983 DNS specifications. Several additional Request for Comments have proposed extensions to the core DNS protocols.\n\nThe domain name space consists of a tree data structure. Each node or leaf in the tree has a \"label\" and zero or more \"resource records\" (RR), which hold information associated with the domain name. The domain name itself consists of the label, possibly concatenated with the name of its parent node on the right, separated by a dot.\nThe tree sub-divides into \"zones\" beginning at the root zone. A DNS zone may consist of only one domain, or may consist of many domains and sub-domains, depending on the administrative choices of the zone manager. DNS can also be partitioned according to \"class\"; the separate classes can be thought of as an array of parallel namespace trees.\n\nAdministrative responsibility over any zone may be divided by creating additional zones. Authority over the new zone is said to be \"delegated\" to a designated name server. The parent zone ceases to be authoritative for the new zone.\n\nThe definitive descriptions of the rules for forming domain names appear in RFC 1035, RFC 1123, and RFC 2181.\nA domain name consists of one or more parts, technically called \"labels\", that are conventionally concatenated, and delimited by dots, such as example.com.\n\nThe right-most label conveys the top-level domain; for example, the domain name www.example.com belongs to the top-level domain \"com\".\n\nThe hierarchy of domains descends from right to left; each label to the left specifies a subdivision, or subdomain of the domain to the right. For example: the label \"example\" specifies a subdomain of the \"com\" domain, and \"www\" is a subdomain of example.com. This tree of subdivisions may have up to 127 levels.\n\nA label may contain zero to 63 characters. The null label, of length zero, is reserved for the root zone. The full domain name may not exceed the length of 253 characters in its textual representation. In the internal binary representation of the DNS the maximum length requires 255 octets of storage, since it also stores the length of the name.\n\nAlthough domain names may theoretically consist of any character representable in an octet, host names use a preferred format and character set. The characters allowed in their labels are a subset of the ASCII character set, consisting of characters \"a\" through \"z\", \"A\" through \"Z\", digits \"0\" through \"9\", and hyphen. This rule is known as the \"LDH rule\" (letters, digits, hyphen). Domain names are interpreted in case-independent manner. Labels may not start or end with a hyphen. An additional rule requires that top-level domain names should not be all-numeric.\n\nThe limited set of ASCII characters permitted in the DNS prevented the representation of names and words of many languages in their native alphabets or scripts. To make this possible, ICANN approved the Internationalizing Domain Names in Applications (IDNA) system, by which user applications, such as web browsers, map Unicode strings into the valid DNS character set using Punycode. In 2009 ICANN approved the installation of internationalized domain name country code top-level domains (\"ccTLD\"s). In addition, many registries of the existing top level domain names (\"TLD\"s) have adopted the IDNA system.\n\nThe Domain Name System is maintained by a distributed database system, which uses the client–server model. The nodes of this database are the name servers. Each domain has at least one authoritative DNS server that publishes information about that domain and the name servers of any domains subordinate to it. The top of the hierarchy is served by the root name servers, the servers to query when looking up (\"resolving\") a TLD.\n\nAn \"authoritative\" name server is a name server that only gives answers to DNS queries from data that has been configured by an original source, for example, the domain administrator or by dynamic DNS methods, in contrast to answers obtained via a query to another name server that only maintains a cache of data.\n\nAn authoritative name server can either be a \"master\" server or a \"slave\" server. A master server is a server that stores the original (\"master\") copies of all zone records. A slave server uses a special automatic updating mechanism in the DNS protocol in communication with its master to maintain an identical copy of the master records.\n\nEvery DNS zone must be assigned a set of authoritative name servers. This set of servers is stored in the parent domain zone with name server (NS) records.\n\nAn authoritative server indicates its status of supplying definitive answers, deemed \"authoritative\", by setting a protocol flag, called the \"Authoritative Answer\" (\"AA\") bit in its responses. This flag is usually reproduced prominently in the output of DNS administration query tools, such as dig, to indicate \"that the responding name server is an authority for the domain name in question.\"\n\nDomain name resolvers determine the domain name servers responsible for the domain name in question by a sequence of queries starting with the right-most (top-level) domain label.\n\nFor proper operation of its domain name resolver, a network host is configured with an initial cache (\"hints\") of the known addresses of the root name servers. The hints are updated periodically by an administrator by retrieving a dataset from a reliable source.\n\nAssuming the resolver has no cached records to accelerate the process, the resolution process starts with a query to one of the root servers. In typical operation, the root servers do not answer directly, but respond with a referral to more authoritative servers, e.g., a query for \"www.wikipedia.org\" is referred to the \"org\" servers. The resolver now queries the servers referred to, and iteratively repeat this process until it receives an authoritative answer. The diagram illustrates this process for the host www.wikipedia.org.\n\nThis mechanism would place a large traffic burden on the root servers, if every resolution on the Internet would require starting at the root. In practice caching is used in DNS servers to off-load the root servers, and as a result, root name servers actually are involved in only a fraction of all requests.\n\nIn theory, authoritative name servers are sufficient for the operation of the Internet. However, with only authoritative name servers operating, every DNS query must start with recursive queries at the root zone of the Domain Name System and each user system would have to implement resolver software capable of recursive operation.\n\nTo improve efficiency, reduce DNS traffic across the Internet, and increase performance in end-user applications, the Domain Name System supports DNS cache servers which store DNS query results for a period of time determined in the configuration (\"time-to-live\") of the domain name record in question.\nTypically, such caching DNS servers also implement the recursive algorithm necessary to resolve a given name starting with the DNS root through to the authoritative name servers of the queried domain. With this function implemented in the name server, user applications gain efficiency in design and operation.\n\nThe combination of DNS caching and recursive functions in a name server is not mandatory; the functions can be implemented independently in servers for special purposes.\n\nInternet service providers typically provide recursive and caching name servers for their customers. In addition, many home networking routers implement DNS caches and recursors to improve efficiency in the local network.\n\nThe client side of the DNS is called a DNS resolver. A resolver is responsible for initiating and sequencing the queries that ultimately lead to a full resolution (translation) of the resource sought, e.g., translation of a domain name into an IP address. An individual DNS query may be either \"non-recursive\", \"recursive\", or \"iterative\", or a combination of these.\n\n\nName servers in delegations are identified by name, rather than by IP address. This means that a resolving name server must issue another DNS request to find out the IP address of the server to which it has been referred. If the name given in the delegation is a subdomain of the domain for which the delegation is being provided, there is a circular dependency.\n\nIn this case, the name server providing the delegation must also provide one or more IP addresses for the authoritative name server mentioned in the delegation. This information is called \"glue\". The delegating name server provides this glue in the form of records in the \"additional section\" of the DNS response, and provides the delegation in the \"authority section\" of the response. A glue record is a combination of the name server and IP address.\n\nFor example, if the authoritative name server for example.org is ns1.example.org, a computer trying to resolve www.example.org first resolves ns1.example.org. Since ns1 is contained in example.org, this requires resolving example.org first, which presents a circular dependency. To break the dependency, the name server for the top level domain org includes glue along with the delegation for example.org. The glue records are address records that provide IP addresses for ns1.example.org. The resolver uses one or more of these IP addresses to query one of the domain's authoritative servers, which allows it to complete the DNS query.\n\nA standard practice in implementing name resolution in applications is to reduce the load on the Domain Name System servers by caching results locally, or in intermediate resolver hosts. Results obtained from a DNS request are always associated with the time to live (TTL), an expiration time after which the results must be discarded or refreshed. The TTL is set by the administrator of the authoritative DNS server. The period of validity may vary from a few seconds to days or even weeks.\n\nAs a result of this distributed caching architecture, changes to DNS records do not propagate throughout the network immediately, but require all caches to expire and to be refreshed after the TTL. RFC 1912 conveys basic rules for determining appropriate TTL values.\n\nSome resolvers may override TTL values, as the protocol supports caching for up to 68 years or no caching at all. Negative caching, i.e. the caching of the fact of non-existence of a record, is determined by name servers authoritative for a zone which must include the Start of Authority (SOA) record when reporting no data of the requested type exists. The value of the \"minimum\" field of the SOA record and the TTL of the SOA itself is used to establish the TTL for the negative answer.\n\nA reverse lookup is a query of the DNS for domain names when the IP address is known. Multiple domain names may be associated with an IP address. The DNS stores IP addresses in the form of domain names as specially formatted names in pointer (PTR) records within the infrastructure top-level domain arpa. For IPv4, the domain is in-addr.arpa. For IPv6, the reverse lookup domain is ip6.arpa. The IP address is represented as a name in reverse-ordered octet representation for IPv4, and reverse-ordered nibble representation for IPv6.\n\nWhen performing a reverse lookup, the DNS client converts the address into these formats before querying the name for a PTR record following the delegation chain as for any DNS query. For example, assuming the IPv4 address 208.80.152.2 is assigned to Wikimedia, it is represented as a DNS name in reverse order: 2.152.80.208.in-addr.arpa. When the DNS resolver gets a pointer (PTR) request, it begins by querying the root servers, which point to the servers of American Registry for Internet Numbers (ARIN) for the 208.in-addr.arpa zone. ARIN's servers delegate 152.80.208.in-addr.arpa to Wikimedia to which the resolver sends another query for 2.152.80.208.in-addr.arpa, which results in an authoritative response.\n\nUsers generally do not communicate directly with a DNS resolver. Instead DNS resolution takes place transparently in applications such as web browsers, e-mail clients, and other Internet applications. When an application makes a request that requires a domain name lookup, such programs send a resolution request to the DNS resolver in the local operating system, which in turn handles the communications required.\n\nThe DNS resolver will almost invariably have a cache (see above) containing recent lookups. If the cache can provide the answer to the request, the resolver will return the value in the cache to the program that made the request. If the cache does not contain the answer, the resolver will send the request to one or more designated DNS servers. In the case of most home users, the Internet service provider to which the machine connects will usually supply this DNS server: such a user will either have configured that server's address manually or allowed DHCP to set it; however, where systems administrators have configured systems to use their own DNS servers, their DNS resolvers point to separately maintained name servers of the organization. In any event, the name server thus queried will follow the process outlined above, until it either successfully finds a result or does not. It then returns its results to the DNS resolver; assuming it has found a result, the resolver duly caches that result for future use, and hands the result back to the software which initiated the request.\n\nSome large ISPs have configured their DNS servers to violate rules, such as by disobeying TTLs, or by indicating that a domain name does not exist just because one of its name servers does not respond.\n\nSome applications, such as web browsers, maintain an internal DNS cache to avoid repeated lookups via the network. This practice can add extra difficulty when debugging DNS issues, as it obscures the history of such data. These caches typically use very short caching times – in the order of one minute.\n\nInternet Explorer represents a notable exception: versions up to IE 3.x cache DNS records for 24 hours by default. Internet Explorer 4.x and later versions (up to IE 8) decrease the default time out value to half an hour, which may be changed by modifying default configuration.\n\nGoogle Chrome triggers a specific error message for DNS issues. When the DNS server is down or broken, Google Chrome returns an error message.\n\nThe Domain Name System includes several other functions and features.\n\nHostnames and IP addresses are not required to match in a one-to-one relationship. Multiple hostnames may correspond to a single IP address, which is useful in virtual hosting, in which many web sites are served from a single host. Alternatively, a single hostname may resolve to many IP addresses to facilitate fault tolerance and load distribution to multiple server instances across an enterprise or the global Internet.\n\nDNS serves other purposes in addition to translating names to IP addresses. For instance, mail transfer agents use DNS to find the best mail server to deliver e-mail. The domain to mail exchanger mapping provided by MX records may present an additional layer of fault tolerance and load distribution.\n\nThe DNS is used for efficient storage and distribution of IP addresses of blacklisted email hosts. A common method is to place the IP address of the subject host into the sub-domain of a higher level domain name, and to resolve that name to a record that indicates a positive or a negative indication.\n\nFor example:\nE-mail servers can query blacklist.example to find out if a specific host connecting to them is in the blacklist. Many of such blacklists, either subscription-based or free of cost, are available for use by email administrators and anti-spam software.\n\nThe Sender Policy Framework and DomainKeys were designed to take advantage of another DNS record type, the TXT record, but have since been assigned specific record types.\n\nTo provide resilience in the event of computer or network failure, multiple DNS servers are usually provided for coverage of each domain. At the top level of global DNS, thirteen groups of root name servers exist, with additional \"copies\" of them distributed worldwide via anycast addressing.\n\nDynamic DNS (DDNS) updates a DNS server with a client IP address on-the-fly, for example, when moving between ISPs or mobile hot spots, or when the IP address changes administratively.\n\nThe DNS protocol uses two types of DNS messages, queries and replies, and they both have the same format. Each message consists of a header and four sections: question, answer, authority, and an additional space. A header field (\"flags\") controls the content of these four sections.\n\nThe header section contains the following fields: \"Identification\", \"Flags\", \"Number of questions\", \"Number of answers\", \"Number of authority resource records\" (RRs), and \"Number of additional RRs\". The identification field can be used to match responses with queries. The flag field consists of several sub-fields. The first is a single bit which indicates if the message is a query (0) or a reply (1). The second sub-field consists of four bits; if the value is 1, the present packet is a reply; if it is 2, the present packet is a status; if the value is 0, the present packet is a request. A single-bit sub-field indicates if the DNS server is authoritative for the queried hostname. Another single-bit sub-field indicates if the client wants to send a recursive query (\"RD\"). The next single-bit sub-field indicates if the replying DNS server supports recursion (\"RA\"), since not all DNS servers are configured to do this task. Another sub-field indicates if the request was truncated for some reason (\"TC\"), and a four-bit sub-field indicates status. The \"question\" section contains the domain name and type of record (A, AAAA, MX, TXT, etc.) being resolved. The domain name is broken into discrete labels which are concatenated; each label is prefixed by the length of that label. The \"answer\" section has the resource records of the queried name. A domain name may occur in multiple records if it has multiple IP addresses associated.\n\nDNS primarily uses the User Datagram Protocol (UDP) on port number 53 to serve requests. DNS queries consist of a single UDP request from the client followed by a single UDP reply from the server. The Transmission Control Protocol (TCP) is used when the response data size exceeds 512 bytes, or for tasks such as zone transfers. Some resolver implementations use TCP for all queries.\n\nThe Domain Name System specifies a set of various types of resource records (RRs), which are the basic information elements of the domain name system. Each record has a type (name and number), an expiration time (time to live), a class, and type-specific data. Resource records of the same type are described as a \"resource record set\" (RRset). The order of resource records in a set, which is returned by a resolver to an application, is undefined, but often servers implement round-robin ordering to achieve load balancing. The Domain Name System Security Extensions (DNSSEC), however, work on the complete set of resource record in canonical order.\n\nWhen sent over an Internet Protocol network, all records use the common format specified in RFC 1035:\n\n\"NAME\" is the fully qualified domain name of the node in the tree. On the wire, the name may be shortened using label compression where ends of domain names mentioned earlier in the packet can be substituted for the end of the current domain name. A free standing \"@\" is used to denote the current origin.\n\n\"TYPE\" is the record type. It indicates the format of the data and it gives a hint of its intended use. For example, the \"A\" record is used to translate from a domain name to an IPv4 address, the \"NS\" record lists which name servers can answer lookups on a DNS zone, and the \"MX\" record specifies the mail server used to handle mail for a domain specified in an e-mail address.\n\n\"RDATA\" is data of type-specific relevance, such as the IP address for address records, or the priority and hostname for MX records. Well known record types may use label compression in the RDATA field, but \"unknown\" record types must not (RFC 3597).\n\nThe \"CLASS\" of a record is set to IN (for \"Internet\") for common DNS records involving Internet hostnames, servers, or IP addresses. In addition, the classes Chaos (CH) and Hesiod (HS) exist. Each class is an independent name space with potentially different delegations of DNS zones.\n\nIn addition to resource records defined in a zone file, the domain name system also defines several request types that are used only in communication with other DNS nodes (\"on the wire\"), such as when performing zone transfers (AXFR/IXFR) or for EDNS (OPT).\n\nThe domain name system supports wildcard DNS records which specify names that start with the \"asterisk label\", '*', e.g., *.example. DNS records belonging to wildcard domain names specify rules for generating resource records within a single DNS zone by substituting whole labels with matching components of the query name, including any specified descendants. For example, in the following configuration, the DNS zone \"x.example\" specifies that all subdomains, including subdomains of subdomains, of \"x.example\" use the mail exchanger (MX) \"a.x.example\". The A record for \"a.x.example\" is needed to specify the mail exchanger IP address. As this has the result of excluding this domain name and its subdomains from the wildcard matches, an additional MX record for the subdomain \"a.x.example\", as well as a wildcarded MX record for all of its subdomains, must also be defined in the DNS zone.\n\nThe role of wildcard records was refined in RFC 4592, because the original definition in RFC 1034 was incomplete and resulted in misinterpretations by implementers.\n\nThe original DNS protocol had limited provisions for extension with new features. In 1999, Paul Vixie published in RFC 2671 an extension mechanism, called Extension mechanisms for DNS (EDNS) that introduced optional protocol elements without increasing overhead when not in use. This was accomplished through the OPT pseudo-resource record that only exists in wire transmissions of the protocol, but not in any zone files. Initial extensions were also suggested (EDNS0), such as increasing the DNS message size in UDP datagrams.\n\nDynamic DNS updates use the UPDATE DNS opcode to add or remove resource records dynamically from a zone database maintained on an authoritative DNS server. The feature is described in RFC 2136. This facility is useful to register network clients into the DNS when they boot or become otherwise available on the network. Since a booting client may be assigned a different IP address each time from a DHCP server, it is not possible to provide static DNS assignments for such clients.\n\nOriginally, security concerns were not major design considerations for DNS software or any software for deployment on the early Internet, as the network was not open for participation by the general public. However, the expansion of the Internet into the commercial sector in the 1990s changed the requirements for security measures to protect data integrity and user authentication.\n\nSeveral vulnerability issues were discovered and exploited by malicious users. One such issue is DNS cache poisoning, in which data is distributed to caching resolvers under the pretense of being an authoritative origin server, thereby polluting the data store with potentially false information and long expiration times (time-to-live). Subsequently, legitimate application requests may be redirected to network hosts operated with malicious intent.\n\nDNS responses traditionally do not have a cryptographic signature, leading to many attack possibilities; the Domain Name System Security Extensions (DNSSEC) modify DNS to add support for cryptographically signed responses. DNSCurve has been proposed as an alternative to DNSSEC. Other extensions, such as TSIG, add support for cryptographic authentication between trusted peers and are commonly used to authorize zone transfer or dynamic update operations.\n\nSome domain names may be used to achieve spoofing effects. For example, and paypa1.com are different names, yet users may be unable to distinguish them in a graphical user interface depending on the user's chosen typeface. In many fonts the letter \"l\" and the numeral \"1\" look very similar or even identical. This problem is acute in systems that support internationalized domain names, since many character codes in ISO 10646 may appear identical on typical computer screens. This vulnerability is occasionally exploited in phishing.\n\nTechniques such as forward-confirmed reverse DNS can also be used to help validate DNS results.\n\nThe right to use a domain name is delegated by domain name registrars which are accredited by the Internet Corporation for Assigned Names and Numbers (ICANN) or other organizations such as OpenNIC, that are charged with overseeing the name and number systems of the Internet. In addition to ICANN, each top-level domain (TLD) is maintained and serviced technically by an administrative organization, operating a registry. A \"registry\" is responsible for operating the database of names within its authoritative zone, although the term is most often used for TLDs. A \"registrant\" is a person or organization who asked for domain registration. The registry receives registration information from each domain name \"registrar\", which is authorized (accredited) to assign names in the corresponding zone and publishes the information using the WHOIS protocol. As of 2015, usage of RDAP is being considered.\n\nICANN publishes the complete list of TLDs, TLD registries, and domain name registrars. Registrant information associated with domain names is maintained in an online database accessible with the WHOIS service. For most of the more than 290 country code top-level domains (ccTLDs), the domain registries maintain the WHOIS (Registrant, name servers, expiration dates, etc.) information. For instance, DENIC, Germany NIC, holds the DE domain data. Since about 2001, most Generic top-level domain (gTLD) registries have adopted this so-called \"thick\" registry approach, i.e. keeping the WHOIS data in central registries instead of registrar databases.\n\nFor COM and NET domain names, a \"thin\" registry model is used. The domain registry (e.g., VeriSign) holds basic WHOIS data (i.e., registrar and name servers, etc.) One can find the detailed WHOIS (registrant, name servers, expiry dates, etc.) at the registrars.\n\nSome domain name registries, often called \"network information centers\" (NIC), also function as registrars to end-users. The major generic top-level domain registries, such as for the domains COM, NET, ORG, INFO, use a registry-registrar model consisting of many domain name registrars. In this method of management, the registry only manages the domain name database and the relationship with the registrars. The \"registrants\" (users of a domain name) are customers of the registrar, in some cases through additional layers of resellers.\n\nThe Domain Name System is defined by Request for Comments (RFC) documents published by the Internet Engineering Task Force (Internet standards). The following is a list of RFCs that define the DNS protocol.\n\n\n\n\n\nThese RFCs are advisory in nature, but may provide useful information despite defining neither a standard or BCP. (RFC 1796)\n\n\nThese RFCs have an official status of Unknown, but due to their age are not clearly labeled as such.\n\n\n"}
{"id": "8340", "url": "https://en.wikipedia.org/wiki?curid=8340", "title": "David Letterman", "text": "David Letterman\n\nDavid Michael Letterman (born April 12, 1947) is an American television host, comedian, writer, and producer. He hosted a late night television talk show for 33 years, beginning with the February 1, 1982 debut of \"Late Night with David Letterman\" on NBC, and ending with the May 20, 2015 broadcast of \"Late Show with David Letterman\" on CBS. In total, Letterman hosted 6,028 episodes of \"Late Night\" and \"Late Show\", surpassing friend and mentor Johnny Carson as the longest-serving late night talk show host in American television history. In 1996 Letterman was ranked 45th on \"TV Guide\"s 50 Greatest TV Stars of All Time.\n\nLetterman is also a television and film producer. His company, Worldwide Pants, produced his show as well as \"The Late Late Show with Craig Ferguson\" and several prime-time comedies, the most successful of which was \"Everybody Loves Raymond\", now in syndication.\n\nSeveral late-night hosts have cited Letterman's influence, including Conan O'Brien (his successor on \"Late Night\"), Stephen Colbert (his successor on \"The Late Show\"), Jimmy Fallon, Jimmy Kimmel and Seth Meyers.\n\nLetterman was born in Indianapolis, Indiana. His father, Harry Joseph Letterman (April 15, 1915 – February 13, 1973), was a florist. His mother, Dorothy Marie Mengering (née Hofert; July 18, 1921 – April 11, 2017), a church secretary, was an occasional figure on Letterman's show, usually at holidays and birthdays.\n\nHe lived on the north side of Indianapolis (Broad Ripple area), not far from Speedway, Indiana, and the Indianapolis Motor Speedway; and he enjoyed collecting model cars, including racers. In 2000, he told an interviewer for \"Esquire\" that, while growing up, he admired his father's ability to tell jokes and be the life of the party. Harry Joseph Letterman survived a heart attack at age 36, when David was a young boy. The fear of losing his father was constantly with Letterman as he grew up. The elder Letterman died of a second heart attack at age 57.\n\nLetterman attended his hometown's Broad Ripple High School at the same time as Marilyn Tucker (future wife of Dan Quayle) and worked as a stock boy at the local Atlas Supermarket. According to the \"Ball State Daily News\", he originally had wanted to attend Indiana University, but his grades were not good enough, so he instead attended Ball State University, in Muncie, Indiana. He is a member of the Sigma Chi fraternity, and he graduated in 1969 from what was then the Department of Radio and Television. A self-described average student, Letterman later endowed a scholarship for what he called \"C students\" at Ball State.\n\nThough he registered for the draft and passed his physical after graduating from college, he was not drafted for service in Vietnam because of receiving a draft lottery number of 346 (out of 366).\n\nLetterman began his broadcasting career as an announcer and newscaster at the college's student-run radio station—WBST—a 10-watt campus station which now is part of Indiana Public Radio. He was fired for treating classical music with irreverence. He then became involved with the founding of another campus station—WAGO-AM 570 (now WWHI, 91.3).\n\nHe credits Paul Dixon, host of the \"Paul Dixon Show\", a Cincinnati-based talk show also shown in Indianapolis while he was growing up, for inspiring his choice of career:\nI was just out of college [in 1969], and I really didn't know what I wanted to do. And then all of a sudden I saw him doing it [on TV]. And I thought: That's really what I want to do!\n\nLetterman began his career as a radio talk show host on WNTS (AM) and on Indianapolis television station WLWI (which changed its call sign to WTHR in 1976) as an anchor, and weatherman. He received some attention for his unpredictable on-air behavior, which included congratulating a tropical storm for being upgraded to a hurricane and predicting hail stones \"the size of canned hams.\" He would also occasionally report the weather and the day's very high and low temps for fictitious cities (\"Eight inches of snow in Bingree and surrounding areas\") while on another occasion saying that a state border had been erased when a satellite map accidentally omitted the state border between Indiana and Ohio, attributing it to dirty political dealings. (\"The higher-ups have removed the border between Indiana and Ohio making it one giant state. Personally, I'm against it. I don't know what to do about it.\") He also starred in a local kiddie show, made wisecracks as host of a late night TV show called \"Freeze-Dried Movies\" (he once acted out a scene from \"Godzilla\" using plastic dinosaurs), and hosted a talk show that aired early on Saturday mornings called \"Clover Power\", in which he interviewed 4-H members about their projects.\n\nIn 1971 Letterman appeared as a pit road reporter for ABC Sports' tape-delayed coverage of the Indianapolis 500. Letterman was initially introduced as Chris Economaki, although this was corrected at the end of the interview. Letterman interviewed Mario Andretti, who had just crashed out of the race.\n\nIn 1975, encouraged by his then-wife Michelle and several of his Sigma Chi fraternity brothers, Letterman moved to Los Angeles, California, with hope of becoming a comedy writer. He and Michelle packed their belongings in his pickup truck and headed west. As of 2012, he still owned the truck. In Los Angeles, he began performing comedy at The Comedy Store. Jimmie Walker saw him on stage; with an endorsement from George Miller, Letterman joined a group of comedians whom Walker hired to write jokes for his stand-up act, a group that at various times would also include Jay Leno, Paul Mooney, Robert Schimmel, Richard Jeni, Louie Anderson, Elayne Boosler, Byron Allen, Jack Handey, and Steve Oedekerk.\n\nBy the summer of 1977, Letterman was a writer and regular on the six-week summer series \"The Starland Vocal Band Show\", broadcast on CBS. He hosted a 1977 pilot for a game show entitled \"The Riddlers\" (that was never picked up), and co-starred in the Barry Levinson-produced comedy special \"Peeping Times\" that aired in January 1978. Later that year, Letterman was a cast member on Mary Tyler Moore's variety show, \"Mary\". Letterman made a guest appearance on \"Mork & Mindy\" (as a parody of EST leader Werner Erhard) and appearances on game shows such as \"The $20,000 Pyramid\", \"The Gong Show\", \"Hollywood Squares\", \"Password Plus\" and \"Liar's Club\", as well as the Canadian cooking show \"Celebrity Cooks\" (November 1977), talk shows such as \"90 Minutes Live\" (February 24 and April 14, 1978), and \"The Mike Douglas Show\" (April 3, 1979 and February 7, 1980). He was also screen tested for the lead role in the 1980 film \"Airplane!\", a role that eventually went to Robert Hays.\n\nHis dry, sarcastic humor caught the attention of scouts for \"The Tonight Show Starring Johnny Carson\", and Letterman was soon a regular guest on the show. Letterman became a favorite of Carson and was a regular guest host for the show beginning in 1978. Letterman credits Carson as the person who influenced his career the most.\n\nOn June 23, 1980, Letterman was given his own morning comedy show on NBC, \"The David Letterman Show\". It was originally 90 minutes long, but was shortened to 60 minutes in August 1980. The show was a critical success, winning two Emmy Awards, but was a ratings disappointment and was canceled in October 1980.\n\nNBC kept Letterman under contract to try him in a different time slot. \"Late Night with David Letterman\" debuted February 1, 1982; the first guest on the first show was Bill Murray. Murray later went on to become one of Letterman's most recurrent guests, guesting on the show's 30th anniversary episode, which aired January 31, 2012 and on the very last show, which aired May 20, 2015. The show ran Monday through Thursday at 12:30 a.m. Eastern Time, immediately following \"The Tonight Show Starring Johnny Carson\" (a Friday night broadcast was added in June 1987). It was seen as being edgy and unpredictable, and soon developed a cult following (particularly among college students). Letterman's reputation as an acerbic interviewer was borne out in verbal sparring matches with Cher (who even called him an asshole on the show), Shirley MacLaine, Charles Grodin, and Madonna. The show also featured comedy segments and running characters, in a style heavily influenced by the 1950s and 1960s programs of Steve Allen. Although Ernie Kovacs is often cited as an influence on the show, Letterman has denied this.\n\nThe show often featured quirky, genre-mocking regular features, including \"Stupid Pet Tricks\" (which had its origins on Letterman's morning show), Stupid Human Tricks, dropping various objects off the roof of a five-story building, demonstrations of unorthodox clothing (such as suits made of Alka-Seltzer, Velcro and suet), a recurring Top 10 list, the Monkey-Cam (and the Audience Cam), a facetious letter-answering segment, several \"Film[s] by My Dog Bob\" in which a camera was mounted on Letterman's own dog (often with comic results) and Small Town News, all of which would eventually move with Letterman to CBS.\n\nOther memorable moments included Letterman using a bullhorn to interrupt a live interview on \"The Today Show\", announcing that he was the NBC News president and that he was not wearing any pants; walking across the hall to Studio 6B, at the time the news studio for WNBC-TV, and interrupting Al Roker's weather segments during \"Live at Five\"; and staging \"elevator races\", complete with commentary by NBC Sports' Bob Costas. In one infamous appearance, in 1982, Andy Kaufman (who was already wearing a neck brace) appeared with professional wrestler Jerry Lawler, who slapped and knocked the comedian to the ground (though Lawler and Kaufman's friend Bob Zmuda later revealed that the event was staged).\n\nIn 1992, Johnny Carson retired, and many fans believed that Letterman would become host of \"The Tonight Show\". When NBC instead gave the job to Jay Leno, Letterman departed NBC to host his own late-night show on CBS, opposite \"The Tonight Show\" at 11:30 p.m., called the \"Late Show with David Letterman\". The new show debuted on August 30, 1993, and was taped at the historic Ed Sullivan Theater, where Ed Sullivan broadcast his eponymous variety series from 1948 to 1971. For Letterman's arrival, CBS spent  million in renovations. In addition to that cost, CBS also signed Letterman to a lucrative three-year,  million/year contract, doubling his \"Late Night\" salary. The total cost for everything (renovations, negotiation right paid to NBC, signing Letterman, announcer Bill Wendell, Shaffer, the writers and the band) was over  million.\n\nBut while the expectation was that Letterman would retain his unique style and sense of humor with the move, \"Late Show\" was not an exact replica of his old NBC program. Recognizing the more formal mood (and wider audience) of his new time slot and studio, Letterman eschewed his trademark blazer with khaki pants and white wrestling shoes wardrobe combination in favor of expensive shoes, tailored suits and light-colored socks. The monologue was lengthened. Paul Shaffer and the \"World's Most Dangerous Band\" followed Letterman to CBS, but they added a brass section and were rebranded the \"CBS Orchestra\" as a short monologue and a small band were mandated by Carson while Letterman occupied the 12:30 slot. Additionally, because of intellectual property disagreements, Letterman was unable to import many of his \"Late Night\" segments verbatim, but he sidestepped this problem by simply renaming them (the \"Top Ten List\" became the \"Late Show Top Ten\", \"Viewer Mail\" became the \"CBS Mailbag\", etc.) \"Time\" magazine stated that \"Letterman's innovation ... gained power from its rigorous formalism\", as his biographer Jason Zinoman puts it, he was \"a fascinatingly disgruntled eccentric trapped inside a more traditional talk show.\"\n\nThe main competitor of the \"Late Show\" was NBC's \"The Tonight Show\", which was hosted by Jay Leno for 22 years, but from June 1, 2009, to January 22, 2010, was hosted by Conan O'Brien. In 1993 and 1994, the \"Late Show\" consistently gained higher ratings than \"The Tonight Show\". But in 1995, ratings dipped and Leno's show consistently beat Letterman's in the ratings from the time that Hugh Grant came on Leno's show after Grant's arrest for soliciting a prostitute; Leno typically attracted about five million nightly viewers between 1999 and 2009. The \"Late Show\" lost nearly half its audience during its competition with Leno, attracting 7.1 million viewers nightly in its 1993–94 season and about 3.8 million per night as of Leno's departure in 2009. In the final months of his first stint as host of \"The Tonight Show\", Leno beat Letterman in the ratings by a 1.3 million viewer margin (5.2 million to 3.9 million), and \"Nightline\" and the \"Late Show\" were virtually tied. Once O'Brien took over \"Tonight\", however, Letterman closed the gap in the ratings. O'Brien initially drove the median age of \"Tonight Show\" viewers from 55 to 45, with most older viewers opting to watch the \"Late Show\" instead.\n\nFollowing Leno's return to \"The Tonight Show\", however, Leno regained his lead.\n\nLetterman's shows have garnered both critical and industry praise, receiving 67 Emmy Award nominations, winning 12 times in his first 20 years in late night television. From 1993 to 2009, Letterman ranked higher than Leno in the annual Harris Poll of \"Nation's Favorite TV Personality\" 12 times. For example, in 2003 and 2004 Letterman ranked second in that poll, behind only Oprah Winfrey, a year that Leno was ranked fifth. Leno was higher than Letterman on that poll three times during the same period, in 1998, 2007, and 2008.\n\nOn March 27, 1995, Letterman acted as the host for the 67th Academy Awards ceremony. Critics blasted Letterman for what they deemed a poor hosting of the Oscars, noting that his irreverent style undermined the traditional importance and glamor of the event. In a joke about their unusual names (inspired by a celebrated comic essay in \"The New Yorker\", \"Yma Dream\" by Thomas Meehan), he started off by introducing Uma Thurman to Oprah Winfrey, and then both of them to Keanu Reeves: \"Oprah...Uma. Uma...Oprah,\" \"Have you kids met Keanu?\" This and many of his other jokes fell flat. Although Letterman attracted the highest ratings to the annual telecast since 1983, many felt that the bad publicity garnered by Letterman's hosting caused a decline in the \"Late Show\"'s ratings.\n\nLetterman recycled the apparent debacle into a long-running gag. On his first show after the Oscars, he joked, \"Looking back, I had no idea that thing was being televised.\" He lampooned his stint two years later, during Billy Crystal's opening Oscar skit, which also parodied the plane-crashing scenes from that year's chief nominated film, \"The English Patient\".\n\nFor years afterward, Letterman recounted his hosting the Oscars, although the Academy of Motion Picture Arts and Sciences continued to hold Letterman in high regard and they had invited him to host the Oscars again. On September 7, 2010, he made an appearance on the premiere of the 14th season of \"The View\", and confirmed that he had been considered for hosting again.\n\nOn January 14, 2000, a routine check-up revealed that an artery in Letterman's heart was severely obstructed. He was rushed to emergency surgery for a quintuple bypass.\n\nDuring the initial weeks of his recovery, reruns of the \"Late Show\" were shown and introduced by friends of Letterman including Drew Barrymore, Ray Romano, Robin Williams, Bonnie Hunt, Megan Mullally, Bill Murray, Regis Philbin, Charles Grodin, Nathan Lane, Julia Roberts, Bruce Willis, Jerry Seinfeld, Martin Short, Steven Seagal, Hillary Clinton, Danny DeVito, Steve Martin, and Sarah Jessica Parker.\n\nSubsequently, while still recovering from surgery, Letterman revived the late night tradition that had virtually disappeared on network television during the 1990s of 'guest hosts' by allowing Bill Cosby, Kathie Lee Gifford, Dana Carvey, Janeane Garofalo, and others to host new episodes of the \"Late Show\".\n\nUpon his return to the show on February 21, 2000, Letterman brought all but one of the doctors and nurses on stage who had participated in his surgery and recovery (with extra teasing of a nurse who had given him bed baths—\"This woman has seen me naked!\"), including Dr. O. Wayne Isom and physician Louis Aronne, who frequently appears on the show. In a show of emotion, Letterman was nearly in tears as he thanked the health care team with the words \"These are the people who saved my life!\" The episode earned an Emmy nomination. For a number of episodes, Letterman continued to crack jokes about his bypass, including saying, \"Bypass surgery: it's when doctors surgically create new blood flow to your heart. A bypass is what happened to me when I didn't get \"The Tonight Show!\" It's a whole different thing.\" In a later running gag he lobbied his home state of Indiana to rename the freeway circling Indianapolis (I-465) \"The David Letterman Bypass.\" He also featured a montage of faux news coverage of his bypass surgery, which included a clip of Letterman's heart for sale on the Home Shopping Network. Letterman became friends with his doctors and nurses. In 2008, a \"Rolling Stone\" interview stated he hosted a doctor and nurse who'd helped perform the emergency quintuple-bypass heart surgery that saved his life in 2000. 'These are people who were complete strangers when they opened my chest,' he says. 'And now, eight years later, they're among my best friends.'\n\nAdditionally, Letterman invited the band Foo Fighters to play \"Everlong\", introducing them as \"my favorite band, playing my favorite song.\" During a later Foo Fighters appearance, Letterman said that Foo Fighters had been in the middle of a South American tour which they canceled to come play on his comeback episode.\n\nLetterman again handed over the reins of the show to several guest hosts (including Bill Cosby, Brad Garrett, Whoopi Goldberg, Elvis Costello, John McEnroe, Vince Vaughn, Will Ferrell, Bonnie Hunt, Luke Wilson and bandleader Paul Shaffer) in February 2003, when he was diagnosed with a severe case of shingles. Later that year, Letterman made regular use of guest hosts—including Tom Arnold and Kelsey Grammer—for new shows broadcast on Fridays. In March 2007, Adam Sandler—who had been scheduled to be the lead guest—served as a guest host while Letterman was ill with a stomach virus.\n\nIn March 2002, as Letterman's contract with CBS neared expiration, ABC offered him the time slot for long-running news program \"Nightline\" with Ted Koppel. Letterman was interested as he believed he could never match Leno's ratings at CBS due to Letterman's complaint of weaker lead-ins from the network's late local news programs, but was reluctant to replace Koppel. Letterman addressed his decision to re-sign on the air, stating that he was content at CBS and that he had great respect for Koppel.\nOn December 4, 2006, CBS revealed that Letterman signed a new contract to host \"Late Show with David Letterman\" through the fall of 2010. \"I'm thrilled to be continuing on at CBS,\" said Letterman. \"At my age you really don't want to have to learn a new commute.\" Letterman further joked about the subject by pulling up his right pants leg, revealing a tattoo, presumably temporary, of the ABC logo.\n\n\"Thirteen years ago, David Letterman put CBS late night on the map and in the process became one of the defining icons of our network,\" said Leslie Moonves, president and CEO of CBS Corporation. His presence on our air is an ongoing source of pride, and the creativity and imagination that the \"Late Show\" puts forth every night is an ongoing display of the highest quality entertainment. We are truly honored that one of the most revered and talented entertainers of our time will continue to call CBS 'home.'\n\nAccording to a 2007 article in \"Forbes\" magazine, Letterman earned  million a year. A 2009 article in \"The New York Times\", however, said his salary was estimated at  million per year. In June 2009, Letterman's Worldwide Pants and CBS reached agreement to continue the \"Late Show\" until at least August 2012. The previous contract had been set to expire in 2010, and the two-year extension is shorter than the typical three-year contract period negotiated in the past. Worldwide Pants agreed to lower its fee for the show, though it had remained a \"solid moneymaker for CBS\" under the previous contract.\nOn the February 3, 2011, edition of the \"Late Show\", during an interview with Howard Stern, Letterman said he would continue to do his talk show for \"maybe two years, I think.\"\n\nIn April 2012, CBS announced it had extended its contract with Letterman through 2014. His contract was subsequently extended to 2015.\n\nDuring the taping of his April 3, 2014, show, Letterman announced that he had informed CBS president Leslie Moonves that he would retire from hosting \"Late Show\" by May 20, 2015. It was announced soon after that comedian and political satirist Stephen Colbert would succeed Letterman. Letterman's last episode aired on May 20, 2015, and opened with a presidential send off featuring the four of the five living American presidents, George H. W. Bush, Bill Clinton, George W. Bush and Barack Obama, each mimicking the late president Gerald Ford's statement that \"Our long national nightmare is over.\" It also featured cameos from \"The Simpsons\" and \"Wheel of Fortune\" (the latter with a puzzle saying \"Good riddance to David Letterman\"), a Top Ten List of \"things I wish I could have said to David Letterman\" performed by regular guests including Alec Baldwin, Barbara Walters, Steve Martin, Jerry Seinfeld, Jim Carrey, Chris Rock, Julia Louis-Dreyfus, Peyton Manning, Tina Fey, and Bill Murray, and closed with a montage of scenes from both his CBS and NBC series set to a live performance of \"Everlong\" by Foo Fighters.\n\nThe final episode of \"Late Show with David Letterman\" was watched by 13.76 million viewers in the United States with an audience share of 9.3/24, earning the show its highest ratings since following the 1994 Olympics on February 25, 1994, and the show's highest demo numbers (4.1 in adults 25-54 and 3.1 in adults 18-49) since Oprah Winfrey's first \"Late Show\" appearance following the ending of her feud with Letterman on December 1, 2005. In a rarity for a late-night show, it was also the highest-rated program on network television that night, beating out all prime-time shows. In total, Letterman hosted 6,028 episodes of \"Late Night\" and \"Late Show\", surpassing friend and mentor Johnny Carson as the longest-serving late night talk show host in American television history.\n\nIn the months following the end of \"Late Show\" Letterman has been seen occasionally at sports events such as the Indianapolis 500, during which he submitted to an interview with a local publication. He made a surprise appearance on stage in San Antonio, Texas when he was invited up for an extended segment during Steve Martin and Martin Short's \"A Very Stupid Conversation\" show saying \"I retired, and...I have no regrets,\" Letterman told the crowd after walking on stage. \"I was happy. I'll make actual friends. I was complacent. I was satisfied. I was content, and then a couple of days ago Donald Trump said he was running for president. I have made the biggest mistake of my life, ladies and gentlemen\" and then delivering a Top Ten List roasting Donald Trump's presidential campaign followed by an on-stage conversation with Martin and Short. Cell phone recordings of the appearance were posted on YouTube by audience members and were widely reported in the media.\n\nIn 2016, Letterman joined the climate change documentary show \"Years of Living Dangerously\" as one of the show's celebrity correspondents. In season two's premiere episode, Letterman traveled to India to investigate the country's efforts to expand its inadequate energy grid, power its booming economy and bring electricity for the first time to 300 million citizens. He also interviewed Indian Prime Minister Narendra Modi, and traveled to rural villages where power is a scarce luxury and explored the United States role in India's energy future.\n\nIn 2017, Letterman and Alec Baldwin co-hosted \"The Essentials\" on Turner Classic Movies. Letterman and Baldwin introduced seven films for the series\n\nLetterman has announced that in 2018 he will be hosting a six-episode series of hour-long programs on Netflix consisting of long-form interviews and field segments.\n\nIn spite of Johnny Carson's clear intention to pass his title to Letterman, NBC selected Jay Leno to host \"The Tonight Show\" after Carson's departure. Letterman maintained a close relationship with Carson through his break with NBC. Three years after he left for CBS, HBO produced a made-for-television movie called \"The Late Shift\", based on a book by \"The New York Times\" reporter Bill Carter, chronicling the battle between Letterman and Leno for the coveted \"Tonight Show\" hosting spot.\n\nCarson later made a few cameo appearances as a guest on Letterman's show. Carson's final television appearance came May 13, 1994, on a \"Late Show\" episode taped in Los Angeles, when he made a surprise appearance during a 'Top 10 list' segment. In early 2005, it was revealed that Carson occasionally sent jokes to Letterman, who used these jokes in his monologue; according to CBS senior vice president Peter Lassally (a one-time producer for both men), Carson got \"a big kick out of it.\" Letterman would do a characteristic Johnny Carson golf swing after delivering one of Carson's jokes. In a tribute to Carson, all of the opening monologue jokes during the first show following Carson's death were written by Carson.\n\nLassally also claimed that Carson had always believed Letterman, not Leno, to be his \"rightful successor.\" During the early years of the \"Late Show\"s run, Letterman occasionally used some of Carson's trademark bits, including \"Carnac the Magnificent\" (with Paul Shaffer as Carnac), \"Stump the Band\", and the \"Week in Review.\"\n\nOprah Winfrey appeared on Letterman's show when he was hosting NBC's \"Late Night\" on May 2, 1989. Following that appearance, the two had a 16-year feud which arose, as Winfrey explained to Letterman after the feud had been resolved, as a result of the acerbic tone of their 1989 interview of which she said that it \"felt so uncomfortable to me that I didn't want to have that experience again\".\n\nThe feud apparently ended in 2005 when Winfrey appeared on CBS's \"Late Show with David Letterman\" on December 2, in an event Letterman jokingly referred to as \"the Super Bowl of Love\".\n\nWinfrey and Letterman also appeared together in a \"Late Show\" promo that aired during CBS's coverage of Super Bowl XLI in February 2007, with the two sitting next to each other on the couch watching the game. Since the game was played between the Indianapolis Colts and Chicago Bears, the Indianapolis-born Letterman wears a Peyton Manning jersey, while Winfrey—whose show was taped in Chicago—wears a Brian Urlacher jersey. On September 10, 2007, Letterman made his first appearance on \"The Oprah Winfrey Show\" at Madison Square Garden in New York City.\n\nThree years later, during CBS's coverage of Super Bowl XLIV, the two appeared again in a \"Late Show\" promo, this time with Winfrey sitting on a couch between Letterman and Jay Leno. This time Letterman was wearing the retired 70 jersey of Colts' Hall of Fame and Letterman regular guest, Art Donovan (the Colts faced the New Orleans Saints in this Super Bowl). The appearance was Letterman's idea: Leno flew to New York City on an NBC corporate jet, sneaking into the Ed Sullivan Theater during the \"Late Show\"'s February 4 taping wearing a disguise, meeting Winfrey and Letterman at a living room set created in the theater's balcony where they taped their promo.\n\nWinfrey interviewed Letterman in January 2013 on \"Oprah's Next Chapter\". Winfrey and Letterman discussed their feud during the interview and Winfrey revealed that she had had a \"terrible experience\" while appearing on Letterman's show years earlier. Letterman could not recall the incident but apologized.\n\n\"Late Show\" went off air for eight weeks during the months of November and December because of the Writers Guild of America strike. Letterman's production company, Worldwide Pants, was the first company to make an individual agreement with the WGA, thus allowing his show to come back on air on January 2, 2008. On his first episode since being off air, he surprised the viewing audience with his newly grown beard, which signified solidarity with the strike. His beard was shaved off during the show on January 7, 2008.\n\nOn June 8 and 9, 2009, Letterman told two sexually themed jokes about a daughter (never named) of Sarah Palin on his TV show. Palin was in New York City at the time with her then fourteen-year-old daughter, Willow, and some contemporaries thought the jokes to be aimed at Willow, which caused some small amount of controversy. In a statement posted on the Internet, Palin said, \"I doubt [Letterman would] ever dare make such comments about anyone else's daughter,\" and that \"laughter incited by sexually perverted comments made by a 62-year-old male celebrity aimed at a 14-year-old girl is disgusting.\" On his show of June 10, Letterman responded to the controversy, saying the jokes were meant to be about Palin's eighteen-year-old daughter, Bristol, whose pregnancy as an unmarried teenager had caused some controversy during the United States presidential election of 2008. \"These are not jokes made about (Palin's) 14-year-old daughter,\" he said. \"I would never, never make jokes about raping or having sex of any description with a 14-year-old girl.\" His remarks did not put an end to public criticism, however. The National Organization for Women released a statement supporting Palin, noting that Letterman had given \"[only] something of an apology.\" When the controversy failed to subside, Letterman addressed the issue again on his show of June 15, faulting himself for the error and apologizing \"especially to the two daughters involved, Bristol and Willow, and also to the governor and her family and everybody else who was outraged by the joke.\"\n\nOn August 17, 2011, it was reported that an Islamist militant had posted a death threat against Letterman on a website frequented by Al-Qaeda supporters, calling on American Muslims to kill Letterman for making a joke about the death of an Al-Qaeda leader killed in a drone strike in Pakistan in June 2011, Ilyas Kashmiri. In his show on August 22, Letterman joked about the threat, saying \"State Department authorities are looking into this. They're not taking this lightly. They're looking into it. They're questioning, they're interrogating, there's an electronic trail—but everybody knows it's Leno.\"\n\nLetterman appeared in issue 239 of the Marvel comic book \"The Avengers\", in which the title characters are guests on \"Late Night\". A parody of Letterman, named \"David Endochrine\", is gassed to death along with his bandleader named \"Paul\" and their audience in Frank Miller's \"The Dark Knight Returns\".\n\nLetterman appeared in the pilot episode of the short-lived 1986 series \"Coach Toast\", and he appears with a bag over his head as a guest on Bonnie Hunt's ca. 1993 sitcom \"The Building\". He also appears in \"The Simpsons\" as himself in a couch gag when the Simpsons find themselves (and the couch) in \"Late Night with David Letterman\". He had a cameo in the feature film \"Cabin Boy\", with Chris Elliott, who worked as a writer on Letterman's show. In this and other appearances, Letterman is listed in the credits as \"Earl Hofert\", the name of Letterman's maternal grandfather. He also appeared as himself in the Howard Stern biographical film \"Private Parts\" as well as the 1999 Andy Kaufman biopic \"Man on the Moon\", in a few episodes of Garry Shandling's 1990s TV series \"The Larry Sanders Show\" and in \"The Abstinence\", a 1996 episode of the sitcom \"Seinfeld\".\n\nLetterman provided vocals for the Warren Zevon song \"Hit Somebody\" from \"My Ride's Here\", and provided the voice for Butt-head's father in the 1996 animated film \"Beavis and Butt-Head Do America\", once again credited as Earl Hofert.\n\nIn 2010, a documentary \"Dying to do Letterman\" was released directed by Joke Fincioen and Biagio Messina featuring Steve Mazan, a stand up comic, who has cancer and wants to appear on the Letterman show. The film won best documentary and jury awards at the Cinequest Film Festival. Steve Mazan published a same-titled book (full title, \"Dying to Do Letterman: Turning Someday into Today\") about his own saga.\n\nLetterman appeared as a guest on CNN's \"Piers Morgan Tonight\" on May 29, 2012, when he was interviewed by Regis Philbin, the guest host and long-time friend. Philbin again interviewed Letterman (and Shaffer) while guest-hosting CBS' \"The Late Late Show\" (between the tenures of Craig Ferguson and James Corden) on January 27, 2015.\n\nIn June 2013, he appeared in the second episode of season two of \"Comedians in Cars Getting Coffee\".\n\nOn November 5, 2013, Letterman and Bruce McCall published a fiction satire book titled \"This Land Was Made for You and Me (But Mostly Me)\". \n\nLetterman started his production company—Worldwide Pants Incorporated—which produced his show and several others, including \"Everybody Loves Raymond\"; \"The Late Late Show\" and two television series for Bonnie Hunt. Worldwide Pants also produced the dramedy program \"Ed\" which aired on NBC from 2000–2004. It was Letterman's first association with NBC since he left the network in 1993. During the run of \"Ed,\" the star, Tom Cavanagh, appeared as a guest on the \"Late Show\" several times.\n\nIn 2005, Worldwide Pants produced its first feature film, \"Strangers with Candy\", which was a prequel to the Comedy Central TV series of the same title. In 2007, Worldwide Pants produced the ABC comedy series, \"Knights of Prosperity.\"\n\nWorldwide Pants made significant news in December 2007 when it was announced that Letterman's company had independently negotiated its own contract with the Writers Guild of America, East, thus allowing Letterman, Craig Ferguson, and their writers to return to work, while the union continued its strike against production companies, networks and studios who had not reached an agreement.\n\nIn late April 2010, several music industry websites reported that Letterman started a record label named Clear Entertainment/C.E. Music and signed his first artist, Runner Runner. Lucy Walsh announced on her MySpace page that she has been signed by Letterman and Clear Entertainment/C.E. Music and is working on her album.\n\nRahal Letterman Lanigan Racing (RLLR) is an auto racing team that currently races in the United SportsCar Championship (formerly the American Le Mans Series), and full-time in the Verizon IndyCar Series. It is co-owned by 1986 Indianapolis 500 winner Bobby Rahal, businessman Mike Lanigan, and Letterman himself, and is based in Hilliard, Ohio. The team won the 2004 Indianapolis 500 with driver Buddy Rice.\n\nThe Letterman Foundation for Courtesy and Grooming is a private foundation through which Letterman has donated millions of dollars to charities and other non-profits in Indiana and Montana, celebrity-affiliated organizations such as Paul Newman's Hole in the Wall Gang Camp, universities such as Ball State, and other organizations such as the American Cancer Society, Salvation Army, and Doctors Without Borders.\n\nLetterman's biggest influence and his mentor was Johnny Carson. Other comedians that influenced Letterman were Paul Dixon, Steve Allen, Jonathan Winters, Garry Moore, Ernie Kovacs, Jack Paar, Don Rickles, and David Brenner.\n\nComedians that were influenced by Letterman include: Stephen Colbert, Ray Romano, Jimmy Kimmel, Jay Leno, Conan O'Brien, Jon Stewart, Larry Wilmore, Seth Meyers, Jimmy Fallon, John Oliver, and James Corden.\n\nIn 2015, Forbes estimated that Letterman's annual income was $35 million.\n\nOn July 2, 1968, Letterman married his college sweetheart Michelle Cook (born July 2, 1946) in Muncie, Indiana; the marriage ended in divorce by October 1977. He also had a long-term relationship and lived with former head writer and producer on \"Late Night\", Merrill Markoe (born August 13, 1948) from 1978 to 1988. Markoe was the mind behind several \"Late Night\" staples, such as \"Stupid Pet/Human Tricks\". \"Time\" magazine states that she was the defining relationship in Letterman's career as his writing partner \"who put the surrealism in Letterman's comedy.\"\n\nLetterman and Regina Lasko (born November 20, 1960) started dating in February 1986, while he was still living with Markoe. He has a son, Harry Joseph Letterman (born November 3, 2003), with her. Harry is named after Letterman's father. In 2005, police discovered a plot to kidnap Harry Letterman and ransom him for  million. Kelly Frank, a house painter who had worked for Letterman, was charged in the conspiracy.\n\nLetterman and Lasko wed on March 19, 2009, during a quiet courthouse civil ceremony in Choteau, Montana, where he purchased a ranch in 1999. Letterman announced the marriage during the taping of his show of March 23, shortly after congratulating Bruce Willis for getting married the previous week. Letterman told the audience he nearly missed the ceremony because his truck became stuck in mud two miles from their house. The family resides in North Salem, New York, on a 108-acre estate.\n\nLetterman suffers from tinnitus (ringing in the ears), which is a symptom of hearing loss. On the \"Late Show\" in 1996, Letterman talked about his tinnitus in an interview he did with actor William Shatner, who has severe tinnitus himself, caused from an on-set explosion. Letterman said at first he could not figure out where the noise in his head was coming from and that he hears constant noises and ringing in his ears 24 hours a day.\n\nLetterman no longer drinks alcohol and has on more than one occasion said that he had once been a \"horrible alcoholic\" and had begun drinking around the age of 13 until the age of 34, in 1981: \"I was drunk 80% of the time. ... I loved it. I was one of those guys, I looked around, and everyone else had stopped drinking and I couldn't understand why.\" When he is shown on the \"Late Show\" (or, before that, on \"Late Night\") drinking what appears to be alcohol, it is actually substituted with apple juice by the crew. In 2015, he said that \"For years and years and years – 30, 40 years – I was anxious and hypochondriacal and an alcoholic, and many, many other things that made me different from other people.\" He became calmer through a combination of transcendental meditation and low doses of medication. Letterman has implied that he is a Lutheran.\n\nLetterman's sister is a journalist, as is her husband. Their son, Liam Letterman Shelton, attended Letterman's \"alma mater\", Ball State University in Muncie, Indiana, where Letterman funded the journalism school, and studied a four-year double major in journalism news/telecommunications news.\n\nBeginning in May 1988, Letterman was stalked by Margaret Mary Ray, a woman suffering from schizophrenia. She stole his Porsche, camped out on his tennis court, and repeatedly broke into his house. Her exploits drew national attention, with Letterman occasionally joking about her on his show, although he never referred to her by name. After she committed suicide in October 1998, Letterman told \"The New York Times\" that he had great compassion for her. A spokesperson for Letterman said: \"This is a sad ending to a confused life.\"\n\nOn October 1, 2009, Letterman announced on his show that he had been the victim of a blackmail attempt by someone threatening to reveal that he'd had sex with several of his female employees, and at the same time, he confirmed that he had such relationships. He stated that three weeks earlier (on September 9, 2009) someone had left a package in his car with material he said he would write into a screenplay and a book if Letterman did not pay him  million. Letterman said that he contacted the Manhattan District Attorney's office, ultimately cooperating with them to conduct a sting operation involving giving the man a phony check. Subsequently, Robert J. \"Joe\" Halderman, a producer of the CBS true crime journalism series \"48 Hours\", was arrested after trying to deposit the check. He was indicted by a Manhattan grand jury and pleaded not guilty to a charge of attempted grand larceny on October 2, 2009. Eventually, on March 9, 2010, he pleaded guilty to this same felony and served a six-month jail sentence, followed by probation and community service.\n\nA central figure in the case and one of the women with whom Letterman had had a sexual relationship was his longtime personal assistant Stephanie Birkitt, who often appeared with him on his show. She had also worked for \"48 Hours\". Until a month prior to the revelations, she had shared a residence with Halderman, who allegedly had copied her personal diary and used it, along with private emails, in the blackmail package.\n\nIn the days following the initial announcement of the affairs and the arrest, several prominent women, including Kathie Lee Gifford, co-host of NBC's \"Today Show\", and NBC news anchor Ann Curry questioned whether Letterman's affairs with subordinates created an unfair working environment. A spokesman for Worldwide Pants said that the company's sexual harassment policy did not prohibit sexual relationships between managers and employees. According to business news reporter Eve Tahmincioglu, \"CBS suppliers are supposed to follow the company's business conduct policies\" and the CBS 2008 Business Conduct Statement states that \"If a consenting romantic or sexual relationship between a supervisor and a direct or indirect subordinate should develop, CBS requires the supervisor to disclose this information to his or her Company's Human Resources Department...\".\n\nOn October 3, 2009, a former CBS employee, Holly Hester, announced that she and Letterman had engaged in a year-long \"secret\" affair in the early 1990s while she was his intern and a student at New York University.\n\nOn October 5, 2009, Letterman devoted a segment of his show to a public apology to his wife and staff. Three days later, Worldwide Pants announced that Birkitt had been placed on a \"paid leave of absence\" from the \"Late Show\". On October 15, CBS News announced that the company's Chief Investigative Correspondent, Armen Keteyian, had been assigned to conduct an \"in-depth investigation\" into Letterman.\n\nLetterman is a car enthusiast and owns an extensive collection. In 2012 it was reported that the collection consisted of ten Ferraris, eight Porsches, four Austin Healeys, two Honda motorcycles, a Chevy pickup and one car each from automakers Mercedes-Benz, Jaguar, MG, Volvo and Pontiac.\n\nIn his 2013 appearance on \"Comedians in Cars Getting Coffee\", part of Jerry Seinfeld's conversation with Letterman was filmed in Letterman's outwardly unassuming 1995 Volvo 960 station wagon that is powered by a 380 horsepower racing engine. Paul Newman had the car built for Letterman.\n\nOn September 7, 2007, Letterman visited his \"alma mater\", Ball State University in Muncie, Indiana, for the dedication of a communications facility named in his honor for his dedication to the university. The  million, David Letterman Communication and Media Building opened for the 2007 fall semester. Thousands of Ball State students, faculty, and local residents welcomed Letterman back to Indiana. Letterman's emotional speech touched on his struggles as a college student and his late father, and also included the \"top ten good things about having your name on a building\", finishing with \"if reasonable people can put my name on a  million building, anything is possible.\" Over many years Letterman \"has provided substantial assistance to [Ball State's] Department of Telecommunications, including an annual scholarship that bears his name.\"\n\nAt the same time, Letterman also received a Sagamore of the Wabash award given by Indiana Governor Mitch Daniels, which recognizes distinguished service to the state of Indiana.\n\nIn his capacities as either a performer, producer, or as part of a writing team, Letterman is among the most nominated people in the history of the Emmy Awards with 52 nominations, winning two Daytime Emmys and ten Primetime Emmys since 1981. He won four American Comedy Awards and in 2011 became the first recipient of the Johnny Carson Award for Comedic Excellence at The Comedy Awards.\n\nLetterman was a recipient of the 2012 Kennedy Center Honors, where he was called \"one of the most influential personalities in the history of television, entertaining an entire generation of late-night viewers with his unconventional wit and charm.\" On May 16, 2017, Letterman was named the next recipient of the Mark Twain Prize for American Humor, the award granted annually by the John F. Kennedy Center for the Performing Arts. He was scheduled to receive the prize in a ceremony slated for October 22.\n\n\n"}
{"id": "8341", "url": "https://en.wikipedia.org/wiki?curid=8341", "title": "Delroy Lindo", "text": "Delroy Lindo\n\nDelroy George Lindo (born November 18, 1952) is a British-American actor and theatre director. Lindo has been nominated for Tony and Screen Actors Guild awards and has won a Satellite Award. He is perhaps best known for his roles in a trio of Spike Lee films, especially as West Indian Archie in Lee's \"Malcolm X\" (1992) and Woody Carmichael in \"Crooklyn\" (1994), Catlett in \"Get Shorty\", Arthur Rose in \"The Cider House Rules\", and Detective Castlebeck in \"Gone in 60 Seconds\" (2000). Lindo starred as Alderman Ronin Gibbons in the TV series \"The Chicago Code\" (2011) and as Winter on the series \"Believe,\" which premiered in 2014.\n\nDelroy Lindo was born in 1952 in Eltham, south-east London, the son of Jamaican parents who had emigrated to Britain. He was brought up in nearby Lewisham and got interested in acting as a child in a Nativity play. His mother was a nurse and his father worked in various jobs. As a teenager, he and his mother moved to Toronto, Ontario, Canada. When he was sixteen, they moved to San Francisco. At the age of 24, Lindo started acting studies at the American Conservatory Theater, graduating in 1979.\n\nLindo's film debut came in 1976 with the British comedy \"Find the Lady\", followed by two other roles in films, including an Army Sergeant in \"More American Graffiti\" (1979).\n\nHe quit film for 10 years to concentrate on theatre acting. In 1982 he debuted on Broadway in \"\"Master Harold\"...and the Boys,\" directed by the play's South African author Athol Fugard. By 1988 Lindo had earned a Tony nomination for his portrayal of Herald Loomis in August Wilson's \"Joe Turner's Come and Gone\".\n\nLindo returned to film in the 1990s, acting alongside Rutger Hauer and Joan Chen in the cult science fiction film \"Salute of the Jugger\" (1990), which has become a cult classic. Although he had turned down Spike Lee for a role in his debut \"Do the Right Thing\", Lee cast him as Woody Carmichael in the drama \"Crooklyn\" (1994), which brought him notice. Together with his other roles with Lee - as the West Indian Archie, a psychotic gangster, in \"Malcolm X\", and a starring role as a neighbourhood drug dealer in \"Clockers\" - he became established in his film career.\n\nOther films in which he has starring roles are Barry Sonnenfeld's \"Get Shorty\" (1995), Ron Howard's \"Ransom\" (1996) and \"Soul of the Game\" (1996), as the baseball player Satchel Paige. As a character actor, Lindo has readily taken on roles as treacherous bad guys as well as those of trustworthy professionals.\n\nIn 1998 Lindo co-starred as African-American explorer Matthew Henson, in the TV film \"Glory & Honor\", directed by Kevin Hooks. It portrayed his nearly 20-year partnership with Commander Robert Peary in Arctic exploration and their effort to find the Geographic North Pole in 1909. He received a Satellite Award as best actor. Lindo continues to work in television and was most recently seen on the short-lived NBC drama \"Kidnapped\".\n\nLindo played an angel in the comedy film \"A Life Less Ordinary\" (1997), in which Dan Hedaya played the angel Gabriel, and Lindo's boss. He guest-starred on \"The Simpsons\" in the episode \"Brawl in the Family\", playing a similar character named Gabriel.\n\nLindo had a small role in the 1995 science fiction/action film \"Congo,\" playing the corrupt Captain Wanta. Lindo was not credited for the role, but one of his lines in the film, \"\"Stop eating my sesame cake!\"\", has become an internet meme.\n\nIn the British film, \"Wondrous Oblivion\" (2003), directed by Paul Morrison, he starred as Dennis Samuels, the father of a Jamaican immigrant family in London in the 1950s; he coaches his children and the son of a neighbour Jewish family in cricket, earning their admiration in a time of strained social relations. Lindo said he made the film in honour of his parents, who had similarly moved to London in those years.\n\nIn 2007, Lindo began an association with Berkeley Repertory Theatre in Berkeley, California, when he directed Tanya Barfield's play \"The Blue Door\". In the autumn of 2008, Lindo revisited August Wilson's play, \"Joe Turner's Come and Gone\", directing a production at the Berkeley Rep. In 2010, he played the role of elderly seer Bynum in David Lan's production of \"Joe Turner\" at the Young Vic Theatre in London.\n\nLindo is poised to play Marcus Garvey in an upcoming biopic of the black nationalist historical figure.\n\n"}
{"id": "8343", "url": "https://en.wikipedia.org/wiki?curid=8343", "title": "David Janssen", "text": "David Janssen\n\nDavid Janssen (born David Harold Meyer, March 27, 1931 – February 13, 1980) was an American film and television actor who is best known for his starring role as Dr. Richard Kimble in the television series \"The Fugitive\" (1963–1967). Janssen also had the title roles in three other series: \"Richard Diamond, Private Detective\"; \"Harry O\"; and \"O'Hara, U.S. Treasury\".\n\nIn 1996 \"TV Guide\" ranked him number 36 on its \"50 Greatest TV Stars of All Time\" list.\n\nJanssen was born in 1931 in Naponee, a village in Franklin County in southern Nebraska, to Harold Edward Meyer, a banker (May 12, 1906 – November 4, 1990) and Berniece Graf (May 11, 1910 – November 26, 1995). Janssen was of Irish and Jewish descent. Following his parents' divorce in 1935, his mother moved with five-year-old David to Los Angeles, California, and later married Eugene Janssen (February 18, 1918 – March 30, 1996) in 1940 in Los Angeles. Young David used his stepfather's name after he entered show business as a child.\n\nHe attended Fairfax High School in Los Angeles, where he excelled on the basketball court setting a school scoring record that lasted over 20 years. His first film part was at the age of thirteen, and by the age of twenty-five he had appeared in twenty films and served two years as an enlisted man in the United States Army. During his Army days, Janssen became friends with fellow enlistees Martin Milner and Clint Eastwood while posted at Fort Ord, California.\n\nJanssen appeared in many television series before he landed programs of his own. In 1956, he and Peter Breck appeared in John Bromfield's syndicated series \"Sheriff of Cochise\" in the episode \"The Turkey Farmers\". Later, he guest starred on NBC's medical drama \"The Eleventh Hour\" in the role of Hal Kincaid in the 1962 episode \"Make Me a Place\", with series co-stars Wendell Corey and Jack Ging. He joined friend Martin Milner in a 1962 episode of \"Route 66\" as the character Kamo in the episode \"One Tiger to a Hill.\"\n\nJanssen starred in four television series of his own:\n\nAt the time, the final episode of \"The Fugitive\" held the record for the greatest number of American homes with television sets to watch a series finale, at 72 percent in August 1967.\n\nHis films include \"To Hell and Back\", the biography of Audie Murphy, who was the most decorated American soldier of World War II; John Wayne's Vietnam war film \"The Green Berets\"; opposite Gregory Peck in the space story \"Marooned\", in which Janssen played an astronaut sent to rescue three stranded men in space, and \"The Shoes of the Fisherman\", as a television journalist in Rome reporting on the election of a new Pope (Anthony Quinn).\n\nHe starred as a Los Angeles police detective trying to clear himself in the killing of an apparently innocent doctor in the 1968 film \"Warning Shot\".\n\nJanssen played an alcoholic in the 1977 TV movie \"A Sensitive, Passionate Man\", which co-starred Angie Dickinson, and an engineer who devises an unbeatable system for blackjack in the 1978 made-for-TV movie \"Nowhere to Run\", co-starring Stefanie Powers and Linda Evans. Janssen's impressively husky voice was used to good effect as the narrator for the TV mini-series \"Centennial\" (1978–79); he also appeared in the final episode.\n\nThough Janssen's scenes were cut from the final release, he also appeared as a journalist in the film \"Inchon\", which he accepted to work with Laurence Olivier who played General Douglas MacArthur. At the time of his death, Janssen had just begun filming a television movie playing the part of Father Damien, the priest who dedicated himself to the leper colony on the island of Molokai, Hawaii. The part was eventually reassigned to actor Ken Howard of the CBS series \"The White Shadow\".\n\nIn 1996 \"TV Guide\" ranked him number 36 on its 50 Greatest TV Stars of All Time list.\n\nJanssen was married twice. His first marriage was to model and interior decorator Ellie Graham, who he married in Las Vegas on August 25, 1958. They divorced in 1968. In 1975, he married actress and model Dani Crayne Greco. They remained married until Janssen's death.\n\nJanssen died of a heart attack in the early morning of February 13, 1980, at his home in Malibu, California at age 48. At the time of his death, Janssen was filming the television movie \"Father Damien\". Janssen was buried at the Hillside Memorial Park Cemetery in Culver City, California. A non-denominational funeral was held at the Jewish chapel of the cemetery on February 17. Suzanne Pleshette delivered the eulogy at the request of Janssen's widow. Johnny Carson, Rod Stewart and Gregory Peck were among Janssen's pallbearers. Honorary pallbearers included Jack Lemmon, George Peppard, James Stewart and Danny Thomas.\n\nFor his contribution to the television industry, David Janssen has a star on the Hollywood Walk of Fame located on the 7700 block of Hollywood Boulevard.\n\n"}
{"id": "8344", "url": "https://en.wikipedia.org/wiki?curid=8344", "title": "Docetism", "text": "Docetism\n\nIn Christian terminology, docetism (from the Greek \"dokeĩn\" (to seem) \"dókēsis\" (apparition, phantom), is the doctrine that the phenomenon of Christ, his historical and bodily existence, and above all the human form of Jesus, was mere semblance without any true reality. Broadly it is taken as the belief that Jesus only seemed to be human, and that his human form was an illusion. The word \"Dokētaí\" (illusionists) referring to early groups who denied Jesus' humanity, first occurred in a letter by Bishop Serapion of Antioch (197–203), who discovered the doctrine in the Gospel of Peter, during a pastoral visit to a Christian community using it in Rhosus, and later condemned it as a forgery. It appears to have arisen over theological contentions concerning the meaning, figurative or literal, of a sentence from the Gospel of John: \"the Word was made Flesh\".\n\nDocetism was unequivocally rejected at the First Council of Nicaea in 325 and is regarded as heretical by the Catholic Church, Orthodox Church, and Coptic Church.\n\nDocetism is broadly defined as any teaching that claims that Jesus' body was either absent or illusory. The term 'docetic' is rather nebulous. For Robert Price \"docetism\", together with \"encratism\", \"Gnosticism\" and \"adoptionism\", has been employed \"far beyond what historically descriptive usage would allow\". Two varieties were widely known. In one version, as in Marcionism, Christ was so divine that he could not have been human, since God lacked a material body, which therefore could not physically suffer. Jesus only \"appeared\" to be a flesh-and-blood man; his body was a phantasm. Other groups who were accused of docetism held that Jesus was a man in the flesh, but Christ was a separate entity who entered Jesus's body in the form of a dove at his baptism, empowered him to perform miracles, and abandoned him upon his death on the cross.\n\nDocetism's origin within Christianity is obscure. Ernst Käsemann controversially defined the Christology of St John’s Gospel as \"naïve docetism\" in 1968. The ensuing debate reached an impasse as awareness grew that the very term \"docetism\", like \"gnosticism\", was difficult to define within the religio-historical framework of the debate. It has occasionally been argued that its origins were in heterodox Judaism or Oriental and Grecian philosophies. The alleged connection with Jewish Christianity would have reflected Jewish Christian concerns with the inviolability of (Jewish) monotheism. Docetic opinions seem to have circulated from very early times, 1 John 4:2 appearing explicitly to reject them. Some 1stcentury Christian groups developed docetic interpretations partly as a way to make Christian teachings more acceptable to pagan ways of thinking about divinity.\n\nIn his critique of the theology of Clement of Alexandria, Photius in his Myriobiblon held that Clement's views reflected a quasi-docetic view of the nature of Christ, writing that \"[Clement] hallucinates that the Word was not incarnate but \"only seems to be\".\" (ὀνειροπολεῖ καὶ μὴ σαρκωθῆναι τὸν λόγον ἀλλὰ \"δόξαι\".) In Clement’s time, some disputes contended over whether Christ assumed the \"psychic\" flesh of mankind as heirs to Adam, or the \"spiritual\" flesh of the resurrection. Docetism largely died out during the first millennium AD.\n\nThe opponents against whom Ignatius of Antioch inveighs are often taken to be Monophysite docetists. In his letter to the Smyrnaeans, 7:1, written around 110AD, he writes:\nWhile these characteristics fit a Monophysite framework, a slight majority of scholars consider that Ignatius was waging a polemic on two distinct fronts, one Jewish, the other docetic; a minority holds that he was concerned with a group that commingled Judaism and docetism. Others, however, doubt that there was actual docetism threatening the churches, arguing that he was merely criticizing Christians who lived Jewishly or that his critical remarks were directed at an Ebionite or Cerinthian possessionist Christology, according to which Christ was a heavenly spirit that temporarily possessed Jesus.\n\nThe Qur'an has a docetic Christology, viewing Jesus as a divine illuminator rather than the redeemer (as he is viewed in Christianity). However, the Islamic docetism is not focused on the general life and person of Jesus or the Christ. In Islam \"the Christ\" (\"al-masīḥ\") is not generally viewed as distinct from humanity nor a special spirit being as in docetism or some gnosticisms. Islamic docetism focuses on a denial of the crucifixion of Jesus. Sura 4:157–158 reads:\n\nSince Arthur Drews published his \"The Christ Myth\" (Die Christusmythe) in 1909, occasional connections have been drawn between docetist theories and the modern idea that Christ was a myth. Shailer Mathews called Drews' theory a \"modern docetism\". Frederick Cornwallis Conybeare thought any connection to be based on a misunderstanding of docetism. The idea recurred in classicist Michael Grant's 1977 review of the evidence for Jesus, who compared modern scepticism about an historical Jesus to the ancient docetic idea that Jesus only \"seemed\" to come into the world \"in the flesh\". Modern theories did away with \"seeming\".\n\n\n\n\n"}
{"id": "8347", "url": "https://en.wikipedia.org/wiki?curid=8347", "title": "Greek drachma", "text": "Greek drachma\n\nDrachma ( , ; pl. \"drachmae\" or \"drachmas\") was the currency used in Greece during several periods in its history:\n\nIt was also a small unit of weight.\n\nThe name \"drachma\" is derived from the verb δράσσομαι (\"drássomai\", \"(I) grasp\"). It is believed that the same word with the meaning of \"handful\" or \"handle\" is found in Linear B tablets of the Mycenean Pylos. Initially a drachma was a fistful (a \"grasp\") of six \"oboloí\" or \"obeloí\" (metal sticks, literally \"spits\") used as a form of currency as early as 1100 BC and being a form of \"bullion\": bronze, copper, or iron ingots denominated by weight. A hoard of over 150 rod-shaped obeloi was uncovered at Heraion of Argos in Peloponnese. Six of them are displayed at the Numismatic Museum of Athens.\n\nIt was the standard unit of silver coinage at most ancient Greek mints, and the name \"obol\" was used to describe a coin that was one-sixth of a drachma. The notion that \"drachma\" derived from the word for fistful was recorded by Herakleides of Pontos (387–312 BC) who was informed by the priests of Heraion that Pheidon, king of Argos, dedicated rod-shaped obeloi to Heraion. Similar information about Pheidon's obeloi was also recorded at the Parian Chronicle.\n\nAncient Greek coins normally had distinctive names in daily use. The Athenian tetradrachm was called owl, the Aeginetic stater was called chelone, the Corinthian stater was called \"hippos\" (horse) an so on. Each city would mint its own and have them stamped with recognizable symbols of the city, known as badge in numismatics, along with suitable inscriptions, and they would often be referred to either by the name of the city or of the image depicted. The exact exchange value of each was determined by the quantity and quality of the metal, which reflected on the reputation of each mint.\n\nAmong the Greek cities that used the drachma were: Abdera, Abydos, Alexandria, Aetna, Antioch, Athens, Chios, Cyzicus, Corinth, Ephesus, Eretria, Gela, Catana, Kos, Maronia, Naxos, Pella, Pergamum, Rhegion, Salamis, Smyrni, Sparta, Syracuse, Tarsus, Thasos, Tenedos, Troy and more.\n\nThe 5th century BC Athenian \"tetradrachm\" (\"four drachmae\") coin was perhaps the most widely used coin in the Greek world prior to the time of Alexander the Great (along with the Corinthian stater). It featured the helmeted profile bust of Athena on the obverse (front) and an owl on the reverse (back). In daily use they were called \"glaukes\" (owls), hence the proverb , 'an owl to Athens', referring to something that was in plentiful supply, like 'coals to Newcastle'. The reverse is featured on the national side of the modern Greek 1 euro coin.\n\nDrachmae were minted on different weight standards at different Greek mints. The standard that came to be most commonly used was the Athenian or Attic one, which weighed a little over 4.3 grams.\n\nAfter Alexander the Great's conquests, the name \"drachma\" was used in many of the Hellenistic kingdoms in the Middle East, including the Ptolemaic kingdom in Alexandria and the Parthian Empire based in what is modern-day Iran. The Arabic unit of currency known as \"dirham\" (in the Arabic language, درهم), known from pre-Islamic times and afterwards, inherited its name from the drachma or didrachm (, 2 drachmae); the dirham is still the name of the official currencies of Morocco and the United Arab Emirates. The Armenian dram also derives its name from the drachma.\n\nIt is difficult to estimate comparative exchange rates with modern currency because the range of products produced by economies of centuries gone by were different from today, which makes purchasing power parity (PPP) calculations very difficult; however, some historians and economists have estimated that in the 5th century BC a drachma had a rough value of 25 U.S. dollars (in the year 1990 – equivalent to 46.50 USD in 2015), whereas classical historians regularly say that in the heyday of ancient Greece (the fifth and fourth centuries) the daily wage for a skilled worker or a hoplite was one drachma, and for a heliast (juror) half a drachma since 425 BC.\n\nModern commentators derived from Xenophon that half a drachma per day (360 days per year) would provide \"a comfortable subsistence\" for \"the poor citizens\" (for the head of a household in 355 BC). Earlier in 422 BC, we also see in Aristophanes (\"Wasps\", line 300–302) that the daily half-drachma of a juror is just enough for the daily subsistence of a family of three.\n\nA modern person might think of one drachma as the rough equivalent of a skilled worker's daily pay in the place where they live, which could be as low as $1 USD, or as high as $100 USD, depending on the country.\n\nFractions and multiples of the drachma were minted by many states, most notably in Ptolemaic Egypt, which minted large coins in gold, silver and bronze.\n\nNotable Ptolemaic coins included the gold \"pentadrachm\" and \"octadrachm\", and silver \"tetradrachm\", \"decadrachm\" and \"pentakaidecadrachm\". This was especially noteworthy as it would not be until the introduction of the Guldengroschen in 1486 that coins of substantial size (particularly in silver) would be minted in significant quantities.\n\nFor the Roman successors of the drachma, see Roman provincial coins.\n\nThe weight of the silver drachma was approximately 4.3 grams or 0.15 ounces, although weights varied significantly from one city-state to another. It was divided into six obols of 0.72 grams, which were subdivided into four tetartemoria of 0.18 grams, one of the smallest coins ever struck, approximately 5–7 mm in diameter.\n\nMinae and talents were never actually minted: they represented weight measures used for commodities (e.g. grain) as well as metals like silver or gold. The New Testament mentions both didrachma and, by implication, tetradrachma in context of the Temple tax. Luke's Gospel includes a parable told by Jesus of a woman with 10 drachmae, who lost one and searched her home until she found it.\n\nThe drachma was reintroduced in May 1832, shortly before the establishment of the modern state of Greece (with the exception of the subdivision Taurus). It replaced the \"phoenix\" at par. The drachma was subdivided into 100 lepta.\n\nThe first coinage consisted of copper denominations of 1, 2, 5 and 10 lepta, silver denominations of , , 1 and 5 drachmae and a gold coin of 20 drachmae. The drachma coin weighed 4.5 g and contained 90% silver, with the 20-drachma coin containing 5.8 g of gold.\n\nIn 1868, Greece joined the Latin Monetary Union and the drachma became equal in weight and value to the French franc. The new coinage issued consisted of copper coins of 1, 2, 5 and 10 lepta, with the 5- and 10-lepta coins bearing the names \"obolos\" () and \"diobolon\" (), respectively; silver coins of 20 and 50 lepta, 1, 2 and 5 drachmae and gold coins of 5, 10 and 20 drachmae. (Very small numbers of 50- and 100-drachma coins in gold were also issued.)\n\nIn 1894, cupro-nickel 5-, 10- and 20-lepta coins were introduced. No 1-lepton or 2-lepta coin had been issued since the late 1870s. Silver coins of 1 and 2 drachmae were last issued in 1911, and no coins were issued between 1912 and 1922, during which time the Latin Monetary Union collapsed due to World War I.\n\nBetween 1926 and 1930, a new coinage was introduced for the new Hellenic Republic, consisting of cupro-nickel coins in denominations of 20 lepta, 50 lepta, 1 drachma, and 2 drachmae; nickel coins of 5 drachmae; and silver coins of 10 and 20 drachmae. These were the last coins issued for the first modern drachma, and none were issued for the second.\n\nNotes were issued by the National Bank of Greece from 1841 until 2001 when Greece joined the Euro. Early denominations ranged from 10 to 500 drachmae. Smaller denominations (1, 2, 3 and 5 drachmae) were issued from 1885, with the first 5-drachma notes being made by cutting 10-drachma notes in half.\n\nWhen Greece finally achieved its independence from the Ottoman Empire in 1828, the phoenix was introduced as the monetary unit; its use was short-lived, however, and in 1832 the phoenix was replaced by the drachma, adorned with the image of King Otto of Greece, who reigned as modern Greece’s first king from 1832 to 1862. The drachma was divided into 100 lepta. In 2002 the drachma ceased to be legal tender after the euro, the monetary unit of the European Union, became Greece’s sole currency.\n\nBetween 1917 and 1920, the Greek government issued paper money in denominations of 10 lepta, 50 lepta, 1 drachma, 2 drachmae, and 5 drachmae. The National Bank of Greece introduced 1000-drachma notes in 1901, and the Bank of Greece introduced 5000-drachma notes in 1928. The Greek government again issued notes between 1940 and 1944, in denominations ranging from 50 lepta to 20 drachmae.\n\nDuring the German-Italian occupation of Greece from 1941 to 1944, catastrophic hyperinflation and Nazi looting of the Greek treasury caused much higher denominations to be issued, culminating in 100,000,000,000-drachma notes in 1944.\n\nIn November 1944, after Greece was liberated from Germany, old drachmae were exchanged for new ones at the rate of 50,000,000,000 to 1. Only paper money was issued. The government issued notes of 1, 5, 10 and 20 drachmae, with the Bank of Greece issuing 50-, 100-, 500-, 1000-, 5000-, and 10,000-drachma notes. This drachma also suffered from high inflation. The government later issued 100-, 500-, and 1000-drachma notes, and the Bank of Greece issued 20,000-and 50,000-drachma notes.\n\nIn 1953, in an effort to halt inflation, Greece joined the Bretton Woods system. In 1954, the drachma was revalued at a rate of 1000 to 1. The new currency was pegged at 30 drachmae = 1 United States dollar. In 1973, the Bretton Woods System was abolished; over the next 25 years the official exchange rate gradually declined, reaching 400 drachmae to 1 U. S. dollar. On 1 January 2002, the Greek drachma was officially replaced as the circulating currency by the euro, and it has not been legal tender since 1 March 2002.\n\nThe first issue of coins minted in 1954 consisted of holed aluminium 5-, 10- and 20-lepton pieces, with 50-lepton, 1-, 2-, 5- and 10-drachma pieces in cupro-nickel. A silver 20-drachma piece was issued in 1960, replacing the 20-drachma banknote. Coins in denominations from 50 lepta to 20 drachmae carried a portrait of King Paul (1947–1964). New coins were introduced in 1966, ranging from 50 lepta to 10 drachmae, depicting King Constantine II (1964–1974). The reverse of all coins was altered in 1971 to reflect the military junta which was in power from 1967 to 1974. This design included a soldier standing in front of the flames of the rising phoenix.\n\nA 20-drachmae coin in cupro-nickel with an image of Europa on the obverse was issued in 1973. In the latter part of 1973, several new coin types were introduced: unholed aluminium (10 and 20 lepta), nickel-brass (50 lepta, 1 drachma, and 2 drachmae) and cupro-nickel (5, 10, and 20 drachmae). These provisional coins carried the design of the phoenix rising from the flame on the obverse, and used the country's new designation as the \"Hellenic Republic\", replacing the coins also issued in 1973 as the Kingdom of Greece with King Constantine II's portrait. A new series of all 8 denominations was introduced in 1976 carrying images of early national heroes on the smaller values.\n\nCupro-nickel 50-drachmae coins were introduced in 1980. In 1986, nickel-brass 50-drachma coins were introduced, followed by copper 1- and 2-drachma pieces in 1988 and nickel-brass coins of 20 and 100 drachmae in 1990. In 2000, a set of 6 themed 500-drachma coins was issued to commemorate the 2004 Athens Olympic Games.\n\nCoins in circulation at the time of the adoption of the euro were\n\nThe first issues of banknotes were in denominations of 10, 20 and 50 drachmae, soon followed by 100, 500 and 1000 drachmae by 1956. 5000-drachma notes were introduced in 1984, followed by 10,000-drachma notes in 1995 and 200-drachma notes in 1997.\n\nBanknotes in circulation at the time of the adoption of the euro were\n\nIn Unicode, the currency symbol is . There is a special Attic numeral, for the value of one drachma but it fails to render in most browsers.\n\n\n\nThe Drachmi Greek Democratic Movement Five Stars which was founded in 2013, aims to restore the Drachma, as Greece's currency.\n\n\n \n"}
{"id": "8349", "url": "https://en.wikipedia.org/wiki?curid=8349", "title": "Denarius", "text": "Denarius\n\nIn the Roman currency system, the dēnārius (pronunciation: ), plural: dēnāriī (pronunciation: ) was a small silver coin first minted about 211 BC during the Second Punic War. It became the most common coin produced for circulation but was slowly debased in weight and silver content until its replacement by the double denarius, called the antoninianus, early in the 3rd century AD. The word \"dēnārius\" is derived from the Latin \"dēnī\" \"containing ten\", as its value was 10 assēs, although in the middle of the 2nd century BC it was recalibrated so that it was now worth sixteen assēs or four sēstertiī. It is the origin of several modern words such as the currency name dinar; it is also the origin for the common noun for money in Italian \"denaro\", in Slovene \"denar\", in Portuguese \"dinheiro\", and in Spanish \"dinero\". Its symbol is X̶; a letter x with stroke.\n\nA predecessor of the denarius was first struck in 267 BC, five years before the first Punic War with an average weight of 6.81 grams, or of a Roman pound. Contact with the Greeks prompted a need for silver coinage in addition to the bronze currency that the Romans were using during that time. The predecessor of the denarius was a Greek-styled silver coin, very similar to the didrachm and drachma struck in Metapontion and other Greek cities in southern Italy. These coins were inscribed for Rome but closely resemble their Greek counterparts. They were most likely used for trade purposes and were seldom used in Rome.\n\nThe first distinctively Roman silver coin appeared around 226 BC. Classic historians sometimes called these coins dēnāriī in the past, but they are classified by modern numismatists as \"quadrīgātī\", which is derived from the quadrīgæ, or four-horse chariot, on the reverse, and which with a two-horse chariot or biga was the prototype for the most common designs used on Roman silver coins for the next 150 years.\n\nRome overhauled its coinage around 211 BC and introduced the denarius alongside a short-lived denomination called the victoriatus. This denarius contained an average 4.5 grams, or of a Roman pound of silver. It formed the backbone of Roman currency throughout the Roman republic.\n\nThe denarius began to undergo slow debasement toward the end of the republican period. Under the rule of Augustus, (63 BC-AD 14) its silver content fell to 3.9 grams (a theoretical weight of of a Roman pound). It remained at nearly this weight until the time of Nero (AD 37-68), when it was reduced to of a pound, or 3.4 grams. Debasement of the coin's silver content continued after Nero. Later Roman emperors reduced its content to 3 grams around the late third century.\n\nThe value at its introduction was 10 asses, giving the denarius its name, which translates as \"containing ten\". In about 141 BC, it was re-tariffed at 16 asses, to reflect the decrease in weight of the as. The denarius continued to be the main coin of the Roman Empire until it was replaced by the antoninianus in the middle of the third century. The last issuance of this coin occurred in bronze form by Aurelian, between AD 270 and 275, and in the first years of the reign of Diocletian. For more details, see 'Denarius', in \"A Dictionary of Ancient Roman Coins\", by John R. Melville-Jones (1990).\n\nThe denarius has a link from the Roman times to the British penny and US 1 cent piece (colloquially called 'penny').\n\nIt is difficult to give even rough comparative values for money from before the 20th century, as the range of products and services available for purchase was different. Classical historians often say that in the late Roman Republic and early Roman Empire (~27BC) the daily wage for an unskilled laborer and common soldier was 1 denarius (with no tax deductions) or about US$2.8 in bread. During the republic (509–27 BC), legionary pay was 112.5 denarii per year (0.3/day), later doubled by Julius Caesar to 225 denarii (0.6/day), with soldiers having to pay for their own food and arms. Centurions received considerably higher pay; under Augustus, the lowest rank of centurion was paid 3,750 denarii and the highest rank, 15,000 denarii.\n\nThe silver content of the denarius under the Roman Empire (after Nero) was about 50 grains, 3.24 grams, or (0.105ozt) troy ounce. On June 6, 2011, this was about US$3.62 in value if the silver were 0.999 pure.\n\nThe fineness of the silver content varied with political and economic circumstances. From a purity of greater than 90% silver in the first century A.D., the denarius fell to under 60% purity by the end of the second century A.D., and plummeted to 5% purity by the end of the third century A.D. By the reign of Gallienus, the antoninianus was a copper coin with a thin silver wash.\n\nBy comparison, a laborer earning the minimum wage in the United States in January 2014 made US$58 for an 8-hour day, before taxes (utilizing the mode value of $7.25 per hour, which was true then in 20 states) and a labourer earning the minimum wage in the United Kingdom in 2014 made GBP£52 for an 8-hour day, before taxes.\n\nIn the final years of the first century BC Tincomarus the ruler of part of Britain started issuing coins that appear to have been made from melted down Denarii.The coins of Eppillus, issued around Calleva Atrebatum during the same time period, appear to have derived design elements from various dēnāriī such as those of Augustus and M. Volteius.\n\nEven after the denarius was no longer regularly issued, it continued to be used as a unit of account, and the name was applied to later Roman coins in a way that is not understood. The Arabs who conquered large parts of the land that once belonged to the Eastern Roman Empire issued their own gold dinar. The lasting legacy of the denarius can be seen in the use of \"d\" as the abbreviation for the British penny before 1971. It survived in France as the name of a coin, the denier. The denarius also survives in the common Arabic name for a currency unit, the \"dinar\" used from pre-Islamic times, and still used in several modern Arabic-speaking nations. The major currency unit in former Principality of Serbia, Kingdom of Serbia and former Yugoslavia was \"dinar\", and it is still used in present-day Serbia. The Macedonian currency \"denar\" is also derived from the Roman denarius. The Italian word \"denaro\", the Spanish word \"dinero\", the Portuguese word \"dinheiro\", and the Slovene word \"\", all meaning money, are also derived from Latin \"denarius\".\n\nThe gold \"aureus\" seems to have been a \"currency of account,\" a denomination not commonly seen in daily transactions due to its high value. Numismatists think that the aureus was used to pay bonuses to the legions at the accession of new emperors. It was valued at 25 denarii.\n\n1 gold aureus = 2 gold quinarii = 25 silver denarii = 50 silver quinarii = 100 bronze sestertii = 200 bronze dupondii = 400 copper asses = 800 copper semisses = 1600 copper quadrantes\n\nThe denarius has been commonly identified as the tribute penny held by Jesus in the Render unto Caesar passage Matthew 22:15-22 and Mark 12:13-17.\n\nIn the New Testament, the gospels refer to the denarius as a day's wage for a common laborer (Matthew 20:2, John 12:5). In the Book of Revelation, during the Third Seal: Black Horse, a choinix (or quart) of wheat and three quarts of barley were each valued at one denarius. Bible scholar Robert H. Mounce says the price of the wheat and barley as described in the vision appears to be ten to twelve times their normal cost in ancient times. Revelation describes a condition where basic goods are sold at greatly inflated prices. Thus, the black horse rider depicts times of deep scarcity or famine but not of starvation. The English word \"quart\" translates choinix. Apparently, a choinix of wheat was the daily ration of one adult. Thus, in the conditions pictured by Revelation 6 the normal income for a working-class family would buy enough food for only one person. The less costly barley would feed three people for one day's wages.\n\nThe silver denarius is one of the two main units of currency in Rick Riordan's \"The Heroes of Olympus\" series, along with the golden drachma.\n\n\"Denar\" was a common unit of money in the Xena and television shows. Occasionally it appeared as a large silver coin. An example of its use was in the Hercules episode, The March to Freedom, where it can be heard in the bidding at a slave auction.\n\n\n"}
{"id": "8350", "url": "https://en.wikipedia.org/wiki?curid=8350", "title": "Della Rovere", "text": "Della Rovere\n\nThe Della Rovere family (; literally \"of the Oak Tree\") is a noble family of Italy. Coming from modest beginnings in Savona, Liguria, the family rose to prominence through nepotism and ambitious marriages arranged by two della Rovere popes, Francesco della Rovere, who ruled as Pope Sixtus IV (1471–1484) and his nephew Giuliano (Pope Julius II, 1503–1513). Pope Sixtus IV built the Sistine Chapel, which is named for him. The Basilica San Pietro in Vincoli in Rome is the family church of the della Rovere.\n\nGuidobaldo da Montefeltro adopted Francesco Maria I della Rovere, his sister's child and nephew of Pope Julius II. Guidobaldo I, who was heirless, called Francesco Maria at his court, and named him as heir of the Duchy of Urbino in 1504, this through the intercession of Julius II. In 1508, Francesco Maria inherited the duchy thereby starting the line of Rovere Dukes of Urbino. That dynasty ended in 1626 when Pope Urban VIII incorporated Urbino into the papal dominions. As compensation to the last sovereign duke, the title only could be continued by Francesco Maria II, and after his death by his heir, Federico Ubaldo.\n\nVittoria, last descendant of the della Rovere family (she was the only child of Federico Ubaldo), married Ferdinando II de' Medici, Grand Duke of Tuscany. They had two children: Cosimo III, Tuscany's longest reigning monarch, and Francesco Maria de' Medici, a prince of the Church.\n\nCurrently, only a cadet branch of the Lante della Rovere is survived, continuing the family traditions.\n\n\nDotted lines indicate duplicates (where a person appears more than once in the tree).<br>\nSmall caps text indicates the surname of the children (regardless of number) of a union.<br>\nAll persons have the surname Della Rovere unless otherwise indicated.\n\n\n"}
{"id": "8351", "url": "https://en.wikipedia.org/wiki?curid=8351", "title": "David Mamet", "text": "David Mamet\n\nDavid Alan Mamet (; born November 30, 1947) is an American playwright, essayist, screenwriter, and film director. As a playwright, Mamet has won a Pulitzer Prize and received Tony nominations for \"Glengarry Glen Ross\" (1984) and \"Speed-the-Plow\" (1988). Mamet first gained acclaim for a trio of off-Broadway plays in 1976, \"The Duck Variations,\" \"Sexual Perversity in Chicago,\" and \"American Buffalo.\" His play \"Race\" opened on Broadway on December 6, 2009, and his play \"The Penitent\" previewed off-Broadway on February 8, 2017.\n\nMamet's books include: \"The Old Religion\" (1997), a novel about the lynching of Leo Frank; \"Five Cities of Refuge: Weekly Reflections on Genesis, Exodus, Leviticus, Numbers and Deuteronomy\" (2004), a Torah commentary with Rabbi Lawrence Kushner; \"The Wicked Son\" (2006), a study of Jewish self-hatred and antisemitism; \"Bambi vs. Godzilla\", a commentary on the movie business; \"The Secret Knowledge: On the Dismantling of American Culture\" (2011), a commentary on cultural and political issues; and \"Three War Stories\" (2013), a trio of novellas about the physical and psychological effects of war.\n\nFeature films that Mamet both wrote and directed include \"Redbelt\" (2008), \"The Spanish Prisoner\" (1997), \"House of Games\" (1987) (which won Best Film and Best Screenplay awards at the 1987 Venice Film Festival and \"Film of the Year\" for the 1989 London Critics Circle Film Awards), \"Spartan\" (2004), \"Heist\" (2001), \"State and Main\" (2000) (Winner of a Best Acting - Ensemble award from the National Board of Review), \"The Winslow Boy\" (1999), and \"Oleanna\" (1994). This was accompanied by \"Homicide\" (1991) (nominated for the Palme d'Or at 1991 Cannes Film Festival and won a \"Screenwriter of the Year\" award for Mamet from the London Critics Circle Film Awards and Best Cinematography for Roger Deakins from the Los Angeles Film Critics Association Awards), \"Things Change\" (1988) (which won the Volpi Cup for Best Actor at 1988 Venice Film Festival for Don Ameche and Joe Mantegna), and most recently the 2013 HBO film \"Phil Spector\", starring Al Pacino as Spector with Helen Mirren and Jeffrey Tambor. His drama \"Glengarry Glen Ross\", in 1992, was adapted by Mamet into a film version which also received an Academy Award nomination.\n\nMamet wrote the screenplays for \"The Verdict\" (1982), directed by Sidney Lumet, \"The Postman Always Rings Twice\" (1981), directed by Bob Rafelson, \"The Untouchables\" (1987) directed by Brian De Palma, \"Hoffa\" (1992), \"Ronin\" (1998), \"Wag the Dog\" (1997), \"The Edge\" (1997), and \"Hannibal\" (2001). Mamet was also the executive producer and frequent writer for the TV show \"The Unit.\" As a screenplay writer, Mamet received Oscar nominations for \"The Verdict\" and \"Wag the Dog\".\n\nDavid Mamet also studied acting at The Neighborhood Playhouse School of the Theatre in New York City.\n\nMamet was born in 1947 in Chicago to Jewish parents, Lenore June (née Silver), a teacher, and Bernard Morris Mamet, an attorney. One of his first jobs was as a busboy at Chicago's The Second City. He was educated at the progressive Francis W. Parker School and at Goddard College in Plainfield, Vermont. At the Chicago Public Library Foundation 20th anniversary fundraiser in 2006, though, Mamet announced \"My alma mater is the Chicago Public Library. I got what little educational foundation I got in the third-floor reading room, under the tutelage of a Coca-Cola sign\".\n\nMamet is a founding member of the Atlantic Theater Company; he first gained acclaim for a trio of off-Broadway plays in 1976, \"The Duck Variations,\" \"Sexual Perversity in Chicago,\" and \"American Buffalo.\" He was awarded the Pulitzer Prize in 1984 for \"Glengarry Glen Ross,\" which received its first Broadway revival in the summer of 2005. His play \"Race\", which opened on Broadway on December 6, 2009 and featured James Spader, David Alan Grier, Kerry Washington, and Richard Thomas in the cast, received mixed reviews. His play \"The Anarchist\", starring Patti LuPone and Debra Winger, in her Broadway debut, opened on Broadway on November 13, 2012 in previews and was scheduled to close on December 16, 2012. His 2017 play \"The Penitent\" previewed off-Broadway on February 8, 2017.\n\nIn 2002, Mamet was inducted into the American Theatre Hall of Fame. Mamet later received the PEN/Laura Pels International Foundation for Theater Award for Grand Master of American Theater in 2010.\n\nMamet's feature films, which he both wrote and directed, include in chronological order: his feature directorial debut \"House of Games\" (1987) (which won Best Film and Best Screenplay awards at the 1987 Venice Film Festival and \"Film of the Year\" for the 1989 London Critics Circle Film Awards), \"Things Change\" (1988), \"Homicide\" (1991) (nominated for the Palme d'Or at 1991 Cannes Film Festival and won a \"Screenwriter of the Year\" award for Mamet from the London Critics Circle Film Awards and Best Cinematography from Roger Deakins from the Los Angeles Film Critics Association Awards), \"Oleanna\" (1994), \"The Spanish Prisoner\" (1997), \"The Winslow Boy\" (1999), \"State and Main\" (2000), \"Heist\" (2001), \"Spartan\" (2004), \"Redbelt\" (2008), and in 2012 a bio-pic TV movie \"Phil Spector\" about the American record producer and songwriter Phil Spector starring Al Pacino as Spector, as well as Helen Mirren and Jeffrey Tambor. His latest feature-length film, a thriller titled \"Blackbird\", was slated for release in 2015, but is still in development. \"Blackbird\" will star James Badge Dale as “a military major who is trying to discover the truth about the political secrets of a woman’s grandfather who worked for the U.S. special ops during the 1960s,” according to Deadline.com.\n\nMamet has also written the screenplays for such classic films as \"The Verdict\" (1982), directed by Sidney Lumet, \"The Postman Always Rings Twice\" (1981), \"The Untouchables\" (1987) directed by Brian De Palma, \"Hoffa\" (1992), \"The Edge\" (1997), \"Wag the Dog\" (1997), \"Ronin\" (1998), and \"Hannibal\" (2001).\n\nMamet's first produced screenplay was the 1981 production of \"The Postman Always Rings Twice\" (directed by Bob Rafelson), based upon James M. Cain's novel. He received an Academy Award nomination one year later for his first script, \"The Verdict\", written in the late 1970s. He also wrote the screenplay for \"The Untouchables.\"\n\nIn 1987, Mamet made his film directing debut with \"House of Games\", starring his then-wife, Lindsay Crouse, and a host of longtime stage associates. He uses friends as actors, especially in one early scene in the movie, which featured Vermont poker-playing friends. He is quoted as saying, \"It was my first film as a director and I needed support, so I stacked the deck.\" Two of the four poker friends included in the film were fellow Goddard College graduates Allen Soule and Bob Silverstein. Three of Mamet's own films, \"House of Games\", \"The Spanish Prisoner\", and \"Heist,\" have involved the world of con artists.\n\nMamet adapted \"Glengarry Glen Ross\" for the cinema in 1992, writing an additional part (including the monologue \"Coffee's for closers\") for Alec Baldwin.\n\nMamet remains a writer and director, and has assembled an informal repertory company for his films, including Crouse, William H. Macy, Joe Mantegna, Rebecca Pidgeon, and Ricky Jay, as well as some of the aforementioned poker associates. Mamet has funded his own films with payments he receives for credited and uncredited rewrites of typically big-budget films. For instance, Mamet did a rewrite of the script for \"Ronin\" under the pseudonym “Richard Weisz” and turned in an early version of a script for \"Malcolm X\" that director Spike Lee rejected. In 2000, Mamet directed a film version of \"Catastrophe,\" a one-act play by Samuel Beckett featuring Harold Pinter and John Gielgud (in his final screen performance). In 2008, he directed and wrote the mixed martial arts movie \"Redbelt,\" about a martial arts instructor tricked into fighting in a professional bout. Mamet teamed up with his wife Rebecca Pidgeon to adapt the novel \"Come Back to Sorrento\" as a screenplay. The film was in development during 2010. He is also director of the TV film \"Phil Spector\".\n\nIn \"On Directing Film,\" Mamet asserts that directors should focus on getting the point of a scene across, rather than simply following a protagonist, or adding visually beautiful or intriguing shots. Films should create order from disorder in search of the objective.\n\nIn 1990 Mamet published \"The Hero Pony\", a 55-page collection of poetry. He has also published a series of short plays, monologues and three novels, \"The Village\" (1994), \"The Old Religion\" (1997), and \"Wilson: A Consideration of the Sources\" (2000). He has written several non-fiction texts, and children's stories, including \"True and False: Heresy and Common Sense for the Actor\"(1997). In 2004 he published a lauded version of the classical Faust story, \"Faustus\", however, the play, when staged in San Francisco during the spring of 2004, was not well received by critics. On May 1, 2010, Mamet released a graphic novel \"The Trials of Roderick Spode (The Human Ant)\".\n\nOn June 2, 2011, \"The Secret Knowledge: On the Dismantling of American Culture\", Mamet's book detailing his conversion from modern liberalism to \"a reformed liberal\" was released.\n\nMamet published \"Three War Stories\", a collection of novellas, on November 11, 2013. In an interview with Newsmax TV, Mamet said he wanted to write about war, despite never having served. Moreover, the book allowed Mamet to free characters that had occupied his mind for years. On the subject of characters as a reason for writing, Mamet told the host, “You want to get these guys out of your head. You just want them to stop talking to you.\"\n\nMamet wrote the \"Wasted Weekend\" episode of \"Hill Street Blues\" that aired in 1987. His then-wife, Lindsay Crouse, appeared in numerous episodes (including that one) as Officer McBride. Mamet is also the creator, producer and frequent writer of the television series \"The Unit\", where he wrote a well-circulated memo to the writing staff. He directed a third-season episode of \"The Shield\" with Shawn Ryan. In 2007, Mamet directed two television commercials for Ford Motor Company. The two 30-second ads featured the Ford Edge and were filmed in Mamet's signature style of fast-paced dialogue and clear, simple imagery. Mamet's sister, Lynn, is a producer and writer for television shows, such as \"The Unit\" and \"Law & Order\".\n\nMamet has contributed several dramas to BBC Radio through Jarvis & Ayres Productions, including an adaptation of \"Glengarry Glen Ross\" for BBC Radio 3 and new dramas for BBC Radio 4. The comedy \"Keep Your Pantheon (or On the Whole I'd Rather Be in Mesopotamia)\" was aired in 2007.\n\nSince May 2005 he has been a contributing blogger at \"The Huffington Post\", drawing satirical cartoons with themes including political strife in Israel. In a 2008 article for the \"Village Voice\" headlined \"Why I Am No Longer a 'Brain-Dead Liberal\"' he revealed that he had gradually rejected political correctness and progressivism and embraced conservatism. Mamet has spoken in interviews of changes in his views, highlighting his agreement with free market theorists such as Friedrich Hayek the historian Paul Johnson, and economist Thomas Sowell, whom Mamet called \"one of our greatest minds\".\n\nDuring promotion of a book, Mamet was criticized for claiming that the British people had \"a taint of anti-semitism,\" claiming they \"want to give [Israel] away.\" In the same interview, Mamet went on to say that \"there are famous dramatists and novelists [in the UK] whose works are full of anti-Semitic filth,\" but that he could not specify to whom he was referring for fear of litigation. He is known for his pro-Israel positions; in his book \"The Secret Knowledge\" he claimed that \"Israelis would like to live in peace within their borders; the Arabs would like to kill them all.\"\n\nIn November 2012 Mamet penned an article for \"The Jewish Journal of Greater Los Angeles\" imploring fellow Jewish Americans to vote for Republican nominee Mitt Romney.\n\nIn an essay for \"Newsweek\", published on 29 January 2013, Mamet argued against gun control laws: \"It was intended to guard us against this inevitable decay of government that the Constitution was written. Its purpose was and is not to enthrone a Government superior to an imperfect and confused electorate, but to protect us from such a government.\"\n\nMamet's style of writing dialogue, marked by a cynical, street-smart edge, precisely crafted for effect, is so distinctive that it has come to be called \"Mamet speak.\" Mamet has recognized an association of his edgy narrative style by noting his debt to Harold Pinter, to whom he dedicated \"Glengarry Glen Ross\". He often uses italics and quotation marks to highlight particular words and to draw attention to his characters' frequent manipulation and deceitful use of language. His characters frequently interrupt one another, their sentences trail off unfinished, and their dialogue overlaps. Moreover, certain expressions and figures of speech are deliberately misrepresented to show that the character is not paying close attention to every detail of his dialogue (e.g., \"or so forth\" instead of \"and so forth\"). Mamet himself has criticized his (and other writers') tendency to write \"pretty\" at the expense of sound, logical plots.\n\nWhen asked how he developed his style for writing dialogue, Mamet said, \"In my family, in the days prior to television, we liked to while away the evenings by making ourselves miserable, based solely on our ability to speak the language viciously. That's probably where my ability was honed.\"\n\nOne instance of Mamet's dialogue style can be found in \"Glengarry Glen Ross\", in which two down-on-their-luck real estate salesmen are considering stealing from their employer's office. George Aaronow and Dave Moss equivocate on the meaning of \"talk\" and \"speak\", turning language and meaning to deceptive purposes:\n\nMamet dedicated \"Glengarry Glen Ross\" to Harold Pinter, who was instrumental in its being first staged at the Royal National Theatre, (London) in 1983, and whom Mamet has acknowledged as an influence on its success, and on his other work.\n\nMamet's plays have frequently sparked debate and controversy. During a staging of \"Oleanna\" in 1992, in which a post-secondary student accuses her professor of sexual harassment, a critic reported that the play divided the audience by gender and recounted \"couples emerged screaming at each other\".\n\nArthur Holmberg in his 2014 book \"David Mamet and Male Friendship\", has reconsidered the gender issue in many of Mamet's plays throughout his career by asserting a prominent and recurrent reversed sexual orientation of portrayed male gender preferences.\n\nMamet and actress Lindsay Crouse were married in 1977 and divorced in 1990. He and Crouse have two children, Willa and Zosia. Willa is a professional photographer and Zosia is an actress. Mamet has been married to actress and singer-songwriter Rebecca Pidgeon since 1991. They have two children, Clara and Noah.\n\nThe papers of David Mamet were sold to the Harry Ransom Center at the University of Texas at Austin in 2007 and first opened for research in 2009. The growing collection consists mainly of manuscripts and related production materials for most of his plays, films, and other writings, but also includes his personal journals from 1966 to 2005. In 2015, the Ransom Center secured a second major addition to Mamet's papers that include more recent works. Additional materials relating to Mamet and his career can be found in the Ransom Center's collections of Robert De Niro, Mel Gussow, Tom Stoppard, Sam Shepard, Paul Schrader, Don DeLillo, and John Russell Brown.\n\nMamet is credited as writer of these works except where noted. Credits in addition to writer also noted.\n\n"}
{"id": "8352", "url": "https://en.wikipedia.org/wiki?curid=8352", "title": "December 6", "text": "December 6\n\n\n\n\n"}
{"id": "8353", "url": "https://en.wikipedia.org/wiki?curid=8353", "title": "December 5", "text": "December 5\n\n\n\n"}
{"id": "8354", "url": "https://en.wikipedia.org/wiki?curid=8354", "title": "December 4", "text": "December 4\n\n\n\n\n"}
{"id": "8355", "url": "https://en.wikipedia.org/wiki?curid=8355", "title": "December 3", "text": "December 3\n\n\n\n"}
{"id": "8356", "url": "https://en.wikipedia.org/wiki?curid=8356", "title": "December 2", "text": "December 2\n\n\n\n\n"}
{"id": "8357", "url": "https://en.wikipedia.org/wiki?curid=8357", "title": "December 1", "text": "December 1\n\n\n\n\n"}
{"id": "8359", "url": "https://en.wikipedia.org/wiki?curid=8359", "title": "December 24", "text": "December 24\n\n\n\n"}
{"id": "8360", "url": "https://en.wikipedia.org/wiki?curid=8360", "title": "December 26", "text": "December 26\n\n\n\n"}
{"id": "8361", "url": "https://en.wikipedia.org/wiki?curid=8361", "title": "Definable real number", "text": "Definable real number\n\nDefinable real numbers are those that can be uniquely specified by a description. The description may be expressed as a construction or as a formula of a formal language. For example, the positive square root of 2, formula_1, can be defined as the unique positive solution to the equation formula_2, and it can be constructed with a compass and straightedge.\n\nDifferent notions of description give rise to different notions of definability. Specific varieties of definable numbers include the constructible numbers of geometry, the algebraic numbers, and the computable numbers.\n\nOne way of specifying a real number uses geometric techniques. A real number \"r\" is a constructible number if there is a method to construct a line segment of length \"r\" using a compass and straightedge, beginning with a fixed line segment of length 1.\n\nEach positive integer, and each positive rational number, is constructible. The positive square root of 2 is constructible. However, the cube root of 2 is not constructible; this is related to the impossibility of doubling the cube.\n\nA real number \"r\" is called an algebraic number if there is a polynomial \"p\"(\"x\"), with only integer coefficients, so that \"r\" is a root of \"p\", that is, \"p\"(\"r\")=0. \nEach algebraic number can be defined individually using the order relation on the reals. For example, if a polynomial \"q\"(\"x\") has 5 roots, the third one can be defined as the unique \"r\" such that \"q\"(\"r\") = 0 and such that there are two distinct numbers less than \"r\" for which \"q\" is zero.\n\nAll rational numbers are algebraic, and all constructible numbers are algebraic. There are numbers such as the cube root of 2 which are algebraic but not constructible.\n\nThe algebraic numbers form a subfield of the real numbers. This means that 0 and 1 are algebraic numbers and, moreover, if \"a\" and \"b\" are algebraic numbers, then so are \"a\"+\"b\", \"a\"−\"b\", \"ab\" and, if \"b\" is nonzero, \"a\"/\"b\".\n\nThe algebraic numbers also have the property, which goes beyond being a subfield of the reals, that for each positive integer \"n\" and each algebraic number \"a\", all of the \"n\"th roots of \"a\" that are real numbers are also algebraic.\n\nThere are only countably many algebraic numbers, but there are uncountably many real numbers, so in the sense of cardinality most real numbers are not algebraic. This nonconstructive proof that not all real numbers are algebraic was first published by\nGeorg Cantor in his 1874 paper \"On a Property of the Collection of All Real Algebraic Numbers\".\n\nSpecific examples of non-algebraic numbers, which are called transcendental numbers, include π and Euler's number \"e\".\n\nA real number is a computable number if there is an algorithm that, given a natural number \"n\", produces a decimal expansion for the number accurate to \"n\" decimal places. This notion was introduced by Alan Turing in 1936.\n\nThe computable numbers include the algebraic numbers along with many transcendental numbers including π and \"e\". Like the algebraic numbers, the computable numbers also form a subfield of the real numbers, and the positive computable numbers are closed under taking \"n\"th roots for each positive \"n\".\n\nNot all real numbers are computable. The entire set of computable numbers is countable, so most reals are not computable. Specific examples of noncomputable real numbers include the limits of Specker sequences, and algorithmically random real numbers such as Chaitin's Ω numbers.\n\nAnother notion of definability comes from the formal theories of arithmetic, such as Peano arithmetic. The language of arithmetic has symbols for 0, 1, the successor operation, addition, and multiplication, intended to be interpreted in the usual way over the natural numbers. Because no variables of this language range over the real numbers, a different sort of definability is needed to refer to real numbers. A positive real number \"a\" is \"definable in the language of arithmetic\" (or \"arithmetical\") if its Dedekind cut can be defined as a predicate in that language; that is, if there is a first-order formula \"φ\" in the language of arithmetic, with two free variables, such that\n\nA real number \"a\" is first-order definable in the language of set theory, without parameters, if there is a formula \"φ\" in the language of set theory, with one free variable, such that \"a\" is the unique real number such that \"φ(a)\" holds in the standard model of set theory (see ). This notion cannot be expressed as a formula in the language of set theory.\n\nAll analytical numbers, and in particular all computable numbers, are definable in the language of set theory. Thus the real numbers definable in the language of set theory include all familiar real numbers such as 0, 1, , \"e\", et cetera, along with all algebraic numbers. Assuming that they form a set in the model, the real numbers definable in the language of set theory over a particular model of ZFC form a field. \nEach set model \"M\" of ZFC set theory that contains uncountably many real numbers must contain real numbers that are not definable within \"M\" (without parameters). This follows from the fact that there are only countably many formulas, and so only countably many elements of \"M\" can be definable over \"M\". Thus, if \"M\" has uncountably many real numbers, we can prove from \"outside\" \"M\" that not every real number of \"M\" is definable over \"M\". \nThis argument becomes more problematic if it is applied to class models of ZFC, such as the von Neumann universe . The argument that applies to set models cannot be directly generalized to class models in ZFC because the property \"the real number \"x\" is definable over the class model \"N\"\" cannot be expressed as a formula of ZFC. Similarly, the question whether the von Neumann universe contains real numbers that it cannot define cannot be expressed as a sentence in the language of ZFC. Moreover, there are countable models of ZFC in which all real numbers, all sets of real numbers, functions on the reals, etc. are definable .\n\n\n"}
{"id": "8362", "url": "https://en.wikipedia.org/wiki?curid=8362", "title": "Diego de Almagro", "text": "Diego de Almagro\n\nDiego de Almagro, ( – July 8, 1538), also known as El Adelantado and El Viejo, was a Spanish conquistador and a companion and later rival of Francisco Pizarro. He participated in the Spanish conquest of Peru and is credited as the first European discoverer of Chile.\n\nAlmagro lost his left eye battling with coastal natives in the New World. In 1525 he joined the Pizarro brothers and Hernándo de Luque at Panama for the conquest of Peru.\n\nDiego de Almagro was born and raised in Almagro, Ciudad Real, Spain with parents Juan de Montenegro and Elvira Gutiérrez. He married twice; with Ana Martínez and Mencia and got two children; son Diego de Almagro II with Ana Martínez and daughter Isabel with Mencia.\nDiego de Almagro arrived in the New World on June 30, 1514, under the expedition that Ferdinand II of Aragon had sent under the guidance of Pedrarias Dávila. The expedition had landed in the city of Santa María la Antigua del Darién, Panama, where many other future conquistadors had already arrived, among them Francisco Pizarro.\n\nThere are not many details of Almagro's activities during this period, but it is known that he accompanied various sailors who departed from the city of Darien between 1514 and 1515. De Almagro eventually returned and settled in Darien, where he was granted an encomienda. He built a house and made a living from agriculture.\n\nDe Almagro undertook his first conquest on November 1515, commanding 260 men as he founded Villa del Acla, named after the Indian place. Due to illness he had to leave behind this mission to the licenciate Gaspar de Espinosa.\n\nEspinosa decided to undertake a new expedition, which departed in December 1515 with 200 men, including De Almagro and Francisco Pizarro, who for the first time was designated as a captain. During this expedition, which lasted 14 months, De Almagro, Pizarro and Hernando de Luque became close friends.\n\nAlso during this time De Almagro established a friendship with Vasco Núñez de Balboa, who was in charge of Acla. De Almagro wanted to have a ship built with the remaining materials of the Espinosa expedition, to be finished on the coast of the \"Great South Sea\", as the Pacific Ocean was first called by the Spanish. Current historians do not believe that De Almagro was expected to participate in Balboa's expedition and probably returned to Darien.\n\nDe Almagro took part in the various expeditions that took place in the Gulf of Panama, taking part again in Espinosa's parties. Espinosa was supported by using Balboa's ships. De Almagro was recorded as a witness on the lists of natives whom Espinosa ordered to be carried. De Almagro remained as an early settler in the newly founded city of Panama. For four years he stayed there, working at the management of his properties and those of Pizarro. He took Ana Martínez, an indigenous woman, as a common-law wife. In this period, his first son, el \"Mozo\", was born to them.\n\nBy 1524 an association of conquest regarding South America was formalized among Almagro, Pizarro and Luque. By the beginning of August 1524, they had received the requisite permission to discover and conquer lands further south. De Almagro would remain in Panama to recruit men and gather supplies for the expeditions led by Pizarro.\n\nAfter several expeditions to South America, Pizarro secured his stay in Peru with the \"Capitulation\" on 6 July 1529. During Pizarro's continued exploration of Incan territory, he and his men succeeded in defeating the Inca army under Emperor Atahualpa during the Battle of Cajamarca in 1532. De Almagro joined Pizarro soon afterward, bringing more men and arms.\n\nAfter Peru fell to the Spanish, both Pizarro and De Almagro initially worked together in the founding of new cities to consolidate their dominions. As such, Pizarro dispatched De Almagro to pursue Quizquiz, fleeing to the Inca Empire's northern city of Quito. Their fellow conquistador Sebastián de Belalcázar, who had gone forth without Pizarro's approval, had already reached Quito and witnessed the destruction of the city by Inca general Rumiñawi. The Inca warrior had ordered the city to be burned and its gold to be buried at an undisclosed location where the Spanish could never find it. The arrival of Pedro de Alvarado from Guatemala, in search of Inca gold further complicated the situation for Almagro and Belalcázar. Alvarado's presence, however, did not last long as he left South America in exchange for monetary compensation from Pizarro.\n\nIn an attempt to claim Quito ahead of Belalcázar, in August 1534 De Almagro founded a city on the shores of Laguna de Colta (Colta Lake) in the foothills of Chimborazo, some south of present-day Quito, and named it \"Santiago de Quito.\" Four months later would come the foundation of the Peruvian city of Trujillo, which Almagro named as \"Villa Trujillo de Nueva Castilla\" (the Village of Trujillo in New Castille) in honor of Francisco Pizarro's birthplace, Trujillo in Extremadura, Spain. These events were the height of the Pizarro-Almagro friendship, which historians describe as one of the last events in which their friendship soon faded and entered a period of turmoil for the control of the Incan capital of Cuzco.\n\nAfter splitting the treasure of Inca emperor Atahualpa, both Pizarro and Almagro left towards Cuzco and took the city in 1533. However, De Almagro's friendship with Pizarro showed signs of deterioration in 1526 when Pizarro, in the name of the rest of the conquistadors, called forth the \"Capitulacion de Toledo\" law in which King Charles I of Spain had laid out his authorization for the conquest of Peru and the awards every conquistador would receive from it. Long before, however, each conquistador had promised to equally split the benefits. Pizarro managed to have a larger stake and awards for himself. Despite this, De Almagro still obtained an important fortune for his services, and the King awarded him in November 1532 the noble title of \"Don\" and he was assigned a personal coat of arms.\n\nAlthough by this time Diego de Almagro had already acquired sufficient wealth in the conquest of Peru and was living a luxurious life in Cuzco, the prospect of conquering the lands further south was very attractive to him. Given that the dispute with Pizarro over Cuzco had kept intensifying, Almagro spent a great deal of time and money equipping a company of 500 men for a new exploration south of Peru.\n\nBy 1534 the Spanish crown had determined to split the region in two parallel lines, forming the governorship of \"Nueva Castilla\" (from the 1° to the 14° latitude, close to Pisco), and that of \"Nueva Toledo\" (from the 14° to the 25° latitude, in Taltal, Chile), assigning the first to Francisco Pizarro and the second to Diego de Almagro. The crown had previously assigned Almagro the governorship of Cuzco, and as such De Almagro was heading there when Charles V divided the territory between Nueva Castilla and Nueva Toledo. This might have been the reason why Almagro did not immediately confront Pizarro for Cuzco, and promptly decided to embark on his new quest for the discovery of the riches of Chile.\n\nCharles V had given Diego a grant extending two hundred leagues south of Francisco Pizarro's. Francisco and Diego concluded a new contract on 12 June 1535, in which they agreed to share future discoveries equally. Diego raised an expedition for Chile, expecting it \"would lead to even greater riches than they had found in Peru.\" Almagro prepared the way by sending ahead three of his Spanish soldiers, the religious chief of the Inca empire, \"Willaq Umu,\" and Paullo Topa, brother of \"Manco Inca Yupanqui.\" De Almagro sent Juan de Saavedra forward with one hundred and fifty men, and soon followed them with additional forces. Saavedra established on January 23, 1535 the first Spanish settlement in Bolivia near the Inca regional capital of Paria.\n\nAlmagro left Cuzco on July 3, 1535 with his supporters and stopped at Moina until the 20th of that month. Meanwhile, Francisco Pizarro's brother, Juan Pizarro, had arrested Inca Manco Inca Yupanqui, further complicating De Almagro's plans as it heavily increased the dissatisfaction of the Indians submitted to Spanish rule. Not having formally been appointed governor of any territories in the Capitulation of Toledo in 1528, however, forcing him to declare himself \"adelantado\" (governor) of Nueva Toledo, or southern Peru and present-day Chile. Some sources suggest Almagro received such a requirement in 1534 by the Spanish king and was officially declared governor of New Toledo.\n\nOnce he left Moina, De Almagro followed the Inca trail followed by 750 Spaniards deciding to join him in quest for the gold lost in the ransom of Atahualpa, which had mainly benefited the Pizarro brothers and their supporters. After crossing the Bolivian mountain range and traveling past Lake Titicaca, Almagro arrived on the shores of the Desaguadero River and finally set up camp in Tupiza. From there, the expedition stopped at Chicoana and then turned to the southeast to cross the Andes mountains.\n\nThe expedition turned out to be a difficult and exhausting endeavor. The hardest phase was the crossing of the Andean cordilleras: the cold, hunger and tiredness meant the death of various Spanish and natives, but mainly slaves who were not accustomed to such rigorous climate.\n\nUpon this point, De Almagro determined everything was a failure. He ordered a small group under Rodrigo Orgonez on a reconnaissance of the country to the south.\n\nBy luck, these men found the Valley of Copiapó, where Gonzalo Calvo Barrientos, a Spanish soldier whom Pizarro had expelled from Peru for stealing objects the Inca had offered for his ransom, had already established a friendship with the local natives. There, in the valley of the river Copiapó, Almagro took official possession of Chile and claimed it in the name of King Charles V.\n\nDe Almagro promptly initiated the exploration of the new territory, starting up the valley the Aconcagua River, where he was well received by the natives. However, the intrigues of his interpreter, Felipillo, who had previously helped Pizarro in dealing with \"Atahualpa\", almost thwarted De Almagro's efforts. Felipillo had secretly urged the local natives to attack the Spanish, but they desisted, not understanding the dangers that they posed. De Almagro directed Gómez de Alvarado along with 100 horsemen and 100 foot to continue the exploration, which ended in the confluence of the Ñuble and Itata rivers. The Battle of Reinohuelén between the Spanish and hostile Mapuche Indians forced the explorers to return to the north.\n\nDe Almagro's own reconnaissance of the land and the bad news of Gómez de Alvarado's encounter with the fierce Mapuche, along with the bitter cold winter that settled ferociously upon them, only served to confirm that everything had failed. He never found gold or the cities which Incan scouts had told him lay ahead, only communities of the indigenous population who lived from subsistence agriculture. Local tribes put up fierce resistance to the Spanish forces. The exploration of the territories of Nueva Toledo, which lasted 2 years, was marked by a complete failure for De Almagro. Despite this, at first he thought staying and founding a city would serve well for his honor. The initial optimism that led Almagro to bring his son he had with the indigenous Panamanian Ana Martínez to Chile had faded.\n\nSome historians have suggested that, but for the urging of his senior explorers, De Almagro would probably have stayed permanently in Chile. He was urged to return to Peru and this time take definitive possession of Cuzco, so as to consolidate an inheritance for his son. Dismayed with his experience in the south, Almagro made plans of return to Peru. He never officially founded a city in the territory of what is now Chile.\n\nThe withdrawal of the Spanish from valleys of Chile was violent: Almagro authorized his soldiers to ransack the natives' properties, leaving their soil desolate. In addition, the Spanish soldiers took natives captive to serve as slaves. The locals were captured, tied together, and forced to carry the heavy loads belonging to the conquistadors.\n\nAfter the exhausting crossing of the Atacama Desert, mainly due to the weather conditions, Almagro finally reached Cuzco, Peru, in 1537. According to some authors, it was during this time that the Spanish term \"\"roto\"\" (torn), used by Peruvians to refer to Chileans, was first coined. De Almagro's disappointed troops returned to Cuzco with their \"torn clothes\" due to the extensive and laborious passage on foot by the Atacama Desert.\n\nAfter his return, De Almagro was surprised to learn of the Inca Manco's rebellion. Diego de Almagro sent an embassy to the Inca, but they mistrusted all of the Spaniards by this time. Hernando Pizarro's men formed an uneasy truce with De Almagro's men, surveying to determine the boundaries of their leaders' royal grants. They needed to determine in which portion the city of Cuzco was located. However, De Almagro's troops quickly took the city and imprisoned the Pizarro brothers, Hernando and Gonzalo, on the night of 8 April 1537.\n\nAfter occupying Cuzco, De Almagro confronted an army sent by Francisco Pizarro to liberate his brothers. Alonso de Alvarado commanded it and was defeated during the Battle of Abancay on July 12, 1537. He and some of his men were imprisoned. Later, Gonzalo Pizarro and De Alvarado escaped prison. Subsequent negotiations between Francisco Pizarro and De Almagro concluded with the liberation of Hernando, the third Pizarro brother, in return for conceding control and administration of Cuzco to De Almagro. Pizarro never intended to give up the city permanently, but was buying time to organize an army strong enough to defeat Almagro's troops.\n\nDuring this time Almagro fell ill, and Pizarro and his brothers grabbed the opportunity to defeat him and his followers. The Almagristas were defeated at Las Salinas in April 1538, with Orgóñez being killed on the field of battle. De Almagro fled to Cuzco, still in the hands of his loyal supporters, but found only temporary refuge; the forces of the Pizarro brothers entered the city without resistance. Once captured, Almagro was humiliated by Hernando Pizarro and his requests to appeal to the King were ignored.\n\nWhen Diego de Almagro begged for his life, Hernando responded:\n\n\"-he was surprised to see Almagro demean himself in a manner so unbecoming a brave cavalier, that his fate was no worse than had befallen many a soldier before him; and that, since God had given him the grace to be a Christian, he should employ his remaining moments in making up his account with Heaven!\"\n\nAlmagro was condemned to death and executed by \"garrote\" in his dungeon, and then decapitated, on July 8, 1538. His corpse was taken to the public Plaza Mayor of Cuzco, where a herald proclaimed his crimes. Hernan Ponce de Leon took his body and buried him in the church of Our Lady of Mercy in Cuzco.\n\nDiego de Almagro II (1520–1542), known as \"El Mozo\" (The Lad), son of Diego de Almagro I, whose mother was an Indian girl of Panama, became the foil of the conspirators who had put Pizarro to the sword. Pizarro was murdered on June 26, 1541; the conspirators promptly proclaimed the lad De Almagro Governor of Peru. From various causes, all of the conspirators either died or were killed except for one, who was executed after the lad Almagro gave an order. The lad De Almagro fought the desperate battle of Chupas on September 16, 1542, escaped to Cuzco, but was arrested, immediately condemned to death, and executed in the great square of the city.\n\n\n\n"}
{"id": "8363", "url": "https://en.wikipedia.org/wiki?curid=8363", "title": "Divinity", "text": "Divinity\n\nIn religion, divinity or godhead is the state of things that are believed to come from a supernatural power or deity, such as a god, supreme being, creator deity, or spirits, and are therefore regarded as sacred and holy.\nSuch things are regarded as divine due to their transcendental origins or because their attributes or qualities are superior or supreme relative to things of the Earth. Divine things are regarded as eternal and based in truth, while material things are regarded as ephemeral and based in illusion. Such things that may qualify as divine are apparitions, visions, prophecies, miracles, and in some views also the soul, or more general things like resurrection, immortality, grace, and salvation. Otherwise what is or is not divine may be loosely defined, as it is used by different belief systems.\n\nThe root of the word \"divine\" is literally \"godly\" (from the Latin \"deus\", cf. \"Dyaus\", closely related to Greek \"zeus\", \"div\" in Persian and \"deva\" in Sanskrit), but the use varies significantly depending on which deity is being discussed. This article outlines the major distinctions in the conventional use of the terms.\n\nFor specific related academic terms, see Divinity (academic discipline), or Divine (Anglican).\n\nDivinity as a quality has two distinct usages:\nOverlap occurs between these usages because deities or godly entities are often identical with or identified by the powers and forces that are credited to them — in many cases a deity is merely a power or force personified — and these powers and forces may then be extended or granted to mortal individuals. For instance, Jehovah is closely associated with storms and thunder throughout much of the Old Testament. He is said to speak in thunder, and thunder is seen as a token of his anger. This power was then extended to prophets like Moses and Samuel, who caused thunderous storms to rain down on their enemies. (See and 1 Samuel 12:18.)\n\nDivinity always carries connotations of goodness, beauty, beneficence, justice, and other positive, pro-social attributes. In monotheistic faiths there is an equivalent cohort of malefic supernatural beings and powers, such as demons, devils, afreet, etc., which are not conventionally referred to as divine; \"demonic\" is often used instead. Pantheistic and polytheistic faiths make no such distinction; gods and other beings of transcendent power often have complex, ignoble, or even irrational motivations for their acts. Note that while the terms \"demon\" and \"demonic\" are used in monotheistic faiths as antonyms to \"divine\", they are in fact derived from the Greek word \"daimón\" (δαίμων), which itself translates as \"divinity\".\n\nThere are three distinct usages of \"divinity\" and \"divine\" in religious discourse:\n\nIn monotheistic faiths, the word \"divinity\" is often used to refer to the singular God central to that faith. Often the word takes the definite article and is capitalized — \"\"the Divinity\"\" — as though it were a proper name or definitive honorific. \n\"Divine\" — capitalized — may be used as an adjective to refer to the manifestations of such a Divinity or its powers: e.g. \"basking in the Divine presence...\"\n\nThe terms \"divinity\" and \"divine\" — uncapitalized, and lacking the definite article — are sometimes used as to denote 'god(s) or certain other beings and entities which fall short of absolute Godhood but lie outside the human realm. These include (by no means an exhaustive list):\n\nAs previously noted, divinities are closely related to the transcendent force(s) or power(s) credited to them, so much so that in some cases the powers or forces may themselves be invoked independently. This leads to the second usage of the word \"divine\" (and a less common usage of \"divinity\"): to refer to the operation of transcendent power in the world.\n\nIn its most direct form, the operation of transcendent power implies some form of divine intervention. For pan- and polytheistic faiths this usually implies the direct action of one god or another on the course of human events. In Greek legend, for instance, it was Poseidon (god of the sea) who raised the storms which blew Odysseus' craft off course on his return journey, and Japanese tradition holds that a god-sent wind saved them from Mongol invasion. Prayers or propitiations are often offered to specific gods of pantheisms to garner favorable interventions in particular enterprises: e.g. safe journeys, success in war, or a season of bountiful crops. Many faiths around the world — from Japanese Shinto and Chinese traditional religion, to certain African practices and the faiths derived from those in the Caribbean, to Native American beliefs — hold that ancestral or household deities offer daily protection and blessings. In monotheistic religions, divine intervention may take very direct forms: miracles, visions, or intercessions by blessed figures.\n\nTranscendent force or power may also operate through more subtle and indirect paths. Monotheistic faiths generally support some version of divine providence, which acknowledges that the divinity of the faith has a profound but unknowable plan always unfolding in the world. Unforeseeable, overwhelming, or seemingly unjust events are often thrown on 'the will of the Divine', in deferences like the Muslim \"inshallah\" ('as God wills it') and Christian 'God works in mysterious ways'. Often such faiths hold out the possibility of divine retribution as well, where the divinity will unexpectedly bring evil-doers to justice through the conventional workings of the world; from the subtle redressing of minor personal wrongs, to such large-scale havoc as the destruction of Sodom and Gomorrah or the biblical Great Flood. Other faiths are even more subtle: the doctrine of \"karma\" shared by Buddhism and Hinduism is a divine law similar to divine retribution but without the connotation of punishment: our acts, good or bad, intentional or unintentional, reflect back on us as part of the natural working of the universe. Philosophical Taoism also proposes a transcendent operant principle — transliterated in English as \"tao\" or \"dao\", meaning 'the way' — which is neither an entity or a being per se, but reflects the natural ongoing process of the world. Modern western mysticism and new age philosophy often use the term 'the Divine' as a noun in this latter sense: a non-specific principle or being that gives rise to the world, and acts as the source or wellspring of life. In these latter cases the faiths do not promote deference, as happens in monotheisms; rather each suggests a path of action that will bring the practitioner into conformance with the divine law: \"ahimsa\" — 'no harm' — for Buddhist and Hindu faiths; \"de\" or \"te\" — 'virtuous action' — in Taoism; and any of numerous practices of peace and love in new age thinking.\n\nIn the third usage, extensions of divinity and divine power are credited to living, mortal individuals. Political leaders are known to have claimed actual divinity in certain early societies — the ancient Egyptian Pharaohs being the premier case — taking a role as objects of worship and being credited with superhuman status and powers. More commonly, and more pertinent to recent history, leaders merely claim some form of divine mandate, suggesting that their rule is in accordance with the will of God. The doctrine of the divine right of kings was introduced as late as the 17th century, proposing that kings rule by divine decree; Japanese Emperors ruled by divine mandate until the inception of the Japanese constitution after World War II\n\nLess politically, most faiths have any number of people that are believed to have been touched by divine forces: saints, prophets, heroes, oracles, martyrs, and enlightened beings, among others. Saint Francis of Assisi, in Catholicism, is said to have received instruction directly from God and it is believed that he grants plenary indulgence to all who confess their sins and visit his chapel on the appropriate day. In Greek mythology, Achilles' mother bathed him in the river Styx to give him immortality, and Hercules — as the son of Zeus — inherited near-godly powers. In religious Taoism, Lao Tsu is venerated as a saint with his own powers. Various individuals in the Buddhist faith, beginning with Siddhartha, are considered to be enlightened, and in religious forms of Buddhism they are credited with divine powers. Muhammad and Christ, in their respective traditions, are each said to have performed divine miracles.\n\nIn general, mortals with divine qualities are carefully distinguished from the deity or deities in their religion's main pantheon. Even the Christian faith, which generally holds Christ to be identical to God, distinguishes between God the Father and Christ the begotten Son. There are, however, certain esoteric and mystical schools of thought, present in many faiths — Sufis in Islam, Gnostics in Christianity, Advaitan Hindus, Zen Buddhists, as well as several non-specific perspectives developed in new age philosophy — which hold that all humans are in essence divine, or unified with the Divine in a non-trivial way. Such divinity, in these faiths, would express itself naturally if it were not obscured by the social and physical worlds we live in; it needs to be brought to the fore through appropriate spiritual practices.\n\nIn traditional Christian theology, the concept and nature of divinity always has its source ultimately from God himself. It's the state or quality of being divine, and the term can denote Godly nature or character. In Hebrew, the terms would usually be \"el\", \"elohim\", and in Greek usually \"theos\", or \"theias\". The divinity in the Bible is considered the Godhead itself, or God in general. Or it may have reference to a deity. Even angels in the Psalms are considered divine or \"elohim\", as spirit beings, in God's form. Redeemed Christians, when taken to heaven as immortalized born-again believers, according to Biblical verses, are said to partake of the \"divine nature\". (Psalm 8:5; Hebrews 2:9; 2 Peter 1:4)\n\nIn the Christian Greek Scriptures of the Bible, the Greek word θεῖον (\"theion\") in the Douay Version, is translated as \"divinity\". Examples are below:\n\nThe word translated as either \"deity\", \"Godhead\", or \"divinity\" in the Greek New Testament is also the Greek word θεότητος (\"theotētos\"), and the one Verse that contains it is this:\nColossians 2:9\n\nThe word \"divine\" in the New Testament is the Greek word θείας (\"theias\"), and is the adjective form of \"divinity\". Biblical examples from the King James Bible are below:\n\nThe most prominent conception of divine entities in The Church of Jesus Christ of Latter-day Saints (LDS Church) is the Godhead, a divine council of three distinct beings: Elohim (the Father), Jehovah (the Son, or Jesus), and the Holy Spirit. Joseph Smith described a nontrinitarian Godhead, with God the Father and Jesus Christ each having individual physical bodies, and the Holy Spirit as a distinct personage with a spirit body. Smith also introduced the existence of a Heavenly Mother in the King Follett Discourse, but very little is acknowledged or known beyond her existence.\n\nMormons hold a belief in the divine potential of humanity; Smith taught a form of divinization where mortal men and women can become like god through salvation and exaltation. Lorenzo Snow succinctly summarized this using a couplet, which is often repeated within the LDS Church: \"As man now is, God once was: As God now is, man may be.\"\n\n"}
{"id": "8367", "url": "https://en.wikipedia.org/wiki?curid=8367", "title": "Depth of field", "text": "Depth of field\n\nIn optics, particularly as it relates to film and photography, depth of field (DOF), also called \"focus range\" or \"effective focus range\", is the distance between the nearest and farthest objects in a scene that appear acceptably sharp in an image. Although a lens can precisely focus at only one distance at a time, the decrease in sharpness is gradual on each side of the focused distance, so that within the DOF, the unsharpness is imperceptible under normal viewing conditions.\n\nIn some cases, it may be desirable to have the entire image sharp, and a large DOF is appropriate. In other cases, a small DOF may be more effective, emphasizing the subject while de-emphasizing the foreground and background. In cinematography, a large DOF is often called deep focus, and a small DOF is often called shallow focus.\n\nPrecise focus is possible at only one distance; at that distance, a point object will produce a point image. At any other distance, a point object is \"defocused\", and will produce a blur spot shaped like the aperture, which for the purpose of analysis is usually assumed to be circular. When this circular spot is sufficiently small, it is indistinguishable from a point, and appears to be in focus; it is rendered as \"acceptably sharp\". The diameter of the circle increases with distance from the point of focus; the largest circle that is indistinguishable from a point is known as the \"acceptable circle of confusion\", or informally, simply as the \"circle of confusion\". The acceptable circle of confusion is influenced by visual acuity, viewing conditions, and the amount by which the image is enlarged (Ray 2000, 52–53). The increase of the circle diameter with defocus is gradual, so the limits of depth of field are not hard boundaries between sharp and unsharp.\n\nFor 35 mm motion pictures, the image area on the film is roughly 22 mm by 16 mm. The limit of tolerable error was traditionally set at 0.05 mm (0.002 in) diameter, while for 16 mm film, where the size is about half as large, the tolerance is stricter, 0.025 mm (0.001 in). More modern practice for 35 mm productions set the circle of confusion limit at 0.025 mm (0.001 in).\n\nFor full-frame 35mm still photography, the circle of confusion is usually chosen to be about 1/30 mm. Because the human eye is capable of resolving a spot with diameter about 1/4 mm at 25 cm distance from the viewing eye, and the 35 mm negative needs about an 8X enlargement to make an 8x10 inch print, it is sometimes argued that the criterion should be about 1/32 mm on the 35mm negative, but 1/30 mm is close enough.\n\nFor 6x6 cm format enlarged to 8x8 inches and viewed at 25 cm, the enlargement is 3.4X, hence the circle of confusion criterion is about 1/(3.4 x 4) = 0.07 mm.\n\nSimilarly, for subminiature photography (for example the Tessina) with a frame format of 14x21mm, 8x12 inches corresponds to 14.5X enlargement, hence circle of confusion limit about 0.017 mm.\n\nMany sources propose CoC limits as a fraction of the film format diagonal, typically 1/1000 in the early twentieth century to 1/1500 more recently. The three formats above at fraction 1/1500 would use 0.029 (about 1/32), 0.056, and 0.017 mm.\n\nTraditional depth-of-field formulas and tables assume equal circles of confusion for near and far objects. Some authors, such as Merklinger (1992), have suggested that distant objects often need to be much sharper to be clearly recognizable, whereas closer objects, being larger on the film, do not need to be so sharp. The loss of detail in distant objects may be particularly noticeable with extreme enlargements. Achieving this additional sharpness in distant objects usually requires focusing beyond the hyperfocal distance, sometimes almost at infinity. For example, if photographing a cityscape with a traffic bollard in the foreground, this approach, termed the \"object field method\" by Merklinger, would recommend focusing very close to infinity, and stopping down to make the bollard sharp enough. With this approach, foreground objects cannot always be made perfectly sharp, but the loss of sharpness in near objects may be acceptable if recognizability of distant objects is paramount.\n\nOther authors (Adams 1980, 51) have taken the opposite position, maintaining that slight unsharpness in foreground objects is usually more disturbing than slight unsharpness in distant parts of a scene.\n\nMoritz von Rohr also used an object field method, but unlike Merklinger, he used the conventional criterion of a maximum circle of confusion diameter in the image plane, leading to unequal front and rear depths of field.\n\nSeveral other factors, such as subject matter, movement, camera-to-subject distance, lens focal length, selected lens \"f\"-number, format size, and circle of confusion criteria also influence when a given defocus becomes noticeable. The combination of focal length, subject distance, and format size defines magnification at the film / sensor plane.\n\nDOF is determined by subject magnification at the film / sensor plane and the selected lens aperture or \"f\"-number. For a given \"f\"-number, increasing the magnification, either by moving closer to the subject or using a lens of greater focal length, decreases the DOF; decreasing magnification increases DOF. For a given subject magnification, increasing the \"f\"-number (decreasing the aperture diameter) increases the DOF; decreasing \"f\"-number decreases DOF.\n\nIf the original image is enlarged to make the final image, the circle of confusion in the original image must be smaller than that in the final image by the ratio of enlargement. Cropping an image and enlarging to the same size final image as an uncropped image taken under the same conditions is equivalent to using a smaller format under the same conditions, so the cropped image has less DOF. (Stroebel 1976, 134, 136–37).\n\nWhen focus is set to the hyperfocal distance, the DOF extends from half the hyperfocal distance to infinity, and the DOF is the largest possible for a given \"f\"-number.\n\nThe comparative DOFs of two different format sizes depend on the conditions of the comparison. The DOF for the smaller format can be either more than or less than that for the larger format. In the discussion that follows, it is assumed that the final images from both formats are the same size, are viewed from the same distance, and are judged with the same circle of confusion criterion. (Derivations of the effects of format size are given under Derivation of the DOF formulae.)\n\nWhen the \"same picture\" is taken in two different format sizes from the same distance at the same \"f\"-number with lenses that give the same angle of view, and the final images (e.g., in prints, or on a projection screen or electronic display) are the same size, DOF is, to a first approximation, inversely proportional to format size (Stroebel 1976, 139). Though commonly used when comparing formats, the approximation is valid only when the subject distance is large in comparison with the focal length of the larger format and small in comparison with the hyperfocal distance of the smaller format.\n\nMoreover, the larger the format size, the longer a lens will need to be to capture the same framing as a smaller format. In motion pictures, for example, a frame with a 12 degree horizontal field of view will require a 50 mm lens on 16 mm film, a 100 mm lens on 35 mm film, and a 250 mm lens on 65 mm film. Conversely, using the same focal length lens with each of these formats will yield a progressively wider image as the film format gets larger: a 50 mm lens has a horizontal field of view of 12 degrees on 16 mm film, 23.6 degrees on 35 mm film, and 55.6 degrees on 65 mm film. Therefore, because the larger formats require longer lenses than the smaller ones, they will accordingly have a smaller depth of field. Compensations in exposure, framing, or subject distance need to be made in order to make one format look like it was filmed in another format.\n\nMany small-format digital SLR camera systems allow using many of the same lenses on both full-frame and \"cropped format\" cameras. If, for the same focal length setting, the subject distance is adjusted to provide the \"same field of view\" at the subject, at the same \"f\"-number and final-image size, the smaller format has \"greater\" DOF, as with the \"same picture\" comparison above. If pictures are taken from the \"same distance\" using the same \"f\"-number, same focal length, and the final images are the same size, the smaller format has \"less\" DOF. If pictures taken from the same subject distance using the same focal length, are given the \"same enlargement\", both final images will have the \"same\" DOF. The pictures from the two formats will differ because of the different angles of view. If the larger format is cropped to the captured area of the smaller format, the final images will have the same angle of view, have been given the same enlargement, and have the same DOF.\n\nIn many cases, the DOF is fixed by the requirements of the desired image. For a given DOF and field of view, the required \"f\"-number is proportional to the format size. For example, if a 35 mm camera required 11, a 4×5 camera would require 45 to give the same DOF. For the same ISO speed, the exposure time on the 4×5 would be sixteen times as long; if the 35 camera required 1/250 second, the 4×5 camera would require 1/15 second. The longer exposure time with the larger camera might result in motion blur, especially with windy conditions, a moving subject, or an unsteady camera.\n\nAdjusting the \"f\"-number to the camera format is equivalent to maintaining the same absolute aperture diameter; when set to the same absolute aperture diameters, both formats have the same DOF.\n\nComparison of fast standard lenses in the four main formats when used for portraiture with appropriate circles of confusion to produce an uncropped image at 10x8 inches to be viewed at 25 cm show that the following settings with similar aperture diameters produce similar DoF:\nFor any of these, doubling the f-number will approximately double the depth of field.\n\nWhen the lens axis is perpendicular to the image plane, as is normally the case, the plane of focus (POF) is parallel to the image plane, and the DOF extends between parallel planes on either side of the POF. When the lens axis is not perpendicular to the image plane, the POF is no longer parallel to the image plane; the ability to rotate the POF is known as the Scheimpflug principle. Rotation of the POF is accomplished with camera movements (tilt, a rotation of the lens about a horizontal axis, or swing, a rotation about a vertical axis). Tilt and swing are available on most view cameras, and are also available with specific lenses on some small- and medium-format cameras.\n\nWhen the POF is rotated, the near and far limits of DOF are no longer parallel; the DOF becomes wedge-shaped, with the apex of the wedge nearest the camera (Merklinger 1993, 31–32; Tillmanns 1997, 71). With tilt, the height of the DOF increases with distance from the camera; with swing, the width of the DOF increases with distance.\n\nIn some cases, rotating the POF can better fit the DOF to the scene, and achieve the required sharpness at a smaller f-number. Alternatively, rotating the POF, in combination with a small f-number, can minimize the part of an image that is within the DOF.\n\nFor a given subject framing and camera position, the DOF is controlled by the lens aperture diameter, which is usually specified as the f-number, the ratio of lens focal length to aperture diameter. Reducing the aperture diameter (increasing the f-number) increases the DOF because the circle of confusion is shrunk directly and indirectly by reducing the light hitting the outside of the lens which is focused to a different point than light hitting the inside of the lens due to spherical aberration caused by the construction of the lens; however, it also reduces the amount of light transmitted, and increases diffraction, placing a practical limit on the extent to which DOF can be increased by reducing the aperture diameter.\n\nMotion pictures make only limited use of this control; to produce a consistent image quality from shot to shot, cinematographers usually choose a single aperture setting for interiors and another for exteriors, and adjust exposure through the use of camera filters or light levels. Aperture settings are adjusted more frequently in still photography, where variations in depth of field are used to produce a variety of special effects.\n\nThe advent of digital technology in photography has provided additional means of controlling the extent of image sharpness; some methods allow extended DOF that would be impossible with traditional techniques, and some allow the DOF to be determined after the image is made.\n\nFocus stacking is a digital image processing technique which combines multiple images taken at different focus distances to give a resulting image with a greater depth of field than any of the individual source images. Available programs for multi-shot DOF enhancement include Adobe Photoshop, Syncroscopy AutoMontage, PhotoAcute Studio, Helicon Focus and CombineZ. Getting sufficient depth of field can be particularly challenging in macro photography. The images to the right illustrate the extended DOF that can be achieved by combining multiple images.\n\nWavefront coding is a method that convolves rays in such a way that it provides an image where fields are in focus simultaneously with all planes out of focus by a constant amount.\n\nA plenoptic camera uses a microlens array to capture 4D light field information about a scene.\n\nColour apodization is a technique combining a modified lens design with image processing to achieve an increased depth of field. The lens is modified such that each colour channel has a different lens aperture. For example, the red channel may be f/2.4, green may be f/2.4, whilst the blue channel may be f/5.6. Therefore, the blue channel will have a greater depth of field than the other colours. The image processing identifies blurred regions in the red and green channels and in these regions copies the sharper edge data from the blue channel. The result is an image that combines the best features from the different f-numbers, (Kay 2011).\n\nIn 2013, Nokia implemented DOF control in some of its high-end smartphones, called Refocus, which can change a picture's depth of field after the picture is taken. It works best when there are close-up and distant objects in the frame.\n\nIf the camera position and image framing (i.e., angle of view) have been chosen, the only means of controlling DOF is the lens aperture. Most DOF formulas imply that any arbitrary DOF can be achieved by using a sufficiently large f-number. Because of diffraction, however, this isn't really true. Once a lens is stopped down to where most aberrations are well corrected, stopping down further will decrease sharpness in the plane of focus. At the DOF limits, however, further stopping down decreases the size of the defocus blur spot, and the overall sharpness may still increase. Eventually, the defocus blur spot becomes negligibly small, and further stopping down serves only to decrease sharpness even at DOF limits (Gibson 1975, 64). There is thus a tradeoff between sharpness in the POF and sharpness at the DOF limits. But the sharpness in the POF is always greater than that at the DOF limits; if the blur at the DOF limits is imperceptible, the blur in the POF is imperceptible as well.\n\nFor general photography, diffraction at DOF limits typically becomes significant only at fairly large f-numbers; because large f-numbers typically require long exposure times, motion blur may cause greater loss of sharpness than the loss from diffraction. The size of the diffraction blur spot depends on the effective f-number formula_1, however, so diffraction is a greater issue in close-up photography, and the tradeoff between DOF and overall sharpness can become quite noticeable (Gibson 1975, 53; Lefkowitz 1979, 84).\n\nMany lenses for small- and medium-format cameras include scales that indicate the DOF for a given focus distance and f-number; the 35 mm lens in the image is typical. That lens includes distance scales in feet and meters; when a marked distance is set opposite the large white index mark, the focus is set to that distance. The DOF scale below the distance scales includes markings on either side of the index that correspond to f-numbers. When the lens is set to a given f-number, the DOF extends between the distances that align with the f-number markings.\n\nSome cameras have the DOF scale not on lens barrel, but on focusing knob or dial; for example, the Rolleiflex TLR has its DOF scale on the focusing knob; the subminiature camera Tessina has DOF a scale on the focusing dial.\n\nWhen the 35 mm lens above is set to f/11 and focused at approximately 1.3 m, the DOF (a \"zone\" of acceptable sharpness) extends from 1 m to 2 m. Conversely, the required focus and f-number can be determined from the desired DOF limits by locating the near and far DOF limits on the lens distance scale and setting focus so that the index mark is centered between the near and far distance marks. The required f-number is determined by finding the markings on the DOF scale that are closest to the near and far distance marks (Ray 1994, 315). For the 35 mm lens above, if it were desired for the DOF to extend from 1 m to 2 m, focus would be set so that index mark was centered between the marks for those distances, and the aperture would be set to f/11.\n\nThe focus so determined would be about 1.3 m, the approximate harmonic mean of the near and far distances. See the section Focus and \"f\"-number from DOF limits for additional discussion.\n\nIf the marks for the near and far distances fall outside the marks for the largest f-number on the DOF scale, the desired DOF cannot be obtained; for example, with the 35 mm lens above, it is not possible to have the DOF extend from 0.7 m to infinity. The DOF limits can be determined visually, by focusing on the farthest object to be within the DOF and noting the distance mark on the lens distance scale, and repeating the process for the nearest object to be within the DOF.\n\nSome distance scales have markings for only a few distances; for example, the 35 mm lens above shows only 3 ft and 5 ft on its upper scale. Using other distances for DOF limits requires visual interpolation between marked distances. Since the distance scale is nonlinear, accurate interpolation can be difficult. In most cases, English and metric distance markings are not coincident, so using both scales to note focused distances can sometimes lessen the need for interpolation. Many autofocus lenses have smaller distance and DOF scales and fewer markings than do comparable manual-focus lenses, so that determining focus and f-number from the scales on an autofocus lens may be more difficult than with a comparable manual-focus lens. In most cases, determining these settings using the lens DOF scales on an autofocus lens requires that the lens or camera body be set to manual focus.\n\nOn a view camera, the focus and f-number can be obtained by measuring the \"focus spread\" and performing simple calculations. The procedure is described in more detail in the section Focus and f-number from DOF limits. Some view cameras include DOF calculators that indicate focus and f-number without the need for any calculations by the photographer (Tillmanns 1997, 67–68; Ray 2002, 230–31).\n\nThe hyperfocal distance is the nearest focus distance at which the DOF extends to infinity; focusing the camera at the hyperfocal distance results in the largest possible depth of field for a given f-number (Ray 2000, 55). Focusing \"beyond\" the hyperfocal distance does not increase the far DOF (which already extends to infinity), but it does decrease the DOF in front of the subject, decreasing the total DOF. Some photographers consider this wasting DOF; however, see Object field methods above for a rationale for doing so. Focusing on the hyperfocal distance is a special case of zone focusing in which the far limit of DOF is at infinity.\n\nIf the lens includes a DOF scale, the hyperfocal distance can be set by aligning the infinity mark on the distance scale with the mark on the DOF scale corresponding to the f-number to which the lens is set. For example, with the 35 mm lens shown above set to f/11, aligning the infinity mark with the '11' to the left of the index mark on the DOF scale would set the focus to the hyperfocal distance.\n\nSome cameras have their hyperfocal distance marked on the focus dial. For example, on the Minox LX focusing dial there is a red dot between 2 m and infinity; when the lens is set at the red dot, that is, focused at the hyperfocal distance, the depth of field stretches from 2 m to infinity.\n\nThe Zeiss Ikon Contessa camera has 20 ft marked in red, and aperture 8 marked in red; this is the snapshot hyperfocal setting.\n\nDepth of field can be anywhere from a fraction of a millimeter to virtually infinite. In some cases, such as landscapes, it may be desirable to have the entire image sharp, and a large DOF is appropriate. In other cases, artistic considerations may dictate that only a part of the image be in focus, emphasizing the subject while de-emphasizing the background, perhaps giving only a suggestion of the environment (Langford 1973, 81). For example, a common technique in melodramas and horror films is a closeup of a person's face, with someone just behind that person visible but out of focus. A portrait or close-up still photograph might use a small DOF to isolate the subject from a distracting background. The use of limited DOF to emphasize one part of an image is known as \"selective focus\", \"differential focus\" or \"shallow focus\".\n\nAlthough a small DOF implies that other parts of the image will be unsharp, it does not, by itself, determine \"how\" unsharp those parts will be. The amount of background (or foreground) blur depends on the distance from the plane of focus, so if a background is close to the subject, it may be difficult to blur sufficiently even with a small DOF. In practice, the lens f-number is usually adjusted until the background or foreground is acceptably blurred, often without direct concern for the DOF.\n\nSometimes, however, it is desirable to have the entire subject sharp while ensuring that the background is sufficiently unsharp. When the distance between subject and background is fixed, as is the case with many scenes, the DOF and the amount of background blur are not independent. Although it is not always possible to achieve both the desired subject sharpness and the desired background unsharpness, several techniques can be used to increase the separation of subject and background.\n\nFor a given scene and subject magnification, the background blur increases with lens focal length. If it is not important that background objects be unrecognizable, background de-emphasis can be increased by using a lens of longer focal length and increasing the subject distance to maintain the same magnification. This technique requires that sufficient space in front of the subject be available; moreover, the perspective of the scene changes because of the different camera position, and this may or may not be acceptable.\n\nThe situation is not as simple if it is important that a background object, such as a sign, be unrecognizable. The magnification of background objects also increases with focal length, so with the technique just described, there is little change in the recognizability of background objects. However, a lens of longer focal length may still be of some help; because of the narrower angle of view, a slight change of camera position may suffice to eliminate the distracting object from the field of view.\n\nAlthough tilt and swing are normally used to maximize the part of the image that is within the DOF, they also can be used, in combination with a small f-number, to give selective focus to a plane that isn't perpendicular to the lens axis. With this technique, it is possible to have objects at greatly different distances from the camera in sharp focus and yet have a very shallow DOF. The effect can be interesting because it differs from what most viewers are accustomed to seeing.\n\nThe DOF beyond the subject is always greater than the DOF in front of the subject. When the subject is at the hyperfocal distance or beyond, the far DOF is infinite, so the ratio is 1:∞; as the subject distance decreases, near:far DOF ratio increases, approaching unity at high magnification. For large apertures at typical portrait distances, the ratio is still close to 1:1. The oft-cited rule that 1/3 of the DOF is in front of the subject and 2/3 is beyond (a 1:2 ratio) is true only when the subject distance is 1/3 the hyperfocal distance.\n\nAs a lens is stopped down, the defocus blur at the DOF limits decreases but diffraction blur increases. The presence of these two opposing factors implies a point at which the combined blur spot is minimized (Gibson 1975, 64); at that point, the f-number is optimal for image sharpness.\nIf the final image is viewed under normal conditions (e.g., an 8″×10″ image viewed at 10″), it may suffice to determine the f-number using criteria for minimum required sharpness, and there may be no practical benefit from further reducing the size of the blur spot. But this may not be true if the final image is viewed under more demanding conditions, e.g., a very large final image viewed at normal distance, or a portion of an image enlarged to normal size (Hansma 1996). Hansma also suggests that the final-image size may not be known when a photograph is taken, and obtaining the maximum practicable sharpness allows the decision to make a large final image to be made at a later time.\n\nHansma (1996) and Peterson (1996) have discussed determining the combined effects of defocus and diffraction using a root-square combination of the individual blur spots. Hansma's approach determines the f-number that will give the maximum possible sharpness; Peterson's approach determines the minimum f-number that will give the desired sharpness in the final image, and yields a maximum focus spread for which the desired sharpness can be achieved. In combination, the two methods can be regarded as giving a maximum and minimum f-number for a given situation, with the photographer free to choose any value within the range, as conditions (e.g., potential motion blur) permit. Gibson (1975), 64) gives a similar discussion, additionally considering blurring effects of camera lens aberrations, enlarging lens diffraction and aberrations, the negative emulsion, and the printing paper. Couzin (1982) gave a formula essentially the same as Hansma's for optimal \"f\"-number, but did not discuss its derivation.\n\nHopkins (1955), Stokseth (1969), and Williams and Becklund (1989) have discussed the combined effects using the modulation transfer function. Conrad's Depth of Field in Depth (PDF), and Jacobson's Photographic Lenses Tutorial discuss the use of Hopkins's method specifically in regard to DOF.\n\nIn semiconductor photolithography applications, depth of field is extremely important as integrated circuit layout features must be printed with high accuracy at extremely small size. The difficulty is that the wafer surface is not perfectly flat, but may vary by several micrometres. Even this small variation causes some distortion in the projected image, and results in unwanted variations in the resulting pattern. Thus photolithography engineers take extreme measures to maximize the optical depth of field of the photolithography equipment. To minimize this distortion further, semiconductor manufacturers may use chemical mechanical polishing to make the wafer surface even flatter before lithographic patterning.\n\nA person may sometimes experience better vision in daylight than at night because of an increased depth of field due to constriction of the pupil (i.e., miosis).\n\nThe basis of these formulas is given in the section Derivation of the DOF formulae; refer to the diagram in that section for illustration of the quantities discussed below.\n\nLet formula_2 be the lens focal length,\nformula_3 be the lens f-number, and formula_4 be the\ncircle of confusion for a given image format. The\nhyperfocal distance formula_5 is given by\n\nLet formula_7 be the distance at which the camera is focused (the \"subject distance\"). When formula_7 is large in comparison with the lens focal length, the distance formula_9 from the camera to the near limit of DOF and the distance formula_10 from the camera to the far limit of DOF are\n\nand\n\nThe depth of field formula_13 is\n\nSubstituting for formula_5 and rearranging, DOF can be expressed as\n\nThus, for a given image format, depth of field is determined by three factors: the focal length of the lens, the f-number of the lens opening (the aperture), and the camera-to-subject distance.\n\nWhen the subject distance is the hyperfocal distance,\n\nand\n\nFor formula_19, the far limit of DOF is at infinity and the DOF is infinite; of course, only objects at or beyond the near limit of DOF will be recorded with acceptable sharpness.\n\nWhen the subject distance formula_7 approaches the focal length, using the formulas given above can result in significant errors. For close-up work, the hyperfocal distance has little applicability, and it usually is more convenient to express DOF in terms of image magnification. Let formula_21 be the magnification; when the subject distance is small in comparison with the hyperfocal distance,\n\nso that for a given magnification, DOF is independent of focal length. In other words, for the same subject magnification, at the same \"f\"-number, all focal lengths\nused on a given image format give approximately the same DOF.\n\nThe discussion thus far has assumed a symmetrical lens for which the entrance and exit pupils coincide with the front and rear nodal planes, and for which the pupil magnification (the ratio of exit pupil diameter to that of the entrance pupil) is unity. Although this assumption usually is reasonable for large-format lenses, it often is invalid for medium- and small-format lenses.\n\nWhen formula_23, the DOF for an asymmetrical lens is\n\nwhere formula_25 is the pupil magnification. When the pupil magnification is unity, this equation reduces to that for a symmetrical lens.\n\nExcept for close-up and macro photography, the effect of lens asymmetry is minimal. At unity magnification, however, the errors from neglecting the pupil magnification can be significant. Consider a telephoto lens with formula_26 and a retrofocus wide-angle lens with formula_27, at formula_28. The asymmetrical-lens formula gives formula_29 and formula_30, respectively. The symmetrical lens formula gives formula_31 in either case. The errors are −33% and 33%, respectively.\n\nFor given near and far DOF limits formula_9 and formula_10, the required f-number is smallest when focus is set to\n\nthe harmonic mean of the near and far distances. When the subject distance is large in comparison with the lens focal length, the required f-number is\n\nWhen the far limit of DOF is at infinity,\n\nand\n\nIn practice, these settings usually are determined on the image side of the lens, using measurements on the bed or rail with a view camera, or using lens DOF scales on manual-focus lenses for small- and medium-format cameras. If formula_38 and formula_39 are the image distances that correspond to the near and far limits of DOF, the required f-number is minimized when the image distance\nformula_40 is\n\nIn practical terms, focus is set to halfway between the near and far image distances. The required f-number is\n\nThe image distances are measured from the camera's image plane to the lens's image nodal plane, which is not always easy to locate. In most cases, focus and f-number can be determined with sufficient accuracy using the approximate formulas above, which require only the difference between the near and far image distances; view camera users sometimes refer to the difference formula_43 as the \"focus spread\" (Hansma 1996, 55). Most lens DOF scales are based on the same concept.\n\nThe focus spread is related to the depth of focus. Ray (2000, 56) gives two definitions of the latter. The first is the tolerance of the position of the image plane for which an object remains acceptably sharp; the second is that the limits of depth of focus are the image-side conjugates of the near and far limits of DOF. With the first definition, focus spread and depth of focus are usually close in value though conceptually different. With the second definition, focus spread and depth of focus are the same.\n\nIf a subject is at distance formula_7 and the foreground or background is at distance formula_45, let the distance between the subject and the foreground or background be indicated by\n\nThe blur disk diameter formula_47 of a detail at distance formula_48 from the subject can be expressed as a function of the subject magnification formula_49, focal length formula_2, f-number formula_3 or alternatively the diameter of the entrance pupil formula_52 (often called the aperture) according to\n\nThe minus sign applies to a foreground object, and the plus sign applies to a background object.\n\nThe blur increases with the distance from the subject; when formula_54, the detail\nis within the depth of field, and the blur is imperceptible. If the detail is only slightly outside the DOF, the blur may be only barely perceptible.\n\nFor a given subject magnification, f-number, and distance from the subject of the foreground or background detail, the degree of detail blur varies with the lens focal length. For a background detail, the blur increases with focal length; for a foreground detail, the blur decreases with focal length. For a given scene, the positions of the subject, foreground, and background usually are fixed, and the distance between subject and the foreground or background remains constant regardless of the camera position; however, to maintain constant magnification, the subject distance must vary if the focal length is changed. For small distance between the foreground or background detail, the effect of focal length is small; for large distance, the effect can be significant. For a reasonably distant background detail, the blur disk diameter is\n\ndepending only on focal length.\n\nThe blur diameter of foreground details is very large if the details are close to the lens.\n\nThe magnification of the detail also varies with focal length; for a given detail, the ratio of the blur disk diameter to imaged size of the detail is independent of focal length, depending only on the detail size and its distance from the subject. This ratio can be useful when it is important that the background be recognizable (as usually is the case in evidence or surveillance photography), or unrecognizable (as might be the case for a pictorial photographer using selective focus to isolate the subject from a distracting background). As a general rule, an object is recognizable if the blur disk diameter is one-tenth to one-fifth the size of the object or smaller (Williams 1990, 205), and unrecognizable when the blur disk diameter is the object size or greater.\n\nThe effect of focal length on background blur is illustrated in van Walree's article on Depth of field.\n\nThe distance scales on most medium- and small-format lenses indicate distance from the camera's image plane. Most DOF formulas, including those in this article, use the object distance formula_7 from the lens's front nodal plane, which often is not easy to locate. Moreover, for many zoom lenses and internal-focusing non-zoom lenses, the location of the front nodal plane, as well as focal length, changes with subject distance. When the subject distance is large in comparison with the lens focal length, the exact location of the front nodal plane is not critical; the distance is essentially the same whether measured from the front of the lens, the image plane, or the actual nodal plane. The same is not true for close-up photography; at unity magnification, a slight error in the location of the front nodal plane can result in a DOF error greater than the errors from any approximations in the DOF equations.\n\nThe asymmetrical lens formulas require knowledge of the pupil magnification, which usually is not specified for medium- and small-format lenses. The pupil magnification can be estimated by looking into the front and rear of the lens and measuring the diameters of the apparent apertures, and computing the ratio of rear diameter to front diameter (Shipman 1977, 144). However, for many zoom lenses and internal-focusing non-zoom lenses, the pupil magnification changes with subject distance, and several measurements may be required.\n\nMost DOF formulas, including those discussed in this article, employ several simplifications:\n\n\nThe lens designer cannot restrict analysis to Gaussian optics and cannot ignore lens aberrations. However, the requirements of practical photography are less demanding than those of lens design, and despite the simplifications employed in development of most DOF formulas, these formulas have proven useful in determining camera settings that result in acceptably sharp pictures. It should be recognized that DOF limits are not hard boundaries between sharp and unsharp, and that there is little point in determining DOF limits to a precision of many significant figures.\n\nA symmetrical lens is illustrated at right. The subject, at distance formula_7, is in focus at image distance formula_40. Point objects \nat distances formula_59 and formula_60 would be in focus at image distances formula_61 and formula_62, respectively; at image distance formula_40, they are imaged as blur spots. The depth of field is controlled by the aperture stop diameter formula_52; when the blur spot diameter is equal to the acceptable circle of confusion formula_4, the near and far limits of DOF are at formula_60 and formula_59. From similar triangles,\n\nand\n\nIt usually is more convenient to work with the lens f-number than the aperture diameter; the f-number formula_3 is related to the lens focal length formula_2 and the aperture diameter formula_52 by\n\nThe image distance formula_40 is related to an object distance formula_7 by the thin lens equation\n\nformula_77...(5)\n\nformula_78...(6)\n\nSolve the equations set (1) to (6) and obtain the exact solutions without any simplification\n\nand\n\nSolving equation (8) for the focus distance formula_7 and setting the far limit of DOF formula_10 to infinity gives\n\nwhere formula_5 is the hyperfocal distance. Setting the subject distance to the hyperfocal distance and solving for the near limit of DOF gives\n\nSubstituting the expression for hyperfocal distance into equations (7) and (8) for the near and far limits of DOF gives\n\nFor any practical value of formula_5, the focal length is negligible in comparison, so that\n\nSubstituting the approximate expression for hyperfocal distance into the formulas for the near and far limits of DOF gives\n\nand\n\nHowever, if one states by definition that formula_92, then coming\n\nand\n\nCombining, the depth of field formula_13 is\n\nMagnification formula_21 can be expressed as\n\nat the hyperfocal distance, the magnification formula_99 then is\n\nSubstituting formula_101 for formula_5 and simplifying gives\n\nIt is sometimes convenient to express DOF in terms of magnification formula_21. Substituting\n\nand\n\ninto the formula for DOF and rearranging gives\n\nafter Larmore (1965), 163).\n\nMultiplying the numerator and denominator of the exact formula above by\n\ngives\n\nIf the \"f\"-number and circle of confusion are constant, decreasing the focal length formula_2 increases the second term in the denominator, decreasing the denominator and increasing the value of the right-hand side, so that a shorter focal length gives greater DOF.\n\nThe term in parentheses in the denominator is the hyperfocal magnification formula_99, so that\n\nAs subject distance is decreased, the subject magnification increases, and eventually becomes large in comparison with the hyperfocal magnification. Thus the effect of focal length is greatest near the hyperfocal distance, and decreases as subject distance is decreased. However, the near/far perspective will differ for different focal lengths, so the difference in DOF may not be readily apparent.\n\nWhen formula_23, formula_114, and\n\nso that for a given magnification, DOF is essentially independent of focal length. Stated otherwise, for the same subject magnification and the same \"f\"-number, all focal lengths for a given image format give approximately the same DOF. This statement is true only when the subject distance is small in comparison with the hyperfocal distance, however.\n\nWhen the subject distance is large in comparison with the lens focal length,\n\nand\n\nso that\n\nFor formula_19, the far limit of DOF is at infinity and the DOF is infinite; of course, only objects at or beyond the near limit of DOF will be recorded with acceptable sharpness.\n\nWhen the subject distance formula_7 approaches the lens focal length, the focal length no longer is negligible, and the approximate formulas (11),(12) above cannot be used without introducing significant error. Use formular (9) and (10) instead.\n\nIt usually is more convenient to express DOF in terms of magnification. The distance is small in comparison with the hyperfocal distance, so the simplified formula\n\ncan be used with good accuracy. For a given magnification, DOF is independent of focal length.\n\nFrom the \"exact\" equations for near and far limits of DOF, the DOF in front of the subject is\n\nand the DOF beyond the subject is\n\nThe near:far DOF ratio is\n\nThis ratio is always less than unity; at moderate-to-large subject distances, formula_125, and\n\nWhen the subject is at the hyperfocal distance or beyond, the far DOF is infinite, and the near:far ratio is zero. It's commonly stated that approximately 1/3 of the DOF is in front of the subject and approximately 2/3 is beyond; however, this is true only when formula_127.\n\nAt closer subject distances, it's often more convenient to express the DOF ratio in terms of the magnification\n\nsubstitution into the \"exact\" equation for DOF ratio gives\n\nAs magnification increases, the near:far ratio approaches a limiting value of unity.\n\nWhen the subject distance is much less than hyperfocal, the total DOF is given to good approximation by\n\nWhen additionally the magnification is small compared to unity, the value of formula_21 in the numerator can be neglected, and the formula further simplifies to\n\nThe DOF ratio for two different formats is then\n\nEssentially the same approach is described in Stroebel (1976), 136–39).\n\nThe results of the comparison depend on what is assumed. One approach is to assume that essentially the same picture is taken with each format and enlarged to produce the same size final image, so the subject distance remains the same, the focal length is adjusted to maintain the same angle of view, and to a first approximation, magnification is in direct proportion to some characteristic dimension of each format. If both pictures are enlarged to give the same size final images with the same sharpness criteria, the circle of confusion is also in direct proportion to the format size. Thus if formula_134 is the characteristic dimension of the format,\n\nWith the same \"f\"-number, the DOF ratio is then\n\nso the DOF ratio is in inverse proportion to the format size. This ratio is approximate, and breaks down in the macro range of the larger format (the value of formula_21 in the numerator is no longer negligible) or as distance approaches the hyperfocal distance for the smaller format (the DOF of the smaller format approaches infinity).\n\nIf the formats have approximately the same aspect ratios, the characteristic dimensions can be the format diagonals; if the aspect ratios differ considerably (e.g., 4×5 vs. 6×17), the dimensions must be chosen more carefully, and the DOF comparison may not even be meaningful.\n\nIf the DOF is to be the same for both formats the required \"f\"-number is in direct proportion to the format size:\n\nAdjusting the \"f\"-number in proportion to format size is equivalent to using the same absolute aperture diameter for both formats, discussed in detail below in Use of absolute aperture diameter.\n\nIf the same lens focal length is used in both formats, magnifications can be maintained in the ratio of the format sizes by adjusting subject distances; the DOF ratio is the same as that given above, but the images differ because of the different perspectives and angles of view.\n\nIf the same DOF is required for each format, an analysis similar to that above shows that the required \"f\"-number is in direct proportion to the format size.\n\nAnother approach is to use the same focal length with both formats at the same subject distance, so the magnification is the same, and with the same \"f\"-number,\n\nso the DOF ratio is in \"direct\" proportion to the format size, due to the smaller format size having a smaller circle of confusion when the final image size is the same. The perspective is the same for both formats, but because of the different angles of view, the pictures are not the same.\n\nCropping an image and enlarging to the same size final image as an uncropped image taken under the same conditions is equivalent to using a smaller format; the cropped image requires greater enlargement and consequently has a smaller circle of confusion. A cropped then enlarged image has less DOF than the uncropped image.\n\nThe aperture diameter is normally given in terms of the \"f\"-number because all lenses set to the same \"f\"-number give approximately the same image illuminance (Ray 2002, 130), simplifying exposure settings. In deriving the basic DOF equations, formula_140 can be substituted for the absolute aperture diameter formula_52, giving the DOF in terms of the absolute aperture diameter:\n\nafter Larmore (1965), 163). When the subject distance formula_7 is small in comparison with the hyperfocal distance, the second term in the denominator can be neglected, leading to\n\nWith the same subject distance and angle of view for both formats, formula_145, and\n\nso the DOFs are in inverse proportion to the absolute aperture diameters. When the diameters are the same, the two formats have the same DOF. Von Rohr (1906) made this same observation, saying \"At this point it will be sufficient to note that all these formulae involve quantities relating exclusively to the entrance-pupil and its position with respect to the object-point, whereas the focal length of the transforming system does not enter into them.\" Lyon's Depth of Field Outside the Box describes an approach very similar to that of von Rohr.\n\nUsing the same absolute aperture diameter for both formats with the \"same picture\" criterion is equivalent to adjusting the \"f\"-number in proportion to the format sizes, discussed above under \"Same picture\" for both formats\n\nThe equations for\nthe DOF limits can be combined to eliminate formula_147 and solve for the subject distance. For given near and far DOF limits formula_9 and formula_10, the subject distance is\n\nthe harmonic mean of the near and far distances. The equations for DOF limits also can be combined to eliminate\nformula_7 and solve for the required f-number, giving\n\nWhen the subject distance is large in comparison with the lens focal\nlength, this simplifies to\n\nWhen the far limit of DOF is at infinity, the equations for formula_7 and formula_3 give indeterminate results. But if all terms in the numerator and denominator on the right-hand side of the equation for formula_7 are divided by formula_157, it is seen that when formula_157 is at infinity,\n\nSimilarly, if all terms in the numerator and denominator on the right-hand side of the equation for formula_3 are divided by formula_157, it is seen that when formula_157 is at infinity,\n\nMost discussions of DOF concentrate on the object side of the lens,\nbut the formulas are simpler and the measurements usually easier to make on the\nimage side. If the basic image-side equations\n\nand\n\nare combined and solved for the image distance formula_40, the result is\n\nthe harmonic mean of the near and far image distances. The basic image-side equations can also be combined and solved for formula_3, giving\n\nThe image distances are measured from the camera's image plane to the lens's image nodal plane, which is not always easy to locate. The harmonic mean is always less than the arithmentic mean, but when the difference between the near and far image distances is reasonably small, the two means are close to equal, and focus can be set with sufficient accuracy using\n\nThis formula requires only the \"difference\"\nformula_43 between the near and far image distances.\nView camera users often refer to this difference as the \"focus spread\";\nit usually is measured on the bed or focusing rail.\nFocus is simply set to halfway between the near and far image distances.\n\nSubstituting formula_172 into the equation for formula_3 and rearranging gives\n\nOne variant of the thin-lens equation is formula_175, where formula_21 is the magnification; substituting this into the equation for formula_3 gives\n\nAt moderate-to-large subject distances, formula_21 is small compared to unity, and the\nf-number can often be determined with sufficient accuracy using\n\nFor close-up photography, the magnification cannot be ignored, and the f-number should be determined using the first approximate formula.\n\nAs with the approximate formula for formula_40, the approximate formulas for formula_3 require only the focus spread formula_43 rather than the absolute image distances.\n\nWhen the far limit of DOF is at infinity, formula_184.\n\nOn manual-focus small- and medium-format lenses, the focus and f-number usually are determined using the lens DOF scales, which often are based on the approximate equations above.\n\nIf the equation for the far limit of DOF is solved for formula_4, and the far distance replaced by an arbitrary distance formula_45, the blur disk diameter formula_47 at that distance is\n\nWhen the background is at the far limit of DOF, the blur disk diameter is equal to the circle of confusion formula_4, and the blur is just imperceptible. The diameter of the background blur disk increases with the distance to the background. A similar relationship holds for the foreground; the general expression for a defocused object at distance formula_45 is\n\nFor a given scene, the distance between the subject and a foreground or background object is usually\nfixed; let that distance be represented by\n\nthen\n\nor, in terms of subject distance,\n\nwith the minus sign used for foreground objects and the plus sign used for background objects. For a relatively distant background object,\n\nIn terms of subject magnification, the subject distance is\n\nso that, for a given f-number and subject magnification,\n\nDifferentiating formula_47 with respect to formula_2 gives\n\nWith the plus sign, the derivative is everywhere positive, so that for a background object, the blur disk size increases with focal length. With the minus sign, the derivative is everywhere negative, so that for a foreground object, the blur disk size decreases with focal length.\n\nThe magnification of the defocused object also varies with focal length; the magnification of the\ndefocused object is\n\nwhere formula_202 is the image distance of the subject. For a defocused object with some characteristic dimension formula_203, the imaged size of that object is\n\nThe ratio of the blur disk size to the imaged size of that object then is\n\nso for a given defocused object, the ratio of the blur disk diameter to object size is independent of focal length, and depends only on the object size and its distance from the subject.\n\nThis discussion thus far has assumed a symmetrical lens for which the entrance and exit pupils coincide with the object and image nodal planes, and for which the pupil magnification is unity. Although this assumption usually is reasonable for large-format lenses, it often is invalid for medium- and small-format lenses.\n\nFor an asymmetrical lens, the DOF ahead of the subject distance and the DOF beyond the subject distance are given by\n\nand\n\nwhere formula_25 is the pupil magnification.\n\nCombining gives the total DOF:\n\nWhen formula_23, the second term in the denominator becomes small in comparison with the first, and (Shipman 1977, 147)\n\nWhen the pupil magnification is unity, the equations for asymmetrical lenses reduce to those given earlier for symmetrical lenses.\n\nExcept for close-up and macro photography, the effect of lens asymmetry is minimal. A slight rearrangement of the last equation gives\n\nAs magnification decreases, the formula_213 term becomes smaller in comparison with the formula_214 term, and eventually the effect of pupil magnification becomes negligible.\n\n\n\n"}
{"id": "8368", "url": "https://en.wikipedia.org/wiki?curid=8368", "title": "Dumnonii", "text": "Dumnonii\n\nThe Dumnonii or Dumnones were a British tribe who inhabited Dumnonia, the area now known as Devon and Cornwall (and some areas of present-day Dorset and Somerset) in the further parts of the South West peninsula of Britain, from at least the Iron Age up to the early Saxon period. They were bordered to the east by the Durotriges tribe.\n\nWilliam Camden, in his 1607 edition of \"Britannia\", describes Cornwall and Devon as being two parts of the same 'country' which:\nCamden had learnt some Welsh during the course of his studies and it would appear that he is the origin of the interpretation of Dumnonii as \"deep valley dwellers\" from his understanding of the Welsh of his time. John Rhys later theorized that the tribal name was derived from the name of a goddess, \"Domnu\", probably meaning \"the goddess of the deep\". The proto-Celtic root *dubno- or *dumno- meaning \"the deep\" or \"the earth\" (or alternatively meaning \"dark\" or \"gloomy\") appears in personal names such as Dumnorix and Dubnovellaunus. Another group with a similar name but with no known links were the Fir Domnann of Connacht.\n\nThe Roman name of the town of Exeter, \"Isca Dumnoniorum\" (\"Isca of the Dumnonii\"), contains the root \"*iska-\" \"water\" for \"Water of the Dumnonii\". The Latin name suggests that the city was already an \"oppidum\", or walled town, on the banks on the River Exe before the foundation of the Roman city, in about AD 50. The Dumnonii gave their name to the English county of Devon, and their name is represented in Britain's two extant Brythonic languages as \"Dewnans\" in Cornish and \"Dyfnaint\" in Welsh. Amédée Thierry (\"Histoire des Gaulois\", 1828), one of the inventors of the \"historic race\" of Gauls, could confidently equate them with the Cornish (\"les Cornouailles\").\n\nVictorian historians often referred to the tribe as the Damnonii, which is also the name of another people from lowland Scotland, although there are no known links between the two populations.\n\nThe people of Dumnonia spoke a Southwestern Brythonic dialect similar to the forerunner of more recent Cornish and Breton. Irish immigrants, the Déisi, are evidenced by the Ogham-inscribed stones they have left behind, confirmed and supplemented by toponymical studies. The stones are sometimes inscribed in Latin, sometimes in both scripts. Tristram Risdon suggested the continuance of a Brythonic dialect in the South Hams, Devon, as late as the 14th century, in addition to its use in Cornwall.\n\nPtolemy's 2nd century \"Geography\" places the Dumnonii to the west of the Durotriges. The name \"purocoronavium\" that appears in the Ravenna Cosmography implies the existence of a sub-tribe called the Cornavii or Cornovii, perhaps the ancestors of the Cornish people.\n\nIn the sub-Roman period a Brythonic kingdom called Dumnonia emerged, covering the entire peninsula, although it is believed by some to have effectively been a collection of sub-kingdoms.\n\nA kingdom of Domnonée (and of Cornouaille alongside) was established in the province of Armorica directly across the English Channel, and has apparent links with the British population, suggesting an ancient connection of peoples along the western Atlantic seaboard.\n\nThe Latin name for Exeter is Isca Dumnoniorum (\"Water of the Dumnonii\"). This oppidum (a Latin term meaning an important town) on the banks of the River Exe certainly existed prior to the foundation of the Roman city in about AD 50. \"Isca\" is derived from the Brythonic word for flowing water, which was given to the River Exe. This is reflected in the Welsh name for Exeter: \"Caerwysg\" meaning \"fortified settlement on the river Uisc\".\n\nIsca Dumnoniorum originated with a settlement that developed around the Roman fortress of the Legio II Augusta and is one of the four \"poleis\" (cities) attributed to the tribe by Ptolemy. It is also listed in two routes of the late 2nd century Antonine Itinerary.\n\nA legionary bath-house was built inside the fortress sometime between 55 and 60 and underwent renovation shortly afterwards (c. 60-65) but by c. 68 (perhaps even 66) the legion had transferred to a newer fortress at Gloucester. This saw the dismantling of the Isca fortress, and the site was then abandoned. Around AD 75, work on the \"civitas forum\" and \"basilica\" had commenced on the site of the former \"principia\" and by the late 2nd century the \"civitas\" walls had been completed. They were 3 metres thick and 6 metres high and enclosed exactly the same area as the earlier fortress. However, by the late 4th century the \"civitas\" was in decline.\n\nAs well as Isca Dumnoniorum, Ptolemy's 2nd century \"Geography\" names three other towns:\n\nThe Ravenna Cosmography includes the last two names (in slightly different forms, as \"Tamaris\" and \"Uxelis\"), and adds several more names which may be settlements in the territory. These include:\n\nOther Romano-British sites in Dumnonia include:\n\nNew settlements continued to be built throughout the Roman period, including sites at Chysauster and Trevelgue Head. The style is native in form with no Romanised features. Near Padstow, a Roman site of some importance now lies buried under the sands on the opposite side of the Camel estuary near St. Enodoc's Church, and may have been a western coastal equivalent of a Saxon Shore Fort. At Magor Farm in Illogan, near Camborne, an archaeological site has been identified as being a villa.\n\nThe Dumnonii are thought to have occupied relatively isolated territory in Cornwall, Devon, Somerset and possibly part of Dorset. Their cultural connections, as expressed in their ceramics, were with the peninsula of Armorica across the Channel, rather than with the southeast of Britain. They do not seem to have been politically centralised: coins are relatively rare, none of them locally minted, and the structure, distribution and construction of Bronze Age and Iron Age hill forts, \"rounds\" and defensible farmsteads in the south west point to a number of smaller tribal groups living alongside each other.\n\nDumnonia is noteworthy for its many settlements that have survived from the Romano-British period, but also for its lack of a villa system. Local archaeology has revealed instead the isolated enclosed farmsteads known locally as \"rounds\". These seem to have survived the Roman abandonment of Britain, but were subsequently replaced, in the 6th and 7th centuries, by the unenclosed farms taking the Brythonic toponymic \"tre-\".\n\nAs in most other Brythonic areas, Iron Age hill forts, such as Hembury Castle, were refortified for the use of chieftains or kings. Other high-status settlements such as Tintagel seem to have been reconstructed during this period. Post-Roman imported pottery has been excavated from many sites across the region, and the apparent surge in late 5th century Mediterranean and/or Byzantine imports is yet to be explained satisfactorily.\n\nApart from fishing and agriculture, the main economic resource of the Dumnonii was tin mining. The area of Dumnonia had been mined since ancient times, and the tin was exported from the ancient trading port of Ictis (St Michael's Mount). Tin extraction (mainly by streaming) had existed here from the early Bronze Age around the 22nd century BC. West Cornwall, around Mount's Bay, was traditionally thought to have been visited by metal traders from the eastern Mediterranean\n\nDuring the first millennium BC trade became more organised, first with the Phoenicians, who settled Gades (Cadiz) around 1100 BC, and later with the Greeks, who had settled Massilia (Marseilles) and Narbo (Narbonne) around 600 BC. Smelted Cornish tin was collected at Ictis whence it was conveyed across the Bay of Biscay to the mouth of the Loire and then to Gades via the Loire and Rhone valleys. It went then through the Mediterranean Sea in ships to Gades.\n\nDuring the period c. 500-450 BC, the tin deposits seem to have become more important, and fortified settlements appear such as at Chun Castle and Kenidjack Castle, to protect both the tin smelters and mines.\n\nThe earliest account of Cornish tin mining was written by Pytheas of Massilia late in the 4th century BC after his circumnavigation of the British Isles. Underground mining was described in this account, although it cannot be determined when it had started. Pytheas's account was noted later by other writers including Pliny the Elder and Diodorus Siculus.\n\nIt is likely that tin trade with the Mediterranean was later on under the control of the Veneti. Britain was one of the places proposed for the \"Cassiterides\", that is Tin Islands. Tin working continued throughout Roman occupation although it appears that output declined because of new supplies brought in from the deposits discovered in Iberia (Spain and Portugal). However, when these supplies diminished, production in Dumnonia increased and appears to have reached a peak during the 3rd century AD.\n\nThe Sub-Roman or Post-Roman history of Dumnonia comes from a variety of sources and is considered exceedingly difficult to interpret given that historical fact, legend and confused pseudo-history are compounded by a variety of sources in Middle Welsh and Latin. The main sources available for discussion of this period include Gildas's \"De Excidio Britanniae\" and Nennius's \"Historia Brittonum\", the \"Annales Cambriae\", \"Anglo-Saxon Chronicle\", William of Malmesbury's \"Gesta Regum Anglorum\" and \"De Antiquitate Glastoniensis Ecclesiae\", along with texts from the \"Black Book of Carmarthen\" and the \"Red Book of Hergest\", and Bede's \"Historia ecclesiastica gentis Anglorum\" as well as \"The Descent of the Men of the North\" (\"Bonedd Gwŷr y Gogledd\", in Peniarth MS 45 and elsewhere) and the \"Book of Baglan\".\n\n\n\n\n"}
{"id": "8372", "url": "https://en.wikipedia.org/wiki?curid=8372", "title": "Declaration of independence", "text": "Declaration of independence\n\nA declaration of independence or declaration of statehood is an assertion by a defined territory that it is independent and constitutes a state. Such places are usually declared from part or all of the territory of another nation or failed nation, or are breakaway territories from within the larger state. In 2010, the UN's International Court of Justice ruled in an advisory opinion in Kosovo that \"International law contains no prohibition on declarations of independence\", though the state from which the territory wishes to secede may regard the declaration as rebellion, which may lead to a war of independence or a constitutional settlement to resolve the crisis.\n\n"}
{"id": "8373", "url": "https://en.wikipedia.org/wiki?curid=8373", "title": "Drag racing", "text": "Drag racing\n\nDrag racing is a type of motor racing in which automobiles or motorcycles (usually specially prepared for the purpose) compete, usually two at a time, to be first to cross a set finish line. The race follows a short, straight course from a standing start over a measured distance, most commonly ¼ mile (), with a shorter 3/16 mile 10 feet () becoming increasingly popular, as it has become the standard for nitromethane-powered Top Fuel dragsters and funny cars, where some major bracket races and other sanctioning bodies have adopted it as the standard, while (1/8 mi) is also popular in some circles. Electronic timing and speed sensing systems have been used to record race results since the 1960s.\n\nThe history of automobiles and motorcycles being used for drag racing is nearly as long as the history of motorized vehicles themselves, and has taken the form of both illegal street racing, and as an organized and regulated motorsport. This article covers the legal sport.\n\nBefore each race (commonly known as a pass), each driver is allowed to perform a burnout, which heats the driving tires and lays rubber down at the beginning of the track, improving traction. Each driver then lines up (or stages) at the starting line.\n\nModern professional races are started electronically by a system known as a \"Christmas tree\", which consists of a column of lights for each driver/lane, and two light beam sensors per lane on the track at the starting line. Current NHRA trees, for example, feature one blue light (split into halves), then three amber, one green, and one red. When the first light beam is broken by a vehicle's front tire(s), the vehicle is \"pre-staged\" (approximately from the starting line), and the pre-stage indicator on the tree is lit. When the second light beam is broken, the vehicle is \"staged\", and the stage indicator on the tree is lit. Vehicles may then leave the pre-stage beam, but must remain in the stage beam until the race starts.\n\nOnce one competitor is staged, their opponent has a set amount of time to stage or they will be instantly disqualified, indicated by a red light on the tree. Otherwise, once both drivers are staged, the system chooses a short delay at random (to prevent a driver being able to anticipate the start), then starts the race. The light sequence at this point varies slightly. For example, in NHRA Professional classes, three amber lights on the tree flash simultaneously, followed 0.4 seconds later by a green light (this is also known as a \"pro tree\"). In NHRA Sportsman classes, the amber lights illuminate in sequence from top to bottom, 0.5 seconds apart, followed 0.5 seconds later by the green light (this is also known as a \"sportsman tree\" or \"full tree\"). If a vehicle leaves the starting line before the green light illuminates, the red light for that lane illuminates instead, and the driver is disqualified (also known as \"red lighting\"). In a handicap start, the green light automatically lights up for the first driver, and the red light is only lit in the proper lane after both cars have launched if one driver leaves early, or if both drivers left early, the driver whose reaction time is worse (if one lane has a -.015 and the other lane has a -.022, the lane of the driver who committed a 0.022 is given the red light after both cars have left)., as a red light infraction is only assessed to the driver with the worse infraction, if both drivers leave early. Even if both drivers leave early, the green light is automatically lit for the driver that left last, and they still may win the pass (as in the 2014 NHRA Auto Club Pro Stock final, Erica Enders-Stevens and Jason Line both committed red light infractions; only Line was assessed with a red light, as he was -.011 versus Enders-Stevens' -.002).\n\nSeveral measurements are taken for each race: reaction time, elapsed time, and speed. Reaction time is the period from the green light illuminating to the vehicle leaving the starting line. Elapsed time is the period from the vehicle leaving the starting line to crossing the finish line. Speed is measured through a speed trap covering the final to the finish line, indicating average speed of the vehicle in that distance.\n\nExcept where a breakout rule is in place, the winner is the first vehicle to cross the finish line, and therefore the driver with the lowest combined reaction time and elapsed time. Because these times are measured separately, a driver with a slower elapsed time can actually win if that driver's advantage in reaction time exceeds the elapsed time difference. In heads-up racing, this is known as a \"holeshot win\". In categories where a breakout rule is in effect (for example, NHRA Junior Dragster, Super Comp, Super Gas, Super Stock, and Stock classes, as well as some dial-in classes), if a competitor is faster than his or her predetermined time (a \"breakout\"), that competitor loses. If both competitors are faster than their predetermined times, the competitor who breaks out by less time wins. Regardless, a red light foul is worse than a breakout, except in Junior Dragster where exceeding the absolute limit is a cause for disqualification.\n\nMost race events use a traditional bracket system, where the losing car and driver are eliminated from the event while the winner advances to the next round, until a champion is crowned. Events typically use 4, 8, or 16 car brackets. Drivers are typically seeded by elapsed times in qualifying. In bracket racing without a breakout (such as NHRA Competition Eliminator), pairings are based on times compared to their index (faster than index for class is better). In bracket racing with a breakout (Stock, Super Stock, but also the NHRA's Super classes), the closest to the index is favourable.\n\nA popular alternative to the standard eliminations format is the Chicago Style format (also called the Three Round format in Australia), named for the US 30 Dragstrip in suburban Gary, Indiana where a midweek meet featured this format. All entered cars participate in one qualifying round, and then are paired for the elimination round. The two fastest times among winners from this round participate in the championship round. Depending on the organisation, the next two fastest times may play for third, then fifth, and so forth, in consolation rounds. Currently, an IHRA 400 Thunder championship race in Australia uses the format.\n\nThe standard distance of a drag race is 1,320 feet, 402 m, or 1/4 mile. However, due to safety concerns, certain sanctioning bodies (notably the NHRA for its Top Fuel and Funny Car classes) have shortened races to 1,000 feet. Some drag strips are even shorter and run 660 feet, 201 m, or 1/8 mile. The 1,000 foot distance is now also popular with bracket racing, especially in meets where there are 1/8 mile cars and 1/4 mile cars racing together, and is used by the revived American Drag Racing League for its primary classes (not Jr Dragster). Some organisations that deal with Pro Modified and \"Mountain Motor\" Pro Stock cars (Professional Drag Racers Association) use the 1/8 mile distance, even if the tracks are 1/4 mile tracks.\n\nThe National Hot Rod Association (NHRA) oversees the majority of drag racing events in North America. The next largest organization is the International Hot Rod Association (IHRA). Nearly all drag strips are associated with one sanctioning body or the other.\n\nBesides NHRA and IHRA, there are niche organizations for muscle cars and nostalgia vehicles. The Nostalgia Drag Racing League (NDRL) based in Brownsburg, IN, runs a series of 1/4 mile (402m) drag races in the Midwest for 1979 and older nostalgic appearing cars, with four classes of competition running in an index system. Pro 7.0 and Pro 7.50 run heads up 200 mile per hour (320 kilometre per hour) passes, while Pro Comp and Pro Gas run 8.0 to 10.0 indices. NDRL competition vehicles typically include Front Engine Dragsters, Altereds, Funny Cars, early Pro Stock clones, Super Stocks and Gassers.\n\nThe National Electric Drag Racing Association (NEDRA) races electric vehicles against high performance gasoline-powered vehicles such as Dodge Vipers or classic muscle cars in 1/4 and 1/8 mile (402m & 201m) races. The current electric drag racing record is 6.940 seconds at 201.37 mph (324.0736 kph) for a quarter mile (420m). Another niche organization is the VWDRC which run a VW-only championship with vehicles running under 7 seconds.\n\nPrior to the founding of the NHRA and IHRA, smaller organizations sanctioned drag racing in the early years, which included the competing AHRA in the United States from 1955 to 2005.\n\nThe first Australian Nationals event was run in 1965 at Riverside raceway, near Melbourne. The Australian National Drag Racing Association (ANDRA) was established in 1973, and today they claim they are the \"best in the world outside the United States\". ANDRA sanctions races throughout Australia and throughout the year at all levels, from Junior Dragster to Top Fuel.\n\nThe ANDRA Pro Series is for professional drivers and riders and includes Top Fuel, Top Alcohol, Top Doorslammer (similar to the USA Pro Modified class), Pro Stock (using 400 cubic inch engines (6.5 litres)), Top Bike and Pro Stock Motorcycle.\n\nThe Rocket Allstars Racing Series is for ANDRA sportsman drivers and riders and includes Competition, Super Stock, Super Compact, Competition Bike, Supercharged Outlaws, Modified, Super Sedan, Modified Bike, Super Street and Junior Dragster.\n\nBroadcasting is provided on SBS Speedweek.\n\nIn 2015, after a dispute with ANDRA, Sydney Dragway, Willowbank Raceway and the Perth Motorplex invited the International Hot Rod Association (IHRA) to sanction events at their tracks. Since then the Perth Motorplex has reverted back to an ANDRA sanction and Springmount Raceway has embraced the IHRA umbrella. The 400 Thunder Series now attracts professional racers to its races at Sydney Dragway and Willowbank Raceway and is the premiere series in Australia.\n\nCommunications Provider OVO Mobile provides a live stream of all 400 Thunder Australian Professional Drag Racing Series events to fans globally.\nThe 400 Thunder Series is aired on Fox Sports with each professional bracket having its own half hour program from each 400 Thunder Series event.\n\nDrag racing was imported to Europe by American NATO troops during the Cold War. Races were held in West Germany beginning in the 1960s at the airbases at Ramstein and Sembach and in the UK at various airstrips and racing circuits before the opening of Europe's first permanent drag strip at Santa Pod Raceway in 1966.\n\nThe FIA organises a Europe-wide four wheeled championship for the Top Fuel, Top Methanol Dragster, Top Methanol Funny Car, Pro Modified and Pro Stock classes. FIM Europe organises a similar championship for bike classes. In addition, championships are run for sportsman classes in many countries throughout Europe by the various national motorsport governing bodies.\n\nDrag racing in New Zealand started in the 1960s. The New Zealand Hot Rod Association (NZHRA) sanctioned what is believed to have been the first drag meeting at an open cut coal mine at Kopuku, south of Auckland, sometime in 1966. In 1973, the first and only purpose built drag strip opened in Meremere by the Pukekohe Hot Rod Club. In April 1993 the governance of drag racing was separated from the NZHRA and the New Zealand Drag Racing Association (NZDRA) was formed. In 2014, New Zealand's second purpose built drag strip - Masterton Motorplex - opened.\n\nThe first New Zealand Drag Racing Nationals was held in the 1966/67 season at Kopuku, near Auckland.\n\nThere are now two governing bodies operating drag racing in New Zealand with the Florida-based International Hot Rod Association sanctioning both of New Zealands major tracks at Ruapuna (Pegasus Bay Drag Racing Association) on the South Island and Meremere Dragway Inc in the North Island. However, the official ASN of the sport, per FIA regulations, is the New Zealand Drag Racing Association.\n\nA lot of countries in South America race 200 meters, unlike the United States and places like Australia, which race 400 meters or 1/4 mile.\n\nOrganized drag racing in Colombia is Club G3's responsibility, which is a private organization. The events take place at Autódromo de Tocancipá.\n\nCuraçao\n\nOn the island of Curaçao, organization of drag racing events is handled by the Curaçao Autosport Foundation (FAC)\nAll racing events, including street legal competitions, happen at the Curaçao International Raceway.\n\n'Aruba'\n\nOn the island of Aruba all racing events, including street legal competitions, happen at Palomarga international raceway.\n\nBarbados\n\nOn the island of Barbados, organization of drag racing events is done by the Barbados Association of Dragsters and Drifters. Currently the drag racing is done at Bushy Park racing circuit over 1/8 mile, while \"acceleration tests\" of 1/4 mile are done at the Paragon military base.\n\nOrganized drag racing is rapidly growing in India. \"Autocar India\" organised the country's first drag race meet in Mumbai in 2002.\n\nDrag racing is also gaining popularity in Pakistan, with private organizations organizing such events. The Bahria Town housing project recently organized a drag racing event in Rawalpindi, with the help of some of the country's best drivers.\n\nSri Lanka has seen an immense growth in Drag racing through legal meets held by the Ceylon Motor Sports Club, an FiA sanctioned body. In recent years, exotic cars and Japanese power houses have been taking part in these popular events.\n\nDrag racing is an established sport in South Africa, with a number of strips around the country including Tarlton International Raceway and ODI Raceway. Drag racing is controlled by Motorsport South Africa and all drivers are required to hold a valid Motorsport South Africa license. Drivers can compete in a number of categories including Top Eliminator, Senior Eliminator, Super Competition Eliminator, Competition Eliminator, Pro Street Bikes, Superbike Eliminator, Supersport Shootout (motorcycle), Street Modified, and Factory Stock.\n\nThere are hundreds of classes in drag racing, each with different requirements and restrictions on things such as weight, engine size, body style, modifications, and many others. NHRA and IHRA share some of these classes, but many are solely used by one sanctioning body or the other. The NHRA boasts over 200 classes, while the IHRA has fewer. Some IHRA classes have multiple sub-classes in them to differentiate by engine components and other features. There is even a class for aspiring youngsters, Junior Dragster, which typically uses an eighth-mile track, also favored by VW racers.\n\nIn 1997, the FIA (cars) and UEM (bikes) began sanctioning drag racing in Europe with a fully established European Drag Racing Championship, in cooperation (and rules compliance) with NHRA. The major European drag strips include Santa Pod Raceway in Podington, England; Alastaro Circuit, Finland; Mantorp Park, Sweden; Gardermoen Raceway, Norway and the Hockenheimring in Germany. The major difference is the nitro-class distance, which is 300 meters at some tracks, although the NHRA and FIA are likely to discuss the distance change in the future.\n\nThere is a somewhat arbitrary definition of what constitutes a \"professional\" class. The NHRA includes 5 pro classes; Top Fuel, Funny Car, Pro Stock, Pro Modified and Pro Stock Motorcycle. The FIA features a different set of 5 pro classes; Top Fuel, Top Methanol Dragster, Top Methanol Funny Car, Pro Modified and Pro Stock. Other sanctioning bodies have similarly different definitions. A partial list of classes includes:\nA complete listing of all classes can be found on the respective NHRA and IHRA official websites.\n\nThe UEM also has a different structure of professional categories with Top Fuel Bike, Super Twin Top Fuel Bike, and Pro Stock Bike contested, leaving the entire European series with a total of 8 professional categories.\n\nTo allow different cars to compete against each other, some competitions are raced on a handicap basis, with faster cars delayed on the starting line enough to theoretically even things up with the slower car. This may be based on rule differences between the cars in stock, super stock, and modified classes, or on a competitor's chosen \"dial-in\" in bracket racing.\n\nFor a list of drag racing world records in each class, see Dragstrip#Quarter mile times.\n\nA \"dial-in\" is a time the driver estimates it will take his or her car to cross the finish line, and is generally displayed on one or more windows so the starter can adjust the starting lights on the tree accordingly. The slower car will then get a head start equal to the difference in the two dial-ins, so if both cars perform perfectly, they would cross the finish line dead even. If either car goes faster than its dial-in (called breaking out), it is disqualified regardless of who has the lower elapsed time; if both cars break out, the one who breaks out by the smallest amount wins. However, if a driver had jump-started (red light) or crossed a boundary line, both violations override any break out (except in some classes with an absolute break out rule such as Junior classes). This eliminates any advantage from putting a slower time on the windshield to get a head start. The effect of the bracket racing rules is to place a premium on consistency of performance of the driver and car rather than on raw speed, in that victory goes to the driver able to precisely predict elapsed time, whether it is fast or slow. This in turn makes victory much less dependent on large infusions of money, and more dependent on skill. Therefore, bracket racing is popular with casual weekend racers. Many of these recreational racers will drive their vehicles to the track, race them, and then simply drive them home. As most tracks host only one NHRA national event, and two or three regional events (smaller tours, car shows, \"etc.\") annually, on most weekends these tracks host local casual and weekend racers. Organizationally, however, the tracks are run according to the rules of either the NHRA or the IHRA with regional points and a championship on the line. Even street vehicles must pass a safety inspection prior to being allowed to race.\n\nThe National Hot Rod Association (NHRA) was founded in 1951, to take illegal racing off the street.\n\nThe organization banned the use of nitromethane in 1957, calling it unsafe, in part through the efforts of C. J. Hart; the ban would be lifted in 1963.\n\n\n\n\n\n"}
{"id": "8375", "url": "https://en.wikipedia.org/wiki?curid=8375", "title": "Draugr", "text": "Draugr\n\nThe draugr or draug (, plural ; modern , and Danish, Swedish, and ), also called , literally \"again-walker\" () is an undead creature from Norse mythology.\n\nThe word \"draugr\" can be traced to a Proto-Indo European stem \"*\" \"phantom\", from \"*\" \"deceive\".\nThe Old Norse meaning of the word is a revenant.\n\nThe will appears to be strong, strong enough to draw the \"hugr\" [animate will] back to one's body. These reanimated individuals were known as \"draugar\". However, though the dead might live again, they could also die again. \"Draugar\" die a \"second death\" as Chester Gould calls it, when their bodies decay, are burned, dismembered or otherwise destroyed.\n\nDraugar live in their graves, often guarding treasure buried with them in their burial mound. They are animated corpses — unlike ghosts they have a corporeal body with similar physical abilities as in life. Older literature makes clear distinctions between sea-draugar and land-draugar.\n\nDraugar possess superhuman strength, can increase their size at will, and carry the unmistakable stench of decay. \"The appearance of a \"draugr\" was that of a dead body: swollen, blackened and generally hideous to look at.\" They are undead figures from Norse and Icelandic mythology that appear to retain some semblance of intelligence. They exist either to guard their treasure, wreak havoc on living beings, or torment those who had wronged them in life. The draugr's ability to increase its size also increased its weight, and the body of the draugr was described as being extremely heavy. Thorolf of Eyrbyggja saga was \"uncorrupted, and with an ugly look about him... swollen to the size of an ox,\" and his body was so heavy that it could not be raised without levers. They are also noted for the ability to rise from the grave as wisps of smoke and \"swim\" through solid rock, which would be useful as a means of exiting their graves.\n\nIn folklore, draugar slay their victims through various methods including crushing them with their enlarged forms, devouring their flesh, devouring them whole in their enlarged forms, indirectly killing them by driving them mad, and by drinking their blood. Animals feeding near the grave of a draugr may be driven mad by the creature's influence. They may also die from being driven mad. Thorolf, for example, caused birds that flew over his bowl barrow to drop dead. Draugar are also noted as being able to drive living people insane.\n\nThe draugr's victims were not limited to trespassers in its howe. The roaming undead decimated livestock by running the animals to death while either riding them or pursuing them in some hideous, half-flayed form. Shepherds, whose duties to their flocks left them out of doors at night time, were also particular targets for the hunger and hatred of the undead:\nDraugar are noted for having numerous magical abilities (referred to as \"trollskap\") resembling those of living witches and wizards such as shape-shifting, controlling the weather and seeing into the future. Among the creatures that a draugr may turn into are a seal, a great flayed bull, a grey horse with a broken back but no ears or tail and a cat that would sit upon a sleeper's chest and grow steadily heavier until the victim suffocated. The draugr Þráinn (Thrain) shape-shifted into a \"cat-like creature\" (\"kattakyn\") in \"Hrómundar saga Gripssonar\":\n\nDraugar have the ability to enter into the dreams of the living, \"but it generally happens even so that they leave beside the living person some gift, by which, on awakening, the living person may be assured of the tangible nature of the visit.\" Draugar also have the ability to curse a victim, as shown in the Grettis saga, where Grettir is cursed to be unable to become any stronger. Draugar also brought disease to a village and could create temporary darkness in daylight hours. While the draugr certainly preferred to be active during the night, it did not appear to be vulnerable to sunlight like some other revenants.\n\nA draugr's presence may be shown by a great light that glowed from the mound like foxfire. This fire would form a barrier between the land of the living and the land of the dead. The draugr could also move magically through the earth, swimming through solid stone as does Killer-Hrapp:\n\nSome draugar are immune to weapons, and only a hero has the strength and courage needed to stand up to so formidable an opponent. In legends the hero would often have to wrestle the draugr back to his grave, thereby defeating him, since weapons would do no good. A good example of this kind of fight is found in \"Hrómundar saga Gripssonar\". Although iron could injure a draugr, as is the case with many supernatural creatures, it would not be sufficient to stop it. Sometimes the hero is required to dispose of the body in unconventional ways. The preferred method is to cut off the draugr's head, burn the body, and dump the ashes in the sea; the emphasis being on making absolutely sure the draugr was dead and gone.\n\nThe draugar were said to be either \"hel-blár\" (\"death-blue\") or, conversely, \"nár-fölr\" (\"corpse-pale\"). The \"death-blue\" color was not actually grey but was a dark blue or maroon hue that covered the entire body. Glámr, the undead shepherd of \"Grettis saga\", was reported to be dark blue in color and in Laxdæla saga, the bones of a dead sorceress who had appeared in dreams were dug up and found to be \"blue and evil looking.\"\n\nThe resting place of the draugr was a tomb that served much as a workable home for the creature. Draugar are able to leave this dwelling place and visit the living during the night. Such visits are supposed to be universally horrible events that often end in death for one or more of the living, which would then warrant the exhumation of the draugr by a hero.\n\nThe motivation of the actions of a draugr was primarily jealousy and greed. The greed of a draugr causes it to viciously attack any would-be grave robbers, but the draugr also expresses an innate jealousy of the living, stemming from a longing for the things of the life it once had. This idea is clearly expressed in \"Friðþjófs saga\", where a dying king declared:\n\nThis desire for the friendship experienced in life is one example of the manifestation of this aspect of the draugr. Draugar also exhibit an immense and nearly insatiable appetite, as shown in the encounter of Aran and Asmund, sword brothers who made an oath that if one should die, the other would sit vigil with him for three days inside the burial mound. When Aran died, Asmund brought his own possessions into the barrow: banners, armor, hawk, hound, and horse. Then Asmund set himself to wait the agreed upon three days:\n\nAfter a person’s death, the main indication that the person will become a draugr is that the corpse is not in a horizontal position. In most cases, the corpse is found in an upright or sitting position, and this is an indication that the dead might return. Any mean, nasty, or greedy person can become a draugr. As noted by Ármann, “most medieval Icelandic ghosts are evil or marginal people. If not dissatisfied or evil, they are unpopular”. This is the prime way that draugar share characteristics with ghosts, since any person can become a ghost.\n\nIn many Western mythologies, ghosts are generally people with unfinished business or those who are so evil their spirit makes an impact on the place they lived. Ghosts and draugar refuse to follow the prescribed path of death, selfishly staying on Earth when they are supposed to move on. This is easily understandable because, “selfishness is an important attribute of every ghost, and therefore it is no wonder that ghosts tend to be people who were troublesome during their lifetime”.\n\nHowever, unlike ghosts, draugar can also come about through infection by another draugr such as in the story of Glámr. When Glámr arrives in the haunted valley in \"Grettis saga\", \"the previous evil spirits are relegated to the sidelines and, when Glámr is found dead, they disappear, whereas he takes over their role as ghost of the valley.\" Although Glámr is an arguably marginal character to begin with, it is only after his fight with the first malignant spirit that the first spirit leaves the valley, and Glámr takes its place wreaking havoc. Similarly, in \"Eyrbyggja saga\", a shepherd is killed by a draugr and rises the next night as one himself.\n\nTraditionally, a pair of open iron scissors were placed on the chest of the recently deceased, and straws or twigs might be hidden among their clothes. The big toes were tied together or needles were driven through the soles of the feet in order to keep the dead from being able to walk. Tradition also held that the coffin should be lifted and lowered in three different directions as it was carried from the house to confuse a possible draugr's sense of direction.\n\nThe most effective means of preventing the return of the dead was believed to be the corpse door. A special door was built, through which the corpse was carried feet-first with people surrounding it so the corpse couldn't see where it was going. The door was then bricked up to prevent a return. It is speculated that this belief began in Denmark and spread throughout the Norse culture. The belief was founded on the idea that the dead could only leave through the way they entered.\n\nIn \"Eyrbyggja saga\", the draugar infesting the home of the Icelander Kiartan were driven off by holding a \"door-doom\". One by one the draugar were summoned to the door-doom and given judgment and were forced out of the home by this legal method. The home was then purified with holy water to ensure they never came back.\n\nA variation of the draugr is the \"haugbui\". The haugbui (from Old Norse \"haugr\"' \"howe, barrow, tumulus\") was a mound-dweller, the dead body living on within its tomb. The notable difference between the two was that the haugbui is unable to leave its grave site and only attacks those that trespass upon their territory.\n\nThe haugbui was rarely found far from its burial place and is a type of undead commonly found in Norse saga material. The creature is said to either swim alongside boats or sail around them in a partially submerged vessel, always on their own. In some accounts, witnesses portray them as shapeshifters who take on the appearance of seaweed or moss-covered stones on the shoreline.\n\nThe words \"dragon\" and \"draugr\" are not linguistically related. However, both the serpent and the spirit serve as jealous guardians of the graves of kings or ancient civilizations. Dragons that act as draugar appear in \"Beowulf\" as well as in some of the heroic lays of the \"Poetic Edda\" (in the form of Fafnir).\n\nOne of the best-known draugar is Glámr, who is defeated by the hero in \"Grettis saga\". After Glámr dies on Christmas Eve, \"people became aware that Glámr was not resting in peace. He wrought such havoc that some people fainted at the sight of him, while others went out of their minds\". After a mundane battle, Grettir eventually gets Glámr on his back. Just before Grettir kills him, Glámr curses Grettir because \"Glámr was endowed with more evil force than most other ghosts\", and thus he was able to speak and leave Grettir with his curse after his death.\n\nA somewhat ambivalent, alternative view of the draugr is presented by the example of Gunnar Hámundarson in \"Njáls saga\": \"It seemed as though the howe was agape, and that Gunnar had turned within the howe to look upwards at the moon. They thought that they saw four lights within the howe, but not a shadow to be seen. Then they saw that Gunnar was merry, with a joyful face.\"\n\nIn the \"Eyrbyggja saga\", a shepherd is assaulted by a blue-black draugr. The shepherd's neck is broken during the ensuing scuffle. The shepherd rises the next night as a draugr.\n\nIn more recent Scandinavian folklore, the draug (the modern spelling used in Denmark, Norway, and Sweden) is often identified with the spirits of mariners drowned at sea. The creature is said to possess a distinctly human form, with the exception that its head is composed entirely of seaweed. In other tellings, the draug is described as being a headless fisherman, dressed in oilskin and sailing in half a boat (the Norwegian municipality of Bø, Nordland has the half-boat in its coat-of-arms). This trait is common in the northernmost part of Norway, where life and culture was based on fishing more than anywhere else. The reason for this may be that the fishermen often drowned in great numbers, and the stories of restless dead coming in from sea were more common up north than anywhere else in the country.\n\nA recorded legend from Trøndelag tells how a cadaver lying on a beach became the object of a quarrel between the two types of draug (headless and seaweed-headed). A similar source even tells of a third type, the \"gleip\", known to hitch themselves to sailors walking ashore and make them slip on the wet rocks.\n\nBut, though the draug usually presages death, there is an amusing account in Northern Norway of a northerner who managed to outwit him:\n\nThe modern and popular connection between the draug and the sea can be traced back to the author Jonas Lie and the story-teller Regine Nordmann, as well as the drawings of Theodor Kittelsen, who spent some years living in Svolvær. Up north, the tradition of sea-draugs is especially vivid.\n\nArne Garborg describes land-draugs coming fresh from the graveyards, and the term \"draug\" is even used of vampires. The notion of draugs who live in the mountains is present in the poetic works of Henrik Ibsen (\"Peer Gynt\"), and Aasmund Olavsson Vinje. The Nynorsk translation of \"The Lord of the Rings\" used the term for both Nazgûl and the dead men of Dunharrow. also the Barrow-Wights are partly inspired by Draugr.\n\nThe term \"draug\" has come to be used to describe any type of revenant in Nordic folklore.\n\n\n\n"}
{"id": "8376", "url": "https://en.wikipedia.org/wiki?curid=8376", "title": "Day", "text": "Day\n\nA day is a unit of time. In common usage, it is either an interval equal to 24 hours or daytime, the consecutive period of time during which the Sun is above the horizon. The period of time during which the Earth completes one rotation with respect to the Sun is called a \"solar day\". Several definitions of this universal human concept are used according to context, need and convenience. In 1960, the second was redefined in terms of the orbital motion of the Earth, and was designated the SI base unit of time. The unit of measurement \"day\", redefined in 1960 as 86 400 SI seconds and symbolized \"d\", is not an SI unit, but is accepted for use with SI. A civil day is usually 86 400 seconds, plus or minus a possible leap second in Coordinated Universal Time (UTC), and occasionally plus or minus an hour in those locations that change from or to daylight saving time. The word \"day\" may also refer to a day of the week or to a calendar date, as in answer to the question, \"On which day?\" The life patterns of humans and many other species are related to Earth's solar day and the day-night cycle (see circadian rhythms).\n\nIn recent decades the average length of a solar day on Earth has been about 86 400.002 seconds (24.000 000 6 hours) and there are about 365.242 2 solar days in one mean tropical year. Because celestial orbits are not perfectly circular, and thus objects travel at different speeds at various positions in their orbit, a solar day is not the same length of time throughout the orbital year. A \"day\", understood as the span of time it takes for the Earth to make one entire rotation\nwith respect to the celestial background or a distant star (assumed to be fixed), is called a \"stellar day\". This period of rotation is about 4 minutes less than 24 hours (23 hours 56 minutes and 4.1 seconds) and there are about 366.242 2 stellar days in one mean tropical year (one stellar day more than the number of solar days). Mainly due to tidal effects, the Earth's rotational period is not constant, resulting in further minor variations for both solar days and stellar \"days\". Other planets and moons have stellar and solar days of different lengths to Earth's.\n\nBesides the day of 24 hours (86 400 seconds), the word \"day\" is used for several different spans of time based on the rotation of the Earth around its axis. An important one is the solar day, defined as the time it takes for the Sun to return to its culmination point (its highest point in the sky). Because the Earth orbits the Sun elliptically as the Earth spins on an inclined axis, this period can be up to 7.9 seconds more than (or less than) 24 hours. On average over the year this day is equivalent to 24 hours (86 400 seconds).\n\nA day, in the sense of daytime that is distinguished from night-time, is commonly defined as the period during which sunlight directly reaches the ground, assuming that there are no local obstacles. The length of daytime averages slightly more than half of the 24-hour day. Two effects make daytime on average longer than nights. The Sun is not a point, but has an apparent size of about 32 minutes of arc. Additionally, the atmosphere refracts sunlight in such a way that some of it reaches the ground even when the Sun is below the horizon by about 34 minutes of arc. So the first light reaches the ground when the centre of the Sun is still below the horizon by about 50 minutes of arc. The difference in time depends on the angle at which the Sun rises and sets (itself a function of latitude), but can amount to around seven minutes.\n\nAncient custom has a new day start at either the rising or setting of the Sun on the local horizon (Italian reckoning, for example, being 24 hours from sunset, oldstyle). The exact moment of, and the interval between, two sunrises or sunsets depends on the geographical position (longitude as well as latitude), and the time of year (as indicated by ancient hemispherical sundials).\n\nA more constant day can be defined by the Sun passing through the local meridian, which happens at local noon (upper culmination) or midnight (lower culmination). The exact moment is dependent on the geographical longitude, and to a lesser extent on the time of the year. The length of such a day is nearly constant (24 hours ± 30 seconds). This is the time as indicated by modern sundials.\n\nA further improvement defines a fictitious mean Sun that moves with constant speed along the celestial equator; the speed is the same as the average speed of the real Sun, but this removes the variation over a year as the Earth moves along its orbit around the Sun (due to both its velocity and its axial tilt).\n\nThe Earth's day has increased in length over time. This phenomenon is due to tides raised by the Moon which slow Earth's rotation. Because of the way the second is defined, the mean length of a day is now about 86 400.002 seconds, and is increasing by about 1.7 milliseconds per century (an average over the last 2 700 years). (See tidal acceleration for details.) The length of a day circa 620 million years ago has been estimated from rhythmites (alternating layers in sandstone) as having been about 21.9 hours. The length of day for the Earth before the moon was created is still unknown.\n\nThe term comes from the Old English \"dæg\", with its cognates such as \"dagur\" in Icelandic, \"Tag\" in German, and \"dag\" in Norwegian, Danish, Swedish and Dutch. All of them from the Indo-European root dyau which explains the similarity with Latin dies though the word is known to come from the Germanic branch. , \"day\" is the 205th most common word in US English, and the 210th most common in UK English.\n\nA day, symbol \"d\", is defined as 86 400 seconds. The Second is the base unit of time in SI units.\n\nA day according to Coordinated Universal Time (UTC) can include a negative or positive leap second, and can therefore have a length of either 86 399 or 86 401 seconds.\n\nIn 1967–68, during the 13th CGPM (Resolution 1), the International Bureau of Weights and Measures (BIPM) redefined a second as … the duration of 9 192 631 770 periods of the radiation corresponding to the transition between two hyperfine levels of the ground state of the caesium 133 atom.\nThis makes the SI-based day last exactly 794 243 384 928 000 of those periods.\n\nIn the 19th century, an idea circulated to make a decimal fraction ( or ) of an astronomical day the base unit of time. This was an afterglow of the short-lived movement toward a decimalisation of timekeeping and the calendar, which had been given up already due to its difficulty in transitioning from traditional, more familiar units. The most successful alternative is the \"centiday\", equal to 14.4 minutes (864 seconds), being not only a shorter multiple of an hour (0.24 vs 2.4) but also closer to the SI multiple \"kilosecond\" (1 000 seconds) and equal to the traditional Chinese unit, \"ke\".\n\nThe word refers to various similarly defined ideas, such as:\n\nFor civil purposes, a common clock time is typically defined for an entire region based on the local mean solar time at a central meridian. Such \"time zones\" began to be adopted about the middle of the 19th century when railroads with regularly occurring schedules came into use, with most major countries having adopted them by 1929. As of 2015, throughout the world, 40 such zones are now in use: the central zone, from which all others are defined as offsets, is known as , which uses Coordinated Universal Time (UTC).\n\nThe most common convention starts the civil day at midnight: this is near the time of the lower culmination of the Sun on the central meridian of the time zone. Such a day may be referred to as a calendar day.\nA day is commonly divided into 24 hours of 60 minutes, with each minute composed of 60 seconds.\n\nIn order to keep the civil day aligned with the apparent movement of the Sun, positive or negative leap seconds may be inserted from time to time. Therefore, although typically 86 400 SI seconds in duration, a civil day can be either 86 401 or 86 399 SI seconds long on such a day.\n\nLeap seconds are announced in advance by the International Earth Rotation and Reference Systems Service (IERS), which measures the Earth's rotation and determines whether a leap second is necessary. Leap seconds occur only at the end of a UTC-calculated month, and have only ever been inserted at the end of June 30 or December 31.\n\nFor most diurnal animals, the day naturally begins at dawn and ends at sunset. Humans, with their cultural norms and scientific knowledge, have employed several different conceptions of the day's boundaries. The Jewish day begins at either sunset or nightfall (when three second-magnitude stars appear). Medieval Europe also followed this tradition, known as Florentine reckoning: in this system, a reference like \"two hours into the day\" meant \"two hours after sunset\" and thus times during the evening need to be shifted back one calendar day in modern reckoning. Days such as Christmas Eve, Halloween, and the Eve of Saint Agnes are remnants of the older pattern when holidays began during the prior evening. Common convention in modern times is for the civil day to begin at midnight, i.e. 00:00, and last a full 24 hours until 24:00 (i.e. 00:00 of the next day). Prior to 1926, Turkey had two time systems: Turkish (counting the hours from sunset) and French (counting the hours from midnight).\n\nIn ancient Egypt, the day was reckoned from sunrise to sunrise. Muslims fast from sunrise to sunset each day during the month of Ramadan. The \"Damascus Document\", copies of which were also found among the Dead Sea scrolls, states regarding the observance of the Sabbath that \"No one is to do any work on Friday \"from the moment that the Sun's disk stands distant from the horizon by the length of its own diameter\",\" presumably indicating that the monastic community responsible for producing this work counted the day as ending shortly before the Sun had begun to set. \n\nIn many cultures, nights are named after the previous day. For example,\"Friday night\" usually means the entire night between Friday and Saturday. This difference from the civil day often leads to confusion. Events starting at midnight are often announced as occurring the day before. TV-guides tend to list nightly programs at the previous day, although programming a VCR requires the strict logic of starting the new day at 00:00 (to further confuse the issue, VCRs set to the 12-hour clock notation will label this \"12:00 AM\"). Expressions like \"today\", \"yesterday\" and \"tomorrow\" become ambiguous during the night. Because Jews and Muslims begin their days at nightfall, \"Saturday\" night, for example, is what most people would call Friday night.\n\nValidity of tickets, passes, etc., for a day or a number of days may end at midnight, or closing time, when that is earlier. However, if a service (e.g., public transport) operates from for example, 6:00 to 1:00 the next day (which may be noted as 25:00), the last hour may well count as being part of the previous day. For services depending on the day (\"closed on Sundays\", \"does not run on Fridays\", and so on) there is a risk of ambiguity. For example, a day ticket on the Nederlandse Spoorwegen (Dutch Railways) is valid for 28 hours, from 0:00 to 28:00 (that is, 4:00 the next day); the validity of a pass on Transport for London (TfL) services is until the end of the \"transport day\"—that is to say, until 4:30 am on the day after the \"expiry\" date stamped on the pass.\n\nTo distinguish between a full day and daytime, the word \"nychthemeron\" (from Greek for a night and a day) may be used in English for the former, or more colloquially the term . In other languages, the latter is also often used. Other languages also have a separate word for a full day, such as \"\" in Finnish, \"\" in Estonian, \"\" in Swedish, \"\" in Danish, \"\" in Norwegian, \"\" in Icelandic, \"\" in Dutch, \"\" in Polish, \"\" (\"sutki\") in Russian, \"\" (\"sutki\") in Belarusian, \"\" (\"doba\") in Ukrainian, \"\" in Bulgarian, in Hebrew and \"шабонарӯз\" in Tajik. In Italian, \"giorno\" is used to indicate a full day, while \"dì\" means daytime. In ancient India, \"Ahoratra\" is used to represent a full day.\nIn places which experience the midnight sun (polar day), daytime may extend beyond one 24 hour period and could even extend to months\n\n"}

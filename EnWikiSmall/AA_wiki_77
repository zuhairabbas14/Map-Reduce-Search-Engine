{"id": "10165", "url": "https://en.wikipedia.org/wiki?curid=10165", "title": "Effects unit", "text": "Effects unit\n\nAn effects unit or pedal is an electronic or digital device that alters how a musical instrument or other audio source sounds. In the 2010s, most effects use solid state electronics and/or computer chips. Some vintage effects units from the 1930s to the 1970s and modern reissues of these effects use mechanical components as well (e.g., Leslie rotating speaker, spring reverb, and tape recorder-based echo effects) or vacuum tubes. Some effects subtly \"color\" a sound, such as a reverb unit used on a low setting, while others transform it dramatically, such as a distortion pedal used with electric guitar, with the overdrive set to its maximum level. Musicians, audio engineers and record producers use effects units during live performances or in the studio, typically with electric guitar, electronic keyboard, electric piano or electric bass. While guitar effects are most frequently used with electric or electronic instruments, effects can also be used with acoustic instruments, drums and vocals. Rackmounted or audio console-integrated reverb effects are commonly used with vocals in live sound and sound recording. Examples of common effects units include wah-wah pedals, fuzzboxes and reverb units.\n\nEffects are built into amplifiers (reverb and distortion are the most common in 2010s-era amps, but vintage amps and modern reissued amps may also have tremolo and vibrato); housed in table top units designed for DJs and record producers, a format which typically contains multiple effects; \"stompboxes\" and \"rackmount units\", or they are built into the instruments themselves, as in the case of the Hammond organ, which includes chorus and vibrato effects inside the instrument chassis. A stompbox or \"pedal\" is a small metal or plastic box placed on the floor in front of the musician and connected to the instrument and the instrument amplifier with patch cords. Pedals are usually the least expensive format. Typically, one or more on-off foot-operated switches control a device that provides only one or two effects, with many pedals having knobs for controlling the volume, tone and intensity of the effect. A \"rackmount\" device mounts on a standard 19-inch equipment rack and usually contains several types of effects. Rackmount effects typically have buttons and/or knobs on the face of the chassis for controlling the effects and a patch bay at the rear of the unit.\n\nWhile there is currently no firm consensus on how to categorize effects, the following are seven common classifications: distortion/overdrive, also called \"fuzz\", which produce the \"growling\" audio clipping sounds that are a key part of electric guitar playing in electric blues, hard rock and heavy metal music; dynamics effects which affect loudness, such as volume pedals and audio compressors; filters which modify the frequency range of the instrument, such as the wah-wah pedal and the graphic equalizer; modulation effects, such as the chorus, flanger and phaser; pitch/frequency effects such as a pitch shifter, a common example of which is an octave pedal, which can shift a note down an octave (or up an octave); time-based effects, such as reverb, echo effect and looper pedals (the latter can be used by a one person band to record a riff and then solo over it); and feedback/sustain effects, such as electric guitar feedback and the EBow, which are two different techniques for producing pipe organ-like sustain on the electric guitar. Guitarists derive their signature sound or \"tone\" from their choice of instrument, pickups, effects units, and guitar amp and from the different settings they use with their pickups, effects units and amp.\n\nAn effects unit is also called an \"effect box\", \"effects device\", \"effects processor\" or simply \"effects\". In audio engineer parlance, a signal without effects is \"dry\" and an effect-processed signal is \"wet\". The abbreviation \"F/X\" or \"FX\" is sometimes used. A pedal-style unit may be called a \"stomp box\", \"stompbox\", \"effects pedal\" or \"pedal\". A musician bringing many pedals to a live show or recording session often mounts the pedals on a guitar pedalboard, to reduce set-up and tear-down time and, for pedalboards with lids, protect the pedals during transportation. When a musician has multiple effects in a rack mounted road case, this case may be called an \"effects rack\" or \"rig\". When rackmounted effects are mounted in a roadcase, this also speeds up a musician's set-up and tear-down time, because all of the effects can be connected together inside the rack case and all of the units can be plugged into a powerbar.\n\nEffects units are available in a variety of formats or form factors. Stompboxes are usually the smallest, least expensive, and most rugged effects units. Rackmount devices are generally more expensive and offer a wider range of functions. An effects unit can consist of analog or digital circuitry or a combination of the two. During a live performance, the effect is plugged into the electrical \"signal\" path of the instrument. In the studio, the instrument or other sound-source's auxiliary output is patched into the effect. Form factors are part of a studio or musician's outboard gear.\nStompboxes are small plastic or metal chassis which usually lie on the floor or in a pedalboard to be operated by the user's feet. Pedals are often rectangle-shaped, but there are a range of other shapes (e.g., the circle-shaped Fuzz Face). Typical simple stompboxes have a single footswitch, one to three potentiometers (\"pots\" or \"knobs\") for controlling the effect, and a single LED that indicates if the effect is on. A typical distortion or overdrive pedal's three potentiometers, for example, control the level or intensity of the distortion effect, the tone of the effected signal and the volume (level) of the effected signal. Depending on the type of pedal, the potentiometers may control different parameters of the effect. For a chorus effect, for example, the knobs may control the depth and speed of the effect. Complex stompboxes may have multiple footswitches, many knobs, additional switches or buttons that are operated with the fingers, and an alphanumeric LED display that indicates the status of the effect with short acronyms (e.g., DIST for \"distortion\"). Some pedals have two knobs stacked on top of each other, enabling the unit to provide two knobs per single knob space.\n\nAn \"effects chain\" or \"signal chain\" is formed by connecting two or more stompboxes. Effect chains are typically created between the guitar and the amp or between the preamplifier (\"preamp\") and the power amp. When a pedal is off or inactive, the electric audio signal coming into the pedal diverts onto a \"bypass\", an unaltered \"dry\" signal that continues on to other effects down the chain. In this way, a musician can combine effects within a chain in a variety of ways without having to reconnect boxes during a performance. A \"controller\" or \"effects management system\" lets the musician create multiple effect chains, so they can select one or several chains by tapping a single switch. The switches are usually organized in a row or a simple grid.\n\nTo preserve the clarity of the tone, it is most common to put compression, wah and overdrive pedals at the start of the chain; modulation (chorus, flanger, phase shifter) in the middle; and time-based units (delay/echo, reverb) at the end. When using many effects, unwanted noise and hum can be introduced into the sound. Some performers use a noise gate pedal at the end of a chain to reduce unwanted noise and hum introduced by overdrive units or vintage gear.\n\nRackmounted effects are typically built in a thin metal chassis with metal \"ears\" designed to be screwed into a 19-inch rack that is standard to the telecommunication, computing and music technology industries. Rackmounted effects may be one, two or three rack spaces high. When purchased from the store, rack-mounted equipment is not equipped with the rugged chassis features used on stompboxes and amps that are designed to be transported as standalone units, such as corner protectors. Rackmounted units are typically mounted in a rack, which is housed in a road case, a tough plastic case with removable front and rear covers that can be latched on during transportation to protect the knobs and switches and then removed during performances. A rackmount unit may contain electronic circuitry identical to a stompbox's, although its circuits are typically more complex. Unlike stompboxes, rackmounts usually have several different types of effects.\n\nRackmounts are most commonly used in recording studios and \"front of house\" live sound mixing situations, though professional musicians who play electric bass, electric guitar, or synthesizers may use them in place of stompboxes, to create a rackmounted head unit for their speaker cabinet(s). Rackmounts are controlled by knobs, switches or buttons on their front panel, and often by a MIDI digital control interface. During live performances, a musician can operate rackmounted effects using a \"foot controller\". By setting up effects in a rack-mounted road case, this speeds up set-up and tear-down, because all of the effects can be connected together with patch cords (which can be left connected permanently) and all of the units can be plugged into a power bar. This means that a musician only needs to plug in the main power bar into AC Mains power and plug their instrument into the rack, and the last effect unit's output into their instrument amplifier and/or the PA system.\n\n\"Shock mount\" racks are designed for musicians who frequently move gear between venues. Shock mounts help to protect electronic devices from bumps during transportation. Devices that are less than 19 inches wide may use special \"ear\" adapters to mount on a rack.\n\nEffects are often incorporated into amplifiers and even some types of instruments. Electric guitar amplifiers typically have built-in reverb and distortion, while acoustic guitar and keyboard amplifiers tend to only have built-in reverb. Some acoustic instrument amplifiers have reverb, chorus, compression and equalization (bass and treble) effects. Vintage guitar amps (and their 2010-era reissued models) typically have tremolo and vibrato effects, and sometimes reverb. The Fender Bandmaster Reverb amp, for example, had built-in reverb and vibrato. Built-in effects may offer the user less control than standalone pedals or rackmounted units. For example, on some lower- to mid-priced bass amplifiers, the only control on the audio compression effect is a button or switch to turn it on or off, or a single knob. In contrast, a pedal or rackmounted unit would typically provide ratio, threshold and attack knobs and sometimes \"soft knee\" or other options to allow the user to control the compression.\n\nSince the 2000s, guitar amplifiers began having built-in multi-effects units or digital modeling effects. Bass amplifiers are less likely to have built-in effects, although some may have a compressor/limiter or fuzz bass effect. Bass amps from the 1980s sometimes included built-in bass chorus.\n\nInstruments with built-in effects include Hammond organs, electronic organs, electronic pianos and digital synthesizers. Built-in effects for keyboard typically include reverb, chorus and, for Hammond organ, vibrato. Many \"clonewheel organs include an overdrive effect. Occasionally, acoustic-electric and electric guitars will have built-in effects, such as a preamp or equalizer.\n\nA multi-effects device (also called a \"multi-FX\" device) is a single electronics effects pedal or rackmount device that contains many different electronic effects. Multi-FX devices allow users to \"preset\" combinations of different effects, allowing musicians quick on-stage access to different effects combinations. Multi-effects units typically have a range of distortion, chorus, flanger, phaser and reverb effects. The most expensive multi-effects units may also have looper functions. Pedal-style multieffects range from fairly inexpensive stompboxes that contain two pedals and a few knobs to control the effects to large, expensive floor units with many pedals and knobs. Rackmounted multieffects units are typically mounted in a rack. Guitarists and bassists may mount their rackmounted multieffects unit in the same rack with their preamplifier and power amplifier.\n\nA tabletop unit is a type of multi-effects device that sits on a desk and is controlled manually. One such example is the Pod guitar amplifier modeler. Digital effects designed for DJs are often sold in tabletop models, so that the units can be placed alongside a DJ mixer, turntables and CD scratching gear. For a DJ, a pedal located on the floor would not be practical because she/he would find it hard to adjust the knobs.\n\nThe earliest sound effects were strictly studio productions. In the mid to late 1940s, recording engineers and experimental musicians such as Les Paul began manipulating reel-to-reel recording tape to create echo effects and unusual, futuristic sounds. Microphone placement (\"miking\") techniques were used in spaces with specially designed acoustic properties to simulate echo chambers. In 1948 DeArmond released the Trem-Trol, the first commercially available stand-alone effects unit. This device produced a tremolo by passing an instrument's electrical signal through a water-based electrolytic fluid. Most stand-alone effects of the 1950s and early 60s such as the Gibson GA-VI vibrato unit and the Fender reverb box, were expensive and impractical, requiring bulky transformers and high voltages. The original stand-alone units were not especially in-demand as many effects came built into amplifiers. The first popular stand-alone was the 1958 Watkins Copicat, a relatively portable tape echo effect made famous by the British band, The Shadows.\n\nGuitar amplifier built-in effects were the first effects that musicians used regularly outside the studio. From the late 1940s onward, the Gibson Guitar Corp. began including vibrato circuits in combo amplifiers. The 1950 Ray Butts EchoSonic amp was the first to feature the \"slapback\" echo sound, which quickly became popular with guitarists such as Chet Atkins, Carl Perkins, Scotty Moore, Luther Perkins, and Roy Orbison. By the 1950s, tremolo, vibrato and reverb were available as built-in effects on many guitar amplifiers. Both Premier and Gibson built tube-powered amps with spring reverb. Fender began manufacturing the tremolo amps Tremolux in 1955 and Vibrolux in 1956.\n\nDistortion was not an effect originally intended by amplifier manufacturers, but could often easily be achieved by \"overdriving\" the power supply in early tube amplifiers. In the 1950s, guitarists began deliberately increasing gain beyond its intended levels to achieve \"warm\" distorted sounds. Among the first musicians to experiment with distortion were Willie Johnson of Howlin' Wolf, Goree Carter, Joe Hill Louis, Ike Turner, Guitar Slim, and Chuck Berry.\n\nIn 1954 Pat Hare produced heavily distorted power chords for several recordings (including James Cotton's \"), creating \"a grittier, nastier, more ferocious electric guitar sound,\" accomplished by turning the volume knob on his amplifier \"all the way to the right until the speaker was screaming.\" Link Wray's 1958 recording \"Rumble\" inspired young musicians such as Pete Townshend of The Who, Jimmy Page of Led Zeppelin, Jeff Beck, Dave Davies of The Kinks, and Neil Young to explore distortion. Davies would famously doctor the speakers of his amp by slitting them with a razor blade to achieve a grittier guitar sound on the 1964 song \"You Really Got Me\". In 1966, the British company Marshall Amplification began producing the Marshall 1963, a guitar amplifier capable of producing the distorted \"crunch\" that rock musicians were starting to seek.\n\nThe electronic transistor finally made it possible to cram the aural creativity of the recording studio into small, highly portable stompbox units. Transistors replaced vacuum tubes, allowing for much more compact formats and greater stability. The first transistorized guitar effect was the 1962 Maestro Fuzz Tone pedal, which became a sensation after its use in the 1965 Rolling Stones hit \"(I Can't Get No) Satisfaction\".\n\nWarwick Electronics manufactured the first wah-wah pedal, The Clyde McCoy, in 1967 and that same year Jim Morris of Kelsey-Morris Sound developed the first octave effect, which Jimi Hendrix named \"Octavio\". In 1968, Univox began marketing Shin-ei's Uni-Vibe pedal, an effect designed by noted audio engineer Fumio Mieda that mimicked the odd phase shift and chorus effects of the Leslie rotating speakers used in Hammond organs. The pedals soon became favorite effects of guitarists Jimi Hendrix and Robin Trower. Upon first hearing the Octavia, Hendrix allegedly rushed back to the studio and immediately used it to record the guitar solos on \"Purple Haze\" and \"Fire\". In 1976, Roland subsidiary Boss Corporation released the CE-1 Chorus Ensemble, the first chorus pedal, created by taking a chorus circuit from an amplifier and putting it into a stompbox. By the mid-1970s a variety of solid-state effects pedals including flangers, chorus pedals, ring modulators and phase shifters were available.\n\nIn the 1980s, digital rackmount units began replacing stompboxes as the effects format of choice. Often musicians would record \"dry\", unaltered tracks in the studio and effects would be added in post-production. The success of Nirvana's 1991 album \"Nevermind\" helped to re-ignite interest in stompboxes. Some grunge guitarists would chain several fuzz pedals together and plug them into a tube amplifier. Throughout the 1990s, musicians committed to a \"lo-fi\" aesthetic such as J Mascis of Dinosaur Jr., Stephen Malkmus of Pavement and Robert Pollard of Guided by Voices continued to use analog effects pedals.\nEffects and effects units—stompboxes in particular—have been celebrated by pop and rock musicians in album titles, songs and band names. The Big Muff, a classic fuzzbox manufactured by Electro-Harmonix, is commemorated by the Depeche Mode song \"Big Muff\" and the Mudhoney EP \"Superfuzz Bigmuff\". Nine Inch Nails, Pink Floyd, George Harrison, They Might Be Giants and Joy Division are among the many musicians who have referenced effects units in their music.\n\nDistortion effects create \"warm\", \"gritty\", and \"fuzzy\" sounds by \"clipping\" an instrument's audio signal, which distorts the shape of its wave form and adds overtones. Distortion effects are sometimes called \"gain\" effects, as distorted guitar sounds were first achieved by increasing the electric power supply, e.g. gain, to tube amplifiers.\n\nDistortion and overdrive: Distortion and overdrive units re-shape or \"clip\" an audio signal's wave form so that it has flattened peaks, creating \"warm\" sounds by adding harmonics or \"gritty\" sounds by adding inharmonic overtones. In tube amplifiers, distortion is created by compressing the instrument's out-going electrical signal in vacuum tubes or \"valves\". Distortion pedals produce perfectly flattened peaks or \"hard\" clipping. Overdrive pedals produce \"soft” tube-like distortion by compressing the sine wave without completely flattening it. Much like tube amps, overdrive units produce \"clean\" sounds at quieter volumes and distorted \"warm\" sounds at louder volumes. Distortion and overdrive pedals may either be transistor-based or digital. While distortion pedals are most associated with electric guitar, they are also used with bass guitar (fuzz bass), Hammond organ and electric piano.<br>\nDistortion and overdrive effects: Boss DS-1 Distortion, Ibanez Tube Screamer, Marshall ShredMaster, MXR Distortion +, Pro Co RAT.\n\nFuzz: A fuzz pedal or \"fuzzbox\" is a type of overdrive pedal that clips a sound-wave until it is nearly a squarewave, resulting in a heavily distorted or \"fuzzy\" sound. Fuzzboxes may contain frequency multiplier circuitry to achieve a harsh timbre by adding complex harmonics. The Rolling Stones' \"(I Can't Get No) Satisfaction\" greatly popularized the use of fuzz effects. Fuzz bass (also called \"bass overdrive\") is a style of playing the electric bass that produces a buzzy, overdriven sound via a tube or transistor amp or by using a fuzz or overdrive pedal.\n<br>\nFuzz effects: Arbiter Fuzz Face, Electro-Harmonix Big Muff, Shin-ei Companion FY-2, Univox Super-Fuzz, Vox Tone Bender, Z.Vex Fuzz Factory.\n\nAlso called volume and amplitude effects, dynamics effects modify the volume of an instrument. Dynamics effects were among the first effects introduced to guitarists.\n\nBoost/volume pedal: A boost or \"clean boost\" pedal amplifies the volume of an instrument by increasing the amplitude of its audio signal. These units are generally used for \"boosting\" volume during solos and preventing signal loss in long \"effects chains\". A guitarist switching from rhythm guitar to lead guitar for a guitar solo may use a boost to increase the volume of his or her solo.\n\nTreadle-based volume pedals are used by electric instrument players (guitar, bass, keyboards) to adjust the volume of their instrument with one foot while their hands are being used to play their instrument. Treadle-style volume pedals are often also used to create swelling effects by removing the attack of a note or chord, as popularised by pedal steel guitar players. This enables electric guitar and pedal steel players to imitate the soft swelling sound that an orchestra string section can produce, in which a note or chord starts very softly and then grows in volume. Treadle-based volume pedals do not usually have batteries or require external power.\nVolume effects: Electro-Harmonix LPB-1, Fender Volume Pedal, MXR Micro Amp, Ernie Ball Volume Pedal.\n\nCompressor: Compressors make loud sounds quieter and quiet sounds louder by decreasing or \"compressing\" the dynamic range of an audio signal. A compressor is often used to stabilize volume and smooth a note's \"attack\" by dampening its onset and amplifying its sustain. A compressor can also function as a limiter with extreme settings of its controls.<br>\nCompressor effects: Keeley Compressor, MXR Dyna Comp, Boss CS-3 Compression Sustainer.\n\nNoise gate: Noise gates attenuate hum, hiss, and static in the signal by greatly diminishing the volume when the signal falls below a set threshold. Noise gates are often used by electric guitarist who play with vintage amps, which can have unwanted hum in the tone, and by guitarists from heavy metal who use high distortion levels, which add noise to the signal even when no notes are being played. Noise gates mute the signal when it falls below a certain threshold. This means that during bars of rest for the guitarist in a song, the hum or noise from the amp or distortion pedal will not be heard by the audience. Noise gates are expanders—meaning that, unlike compressors, they increase the dynamic range of an audio signal to make quiet sounds even quieter. If used with extreme settings and combined with reverb, they can create unusual sounds, such as the gated drum effect used in 1980s pop songs, a style popularized by the Phil Collins song \"In the Air Tonight\".<br>\nNoise gate effects: Boss NS-2 Noise Suppressor.\n\nFilter effects alter the frequency content of an audio signal that passes through them by either boosting or weakening specific frequencies or frequency regions.\n\nEqualizer: An equalizer is a set of linear filters that strengthen (\"boost\") or weaken (\"cut\") specific frequency regions. While basic home stereos often have equalizers for two bands, to adjust bass and treble, professional graphic equalizers offer much more targeted control over the audio frequency spectrum. Audio engineers use highly sophisticated equalizers to eliminate unwanted sounds, make an instrument or voice more prominent, and enhance particular aspects of an instrument's tone.<br>\nEqualizer effects: Boss GE-7 Equalizer, MXR 10-band EQ Pedal.\n\nTalk box: A talk box directs the sound from an electric guitar or synthesizer into the mouth of a performer using a tube, allowing him or her to shape the sound into vowels and consonants with his or her mouth. The modified sound is then picked up by a microphone. In this way the guitarist is able create the effect that her or his guitar \"licks\" are \"talking\". Some famous uses of the talkbox include Bon Jovi's \"Livin' on a Prayer\", Stevie Wonder's \"Black Man\", Mötley Crüe's \"Kickstart My Heart\", Joe Walsh's \"Rocky Mountain Way\", Alice in Chains's \"Man in the box\" and Peter Frampton's \"Show Me the Way\".<br>\nTalk boxes: Dunlop HT1 Heil Talk Box, Rocktron Banshee.\n\nWah-wah: A wah-wah pedal creates vowel-like sounds by altering the frequency spectrum produced by an instrument—i.e., how loud it is at each separate frequency—in what is known as a spectral glide or \"sweep\".\nThe device is operated by a foot treadle that opens and closes a potentiometer. Wah-wah pedals are often used by funk and rock guitarists.<br>\nWah effects: Dunlop Cry Baby, Morley Power Wah, Musitronics Mu-Tron III.\n\n\"Modulation\", in general electronics, means the altering of signal strength. In audio devices, modulation is a control feature that varies the strength of some effect over time to alter tonal properties. Some modulation effects mix (\"modulate\") an instrument's audio signal with a signal generated by the effect called a carrier wave. Other modulation effects split an instrument's audio signal in two, altering one portion of the signal and mixing it with the unaltered portion.\n\nChorus: Chorus pedals mimic the effect choirs and string orchestras produce naturally, by having slight variations in timbre and pitch, by mixing sounds with slight differences in timbre and pitch. A chorus effect splits the instrument-to-amplifier audio signal, and adds a slight delay and frequency variations or \"vibrato\" to part of the signal while leaving the rest unaltered. A well-known usage of chorus is the lead guitar in \"Come As You Are\" by Nirvana.<br>\nChorus effects: Boss CE-1 Chorus Ensemble, Electro-Harmonix Small Clone, TC Electronic Stereo Chorus.\n\nFlanger: A flanger creates a \"whooshing\" \"jet plane\" or \"spaceship\" sound, simulating a studio effect that was first produced by recording a track on two synchronized tapes and periodically slowing one tape by pressing the edge of its reel (the \"flange\"). When the two tapes' audio signals are later mixed, a comb filter effect can be heard. Flanger units add a variably delayed version of the audio signal to the original or signal, creating a comb filter or Doppler effect. Some famous uses of flanger effects include \"Walking on the Moon\" by The Police, the intro to \"Ain't Talkin' 'Bout Love\" by Van Halen, and \"Barracuda\" by Heart.<br>\nFlanger effects: Electro-Harmonix Electric Mistress, MXR Flanger, Boss BF-3 Flanger.\n\nPhaser: A phaser or \"phase shifter\" creates a slight rippling effect—amplifying some aspects of the tone while diminishing others—by splitting an audio signal in two and altering the phase of one portion. Three well-known examples of phaser are the two handed tapping part on the Van Halen instrumental \"Eruption\" and the keyboard parts on Billy Joel's \"Just the Way You Are\" and Paul Simon's \"Slip Slidin' Away\".<br>\nPhase shift effects: Uni-Vibe, Electro-Harmonix Small Stone, MXR Phase 90.\n\nRing modulator: A ring modulator produces a resonant, metallic sound by mixing an instrument's audio signal with a carrier wave generated by the device's internal oscillator. The original sound wave is suppressed and replaced by a \"ring\" of inharmonic higher and lower pitches or \"sidebands\". A notable use of ring modulation is the guitar in the Black Sabbath song \"Paranoid\".<br>\nRing modulator effects: Moogerfooger MF-102 Ring Modulator.\n\nTremolo: A tremolo effect produces a slight, rapid variation in the volume of a note or chord. The \"tremolo effect\" should not be confused with the misleadingly-named \"tremolo bar\", a device on a guitar bridge that creates a vibrato or \"pitch-bending\" effect. In transistorized effects, a tremolo is produced by mixing an instrument's audio signal with a sub-audible carrier wave in such a way that generates amplitude variations in the sound wave. Tremolo effects are built-in effects in some vintage guitar amplifier. The guitar intro in the Rolling Stones' \"Gimme Shelter\" features a tremolo effect.<br>\nTremolo effects: Demeter TRM-1 Tremulator, Fender Tremolux.\n\nVibrato: Vibrato effects produce slight, rapid variations in pitch, mimicking the fractional semitone variations produced naturally by opera singers and violinists when they are prolonging a single note. Vibrato effects often allow the performer to control the rate of the variation as well as the difference in pitch (e.g. \"depth\"). A vibrato with an extreme \"depth\" setting (e.g., half a semitone or more) will produce a dramatic, ululating sound. In transistorized effects, vibrato is produced by mixing an instrument's audio signal with a carrier wave in such a way that generates frequency variations in the sound wave. Guitarists often use the terms \"vibrato\" and \"tremolo\" misleadingly. A so-called \"vibrato unit\" in a guitar amplifier actually produces tremolo, while a \"tremolo arm\" or \"whammy bar\" on a guitar produces vibrato.<br>\nVibrato effects: Boss VB-2 Vibrato.\n\nPitch/frequency effects modify pitch by altering the frequency of a sound wave or sound signal or adding new harmonies.\n\nPitch shifter and harmonizer: A pitch shifter (also called an \"octaver\" for effects that shift pitch by an octave) raises or lowers (e.g. \"transposes\") each note a performer plays by a pre-set interval. For example, a pitch shifter set to increase the pitch by a fourth will raise each note four diatonic intervals above the notes actually played. Simple, less expensive pitch shifters raise or lower the pitch by one or two octaves, while more sophisticated and expensive devices offer a range of interval alterations. A pitch shifter can be used by an electric guitarist to play notes that would normally only be available on an electric bass. As well, a bass player with a four string electric bass can use an octave pedal to obtain low notes that would normally only be obtainable with a five-string bass with a low \"B\" string.\n\nA harmonizer is a type of sophisticated pitch shifter that combines the altered pitch with the original pitch to create a two note harmony based on the original pitch, or even with some pedals, three note harmony. Some hamonizers are able to create chorus-like effects by adding very tiny shifts in pitch.<br> \nPitch shift effects: DigiTech Whammy, Electro-Harmonix POG.\n\nTime-based effects delay the sound signal, add reverb or echos, or, if a long delay is possible, enable musicians to record \"loops\".\nDelay/echo: Delay/echo units produce an echo effect by adding a duplicate instrument-to-amplifier electrical signal to the original signal at a slight time-delay. The effect can either be a single echo called a \"slap\" or \"slapback,\" or multiple echos. A well-known use of delay is the lead guitar in the U2 song \"Where the Streets Have No Name\", and also the opening riff of \"Welcome To The Jungle\" by Guns N'Roses.<br>\nDelay effects: Boss DD-3 Digital Delay, MXR Carbon Copy, Electro-Harmonix Deluxe Memory Man, Line 6 DL4, Roland RE-201.\n\nLooper pedal: A looper pedal or \"phrase looper\" allows a performer to record and later replay a phrase, riff or passage from a song. Loops can be created on the spot during a performance (live looping) or they can be pre-recorded. By using a looper pedal, a singer-guitarist in a one person band can play the backing chords (or riffs) to a song, loop them with the pedal, and then sing and do a guitar solo over the chords. Some units allow a performer to layer multiple loops, enabling the performer to create the effect of a full band. The first loop effects were created with reel-to-reel tape using a tape loop. High-end boutique tape loop effects are still used by some studio producers who want a vintage sound. Digital loop effects recreate this effect using an electronic memory.<br>\nLooper effects: Boss RC-30 Loop Station.\n\nReverb: Reverb units simulate the spacious sounds produced naturally in a huge stone cathedral (or other acoustic space such as a hall or room). This is done by creating a large number of echoes that gradually fade away in volume or \"decay\". One early technique for creating a reverb effect was to send an amplified signal of the music via a speaker to another room with reflective surfaces, such as a tile bathroom, and then record the natural reverberations that were produced. A plate reverb system uses an electromechanical transducer to create vibrations in a plate of metal. Spring reverb systems, which are often used in guitar amplifiers, use a transducer to create vibrations in a spring. Digital reverb effects use various signal processing algorithms to create the reverb effect, often by using multiple feedback delay circuits. Rockabilly and surf guitar are two genres that make heavy use of reverb.<br>\nReverb effects: Electro-Harmonix Holy Grail, Fender Reverb Unit.\n\nAudio feedback: Audio feedback is an effect produced when amplified sound is picked up by a microphone or guitar pickup and played back through an guitar amplifier, initiating a \"feedback loop\", which usually consists of high-pitched sound. Feedback that occurs from a vocal mic into a PA system is almost always avoided. However, in some styles of rock music, electric guitar players intentionally create feedback by playing their instrument directly in front of a heavily amplified, distorted guitar amplifier's speaker enclosure. The creative use of feedback effects was pioneered by guitarists such as Jimi Hendrix in the 1960s. This technique creates sustained, high-pitched overtones and unusual sounds not possible through regular playing techniques. Guitar feedback effects can be difficult to perform, because it is difficult to determine the sound volume and guitar position relative to a guitar amp's loudspeaker necessary for achieving the desired feedback sound. Guitar feedback effects are used in a number of rock genres, including psychedelic rock, heavy metal music and punk rock.\nEBow is a brand name of Heet Sound Products, of Los Angeles, California, for a small, handheld, battery-powered resonator. The Ebow was invented by Greg Heet, as a way to make a note on an electric guitar string resonate continuously, creating an effect that sounds similar to a bowed violin note or a sustained pipe organ note. The resonator uses a pickup - inductive string driver - feedback circuit, including a sensor coil, driver coil, and amplifier, to induce forced string resonance. The Ebow brand resonator is monophonic, and drives only one string at a time.\n\nOther handheld guitar and bass resonators on the market, manufactured under the tradename SRG, produced by Aescher Europa, in Germany, are available in both monophonic (one note at a time) and polyphonic (multiple notes at once) models, which include multiple onboard trigger switch effects, such as HPF (high pass filter) for enhancing harmonics and producing feedback effects, and LPF (low pass filter), producing a bass boost with a cello sound on heavy gauge strings. Later EBow models, such as the plus Ebow, contain a mode slide switch on the back, which allows the player to either produce just sustain or overtone feedback in addition to sustain.\n\nMany compressor pedals are often also marketed as \"sustainer pedals\". As a note is sustained, it loses energy and volume due to diminishing vibration in the string. The compressor pedal boosts its electrical signal to the specified dynamic range, slightly prolonging the duration of the note. This, combined with heavy distortion and the close proximity of the guitar and the speaker cabinet, can lead to infinite sustain at higher volumes.\n\nEnvelope follower: An envelope follower activates an effect once a designated volume is reached. One effect that uses an envelope follower is the \"auto-wah\", which produces a \"wah\" effect depending on how loud or soft the notes are being played.\n\nGuitar amplifier modeling: Amplifier modeling is a digital effect that replicates the sound of various amplifiers, most often vintage analog \"tube\" amps and famous brands of speaker cabinets (e.g., the Ampeg SVT 8x10\" bass cabinet). Sophisticated modeling effects can simulate different types of speaker cabinets (e.g., the sound of an 8x10\" cabinet) and miking techniques. A rotary speaker simulator mimics the doppler and chorus effect sound of a vintage Leslie speaker system by replicating its volume and pitch modulations, overdrive capacity and phase shifts.\n\nPitch correction/vocal effects: Pitch correction effects use signal-processing algorithms to re-tune faulty intonation in a vocalist's performance or create unusual vocoder-type vocal effects. One of the best known examples of this is Autotune, a software program and effect unit which can be used to both correct pitch (it moves a pitch to the nearest semitone), and add vocal effects. Some stompbox-style vocal pedals contain multiple effects, such as reverb and pitch correction.\n\nSimulators: Simulators enable electric guitars to mimic the sound of other instruments such as acoustic guitar, electric bass and sitar. Pick up simulators used on guitars with single-coil pick ups replicate the sound of guitars with humbucker pick ups, or vice versa. A de-fretter is a bass guitar effect that simulates the sound of a fretless bass. The effect uses an envelope-controlled filter and voltage-controlled amplifier to \"soften\" a note's attack both in volume and timbre.\nRotating speakers are specially constructed amplifier/loudspeakers used to create special audio effects using the Doppler effect by rotating the speakers or a sound-directing duct. The rotating speaker creates a chorus-type effect. Named after its inventor, Donald Leslie, it is particularly associated with the Hammond organ but is used with a variety of instruments as well as vocals. The Hammond/Leslie combination has become an element in many genres of music. The Leslie Speaker and the Hammond Organ brands are currently owned by Suzuki Musical Instrument Corporation. The stompbox that simulates this effect is the Uni-Vibe pedal.\n\nThe Korg Kaoss Pad is a small touchpad MIDI controller, sampler, and effects processor for audio and musical instruments, made by Korg. The Kaoss Pad's touchpad can be used to control its internal effects engine, which can be applied to a line-in signal or to samples recorded from the line-in. Effects types include pitch shifting, distortion, filtering, wah-wah, tremolo, flanging, delay, reverberation, auto-panning, gating, phasing, and ring modulation.\nThe Kaoss Pad can also be used as a MIDI controller.\n\nBass effects are electronic effects units that are designed for use with the low pitches created by an electric bass or for an upright bass used with a bass amp or PA system. Two examples of bass effects are fuzz bass and bass chorus. Some bass amplifiers have built-in effects, such as overdrive or chorus. Upright bassists in jazz, folk, blues and similar genres may use a bass preamplifier, a small electronic device that matches the impedance between the piezoelectric pickup and the amp or PA system. Bass preamps also allow for the gain of the signal to be boosted or cut. Some models also offer equalization controls, a compressor, and a DI box connection.\n\nBoutique pedals are designed by smaller, independent companies and are typically produced in limited quantities. Some may even be hand-made, with hand-soldered connections. These pedals are mainly distributed online or through mail-order, or sold in a few music stores. They are often more expensive than mass-produced pedals and offer non-standard features such as true-bypass switching, higher-quality components, innovative designs, in-house-made knobs and hand-painted artwork or etching. Some boutique companies focus on re-creating classic or vintage effects.<br>Some boutique pedal manufacturers include: Analog Man, BJFE, Pete Cornish, Emlyn Crowther, Death By Audio, Devi Ever, Robert Keeley, Roger Linn, Roger Mayer, Strymon, T-Rex Engineering, ToadWorks and Z.Vex Effects.\n\nThere is also a niche market for modifying or \"modding\" effects. Typically, vendors provide either custom modification services or sell new effects pedals they have already modified. The Ibanez Tube Screamer, Boss DS-1, Pro Co RAT and DigiTech Whammy are some of the most often-modified effects. Common modifications include value changes in capacitors or resistors, adding true-bypass so that the effect's circuitry is no longer in the signal path, substituting higher-quality components, replacing the unit's original operational amplifiers (op-amps), or adding functions to the device, such as allowing additional control of some factor or adding another output jack.\n\nNot all stompboxes and rackmounted electronic devices designed for musicians are effects. Strobe tuner and regular electronic tuner pedals indicate whether a guitar string is too sharp or flat. Stompbox-format tuner pedals route the electric signal for the instrument through the unit via a 1/4\" patch cable. These pedal-style tuners usually have an output so that the signal can be plugged into a guitar amp to produce sound. Rackmount power conditioner devices deliver a voltage of the proper level and characteristics to enable equipment to function properly (e.g., by providing transient impulse protection). A rackmounted wireless receiver unit is used to enable a guitarist or bassist to move around on stage without being connected to a cable. A footswitch pedal such as the \"A/B\" pedal routes a guitar signal to an amplifier or enables a performer to switch between two guitars, or between two amplifiers.\n\nGuitar amplifiers and electronic keyboards may have switch pedals for turning built-in reverb and distortion effects on and off; the pedals contain only a switch, with the circuitry for the effect being housed in the amplifier chassis. Some musicians who use rackmounted effects or laptops employ a MIDI controller pedalboard or armband remote controls to trigger sound samples, switch between different effects or control effect settings. A pedal keyboard uses pedals, but it is not an effect unit; it is a foot-operated keyboard in which the pedals are typically used to play bass lines.\n\n<br>\nTechnologies\n"}
{"id": "10166", "url": "https://en.wikipedia.org/wiki?curid=10166", "title": "Enron", "text": "Enron\n\nEnron Corporation was an American energy, commodities, and services company based in Houston, Texas. It was founded in 1985 as the result of a merger between Houston Natural Gas and InterNorth, both relatively small regional companies. Before its bankruptcy on December 2, 2001, Enron employed approximately 20,000 staff and was one of the world's major electricity, natural gas, communications and pulp and paper companies, with claimed revenues of nearly $101 billion during 2000. \"Fortune\" named Enron \"America's Most Innovative Company\" for six consecutive years.\n\nAt the end of 2001, it was revealed that its reported financial condition was sustained by institutionalized, systematic, and creatively planned accounting fraud, known since as the Enron scandal. Enron has since become a well-known example of willful corporate fraud and corruption. The scandal also brought into question the accounting practices and activities of many corporations in the United States and was a factor in the enactment of the Sarbanes–Oxley Act of 2002. The scandal also affected the greater business world by causing the dissolution of the Arthur Andersen accounting firm.\n\nEnron filed for bankruptcy in the Southern District of New York in late 2001 and selected Weil, Gotshal & Manges as its bankruptcy counsel. It ended its bankruptcy during November 2004, pursuant to a court-approved plan of reorganization. A new board of directors changed the name of Enron to Enron Creditors Recovery Corp., and emphasized reorganizing and liquidating certain operations and assets of the pre-bankruptcy Enron. On September 7, 2006, Enron sold Prisma Energy International Inc., its last remaining business, to Ashmore Energy International Ltd. (now AEI).\n\nOne of Enron's primary predecessors was the Northern Natural Gas Company, which was formed in 1930, in Omaha, Nebraska just a few months after Black Tuesday. The low cost of natural gas and cheap labor supply during the Great Depression helped to fuel the company's early beginnings. The company doubled in size by 1932 and was able to bring the first natural gas to Minnesota. Over the next 50 years, Northern expanded even more as it acquired many energy companies and created new divisions within. It was reorganized in 1979 as the main subsidiary of a holding company, InterNorth, which was a diversified energy and energy-related products company. Although most of the acquisitions conducted were successful, some ended poorly. InterNorth competed with Cooper Industries over a hostile takeover of Crouse-Hinds Company, who manufactured electrical products. InterNorth was ultimately unsuccessful as Cooper bought out Crouse-Hinds. Cooper and InterNorth feuded over numerous suits over the course of the takeover that were eventually settled after the transaction was completed. The subsidiary Northern Natural Gas operated the largest natural gas pipeline company in North America. By the 1980s, InterNorth became a major force for natural gas production, transmission and marketing as well as for natural gas liquids, and was an innovator in the plastics industry.\n\nThe Houston Natural Gas (HNG) corporation was initially formed from the Houston Oil Co. in 1925 to provide gas to customers in the Houston market through the building of gas pipelines. Under the leadership of CEO Robert Herring from 1967 to 1981, the company became a large dominant force in the energy sector with a large pipeline network as a result from prosperous period of growth in the early to mid 1970s. This growth was largely seen from the exploitation of unregulated Texas natural gas market and the commodity surge in the early 1970s. Towards the end of the 1970s HNG's luck began to run out with rising gas prices forcing clients to switch to oil. In addition, with the passing of the Natural Gas Policy Act of 1978, the Texas market was more difficult to profit from and as a result the profits of HNG fell. After Herring's death in 1981, M.D. Matthews briefly took over as CEO in a 3-year stint with initial success but ultimately saw a big dip in earnings that led to his exit. In 1984, Kenneth Lay succeeded Matthews and inherited the troubled, but large diversified energy conglomerate.\n\nInterNorth in its conservative success became a target of corporate takeovers. The most prominent being corporate raider Irwin Jacobs. InterNorth CEO Sam Segnar, in searching for a company to merge with to fend off takeover attempts as a poison pill, discovered HNG. In May 1985, Internorth acquired HNG for $2.3 billion, 40% higher than the current market price, in order to avoid the corporate takeover attempt. The combined assets of the two companies would create the second largest gas pipeline system at the time in the United States. Internorth’s north-south pipelines that served Iowa and Minnesota complemented HNG’s Florida and California east-west pipelines well.\n\nThe company was initially named \"HNG/InterNorth Inc.\", even though InterNorth was technically the parent. At the outset, Segnar was CEO for a short time, before he was fired by the Board of Directors whereupon Lay was tapped to be the new CEO. Lay moved the headquarters of the new company back to energy capital Houston. The company then set out to find a new name, spent upwards of $100,000 in focus groups and consulting before \"Enteron\" was suggested. The name was eventually dismissed over its apparent likening to an intestine and shortened to \"Enron.\" Enron still had some lingering problems left over from its merger, however. The company had to pay Jacobs, who was still a threat, over $350 million and reorganize the company. Lay sold off any parts of the company that he didn't believe belong in the long-term future of Enron. Lay consolidated all the gas pipeline efforts under the Enron Gas Pipeline Operating Company. In addition, the company began to ramp up its electric power and natural gas efforts. In 1988 and 1989, the company began adding power plants and cogeneration units to its portfolio. In 1989, Jeffrey Skilling, then a consultant at McKinsey & Co., came up with the idea to link natural gas to consumers in more ways, effectively turning natural gas into a commodity. Enron adopted the idea and called it the \"Gas Bank.\" The division's success prompted Skilling to join Enron as the head of the Gas Bank in 1991. Another major development inside Enron was the beginning of the company's pivot to overseas that was expanded upon in the 1990s. Starting in 1989, the company received a $56 million loan from the Overseas Private Investment Corporation (OPIC) for a power plant in Argentina.\n\nOver the course of the 1990s, Enron made a few changes to its business plan that greatly improved the perceived profitability of the company. Firstly, Enron invested heavily in overseas assets, specifically energy. Another major shift was the gradual transition of focus from a producer of energy to a company that acted more like an investment firm and sometimes a hedge fund, making profits off the margins of the products it traded. These products were traded through the Gas Bank concept, now called the Enron Finance Corp. headed by Skilling.\n\nWith the success of the Gas Bank trading natural gas, Skilling looked to expand the horizons of his division, Enron Capital & Trade. Skilling hired Andrew Fastow in 1990 to help with this.\n\nStarting in 1994 under the Energy Policy Act of 1992, Congress allowed states to deregulate their electricity utilities, allowing them to be opened for competition. California was one such state to do so. Enron, seeing an opportunity with rising prices, was eager to jump into the market. In 1997, Enron acquired Portland General Electric (PGE); while an Oregon utility, it had potential to begin serving the massive California market since PGE was a regulated utility. The new Enron division, Enron Energy, ramped up its efforts by offering discounts to potential customers in California for switching their electric supplier to Enron from their previous supplier starting 1998. Enron Energy also began to sell natural gas to customers in Ohio and wind power in Iowa. However, in 1999, the company ended its retail endeavor, only offering wholesale energy as it was revealed it was spending upwards of $100 million a year.\n\nAs fiber optic technology progressed in the 1990s, multiple companies, including Enron, attempted to make money by \"keeping the continuing network costs low\", which was done by owning their personal network. In 1997, FTV Communications LLC, a limited liability company formed by Enron subsidiary FirstPoint Communications, Inc., Williams Communications Group, Inc. and Touch America. FTV constructed a 1,380 mile fiber optic network between Portland and Las Vegas. In 1998, Enron constructed a building in a rundown area of Las Vegas near E Sahara, building right over the \"backbone\" of fiber optic cables providing service to technology companies nationwide. The location had the ability to send \"the entire Library of Congress anywhere in the world within minutes\" and could stream \"video to the whole state of California\". The location was also more protected from natural disasters than areas such as Los Angeles or the East Coast. According to \"Wall Street Daily\", \"Enron had a secret\" and that they \"wanted to trade bandwidth like it traded oil, gas, electricity, etc. It launched a secret plan to build an enormous amount of fiber optic transmission capacity in Las Vegas ... it was all part of Enron’s plan to essentially own the internet\", essentially, Enron sought to have all US internet service providers rely on their Nevada facility to supply bandwidth, which Enron would sell in a fashion similar to other commodities.\n\nIn January 2000, Kenneth Lay and Jeffrey Skilling announced to analysts that they were going to open trading for their own \"high-speed fiber-optic networks that form the backbone for Internet traffic\". Investors quickly bought Enron stock following the announcement \"as they did with most things Internet-related at the time\", with stock prices rising from $40 per share in January 2000 to $70 per share in March, peaking at $90 in the summer of 2000. Enron executives obtained windfall gains from the rising stock prices, with a total of $924 million of stocks sold by high-lever Enron employees between 2000 and 2001. Head of Enron Broadband Services, Kenneth Rice, sold 1 million shares himself, earning about $70 million in returns. As prices of existing fiber optic cables plummeted due to the vast oversupply of the system, with only 5% of the 40 million miles being active wires, Enron purchased the inactive \"dark fibers\", expecting to buy them for cheap and then score a profit as the need for more usage by internet providers increased, with Enron expecting to lease its acquired dark fibers in 20 year contracts to providers. However, Enron's accounting would use estimates to determine how much their dark fibers would be worth when they were \"lit\" and apply those estimates to their current income, adding exaggerated revenue to their accounts since transactions were not yet made and it was not known if the cables would ever be active. Enron's trading with other energy companies within the broadband market was its attempt to lure large telecommunications companies, such as Verizon Communications, into its broadband scheme to create its own new market.\n\nBy the second quarter of 2001, Enron Broadband Services was reporting losses. On March 12, 2001, a proposed 20-year deal between Enron and Blockbuster Inc. to stream movies on demand over Enron's connections was cancelled, with Enron shares dropping from $80 per share in mid-February 2001 to below $60 the week after the deal was killed. The branch of the company that Jeffrey Skilling \"said would eventually add $40 billion to Enron's stock value\" added only about $408 million in revenue for Enron in 2001, with the company's broadband arm closed shortly after its meager second quarter earnings report in July 2001.\n\nFollowing the bankruptcy of Enron, telecommunications holdings were sold for \"pennies on the dollar\". In 2002, Rob Roy of Switch Communications, with the help of a \"reclusive majority shareholder\", purchased Enron's Nevada facility in an auction only attended by Roy since Enron's \"fiber plans were so secretive that few people even knew about the auction\", with the facility selling for only $930,000. Following the sale, Switch expanded to control \"the biggest data centers in the world\".\n\nEnron, seeing stability after the merger, began to look overseas for new possible energy opportunities in 1991. Enron's first such opportunity was a natural gas power plant utilizing cogeneration that the company built in Teesside, UK. The power plant was so large it could produce up to 3% of the United Kingdom's electricity demand with a capacity of over 1,875 megawatts. Seeing the success in England, the company developed and diversified its assets worldwide under the name of Enron International (EI), headed by former HNG executive Rebecca Mark. By 1994, EI's portfolio included assets in Philippines, Australia, Guatemala, Germany, France, India, Argentina, the Caribbean, China, England, Colombia, Turkey, Bolivia, Brazil, Indonesia, Norway, Poland, and Japan. The division was becoming a large share of earnings for Enron, contributing 25% of earnings in 1996. Mark and EI believed the water industry was the next market to be deregulated by authorities and seeing the potential, searched for ways to enter the market, similar to PGE. \n\nIn 1998, Enron International acquired Wessex Water for $2.88 billion. Wessex Water became the core asset of a new company, Azurix, which expanded to other water companies. After Azurix's promising IPO in June 1999, Enron \"sucked out over $1 billion in cash while loading it up with debt\", according to Bethany McLean and Peter Elkind, authors of \"\". Additionally, British water regulators required Wessex to cut its rates by 12% starting in April 2000, and an upgrade was required of the utility's aging infrastructure, estimated at costing over a billion dollars. By the end of 2000 Azurix had an operating profit of less than $100 million and was $2 billion in debt. In August 2000, after Azurix stock took a plunge following its earnings report, Mark resigned from Azurix and Enron. Azurix assets, including Wessex, were eventually sold by Enron.\n\nIn 1990, Enron's Chief Operating Officer Jeffrey Skilling hired Andrew Fastow, who was well acquainted with the burgeoning deregulated energy market that Skilling wanted to exploit. In 1993, Fastow began establishing numerous limited liability special purpose entities (a common business practice in the energy sector); however, it also allowed Enron to transfer liability so that it would not appear in its accounts, allowing it to maintain a robust and generally increasing stock price and thus keeping its critical investment grade credit ratings.\n\nEnron was originally involved in transmitting and distributing electricity and natural gas throughout the United States. The company developed, built, and operated power plants and pipelines while dealing with rules of law and other infrastructures worldwide. Enron owned a large network of natural gas pipelines, which stretched ocean to ocean and border to border including Northern Natural Gas, Florida Gas Transmission, Transwestern Pipeline company and a partnership in Northern Border Pipeline from Canada. The states of California, New Hampshire and Rhode Island had already passed power deregulation laws by July 1996, the time of Enron's proposal to acquire Portland General Electric corporation. During 1998, Enron began operations in the water sector, creating the Azurix Corporation, which it part-floated on the New York Stock Exchange during June 1999. Azurix failed to become successful in the water utility market, and one of its major concessions, in Buenos Aires, was a large-scale money-loser. After the relocation to Houston, many analysts criticized the Enron management as being greatly in debt. Enron management pursued aggressive retribution against its critics, setting the pattern for dealing with accountants, lawyers, and the financial media.\n\nEnron grew wealthy due largely to marketing, promoting power, and its high stock price. Enron was named \"America's Most Innovative Company\" by the magazine \"Fortune\" for six consecutive years, from 1996 to 2001. It was on the \"Fortune\"s \"100 Best Companies to Work for in America\" list during 2000, and had offices that were stunning in their opulence. Enron was hailed by many, including labor and the workforce, as an overall great company, praised for its large long-term pensions, benefits for its workers and extremely effective management until the exposure of its corporate fraud. The first analyst to question the company's success story was Daniel Scotto, an energy market expert at BNP Paribas, who issued a note in August 2001 entitled \"Enron: All stressed up and no place to go\", which encouraged investors to sell Enron stocks, although he only changed his recommendation on the stock from \"buy\" to \"neutral\".\n\nAs was later discovered, many of Enron's recorded assets and profits were inflated or even wholly fraudulent and nonexistent. One example of fraudulent records was during 1999 when Enron promised to repay Merrill Lynch & Co.'s investment with interest in order to show profit on its books. Debts and losses were put into entities formed \"offshore\" that were not included in the company's financial statements, and other sophisticated and arcane financial transactions between Enron and related companies were used to eliminate unprofitable entities from the company's books.\n\nThe company's most valuable asset and the largest source of honest income, the 1930s-era Northern Natural Gas company, was eventually purchased by a group of Omaha investors, who relocated its headquarters back to Omaha; it is now a unit of Warren Buffett's Berkshire Hathaway Energy. NNG was established as collateral for a $2.5 billion capital infusion by Dynegy Corporation when Dynegy was planning to buy Enron. When Dynegy examined Enron's financial records carefully, they repudiated the deal and dismissed their CEO, Chuck Watson. The new chairman and CEO, the late Daniel Dienstbier, had been president of NNG and an Enron executive at one time and was forced out of Enron by Ken Lay. Dienstbier was an acquaintance of Warren Buffett. NNG continues to be profitable now.\n\nDuring 2001, after a series of revelations involving irregular accounting procedures bordering on fraud perpetrated throughout the 1990s involving Enron and its accounting company Arthur Andersen, Enron suffered the largest Chapter 11 bankruptcy in history (since surpassed by those of Worldcom during 2002 and Lehman Brothers during 2008).\n\nAs the scandal progressed, Enron share prices decreased from US $90.56 during the summer of 2001, to just pennies. Enron had been considered a blue chip stock investment, so this was an unprecedented event in the financial world. Enron's demise occurred after the revelation that much of its profits and revenue were the result of deals with special purpose entities (limited partnerships which it controlled). This meant that many of Enron's debts and the losses that it suffered were not reported in its financial statements.\n\nA rescue attempt by a similar, smaller energy company, Dynegy, failed during late November due to concerns about an unexpected restatement of earnings. Enron filed for bankruptcy on December 2, 2001. In addition, the scandal caused the dissolution of Arthur Andersen, which at the time was one of the \"Big Five\" - the world's foremost accounting firms. The company was found guilty of obstruction of justice during 2002 for destroying documents related to the Enron audit. Since the SEC is not allowed to accept audits from convicted felons, Andersen was forced to stop auditing public companies. Although the conviction was dismissed during 2005 by the Supreme Court, the damage to the Andersen name has prevented it from reviving as a viable business even on a limited scale.\n\nEnron also withdrew a naming-rights deal with the Houston Astros Major League Baseball club to have its name associated with their new stadium, which was known formerly as Enron Field (now Minute Maid Park).\n\nEnron used a variety of deceptive, bewildering, and fraudulent accounting practices and tactics to cover its fraud in reporting Enron's financial information. Special Purpose Entities were created to mask significant liabilities from Enron's financial statements. These entities made Enron seem more profitable than it actually was, and created a dangerous spiral in which, each quarter, corporate officers would have to perform more and more financial deception to create the illusion of billions of dollars in profit while the company was actually losing money. This practice increased their stock price to new levels, at which point the executives began to work on insider information and trade millions of dollars' worth of Enron stock. The executives and insiders at Enron knew about the offshore accounts that were hiding losses for the company; however, the investors knew nothing of this. Chief Financial Officer Andrew Fastow directed the team which created the off-books companies, and manipulated the deals to provide himself, his family, and his friends with hundreds of millions of dollars in guaranteed revenue, at the expense of the corporation for which he worked and its stockholders.\n\nDuring 1999, Enron initiated EnronOnline, an Internet-based trading operation, which was used by virtually every energy company in the United States. Enron president and chief operating officer Jeffrey Skilling began advocating a novel idea: the company didn't really need any \"assets\". By promoting the company's aggressive investment strategy, he helped make Enron the biggest wholesaler of gas and electricity, trading over $27 billion per quarter. The corporation's financial claims, however, had to be accepted at face value. Under Skilling, Enron adopted mark to market accounting, in which anticipated future profits from any deal were tabulated as if currently real. Thus, Enron could record gains from what over time might turn out to be losses, as the company's fiscal health became secondary to manipulating its stock price on Wall Street during the so-called Tech boom. But when a company's success is measured by undocumented financial statements, actual balance sheets are inconvenient. Indeed, Enron's unscrupulous actions were often gambles to keep the deception going and so increase the stock price. An advancing price meant a continued infusion of investor capital on which debt-ridden Enron in large part subsisted (much like a financial \"pyramid\" or \"Ponzi scheme\"). Attempting to maintain the illusion, Skilling verbally attacked Wall Street Analyst Richard Grubman, who questioned Enron's unusual accounting practice during a recorded conference telephone call. When Grubman complained that Enron was the only company that could not release a balance sheet along with its earnings statements, Skilling replied \"Well, thank you very much, we appreciate that ... asshole.\" Though the comment was met with dismay and astonishment by press and public, it became an inside joke among many Enron employees, mocking Grubman for his perceived meddling rather than Skilling's offensiveness. When asked during his trial, Skilling declared that industrial dominance and abuse was a global problem: \"Oh yes, yes sure, it is.\"\n\nEnron initially planned to retain its three domestic pipeline companies as well as most of its overseas assets. However, before emerging from bankruptcy, Enron sold its domestic pipeline companies as CrossCountry Energy for $2.45 billion and later sold other assets to Vulcan Capital Management.\n\nEnron sold its last business, Prisma Energy, during 2006, leaving Enron asset-less. During early 2007, its name was changed to Enron Creditors Recovery Corporation. Its goal is to repay the old Enron's remaining creditors and end Enron's affairs.\n\nAzurix, the former water utility part of the company, remains under Enron ownership, although it is currently asset-less. It is involved in several litigations against the government of Argentina claiming compensation relating to the negligence and corruption of the local governance during its management of the Buenos Aires water concession during 1999, which resulted in substantial amounts of debt (approx. $620 million) and the eventual collapse of the branch.\n\nSoon after emerging from bankruptcy during November 2004, Enron's new board of directors sued 11 financial institutions for helping Lay, Fastow, Skilling and others hide Enron's true financial condition. The proceedings were dubbed the \"megaclaims litigation\". Among the defendants were Royal Bank of Scotland, Deutsche Bank and Citigroup. , Enron has settled with all of the institutions, ending with Citigroup. Enron was able to obtain nearly $7.2 billion to distribute to its creditors as a result of the megaclaims litigation. As of December 2009, some claim and process payments were still being distributed.\n\nDuring August 2000, Enron's stock price attained its greatest value of $90.56 At this time Enron executives, who possessed inside information on the hidden losses, began to sell their stock. At the same time, the general public and Enron's investors were told to buy the stock. Executives told the investors that the stock would continue to increase until it attained possibly the $130 to $140 range, while secretly unloading their shares.\n\nAs executives sold their shares, the price began to decrease. Investors were told to continue buying stock or hold steady if they already owned Enron because the stock price would rebound during the near future. Kenneth Lay's strategy for responding to Enron's continuing problems was his demeanor. As he did many times, Lay would issue a statement or make an appearance to calm investors and assure them that Enron was doing well. In February 2001 an article by Bethany McLean appeared in \"Fortune\" magazine questioning whether Enron stock was overvalued.\n\nBy August 15, 2001, Enron's stock price had decreased to $42. Many of the investors still trusted Lay and believed that Enron would rule the market. They continued to buy or retain their stock as the equity value decreased. As October ended, the stock had decreased to $15. Many considered this a great opportunity to buy Enron stock because of what Lay had been telling them in the media.\n\nLay was accused of selling more than $70 million worth of stock at this time, which he used to repay cash advances on lines of credit. He sold another $29 million worth of stock in the open market. Also, Lay's wife, Linda, was accused of selling 500,000 shares of Enron stock totaling $1.2 million on November 28, 2001. The money earned from this sale did not go to the family but rather to charitable organizations, which had already received pledges of contributions from the foundation. Records show that Mrs. Lay made the sale order sometime between 10:00 and 10:20 am. News of Enron's problems, including the millions of dollars in losses they hid, became public about 10:30 that morning, and the stock price soon decreased to less than one dollar.\n\nFormer Enron executive Paula Rieker was charged with criminal insider trading and sentenced to two years probation. Rieker obtained 18,380 Enron shares for $15.51 a share. She sold that stock for $49.77 a share during July 2001, a week before the public was told what she already knew about the $102 million loss.\nIn 2002, after the tumultuous fall of Enron's external auditor, and management consultant, Andersen LLP, former Andersen Director, John M. Cunningham coined the phrase, \"We have all been Enroned.\"\n\nThe fallout resulted in both Lay and Skilling being convicted for conspiracy, fraud, and insider trading. Lay died before sentencing, Skilling got 24 years and 4 months and a $45 million penalty (later reduced). Fastow got 6 years of jail time, and Lou Pai settled out of court for $31.5 million.\n\nDuring October 2000, Daniel Scotto, the most renowned utility analyst on Wall Street, suspended his ratings on all energy companies conducting business in California because of the possibility that the companies would not receive full and adequate compensation for the deferred energy accounts used as the basis for the California Deregulation Plan enacted during the late 1990s. Five months later, Pacific Gas & Electric (PG&E) was forced into bankruptcy. Senator Phil Gramm, husband of Enron Board member Wendy Gramm and also the second largest recipient of campaign contributions from Enron, succeeded in legislating California's energy commodity trading deregulation. Despite warnings from prominent consumer groups which stated that this law would give energy traders too much influence over energy commodity prices, the legislation was passed during December 2000.\n\nAs the periodical Public Citizen reported, \"Because of Enron's new, unregulated power auction, the company's 'Wholesale Services' revenues quadrupled—- from $12 billion in the first quarter of 2000 to $48.4 billion in the first quarter of 2001.\"\n\nAfter passage of the deregulation law, California had a total of 38 Stage 3 rolling blackouts declared, until federal regulators intervened during June 2001. These blackouts occurred as a result of a poorly designed market system that was manipulated by traders and marketers, as well as poor state management and regulatory oversight. Subsequently, Enron traders were revealed as intentionally encouraging the removal of power from the market during California's energy crisis by encouraging suppliers to shut down plants to perform unnecessary maintenance, as documented in recordings made at the time. These acts contributed to the need for rolling blackouts, which adversely affected many businesses dependent upon a reliable supply of electricity, and inconvenienced a large number of retail customers. This scattered supply increased the price, and Enron traders were thus able to sell power at premium prices, sometimes up to a factor of 20x its normal peak value.\n\nEnron traded in more than 30 different products, including the following:\n\n\nIt was also an extensive futures trader, including sugar, coffee, grains, hogs, and other meat futures. At the time of its bankruptcy filing during December 2001, Enron was structured into seven distinct business units.\n\n\n\n\n\n\nEnron manufactured gas valves, circuit breakers, thermostats, and electrical equipment in Venezuela by means of INSELA SA, a 50–50 joint venture with General Electric. Enron owned three paper and pulp products companies: Garden State Paper, a newsprint mill; as well as Papiers Stadacona and St. Aurelie Timberlands. Enron had a controlling stake in the Louisiana-based petroleum exploration and production company Mariner Energy.\n\nEnron opened EnronOnline, an electronic trading platform for energy commodities, on November 29, 1999. Conceptualized by the company's European Gas Trading team, it was the first web-based transaction system that allowed buyers and sellers to buy, sell, and trade commodity products globally. It allowed users to do business only with Enron. The site allowed Enron to transact with participants in the global energy markets. The main commodities offered on EnronOnline were natural gas and electricity, although there were 500 other products including credit derivatives, bankruptcy swaps, pulp, gas, plastics, paper, steel, metals, freight, and TV commercial time. At its maximum, more than $6 billion worth of commodities were transacted by means of EnronOnline every day.\n\nAfter Enron's bankruptcy in late 2001, EnronOnline was sold to the Swiss financial giant UBS. Within a year, UBS abandoned its efforts to relaunch the division, and closed it in November 2002.\n\nEnron International (EI) was Enron's wholesale asset development and asset management business. Its primary emphasis was developing and building natural gas power plants outside North America. Enron Engineering and Construction Company (EECC) was a wholly owned subsidiary of Enron International, and built almost all of Enron International's power plants. Unlike other business units of Enron, Enron International had a strong cash flow on bankruptcy filing. Enron International consisted of all of Enron's foreign power projects, including ones in Europe.\n\nThe company's Teesside plant was one of the largest gas-fired power stations in the world, built and operated by Enron from 1989, and produced 3 percent of the United Kingdom's energy needs. Enron owned half of the plant's equity, with the remaining 50 per cent split between four regional electricity companies.\n\nRebecca Mark was the CEO of Enron International until she resigned to manage Enron's newly acquired water business, Azurix, during 1997. Mark had a major role in the development of the Dabhol project in India, Enron's largest international endeavor.\n\nEnron International constructed power plants and pipelines across the globe. Some are presently still operating, including the massive Teesside plant in England. Others, like a barge-mounted plant off Puerto Plata in the Dominican Republic, cost Enron money by lawsuits and investment losses. Puerto Plata was a barge-mounted power plant next to the hotel \"Hotelero del Atlantico\". When the plant was activated, winds blew soot from the plant onto the hotel guests' meals, blackening their food. The winds also blew garbage from nearby slums into the plant's water-intake system. For some time the only solution was to hire men who would row out and push the garbage away with their paddles. Through mid-2000 the company collected a paltry $3.5 million from a $95 million investment. Enron also had other investment projects in Europe, South America, Argentina, Brazil, Bolivia, Colombia, Mexico, Jamaica, Venezuela, and across the Caribbean.\n\nAround 1992 Indian experts came to the United States to find energy investors to help with India's energy shortage problems. During December 1993, Enron finalized a 20-year power-purchase contract with the Maharashtra State Electricity Board. The contract allowed Enron to construct a massive 2,015 megawatt power plant on a remote volcanic bluff south of Mumbai. Construction would be completed in two phases, and Enron would form the Dabhol Power Company to help manage the plant. The power project was the first step in a $20 billion scheme to help rebuild and stabilize India's power grid. Enron, GE (which was selling turbines to the project), and Bechtel (which was actually constructing the plant), each contributed 10% equity.\n\nDuring 1996, when India's Congress Party was no longer in power, the Indian government assessed the project as being excessively expensive and refused to pay for the plant and stopped construction. The Maharashtra State Electricity Board (MSEB), the local state-owned utility, was required by contract to continue to pay Enron plant maintenance charges, even if no power was purchased from the plant. The MSEB determined that it could not afford to purchase the power (at Rs. 8 per unit kWh) charged by Enron. The plant operator was unable to find alternate customers for Dabhol power due to the absence of a free market in the regulated structure of utilities in India. From 1996 until Enron's bankruptcy during 2001 the company tried to revive the project and revive interest in India's need for the power plant without success.\n\nDuring the summer of 2001, Enron made an attempt to sell a number of Enron International's assets, many of which were not sold. The public and media believed it was unknown why Enron wanted to sell these assets, suspecting it was because Enron was in need of cash.\nEmployees who worked with company assets were told in 2000 that Jeff Skilling believed that business assets were an outdated means of company worth, and instead he wanted to build a company based on \"intellectual assets\".\n\nEnron Global Exploration & Production Inc. (EGEP) was an Enron subsidiary that was born from the split of domestic assets via EOG Resources (formerly Enron Oil and Gas EOG) and international assets via EGEP (formerly Enron Oil and Gas Int'l, Ltd EOGIL). \nAmong the EGEP assets were the Panna-Mukta and the South Tapti fields, discovered by the Indian state-owned Oil and Natural Gas Corporation (ONGC), which operated the fields initially.\nDecember 1994, a joint venture began between ONGC (40%), Enron (30%) and Reliance (30%).\nMid year of 2002, British Gas (BG) completed the acquisition of EGEP's 30% share of the Panna-Mukta and Tapti fields for $350 million, a few months before Enron filed bankruptcy.\n\nDuring the mid-1990s, Enron established an endowment for the Enron Prize for Distinguished Public Service, awarded by Rice University's Baker Institute to \"recognize outstanding individuals for their contributions to public service\". Recipients were:\n\n\nGreenspan, because of his position as the Fed chairman, was not at liberty to accept the $10,000 honorarium, the $15,000 sculpture, nor the crystal trophy, but only accepted the \"honor\" of being named an Enron Prize recipient. The situation was further complicated because a few days earlier, Enron had filed paperwork admitting it had falsified financial statements for five years. Greenspan did not mention Enron a single time during his speech. At the ceremony, Ken Lay stated, \"I'm looking forward to our first woman recipient.\" The next morning, it was reported in the \"Houston Chronicle\" that no decision had been made on whether the name of the prize would be changed. 19 days after the prize was awarded to Greenspan, Enron declared bankruptcy.\n\nDuring early 2002, Enron was awarded Harvard's (in)famous Ig Nobel Prize for 'Most Creative Use of Imaginary Numbers.' The various former members of Enron management all refused to accept the award in person, although no reason was given at the time.\n\n\n\n\n\n"}
{"id": "10168", "url": "https://en.wikipedia.org/wiki?curid=10168", "title": "Eusebius of Alexandria", "text": "Eusebius of Alexandria\n\nEusebius of Alexandria is an author to whom certain extant homilies are attributed.\n\nNothing is known of the author. In all events, he was not a patriarch of Alexandria, as is affirmed in an early biography, written by one Johannes, a notary, and stating that Eusebius was called by Cyril to be his successor in the episcopate.\n\nThere has been much dispute regarding the details of his life and the age in which he lived. Galland (Vet. Patr. Biblioth., VIII, 23) says: \"de Eusebio qui vulgo dicitur episcopus Alexandræ incerta omnia\" (Concerning Eusebius, commonly called bishop of Alexandria there is nothing sure). His writings have been attributed to Eusebius of Emesa, Eusebius of Cæsarea, and others. According to an old biography said to have been written by his notary, the monk John, and discovered by Cardinal Mai, he lived in the fifth century and led a monastic life near Alexandria. The fame of his virtues attracted the attention of Cyril, Bishop of Alexandria, who visited him with his clergy, and in 444, when dying, had him elected his successor, and consecrated him bishop, though much against his will. Eusebius displayed great zeal in the exercise of his office and did much good by his preaching. Among those he converted was a certain Alexander, a man of senatorial rank. After having ruled his see for seven or, according to another account, for twenty years, he made Alexander his successor and retired to the desert, whence Cyril had summoned him and there died in the odor of sanctity.\n\nWhile Mai seems to have established the existence of a Eusebius of Alexandria who lived in the fifth century, it had been objected than neither the name of Eusebius or his successor Alexander, appears in the list of the occupants of that ancient see. Dioscurus is mentioned as the immediate successor of Cyril. Nor does the style of the homilies seem on the whole in keeping with the age of Cyril. It may be noted, however, that the biographer of Eusebius expressly states that the Cyril in question is the great opponent of Nestorius. Various solution of the difficulty have been proposed. Thilo thinks that the authorship of the homilies is to be assigned either to a certain monk – one of four brothers 3 of the fifth century, or to a presbyter and court chaplain of Justinian I, who took an active part in the theological strifes of the sixth century. Mai suggests that after the death of Cyril, there were two bishops at Alexandria, Dioscurus, the Monophysite leader, and Eusebius, the head of the Catholic party. The homilies cover a variety of subjects, and the author is one of the earliest patristic witnesses to the doctrine regarding the descent of Christ into Hell. A list of homilies with the complete text is given by Mai. They may also be found in Migne, which was published with an introduction by Rand in \"Modern Philology\", II, 261.\n\nThese homilies enjoyed some renown in the Eastern Church in the sixth and seventh centuries.\n\nThe discourses belong probably to the fifth or sixth century, and possibly originated in Alexandria. They deal with the life of Jesus of Nazareth and with questions of ecclesiastical life and practise, which they resolve in a monastic-ascetic way. Their literary character is not quite clear; while most of them are adapted for public delivery, not a few bear the character of ecclesiastical pronouncements. They are now in print except four included among John Chrysostom's works. The fragments preserved in the so-called \"Sacra parallela\" are to be found in Karl Holl's \"Fragmente vornicänischer Kirchenväter.\" A homily concerning the observance of Sunday is attributed by Zahn to Eusebius of Emesa.\n"}
{"id": "10169", "url": "https://en.wikipedia.org/wiki?curid=10169", "title": "Eusebius of Angers", "text": "Eusebius of Angers\n\nEusebius (Bruno) of Angers (died September 1, 1081) was bishop of Angers, France.\n\nHe first appears in the historical record as bishop of Angers at the synod of Rheims in 1049, and for a long time had been an adherent of Berengar's doctrine of the Lord's Supper. As such he was regarded by Berengar himself and by his opponents Dietwin of Liege (Theodwin), Durand of Troarne, and Humbert of Mourmoutiers. But when he recognized the strength of the opposition, he favored a compromise; at any rate he advised Berengar is 1054 to swear to the formula presented to him.\n\nNevertheless, Berengar considered him his friend many years later and requested him to silence a certain Galfrid Martini or to arrange a disputation. In his reply Eusebius not only regretted the whole controversy, but also stated that he would abide by the words of the Bible, according to which the bread and wine after the consecration become the body and blood of the Lord (see transubstantiation); if one asks how this can take place, the answer must be that it is not according to the order of nature but in accordance with the divine omnipotence; at any rate one must be careful not to give offense to the plain Christian. The epistle is a downright renunciation of Berengar in case he should still maintain his view.\n\nIn favor of the supposition that Eusebius changed his opinion from deference to the Count of Anjou, the decided opponent of Berengar and his doctrine, it can be adduced that he did not defend Berengar against the hostilities of the court, and that for a long time he sided with this violent prince. It is also possible that the fact impressed itself upon Eusebius that the religious consciousness of the time more and more opposed Berengar. Our knowledge, however, is too fragmentary to pass a very accurate sentence.\n"}
{"id": "10172", "url": "https://en.wikipedia.org/wiki?curid=10172", "title": "Eusebius", "text": "Eusebius\n\nEusebius of Caesarea (; , \"Eusébios tés Kaisareías\";  260/265 – 339/340), also known as Eusebius Pamphili, was a Greek historian of Christianity, exegete, and Christian polemicist. He became the bishop of Caesarea Maritima about 314 AD. Together with Pamphilus, he was a scholar of the Biblical canon and is regarded as an extremely learned Christian of his time. He wrote \"Demonstrations of the Gospel\", \"Preparations for the Gospel\", and \"On Discrepancies between the Gospels\", studies of the Biblical text. As \"Father of Church History\" he produced the \"Ecclesiastical History\", \"On the Life of Pamphilus\", the \"Chronicle\" and \"On the Martyrs\".\n\nLittle is known about the life of Eusebius. His successor at the See of Caesarea, Acacius, wrote a \"Life of Eusebius\", a work that has since been lost. Eusebius' own surviving works probably only represent a small portion of his total output. Beyond notices in his extant writings, the major sources are the 5th-century ecclesiastical historians Socrates, Sozomen, and Theodoret, and the 4th-century Christian author Jerome. There are assorted notices of his activities in the writings of his contemporaries Athanasius, Arius, Eusebius of Nicomedia, and Alexander of Alexandria. Eusebius' pupil, Eusebius of Emesa, provides some incidental information.\n\nIn his \"Ecclesiastical History\", Eusebius writes of Dionysius of Alexandria as his contemporary. If this is true, Eusebius' birth must have been before Dionysius' death in autumn 264; most modern scholars date the birth to some point in the five years between 260 and 265. He was presumably born in the town in which he lived for most of his adult life, Caesarea Maritima. He was baptized and instructed in the city, and lived in Palestine in 296, when Diocletian's army passed through the region (in the \"Life of Constantine\", Eusebius recalls seeing Constantine traveling with the army). Eusebius was made presbyter by Agapius of Caesarea. Some, like theologian and ecclesiastical historian John Henry Newman, understand Eusebius' statement that he had heard Dorotheus of Tyre \"expound the Scriptures wisely in the Church\" to indicate that Eusebius was Dorotheus' pupil while the priest was resident in Antioch; others, like the scholar D. S. Wallace-Hadrill, deem the phrase too ambiguous to support the contention.\n\nBy the 3rd century, Caesarea had a population of about 100,000. It had been a pagan city since Pompey had given control of the city to the gentiles during his command of the eastern provinces in the 60s BC. The gentiles retained control of the city for the three centuries to follow, despite Jewish petitions for joint governorship. Gentile government was strengthened by the city's refoundation under Herod the Great (r. 37–4 BC), when it had taken on the name of Augustus Caesar. In addition to the gentile settlers, Caesarea had large Jewish and Samaritan minorities. Eusebius was probably born into the Christian contingent of the city. Caesarea's Christian community presumably had a history reaching back to apostolic times, but it is a common claim that no bishops are attested for the town before about 190, even though the Apostolic Constitutions 7.46 states that Zacchaeus was the first bishop.\n\nThrough the activities of the theologian Origen (185/6–254) and the school of his follower Pamphilus (later 3rd century – 309), Caesarea became a center of Christian learning. Origen was largely responsible for the collection of usage information, or which churches were using which gospels, regarding the texts which became the New Testament. The information used to create the late-fourth-century Easter Letter, which declared accepted Christian writings, was probably based on the Ecclesiastical History [HE] of Eusebius of Caesarea, wherein he uses the information passed on to him by Origen to create both his list at HE 3:25 and Origen's list at HE 6:25. Eusebius got his information about what texts were accepted by the third-century churches throughout the known world, a great deal of which Origen knew of firsthand from his extensive travels, from the library and writings of Origen.\n\nOn his deathbed, Origen had made a bequest of his private library to the Christian community in the city. Together with the books of his patron Ambrosius, Origen's library (including the original manuscripts of his works) formed the core of the collection that Pamphilus established. Pamphilus also managed a school that was similar to (or perhaps a re-establishment of) that of Origen. Pamphilus was compared to Demetrius of Phalerum and Pisistratus, for he had gathered Bibles \"from all parts of the world\". Like his model Origen, Pamphilus maintained close contact with his students. Eusebius, in his history of the persecutions, alludes to the fact that many of the Caesarean martyrs lived together, presumably under Pamphilus.\n\nSoon after Pamphilus settled in Caesarea (\"ca\". 280s), he began teaching Eusebius, who was then somewhere between twenty and twenty-five. Because of his close relationship with his schoolmaster, Eusebius was sometimes called \"Eusebius Pamphili\": \"Eusebius, son of Pamphilus\". The name may also indicate that Eusebius was made Pamphilus' heir. Pamphilus gave Eusebius a strong admiration for the thought of Origen. Neither Pamphilus nor Eusebius knew Origen personally; Pamphilus probably picked up Origenist ideas during his studies under Pierius (nicknamed \"Origen Junior\") in Alexandria. In Caesarea, Origenist thought was continued in the generation after his death by Theotecnus, bishop of the city for much of the late 3rd century and an alumnus of Origen's school.\n\nEusebius' \"Preparation for the Gospel\" bears witness to the literary tastes of Origen: Eusebius quotes no comedy, tragedy, or lyric poetry, but makes reference to all the works of Plato and to an extensive range of later philosophic works, largely from Middle Platonists from Philo to the late 2nd century. Whatever its secular contents, the primary aim of Origen and Pamphilus' school was to promote sacred learning. The library's biblical and theological contents were more impressive: Origen's Hexapla and Tetrapla; a copy of the original Aramaic version of the Gospel of Matthew; and many of Origen's own writings. Marginal comments in extant manuscripts note that Pamphilus and his friends and pupils, including Eusebius, corrected and revised much of the biblical text in their library. Their efforts made the hexaplaric Septuagint text increasingly popular in Syria and Palestine. Soon after joining Pamphilus' school, Eusebius started helping his master expand the library's collections and broaden access to its resources. At about this time Eusebius compiled a \"Collection of Ancient Martyrdoms\", presumably for use as a general reference tool.\n\nIn the 290s, Eusebius began work on his \"magnum opus\", the \"Ecclesiastical History\", a narrative history of the Church and Christian community from the Apostolic Age to Eusebius' own time. At about the same time, he worked on his \"Chronicle\", a universal calendar of events from the Creation to, again, Eusebius' own time. He completed the first editions of the \"Ecclesiastical History\" and \"Chronicle\" before 300.\n\nEusebius succeeded Agapius as Bishop of Caesarea soon after 313 and was called on by Arius who had been excommunicated by his bishop Alexander of Alexandria. An episcopal council in Caesarea pronounced Arius blameless. Eusebius, a learned man and famous author, enjoyed the favour of the Emperor Constantine. Because of this he was called upon to present the creed of his own church to the 318 attendees of the Council of Nicaea in 325.\" However, the anti-Arian creed from Palestine prevailed becoming the basis for the Nicene Creed.\n\nThe theological views of Arius, that taught the subordination of the Son to the Father, continued to be a problem. Eustathius of Antioch strongly opposed the growing influence of Origen's theology as the root of Arianism. Eusebius, an admirer of Origen, was reproached by Eustathius for deviating from the Nicene faith. Eusebius prevailed and Eustathius was deposed at a synod in Antioch.\n\nHowever, Athanasius of Alexandria became a more powerful opponent and in 334, he was summoned before a synod in Caesarea (which he refused to attend). In the following year, he was again summoned before a synod in Tyre at which Eusebius of Caesarea presided. Athanasius, foreseeing the result, went to Constantinople to bring his cause before the Emperor. Constantine called the bishops to his court, among them Eusebius. Athanasius was condemned and exiled at the end of 335. Eusebius remained in the Emperor's favour throughout this time and more than once was exonerated with the explicit approval of the Emperor Constantine. After the Emperor's death (c.337), Eusebius wrote the Life of Constantine, an important historical work because of eye witness accounts and the use of primary sources. Eusebius died c.339.\n\nMuch like his birth, the exact date of Eusebius’ death is unknown. However, there is primary text evidence from a council held in Antioch that by the year 341, his successor Acacius had already filled the seat as Bishop. Socrates and Sozomen write about Eusebius’ death, and place it just before Constantine’s son Constantine II died, which was in early 340. They also say that it was after the second banishment of Athanasius, which began in mid 339. This means that his death occurred some time between the second half of 339 and early 340.\n\nOf the extensive literary activity of Eusebius, a relatively large portion has been preserved. Although posterity suspected him of Arianism, Eusebius had made himself indispensable by his method of authorship; his comprehensive and careful excerpts from original sources saved his successors the painstaking labor of original research. Hence, much has been preserved, quoted by Eusebius, which otherwise would have been destroyed.\n\nThe literary productions of Eusebius reflect on the whole the course of his life. At first, he occupied himself with works on Biblical criticism under the influence of Pamphilus and probably of Dorotheus of Tyre of the School of Antioch. Afterward, the persecutions under Diocletian and Galerius directed his attention to the martyrs of his own time and the past, and this led him to the history of the whole Church and finally to the history of the world, which, to him, was only a preparation for ecclesiastical history.\n\nThen followed the time of the Arian controversies, and dogmatic questions came into the foreground. Christianity at last found recognition by the State; and this brought new problems—apologies of a different sort had to be prepared. Lastly, Eusebius wrote eulogies in praise of Constantine. To all this activity must be added numerous writings of a miscellaneous nature, addresses, letters, and the like, and exegetical works that extended over the whole of his life and that include both commentaries and treatises on Biblical archaeology.\n\nEusebius' \"Onomasticon\" (more properly, \"On the Place-Names in the Holy Scripture\", ) is a directory of place names, or \"gazetteer\", a primary source that provides historical geographers with a contemporary knowledge of fourth century Palestine and Transjordan. It sits uneasily between the ancient genres of geography and lexicography, taking elements from both but a member of neither. \nEusebius' description of his own method, who wrote: \"I shall collect the entries from the whole of the divinely inspired Scriptures, and I shall set them out grouped by their initial letters so that one may easily perceive what lies scattered throughout the text,\" implies that he had no similar type of book to work from; his work was entirely original, based only on the text of the Bible. Eusebius organizes his entries into separate categories according to their first letters. The entries for Joshua under Tau, for example, read as follows: \nTina (Kinah, 15:22): of the tribe of Judah.<br>\nTelem (15:24): of the tribe of Judah.<br>\nTessam ([Azem] 15:29): of the tribe of Judah.<br>\nTyre ([Zer] 19:35): of the tribe of Naphthali.\n\nUnder each letter, the entries are organized first by the book they are found in, and then by their place in that book. In almost all of the entries in his geographical opus, Eusebius brings down the respective distances in Roman \"milestones\" from major points of reference, such as from Jerusalem, Beit Gubrin (Eleutheropolis), Hebron, Ptolemais, Caesarea, etc. Since most villages in the \"Onomasticon\" are far removed from Roman-built roads, scholars have concluded that Eusebius did not glean the geographical information from maps based on a milestone survey, but rather collected the information from some other source. Where there is a contemporary town at the site or nearby, Eusebius notes it in the corresponding entry. \"Terebinth\", for example, describes Shechem as \"near Neapolis\", modern Nablus, and \"Tophet\" is located \"in the suburbs of Jerusalem\". The \"Onomasticon\" has traditionally been dated before 324, on the basis of its sparse references to Christianity, and complete absence of remarks on Constantine's buildings in the Holy Land. The work also describes traditional religious practices at the oak of Mamre as though they were still happening, while they are known to have been suppressed soon after 325, when a church was built on the site. Eusebius references to the encampment of the Legio X Fretensis at Aila (in southern Israel, near modern Aqaba and Eilat); the X Fretensis was probably transferred from Jerusalem to Aila under Diocletian.\n\nEusebius compiled his work in Greek, although a Latin translation of the same work was made by Jerome about a century later.\n\nPamphilus and Eusebius occupied themselves with the textual criticism of the Septuagint text of the Old Testament and especially of the New Testament. An edition of the Septuagint seems to have been already prepared by Origen, which, according to Jerome, was revised and circulated by Eusebius and Pamphilus. For an easier survey of the material of the four Evangelists, Eusebius divided his edition of the New Testament into paragraphs and provided it with a synoptical table so that it might be easier to find the pericopes that belong together. These canon tables or \"Eusebian canons\" remained in use throughout the Middle Ages, and illuminated manuscript versions are important for the study of early medieval art, as they are the most elaborately decorated pages of many Gospel books. Eusebius detailed in \"Epistula ad Carpianum\" how to use his canons.\n\nThe \"Chronicle\" ( (\"Pantodape historia\")) is divided into two parts. The first part, the \"Chronography\" ( (\"Chronographia\")), gives an epitome of universal history from the sources, arranged according to nations. The second part, the \"Canons\" ( (\"Chronikoi kanones\")), furnishes a synchronism of the historical material in parallel columns, the equivalent of a parallel timeline.\n\nThe work as a whole has been lost in the original Greek, but it may be reconstructed from later chronographists of the Byzantine school who made excerpts from the work, especially George Syncellus. The tables of the second part have been completely preserved in a Latin translation by Jerome, and both parts are still extant in an Armenian translation. The loss of the Greek originals has given an Armenian translation a special importance; thus, the first part of Eusebius' \"Chronicle\", of which only a few fragments exist in the Greek, has been preserved entirely in Armenian, though with lacunae. The \"Chronicle\" as preserved extends to the year 325.\n\nIn his \"Church History\" or \"Ecclesiastical History\", Eusebius wrote the first surviving history of the Christian Church as a chronologically-ordered account, based on earlier sources, complete from the period of the Apostles to his own epoch. The time scheme correlated the history with the reigns of the Roman Emperors, and the scope was broad. Included were the bishops and other teachers of the Church, Christian relations with the Jews and those deemed heretical, and the Christian martyrs through 324. Although its accuracy and biases have been questioned, it remains an important source on the early church due to Eusebius's access to materials now lost.\n\nEusebius' \"Life of Constantine\" (\"Vita Constantini\") is a eulogy or panegyric, and therefore its style and selection of facts are affected by its purpose, rendering it inadequate as a continuation of the \"Church History.\" As the historian Socrates Scholasticus said, at the opening of his history which was designed as a continuation of Eusebius, \"Also in writing the life of Constantine, this same author has but slightly treated of matters regarding Arius, being more intent on the rhetorical finish of his composition and the praises of the emperor, than on an accurate statement of facts.\" The work was unfinished at Eusebius' death. Some scholars have questioned the Eusebian authorship of this work.\n\nBefore he compiled his church history, Eusebius edited a collection of martyrdoms of the earlier period and a biography of Pamphilus. The martyrology has not survived as a whole, but it has been preserved almost completely in parts. It contained:\n\n\nOf the life of Pamphilus, only a fragment survives. A work on the martyrs of Palestine in the time of Diocletian was composed after 311; numerous fragments are scattered in legendaries which have yet to be collected. The life of Constantine was compiled after the death of the emperor and the election of his sons as Augusti (337). It is more a rhetorical eulogy on the emperor than a history but is of great value on account of numerous documents incorporated in it.\n\nTo the class of apologetic and dogmatic works belong:\n\n\n\nA number of writings, belonging in this category, have been entirely lost.\n\nAll of the exegetical works of Eusebius have suffered damage in transmission. The majority of them are known to us only from long portions quoted in Byzantine catena-commentaries. However these portions are very extensive. Extant are:\n\n\nEusebius also wrote a work \"Quaestiones ad Stephanum et Marinum\", \"On the Differences of the Gospels\" (including solutions). This was written for the purpose of harmonizing the contradictions in the reports of the different Evangelists. This work was recently (2011) translated into the English language by David J. Miller and Adam C. McCollum (edited by Roger Pearse) and was published under the name \"Eusebius of Caesarea: Gospel Problems and Solutions.\" The original work was also translated into Syriac, and lengthy quotations exist in a \"catena\" in that language, and also in Coptic and Arabic catenas.\n\nEusebius also wrote treatises on Biblical archaeology:\n\n\nThese three treatises have been lost.\n\nThe addresses and sermons of Eusebius are mostly lost, but some have been preserved, e.g., a sermon on the consecration of the church in Tyre and an address on the thirtieth anniversary of the reign of Constantine (336).\n\nMost of Eusebius' letters are lost. His letters to Carpianus and Flacillus exist complete. Fragments of a letter to the empress Constantia also exists.\n\nEusebius is fairly unusual in his preterist, or fulfilled eschetological view. Saying \"The Holy Scriptures foretell that there will be unmistakable signs of the Coming of Christ. Now there were among the Hebrews three outstanding offices of dignity, which made the nation famous, firstly the kingship, secondly that of prophet, and lastly the high priesthood. The prophecies said that the abolition and complete destruction of all these three together would be the sign of the presence of the Christ. And that the proofs that the times had come, would lie in the ceasing of the Mosaic worship, the desolation of Jerusalem and its Temple, and the subjection of the whole Jewish race to its enemies...The holy oracles foretold that all these changes, which had not been made in the days of the prophets of old, would take place at the coming of the Christ, which I will presently shew to have been fulfilled as never before in accordance with the predictions.\" (Demonstratio Evangelica VIII)\n\nFrom a dogmatic point of view, Eusebius stands entirely upon the shoulders of Origen. Like Origen, he started from the fundamental thought of the absolute sovereignty (\"monarchia\") of God. God is the cause of all beings. But he is not merely a cause; in him everything good is included, from him all life originates, and he is the source of all virtue. God sent Christ into the world that it may partake of the blessings included in the essence of God. Christ is God and is a ray of the eternal light; but the figure of the ray is so limited by Eusebius that he expressly distinguishes the Son as distinct from Father as a ray is also distinct from its source the sun.\n\nEusebius was intent upon emphasizing the difference of the persons of the Trinity and maintaining the subordination of the Son (Logos, or Word) to God. The Logos, the Son (Jesus) is an hypostasis of God the Father whose generation, for Eusebius, took place before time. The Logos acts as the organ or instrument of God, the creator of life, the principle of every revelation of God, who in his absoluteness and transcendence is enthroned above and isolated from all the world. Eusebius, with most of the Christian tradition, assumed God was immutable. Therefore, to Eusebius's mind, the Logos must possess divinity by participation (and not originally like the Father), so that he can change, unlike God the Father. Thus he assumed a human body without altering the immutable divine Father. Eusebius never calls Jesus \"o theós\", but \"theós\" because in all contrary attempts he suspected either polytheism (three distinct gods) or Sabellianism (three modes of one divine person).\n\nLikewise, Eusebius described the relation of the Holy Spirit within the Trinity to that of the Son to the Father. No point of this doctrine is original with Eusebius, all is traceable to his teacher Origen. The lack of originality in his thinking shows itself in the fact that he never presented his thoughts in a system. After nearly being excommunicated due to charges of heresy by Alexander of Alexandria, Eusebius submitted and agreed to the Nicene Creed at the First Council of Nicea in 325.\n\nEusebius held that men were sinners by their own free choice and not by the necessity of their natures. Eusebius said, \"The Creator of all things has impressed a natural law upon the soul of every man, as an assistant and ally in his conduct, pointing out to him the right way by this law; but, by the free liberty with which he is endowed, making the choice of what is best worthy of praise and acceptance, because he has acted rightly, not by force, but from his own free-will, when he had it in his power to act otherwise, As, again, making him who chooses what is worst, deserving of blame and punishment, as having by his own motion neglected the natural law, and becoming the origin and fountain of wickedness, and misusing himself, not from any extraneous necessity, but from free will and judgment. The fault is in him who chooses, not in God. For God has not made nature or the substance of the soul bad; for he who is good can make nothing but what is good. Everything is good which is according to nature. Every rational soul has naturally a good free-will, formed for the choice of what is good. But when a man acts wrongly, nature is not to be blamed; for what is wrong, takes place not according to nature, but contrary to nature, it being the work of choice, and not of nature\".\n\nBy the time of the Byzantine Iconoclasm several centuries later, Eusebius had unfairly gained the reputation of having been an Arian, and was roundly condemned as such by Patriarch Nikephoros I of Constantinople. A letter Eusebius is supposed to have written to Constantine's daughter Constantia, refusing to fulfill her request for images of Christ, was quoted in the decrees (now lost) of the Iconoclast Council of Hieria in 754, and later quoted in part in the rebuttal of the Hieria decrees in the Second Council of Nicaea of 787, now the only source from which some of the text is known. The authenticity, or authorship of the letter remain uncertain.\n\n\nAlternate views have suggested that Gibbon's dismissal of Eusebius is inappropriate:\n\n\nWhile many have shared Burckhardt's assessment, particularly with reference to the \"Life of Constantine\", others, while not pretending to extol his merits, have acknowledged the irreplaceable value of his works which may principally reside in the copious quotations that they contain from other sources, often lost.\n\n\n\n\n\n\n\n"}
{"id": "10174", "url": "https://en.wikipedia.org/wiki?curid=10174", "title": "Empiricism", "text": "Empiricism\n\nEmpiricism is a theory that states that knowledge comes only or primarily from sensory experience. It is one of several views of epistemology, the study of human knowledge, along with rationalism and skepticism. Empiricism emphasizes the role of empirical evidence in the formation of ideas, over the idea of innate ideas or traditions; empiricists may argue however that traditions (or customs) arise due to relations of previous sense experiences.\n\nEmpiricism in the philosophy of science emphasizes evidence, especially as discovered in experiments. It is a fundamental part of the scientific method that all hypotheses and theories must be tested against observations of the natural world rather than resting solely on a priori reasoning, intuition, or revelation.\n\nEmpiricism, often used by natural scientists, says that \"knowledge is based on experience\" and that \"knowledge is tentative and probabilistic, subject to continued revision and falsification.\" One of the epistemological tenets is that sensory experience creates knowledge. Empirical research, including experiments and validated measurement tools, guides the scientific method.\n\nThe English term \"empirical\" derives from the Ancient Greek word ἐμπειρία, \"empeiria\", which is cognate with and translates to the Latin \"experientia\", from which are derived the word \"experience\" and the related \"experiment\". The term was used by the Empiric school of ancient Greek medical practitioners, who rejected the three doctrines of the Dogmatic school, preferring to rely on the observation of \"\"phenomena\"\".\n\nA central concept in science and the scientific method is that it must be \"empirically\" based on the evidence of the senses. Both natural and social sciences use working hypotheses that are testable by observation and experiment. The term \"semi-empirical\" is sometimes used to describe theoretical methods that make use of basic axioms, established scientific laws, and previous experimental results in order to engage in reasoned model building and theoretical inquiry.\n\nPhilosophical empiricists hold no knowledge to be properly inferred or deduced unless it is derived from one's sense-based experience. This view is commonly contrasted with rationalism, which states that knowledge may be derived from reason independently of the senses. For example, John Locke held that some knowledge (e.g. knowledge of God's existence) could be arrived at through intuition and reasoning alone. Similarly Robert Boyle, a prominent advocate of the experimental method, held that we have innate ideas. The main continental rationalists (Descartes, Spinoza, and Leibniz) were also advocates of the empirical \"scientific method\".\n\n\"Vaisheshika\" darsana, founded by the ancient Indian philosopher Kanada, accepted perception and inference as the only two reliable sources of knowledge. This is enumerated in his work Vaiśeṣika Sūtra.\nThe notion of \"tabula rasa\" (\"clean slate\" or \"blank tablet\") connotes a view of mind as an originally blank or empty recorder (Locke used the words \"white paper\") on which experience leaves marks. This denies that humans have innate ideas. The image dates back to Aristotle:\nWhat the mind (\"nous\") thinks must be in it in the same sense as letters are on a tablet (\"grammateion\") which bears no actual writing (\"grammenon\"); this is just what happens in the case of the mind. (Aristotle, \"On the Soul\", 3.4.4301).\n\nAristotle's explanation of how this was possible was not strictly empiricist in a modern sense, but rather based on his theory of potentiality and actuality, and experience of sense perceptions still requires the help of the active \"nous\". These notions contrasted with Platonic notions of the human mind as an entity that pre-existed somewhere in the heavens, before being sent down to join a body on Earth (see Plato's \"Phaedo\" and \"Apology\", as well as others). Aristotle was considered to give a more important position to sense perception than Plato, and commentators in the Middle Ages summarized one of his positions as \"\"nihil in intellectu nisi prius fuerit in sensu\"\" (Latin for \"nothing in the intellect without first being in the senses\").\n\nThis idea was later developed in ancient philosophy by the Stoic school. Stoic epistemology generally emphasized that the mind starts blank, but acquires knowledge as the outside world is impressed upon it. The doxographer Aetius summarizes this view as \"When a man is born, the Stoics say, he has the commanding part of his soul like a sheet of paper ready for writing upon.\" \n\nDuring the Middle Ages Aristotle's theory of \"tabula rasa\" was developed by Islamic philosophers starting with Al Farabi, developing into an elaborate theory by Avicenna and demonstrated as a thought experiment by Ibn Tufail. For Avicenna (Ibn Sina), for example, the \"tabula rasa\" is a pure potentiality that is actualized through education, and knowledge is attained through \"empirical familiarity with objects in this world from which one abstracts universal concepts\" developed through a \"syllogistic method of reasoning in which observations lead to propositional statements which when compounded lead to further abstract concepts\". The intellect itself develops from a material intellect (\"al-'aql al-hayulani\"), which is a potentiality \"that can acquire knowledge to the active intellect (\"al-'aql al-fa'il\"), the state of the human intellect in conjunction with the perfect source of knowledge\". So the immaterial \"active intellect\", separate from any individual person, is still essential for understanding to occur.\n\nIn the 12th century CE the Andalusian Muslim philosopher and novelist Abu Bakr Ibn Tufail (known as \"Abubacer\" or \"Ebn Tophail\" in the West) included the theory of \"tabula rasa\" as a thought experiment in his Arabic philosophical novel, \"Hayy ibn Yaqdhan\" in which he depicted the development of the mind of a feral child \"from a \"tabula rasa\" to that of an adult, in complete isolation from society\" on a desert island, through experience alone. The Latin translation of his philosophical novel, entitled \"Philosophus Autodidactus\", published by Edward Pococke the Younger in 1671, had an influence on John Locke's formulation of \"tabula rasa\" in \"An Essay Concerning Human Understanding\".\n\nA similar Islamic theological novel, \"Theologus Autodidactus\", was written by the Arab theologian and physician Ibn al-Nafis in the 13th century. It also dealt with the theme of empiricism through the story of a feral child on a desert island, but departed from its predecessor by depicting the development of the protagonist's mind through contact with society rather than in isolation from society.\n\nDuring the 13th century Thomas Aquinas adopted the Aristotelian position that the senses are essential to mind into scholasticism. Bonaventure (1221–1274), one of Aquinas' strongest intellectual opponents, offered some of the strongest arguments in favour of the Platonic idea of the mind.\n\nIn the late renaissance various writers began to question the medieval and classical understanding of knowledge acquisition in a more fundamental way. In political and historical writing Niccolò Machiavelli and his friend Francesco Guicciardini initiated a new realistic style of writing. Machiavelli in particular was scornful of writers on politics who judged everything in comparison to mental ideals and demanded that people should study the \"effectual truth\" instead. Their contemporary, Leonardo da Vinci (1452–1519) said, \"If you find from your own experience that something is a fact and it contradicts what some authority has written down, then you must abandon the authority and base your reasoning on your own findings.\"\n\nThe decidedly anti-Aristotelian and anti-clerical music theorist Vincenzo Galilei (ca. 1520–1591), father of Galileo and the inventor of monody, made use of the method in successfully solving musical problems, firstly, of tuning such as the relationship of pitch to string tension and mass in stringed instruments, and to volume of air in wind instruments; and secondly to composition, by his various suggestions to composers in his \"Dialogo della musica antica e moderna\" (Florence, 1581). The Italian word he used for \"experiment\" was \"esperienza\". It is known that he was the essential pedagogical influence upon the young Galileo, his eldest son (cf. Coelho, ed. \"Music and Science in the Age of Galileo Galilei\"), arguably one of the most influential empiricists in history. Vincenzo, through his tuning research, found the underlying truth at the heart of the misunderstood myth of 'Pythagoras' hammers' (the square of the numbers concerned yielded those musical intervals, not the actual numbers, as believed), and through this and other discoveries that demonstrated the fallibility of traditional authorities, a radically empirical attitude developed, passed on to Galileo, which regarded \"experience and demonstration\" as the \"sine qua non\" of valid rational enquiry.\n\nBritish empiricism, though it was not a term used at the time, derives from the 17th century period of early modern philosophy and modern science. The term became useful in order to describe differences perceived between two of its founders Francis Bacon, described as empiricist, and René Descartes, who is described as a rationalist. Thomas Hobbes and Baruch Spinoza, in the next generation, are often also described as an empiricist and a rationalist respectively. John Locke, George Berkeley, and David Hume were the primary exponents of empiricism in the 18th century Enlightenment, with Locke being the person who is normally known as the founder of empiricism as such.\n\nIn response to the early-to-mid-17th century \"continental rationalism\" John Locke (1632–1704) proposed in \"An Essay Concerning Human Understanding\" (1689) a very influential view wherein the \"only\" knowledge humans can have is \"a posteriori\", i.e., based upon experience. Locke is famously attributed with holding the proposition that the human mind is a \"tabula rasa\", a \"blank tablet\", in Locke's words \"white paper\", on which the experiences derived from sense impressions as a person's life proceeds are written. There are two sources of our ideas: sensation and reflection. In both cases, a distinction is made between simple and complex ideas. The former are unanalysable, and are broken down into primary and secondary qualities. Primary qualities are essential for the object in question to be what it is. Without specific primary qualities, an object would not be what it is. For example, an apple is an apple because of the arrangement of its atomic structure. If an apple was structured differently, it would cease to be an apple. Secondary qualities are the sensory information we can perceive from its primary qualities. For example, an apple can be perceived in various colours, sizes, and textures but it is still identified as an apple. Therefore, its primary qualities dictate what the object essentially is, while its secondary qualities define its attributes. Complex ideas combine simple ones, and divide into substances, modes, and relations. According to Locke, our knowledge of things is a perception of ideas that are in accordance or discordance with each other, which is very different from the quest for certainty of Descartes.\nA generation later, the Irish Anglican bishop, George Berkeley (1685–1753), determined that Locke's view immediately opened a door that would lead to eventual atheism. In response to Locke, he put forth in his \"Treatise Concerning the Principles of Human Knowledge\" (1710) an important challenge to empiricism in which things \"only\" exist either as a \"result\" of their being perceived, or by virtue of the fact that they are an entity doing the perceiving. (For Berkeley, God fills in for humans by doing the perceiving whenever humans are not around to do it.) In his text \"Alciphron\", Berkeley maintained that any order humans may see in nature is the language or handwriting of God. Berkeley's approach to empiricism would later come to be called subjective idealism.\n\nThe Scottish philosopher David Hume (1711–1776) responded to Berkeley's criticisms of Locke, as well as other differences between early modern philosophers, and moved empiricism to a new level of skepticism. Hume argued in keeping with the empiricist view that all knowledge derives from sense experience, but he accepted that this has implications not normally acceptable to philosophers. He wrote for example, \"Locke divides all arguments into demonstrative and probable. On this view, we must say that it is only probable that all men must die or that the sun will rise to-morrow, because neither of these can be demonstrated. But to conform our language more to common use, we ought to divide arguments into demonstrations, proofs, and probabilities—by ‘proofs’ meaning arguments from experience that leave no room for doubt or opposition.\" And,\n\nHume divided all of human knowledge into two categories: \"relations of ideas\" and \"matters of fact\" (see also Kant's analytic-synthetic distinction). Mathematical and logical propositions (e.g. \"that the square of the hypotenuse is equal to the sum of the squares of the two sides\") are examples of the first, while propositions involving some contingent observation of the world (e.g. \"the sun rises in the East\") are examples of the second. All of people's \"ideas\", in turn, are derived from their \"impressions\". For Hume, an \"impression\" corresponds roughly with what we call a sensation. To remember or to imagine such impressions is to have an \"idea\". Ideas are therefore the faint copies of sensations.\nHume maintained that all knowledge, even the most basic beliefs about the natural world, cannot be conclusively established by reason. Rather, he maintained, our beliefs are more a result of accumulated \"habits\", developed in response to accumulated sense experiences. Among his many arguments Hume also added another important slant to the debate about scientific method — that of the problem of induction. Hume argued that it requires inductive reasoning to arrive at the premises for the principle of inductive reasoning, and therefore the justification for inductive reasoning is a circular argument. Among Hume's conclusions regarding the problem of induction is that there is no certainty that the future will resemble the past. Thus, as a simple instance posed by Hume, we cannot know with certainty by inductive reasoning that the sun will continue to rise in the East, but instead come to expect it to do so because it has repeatedly done so in the past.\n\nHume concluded that such things as belief in an external world and belief in the existence of the self were not rationally justifiable. According to Hume these beliefs were to be accepted nonetheless because of their profound basis in instinct and custom. Hume's lasting legacy, however, was the doubt that his skeptical arguments cast on the legitimacy of inductive reasoning, allowing many skeptics who followed to cast similar doubt.\n\nMost of Hume's followers have disagreed with his conclusion that belief in an external world is \"rationally\" unjustifiable, contending that Hume's own principles implicitly contained the rational justification for such a belief, that is, beyond being content to let the issue rest on human instinct, custom and habit. According to an extreme empiricist theory known as phenomenalism, anticipated by the arguments of both Hume and George Berkeley, a physical object is a kind of construction out of our experiences. Phenomenalism is the view that physical objects, properties, events (whatever is physical) are reducible to mental objects, properties, events. Ultimately, only mental objects, properties, events, exist — hence the closely related term subjective idealism. By the phenomenalistic line of thinking, to have a visual experience of a real physical thing is to have an experience of a certain kind of group of experiences. This type of set of experiences possesses a constancy and coherence that is lacking in the set of experiences of which hallucinations, for example, are a part. As John Stuart Mill put it in the mid-19th century, matter is the \"permanent possibility of sensation\".\nMill's empiricism went a significant step beyond Hume in still another respect: in maintaining that induction is necessary for \"all\" meaningful knowledge including mathematics. As summarized by D.W. Hamlin:\n\nMill's empiricism thus held that knowledge of any kind is not from direct experience but an inductive inference from direct experience. The problems other philosophers have had with Mill's position center around the following issues: Firstly, Mill's formulation encounters difficulty when it describes what direct experience is by differentiating only between actual and possible sensations. This misses some key discussion concerning conditions under which such \"groups of permanent possibilities of sensation\" might exist in the first place. Berkeley put God in that gap; the phenomenalists, including Mill, essentially left the question unanswered. In the end, lacking an acknowledgement of an aspect of \"reality\" that goes beyond mere \"possibilities of sensation\", such a position leads to a version of subjective idealism. Questions of how floor beams continue to support a floor while unobserved, how trees continue to grow while unobserved and untouched by human hands, etc., remain unanswered, and perhaps unanswerable in these terms. Secondly, Mill's formulation leaves open the unsettling possibility that the \"gap-filling entities are purely possibilities and not actualities at all\". Thirdly, Mill's position, by calling mathematics merely another species of inductive inference, misapprehends mathematics. It fails to fully consider the structure and method of mathematical science, the products of which are arrived at through an internally consistent deductive set of procedures which do not, either today or at the time Mill wrote, fall under the agreed meaning of induction.\n\nThe phenomenalist phase of post-Humean empiricism ended by the 1940s, for by that time it had become obvious that statements about physical things could not be translated into statements about actual and possible sense data. If a physical object statement is to be translatable into a sense-data statement, the former must be at least deducible from the latter. But it came to be realized that there is no finite set of statements about actual and possible sense-data from which we can deduce even a single physical-object statement. Remember that the translating or paraphrasing statement must be couched in terms of normal observers in normal conditions of observation. There is, however, no \"finite\" set of statements that are couched in purely sensory terms and can express the satisfaction of the condition of the presence of a normal observer. According to phenomenalism, to say that a normal observer is present is to make the hypothetical statement that were a doctor to inspect the observer, the observer would appear to the doctor to be normal. But, of course, the doctor himself must be a normal observer. If we are to specify this doctor's normality in sensory terms, we must make reference to a second doctor who, when inspecting the sense organs of the first doctor, would himself have to have the sense data a normal observer has when inspecting the sense organs of a subject who is a normal observer. And if we are to specify in sensory terms that the second doctor is a normal observer, we must refer to a third doctor, and so on (also see the third man).\n\nLogical empiricism (also \"logical positivism\" or \"neopositivism\") was an early 20th-century attempt to synthesize the essential ideas of British empiricism (e.g. a strong emphasis on sensory experience as the basis for knowledge) with certain insights from mathematical logic that had been developed by Gottlob Frege and Ludwig Wittgenstein. Some of the key figures in this movement were Otto Neurath, Moritz Schlick and the rest of the Vienna Circle, along with A.J. Ayer, Rudolf Carnap and Hans Reichenbach.\n\nThe neopositivists subscribed to a notion of philosophy as the conceptual clarification of the methods, insights and discoveries of the sciences. They saw in the logical symbolism elaborated by Frege (1848–1925) and Bertrand Russell (1872–1970) a powerful instrument that could rationally reconstruct all scientific discourse into an ideal, logically perfect, language that would be free of the ambiguities and deformations of natural language. This gave rise to what they saw as metaphysical pseudoproblems and other conceptual confusions. By combining Frege's thesis that all mathematical truths are logical with the early Wittgenstein's idea that all logical truths are mere linguistic tautologies, they arrived at a twofold classification of all propositions: the \"analytic\" (a priori) and the \"synthetic\" (a posteriori). On this basis, they formulated a strong principle of demarcation between sentences that have sense and those that do not: the so-called verification principle. Any sentence that is not purely logical, or is unverifiable is devoid of meaning. As a result, most metaphysical, ethical, aesthetic and other traditional philosophical problems came to be considered pseudoproblems.\n\nIn the extreme empiricism of the neopositivists—at least before the 1930s—any genuinely synthetic assertion must be reducible to an ultimate assertion (or set of ultimate assertions) that expresses direct observations or perceptions. In later years, Carnap and Neurath abandoned this sort of \"phenomenalism\" in favor of a rational reconstruction of knowledge into the language of an objective spatio-temporal physics. That is, instead of translating sentences about physical objects into sense-data, such sentences were to be translated into so-called \"protocol sentences\", for example, \"\"X\" at location \"Y\" and at time \"T\" observes such and such.\" The central theses of logical positivism (verificationism, the analytic-synthetic distinction, reductionism, etc.) came under sharp attack after World War II by thinkers such as Nelson Goodman, W.V. Quine, Hilary Putnam, Karl Popper, and Richard Rorty. By the late 1960s, it had become evident to most philosophers that the movement had pretty much run its course, though its influence is still significant among contemporary analytic philosophers such as Michael Dummett and other anti-realists.\n\nIn the late 19th and early 20th century several forms of pragmatic philosophy arose. The ideas of pragmatism, in its various forms, developed mainly from discussions between Charles Sanders Peirce and William James when both men were at Harvard in the 1870s. James popularized the term \"pragmatism\", giving Peirce full credit for its patrimony, but Peirce later demurred from the tangents that the movement was taking, and redubbed what he regarded as the original idea with the name of \"pragmaticism\". Along with its \"pragmatic theory of truth\", this perspective integrates the basic insights of empirical (experience-based) and rational (concept-based) thinking.\nCharles Peirce (1839–1914) was highly influential in laying the groundwork for today's empirical scientific method. Although Peirce severely criticized many elements of Descartes' peculiar brand of rationalism, he did not reject rationalism outright. Indeed, he concurred with the main ideas of rationalism, most importantly the idea that rational concepts can be meaningful and the idea that rational concepts necessarily go beyond the data given by empirical observation. In later years he even emphasized the concept-driven side of the then ongoing debate between strict empiricism and strict rationalism, in part to counterbalance the excesses to which some of his cohorts had taken pragmatism under the \"data-driven\" strict-empiricist view.\n\nAmong Peirce's major contributions was to place inductive reasoning and deductive reasoning in a complementary rather than competitive mode, the latter of which had been the primary trend among the educated since David Hume wrote a century before. To this, Peirce added the concept of abductive reasoning. The combined three forms of reasoning serve as a primary conceptual foundation for the empirically based scientific method today. Peirce's approach \"presupposes that (1) the objects of knowledge are real things, (2) the characters (properties) of real things do not depend on our perceptions of them, and (3) everyone who has sufficient experience of real things will agree on the truth about them. According to Peirce's doctrine of fallibilism, the conclusions of science are always tentative. The rationality of the scientific method does not depend on the certainty of its conclusions, but on its self-corrective character: by continued application of the method science can detect and correct its own mistakes, and thus eventually lead to the discovery of truth\".\nIn his Harvard \"Lectures on Pragmatism\" (1903), Peirce enumerated what he called the \"three cotary propositions of pragmatism\" (L: \"cos, cotis\" whetstone), saying that they \"put the edge on the maxim of pragmatism\". First among these he listed the peripatetic-thomist observation mentioned above, but he further observed that this link between sensory perception and intellectual conception is a two-way street. That is, it can be taken to say that whatever we find in the intellect is also incipiently in the senses. Hence, if theories are theory-laden then so are the senses, and perception itself can be seen as a species of abductive inference, its difference being that it is beyond control and hence beyond critique – in a word, incorrigible. This in no way conflicts with the fallibility and revisability of scientific concepts, since it is only the immediate percept in its unique individuality or \"thisness\" – what the Scholastics called its \"haecceity\" – that stands beyond control and correction. Scientific concepts, on the other hand, are general in nature, and transient sensations do in another sense find correction within them. This notion of perception as abduction has received periodic revivals in artificial intelligence and cognitive science research, most recently for instance with the work of Irvin Rock on \"indirect perception\".\n\nAround the beginning of the 20th century, William James (1842–1910) coined the term \"radical empiricism\" to describe an offshoot of his form of pragmatism, which he argued could be dealt with separately from his pragmatism – though in fact the two concepts are intertwined in James's published lectures. James maintained that the empirically observed \"directly apprehended universe needs ... no extraneous trans-empirical connective support\", by which he meant to rule out the perception that there can be any value added by seeking supernatural explanations for natural phenomena. James' \"radical empiricism\" is thus \"not\" radical in the context of the term \"empiricism\", but is instead fairly consistent with the modern use of the term \"empirical\". His method of argument in arriving at this view, however, still readily encounters debate within philosophy even today.\n\nJohn Dewey (1859–1952) modified James' pragmatism to form a theory known as instrumentalism. The role of sense experience in Dewey's theory is crucial, in that he saw experience as unified totality of things through which everything else is interrelated. Dewey's basic thought, in accordance with empiricism was that reality is determined by past experience. Therefore, humans adapt their past experiences of things to perform experiments upon and test the pragmatic values of such experience. The value of such experience is measured experientially and scientifically, and the results of such tests generate ideas that serve as instruments for future experimentation, in physical sciences as in ethics. Thus, ideas in Dewey's system retain their empiricist flavour in that they are only known \"a posteriori\".\n\n\nLeavitt, Fred: \"Dancing with Absurdity: Your Most Cherished Beliefs (and All Your Others) are Probably Wrong. (2015) Peter Lang Publishers.\n"}
{"id": "10175", "url": "https://en.wikipedia.org/wiki?curid=10175", "title": "Estampie", "text": "Estampie\n\nThe estampie (, Occitan and , ) is a medieval dance and musical form which was a popular instrumental and vocal form in the 13th and 14th centuries. The name was also applied to poetry . \n\nThe estampie is similar in form to the lai, consisting of a succession of repeated sections . According to Johannes de Grocheio, there were both vocal and instrumental estampies (for which he used the Latin calque \"stantipes\"), which differed somewhat in form, in that the vocal estampie begins with a refrain, which is repeated at the end of each verse . Also according to Grocheio, the repeating sections in both the vocal and instrumental estampie were called \"puncta\" (singular \"punctus\") , in the form: \n\nThe two statements of each punctus differ only in their endings, described as \"apertum\" (\"open\") and \"clausum\" (\"closed\") by Grocheio, who believed that six \"puncta\" were standard for the stantipes (his term for the estampie), though he was aware of stantipes with seven \"puncta\" . The structure can therefore be diagrammed as: \n\nSometimes the same two endings are used for all the \"puncta\", producing the structure \n\nA similar structure was shared with the saltarello, another medieval dance.\n\nThe earliest reported example of this musical form is the song \"Kalenda maya\", written by the troubadour Raimbaut de Vaqueiras (1180–1207) to the melody of an estampida played by French jongleurs.\nAll other known examples are purely instrumental pieces.\nFourteenth-century examples include estampies with subtitles such as \"Lamento di Tristano\", \"La Manfredina\", Salterello, \"Isabella\", \"Tre fontane\". \n\nThough the estampie is generally monophonic, there are also two-voice compositions in the form of an estampie, such as the three for keyboard in the Robertsbridge Fragment.\n\nAccording to Grocheio, the fiddle was the supreme instrument of the period, and the stantipes, together with the cantus coronatus and ductia, were the principal forms played on fiddles before the wealthy in their celebration .\n\nAccording to the \"OED\", the name comes from the Provençal \"estampida\", feminine of \"estampit\", the past participle of \"estampir\" \"to resound\" .\n\n"}
{"id": "10176", "url": "https://en.wikipedia.org/wiki?curid=10176", "title": "Experimental cancer treatment", "text": "Experimental cancer treatment\n\nExperimental cancer treatments are medical therapies intended or claimed to treat cancer by improving on, supplementing or replacing conventional methods (surgery, chemotherapy, radiation, and immunotherapy).\n\nThe entries listed below vary between theoretical therapies to unproven controversial therapies. Many of these treatments are alleged to help against only specific forms of cancer. It is not a list of treatments widely available at hospitals.\n\nThe twin goals of research are to determine whether the treatment actually works (called efficacy) and whether it is sufficiently safe. Regulatory processes attempt to balance the potential benefits with the potential harms, so that people given the treatment are more likely to benefit from it than to be harmed by it.\n\nMedical research for cancer begins much like research for any disease. In organized studies of new treatments for cancer, the pre-clinical development of drugs, devices, and techniques begins in laboratories, either with isolated cells or in small animals, most commonly rats or mice. In other cases, the proposed treatment for cancer is already in use for some other medical condition, in which case more is known about its safety and potential efficacy.\n\nClinical trials are the study of treatments in humans. The first-in-human tests of a potential treatment are called Phase I studies. Early clinical trials typically enroll a very small number of patients, and the purpose is to identify major safety issues and the \"maximum tolerated dose\", which is the highest dose that does not produce serious or fatal adverse effects. The dose given in these trials may be far too small to produce any useful effect. In most research, these early trials may involve healthy people, but cancer studies normally enroll only people with relatively severe forms of the disease in this stage of testing. On average, 95% of the participants in these early trials receive no benefit, but all are exposed to the risk of adverse effects. Most participants show signs of optimism bias (the irrational belief that they will beat the odds).\n\nLater studies, called Phase II and Phase III studies, enroll more people, and the goal is to determine whether the treatment actually works. Phase III studies are frequently randomized controlled trials, with the experimental treatment being compared to the current best available treatment rather than to a placebo. In some cases, the Phase III trial provides the best available treatment to all participants, in addition to some of the patients receiving the experimental treatment.\n\nChemotherapeutic drugs have a hard time penetrating tumors to kill them at their core because these cells may lack a good blood supply. Researchers have been using anaerobic bacteria, such as \"Clostridium novyi\", to consume the interior of oxygen-poor tumours. These should then die when they come in contact with the tumor's oxygenated sides, meaning they would be harmless to the rest of the body. A major problem has been that bacteria do not consume all parts of the malignant tissue. However, combining the therapy with chemotheraputic treatments can help to solve this problem.\n\nAnother strategy is to use anaerobic bacteria that have been transformed with an enzyme that can convert a non-toxic prodrug into a toxic drug. With the proliferation of the bacteria in the necrotic and hypoxic areas of the tumor, the enzyme is expressed solely in the tumor. Thus, a systemically applied prodrug is metabolised to the toxic drug only in the tumor. This has been demonstrated to be effective with the nonpathogenic anaerobe \"Clostridium sporogenes\".\n\nHAMLET (human alpha-lactalbumin made lethal to tumor cells) is a molecular complex derived from human breast milk that kills tumor cells by a process resembling programmed cell death (apoptosis). It has been tested in humans with skin papillomas and bladder cancer.\n\nDichloroacetate (DCA) has been found to shrink tumors \"in vivo\" in rats, and has a plausible scientific mechanism: DCA appears to reactivate suppressed mitochondria in some types of oxygen-starved tumor cells, and thus promotes apoptosis. Because it was tested for other conditions, DCA is known to be relatively safe, available, and inexpensive, and it can be taken by mouth as a pill, which is convenient. Five patients with brain cancer have been treated with DCA in a clinical trial, and the authors say that the lives of four were 'probably' extended. However, without a large controlled trial it is impossible to say whether the drug is truly effective against cancer.\n\nQuercetin is a principal flavonoid compound and an excellent free-radical-scavenging antioxidant that promotes apoptosis. In vitro it shows some antitumor activity in oral cancer and leukemia. Cultured skin and prostate cancer cells showed significant mortality (compared to nonmalignant cells) when treated with a combination of quercetin and ultrasound. Note that ultrasound also promotes topical absorption by up to 1,000 times, making the use of topical quercetin and ultrasound wands an interesting proposition.\n\nHigh dietary intake of fruits and vegetables is associated with reduction in cancer, and some scientists, such as Gian Luigi Russo at the Institute of Food Sciences in Italy, suspect quercetin may be partly responsible. Research shows that quercetin influences cellular mechanisms in vitro and in animal studies. According to the American Cancer society, \"there is no reliable clinical evidence that quercetin can prevent or treat cancer in humans\".\n\nInsulin potentiation therapy is practice of injecting insulin, usually alongside conventional cancer drugs, in the belief that this improves the overall effect of the treatment. Quackwatch state: \"Insulin Potentiation Therapy (IPT) is one of several unproven, dangerous treatments that is promoted by a small group of practitioners without trustworthy evidence that it works.\"\n\nSeveral drug therapies are being developed based on p53, the tumour suppressor gene that protects the cell in response to damage and stress. It is analogous to deciding what to do with a damaged car: p53 brings everything to a halt, and then decides whether to fix the cell or, if the cell is beyond repair, to destroy the cell. This protective function of p53 is disabled in most cancer cells, allowing them to multiply without check. Restoration of p53 activity in tumours (where possible) has been shown to inhibit tumour growth and can even shrink the tumour.\n\nAs p53 protein levels are usually kept low, one could block its degradation and allow large amounts of p53 to accumulate, thus stimulating p53 activity and its antitumour effects. Drugs that utilize this mechanism include nutlin and MI-219, which are both in phase I clinical trials. There are also other drugs that are still in the preclinical stage of testing, such as RITA and MITA.\n\nBI811283 is a small molecule inhibitor of the aurora B kinase protein being developed by Boehringer Ingelheim for use as an anti-cancer agent. BI 811283 is currently in the early stages of clinical development and is undergoing first-in-human trials in patients with solid tumors and Acute Myeloid Leukaemia.\n\nIntroduction of tumor suppressor genes into rapidly dividing cells has been thought to slow down or arrest tumor growth. Adenoviruses are a commonly utilized vector for this purpose. Much research has focused on the use of adenoviruses that cannot reproduce, or reproduce only to a limited extent, within the patient to ensure safety via the avoidance of cytolytic destruction of noncancerous cells infected with the vector. However, new studies focus on adenoviruses that can be permitted to reproduce, and destroy cancerous cells in the process, since the adenoviruses' ability to infect normal cells is substantially impaired, potentially resulting in a far more effective treatment.\nAnother use of gene therapy is the introduction of enzymes into these cells that make them susceptible to particular chemotherapy agents; studies with introducing thymidine kinase in gliomas, making them susceptible to aciclovir, are in their experimental stage.\n\nEpigenetics is the study of heritable changes in gene activity that are not caused by changes in the DNA sequence, often a result of environmental or dietary damage to the histone receptors within the cell. Current research has shown that epigenetic pharmaceuticals could be a putative replacement or adjuvant therapy for currently accepted treatment methods such as radiation and chemotherapy, or could enhance the effects of these current treatments. It has been shown that the epigenetic control of the proto-onco regions and the tumor suppressor sequences by conformational changes in histones directly affects the formation and progression of cancer. Epigenetics also has the factor of reversibility, a characteristic that other cancer treatments do not offer.\n\nSome investigators, like Randy Jirtle, PhD, of Duke University Medical Center, think epigenetics may ultimately turn out to have a greater role in disease than genetics.\n\nBecause most malignant cells rely on the activity of the protein telomerase for their immortality, it has been proposed that a drug that inactivates telomerase might be effective against a broad spectrum of malignancies. At the same time, most healthy tissues in the body express little if any telomerase, and would function normally in its absence. Currently, inositol hexaphosphate, which is available over-the-counter, is undergoing testing in cancer research due to its telomerase-inhibiting abilities.\n\nA number of research groups have experimented with the use of telomerase inhibitors in animal models, and as of 2005 and 2006 phase I and II human clinical trials are underway. Geron Corporation is currently conducting two clinical trials involving telomerase inhibitors. One uses a vaccine (GRNVAC1) and the other uses a lipidated oligonucleotide (GRN163L).\n\nPhotodynamic therapy (PDT) is generally a non-invasive treatment using a combination of light and a photosensitive drug, such as 5-ALA, Foscan, Metvix, Tookad, WST09, WST11, Photofrin, or Visudyne. The drug is triggered by light of a specific wavelength.\n\nLocalized and whole-body application of heat has been proposed as a technique for the treatment of malignant tumours. Intense heating will cause denaturation and coagulation of cellular proteins, rapidly killing cells within a tumour.\n\nMore prolonged moderate heating to temperatures just a few degrees above normal (39.5 °C) can cause more subtle changes. A mild heat treatment combined with other stresses can cause cell death by apoptosis. There are many biochemical consequences to the heat shock response within the cell, including slowed cell division and increased sensitivity to ionizing radiation therapy. The purpose of overheating the tumor cells is to create a lack of oxygen so that the heated cells become overacidified, which leads to a lack of nutrients in the tumor. This in turn disrupts the metabolism of the cells so that cell death (apoptosis) can set in. In certain cases chemotherapy or radiation that has previously not had any effect can be made effective. Hyperthermia alters the cell walls by means of so-called heat shock proteins. The cancer cells then react very much more effectively to the cytostatics and radiation. If hyperthermia is used conscientiously it has no serious side effects.\n\nThere are many techniques by which heat may be delivered. Some of the most common involve the use of focused ultrasound (FUS or HIFU), microwave heating, induction heating, magnetic hyperthermia, and direct application of heat through the use of heated saline pumped through catheters. Experiments with carbon nanotubes that selectively bind to cancer cells have been performed. Lasers are then used that pass harmlessly through the body, but heat the nanotubes, causing the death of the cancer cells. Similar results have also been achieved with other types of nanoparticles, including gold-coated nanoshells and nanorods that exhibit certain degrees of 'tunability' of the absorption properties of the nanoparticles to the wavelength of light for irradiation. The success of this approach to cancer treatment rests on the existence of an 'optical window' in which biological tissue (i.e., healthy cells) are completely transparent at the wavelength of the laser light, while nanoparticles are highly absorbing at the same wavelength. Such a 'window' exists in the so-called near-infrared region of the electromagnetic spectrum. In this way, the laser light can pass through the system without harming healthy tissue, and only diseased cells, where the nanoparticles reside, get hot and are killed.\n\nMagnetic hyperthermia makes use of magnetic nanoparticles, which can be injected into tumours and then generate heat when subjected to an alternating magnetic field.\n\nOne of the challenges in thermal therapy is delivering the appropriate amount of heat to the correct part of the patient's body. A great deal of current research focuses on precisely positioning heat delivery devices (catheters, microwave, and ultrasound applicators, etc.) using ultrasound or magnetic resonance imaging, as well as of developing new types of nanoparticles that make them particularly efficient absorbers while offering little or no concerns about toxicity to the circulation system. Clinicians also hope to use advanced imaging techniques to monitor heat treatments in real time—heat-induced changes in tissue are sometimes perceptible using these imaging instruments. In magnetic hyperthermia or magnetic fluid hyperthermia method, it will be easier to control temperature distribution by controlling the velocity of ferrofluid injection and size of magnetic nanoparticles.\n\nThis preclinical treatment involves using radio waves to heat up tiny metals that are implanted in cancerous tissue. Gold nanoparticles or carbon nanotubes are the most likely candidate. Promising preclinical trials have been conducted, although clinical trials may not be held for another few years.\n\nAnother method that is entirely non-invasive referred to as Tumor Treating Fields has already reached clinical trial stage in many countries. The concept applies an electric field through a tumour region using electrodes external to the body. Successful trials have shown the process effectiveness to be greater than chemotherapy and there are no side-effects and only negligible time spent away from normal daily activities. This treatment is still in very early development stages for many types of cancer.\n\nHigh-intensity focused ultrasound (HIFU) is still in investigatory phases in many places around the world. In China it has CFDA approval and over 180 treatment centres have been established in China, Hong Kong, and Korea. HIFU has been successfully used to treat cancer to destroy tumours of the bone, brain, breast, liver, pancreas, rectum, kidney, testes, and prostate. Several thousand patients have been treated with various types of tumours. HIFU has CE approval for palliative care for bone metastasis. Experimentally, palliative care has been provided for cases of advanced pancreatic cancer. High-energy therapeutic ultrasound could increase higher-density anti-cancer drug load and nanomedicines to target tumor sites by 20x fold higher than traditional target cancer therapy.\n\nTumor Treating Fields is a novel FDA-approved cancer treatment therapy that uses alternating electric field to disturb the rapid cell division exhibited by cancer cells.\n\nComplementary and alternative medicine (CAM) treatments are the diverse group of medical and healthcare systems, practices, and products that are not part of conventional medicine and have not been proven to be effective. \"Complementary medicine\" usually refers to methods and substances used along with conventional medicine, while \"alternative medicine\" refers to compounds used instead of conventional medicine. CAM use is common among people with cancer.\n\nMost complementary and alternative medicines for cancer have not been rigorously studied or tested. Some alternative treatments that have been proven ineffective continue to be marketed and promoted.\n\n"}
{"id": "10181", "url": "https://en.wikipedia.org/wiki?curid=10181", "title": "Emission", "text": "Emission\n\nEmission may refer to:\n\nEmission of chemical products:\n\nEmission of electromagnetic radiation:\n\nOther uses:\n\n"}
{"id": "10183", "url": "https://en.wikipedia.org/wiki?curid=10183", "title": "Environmental movement in the United States", "text": "Environmental movement in the United States\n\nIn the United States today, the organized environmental movement is represented by a wide range of organizations sometimes called non-governmental organizations or NGOs. These organizations exist on local, national, and international scales. Environmental NGOs vary widely in political views and in the amount they seek to influence the environmental policy of the United States and other governments. The environmental movement today consists of both large national groups and also many smaller local groups with local concerns. Some resemble the old U.S. conservation movement - whose modern expression is The Nature Conservancy, Audubon Society and National Geographic Society - American organizations with a worldwide influence.\n\n\nAs public awareness and the environmental sciences have improved in recent years, environmental issues have broadened to include key concepts such as \"sustainability\" and also new emerging concerns such as ozone depletion, global warming, acid rain, land use and biogenetic pollution.\n\nEnvironmental movements often interact or are linked with other social movements, e.g. for peace, human rights, and animal rights; and against nuclear weapons and/or nuclear power, endemic diseases, poverty, hunger, etc.\n\nSome US colleges are now going green by signing the \"President's Climate Commitment,\" a document that a college President can sign to enable said colleges to practice environmentalism by switching to solar power, etc.\n\nEarly European settlers to the United States brought from Europe the concept of the commons. In the colonial era, access to natural resources was allocated by individual towns, and disputes over fisheries or land use were resolved at the local level. Changing technologies, however, strained traditional ways of resolving disputes of resource use, and local governments had limited control over powerful special interests. For example, the damming of rivers for mills cut off upriver towns from fisheries; logging and clearing of forest in watersheds harmed local fisheries downstream. In New England, many farmers became uneasy as they noticed clearing of forest changed stream flows and a decrease in bird population which helped control insects and other pests. These concerns become widely known with the publication of Man and Nature (1864) by George Perkins Marsh. The environmental impact method of analysis is generally the main mode for determining what issues the environmental movement is involved in. This model is used to determine how to proceed in situations that are detrimental to the environment by choosing the way that is least damaging and has the fewest lasting implications.\n\nConservation first became a national issue during the progressive era's conservation movement (1890s - 1920s). The early national conservation movement shifted emphasis to scientific management which favored larger enterprises and control began to shift from local governments to the states and the federal government.(Judd) Some writers credit sportsmen, hunters and fishermen with the increasing influence of the conservation movement. In the 1870s sportsman magazines such as American Sportsmen, Forest and Stream, and Field and Stream are seen as leading to the growth of the conservation movement.(Reiger) This conservation movement also urged the establishment of state and national parks and forests, wildlife refuges, and national monuments intended to preserve noteworthy natural features.\nConservation groups focus primarily on an issue that's origins are routed in general expansion. As Industrialization became more prominent as well as the increasing trend towards Urbanization the conservative environmental movement began. Contrary to popular belief conservation groups are not against expansion in general, instead they are concerned with efficiency with resources and land development.\n\nTheodore Roosevelt and his close ally George Bird Grinnell, were motivated by the wanton waste that was taking place at the hand of market hunting. This practice resulted in placing a large number of North American game species on the edge of extinction. Roosevelt recognized that the laissez-faire approach of the U.S. Government was too wasteful and inefficient. In any case, they noted, most of the natural resources in the western states were already owned by the federal government. The best course of action, they argued, was a long-term plan devised by national experts to maximize the long-term economic benefits of natural resources. To accomplish the mission, Roosevelt and Grinnell formed the Boone and Crockett Club in 1887. The Club was made up of the best minds and influential men of the day. The Boone and Crockett Club's contingency of conservationists, scientists, politicians, and intellectuals became Roosevelt's closest advisers during his march to preserve wildlife and habitat across North America. As president, Theodore Roosevelt became a prominent conservationist, putting the issue high on the national agenda. He worked with all the major figures of the movement, especially his chief advisor on the matter, Gifford Pinchot. Roosevelt was deeply committed to conserving natural resources, and is considered to be the nation's first conservation President. He encouraged the Newlands Reclamation Act of 1902 to promote federal construction of dams to irrigate small farms and placed 230 million acres (360,000 mi² or 930,000 km²) under federal protection. Roosevelt set aside more Federal land for national parks and nature preserves than all of his predecessors combined.\n\nRoosevelt established the United States Forest Service, signed into law the creation of five National Parks, and signed the 1906 Antiquities Act, under which he proclaimed 18 new U.S. National Monuments. He also established the first 51 Bird Reserves, four Game Preserves, and 150 National Forests, including Shoshone National Forest, the nation's first. The area of the United States that he placed under public protection totals approximately .\n\nGifford Pinchot had been appointed by McKinley as chief of Division of Forestry in the Department of Agriculture. In 1905, his department gained control of the national forest reserves. Pinchot promoted private use (for a fee) under federal supervision. In 1907, Roosevelt designated 16 million acres (65,000 km²) of new national forests just minutes before a deadline.\n\nIn May 1908, Roosevelt sponsored the Conference of Governors held in the White House, with a focus on natural resources and their most efficient use. Roosevelt delivered the opening address: \"Conservation as a National Duty.\"\n\nIn 1903 Roosevelt toured the Yosemite Valley with John Muir, who had a very different view of conservation, and tried to minimize commercial use of water resources and forests. Working through the Sierra Club he founded, Muir succeeded in 1905 in having Congress transfer the Mariposa Grove and Yosemite Valley to the National Park Service. While Muir wanted nature preserved for the sake of pure beauty, Roosevelt subscribed to Pinchot's formulation, \"to make the forest produce the largest amount of whatever crop or service will be most useful, and keep on producing it for generation after generation of men and trees.\" Muir and the Sierra Club vehemently opposed the damming of the Hetch Hetchy Valley in Yosemite in order to provide water to the city of San Francisco. Roosevelt and Pinchot supported the dam, as did President Woodrow Wilson. The Hetch Hetchy dam was finished in 1923 and is still in operation, but the Sierra Club still wants to tear it down.\n\nOther influential conservationists of the Progressive Era included George Bird Grinnell (a prominent sportsmen who founded the Boone and Crockett Club), the Izaak Walton League and John Muir, the founder of the Sierra Club in 1892. Conservationists organized the National Parks Conservation Association, the Audubon Society, and other groups that still remain active.\n\nFranklin Delano Roosevelt (1933–45), like his cousin Theodore Roosevelt, was an ardent conservationist. He used numerous programs of the departments of Agriculture and Interior to end wasteful land-use, mitigate the effects of the Dust Bowl, and efficiently develop natural resources in the West. One of the most popular of all New Deal programs was the Civilian Conservation Corps (1933–1943), which sent two million poor young men to work in rural and wilderness areas, primarily on conservation projects.\n\nAfter World War II increasing encroachment on wilderness land evoked the continued resistance of conservationists, who succeeded in blocking a number of projects in the 1950s and 1960s, including the proposed Bridge Canyon Dam that would have backed up the waters of the Colorado River into the Grand Canyon National Park.\n\nThe Inter-American Conference on the Conservation of Renewable Natural Resources met in 1948 as a collection of nearly 200 scientists from all over the Americans forming the trusteeship principle that:\n\n\"No generation can exclusively own the renewable resources by which it lives. We hold the commonwealth in trust for prosperity, and to lessen or destroy it is to commit treason against the future\"\n\nDuring the 1950s, 1960s and 1970s, several events occurred which raised the public awareness of harm to the environment caused by man. In 1954, the 23 man crew of the Japanese fishing vessel \"Lucky Dragon\" was exposed to radioactive fallout from a hydrogen bomb test at Bikini Atoll, in 1969, an ecologically catastrophic oil spill from an offshore well in California's Santa Barbara Channel, Barry Commoner's protest against nuclear testing, Rachel Carson's book Silent Spring, Paul R. Ehrlich's The Population Bomb all added anxiety about the environment. Pictures of Earth from space emphasized that the earth was small and fragile. \n\nAs the public became more aware of environmental issues, concern about air pollution, water pollution, solid waste disposal, dwindling energy resources, radiation, pesticide poisoning (particularly as described in Rachel Carson's influential Silent Spring, 1962), noise pollution, and other environmental problems engaged a broadening number of sympathizers. That public support for environmental concerns was widespread became clear in the Earth Day demonstrations of 1970. \n\nUnlike the Progressive Era's conservation movement (1890s - 1920s), which was largely elitist consisting of largely of wealthy, politically powerful men, the modern environmental movement was a social movement with more popular support. The environmental movement borrowed tactics from both the successful civil rights movement and the protests against the Vietnam war. \n\nIn the modern wilderness preservation movement, important philosophical roles are played by the writings of John Muir who had been activist in the late 19th and early 20th century. Along with Muir perhaps most influential in the modern movement is Henry David Thoreau who published Walden in 1854. Also important was forester and ecologist Aldo Leopold, one of the founders of the Wilderness Society in 1935, who wrote a classic of nature observation and ethical philosophy, \"A Sand County Almanac\", published in 1949. Other philosophical foundations were established by Ralph Waldo Emerson and Thomas Jefferson.\n\nThere is also a growing movement of campers and other people who enjoy outdoor recreation activities to help preserve the environment while spending time in the wilderness.\n\nThe anti-nuclear movement in the United States consists of more than 80 anti-nuclear groups which have acted to oppose nuclear power or nuclear weapons, or both, in the United States. These groups include the Abalone Alliance, Clamshell Alliance, Institute for Energy and Environmental Research, Nuclear Information and Resource Service, and Physicians for Social Responsibility. The anti-nuclear movement has delayed construction or halted commitments to build some new nuclear plants, and has pressured the Nuclear Regulatory Commission to enforce and strengthen the safety regulations for nuclear power plants.\n\nAnti-nuclear protests reached a peak in the 1970s and 1980s and grew out of the environmental movement. Campaigns which captured national public attention involved the Calvert Cliffs Nuclear Power Plant, Seabrook Station Nuclear Power Plant, Diablo Canyon Power Plant, Shoreham Nuclear Power Plant, and Three Mile Island. On June 12, 1982, one million people demonstrated in New York City's Central Park against nuclear weapons and for an end to the cold war arms race. It was the largest anti-nuclear protest and the largest political demonstration in American history. International Day of Nuclear Disarmament protests were held on June 20, 1983 at 50 sites across the United States.\nThere were many Nevada Desert Experience protests and peace camps at the Nevada Test Site during the 1980s and 1990s.\n\nMore recent campaigning by anti-nuclear groups has related to several nuclear power plants including the Enrico Fermi Nuclear Power Plant, Indian Point Energy Center, Oyster Creek Nuclear Generating Station, Pilgrim Nuclear Generating Station, Salem Nuclear Power Plant, and Vermont Yankee Nuclear Power Plant. There have also been campaigns relating to the Y-12 Nuclear Weapons Plant, the Idaho National Laboratory, proposed Yucca Mountain nuclear waste repository, the Hanford Site, the Nevada Test Site, Lawrence Livermore National Laboratory, and transportation of nuclear waste from the Los Alamos National Laboratory.\n\nSome scientists and engineers have expressed reservations about nuclear power, including: Barry Commoner, S. David Freeman, John Gofman, Arnold Gundersen, Mark Z. Jacobson, Amory Lovins, Arjun Makhijani, Gregory Minor, Joseph Romm and Benjamin K. Sovacool. Scientists who have opposed nuclear weapons include Linus Pauling and Eugene Rabinowitch.\n\nAntitoxics groups are a subgroup that is affiliated with the Environmental Movement in the United States, that is primarily concerned with the effects that cities and their by products have on humans. This aspect of the movement is a self-proclaimed \"movement of housewives\". Concern around the issues of ground water contamination and air pollution rose in the early 1980s and individuals involved in antitoxics groups claim that they are concerned for the health of their families.\nA prominent case can be seen in the Love Canal Homeowner's association (LCHA); in this case a housing development was built on a site that had been used for toxic dumping by the Hooker Chemical Company. As a result of this dumping the residents had symptoms of skin irritation, Lois Gibbs, a resident of the development, started a grassroots campaign for reparations. Eventual success led to the government having to purchase homes that were sold in the development.\n\nPrior to the 1970s the protection of basic air and water supplies was a matter mainly left to each state. During the 1970s, primary responsibility for clean air and water shifted to the federal government. Growing concerns, both environmental and economic, from cities and towns as well as sportsman and other local groups, and senators such as Maine's Edmund S. Muskie, led to passage of extensive legislation, notably the Clean Air Act of 1970 and the Water Pollution Control Act Amendments of 1972. Other legislation included National Environmental Policy Act (NEPA), signed into law in 1970, which established a United States Environmental Protection Agency and a Council on Environmental Quality; the Marine Protection, Research, and Sanctuaries Act of 1972; the Endangered Species Act of 1973, the Safe Drinking Water Act (1974), the Resource Conservation and Recovery Act (1976), the Water Pollution Control Act Amendments of 1977, which became known as the Clean Water Act, and the Comprehensive Environmental Response, Compensation, and Liability Act, commonly known as the Superfund Act (1980). These laws regulated public drinking water systems, toxic substances, pesticides, and ocean dumping; and protected wildlife, wilderness, and wild and scenic rivers. Moreover, the new laws provide for pollution research, standard setting, contaminated site cleanup, monitoring, and enforcement.\n\nThe creation of these laws led to a major shift in the environmental movement. Groups such as the Sierra Club shifted focus from local issues to becoming a lobby in Washington and new groups, for example, the Natural Resources Defense Council and Environmental Defense, arose to influence politics as well. (Larson)\n\nIn the 1980s President Ronald Reagan sought to curtail scope of environmental protection taking steps such as appointing James G. Watt who was called one of the most \"blatantly anti-environmental political appointees\". The major environmental groups responded with mass mailings which led to increased membership and donations. The large environmental organization increasingly relied on ties within Washington, D.C. to advance their environmental agenda. At the same time membership in environmental groups became more suburban and urban. Groups such as animal rights, and the gun control lobby became linked with environmentalism while sportsmen, farmers and ranchers were no longer influential in the movement.\n\nWhen industry groups lobbied to weaken regulation and a backlash against environmental regulations, the so-called wise use movement gained importance and influence. The wise use movement and anti-environmental groups were able to portray environmentalist as out of touch with mainstream values. (Larson)\n\nIn 2004, with the environmental movement seemingly stalled, some environmentalists started questioning whether \"environmentalism\" was even a useful political framework. According to a controversial essay titled \"The Death of Environmentalism \" (Michael Shellenberger and Ted Nordhaus, 2004) American environmentalism has been remarkably successful in protecting the air, water, and large stretches of wilderness in North America and Europe, but these environmentalists have stagnated as a vital force for cultural and political change.\n\nShellenberger and Nordhaus wrote, \"Today environmentalism is just another special interest. Evidence for this can be found in its concepts, its proposals, and its reasoning. What stands out is how arbitrary environmental leaders are about what gets counted and what doesn't as 'environmental.' Most of the movement's leading thinkers, funders, and advocates do not question their most basic assumptions about who we are, what we stand for, and what it is that we should be doing.\" Their essay was followed by a speech in San Francisco called \"Is Environmentalism Dead?\" by former Sierra Club President, Adam Werbach, who argued for the evolution of environmentalism into a more expansive, relevant and powerful progressive politics. Werbach endorsed building an environmental movement that is more relevant to average Americans, and controversially chose to lead Wal-Mart's effort to take sustainability mainstream.\n\nThese \"post-environmental movement\" thinkers argue that the ecological crises the human species faces in the 21st century are qualitatively different from the problems the environmental movement was created to address in the 1960s and 1970s. They argue that climate change and habitat destruction are global and more complex, therefore demanding far deeper transformations of the economy, the culture and political life. The consequence of environmentalism's outdated and arbitrary definition, they argue, is political irrelevancy.\n\nThese \"politically neutral\" groups tend to avoid global conflicts and view the settlement of inter-human conflict as separate from regard for nature - in direct contradiction to the ecology movement and peace movement which have increasingly close links: while Green Parties, Greenpeace, and groups like the ACTivist Magazine regard ecology, biodiversity, and an end to non-human extinction as an absolute basis for peace, the local groups may not, and see a high degree of global competition and conflict as justifiable if it lets them preserve their own local uniqueness. However, such groups tend not to \"burn out\" and to sustain for long periods, even generations, protecting the same local treasures.\n\nLocal groups increasingly find that they benefit from collaboration, e.g. on consensus decision making methods, or making simultaneous policy, or relying on common legal resources, or even sometimes a common glossary. However, the differences between the various groups that make up the modern environmental movement tend to outweigh such similarities, and they rarely co-operate directly except on a few major global questions. In a notable exception, over 1,000 local groups from around the country united for a single day of action as part of the Step It Up 2007 campaign for real solutions to global warming.\n\nGroups such as The Bioregional Revolution are calling on the need to bridge these differences, as the converging problems of the 21st century they claim compel the people to unite and to take decisive action. They promote bioregionalism, permaculture, and local economies as solutions to these problems, overpopulation, global warming, global epidemics, and water scarcity, but most notably to \"peak oil\"—the prediction that the country is likely to reach a maximum in global oil production which could spell drastic changes in many aspects of the residents' everyday lives.\n\nMany environmental lawsuits turn on the question of who has standing; are the legal issues limited to property owners, or does the general public have a right to intervene? Christopher D. Stone's 1972 essay, \"Should trees have standing?\" seriously addressed the question of whether natural objects themselves should have legal rights, including the right to participate in lawsuits. Stone suggested that there was nothing absurd in this view, and noted that many entities now regarded as having legal rights were, in the past, regarded as \"things\" that were regarded as legally rightless; for example, aliens, children and women. His essay is sometimes regarded as an example of the fallacy of hypostatization.\n\nOne of the earliest lawsuits to establish that citizens may sue for environmental and aesthetic harms was Scenic Hudson Preservation Conference v. Federal Power Commission, decided in 1965 by the Second Circuit Court of Appeals. The case helped halt the construction of a power plant on Storm King Mountain in New York State. See also United States environmental law and David Sive, an attorney who was involved in the case.\n\nConservation biology is an important and rapidly developing field.\n\nOne way to avoid the stigma of an \"ism\" was to evolve early anti-nuclear groups into the more scientific Green Parties, sprout new NGOs such as Greenpeace and Earth Action, and devoted groups to protecting global biodiversity and preventing global warming and climate change. But in the process, much of the emotional appeal, and many of the original aesthetic goals were lost. Nonetheless, these groups have well-defined ethical and political views, backed by science.\n\nSome people are skeptical of the environmental movement and feel that it is more deeply rooted in politics than science. Although there have been serious debates about climate change and effects of some pesticides and herbicides that mimic animal sex steroids, science has shown that some of the claims of environmentalists have credence.\n\nClaims made by environmentalists may be perceived as veiled attacks on industry and globalization rather than legitimate environmental concerns. Detractors note that a significant number of environmental theories and predictions have been inaccurate and suggest that the regulations recommended by environmentalists will more likely harm society rather than help nature.\n\nSpecific examples include when Rachel Carson, in her book \"Silent Spring\", suggested that the pesticide DDT caused cancer and drastically harmed ecosystems. DDT is highly toxic to aquatic life, including crawfish, daphnids, sea shrimp and many species of fish. However, DDT is also used to control malaria.\n\nProminent novelist and Harvard Medical School graduate Michael Crichton appeared before the U.S. Senate Committee on Environment and Public Works to address such concerns and recommended the employment of double-blind experimentation in environmental research. Crichton suggested that because environmental issues are so political in nature, policy makers need neutral, conclusive data to base their decisions on, rather than conjecture and rhetoric, and double-blind experiments are the most efficient way to achieve that aim.\n\nA consistent theme acknowledged by both supporters and critics (though more commonly vocalized by critics) of the environmental movement is that we know very little about the Earth we live in. Most fields of environmental studies are relatively new, and therefore what research we have is limited and does not date far enough back for us to completely understand long-term environmental trends. This has led a number of environmentalists to support the use of the precautionary principle in policy making, which ultimately asserts that we don't know how certain actions may affect the environment, and because there is reason to believe they may cause more harm than good we should refrain from such actions.\n\nIn the December 1994 \"Wild Forest Review,\" Alexander Cockburn and Jeffrey St. Clair wrote \"The mainstream environmental movement was elitist, highly paid, detached from the people, indifferent to the working class, and a firm ally of big government.…The environmental movement is now accurately perceived as just another well-financed and cynical special interest group, its rancid infrastructure supported by Democratic Party operatives and millions in grants from corporate foundations.\"\n\nHistorian and President of the American Historical Association William Cronon has criticized the modern environmental movement for having a romantic idealizations of wilderness. Cronon writes \"wilderness serves as the unexamined foundation on which so many of the quasi-religious values of modern environmentalism rest.\" Cronon claims that \"to the extent that we live in an urban-industrial civilization but at the same time pretend to ourselves that our real home is in the wilderness, to just that extent we give ourselves permission to evade responsibility for the lives we actually lead.\"\n\nSimilarly Michael Pollan has argued that the wilderness ethic leads people to dismiss areas whose wildness is less than absolute. In his book Second Nature, Pollan writes that \"once a landscape is no longer 'virgin' it is typically written off as fallen, lost to nature, irredeemable.\"\n\nWithin the environmental movement an ideological debate has taken place between those with an ecocentric view point and an anthropocentric view point. The anthropocentric view has been seen as the conservationist approach to the environment with nature viewed, at least in part, as resource to be used by man. In contrast to the conservationist approach the ecocentric view, associated with John Muir, Henry David Thoreau and William Wordsworth referred to as the preservationist movement. This approach sees nature in a more spiritual way. Many environmental historians consider the split between John Muir and Gifford Pinchot. During the preservation / conservation debate the term preservationist become to be seen as a pejorative term.\n\nWhile the ecocentric view focused on biodiversity and wilderness protection the anthropocentric view focus on urban pollution and social justice. Some environmental writers, for example William Cronon have criticized the ecocentric view as have a dualist view as man being separate from nature. Critics of the anthropocentric view point contend that the environmental movement has been taken over by so-called leftist with an agenda beyond environmental protection.\n\nSeveral books after the middle of the 20th century contributed to the rise of American environmentalism (as distinct from the longer-established conservation movement), especially among college and university students and the more literate public. One was the publication of the first textbook on ecology, \"Fundamentals of Ecology,\" by Eugene Odum and Howard Odum, in 1953. Another was the appearance of the best-seller \"Silent Spring\" by Rachel Carson, in 1962. Her book brought about a whole new interpretation on pesticides by exposing their harmful effects in nature. From this book many began referring to Carson as the \"mother of the environmental movement\". Another influential development was a 1965 lawsuit, Scenic Hudson Preservation Conference v. Federal Power Commission, opposing the construction of a power plant on Storm King Mountain, which is said to have given birth to modern United States environmental law. The wide popularity of \"The Whole Earth Catalogs\", starting in 1968, was quite influential among the younger, hands-on, activist generation of the 1960s and 1970s. Recently, in addition to opposing environmental degradation and protecting wilderness, an increased focus on coexisting with natural biodiversity has appeared, a strain that is apparent in the movement for sustainable agriculture and in the concept of Reconciliation Ecology.\n\nEnvironmentalists became much more influential in American politics after the creation or strengthening of numerous U.S. environmental laws, including the Clean Air Act and Clean Water Act and the formation of the US Environmental Protection Agency, or EPA in 1970. These successes were followed by the enactment of a whole series of laws regulating waste (Resource Conservation and Recovery Act), toxic substances (Toxic Substances Control Act), pesticides (FIFRA: Federal Insecticide, Fungicide, and Rodenticide Act), clean-up of polluted sites (Superfund), protection of endangered species (Endangered Species Act), and more.\n\nFewer environmental laws have been passed in the last decade as corporations and other conservative interests have increased their influence over American politics. Corporate cooperation against environmental lobbyists has been organized by the Wise Use group. At the same time, many environmentalists have been turning toward other means of persuasion, such as working with business, community, and other partners to promote sustainable development.\n\nMuch environmental activism is directed towards conservation, as well as the prevention or elimination of pollution. However, conservation movements, ecology movements, peace movements, green parties, green- and eco-anarchists often subscribe to very different ideologies, while supporting the same goals as those who call themselves \"environmentalists\". To outsiders, these groups or factions can appear to be indistinguishable.\n\nAs human population and industrial activity continue to increase, environmentalists often find themselves in serious conflict with those who believe that human and industrial activities should not be overly regulated or restricted, such as some libertarians.\n\nEnvironmentalists often clash with others, particularly \"corporate interests,\" over issues of the management of natural resources, like in the case of the atmosphere as a \"carbon dump\", the focus of climate change, and global warming controversy. They usually seek to protect commonly owned or unowned resources for future generations.\n\nThose who take issue with new untested technologies are more precisely known, especially in Europe, as political ecologists. They usually seek, in contrast, to preserve the integrity of existing ecologies and ecoregions, and in general are more pessimistic about human \"management\".\n\nWhile most environmentalists are mainstream and peaceful, a small minority are more radical in their approach. Adherents of radical environmentalism and ecological anarchism are involved in direct action campaigns to protect the environment. Some campaigns have employed controversial tactics including sabotage, blockades, and arson, while most use peaceful protests such as marches, tree-sitting, and the like. There is substantial debate within the environmental movement as to the acceptability of these tactics, but almost all environmentalists condemn violent actions that can harm humans.\n\n\n\n"}
{"id": "10184", "url": "https://en.wikipedia.org/wiki?curid=10184", "title": "Environmentalist", "text": "Environmentalist\n\nAn environmentalist is a supporter of the goals of the environmental movement, \"a political and ethical movement that seeks to improve and protect the quality of the natural environment through changes to environmentally harmful human activities\". An environmentalist is engaged in or believes in the philosophy of environmentalism.\n\nEnvironmentalists are sometimes referred to using informal or derogatory terms such as \"greenie\" and \"tree-hugger\".\n\nSome of the notable environmentalists who have been active in lobbying for environmental protection and conservation include:\n\n\n\n"}
{"id": "10186", "url": "https://en.wikipedia.org/wiki?curid=10186", "title": "Eastern Orthodox Church", "text": "Eastern Orthodox Church\n\nThe Eastern Orthodox Church, also known as the Orthodox Church, or officially as the Orthodox Catholic Church, is the second-largest Christian Church and one of the oldest extant religious institutions in the world. The Eastern Orthodox Church teaches that it is the One, Holy, Catholic and Apostolic Church established by Jesus Christ in his Great Commission to the apostles. It practices what it understands to be the original Christian faith and maintains the sacred tradition passed down from the apostles.\n\nThe Eastern Orthodox Church is a communion of autocephalous churches, each typically governed by a Holy Synod. It teaches that all bishops are equal by virtue of their ordination, and has no central governing structure analogous to the Papacy in the Roman Catholic Church. The contemporary Orthodox Church had shared communion with the contemporary Roman Catholic Church until the East–West Schism of AD 1054, which had been triggered by disputes over doctrine, especially the authority of the Pope. Prior to the Council of Chalcedon in AD 451, the Eastern Orthodox had also shared communion with the Oriental Orthodox churches, separating primarily over differences in Christology.\n\nEastern Orthodoxy is the form of Christianity that developed in the Greek-speaking Eastern part of the Roman Empire and continued later in the Byzantine Empire and beyond, playing a prominent role in European, Near Eastern, Slavic, and some African cultures. During the first eight centuries of Christian history, most major intellectual, cultural, and social developments in the Christian Church took place within the Empire or in the sphere of its influence, where the Greek language was widely spoken and used for most theological writings. As a result, the term \"Greek Orthodox\" has sometimes been used to describe all of Eastern Orthodoxy in general, with the word \"Greek\" referring to the heritage of the Byzantine Empire. However, the appellation \"Greek\" was never in official use and was gradually abandoned by the non–Greek-speaking Eastern Orthodox churches, from as early as the 10th century A.D.\n\nIts most prominent episcopal see is Constantinople. The majority of Eastern Orthodox Christians live in Greece, eastern Europe, the Caucasus and Russia, with less numerous communities in the former Byzantine regions of the eastern Mediterranean, Africa and the Middle East. There are also many in other parts of the world, formed through immigration, conversion and missionary activity.\nIn keeping with the Church's teaching on universality and with the Nicene Creed, Orthodox authorities such as Saint Raphael of Brooklyn have insisted that the full name of the church has always included the term \"Catholic\", as in \"Holy Orthodox Catholic Apostolic Church\". The official name of the Eastern Orthodox Church is the Orthodox Catholic Church. It is the name by which the church refers to itself in its liturgical or canonical texts, in official publications, and in official contexts or administrative documents. Orthodox teachers refer to the Church as Catholic. This name and longer variants containing \"Catholic\" are also recognized and referenced in other books and publications by secular or non-Orthodox writers.\n\nThe common name of the Church, Eastern Orthodox Church, is a shortened practicality that helps to avoid confusions in casual use. From ancient times through the first millennium, Greek was the most prevalent shared language in the demographic regions where the Byzantine Empire flourished, and Greek, being the language in which the New Testament was written, was the primary liturgical language of the church. For this reason, the eastern churches were sometimes identified as \"Greek\" (in contrast to the \"Roman\" or \"Latin\" church, which used a Latin translation of the Bible), even before the great schism. After 1054, \"Greek Orthodox\" or \"Greek Catholic\" marked a church as being in communion with Constantinople, much as \"Roman Catholic\" did for communion with Rome. This identification with Greek, however, became increasingly confusing with time. Missionaries brought Orthodoxy to many regions without ethnic Greeks, where the Greek language was not spoken. In addition, struggles between Rome and Constantinople to control parts of southeastern Europe resulted in the conversion of some churches to Rome, which then also used \"Greek Catholic\" to indicate their continued use of the Byzantine rites. Today, many of those same Roman churches remain, while a very large number of Orthodox are not of Greek national origin, and do not use Greek as the language of worship. \"Eastern\", then, indicates the geographical element in the Church's origin and development, while \"Orthodox\" indicates the faith, as well as communion with the Ecumenical Patriarchate of Constantinople. (There are additional Christian churches in the east that are in communion with neither Rome nor Constantinople, who tend to be distinguished by the category named \"Oriental Orthodox\".) While the Church continues officially to call itself \"Catholic\", for reasons of universality, the common title of \"Eastern Orthodox Church\" avoids casual confusion with the Roman Catholic Church.\n\nThe first known use of the phrase \"the catholic church\" (\"he katholike ekklesia\") occurred in a letter written about 110 AD from one Greek church to another (Saint Ignatius of Antioch to the Smyrnaeans). Quote of St Ignatius to the Smyrnaeans (circa 110 AD): \"Wheresoever the bishop shall appear, there let the people be, even as where Jesus may be, there is the universal [katholike] Church.\" Thus, almost from the very beginning, Christians referred to the Church as the \"One, Holy, Catholic (from the Greek καθολική, or \"according to the whole, universal\") and Apostolic Church\". The Orthodox Church claims that it is today the continuation and preservation of that same Church.\n\nA number of other Christian churches also make a similar claim: the Roman Catholic Church, the Anglican Communion, the Assyrian Church and the Oriental Orthodox Churches. In the Orthodox view, the Assyrians and Orientals left the Orthodox Church in the years following the Third Ecumenical Council of Ephesus (431) and the Fourth Ecumenical Council of Chalcedon (451), respectively, in their refusal to accept those councils' Christological definitions. Similarly, the churches in Rome and Constantinople separated in an event known as the East–West Schism, traditionally dated to the year 1054, although it was more a gradual process than a sudden break. The Church of England separated from the Roman Catholic Church, not directly from the Orthodox Church, for the first time in the 1530s (and, after a brief reunion in 1555, again finally in 1558). Thus, though it was united to Orthodoxy when established through the work of Saint Augustine of Canterbury in the early 7th century, its separation from Orthodoxy came about indirectly through the See of Rome.\n\nTo all these churches, the claim to catholicity (universality, oneness with the ancient church) is important for multiple doctrinal reasons that have more bearing internally in each church than in their relation to the others, now separated in faith. The meaning of holding to a faith that is true is the primary reason why anyone's statement of which church split off from which other has any significance at all; the issues go as deep as the schisms. The depth of this meaning in the Orthodox Church is registered first in its use of the word \"Orthodox\" itself, a union of Greek \"orthos\" (\"straight\", \"correct\", \"true\", \"right\") and \"doxa\" (\"glory\" as in Doxa Patri, \"Glory to the Father\").\n\nThe dual meanings of \"doxa\", with \"glory\" or \"glorification\" (of God by the Church and of the Church by God), especially in worship, yield the pair \"correct belief\" and \"true worship\". Together, these express the core of a fundamental teaching about the inseparability of belief and worship and their role in drawing the Church together with Christ. The Bulgarian and all the Slavic churches use the title \"Pravoslavie\" (Cyrillic: \"Православие\"), meaning \"glorification of correctness\", to denote what is in English \"Orthodoxy\", while the Georgians use the title \"Martlmadidebeli\". Several other churches in Europe, Asia, and Africa also came to use \"Orthodox\" in their titles, but are still distinct from the Orthodox Church as described in this article.\n\nThe term \"Eastern Church\" (the geographic east in the East–West Schism) has been used to distinguish it from western Christendom (the geographic West, which at first came to designate the Roman Catholic communion, later also the various Protestant and Anglican branches). \"Eastern\" is used to indicate that the highest concentrations of the Orthodox Church presence remain in the eastern part of the Christian world, although it is growing worldwide. Orthodox Christians throughout the world use various ethnic or national jurisdictional titles, or more inclusively, the title \"Eastern Orthodox\", \"Orthodox Catholic\", or simply \"Orthodox\".\n\nWhat unites Orthodox Christians is the catholic faith, whose vessel is Holy Tradition, inspired through the operation of the Holy Spirit. That faith is expressed most fundamentally in Scripture and in worship, and the latter most essentially through the mystery of Baptism and in the Divine Liturgy. The faith lives and breathes by God's energies in communion with the Church. Inter-communion is the litmus test by which all can see that two churches share the same faith; lack of inter-communion (excommunication, literally \"out of communion\") is the sign of different faiths, even though some central theological points may be shared. The sharing of beliefs can be highly significant, but it is not the full measure of the faith.\n\nThe lines of even this test can blur, however, when differences that arise are not due to doctrine, but to recognition of jurisdiction. As the Orthodox Church has spread into the west and over the world, the church as a whole has yet to sort out all the inter-jurisdictional issues that have arisen in the expansion, leaving some areas of doubt about what is proper church governance. And as in the ancient church persecutions, the aftermath of modern persecutions of Christians in communist nations has left behind both some governance and some faith issues that have yet to be completely resolved.\n\nAll members of the Orthodox Church profess the same faith, regardless of race or nationality, jurisdiction or local custom, or century of birth. Holy Tradition encompasses the understandings and means by which that unity of faith is transmitted across boundaries of time, geography, and culture. It is a continuity that exists only inasmuch as it lives within Christians themselves. It is not static, nor an observation of rules, but rather a sharing of observations that spring both from within and also in keeping with others, even others who lived lives long past. The Holy Spirit maintains the unity and consistency of the Holy Tradition to preserve the integrity of the faith within the Church, as given in the Scriptural promises.\n\nThe shared beliefs of Orthodoxy, and its theology, exist within the Holy Tradition and cannot be separated from it, for their meaning is not expressed in mere words alone. Doctrine cannot be understood unless it is prayed. To be a theologian, one must know how to pray, and one who prays in spirit and in truth becomes a theologian by doing so. Doctrine must also be lived in order to be prayed, for without action, the prayer is idle and empty, a mere vanity, and therefore the theology of demons. According to these teachings of the ancient church, no superficial belief can ever be orthodox. Similarly, reconciliation and unity are not superficial, but are prayed and lived out.\n\nEastern Orthodox Church considers itself to be both orthodox and catholic. Doctrine of Catholicity of the Church, as derived from the Nicene Creed, is essential to Eastern Orthodox Ecclesiology. The term \"Catholicity of the Church\" (Greek ) is used in its original sense, as a designation for the Universality of the Church, centered around Christ. Therefore, Eastern Orthodox notion of Catholicity is not centered around any singular see, unlike Roman Catholicism, that has one earthly center.\n\nDue to the influence of the Roman Catholic Church in the west, where the English language itself developed, the words \"catholic\" and \"catholicity\" are sometimes used to refer to that church specifically. However, the more prominent dictionary sense given for general use is still the one shared by other languages, implying breadth and universality, reflecting comprehensive scope. In a Christian context, the Church, as identified with the original Church founded by Christ and His apostles, is said to be catholic (or universal) in regard to its union with Christ in faith. Just as Christ is indivisible, so are union with Him and faith in Him, whereby the Church is \"universal\", unseparated, and comprehensive, including all who share that faith. Orthodox Bishop Kallistos Ware has called that \"simple Christianity\". That is the sense of early and patristic usage wherein the Church usually refers to itself as the \"Catholic Church\", whose faith is the \"Orthodox faith\". It is also the sense within the phrase \"One, Holy, Catholic, and Apostolic Church\", found in the Nicene Creed, and referred to in Orthodox worship, e.g. in the litany of the catechumens in the divine liturgy.\n\nWith the mutual excommunications of the East–West Schism in 1054, the churches in Rome and Constantinople each viewed the other as having departed from the true Church, leaving a smaller but still-catholic Church in place. Each retained the \"Catholic\" part of its title, the \"Catholic Church\" (or \"Roman Catholic Church\") on the one hand, and the \"Orthodox Catholic Church\" on the other, each of which was defined in terms of inter-communion with either Rome or Constantinople. While the Orthodox Church recognizes what it shares in common with other churches, including the Roman Catholic Church, it sees catholicity in terms of complete union in communion and faith, with the Church throughout all time, and the sharing remains incomplete when not shared fully.\n\nThe religious authority for Eastern Orthodoxy is not a Patriarch or the Pope as in Catholicism, nor the Bible as in Protestantism, but the scriptures as interpreted by the seven ecumenical councils of the Church. The Orthodox Church is a fellowship of \"autocephalous\" (Greek for self-headed) Churches, with the Ecumenical Patriarch of Constantinople being the only autocephalous head who holds the title \"primus inter pares\", meaning \"first among equals\" in Latin. The Patriarch of Constantinople has the honor of primacy, but his title is only first among equals and has no real authority over Churches other than the Constantinopolitan. The Orthodox Church considers Jesus Christ to be the head of the Church and the Church to be his body. It is believed that authority and the grace of God is directly passed down to Orthodox bishops and clergy through the laying on of hands—a practice started by the apostles, and that this unbroken historical and physical link is an essential element of the true Church (Acts 8:17, 1 Tim 4:14, Heb 6:2). However, the Church asserts that Apostolic Succession also requires Apostolic Faith, and bishops without Apostolic Faith, who are in heresy, forfeit their claim to Apostolic Succession.\n\nThe Eastern Orthodox communion is organized into several regional Churches, which are either autocephalous (\"self-headed\") or lower ranking autonomous (the Greek term for \"self-lawed\") Church bodies unified in theology and worship. These include the fourteen autocephalous Churches of Constantinople, Alexandria, Antioch, Jerusalem, Georgia, Cyprus, Bulgaria, Serbia, Russia, Greece, Poland, Romania, Albania, and Czech Republic and Slovakia, which were officially invited to the Pan-Orthodox Council of 2016, as well as a number of autonomous Churches. Each Church has a ruling bishop and a Holy Synod to administer its jurisdiction and to lead the Church in the preservation and teaching of the apostolic and patristic traditions and church practices.\n\nEach bishop has a territory (see) over which he governs. His main duty is to make sure the traditions and practices of the Church are preserved. Bishops are equal in authority and cannot interfere in the jurisdiction of another bishop. Administratively, these bishops and their territories are organized into various autocephalous groups or synods of bishops who gather together at least twice a year to discuss the state of affairs within their respective sees. While bishops and their autocephalous synods have the ability to administer guidance in individual cases, their actions do not usually set precedents that affect the entire Church. Bishops are almost always chosen from the monastic ranks and must remain unmarried.\n\nThere have been a number of times when alternative theological ideas arose to challenge the Orthodox faith. At such times the Church deemed it necessary to convene a general or \"Great\" council of all available bishops throughout the world. The Church considers the first seven Ecumenical Councils (held between the 4th and the 8th centuries) to be the most important; however, there have been more, specifically the Synods of Constantinople, 879–880, 1341, 1347, 1351, 1583, 1819, and 1872, the Synod of Jassy (Iași), 1642, and the Pan-Orthodox Synod of Jerusalem, 1672, all of which helped to define the Orthodox position.\n\nThe ecumenical councils followed a democratic form, with each bishop having one vote. Though present and allowed to speak before the council, members of the Imperial Roman/Byzantine court, abbots, priests, monks and laymen were not allowed to vote. The primary goal of these Great Synods was to verify and confirm the fundamental beliefs of the Church as truth, and to remove as heresy any false teachings that would threaten the Church. The Pope of Rome, at that time, held the position of \"first among equals\". And while he was not present at any of the councils he continued to hold this title until the East–West Schism of 1054 AD.\n\nAccording to Orthodox teaching the position of \"First Among Equals\" gives no additional power or authority to the bishop that holds it, but rather that this person sits as organizational head of a council of equals (like a president). His words and opinions carry no more insight or wisdom than any other bishop. It is believed that the Holy Spirit guides the Church through the decisions of the entire council, not one individual. Additionally it is understood that even the council’s decisions must be accepted by the entire Church in order for them to be valid.\n\nOne of the decisions made by the First Council of Constantinople (the second ecumenical council, meeting in 381) and supported by later such councils was that the Patriarch of Constantinople should be given equal honor to the Pope of Rome since Constantinople was considered to be the \"New Rome\". According to the third Canon of the second ecumenical council: \"Because it is new Rome, the bishop of Constantinople is to enjoy the privileges of honor \"after\" the bishop of Rome.\" This means that both enjoy the same privileges because they are both bishops of the imperial capitals, but the bishop of Rome will precede the bishop of Constantinople since Old Rome precedes New Rome.\n\nThe 28th canon of the fourth ecumenical council clarified this point by stating: \"For the Fathers rightly granted privileges to the throne of Old Rome because it was the royal city. And the One Hundred and Fifty most religious Bishops (i.e. the second ecumenical council in 381) actuated by the same consideration, gave equal privileges to the most holy throne of New Rome, justly judging that the city which is honored with the Sovereignty and the Senate, and enjoys equal privileges with the old imperial Rome, should in ecclesiastical matters also be magnified as she is.\"\n\nBecause of the schism the Orthodox no longer recognize the primacy of the pope. The Patriarch of Constantinople therefore, like the Pope before him, now enjoys the title of \"first among equals\".\n\nPolitics, wars, persecutions, oppressions, and related potential threats can make precise counts of Orthodox membership difficult to obtain at best in some regions. Historically, forced migrations have also altered demographics in relatively short periods of time. The most reliable estimates currently available number Orthodox adherents at around 200 million worldwide, making Eastern Orthodoxy the second largest Christian communion in the world after Catholicism. The numerous Protestant groups in the world, if taken all together, outnumber the Orthodox, but they differ theologically and do not form a single communion. According to the 2015 Yearbook of International Religious Demography, the Orthodox population in 2010 decreased to 4% of the global population from 7.1% of the global population in 1910. According to the same source, in terms of the total Christian population, the relative percentages were 12.2% and 20.4% respectively. According to the Pew Research Center, the Orthodox share of the world's total Christian population was 12% in 2011.\n\nMost members today are concentrated in Eastern Europe and Asian Russia, in addition to significant minorities in Central Asia and the Levant, although Eastern Orthodoxy has spread into a global religion towards Western Europe and the New World, with churches in most countries and major cities. The adherents constitute the largest single religious faith in the world's largest country – Russia, where roughly half of Eastern Orthodox Christians live. They are the majority religion in Ukraine, Romania, Belarus, Greece, Serbia, Bulgaria, Moldova, Georgia, Macedonia, Cyprus, Montenegro, they also dominate in the disputed territories Abkhazia, South Ossetia and Transnistria. Significant minorities of Eastern Orthodox are present in Bosnia and Herzegovina, Latvia, Estonia, Kazakhstan, Kyrgyzstan, Lebanon, Albania, Syria, and many other countries.\n\nThe percentage of Christians in Turkey fell from 19 percent in 1914 to 2.5 percent in 1927, predominately due to persecution, including the Armenian Genocide, the Greek genocide and subsequent population exchange between Greece and Turkey, population exchanges between Bulgaria and Turkey, and associated emigration of Christians to foreign countries (mostly in Europe and the Americas). Today there are more than 160,000 people of different Christian denominations.\n\nThrough mostly labor migration from Eastern Europe and some conversion, Orthodox Christianity is the fastest growing religious grouping in certain Western countries, for example in the Republic of Ireland, but Orthodoxy is not \"a central marker of minority identity\" for the migrants. While in the United States, the number of Orthodox parishes is growing.\n\nOrthodox Christians believe in the Holy Trinity, three distinct, divine persons (\"hypostases\"), without overlap or modality among them, who share one divine essence (\"ousia\" Greek οὐσία)—uncreated, immaterial and eternal. These three persons are typically distinguished by their relation to each other. The Father is eternal and not begotten and does not proceed from any, the Son is eternal and begotten of the Father, and the Holy Spirit is eternal and proceeds from the Father. Orthodox doctrine regarding the Holy Trinity is summarized in the Symbol of Faith.\n\nIn discussing God's relationship to His creation, Orthodox theology distinguishes between God's eternal essence, which is totally transcendent, and His \"uncreated energies\", which is how He reaches us. The God who is transcendent and the God who touches us are one and the same. That is, these energies are not something that proceed from God or that God produces, but rather they are God himself: distinct, yet inseparable from, God's inner being.\n\nIn understanding the Holy Trinity as \"one God in three persons\", \"three persons\" is not to be emphasized more than \"one God\", and vice versa. While the three persons are distinct, they are united in one divine essence, and their oneness is expressed in community and action so completely that they cannot be considered separately. For example, their salvation of mankind is an activity engaged in common: \"Christ became man by the good will of the Father and by the cooperation of the Holy Spirit. Christ sends the Holy Spirit who proceeds from the Father, and the Holy Spirit forms Christ in our hearts, and thus God the Father is glorified.\" Their \"communion of essence\" is \"indivisible\". Trinitarian terminology—essence, hypostasis, etc.—are used \"philosophically\", \"to answer the ideas of the heretics\", and \"to place the terms where they separate error and truth.\" The words do what they can do, but the nature of the Trinity in its fullness remains beyond our comprehension and expression, a Holy Mystery that can only be experienced.\n\nAccording to the Eastern Orthodox faith, at some point in the beginnings of human existence, man was faced with a choice: to learn the difference between good and evil through observation, or through participation. The biblical story of Adam and Eve relates this choice by mankind to participate in evil, accomplished through disobedience to God's command. Both the intent and the action were separate from God's will; it is that separation that defines and marks any operation as sin. The separation from God caused the loss of (fall from) his grace, a severing of mankind from his creator and the source of his life. The end result was the diminishment of human nature and its subjection to death and corruption, an event commonly referred to as the \"fall of man\".\n\nWhen Orthodox Christians refer to Fallen Nature they are not saying that human nature has become evil in itself. Human nature is still formed in the image of God; we are still God's creation, and God has never created anything evil. But our fallen nature remains open to evil intents and actions. It is sometimes said that we are \"inclined to sin\"; that is, we find some sinful things attractive. It is the nature of temptation to make sinful things seem the more attractive, and it is the fallen nature of humans that seeks or succumbs to the attraction. Orthodox Christians reject the Augustinian position that the descendants of Adam and Eve are actually guilty of the original sin of their ancestors. But just as any species begets its own kind, so fallen humans beget fallen humans, and from the beginning of our existence we lie open to sinning by our own choice.\n\nSince the fall of man, then, it has been mankind's dilemma that no human can restore his nature to union with God's grace; it was necessary for God to effect another change in human nature. Orthodox Christians believe that Christ Jesus was both God and Man absolutely and completely, having two natures indivisibly: eternally begotten of the Father in his divinity, he was born in his humanity of a woman, Mary, by her consent, through descent of the Holy Spirit. He lived on earth, in time and history, as a man. As a man he also died, and went to the place of the dead, which is Hades. But being God, neither death nor Hades could contain him, and he rose to life again, in his humanity, by the power of the Holy Spirit, thus destroying the power of Hades, and of death itself. Through God's participation in humanity, Christ's human nature, perfected and unified with his divine nature, ascended into heaven, there to reign in communion with the Holy Trinity.\n\nBy these acts of salvation, Christ provided fallen mankind with the path to escape its fallen nature. The Orthodox Church teaches that through baptism into Christ's death, and our death unto sin in repentance, with God's help we can also rise with Christ into heaven, healed of the breach of our fallen nature and restored to God's grace. To Orthodox Christians, this process is what is meant by \"salvation\", which consists of the Christian life. The ultimate goal is theosis – an even closer union with God and closer likeness to God than existed in the Garden of Eden. This very process is called Deification or \"God became man that man might become 'god'\". However, it must be emphasized that Orthodox Christians do not believe that man literally becomes God in His essence, or a god in his own nature. More accurately, Christ's salvific work enables man in his human nature to become \"partakers of the Divine nature\" (2 Peter 1:4); that is to say, man is united to God in Christ.\n\nThrough Christ's destruction of Hades' power to hold humanity hostage, he made the path to salvation effective for all the righteous who had died from the beginning of time – saving many, including Adam and Eve, who are remembered in the Church as saints.\n\nThe Orthodox reject the idea that Christ died to give God \"satisfaction\", as taught by Anselm, or as a punitive substitute as taught by the Reformers. Sin (separation from God, the source of all life) is its own punishment, capable of imprisoning the soul in an existence without life, without anything good, and without hope: hell, by any measure. Life on earth is God's gift, to give us opportunity to make our choice real: separation, or union.\n\nThe Orthodox Church understands the death and resurrection of Christ Jesus to be real historical events, as described in the gospels of the New Testament. Jesus Christ, the Son of God, was in his humanity (that is, in history) crucified, and died, descending into Hades (Sheol), the place of the dead, as all humans do. But He, alone among humans, has two natures, one human, one divine, which are indivisible and inseparable from each other through the mystery of the incarnation. Hades could not restrain the infinite God. Christ in His divine nature captured the keys of Hades and broke the bonds which had imprisoned the human souls who had been held there through their separation from God.\n\nNeither could death contain the Son of God, the Fountain of Life, who arose from death even in his human nature. Not only this, but he opened the gates of Hades to all the righteous dead of past ages, rescuing them from their fallen human nature and restoring them to a nature of grace with God, bringing them back to life, this time in God's heavenly kingdom. And this path he opened to all who choose to follow him in time yet to come, thus saving the human race. Thus the Orthodox proclaim each year at the time of Pascha (Easter), that Christ \"trampled down death by death, and on those in the tombs bestowed life.\"\n\nThe celebration of the Resurrection of Christ at Pascha is the central event in the liturgical year of the Orthodox Church. According to Orthodox tradition, each human being may partake of this immortality, which would have been impossible without the Resurrection; it is the main promise held out by God in the New Testament. Every holy day of the Orthodox liturgical year relates to the Resurrection directly or indirectly. Every Sunday is especially dedicated to celebrating the Resurrection and the triune God, representing a mini-Pascha. In the liturgical commemorations of the Passion of Christ during Holy Week there are frequent allusions to the ultimate victory at its completion.\n\nChurch teaching is that Orthodox Christians, through baptism, enter a new life of salvation through repentance whose purpose is to share in the life of God through the work of the Holy Spirit. The Orthodox Christian life is a spiritual pilgrimage in which each person, through the imitation of Christ and \"hesychasm\", cultivates the practice of unceasing prayer. Each life occurs within the life of the Church as a member of the body of Christ. It is then through the fire of God's love in the action of the Holy Spirit that each member becomes more holy, more wholly unified with Christ, starting in this life and continuing in the next. The Church teaches that everyone, being born in God's image, is called to theosis, fulfillment of the image in likeness to God. God the creator, having divinity by nature, offers each person participation in divinity by cooperatively accepting His gift of grace.\n\nThe Orthodox Church, in understanding itself to be the Body of Christ, and similarly in understanding the Christian life to lead to the unification in Christ of all members of his body, views the church as embracing all Christ's members, those now living on earth, and also all those through the ages who have passed on to the heavenly life. The church includes the Christian saints from all times, and also judges, prophets and righteous Jews of the first covenant, Adam and Eve, even the angels and heavenly hosts. In Orthodox services, the earthly members together with the heavenly members worship God as one community in Christ, in a union that transcends time and space and joins heaven to earth. This unity of the Church is sometimes called the \"communion of the saints\".\n\nThe Orthodox Church believes death and the separation of body and soul to be unnatural—a result of the Fall of Man. They also hold that the congregation of the Church comprises both the living and the dead. All persons currently in heaven are considered to be saints, whether their names are known or not. There are, however, those saints of distinction whom God has revealed as particularly good examples. When a saint is revealed and ultimately recognized by a large portion of the Church a service of official recognition (glorification) is celebrated.\n\nThis does not 'make' the person a saint, it merely recognizes the fact and announces it to the rest of the Church. A day is prescribed for the saint’s celebration, hymns composed and icons are created. Numerous saints are celebrated on each day of the year. They are venerated (shown great respect and love) but not worshiped, for worship is due to God alone. In showing the saints this love and requesting their prayers, the Orthodox manifest their belief that the saints thus assist in the process of salvation for others.\n\nPre-eminent among the saints is the Virgin Mary, the Mother of God. In Orthodox theology, the Mother of God is the fulfillment of the Old Testament archetypes revealed in the Ark of the Covenant (because she carried the New Covenant in the person of Christ) and the burning bush that appeared before Moses (symbolizing the Mother of God's carrying of God without being consumed). Accordingly, the Orthodox consider Mary to be the Ark of the New Covenant and give her the respect and reverence as such. The Theotokos was chosen by God and she freely co-operated in that choice to be the Mother of Jesus Christ, the God-man.\n\nThe Orthodox believe that the Christ Child from the moment of conception was both fully God and fully human. Mary is thus called the 'Theotokos' or 'Bogoroditsa' as an affirmation of the divinity of the one to whom she gave birth. It is also believed that her virginity was not compromised in conceiving God-incarnate, that she was not harmed and that she remained forever a virgin. Scriptural references to \"brothers\" of Christ are interpreted as kin, given that the word 'brother' was used in multiple ways, as was the term 'father'. Due to her unique place in salvation history, Mary is honored above all other saints and especially venerated for the great work that God accomplished through her.\n\nThe Orthodox Church regards the bodies of all saints as holy, made such by participation in the Holy Mysteries, especially the communion of Christ's holy body and blood, and by the indwelling of the Holy Spirit within the Church. Indeed, that persons and physical things can be made holy is a cornerstone of the doctrine of the Incarnation, made manifest also directly by God in Old Testament times through his dwelling in the Ark of the Covenant. Thus, physical items connected with saints are also regarded as holy, through their participation in the earthly works of those saints. God himself bears witness to this holiness of saints' relics through the many miracles connected with them that have been reported throughout history since Biblical times, often including healing from disease and injury.\n\nOrthodox Christians believe that when a person dies the soul is temporarily separated from the body. Though it may linger for a short period on Earth, it is ultimately escorted either to paradise (Abraham's bosom) or the darkness of Hades, following the Temporary Judgment. Orthodox do not accept the doctrine of Purgatory, which is held by Roman Catholicism. The soul’s experience of either of these states is only a \"foretaste\"—being experienced only by the soul—until the Final Judgment, when the soul and body will be reunited.\n\nThe Orthodox believe that the state of the soul in Hades can be affected by the love and prayers of the righteous up until the Last Judgment. For this reason the Church offers a special prayer for the dead on the third day, ninth day, fortieth day, and the one-year anniversary after the death of an Orthodox Christian. There are also several days throughout the year that are set aside for general commemoration of the departed, sometimes including nonbelievers. These days usually fall on a Saturday, since it was on a Saturday that Christ lay in the Tomb.\n\nWhile the Orthodox consider the text of the Apocalypse (Book of Revelation) to be a part of Scripture, it is also regarded to be a mystery. Speculation on the contents of Revelation are minimal and it is never read as part of the regular order of services. Those theologians who have delved into its pages tend to be amillennialist in their eschatology, believing that the \"thousand years\" spoken of in biblical prophecy refers to the present time: from the Crucifixion of Christ until the Second Coming.\n\nWhile it is not usually taught in church it is often used as a reminder of God’s promise to those who love Him, and of the benefits of avoiding sinful passions. Iconographic depictions of the Final Judgment are often portrayed on the back (western) wall of the church building to remind the departing faithful to be vigilant in their struggle against sin. Likewise it is often painted on the walls of the Trapeza (refectory) in a monastery where monks may be inspired to sobriety and detachment from worldly things while they eat.\n\nThe Orthodox believe that Hell, though often described in metaphor as punishment inflicted by God, is in reality the soul's rejection of God's infinite love which is offered freely and abundantly to everyone.\n\nThe Orthodox believe that after the Final Judgment:\n\nThe official bible of the Orthodox Church contains the Septuagint text of the Old Testament, with the Book of Daniel given in the translation by Theodotion. The Patriarchal Text is used for the New Testament. Orthodox Christians hold that the Bible is a verbal icon of Christ, as proclaimed by the 7th ecumenical council. They refer to the Bible as Holy Scripture, meaning writings containing the foundational truths of the Christian faith as revealed by Christ and the Holy Spirit to its divinely inspired human authors. Holy Scripture forms the primary and authoritative written witness of Holy Tradition and is essential as the basis for all Orthodox teaching and belief. The Bible provides the only texts held to be suitable for reading in Orthodox worship services. Through the many scriptural quotations embedded in the worship service texts themselves, it is often said that the Orthodox pray the Bible as well as read it.\nThe New Testament consists of writings of the apostles and a very few other authors writing within apostolic times. The Old Testament consists of the writings of the Church as it existed in the time of the first covenant (before Christ), that is, within Judaism. The eastern regions of ancient Christianity adopted primarily the Greek-language Jewish translation of those writings known as the Septuagint, while the western regions (under the administration of Rome) depended at first on various Latin translations.\n\nSt. Jerome completed the well-known Vulgate Latin translation only in the early 5th century, around the time the accepted lists of scripture were resolved in the west. The east took up to a century longer to resolve the lists in use there, and ended by accepting a few additional writings from the Septuagint that did not appear in the lists of the west. The differences were small and were not considered to compromise the unity of the faith shared between east and west.\n\nThey did not play a role in the eventual schism in the 11th century that separated the See of Rome and the West from the See of Constantinople and the other apostolic Orthodox Churches, and remained as defined essentially without controversy in the East or West for at least one thousand years. It was only in the 16th century that Reformation Protestants challenged the lists, proclaiming a canon that rejected those Old Testament books that did not appear in the 3rd-century Hebrew Bible. In response, the Roman Catholic and Eastern Orthodox churches reaffirmed their accepted scriptural lists in more formal canons of their own.\n\nOnce established as Holy Scripture, there has never been any question that the Orthodox Church holds the full list of books to be venerable and beneficial for reading and study, even though it informally holds some books in higher esteem than others, the four gospels highest of all. Of the subgroups significant enough to be named, the \"Anagignoskomena\" (ἀναγιγνωσκόμενα, \"things that are read\") comprises ten of the Old Testament books rejected in the Protestant canon, but deemed by the Orthodox worthy to be read in worship services, even though they carry a lesser esteem than the 39 books of the Hebrew canon. The lowest tier contains the remaining books not accepted by either Protestants or Roman Catholics, among them, Psalm 151. Though it is a psalm, and is in the book of psalms, it is not classified as being within the Psalter (the first 150 psalms), and hence does not participate in the various liturgical and prayer uses of the Psalter.\n\nIn a very strict sense, it is not entirely orthodox to call the Holy Scriptures the \"Word of God\". That is a title the Orthodox Church reserves for Christ, as supported in the scriptures themselves, most explicitly in the first chapter of the gospel of John. God's Word is not hollow, like human words. \"God said, 'let there be light'; and there was light.\" This is the Word which spoke the universe into being, and resonates in creation without diminution throughout all history, a Word of divine power.\n\nAs much as the Orthodox Church reveres and depends on the scriptures, they cannot compare to the Word of God's manifest action. But the orthodox do believe that the Holy Scriptures testify to God's manifest actions in history, and that through its divine inspiration God's Word is manifested both in the scriptures themselves and in the cooperative human participation that composed them. It is in that sense that the orthodox refer to the scriptures as \"God's Word\".\n\nThe Orthodox Church does not subscribe to the Protestant doctrine of \"sola scriptura\". The Church has defined what Scripture is; it also interprets what its meaning is. Christ promised: \"When He, the Spirit of truth, has come, He will guide you into all truth\". The Holy Spirit, then, is the infallible guide for the Church to the interpretation of Scripture. The Church depends upon those saints who, by lives lived in imitation of Christ, achieving theosis, can serve as reliable witnesses to the Holy Spirit's guidance. Individual interpretation occurs within the Church and is informed by the Church. It is rational and reasoned, but is not arrived at only by means of deductive reasoning.\n\nAt the same time, the authority of its interpretation resides in Christ as the head of the church, in cooperation with the Holy Spirit, and is expressed through those whom He has brought into union with Himself. The authority is not ecclesiastical, and interpretation is not restricted to clergy, but is open to whomever the Holy Spirit chooses to reveal it. A true interpretation is for the benefit of the whole Church, not just the individual, and it is consistent with \"that faith which has been believed everywhere, always, and by all\" because God's revelation is consistent everywhere, always, and to all. Reading and understanding the Bible, interpreting within the Church, is encouraged and of great benefit, essential to the spiritual life of every Christian.\n\nScriptures are understood to contain historical fact, poetry, idiom, metaphor, simile, moral fable, parable, prophecy and wisdom literature, and each bears its own consideration in its interpretation. While divinely inspired, the text stills consists of words in human languages, arranged in humanly recognizable forms. The Orthodox Church does not oppose honest critical and historical study of the Bible. In biblical interpretation, it does not use speculations, suggestive theories, or incomplete indications, not going beyond what is fully known.\n\n\"That faith which has been believed everywhere, always, and by all\", the faith taught by Jesus to the apostles, given life by the Holy Spirit at Pentecost, and passed down to future generations without additions and without subtractions, is known as Holy Tradition. Holy Tradition does not change in the Orthodox Church because it encompasses those things that do not change: the nature of the one God in Trinity, Father, Son, and Holy Spirit, the history of God's interactions with his peoples, the Law as given to the Israelites, all Christ's teaching as given to the disciples and Jews and recorded in scripture, including the parables, the prophecies, the miracles, and His own example to humanity in His extreme humility. It encompasses also the worship of the church, which grew out of the worship of the synagogue and temple and was extended by Christ at the last supper, and the relationship between God and His people which that worship expresses, which is also evidenced between Christ and his disciples. It includes the authority that Christ bestowed on his disciples when he made them apostles, for the preserving and teaching of the faith, and for governing the organization and conduct of the church (in its administration by bishops).\n\nHoly Tradition is firm, even unyielding, but not rigid or legalistic; instead, it lives and breathes within the Church. For example, the New Testament was entirely written by the early church (mostly the apostles). The whole Bible was accepted as scripture by means of Holy Tradition practiced within the early church. The writing and acceptance took five centuries, by which time the Holy Scriptures themselves had become in their entirety a part of Holy Tradition. But Holy Tradition did not change, because \"that faith which has been believed everywhere, always, and by all\" remained consistent, without additions, and without subtractions. The historical development of the Divine Liturgy and other worship services and devotional practices of the church provide a similar example of extension and growth \"without change\".\n\nThe continuity and stability of Orthodox worship throughout the centuries is one means by which Holy Tradition expresses the unity of the whole church throughout time. Not only can the Orthodox of today visit a church in a place that speaks a language unknown to the visitors yet have the service remain familiar and understandable to them, but the same would hold true were any able to visit past eras. The church strives to preserve Holy Tradition \"unchanging\" that it may express the one unchanging faith for all time to come as well.\n\nBesides these, Holy Tradition includes the doctrinal definitions and statements of faith of the seven ecumenical councils, including the Nicene-Constantinopolitan Creed, and some later local councils, patristic writings, canon law, and icons. Not all portions of Holy Tradition are held to be equally strong. Some, the Holy Scriptures foremost, certain aspects of worship, especially in the Divine Liturgy, the doctrines of the ecumenical councils, the Nicene-Constantinopolitan Creed, possess a verified authority that endures forever, irrevocably. But with local councils and patristic writings, the Church applies a selective judgement. Some councils and writers have occasionally fallen into error, and some contradict each other.\n\nIn other cases, opinions differ, no consensus is forthcoming, and all are free to choose. With agreement among the Fathers, though, the authority of interpretation grows, and full patristic consensus is very strong. With canon law (which tends to be highly rigorous and very strict, especially with clergy) an unalterable validity also does not apply, since canons deal with living on earth, where conditions are always changing and each case is subject to almost infinite variation from the next. Even when and where they were once used with full strictness, their application was not absolute, and was carried out for individuals under the pastoral care of their bishop, who had the authority to decide when individual discipline had been satisfied. This too is a part of the Holy Tradition.\n\nBy tradition, the Orthodox Church, when faced with issues that are larger than a single bishop can resolve, holds a local council. The bishops and such others as may attend convene (as St. Paul called the Corinthians to do) to seek the \"mind of the church\". A council's declarations or edicts then reflect its consensus (if one can be found). An ecumencial council is only called for issues of such import or difficulty or pervasiveness that smaller councils are insufficient to address them. Ecumenical councils' declarations and canons carry binding weight by virtue of their representation across the whole church, by which the mind of the church can be readily seen. However, not all issues are so difficult as to require an ecumenical council to resolve. Some doctrines or decisions, not defined in a formal statement or proclaimed officially, nevertheless are held by the Church unshakably and unanimously without internal disturbance, and these, also reflecting the mind of the church, are just as firmly irrevocable as a formal declaration of an ecumenical council. Lack of formality does not imply lack of authority within Holy Tradition. An example of such unanimity can be found in the acceptance in the 5th century of the lists of books that comprise Holy Scripture, a true canon without official stamp.\n\nDuring the course of the early church, there were numerous followers who attached themselves to the Christ and His mission here on Earth, as well as followers who retained the distinct duty of being commissioned with preserving the quality of life and lessons revealed through the experience of Jesus living, dying, resurrecting and ascending among them. As a matter of practical distinction and logistics, people of varying gifts were accorded stations within the community structure – ranging from the host of agape meals (shared with brotherly and fatherly love), to prophecy and the reading of Scripture, to preaching and interpretations and giving aid to the sick and the poor. Sometime after Pentecost the Church grew to a point where it was no longer possible for the Apostles to minister alone. Overseers (bishops) and assistants (deacons and deaconesses) were appointed to further the mission of the Church.\n\nThe ecclesia recognized the gathering of these early church communities as being greatest in areas of the known world that were famous for their significance on the world stage – either as hotbeds of intellectual discourse, high volumes of trade, or proximity to the original sacred sites. These locations were targeted by the early apostles, who recognized the need for humanitarian efforts in these large urban centers and sought to bring as many people as possible into the ecclesia – such a life was seen as a form of deliverance from the decadent lifestyles promoted throughout the eastern and western Roman empire.\n\nAs the Church increased in size through the centuries, the logistic dynamics of operating such large entities shifted: patriarchs, metropolitans, archimandrites, abbots and abbesses, all rose up to cover certain points of administration.\n\nAs a result of heightened exposure and popularity of the philosophical schools (haereseis) of Greco-Roman society and education, Synods and Councils were forced to engage such schools that sought to co-opt the language and pretext of the Christian faith in order to gain power and popularity for their own political and cultural expansion. As a result, ecumenical councils were held to attempt to rebuild solidarity by using the strength of distant orthodox witnesses to dampen the intense local effects of particular philosophical schools within a given area.\n\nWhile originally intended to serve as an internal check and balance for the defense of the doctrine developed and spread by the apostles to the various sees against faulty local doctrine, at times the church found its own bishops and emperors falling prey to local conventions. At these crucial moments in the history of the church, it found itself able to rebuild on the basis of the faith as it was kept and maintained by monastic communities, who subsisted without reliance on the community of the state or popular culture and were generally unaffected by the materialism and rhetoric that often dominated and threatened the integrity and stability of the urban churches.\n\nIn this sense, the aim of the councils was not to expand or fuel a popular need for a clearer or relevant picture of the original apostolic teaching. Rather, the theologians spoke to address the issues of external schools of thought who wished to distort the simplicity and neutrality of the apostolic teaching for personal or political gain. The consistency of the Orthodox faith is entirely dependent on the Holy Tradition of the accepted corpus of belief – the decisions ratified by the fathers of the seven ecumenical councils, and this is only done at the beginning of a consecutive council so that the effects of the decisions of the prior council can be audited and verified as being both conceptually sound and pragmatically feasible and beneficial for the church as a whole.\n\nMany church traditions, including the schedules of services, feasts, and fasts, are structured by the church’s calendar, which provides a strictly observed intermingled set of cycles of varying lengths. The fixed annual cycle begins 1 September, and establishes the times for all annual observances that are fixed by date, such as Christmas. The annual Paschal cycle is established relative to the varying date of Pascha each year and affects the times for such observances as Pascha itself, Great Lent, Holy Week, and the feasts of Ascension and Pentecost.\n\nLesser cycles also run in tandem with the annual ones. A weekly cycle of days prescribes a specific focus for each day in addition to others that may be observed.\n\nThe services of the church are conducted each day according to the church calendar. Parts of each service remain fixed, while others change depending on the observances prescribed for the specific day in the various cycles, ever providing a flow of constancy within variation. Services are conducted in the church and involve both the clergy and faithful. Services cannot properly be conducted by a single person, but must have at least one other person present (i.e. a Priest cannot celebrate alone, but must have at least a Chanter present and participating).\n\nUsually, all of the services are conducted on a daily basis only in monasteries and cathedrals, while parish churches might only do the services on the weekend and major feast days. On certain Great Feasts (and, according to some traditions, every Sunday) a special All-Night Vigil (\"Agrypnia\") will be celebrated from late at night on the eve of the feast until early the next morning. Because of its festal nature it is usually followed by a breakfast feast shared together by the congregation.\n\nServices, especially the Divine Liturgy, can only be celebrated once a day on a single altar (some churches have multiple altars in order to accommodate large congregations). Each priest may only celebrate the Divine Liturgy once a day. From its Jewish roots, the liturgical day begins at sundown. The traditional daily cycle of services is as follows:\n\nThe Divine Liturgy is the celebration of the Eucharist. Although it is usually celebrated between the Sixth and Ninth Hours, it is not considered to be part of the daily cycle of services, as it occurs outside the normal time of the world. The Divine Liturgy is not celebrated on weekdays during the preparatory season of Great Lent and in some places during the lesser fasting seasons either. Reserve communion is prepared on Sundays and is distributed during the week at the Liturgy of the Presanctified Gifts.\n\nOther items brought to the altar during the Divine Liturgy include a gold or silver chalice with red wine, a small metallic urn of warm water, a metallic communion spoon, a little metallic spear, a sponge, a metal disk with cut pieces of bread upon it, and a star, which is a star-shaped piece of metal over which the priest places a cloth covering when transporting the holy gifts to and from the altar. Also found on the altar table is the antimins. The antimins is a silk cloth, signed by the appropriate diocesan bishop, upon which the sanctification of the holy gifts takes place during each Divine Liturgy. The antimins contain the relics of a saint. When a church is consecrated by a bishop, there is a formal service or prayers and sanctification in the name of the Saint that the church is named after. The bishop will also often present a small relic of a saint to place in or on the altar as part of the consecration of a new church.\n\nAn orthodox priest (or bishop) may celebrate only one Divine Liturgy per day. The Divine Liturgy may only be celebrated once a day on any particular antimins and altar. This means that most parishes or congregations, unless they have more than one officially signed antimins and multiple priests, can celebrate only one Eucharist per day, in order to express the catholicity of the church by avoiding \"private masses\".\n\nThe book containing liturgically read portions of the four gospels is permanently \"enthroned\" on the altar table. The Orthodox bishops, priests, deacons and readers sing/chant specific verses from this Gospel Book on each different day of the year.\n\nThis daily cycle services is conceived of as both the sanctification of time (\"chronos\", the specific times during which they are celebrated), and entry into eternity (\"kairos\"). They consist to a large degree of litanies asking for God's mercy on the living and the dead, readings from the Psalter with introductory prayers, troparia, and other prayers and hymns surrounding them. The Psalms are so arranged that when all the services are celebrated the entire Psalter is read through in their course once a week, and twice a week during Great Lent when the services are celebrated in an extended form.\n\nOrthodox services are sung nearly in their entirety. Services consist in part of a dialogue between the clergy and the people (often represented by the choir or the Psaltis Cantor). In each case the prayers are sung or chanted following a prescribed musical form. Almost nothing is read in a normal speaking voice, with the exception of the homily if one is given.\n\nBecause the human voice is seen as the most perfect instrument of praise, musical instruments (organs, guitars, etc.) are not generally used to accompany the choir.\n\nThe church has developed eight modes or tones (see Octoechos) within which a chant may be set, depending on the time of year, feast day, or other considerations of the Typikon. There are numerous versions and styles that are traditional and acceptable and these vary a great deal between cultures. It is common, especially in the United States, for a choir to learn many different styles and to mix them, singing one response in Greek, then English, then Russian, etc.\n\nIn the Russian tradition there have been some famous composers of \"unaccompanied\" church music, such as Tchaikovsky (Liturgy of St John Chrysostom, op. 41, 1878, and All-Night Vigil, op. 52, 1882) and Rachmaninoff (Liturgy of St John Chrysostom, op. 31, 1910, and All-Night Vigil, op. 37, 1915); and many church tones can likewise be heard influencing their music.\n\nAs part of the legacy handed down from its Judaic roots, incense is used during all services in the Orthodox Church as an offering of worship to God as it was done in the Jewish First and Second Temples in Jerusalem (Exodus chapter 30). Incense is also prophesied in the book of as a \"pure offering\" in the glorification of God by the Gentiles in \"every place\" where the name of God is regarded as \"great\". Traditionally, the base of the incense used is the resin of Boswellia sacra, also known as frankincense, but the resin of fir trees has been used as well. It is usually mixed with various floral essential oils giving it a sweet smell.\n\nIncense represents the sweetness of the prayers of the saints rising up to God (, , ). The incense is burned in an ornate golden censer that hangs at the end of three chains representing the Trinity. Two chains represent the human and Godly nature of the Son, one chain for the Father and one chain for the Holy Spirit. The lower cup represents the earth and the upper cup the heaven. In the Greek, Slavic, and Syrian traditions there are 12 bells hung along these chains representing the 12 apostles. There are also 72 links representing 72 evangelists.\n\nThe charcoal represents the sinners. Fire signifies the Holy Spirit and frankincense the good deeds. The incense also represents the grace of the Holy Trinity. The censer is used (swung back and forth) by the priest/deacon to venerate all four sides of the altar, the holy gifts, the clergy, the icons, the congregation, and the church structure itself. Incense is also used in the home where the individual will go around the house and \"cross\" all of the icons saying in Greek: Ἅγιος ὁ Θεός, Ἅγιος ἰσχυρός, Ἅγιος ἀθάνατος, ἐλέησον ἡμᾶς. or in English: Holy God, Holy Mighty, Holy Immortal, have mercy on us.\n\nThe number of fast days varies from year to year, but in general the Orthodox Christian can expect to spend a little over half the year fasting at some level of strictness. There are spiritual, symbolic, and even practical reasons for fasting. In the Fall from Paradise mankind became possessed by a carnal nature; that is to say, became inclined towards the passions. Through fasting, Orthodox Christians attempt to return to the relationship of love and obedience to God enjoyed by Adam and Eve in Paradise in their own lives, by refraining from carnal practices, by bridling the tongue (), confession of sins, prayer and almsgiving.\n\nFasting is seen as purification and the regaining of innocence. It is a practice of learning to temper the body's primary desire for food. By learning to temper this basic desire of the body, the practitioner can more readily temper other worldly desires, and thus, become better enabled to draw closer to God in the hope of becoming more Christ-like. Through obedience to the Church and its ascetic practices the Orthodox Christian seeks to rid himself or herself of the \"passions\" (The desires of our fallen carnal nature). All Orthodox Christians are provided with a prescribed set of guidelines. They do not view fasting as a hardship, but rather as a privilege and joy. The teaching of the Church provides both the time and the amount of fasting that is expected as a minimum for every member who chooses to participate. For greater ascesis, some may choose to go without food entirely for a short period of time. A complete three-day fast at the beginning and end of a fasting period is not unusual, and some fast for even longer periods, though this is usually practiced only in monasteries.\n\nIn general, fasting means abstaining from meat and meat products, dairy (eggs and cheese) and dairy products, fish, olive oil, and wine. Wine and oil—and, less frequently, fish—are allowed on certain feast days when they happen to fall on a day of fasting; but animal products and dairy are forbidden on fast days, with the exception of \"Cheese Fare\" week which precedes Great Lent, during which dairy products are allowed. Wine and oil are usually also allowed on Saturdays and Sundays during periods of fast. In some Orthodox traditions, caviar is permitted on Lazarus Saturday, the Saturday before Palm Sunday, although the day is otherwise a fast day. Married couples also abstain from sexual activity on fast days so that they may devote themselves fulsomely to prayer ().\n\nWhile it may seem that fasting in the manner set forth by the Church is a strict rule, there are circumstances where a person's spiritual guide may allow an Economy because of some physical necessity (e.g. those who are pregnant or infirm, the very young and the elderly, or those who have no control over their diet, such as prisoners or soldiers).\n\nThe time and type of fast is generally uniform for all Orthodox Christians; the times of fasting are part of the ecclesiastical calendar, and the method of fasting is set by the Holy Canons and Sacred Tradition. There are four major fasting periods during the year:\n\nIn addition to these fasting seasons, Orthodox Christians fast on every Wednesday (in commemoration of Christ's betrayal by Judas Iscariot), and Friday (in commemoration of Christ's Crucifixion) throughout the year. Monastics often fast on Mondays (in imitation of the Angels, who are commemorated on that day in the weekly cycle, since monastics are striving to lead an angelic life on earth, and angels neither eat nor drink).\n\nOrthodox Christians who are preparing to receive the Eucharist do not eat or drink at all from vespers (sunset) until after taking Holy Communion. A similar total fast is expected to be kept on the Eve of Nativity, the Eve of Theophany (Epiphany), Great Friday and Holy Saturday for those who can do so. There are other individual days observed as fasts (though not as days of total fasting) no matter what day of the week they fall on, such as the Beheading of St. John the Baptist on 29 August and the Exaltation of the Holy Cross on 14 September.\n\nStrict fasting is canonically forbidden on Saturdays and Sundays due to the festal character of the Sabbath and the Resurrection, respectively. On those days wine and oil are permitted even if abstention from them would be otherwise called for. Holy Saturday is the only Saturday of the year where a strict fast is kept every year, though it is also kept on the Eve of Theophany in years when that day falls on Saturday.\n\nThere are also four periods in the liturgical year during which no fasting is permitted, even on Wednesday and Friday. These fast-free periods are:\n\nWhen certain feast days fall on fast days, the fasting laws are lessened to a certain extent, to allow some consolation in the \"trapeza\" (refectory) for the longer services, and to provide an element of sober celebration to accompany the spiritual joy of the feast.\n\nIt is considered a greater sin to advertise one's fasting than not to participate in the fast. Fasting is a purely personal communication between the Orthodox Christian and God. If one has health concerns, or responsibilities that cannot be fulfilled because of fasting, then it is perfectly permissible not to fast. An individual's observance of the fasting laws is not to be judged by the community (), but is a private matter between him and his Spiritual Father or Confessor.\n\n\"Almsgiving\", more comprehensively described as \"acts of mercy\", refers to any giving of oneself in charity to someone who has a need, such as material resources, work, assistance, counsel, support, or kindness. Along with \"prayer\" and \"fasting\", it is considered a pillar of the personal spiritual practices of the Orthodox Christian tradition. Almsgiving is particularly important during periods of fasting, when the Orthodox believer is expected to share with those in need the monetary savings from his or her decreased consumption. As with fasting, mentioning to others one's own virtuous deeds tends to reflect a sinful pride, and may also be considered extremely rude.\n\nThe Eastern Orthodox Church places heavy emphasis and awards a high level of prestige to traditions of monasticism and asceticism with roots in Early Christianity in the Near East and Byzantine Anatolia. The most important centres of Christian Orthodox monasticism are Saint Catherine's Monastery in the Sinai Peninsula (Egypt) and Mount Athos in Northern Greece.\n\nAll Orthodox Christians are expected to participate in at least some ascetic works, in response to the commandment of Christ to \"come, take up the cross, and follow me.\" (Mark 10:21 and elsewhere) They are therefore all called to imitate, in one way or another, Christ himself who denied himself to the extent of literally taking up the cross on the way to his voluntary self-sacrifice. However, laypeople are not expected to live in extreme asceticism since this is close to impossible while undertaking the normal responsibilities of worldly life.\n\nThose who wish to do this therefore separate themselves from the world and live as monastics: monks and nuns. As ascetics \"par excellence\", using the allegorical weapons of prayer and fasting in spiritual warfare against their passions, monastics hold a very special and important place in the Church. This kind of life is often seen as incompatible with any kind of worldly activity including that which is normally regarded as virtuous. Social work, school teaching, and other such work is therefore usually left to laypeople. Ascetics of the Orthodox Church are recognized by their long hair, and in case of male monks, long beards.\n\nThere are three main types of monastics. Those who live in monasteries under a common rule are \"coenobitic\". Each monastery may formulate its own rule, and although there are no religious orders in Orthodoxy some respected monastic centers such as Mount Athos are highly influential. \"Eremitic\" monks, or hermits, are those who live solitary lives. It is the yearning of many who enter the monastic life to eventually become solitary hermits. This most austere life is only granted to the most advanced monastics and only when their superiors feel they are ready for it.\n\nHermits are usually associated with a larger monastery but live in seclusion some distance from the main compound. Their local monastery will see to their physical needs, supplying them with simple foods while disturbing them as little as possible. In between are those in \"semi-eremitic\" communities, or \"sketes\", where one or two monks share each of a group of nearby dwellings under their own rules and only gather together in the central chapel, or \"katholikon\", for liturgical observances.\n\nThe spiritual insight gained from their ascetic struggles make monastics preferred for missionary activity. Bishops are almost always chosen from among monks, and those who are not generally receive the monastic tonsure before their consecrations.\n\nMany (but not all) Orthodox seminaries are attached to monasteries, combining academic preparation for ordination with participation in the community's life of prayer. Monks who have been ordained to the priesthood are called \"hieromonk\" (priest-monk); monks who have been ordained to the diaconate are called \"hierodeacon\" (deacon-monk). Not all monks live in monasteries, some hieromonks serve as priests in parish churches thus practicing \"monasticism in the world\".\n\nCultural practices differ slightly, but in general \"Father\" is the correct form of address for monks who have been tonsured, while Novices are addressed as \"Brother\". Similarly, \"Mother\" is the correct form of address for nuns who have been tonsured, while Novices are addressed as \"Sister\". Nuns live identical ascetic lives to their male counterparts and are therefore also called \"monachoi\" (monastics) or the feminine plural form in Greek, \"monachai\", and their common living space is called a monastery.\n\nEverything in the Orthodox Church has a purpose and a meaning revealing God's revelation to man. At the front, or eastern end of the church, is a raised dais with an icon-covered screen or wall (iconostasis or templon) separating the nave from the sanctuary. In the center of this wall is the entrance to the altar known as the \"Royal Doors\" through which only the clergy may pass.\n\nThere is a right and left side door on the front of the iconostasis, one depicting the archangel, Michael and the other Gabriel. The priest and altar boys enter and exit through these doors during appropriate parts of the Divine Liturgy. Immediately to the right of the main gate you will always find an icon of Jesus Christ, on the left, an icon of the Theotokos (Mother of God). Other icons depicted on the iconostasis are Saint John the Forerunner and the Saint after which the church is named.\n\nIn front of the iconostasis is the bishop's chair, a place of honor where a visiting bishop or metropolitan will often sit when visiting the church. An Orthodox priest, when standing at the altar during the Divine Liturgy, faces toward the altar (typically facing east) and properly leads his congregation while together they perform the mystical sacrifice and pray to God.\n\nThe sanctuary contains the Holy Altar, representing the place where Orthodox Christians believe that Christ was born of the virgin Mary, crucified under Pontius Pilate, laid in the tomb, descended into hell, rose from the dead on the third day, ascended into heaven, and will return again at his second coming. A free-standing cross, bearing the body of Christ, may stand behind the altar. On the altar are a cloth covering, a large book containing the gospel readings performed during services, an ark containing presanctified divine gifts (bread and wine) distributed by the deacon or priest to those who cannot come to the church to receive them, and several white beeswax candles.\n\nThe term 'icon' comes from the Greek word \"eikon\", which simply means image. The Orthodox believe that the first icons of Christ and the Virgin Mary were painted by Luke the Evangelist. Icons are filled with symbolism designed to convey information about the person or event depicted. For this reason, icons tend to be formulaic, following a prescribed methodology for how a particular person should be depicted, including hair style, body position, clothing, and background details.\n\nIcon painting, in general, is not an opportunity for artistic expression, though each iconographer brings a vision to the piece. It is far more common for an icon to be copied from an older model, though with the recognition of a new saint in the church, a new icon must be created and approved. The personal and creative traditions of Catholic religious art were largely lacking in Orthodox iconography before the 17th century, when Russian iconography began to be strongly influenced by religious paintings and engravings from both Protestant and Roman Catholic Europe. Greek iconography also began to take on a strong western influence for a period and the difference between some Orthodox icons and western religious art began to vanish. More recently there has been a trend of returning to the more traditional and symbolic representations.\n\nThe style of the icons seems to have been borrowed heavily from the paganism of the Greek culture. Henry Chadwick writes, \"In this instinct there was a measure of truth. The representations of Christ as the Almighty Lord on his judgment throne owed something to pictures of Zeus. Portraits of the Mother of God were not wholly independent of a pagan past of venerated mother-goddesses. In the popular mind the saints had come to fill a role that had been played by heroes and deities.\"\n\nFree-standing statues (three-dimensional depictions) are almost non-existent within the Orthodox Church. This is partly due to the rejection of the previous pagan Greek age (Greek gods) of idol worship and partly because icons are meant to show the spiritual nature of man, not the sensual earthly body. Bas reliefs, however, became common during the Byzantine period and led to a tradition of covering a painted icon in a silver or gold 'riza' in order to preserve the icon. Such bas relief coverings usually leave the faces and hands of the saints exposed for veneration.\n\nIcons are not considered by the Orthodox to be idols or objects of worship. The parameters of their usage were clearly spelled out by the 7th ecumenical council. Justification for their usage utilises the following logic: before God took human form in Christ, no material depiction was possible and therefore blasphemous even to contemplate. Once God became incarnate, depiction was possible.\n\nAs Christ is believed to be God, it is justified to hold in one's mind the image of God-incarnate. Likewise, when one venerates an icon, it is not the wood or paint that are venerated but rather the individual shown, just as it is not the paper one loves when one might kiss the photograph of a loved one. As Saint Basil famously proclaimed, honour or veneration of the icon always passes to its archetype. Following this reasoning, the veneration of the glorified human saint made in God's image, is always a veneration of the divine image, and hence God as foundational archetype.\n\nIcons can be found adorning the walls of churches and often cover the inside structure completely. Most Orthodox homes have an area set aside for family prayer, usually an eastern facing wall, where are hung many icons. Icons have been part of Orthodox Christianity since the beginning of the church.\n\nIcons are often illuminated by a candle or oil lamp. (Beeswax for candles and olive oil for lamps are preferred because they are natural and burn cleanly.) Besides the practical purpose of making icons visible in an otherwise dark church, both candles and oil lamps symbolise the Light of the World, who is Christ.\n\nTales of miraculous icons are not uncommon, though it has always been considered that the message of such an event was for the immediate faithful involved and therefore does not usually attract crowds. Some miraculous icons whose reputations span long periods of time nevertheless become objects of pilgrimage along with the places where they are kept. As several Orthodox theologians and saints have explored in the past, the icon's miraculous nature is found not in the material, but in the glory of the saint who is depicted. The icon is a window, in the words of Paul Florensky, that actually participates in the glory of what it represents.\n\nAn \"iconostasis\", also called the \"templon\", is a wall of icons and religious paintings, separating the nave from the sanctuary in a church. \"Iconostasis\" also refers to a portable icon stand that can be placed anywhere within a church. The modern iconostasis evolved from the Byzantine templon in the 11th century. The evolution of the iconostasis probably owes a great deal to 14th-century Hesychast mysticism and the wood-carving genius of the Russian Orthodox Church.\n\nThe first ceiling-high, five-leveled Russian iconostasis was designed by Andrey Rublyov in the cathedral of the Dormition in Vladimir in 1408. The separation between sanctuary and nave accomplished by the iconostasis is not mandatory, though it is common practice. Depending on circumstance, the role of the iconostasis can be played by masonry, carved panels, screens, curtains, railings, a cord or rope, plain icons on stands, steps, or nothing at all.\n\nDepictions of the cross within the Orthodox Church are numerous and often highly ornamented, but its use does not extend to all Orthodox traditions. Some carry special significance. The Tri-Bar Cross, popular in Russia, Ukraine, and Belorussia, but common throughout the Orthodox world, seen to the right, has three bars. Its origins are in the early Byzantine Church of the 4th century AD.\n\nThe small top crossbar represents the sign that Pontius Pilate nailed above Christ's head. It often is inscribed with an acronym, \"INRI\", Latin, meaning \"Jesus of Nazareth, King of the Jews\" or \"INBI\", Greek, \"Jesus of Nazareth, King of the Jews\"; however, it is often replaced or amplified by the phrase \"The King of Glory\" in order to answer Pilate's statement with Christ's affirmation, \"My Kingdom is not of this world\".\n\nThere is also a bottom slanting bar which has several explanations. Claims of evidence indicate that there was a small wooden platform for the crucified to stand on in order to support his weight; in Jesus' case his feet were nailed side by side to this platform with one nail each in order to prolong the torture of the cross.\n\nImplied evidence for this comes mainly from two sources, namely, the Bible (in order to cause the victim to die faster, his legs were broken so they could not support his weight and he would suffocate) and iconography (all early depictions of the crucifixion show this arrangement, not the later with feet on top with single nail). It has also been pointed out by some experts that the nailed hands of a body crucified in the manner often shown in modern secular art would not support the weight of the body and would tear through. A platform for the feet would relieve this problem.\n\nThat the bottom bar is slanted has two explanations, to represent the very real agony which Christ experienced on the cross (a refutation of Docetism) and to signify that the thief on Christ's right chose the right path while the thief on the left did not.\n\nOther crosses associated with the Orthodox Church are the more traditional single-bar crosses, budded designs, the Greek cross, the Latin cross, the Jerusalem cross (cross pattée), Celtic crosses, and others. A common symbolism of the slanted foot stool is The foot-rest points up, toward Heaven, on Christ’s right hand-side, and downward, to Hades, on Christ’s left. \"Between two thieves Thy Cross did prove to be a balance of\nrighteousness: wherefore one of them was dragged down to Hades by the\nweight of his blasphemy \"[the balance points downward],\" whereas the other was lightened of his transgressions unto the comprehension of theology \"[the balance points upward].\" O Christ God, glory to Thee.\" Another Orthodox cross which is worn in gold is an outer budded cross with an inner Three Bar Cross. The inscription Jesus Christ in Greek: IC (Iesous) on the left side bar and XC (Xhristos) on the right side bar, with a sun on the top of the cross. There is also typically an inscription on the back in Church Slavonic: \"спаси и сохрани\", \"\"Spasi i Sokhrani\"\", \"\"Save and Protect\"\". This cross is known as the Saint Olga Cross.\n\nThe church building has many symbolic meanings; perhaps the oldest and most prominent is the concept that the Church is the Ark (as in Noah's) in which the world is saved from the flood of temptations; therefore, most Orthodox Churches are rectangular in design. Another popular configuration, especially for churches with large choirs is cruciform or cross-shaped or what is called the \"Greek-cross.\"\n\nArchitectural patterns vary in shape and complexity, with chapels sometimes added around the main church, or triple altars; but in general, the symbolic layout of the church remains the same. Each church is created with specified qualifications based on what the apostles said in the Bible. These qualifications include how big the temple should be.\n\nThe Church building is divided into three main parts: the narthex (vestibule), the nave and the sanctuary (also called the \"altar\" or \"holy place\"). The narthex is where catechumens and non-Orthodox visitors were traditionally asked to stand during services. It is separated from the nave by \"The Royal Gate\". On each side of this gate are candle stands (menalia) representing the pillars of fire that went before the Hebrew people escaping from Egypt.\n\nThe nave is where most of the congregation stand during services. Traditionally, men stand on the right and women on the left. This is for a number of reasons: (1) Considering the family unit of past centuries the husband was dominant; thus, standing the same distance from the altar, equality is emphasised. (2) The idea of separating the sexes was inherited from the Jewish tradition of doing so within synagogues (3) Separation of sexes also followed the practice of choirs in which different levels of voice are placed in groups to facilitate harmony.\n\nIn general, men and women dress respectfully, typically wearing their \"Sunday best\" to enter the church. Often, women cover their heads as prescribed by Paul (1 Cor. 11:13). Children are considered full members of the Church and stand attentively and quietly during services. There is often a choir area at the side or in a loft in back. In addition to the Choir, a Chanter is always present at the front of the church to chant responses and hymns that are part of the Divine Liturgy offered by the Priest. There is usually a dome in the ceiling with an icon of Christ depicted as Ruler of the Universe (Pantocrator).\n\nThe Archdiocesan Cathedral of the Holy Trinity on New York City's Upper East Side is the largest Orthodox Christian church in the Western Hemisphere.\n\nApart from the icons, the Orthodox churches and monasteries are often decorated with frescos and mosaics.\n\nThe Orthodox Church also has many associated traditions (sometimes referred to simply as customs), compatible with its life and function, but not necessarily tied so closely to the faith itself. These are not generally regarded as a part of Holy Tradition, though no strict dividing line is drawn. As long as compatibility is maintained, general practice often tends to the permissive rather than the restrictive, with the local priest or bishop resolving questions.\n\nMany of these customs are local or cultural, and some are not even especially religious, but form a part of the church's relationship with the people in the time and place where it exists. Where outside customs affect church practices such as worship, a closer watch is kept for guarding the integrity of worship, but suitable local differences are welcomed and celebrated joyfully. The local church customs, especially liturgical ones, are referred to as differences in typica (Style).\n\nLocality is also expressed in regional terms of churchly jurisdiction, which is often also drawn along national lines. Many Orthodox churches adopt a national title (e.g. Albanian Orthodox, Bulgarian Orthodox, Antiochian Orthodox, Georgian Orthodox, Greek Orthodox, Montenegrin Orthodox, Romanian Orthodox, Russian Orthodox, Serbian Orthodox, Ukrainian Orthodox, etc.) and this title can identify which language is used in services, which bishops preside, and which of the typica is followed by specific congregations. In the Middle East, Orthodox Christians are usually referred to as \"Rum\" (\"Roman\") Orthodox, because of their historical connection with the Eastern Roman (Byzantine) Empire.\n\nDifferences in \"praxis\" (\"practice\") tend to be slight, involving things such as the order in which a particular set of hymns are sung or what time a particular service is celebrated. But observances of the saints' days of local saints are more often celebrated in special services within a locality, as are certain national holidays, like Greek Independence Day. In North America, observances of Thanksgiving Day are increasing.\n\nMembers of the Church are fully united in faith and the Sacred Mysteries with all Orthodox congregations, regardless of nationality or location. In general, Orthodox Christians could travel the globe and feel familiar with the services even if they did not know the language being used.\n\nIn the Levant, Christian Orthodox services and identity often combine both the Byzantine Greek and indigenous (Arabic and Aramaic) traditions. Other Orthodox communities can identify with two Eastern Orthodox churches simultaneously, for example Caucasus Greeks and Pontic Greeks in Russia often identify with both the Greek Orthodox Church and Russian Orthodox Church, as a result of centuries of assimilation and intermarriage with ethnic Russians and other Christian Orthodox communities in mainly southern Russia.\n\nAccording to Orthodox theology, the purpose of the Christian life is to attain \"theosis\", the mystical union of mankind with God. This union is understood as both collective and individual. St. Athanasius of Alexandria wrote concerning the Incarnation that, \"He (Jesus) was made man that we might be made god (θεοποιηθῶμεν).\" See , , . The entire life of the church is oriented towards making this possible and facilitating it.\n\nIn the Orthodox Church the terms \"mystery\" or \"the mysteries\" refer to the process of \"theosis\". While it is understood that God theoretically can do anything instantly and invisibly, it is also understood that he generally chooses to use material substance as a medium in order to reach people. The limitations are those of mankind, not God. Matter is not considered to be evil by the Orthodox. Water, oil, bread, wine, etc., all are means by which God reaches out to allow people to draw closer to him. How this process works is a \"mystery\" and cannot be defined in human terms. These mysteries are surrounded by prayer and symbolism so that their true meaning will not be forgotten.\n\nThose things which in the West are often termed sacraments or sacramentals are known among the Orthodox as the \"sacred mysteries\". While the Roman Catholic Church numbers seven sacraments, and many Protestant groups list two (Baptism and the Eucharist) or even none, the Orthodox do not limit the number. However, for the sake of convenience, catechisms will often speak of the seven Great Mysteries. Among these are Holy Communion (the most direct connection), Baptism, Chrismation, Confession, Unction, Matrimony, and Ordination. But the term also properly applies to other sacred actions such as monastic tonsure or the blessing of holy water, and involves fasting, almsgiving, or an act as simple as lighting a candle, burning incense, praying or asking God's blessing on food.\n\nBaptism is the mystery which transforms the old and sinful person into a new and pure one; the old life, the sins, any mistakes made are gone and a clean slate is given. Through Baptism a person is united to the Body of Christ by becoming a member of the Orthodox Church. During the service, water is blessed. The catechumen is fully immersed in the water three times in the name of the Holy Trinity. This is considered to be a death of the \"old man\" by participation in the crucifixion and burial of Christ, and a rebirth into new life in Christ by participation in his resurrection. Properly a new name is given, which becomes the person's name.\n\nChildren of Orthodox families are normally baptized shortly after birth. Converts to Orthodoxy are usually formally baptized into the Orthodox Church, though exceptions are sometimes made. Those who have left Orthodoxy and adopted a new religion, if they return to their Orthodox roots, are usually received back into the church through the mystery of Chrismation.\n\nProperly, the mystery of Baptism is administered by bishops and priests; however, in emergencies any Orthodox Christian can baptize. In such cases, should the person survive the emergency, it is likely that the person will be properly baptized by a priest at some later date. This is not considered to be a second baptism, nor is it imagined that the person is not already Orthodox, but rather it is a fulfillment of the proper form.\n\nThe service of Baptism used in Orthodox churches has remained largely unchanged for over 1500 years. This fact is witnessed to by St. Cyril of Jerusalem (d. 386), who, in his \"Discourse on the Sacrament of Baptism\", describes the service in much the same way as is currently in use.\n\nChrismation (sometimes called confirmation) is the mystery by which a baptized person is granted the gift of the Holy Spirit through anointing with Holy Chrism. It is normally given immediately after baptism as part of the same service, but is also used to receive lapsed members of the Orthodox Church. As baptism is a person's participation in the death and resurrection of Christ, so Chrismation is a person's participation in the coming of the Holy Spirit at Pentecost.\n\nA baptized and chrismated Orthodox Christian is a full member of the Church and may receive the Eucharist regardless of age.\n\nThe creation of chrism may be accomplished by any bishop at any time, but usually is done only once a year, often when a synod of bishops convenes for its annual meeting. (Some autocephalous churches get their chrism from others.) Anointing with it substitutes for the laying-on of hands described in the New Testament, even when an instrument such as a brush is used.\n\nThe Eucharist is at the center of Orthodox Christianity. In practice, it is the partaking of the Body and Blood of Jesus Christ in the midst of the Divine Liturgy with the rest of the church. The bread and wine are believed to become the genuine Body and Blood of the Christ Jesus through the operation of the Holy Spirit. The Orthodox Church has never described exactly how this occurs, or gone into the detail that the Roman Catholic Church has in the West.\n\nCommunion is given only to baptized and chrismated Orthodox Christians who have prepared by fasting, prayer and confession. The priest will administer the gifts with a spoon, called a \"cochlear\", directly into the recipient's mouth from the chalice. From baptism young infants and children are carried to the chalice to receive holy communion.\n\nBecause of the Orthodox understanding of mankind's fallen nature in general those who wish to commune prepare themselves in a way that reflects mankind in paradise. First, they prepare by having their confession heard and the prayer of repentance read over them by a priest. They will increase their prayer rule, adding the prescribed prayers in preparation for communing. Finally, they will fast completely from food and drink from the evening of the previous day (usually sunset on Saturday if communing on Sunday).\n\nOrthodox Christians who have committed sins but repent of them, and who wish to reconcile themselves to God and renew the purity of their original baptisms, confess their sins to God before a spiritual guide who offers advice and direction to assist the individual in overcoming their sin. Parish priests commonly function as spiritual guides, but such guides can be any person, male or female, who has been given a blessing to hear confessions. Spiritual guides are chosen very carefully as this is a mandate that once chosen must be obeyed. Having confessed, the penitent then has his or her parish priest read the prayer of repentance over them.\n\nSin is not viewed by the Orthodox as a stain on the soul that needs to be wiped out, or a legal transgression that must be set right by a punitive sentence, but rather as a mistake made by the individual with the opportunity for spiritual growth and development. An act of Penance (\"epitemia\"), if the spiritual guide requires it, is never formulaic, but rather is directed toward the individual and their particular problem, as a means of establishing a deeper understanding of the mistake made, and how to effect its cure. Because full participatory membership is granted to infants, it is not unusual for even small children to confess; though the scope of their culpability is far less than an older child, still their opportunity for spiritual growth remains the same.\n\nFrom the Orthodox perspective, marriage is one of the holy mysteries or sacraments. As well as in many other Christian traditions, for example in Roman Catholicism, it serves to unite a woman and a man in eternal union and love before God, with the purpose of following Christ and His Gospel and raising up a faithful, holy family through their holy union. It is referred to extensively in both the Old and New Testaments. Christ declared the essential indissolubility of marriage in the Gospel. Both virginity and marriage have the same reference to the future Kingdom.\n\nJesus said that \"when they rise from the dead, they neither marry nor are given in marriage, but are like angels in heaven\" (Mk 12:25). For the Orthodox Christian this passage should not be understood to imply that Christian marriage will not remain a reality in the Kingdom, but points to the fact that relations will not be \"fleshy\", but \"spiritual\". Love between wife and husband, as an icon of relationship between Christ and Church, is eternal.\nThe Church does recognize that there are rare occasions when it is better that couples do separate, but there is no official recognition of civil divorces. For the Orthodox, to say that marriage is indissoluble means that it should not be broken, the violation of such a union, perceived as holy, being an offense resulting from either adultery or the prolonged absence of one of the partners. Thus, permitting remarriage is an act of compassion of the Church towards sinful man.\n\nIn the U.S., according to 2001 statistics, 14% of Orthodox marriages ended in an ecclesiastical divorce. This figure, since it took no account of how many of the couples who entered such marriages took out a civil divorce, is not comparable with the figure of 43% given at that time for the proportion of all marriages that ended in a civil divorce. But it has been argued as indicating a probable total of only 15% of marriages celebrated in an Orthodox church led to any form of divorce.\n\nEcclesiastically divorced Orthodox (not civilly divorced only) are usually allowed to remarry in the Orthodox Church, though there is usually imposed on them a fairly severe penance by their bishop and the services for a second marriage in this case are more penitential than joyful. Widows are permitted to remarry without repercussion and their second marriage is considered just as valid as the first. One exception to this rule is the clergy and their wives. Should a married priest die, it is normal that his wife will retire to a monastery once their children are out of the house. Widowed priests are not allowed to remarry (no priest may be married after his ordination) and also frequently end up in monasteries.\n\nThe service of Marriage in the Orthodox Church has two distinct parts: the Betrothal and the Crowning. The Betrothal includes:\n\n\nThe Crowning includes the readings from the epistle and gospel, the Blessing of the Common Cup, and the Dance of Isaiah (the bride and groom are led around the table 3 times), and then the Removal of the Crowns. There is no exchange of vows. There is a set expectation of the obligations incumbent on a married couple, and whatever promises they may have privately to each other are their responsibility to keep. The ceremony ends with the reading of Benedictions to and the Greeting of the Couple.\n\nAt the Sacrament of Marriage the crowns are placed on the bride and groom’s heads as the following prayer is recited three times, \"The servant of God, (groom’s name), is crowned to the handmaid of God, (bride’s name), in the Name of the Father, and of the Son, and of the Holy Spirit\" three times. It is then repeated three times as the bride is crowned to the groom. We witness the groom and bride being crowned (visibly proclaimed) as the king and queen, respectively, of a new family, entrusted by God with the authority to rule their family in faith and love and harmony with Christ.\n\nThey both share in this responsibility and privilege as a newly married couple. This is not simply being declared by the priest or even the Church, but by God Himself, as the following hymn is chanted three times: \"O Lord, our God, crown them with glory and honor.\" The crowns are then switched back and forth between the groom and bride’s head, signifying that they completely share their lives together.\n\nThe crowns also serve as a reminder of the crowns that await them in heaven, if they live their lives in faithfulness to God and to each other. Fr. John Meyendorff in his book, Marriage: An Orthodox Perspective, writes: \"According to St. John Chrysostom, the crowns symbolized victory over the ‘passions’.\" In the service of a second marriage the crowns are not to be used, but if it is a second marriage for only one of the two who are marrying and a first marriage for the other, the usual rite is followed.\n\nMany couples keep the wedding crowns in a case and display them near their icon corner or in the couple’s bedroom. They serve as a reminder that God has united them to each other and to himself and that he has bestowed his grace upon them to live in unity, faith and love.\n\nThe church understands marriage to be the union of one man and one woman, and certain Orthodox leaders have spoken out strongly in opposition to the civil institution of same-sex marriage.\n\nSince its founding, the Church spread to different places and its leaders in each region came to be known as \"episkopoi\" (overseers, plural of \"episkopos\", overseer—Gr. ἐπίσκοπος), which became \"bishop\" in English. The other ordained roles are \"presbyter\" (Gr. , elder), which became \"prester\" and then \"priest\" in English, and \"diakonos\" (Gr. , servant), which became \"deacon\" in English (see also subdeacon). There are numerous administrative positions among the clergy that carry additional titles.\n\nIn the Greek tradition, bishops who occupy an ancient see are called metropolitans, while the lead bishop in Greece is the archbishop. (In the Russian tradition, however, the usage of the terms \"metropolitan\" and \"archbishop\" is reversed.) Priests can be archpriests, archimandrites or protopresbyters. Deacons can also be archdeacons or protodeacons. The position of deacon is often occupied for life. The deacon also acts as an assistant to a bishop.\n\nWith the exception of bishops, who remain celibate, the Orthodox Church has always allowed priests and deacons to be married, provided the marriage takes place before ordination. In general it is considered preferable for parish priests to be married as they often act as counsel to married couples and thus can draw on their own experience. Unmarried priests usually are monks and live in monasteries, though there are occasions when, because of a lack of married priests, a monk-priest is temporarily assigned to a parish.\n\nWidowed priests and deacons may not remarry and it is common for such members of the clergy to retire to a monastery (see clerical celibacy). This is also true of widowed wives of clergy, who do not remarry and become nuns when their children are grown. Only men are allowed to take holy orders, although deaconesses had both liturgical and pastoral functions within the church. However, it has fallen out of practice (the last deaconess was ordained in the 19th century).\n\nAnointing with oil, often called \"unction\", is one of the mysteries administered by the Orthodox Church and it is not reserved only for the dying or terminally ill, but for all in need of spiritual or bodily healing. In Greece, during the Ottoman occupation, it became the custom to administer this mystery annually on Great Wednesday to all believers; in recent decades, this custom has spread to many other locations. It is often distributed on major feast days, or any time the clergy feel it necessary for the spiritual welfare of its congregation.\n\nAccording to Orthodox teaching unction is based on the Epistle of James:\n\nIs anyone among you sick? Let him call for the elders of the church, and let them pray over him, anointing him with oil in the name of the Lord. And the prayer of faith will save the sick, and the Lord will raise him up. And if he has committed sins, he will be forgiven.—\n\nFollowing Jesus Christ's Great Commission to the apostles, Christianity spread rapidly throughout the Roman Empire. Paul and the Apostles traveled extensively throughout the Empire, including Asia Minor, establishing Churches in major communities, with the first Churches appearing in Jerusalem and the Holy Land, then in Antioch, Ethiopia, Egypt, Rome, Alexandria, Athens, Thessalonica, Illyricum, and Byzantium, which centuries later would become prominent as the New Rome. Christianity in the Roman Empire met with considerable resistance, as its adherents would refuse to comply with the Roman state (even at the threat of death) in offering sacrifice to the pagan gods. Despite persecutions, the Church spread. The persecution dissipated upon the conversion of Emperor Constantine I in 324 AD.\n\nBy the 4th century Christianity had spread to numerous regions. A number of influential schools of thought had arisen, particularly the Alexandrian and Antiochian philosophical approaches. Other groups, such as the Arians, had also managed to gain influence. However, their positions caused theological conflicts within the Church, thus prompting the Emperor Constantine to call for a great ecumenical synod in order to define the Church's position against the growing, often widely diverging, philosophical and theological interpretations of Christianity. He made it possible for this council to meet not only by providing a location, but by offering to pay for the transportation of all the existing bishops of the Church. Most modern Christian Churches regard this synod, commonly called the First Council of Nicaea or more generally the First Ecumenical Council, as of major importance.\n\nSeveral doctrinal disputes from the 4th century onwards led to the calling of Ecumenical councils. In the Orthodox Church, an Ecumenical council is the supreme authority that can be invoked to resolve contested issues of the faith. As such, these councils have been held to resolve the most important theological matters that came to be disputed within the Church. Many lesser disagreements were resolved through local councils in the areas where they arose, before they grew significant enough to require an Ecumenical council.\n\nThere are seven councils authoritatively recognized as Ecumenical:\nThere are also two other councils which are considered Ecumenical by some Orthodox. All Orthodox agree that the decisions of these further councils are valid; the disagreement is only whether they carry sufficient importance to be considered truly \"Ecumenical:\"\n\nIn addition to these councils there have been a number of other significant councils meant to further define the Orthodox position. They are the Synods of Constantinople, in 1484, 1583, 1755, 1819, and 1872, the Synod of Jassy (Iași) in 1642, and the Pan-Orthodox Synod of Jerusalem in 1672. Another council convened in June 2016 to discuss many modern phenomena including Modernism, other Christian confessions, Orthodoxy's relation with other religions and fasting disciplines.\n\nEastern Christian culture reached its golden age during the high point of the Byzantine Empire and continued to flourish in Ukraine and Russia, after the fall of Constantinople. Numerous autocephalous churches were established in Europe: Russia, Greece, Armenia, Georgia and Ukraine, as well as Asia.\n\nIn the 530s the Church of the Holy Wisdom (Hagia Sophia) was built in Constantinople under emperor Justinian I.\n\nThe Church in Egypt (Patriarchate of Alexandria) split into two groups following the Council of Chalcedon (451), over a dispute about the relation between the divine and human natures of Jesus. Eventually this led to each group anathematizing the other. Those that remained in communion with the other patriarchs (by accepting the Council of Chalcedon) are known today as the Greek Orthodox Church of Alexandria, where the adjective \"Greek\" refers to their ties to the Greek-speaking culture of the Byzantine Empire. However, those who disagreed with the findings of the Council of Chalcedon were the majority in Egypt, and today they are known as the Coptic Orthodox Church of Alexandria, having maintained a separate patriarchate. The Coptic Orthodox Church is currently the largest Christian church in Egypt and in the whole Middle East. There was also a similar, albeit smaller scale, split in Syria (Patriarchate of Antioch), which resulted in the separation of the Syriac Orthodox Church from the Byzantine Patriarchate of Antioch.\n\nThose who disagreed with the Council of Chalcedon are sometimes called \"Oriental Orthodox\" to distinguish them from the \"Eastern Orthodox\", who accepted the Council of Chalcedon. Oriental Orthodox are also sometimes referred to as \"non-Chalcedonians\", or \"anti-Chalcedonians\". The Oriental Orthodox Church denies that it is monophysite and prefers the term \"miaphysite\", to denote the \"united\" nature of Jesus (two natures united into one) consistent with St. Cyril's theology: \"The term union...signifies the concurrence in one reality of those things which are understood to be united\" and \"the Word who is ineffably united with it in a manner beyond all description\" (St. Cyril of Alexandria - \"On the Unity of Christ\"). Both the Eastern Orthodox and Oriental Orthodox churches formally believe themselves to be the continuation of the true church, although over the last several decades there has been considerable reconciliation and the prospect of reunification has been discussed.\n\nAs well, there are the \"Nestorian\" churches, which are Eastern Christian churches that keep the faith of only the first two ecumenical councils, i.e., the First Council of Nicaea and the First Council of Constantinople. \"Nestorian\" is an outsider's term for a tradition that predated the influence of Nestorius, the origin of which might lay in certain sections of the School of Antioch or via Nestorius' teacher(s) Theodore of Mopsuestia and/or Diodore of Tarsus. The \"Nestorian Church\" is commonly referred to as \"the Assyrian Church\" or fully as the Assyrian Church of the East.\n\nIn the 9th and 10th centuries, Christianity made great inroads into pagan Europe, including Kievan Rus'. This work was made possible by the work of the Byzantine-era saints Cyril and Methodius. When king Rastislav of Moravia asked Byzantium for teachers who could minister to the Moravians in their own language, Byzantine emperor Michael III chose these two brothers. Cyril and Methodius translated the Bible and many of the prayer books. As the translations prepared by them were copied by speakers of other dialects, the hybrid literary language Old Church Slavonic was created. Originally sent to convert the Slavs of Great Moravia, Cyril and Methodius were forced to compete with Frankish missionaries from the Roman diocese. Their disciples were driven out of Great Moravia in AD 886.\n\nSome of the disciples, namely Saint Clement of Ohrid and Saint Naum, were of great importance to the Orthodox Faith in Bulgaria. In a short time, the disciples of Cyril and Methodius managed to prepare and instruct the future Bulgarian clergy into the biblical texts and in AD 893, proclaimed the first organized Church on the Balkan Peninsula. The success of the conversion of the Bulgarians facilitated the conversion of East Slavic peoples, most notably the Rus', predecessors of Belarusians, Russians, and Ukrainians.\n\nThe work of the Thessaloniki brothers Cyril and Methodius and their disciples had a major impact to Serbs as well. However, they accepted Christianity collectively by families and by tribes (in the process between the 7th and the 9th century). In commemoration of their baptisms, each Serbian family or tribe began to celebrate an exclusively Serbian custom called Slava in a special way to honor the Saint on whose day they received the sacrament of Holy Baptism. It is the most solemn day of the year for all Serbs of the Orthodox faith and has played a role of vital importance in the history of the Serbian people. Slava is actually the celebration of the spiritual birthday of the Serbian people which the Church blessed and proclaimed it a Church institution.\n\nThe missionaries to the East and South Slavs had great success in part because they used the people's native language rather than Greek, the predominant language of the Byzantine Empire or Latin as the Roman priests did. Today the Russian Orthodox Church is the largest of the Orthodox Churches followed by the Romanian Orthodox Church.\n\nIn the 11th century what was recognised as the Great Schism took place between Rome and Constantinople, which led to separation between the Church of the West, the Roman Catholic Church, and the Eastern Byzantine Churches, now the Orthodox. There were doctrinal issues like the filioque clause and the authority of the Roman Pope involved in the split, but these were greatly exacerbated by political factors of both Church and state, and by cultural and linguistic differences between Latins and Greeks. Before 1054 the Eastern and Western halves of the Church had frequently been in conflict, particularly during the periods of Eastern iconoclasm and the Photian schism.\n\nThe final breach is often considered to have arisen after the capture and sacking of Constantinople by the Fourth Crusade in 1204; the final break with Rome occurred circa 1450. The sacking of Church of Holy Wisdom and establishment of the Latin Empire as a seeming attempt to supplant the Orthodox Byzantine Empire in 1204 is viewed with some rancour to the present day. In 2004, Pope John Paul II extended a formal apology for the sacking of Constantinople in 1204, which was importantly also strongly condemned by the Pope at the time (Innocent III, see reference at end of paragraph); the apology was formally accepted by Patriarch Bartholomew of Constantinople. Many things that were stolen during this time —holy relics, riches, and many other items—were not returned and are still held in various European cities, particularly Venice.\n\nReunion was attempted twice, at the 1274 Second Council of Lyon and the 1439 Council of Florence. The Council of Florence did briefly reestablish communion between East and West, which lasted until after the fall of Constantinople in 1453. In each case, however, the councils were rejected by the Orthodox people as a whole, and the union of Florence also became very politically difficult after Constantinople came under Ottoman rule. Some local Eastern Churches have, however, renewed union with Rome in time since (see Eastern Catholic Churches). Recent decades have seen a renewal of ecumenical spirit and dialogue between the Churches.\n\nIn 1453, the Byzantine Empire fell to the Ottoman Empire. By this time Egypt had been under Muslim control for some seven centuries, but Orthodoxy was very strong in Russia which had recently acquired an autocephalous status; and thus Moscow called itself the Third Rome, as the cultural heir of Constantinople.\n\nUnder Ottoman rule, the Greek Orthodox Church acquired substantial power as an autonomous \"millet\". The ecumenical patriarch was the religious and administrative ruler of the Rûm (Ottoman administrative unit meaning \"Roman\"), which encompassed all the Orthodox subjects of the Empire.\n\nUp until 1666, when Patriarch Nikon was deposed by the tsar, the Russian Orthodox Church had been independent of the State. In 1721 the first Russian Emperor, Peter I abolished completely the patriarchate and so the Church effectively became a department of the government, ruled by a Most Holy Synod composed of senior bishops and lay bureaucrats appointed by the Emperor himself. From 1721 until the Bolsheviks' October Revolution of 1917, the Russian Orthodox Church was essentially transformed into a governmental agency, a tool used to various degrees by the tsars in the imperial campaigns of Russification. The Church was allowed by the State to levy taxes on the peasants. Therefore, the Church, along with the imperial regime, to which it belonged, came to be presented as an enemy of the people by the Bolsheviks and the other Russian revolutionaries.\n\nThe revolution brought a brief period of freedom from governmental control for the Church: an independent patriarchate was reestablished briefly in 1917, until Vladimir Lenin quashed the Church a few years later, imprisoning or killing many of the clergy and of the faithful. Part of the clergy escaped the Bolshevik persecutions by fleeing abroad, where they founded an independent church in exile, reunified with the Russian one in 2007.\n\nThe Orthodox Church clergy in Russia were seen as sympathetic with the cause of the White Army in the Civil War (see White movement) after the October Revolution, and occasionally collaborated with it; Patriarch Tikhon's declared position was vehemently anti-Bolshevik in 1918. This may have further strengthened the Bolshevik animus against the church.\n\nBefore and after the October Revolution of 7 November 1917 (25 October Old Calendar) there was a movement within Russia to unite all of the people of the world under Communist rule (see Communist International). This included the Eastern Bloc countries as well as the Balkan States. Since some of these Slavic states tied their ethnic heritage to their ethnic churches, both the peoples and their church were targeted by the Soviets.\n\nThe Soviets' official interpretation of freedom of conscience was one of \"guaranteeing the right to profess any religion, or profess none, to practice religious cults, or conduct atheist propaganda\", though in effect atheism was sponsored by state and was taught in all educational establishments. Public criticism of atheism was unofficially forbidden and sometimes led to imprisonment.\n\nSoviet Russia was the first state to have as an ideological objective the elimination of religion. Toward that end, the government confiscated church property, ridiculed religion, harassed believers, and propagated atheism in schools. Actions toward particular religions, however, were determined by State interests, and most organized religions were never outlawed.\n\nSome actions against Orthodox priests and believers along with execution included torture, being sent to prison camps, labour camps or mental hospitals.\n\nThe result of state sponsored atheism was to transform the Church into a persecuted and martyred Church. In the first five years after the Bolshevik revolution, 28 bishops and 1,200 priests were executed.\n\nAfter Nazi Germany's attack on the Soviet Union in 1941, Joseph Stalin revived the Russian Orthodox Church to intensify patriotic support for the war effort. By 1957 about 22,000 Russian Orthodox churches had become active. But in 1959 Nikita Khrushchev initiated his own campaign against the Russian Orthodox Church and forced the closure of about 12,000 churches. It is estimated that 50,000 clergy had been executed between the revolution and the end of the Khrushchev era. Members of the church hierarchy were jailed or forced out, their places taken by docile clergy, many of whom had ties with the KGB. By 1985 fewer than 7,000 churches remained active.\n\nIn the Soviet Union, in addition to the methodical closing and destruction of churches, the charitable and social work formerly done by ecclesiastical authorities was taken over by the state. As with all private property, Church owned property was confiscated into public use. The few places of worship left to the Church were legally viewed as state property which the government permitted the church to use. After the advent of state funded universal education, the Church was not permitted to carry on educational, instructional activity of any kind. Outside of sermons during the celebration of the divine liturgy it could not instruct or evangelise to the faithful or its youth. Catechism classes, religious schools, study groups, Sunday schools and religious publications were all illegal or banned. This persecution continued, even after the death of Stalin until the dissolution of the Soviet Union in 1991. This caused many religious tracts to be circulated as illegal literature or samizdat.\n\nAmong the most damaging aspects of Soviet rule, along with these physical abuses, the Soviet Union frequently manipulated the recruitment and appointment of priests, sometimes planting agents of the KGB within the church to monitor religious persons who were viewed – simply for not being atheists – as suspicious and potential threats to Soviet communism. As a result, the return of religious beliefs in Russia has been impeded even after the dissolution of the Soviet Union.\n\nHowever, there is definitely marked return to Christian Orthodoxy in Russia. According to the Pew Research Religion & Public Life Project, between 1991 and 2008, the share of Russian adults identifying as Orthodox Christian rose from 31 percent to 72 percent, according to a new Pew Research Center analysis of three waves of data (1991, 1998 and 2008) from the International Social Survey Programme (ISSP) – a collaboration involving social scientists in about 50 countries.\n\nAlbania was the only state to have declared itself officially fully atheist. In some other Communist states such as Romania, the Romanian Orthodox Church as an organization enjoyed relative freedom and even prospered, albeit under strict secret police control. That, however, did not rule out demolishing churches and monasteries as part of broader systematization (urban planning), and state persecution of individual believers. As an example of the latter, Romania stands out as a country which ran a specialized institution where many Orthodox (along with people of other faiths) were subjected to psychological punishment or torture and mind control experimentation in order to force them give up their religious convictions. However, this was only supported by one faction within the regime, and lasted only three years. The Communist authorities closed down the prison in 1952, and punished many of those responsible for abuses (twenty of them were sentenced to death).\n\nEastern Orthodoxy represents the majority of Eastern Christianity. The Orthodox trace their bishops back to the apostles through apostolic succession, and continue the ancient Christian practices of veneration of saints, especially Mary the Mother of God as the Theotokos, prayers for the dead, and monasticism. Orthodoxy does not openly promote statuary, although it is not expressly condemned, instead limiting itself primarily to two-dimensional iconography. Western theological concepts of original sin, substitutionary atonement, predestination, purgatory and particular judgment are generally rejected by traditional Orthodox theologians.\n\nThe Orthodox believe themselves to be the One Holy Catholic and Apostolic Church; that is, the true Church established by Jesus Christ and placed into the care of the apostles. As almost all other Christian groups are in indirect schism with the Orthodox Church, mostly as a result of the Great Schism with the Roman Catholic Church at the turn of the second Christian millennium (before the schisms of the Protestant Reformation), these other groups are viewed as being Christian, but who, to varying degrees, lack full theological orthodoxy and orthopraxy. As such, all groups outside of the Orthodox Church are not seen as being members of the Church proper, but rather separated brethren who have failed to retain the fullness of the Christian faith and theology. These deviations from orthodoxy have traditionally been called heresy, but due to the term's perceived pejorative connotations, some prefer the more technical designation of the term heterodoxy.\n\nIn 1920, the Ecumenical Patriarchate of Constantinople, published an encyclical \"addressed 'To all the Churches of Christ, wherever they may be', urging closer co-operation among separated Christians, and suggesting a 'League of Churches', parallel to the newly founded League of Nations\". This gesture was instrumental in the foundation of the World Council of Churches (WCC); as such, almost all Eastern Orthodox Churches are members of the WCC and \"Orthodox ecclesiastics and theologians serve on its committees\". Kallistos Ware, a British metropolitan bishop of the Orthodox Church, has stated that ecumenism \"is important for Orthodoxy: it has helped to force the various Orthodox Churches out of their comparative isolation, making them meet one another and enter into a living contact with non-Orthodox Christians.\"\n\nHilarion Alfeyev, Metropolitan of Volokolamsk and head of external relations for the Moscow Patriarchate of the Russian Orthodox Church, stated that Orthodox and Evangelical Protestant Christians share the same positions on \"such issues as abortion, the family, and marriage\" and desire \"vigorous grassroots engagement\" between the two Christian communions on such issues.\n\nIn that regard, the differences between the Roman Catholic and Eastern Orthodox communions have not been improved in any relevant way. Dogmatic and liturgical polarities have been significant, even and especially in recent times. A pertinent point of contention between the monarchically papal, administratively centralized Roman Catholic Church and the decentralized confederation of Orthodox Churches is the theological significance of the Virgin Mary (\"Theotokos\", or \"God-bearer\"). Even during a visit by Pope Francis to Georgia in October 2016, the leader of the Roman Catholics was snubbed by most Orthodox Christians when he was holding mass in front of the practically empty Mikheil Meskhi Stadium in Tbilisi.\n\nThe Oriental Orthodox Churches are not in communion with the Eastern Orthodox Church, despite their similar names. Slow dialogue towards restoring communion between the two churches began in the mid-20th century; also, notably, in the 19th century, when the Greek Patriarch in Egypt had to absent himself from the country for a long period of time, he left his church under the guidance of the Coptic Pope Cyril IV of Alexandria.\n\nHistorically, the Orthodox Church and the non-Chalcedonians were among the first peoples to have contact with Islam, which conquered Roman/Byzantine Syria-Palestine and Egypt in the 7th century, and fought many battles against Islamic conquests. The Qur'an itself records its concurrent observations regarding the Roman world in Surah al-Rum. The main contact with Islam however, came after the conquest of the Seljuk Turks of Roman/Byzantine Anatolia in the 13th century. Until the turn of the 20th century, the Orthodox Church was under the authority of various Islamic Sultanates and Caliphates until the anti-Colonialist surge that began in the early 20th century.\n\nIn Russia, Metropolitan Alfeyev stated belief in the possibility of peaceful coexistence between Islam and Christianity as the two religions have never had religious wars in Russia.\n\nThe various autocephalous and autonomous synods of the Orthodox Church are distinct in terms of administration and local culture, but for the most part exist in full communion with one another.\n\nPresently, there are two communions that reject each other and, in addition, some schismatic churches not in any communion, all three groups identifying as Eastern Orthodox. The main traditional historical communion is divided into two groups - those who use the Revised Julian calendar for calculating fixed feasts and the Julian calendar for calculating movable feasts, and those who use the Julian calendar for all purposes. This second group may include congregations whose church allows them to choose, with the proviso that the choice remains in effect at least until the end of the church year. Also in communion are the Estonian and Finnish Orthodox churches who have a dispensation to use the Gregorian calendar for all purposes. Another group are referred to as True Orthodoxy (also Old Calendarists), they are those who, without authority from their parent churches, have continued to use the old Julian calendar, claiming that the calendar reform in the 1920s is in contravention of the ecumenical councils. Similarly, another group called Old Believers, separated in 1666 from the official Russian Orthodox Church as a protest against church rite reforms introduced by Patriarch Nikon of Moscow. As Eastern Orthodox Christianity is both collegial and local in structure, there is no single organization called the \"True Orthodox Church\" nor is there official recognition among the \"True Orthodox\" as to who is properly included among them. While some unions have taken place even up to the present, the majority of True Orthodox are only secondarily concerned with reunion as opposed to preservation of Eastern Orthodox teaching. The calendar question reflects the dispute between those who wish to use a calendar which is reformed yet not Gregorian (effectively gaining the perceived benefits of the Gregorian calendar without disregarding the three anathemas issued against it in the sixteenth century), something which opponents consider unnecessary and damaging to continuity, and those who wish to maintain the traditional ecclesiastical calendar (which happens to be based on the Julian calendar), arguing that such a modern change goes against 1900 years of Church tradition and was in fact perpetrated without an ecumenical council, which would surely have rejected the idea.\n\nThe dispute has led to much acrimony, and sometimes even to violence. Following canonical precepts, some adherents of the old calendar have chosen to abstain from clerical intercommunion with those synods which have embraced the new calendar until the conflict is resolved. The monastic communities on Mount Athos have provided the strongest opposition to the new calendar, and to modernism in general, while still maintaining communion with their mother church.\n\nSome latent discontent between different national churches exists also in part due to different approach towards ecumenism. While the Ecumenical Patriarch of Constantinople, the Orthodox bishops in North America gathered into the Standing Conference of the Canonical Orthodox Bishops in the Americas (SCOBA), Romanian bishops, and others are fairly open to dialog with the Roman Catholic Church, both conservative and moderate Old Calendarists, many of the monks of Mount Athos, several bishops of Russian, Serbian, and some of Greek and Bulgarian churches regard ecumenism as compromising essential doctrinal stands in order to accommodate other Christians, and object to the emphasis on dialogue leading to inter-communion; believing instead that Orthodox must speak the truth with love, in the hope of leading to the eventual conversion to Orthodoxy of heterodox Christians.\n\nEastern Orthodox Christians are among the wealthiest Christian denominations in the United States. They also tend to be better educated than most other religious groups in America, having a high number of graduate (68%) and post-graduate (28%) degrees per capita.\n\nThe Russian Orthodox Church Outside Russia (ROCOR) has recently united with the Moscow Patriarchate (MP); these two branches of the Russian Orthodox Church had separated from each other in the 1920s due to the subjection of the latter to the hostile Soviet regime (see Act of Canonical Communion).\n\nThe Orthodox Church is a communion of 14 autocephalous (that is, administratively completely independent) regional churches, plus the Orthodox Church in America, which is recognized as autocephalous only by the Russian, Bulgarian, Georgian, Polish, the Czech-Slovak churches. Each has defined geographical boundaries of its jurisdiction and is ruled by its Council of Bishops or Synod presided by a senior bishop – its Primate (or First Hierarch). The Primate may carry the honorary title of Patriarch, Metropolitan (in the Slavic tradition) or Archbishop (in the Greek tradition).\n\nEach regional church consists of constituent eparchies (or, dioceses) ruled by a bishop. Some churches have given an eparchy or group of eparchies varying degrees of autonomy (self-government). Such autonomous churches maintain varying levels of dependence on their mother church, usually defined in a Tomos or other document of autonomy.\n\nBelow is a list of the 14 (15) autocephalous Orthodox churches, all of which are titled equal to each other, but the Ecumenical Patriarchate is titled \"first among equals\". Based on these definitions, the list is in their order of precedence and alphabetical order where necessary, with constituent autonomous churches and exarchates. The Liturgical title of the Primate is listed in italics. The communion:\n\nThere are unresolved internal issues as to the autonomous or autocephalous status of the following Orthodox churches:\n\nTrue Orthodoxy separated from the mainstream communion over issues of ecumenism and calendar reform since the 1920s. The movement rejects the Ecumenical Patriarchate of Constantinople, the Moscow Patriarchate, and those Churches in communion with them, accusing them of heresy and placing themselves under bishops who do the same. They adhere to the use of the old Julian Calendar since Antiquity, claiming that the calendar reform in 1920s is in contravention of the Ecumenical Councils. True Orthodox writers have argued that in missionary areas such as the United States, Orthodox (SCOBA) membership numbers may be overstated, with the comparative number of True Orthodox as up to 15% of the Orthodox population, in Russia, it has been claimed by some clergy that up to a million Russians may be True Orthodox of different jurisdictions, though the total number is often cited at 1.7-2 million together.\n\nCommunion of True Orthodoxy:\nOld Believers are groups that do not accept liturgical reforms carried out in the Russian Orthodox Church by Patriarch Nikon in the 17th century. Although all Old Believers groups emerged as a result of opposition to the Nikonian reform, they do not constitute a single monolithic body. Despite the emphasis on invariable adherence to the pre-Nikonian traditions, the Old Believers feature a great diversity of groups that profess different interpretations of the church tradition and often are not in communion with each other (some groups even practise re-baptism before admitting a member of another group into their midst).\n\nOld Believers:\n\nChurches with irregular or unresolved canonical status are entities that have carried out episcopal consecrations outside of the norms of canon law or whose bishops have been excommunicated by one of the 14 (15) autocephalous churches. These include nationalist and other schisms.\n\n\n\n\n\n"}
{"id": "10190", "url": "https://en.wikipedia.org/wiki?curid=10190", "title": "Eusebius of Nicomedia", "text": "Eusebius of Nicomedia\n\nEusebius of Nicomedia (died 341) was the man who baptised Constantine the Great. He was a bishop of Berytus (modern-day Beirut) in Phoenicia, then of the See of Nicomedia, where the imperial court resided, and finally of Constantinople from 338 up to his death.\n\nDistantly related to the imperial family of Constantine, he owed his progression from a less significant Levantine bishopric to the most important episcopal see to his influence at court, and the great power he wielded in the Church was derived from that source. In fact, during his time in the Imperial court, the Eastern court and the major positions in the Eastern Church were held by Arians or Arian sympathizers. With the exception of a short period of eclipse, he enjoyed the confidence both of Constantine and Constantius II. He also served as the tutor of the later Emperor Julian the Apostate; and it was he who baptized Constantine the Great on May 22, 337 owing to his familial relationship with the emperor. Also during his time in the Imperial court, Arianism became more popular with the Royal family. It can be logically surmised that Eusebius had a huge hand in the acceptance of Arianism in the Constantinian household. The Arian influence grew so strong during his tenure in the Imperial court that it wasn't until the end of the Constantinian dynasty and the appointment of Theodosius I that Arianism lost its influence in the Empire.\n\nIt was of particular interest that Eusebius was nearly persecuted because of his close relationship to the Emperor Licinius while serving as Bishop of Nicomedia during Licinius' reign.\n\nLike Arius, he was a pupil of Lucian of Antioch, and it is probable that he held the same views as Arius from the very beginning; he was also one of Arius' most fervent supporters who encouraged Arius. It was also because of this relationship that he was the first person whom Arius contacted after the latter was excommunicated from Alexandria by Alexander. Apparently, Arius and Eusebius were close enough and Eusebius powerful enough that Arius was able to put his theology down in writing. He afterward modified his ideas somewhat, or perhaps he only yielded to the pressure of circumstances; but he was, if not the teacher, at all events the leader and organizer, of the Arian council.\n\nAt the First Council of Nicaea, 325, he signed the Confession, but only after a long and desperate opposition in which he \"subscribe with hand only, not heart\" according to ancient sources. It was a huge blow to the Arian party since it was surmised that the participants in the First Council of Nicaea were evenly split between non-Arians and Arians.\nHis defense of Arius angered the emperor, and a few months after the council\nhe was sent into exile due to his continual contacts with Arius and his followers. After the lapse of three years, he succeeded in regaining the imperial favor by convincing Constantine that Arius and his views do not conflict with the proclaimed Nicene Creed. After his return in 329 he brought the whole machinery of the state government into action in order to impose his views upon the Church.\n\nIn complement to his theological interests, Eusebius was a skilled politician. Upon his return, he regained the lost ground resulted from the First Council of Nicaea, established alliances with other groups such as the Meletians and expelled many opponents.\n\nHe was described by modern historians as an \"ambitious intriguer\" and a \"consummate political player\". He was also described by ancient sources as a high-handed person who was also aggressive in his dealings.; he also used his allies to spy on his opponents.\n\nHe was able to dislodge and exile three key opponents who espoused the First Council of Nicaea: Eustathius of Antioch in 330, Athanasius of Alexandria in 335 and Marcellus of Ancyra in 336. This was no small feat since Athanasius was regarded as a \"man of God\" by Constantine. and both Eustathius and Athanasius held top positions in the church.\n\nAnother major feat was his appointment as the Patriarch of Constantinople by expelling Paul I of Constantinople; Paul would eventually return as Patriarch after Eusebius' death.\n\nEven outside the empire, Eusebius had great influence. He brought Ulfilas into the Arian priesthood and sent the latter to convert the heathen Goths.\n\nEusebius baptised Constantine the Great in his villa in Nicomedia, on May 22, 337 just before the death of the Emperor.\n\nHe died at the height of his power in the year 341.\n\nHe was so influential that even after his death, Constantius II heeded his and Eudoxus of Constantinople's advice to attempt to convert the Roman Empire to Arianism by creating Arian Councils and official Arian Doctrines.\n\nIt was because of Eusebius that \"On the whole, Constantine and his successors made life pretty miserable for Church leaders committed to the Nicene decision and its Trinitarian formula.\"\n\nEusebius of Nicomedia is not to be confused with his contemporary Eusebius of Caesarea, the author of a well-known early book of Church History.\n\n\nCorrespondence of Eusebius of Nicomedia:\n"}
{"id": "10191", "url": "https://en.wikipedia.org/wiki?curid=10191", "title": "Edo", "text": "Edo\n\n, also romanized as Jedo, Yedo or Yeddo, is the former name of Tokyo. It was the seat of power for the Tokugawa shogunate, which ruled Japan from 1603 to 1868. During this period, it grew to become one of the largest cities in the world and home to an urban culture centered on the notion of a \"floating world\".\n\nFrom the establishment of the Tokugawa \"bakufu\" headquarters at Edo, the town became the \"de facto\" capital and center of political power, although Kyoto remained the formal capital of the country. Edo grew from what had been a small, little-known fishing village in 1457 into the largest metropolis in the world with an estimated population of 1,000,000 by 1721.\n\nEdo was repeatedly devastated by fires, with the Great Fire of Meireki in 1657 being the most disastrous. An estimated 100,000 people died in the fire. During the Edo period, there were about 100 fires mostly begun by accident and often quickly escalating and spreading through neighborhoods of wooden \"machiya\" which were heated with charcoal fires. Between 1600 and 1945, Edo/Tokyo was leveled every 25–50 years or so by fire, earthquakes, or war.\nIn 1868, when the shogunate came to an end, the city was renamed \"Tokyo\" (\"eastern capital\"). The emperor moved his residence to Tokyo, making the city the formal capital of Japan:\n\nIshimaru Sadatsuga was the magistrate of Edo in 1661.\n\nDuring the Edo period, the Shogunate appointed administrators (\"machi bugyō\") with jurisdiction over the police, and beginning with the rule of Tokugawa Yoshimune), the fire department (\"machibikeshi\"). The \"machi bugyō\" heard criminal and civil suits, and performed other administrative functions.\n\nThe city was laid out as a castle town around Edo Castle. The area surrounding the castle known as \"Yamanote\" consisted largely of \"daimyō\" mansions, whose families lived in Edo as part of the \"sankin kōtai\" system; the \"daimyō\" made journeys in alternating years to Edo, and used the mansions for their entourages. It was this extensive samurai class which defined the character of Edo, particularly in contrast to the two major cities of Kyoto and Osaka neither of which were ruled by a \"daimyō\" or had a significant samurai population. Kyoto's character was defined by the Imperial Court, the court nobles, its Buddhist temples and its history; Osaka was the country's commercial center, dominated by the \"chōnin\" or the merchant class.\n\nAreas further from the center were the domain of the \"chōnin\" (町人, \"townsfolk\"). The area known as Shitamachi (下町, \"lower town\" or \"downtown\"), northeast of the castle, was a center of urban culture. The ancient Buddhist temple of Sensō-ji still stands in Asakusa, marking the center of an area of traditional Shitamachi culture. Some shops in the streets near the temple have existed continuously in the same location since the Edo period.\n\nThe Sumida River, then called the Great River (大川, \"Ōkawa\"), ran along the eastern edge of the city. The shogunate's official rice-storage warehouses, other official buildings and some of the city's best-known restaurants were located here.\nThe \"Japan Bridge\" (日本橋, \"Nihon-bashi\") marked the center of the city's commercial center, an area also known as \"Kuramae\" (蔵前, \"in front of the storehouses\"). Fishermen, craftsmen and other producers and retailers operated here. Shippers managed ships known as \"tarubune\" to and from Osaka and other cities, bringing goods into the city or transferring them from sea routes to river barges or land routes such as the Tōkaidō. This area remains the center of Tokyo's financial and business district.\n\nThe northeastern corner of the city was considered a dangerous direction in traditional \"onmyōdō\" (cosmology), and is protected from evil by a number of temples including Sensō-ji and Kan'ei-ji. Beyond this were the districts of the \"eta\" or outcasts, who performed \"unclean\" work and were separated from the main parts of the city. A long dirt path, which was a short distance north of the \"eta\" districts, extended west from the riverbank leading along the northern edge of the city to the Yoshiwara pleasure districts. Previously located within the city proper near Asakusa, the districts were rebuilt in this more-remote location after the Great Fire of Meireki in 1657.\n\n\"See Tokyo for photographs of the modern city.\"\n\n\n\n\n"}
{"id": "10192", "url": "https://en.wikipedia.org/wiki?curid=10192", "title": "Explosive material", "text": "Explosive material\n\nAn explosive material, also called an explosive, is a reactive substance that contains a great amount of potential energy that can produce an explosion if released suddenly, usually accompanied by the production of light, heat, sound, and pressure. An explosive charge is a measured quantity of explosive material, which may be composed of a single ingredient or a combination of two or more.\n\nThe potential energy stored in an explosive material may, for example, be\n\nExplosive materials may be categorized by the speed at which they expand. Materials that detonate (the front of the chemical reaction moves faster through the material than the speed of sound) are said to be \"high explosives\" and materials that deflagrate are said to be \"low explosives\". Explosives may also be categorized by their sensitivity. Sensitive materials that can be initiated by a relatively small amount of heat or pressure are primary explosives and materials that are relatively insensitive are secondary or tertiary explosives.\n\nA wide variety of chemicals can explode; a smaller number are manufactured specifically for the purpose of being used as explosives. The remainder are too dangerous, sensitive, toxic, expensive, unstable, or prone to decomposition or degradation over short time spans.\n\nIn contrast, some materials are merely combustible or flammable if they burn without exploding.\n\nThe distinction, however, is not razor-sharp. Certain materials—dusts, powders, gasses, or volatile organic liquids—may be simply combustible or flammable under ordinary conditions, but become explosive in specific situations or forms, such as dispersed airborne clouds, or confinement or sudden release.\n\nThough early thermal weapons, such as Greek fire, have existed since ancient times, the first widely used explosive in warfare and mining was black powder, invented in 9th century in China by Subho. This material was sensitive to water, and it produced copious amounts of dark smoke. The first useful explosive stronger than black powder was nitroglycerin, developed in 1847. Since nitroglycerin is a liquid and highly unstable, it was replaced by nitrocellulose, TNT in 1863, smokeless powder, dynamite in 1867 and gelignite (the latter two being sophisticated stabilized preparations of nitroglycerin rather than chemical alternatives, both invented by Alfred Nobel). World War I saw the adoption of TNT trinitrotoluene in artillery shells. World War II saw an extensive use of new explosives (see explosives used during World War II). In turn, these have largely been replaced by more powerful explosives such as C-4 and PETN. However, C-4 and PETN react with metal and catch fire easily, yet unlike TNT, C-4 and PETN are waterproof and malleable.\n\nThe largest commercial application of explosives is mining. Whether the mine is on the surface or is buried underground, the detonation or deflagration of either a high or low explosive in a confined space can be used to liberate a fairly specific sub-volume of a brittle material in a much larger volume of the same or similar material. The mining industry tends to use nitrate-based explosives such as emulsions of fuel oil and ammonium nitrate solutions, mixtures of ammonium nitrate prills (fertilizer pellets) and fuel oil (ANFO) and gelatinous suspensions or slurries of ammonium nitrate and combustible fuels.\n\nIn Materials Science and Engineering, explosives are used in cladding. A thin plate of some material is placed atop a thick layer of a different material, both layers typically of metal. Atop the thin layer is placed an explosive. At one end of the layer of explosive, the explosion is initiated. The two metallic layers are forced together at high speed and with great force. The explosion spreads from the initiation site throughout the explosive. Ideally, this produces a metallurgical bond between the two layers.\n\nAs the length of time the shock wave spends at any point is small, we can see mixing of the two metals and their surface chemistries, through some fraction of the depth, and they tend to be mixed in some way. It is possible that some fraction of the surface material from either layer eventually gets ejected when the end of material is reached. Hence, the mass of the now \"welded\" bilayer, may be less than the sum of the masses of the two initial layers.\n\nThere are applications where a shock wave, and electrostatics, can result in high velocity projectiles.\n\nAn explosion is a type of spontaneous chemical reaction that, once initiated, is driven by both a large exothermic change (great release of heat) and a large positive entropy change (great quantities of gases are released) in going from reactants to products, thereby constituting a thermodynamically favorable process in addition to one that propagates very rapidly. Thus, explosives are substances that contain a large amount of energy stored in chemical bonds. The energetic stability of the gaseous products and hence their generation comes from the formation of strongly bonded species like carbon monoxide, carbon dioxide, and (di)nitrogen, which contain strong double and triple bonds having bond strengths of nearly 1 MJ/mole. Consequently, most commercial explosives are organic compounds containing -NO, -ONO and -NHNO groups that, when detonated, release gases like the aforementioned (e.g., nitroglycerin, TNT, HMX, PETN, nitrocellulose).\n\nAn explosive is classified as a low or high explosive according to its rate of burn: low explosives burn rapidly (or deflagrate), while high explosives detonate. While these definitions are distinct, the problem of precisely measuring rapid decomposition makes practical classification of explosives difficult.\n\nTraditional explosives mechanics is based on the shock-sensitive rapid oxidation of carbon and hydrogen to carbon dioxide, carbon monoxide and water in the form of steam. Nitrates typically provide the required oxygen to burn the carbon and hydrogen fuel. High explosives tend to have the oxygen, carbon and hydrogen contained in one organic molecule, and less sensitive explosives like ANFO are combinations of fuel (carbon and hydrogen fuel oil) and ammonium nitrate. A sensitizer such as powdered aluminum may be added to an explosive to increase the energy of the detonation. Once detonated, the nitrogen portion of the explosive formulation emerges as nitrogen gas and toxic nitric oxides.\n\nThe chemical decomposition of an explosive may take years, days, hours, or a fraction of a second. The slower processes of decomposition take place in storage and are of interest only from a stability standpoint. Of more interest are the other two rapid forms besides decomposition, deflagration and detonation.\n\nIn deflagration, decomposition of the explosive material is propagated by a flame front which moves slowly through the explosive material at speeds less than the speed of sound within the substance (usually below 1000 m/s) in contrast to detonation, which occurs at speeds greater than the speed of sound. Deflagration is a characteristic of low explosive material.\n\nThis term is used to describe an explosive phenomenon whereby the decomposition is propagated by an explosive shock wave traversing the explosive material at speeds greater than the speed of sound within the substance. The shock front is capable of passing through the high explosive material at supersonic speeds, typically thousands of metres per second.\n\nIn addition to chemical explosives, there are a number of more exotic explosive materials, and exotic methods of causing explosions. Examples include nuclear explosives, and abruptly heating a substance to a plasma state with a high-intensity laser or electric arc.\n\nLaser- and arc-heating are used in laser detonators, exploding-bridgewire detonators, and exploding foil initiators, where a shock wave and then detonation in conventional chemical explosive material is created by laser- or electric-arc heating. Laser and electric energy are not currently used in practice to generate most of the required energy, but only to initiate reactions.\n\nTo determine the suitability of an explosive substance for a particular use, its physical properties must first be known. The usefulness of an explosive can only be appreciated when the properties and the factors affecting them are fully understood. Some of the more important characteristics are listed below:\n\nSensitivity refers to the ease with which an explosive can be ignited or detonated, i.e., the amount and intensity of shock, friction, or heat that is required. When the term sensitivity is used, care must be taken to clarify what kind of sensitivity is under discussion. The relative sensitivity of a given explosive to impact may vary greatly from its sensitivity to friction or heat. Some of the test methods used to determine sensitivity relate to:\n\nSpecific explosives (usually but not always highly sensitive on one or more of the three above axes) may be idiosyncratically sensitive to such factors as pressure drop, acceleration, the presence of sharp edges or rough surfaces, incompatible materials, or even—in rare cases—nuclear or electromagnetic radiation. These factors present special hazards that may rule out any practical utility.\n\nSensitivity is an important consideration in selecting an explosive for a particular purpose. The explosive in an armor-piercing projectile must be relatively insensitive, or the shock of impact would cause it to detonate before it penetrated to the point desired. The explosive lenses around nuclear charges are also designed to be highly insensitive, to minimize the risk of accidental detonation.\n\nThe index of the capacity of an explosive to be initiated into detonation in a sustained manner. It is defined by the power of the detonator which is certain to prime the explosive to a sustained and continuous detonation. Reference is made to the Sellier-Bellot scale that consists of a series of 10 detonators, from n. 1 to n. 10, each of which corresponds to an increasing charge weight. In practice, most of the explosives on the market today are sensitive to an n. 8 detonator, where the charge corresponds to 2 grams of mercury fulminate.\n\nThe velocity with which the reaction process propagates in the mass of the explosive. Most commercial mining explosives have detonation velocities ranging from 1800 m/s to 8000 m/s. Today, velocity of detonation can be measured with accuracy. Together with density it is an important element influencing the yield of the energy transmitted for both atmospheric over-pressure and ground acceleration. By definition, a \"low explosive,\" such as black powder, or smokeless gunpowder has a burn rate of 171–631 m/s. In contrast, a \"high explosive,\" whether a primary, such as detonating cord, or a secondary, such as TNT or C-4 has a significantly higher burn rate.\n\nStability is the ability of an explosive to be stored without deterioration.\n\nThe following factors affect the stability of an explosive:\n\nThe term power or performance as applied to an explosive refers to its ability to do work. In practice it is defined as the explosive's ability to accomplish what is intended in the way of energy delivery (i.e., fragment projection, air blast, high-velocity jet, underwater shock and bubble energy, etc.). Explosive power or performance is evaluated by a tailored series of tests to assess the material for its intended use. Of the tests listed below, cylinder expansion and air-blast tests are common to most testing programs, and the others support specific applications.\n\nIn addition to strength, explosives display a second characteristic, which is their shattering effect or brisance (from the French meaning to \"break\"), which is distinguished and separate from their total work capacity. This characteristic is of practical importance in determining the effectiveness of an explosion in fragmenting shells, bomb casings, grenades, and the like. The rapidity with which an explosive reaches its peak pressure (power) is a measure of its brisance. Brisance values are primarily employed in France and Russia.\n\nThe sand crush test is commonly employed to determine the relative brisance in comparison to TNT. No test is capable of directly comparing the explosive properties of two or more compounds; it is important to examine the data from several such tests (sand crush, trauzl, and so forth) in order to gauge relative brisance. True values for comparison require field experiments.\n\nDensity of loading refers to the mass of an explosive per unit volume. Several methods of loading are available, including pellet loading, cast loading, and press loading, the choice being determined by the characteristics of the explosive. Dependent upon the method employed, an average density of the loaded charge can be obtained that is within 80–99% of the theoretical maximum density of the explosive. High load density can reduce sensitivity by making the mass more resistant to internal friction. However, if density is increased to the extent that individual crystals are crushed, the explosive may become more sensitive. Increased load density also permits the use of more explosive, thereby increasing the power of the warhead. It is possible to compress an explosive beyond a point of sensitivity, known also as \"dead-pressing\", in which the material is no longer capable of being reliably initiated, if at all.\n\nVolatility is the readiness with which a substance vaporizes. Excessive volatility often results in the development of pressure within rounds of ammunition and separation of mixtures into their constituents. Volatility affects the chemical composition of the explosive such that a marked reduction in stability may occur, which results in an increase in the danger of handling.\n\nThe introduction of water into an explosive is highly undesirable since it reduces the sensitivity, strength, and velocity of detonation of the explosive. Hygroscopicity is used as a measure of a material's moisture-absorbing tendencies. Moisture affects explosives adversely by acting as an inert material that absorbs heat when vaporized, and by acting as a solvent medium that can cause undesired chemical reactions. Sensitivity, strength, and velocity of detonation are reduced by inert materials that reduce the continuity of the explosive mass. When the moisture content evaporates during detonation, cooling occurs, which reduces the temperature of reaction. Stability is also affected by the presence of moisture since moisture promotes decomposition of the explosive and, in addition, causes corrosion of the explosive's metal container.\n\nExplosives considerably differ from one another as to their behavior in the presence of water. Gelatin dynamites containing nitroglycerine have a degree of water resistance. Explosives based on ammonium nitrate have little or no water resistance due to the reaction between ammonium nitrate and water, which liberates ammonia, nitrogen dioxide and hydrogen peroxide. In addition, ammonium nitrate is hygroscopic, susceptible to damp, hence the above concerns.\n\nThere are many types of explosives which are toxic to some extent. Manufacturing inputs can also be organic compounds or hazardous materials that require special handing due to risks (such as carcinogens). The decomposition products, residual solids or gases of some explosives can be toxic, whereas others are harmless, such as carbon dioxide and water.\nExamples of harmful by-products are:\n\n\"Green explosives\" seek to reduce environment and health impacts. An example of such is the lead-free primary explosive copper(I) 5-nitrotetrazolate, an alternative to lead azide. One variety of a green explosive is CDP explosives, whose synthesis does not involve any toxic ingredients, consumes carbon dioxide while detonating and does not release any nitric oxides into the atmosphere when used.\n\nExplosive material may be incorporated in the explosive train of a device or system. An example is a pyrotechnic lead igniting a booster, which causes the main charge to detonate.\n\nThe most widely used explosives are condensed liquids or solids converted to gaseous products by explosive chemical reactions and the energy released by those reactions. The gaseous products of complete reaction are typically carbon dioxide, steam, and nitrogen. Gaseous volumes computed by the ideal gas law tend to be too large at high pressures characteristic of explosions. Ultimate volume expansion may be estimated at three orders of magnitude, or one liter per gram of explosive. Explosives with an oxygen deficit will generate soot or gases like carbon monoxide and hydrogen, which may react with surrounding materials such as atmospheric oxygen. Attempts to obtain more precise volume estimates must consider the possibility of such side reactions, condensation of steam, and aqueous solubility of gases like carbon dioxide.\n\nBy comparison, CDP detonation is based on the rapid reduction of carbon dioxide to carbon with the abundant release of energy. Rather than produce typical waste gases like carbon dioxide, carbon monoxide, nitrogen and nitric oxides, CDP is different. Instead, the highly energetic reduction of carbon dioxide to carbon vaporizes and pressurizes excess dry ice at the wave front, which is the only gas released from the detonation. The velocity of detonation for CDP formulations can therefore be customized by adjusting the weight percentage of reducing agent and dry ice. Interestingly, CDP detonations produce a large amount of solid materials that can have great commercial value as an abrasive:\n\nExample - CDP Detonation Reaction with Magnesium: XCO + 2Mg ----> 2MgO + C + (X-1)CO\n\nThe products of detonation in this example are magnesium oxide, carbon in various phases including diamond, and vaporized excess carbon dioxide that was not consumed by the amount of magnesium in the explosive formulation.\n\nOxygen balance is an expression that is used to indicate the degree to which an explosive can be oxidized. If an explosive molecule contains just enough oxygen to convert all of its carbon to carbon dioxide, all of its hydrogen to water, and all of its metal to metal oxide with no excess, the molecule is said to have a zero oxygen balance. The molecule is said to have a positive oxygen balance if it contains more oxygen than is needed and a negative oxygen balance if it contains less oxygen than is needed. The sensitivity, strength, and brisance of an explosive are all somewhat dependent upon oxygen balance and tend to approach their maxima as oxygen balance approaches zero.\n\nOxygen balance applies to traditional explosives mechanics with the assumption that carbon is oxidized to carbon monoxide and carbon dioxide during detonation. In what seems like a paradox to an explosives expert, Cold Detonation Physics uses carbon in its most highly oxidized state as the source of oxygen in the form of carbon dioxide. Oxygen balance, therefore, either does not apply to a CDP formulation or must be calculated without including the carbon in the carbon dioxide.\n\nA chemical explosive may consist of either a chemically pure compound, such as nitroglycerin, or a mixture of a fuel and an oxidizer, such as black powder or grain dust and air.\n\nSome chemical compounds are unstable in that, when shocked, they react, possibly to the point of detonation. Each molecule of the compound dissociates into two or more new molecules (generally gases) with the release of energy.\n\nThe above compositions may describe most of the explosive material, but a practical explosive will often include small percentages of other substances. For example, dynamite is a mixture of highly sensitive nitroglycerin with sawdust, powdered silica, or most commonly diatomaceous earth, which act as stabilizers. Plastics and polymers may be added to bind powders of explosive compounds; waxes may be incorporated to make them safer to handle; aluminium powder may be introduced to increase total energy and blast effects. Explosive compounds are also often \"alloyed\": HMX or RDX powders may be mixed (typically by melt-casting) with TNT to form Octol or Cyclotol.\n\nAn oxidizer is a pure substance (molecule) that in a chemical reaction can contribute some atoms of one or more oxidizing elements, in which the fuel component of the explosive burns. On the simplest level, the oxidizer may itself be an oxidizing element, such as gaseous or liquid oxygen.\n\nThe availability and cost of explosives are determined by the availability of the raw materials and the cost, complexity, and safety of the manufacturing operations.\n\nA primary explosive is an explosive that is extremely sensitive to stimuli such as impact, friction, heat, static electricity, or electromagnetic radiation. Some primary explosives are also known as contact explosives. A relatively small amount of energy is required for initiation. As a very general rule, primary explosives are considered to be those compounds that are more sensitive than PETN. As a practical measure, primary explosives are sufficiently sensitive that they can be reliably initiated with a blow from a hammer; however, PETN can also usually be initiated in this manner, so this is only a very broad guideline. Additionally, several compounds, such as nitrogen triiodide, are so sensitive that they cannot even be handled without detonating. Nitrogen triiodide is so sensitive that it can be reliably detonated by exposure to alpha radiation; it is the only explosive for which this is true.\n\nPrimary explosives are often used in detonators or to trigger larger charges of less sensitive secondary explosives. Primary explosives are commonly used in blasting caps and percussion caps to translate a physical shock signal. In other situations, different signals such as electrical/physical shock, or, in the case of laser detonation systems, light, are used to initiate an action, i.e., an explosion. A small quantity, usually milligrams, is sufficient to initiate a larger charge of explosive that is usually safer to handle.\n\nExamples of primary high explosives are:\n\nA secondary explosive is less sensitive than a primary explosive and requires substantially more energy to be initiated. Because they are less sensitive, they are usable in a wider variety of applications and are safer to handle and store. Secondary explosives are used in larger quantities in an explosive train and are usually initiated by a smaller quantity of a primary explosive.\n\nExamples of secondary explosives include TNT and RDX.\n\nTertiary explosives, also called blasting agents, are so insensitive to shock that they cannot be reliably detonated by practical quantities of primary explosive, and instead require an intermediate explosive booster of secondary explosive. These are often used for safety and the typically lower costs of material and handling. The largest consumers are large-scale mining and construction operations.\n\nANFO is an example of a tertiary explosive.\n\nLow explosives are compounds where the rate of decomposition proceeds through the material at less than the speed of sound. The decomposition is propagated by a flame front (deflagration) which travels much more slowly through the explosive material than a shock wave of a high explosive. Under normal conditions, low explosives undergo deflagration at rates that vary from a few centimetres per second to approximately 400 metres per second. It is possible for them to deflagrate very quickly, producing an effect similar to a detonation. This can happen under higher pressure or temperature, which usually occurs when ignited in a confined space.\n\nA low explosive is usually a mixture of a combustible substance and an oxidant that decomposes rapidly (deflagration); however, they burn more slowly than a high explosive, which has an extremely fast burn rate.\n\nLow explosives are normally employed as propellants. Included in this group are petroleum products such as propane and gasoline, gunpowder (both black and smokeless), and light pyrotechnics, such as flares and fireworks, but can replace high explosives in certain applications, see gas pressure blasting.\n\nHigh explosives (HE) are explosive materials that detonate, meaning that the explosive shock front passes through the material at a supersonic speed. High explosives detonate with explosive velocity ranging from 3 to 9 km/s. For instance, TNT has a detonation (burn) rate of approximately 5.8 km/s (19,000 feet per second), Detonating cord of 6.7 km/s (22,000 feet per second), and C-4 about 8.5 km/s (29,000 feet per second). They are normally employed in mining, demolition, and military applications. They can be divided into two explosives classes differentiated by sensitivity: primary explosive and secondary explosive. The term \"high explosive\" is in contrast with the term \"low explosive\", which explodes (deflagrates) at a lower rate. They are stable and quite insensitive to fire and mechanical shocks.\n\nPriming compositions are primary explosives mixed with other compositions to control (lessen) the sensitivity of the mixture to the desired property.\n\nFor example, primary explosives are so sensitive that they need to be stored and shipped in a wet state to prevent accidental initiation.\n\nExplosives are often characterized by the physical form that the explosives are produced or used in. These use forms are commonly categorized as:\n\nShipping labels and tags may include both United Nations and national markings.\n\nUnited Nations markings include numbered Hazard Class and Division (HC/D) codes and alphabetic Compatibility Group codes. Though the two are related, they are separate and distinct. Any Compatibility Group designator can be assigned to any Hazard Class and Division. An example of this hybrid marking would be a consumer firework, which is labeled as 1.4G or 1.4S.\n\nExamples of national markings would include United States Department of Transportation (U.S. DOT) codes.\n\nThe Hazard Class and Division (HC/D) is a numeric designator within a hazard class indicating the character, predominance of associated hazards, and potential for causing personnel casualties and property damage. It is an internationally accepted system that communicates using the minimum amount of markings the primary hazard associated with a substance.\n\nListed below are the Divisions for Class 1 (Explosives):\n\nTo see an entire UNO Table, browse Paragraphs 3-8 and 3-9 of NAVSEA OP 5, Vol. 1, Chapter 3.\n\nCompatibility Group codes are used to indicate storage compatibility for HC/D Class 1 (explosive) materials. Letters are used to designate 13 compatibility groups as follows.\n\nA: Primary explosive substance (1.1A).\n\nB: An article containing a primary explosive substance and not containing two or more effective protective features. Some articles, such as detonator assemblies for blasting and primers, cap-type, are included. (1.1B, 1.2B, 1.4B).\n\nC: Propellant explosive substance or other deflagrating explosive substance or article containing such explosive substance (1.1C, 1.2C, 1.3C, 1.4C). These are bulk propellants, propelling charges, and devices containing propellants with or without means of ignition. Examples include single-based propellant, double-based propellant, triple-based propellant, and composite propellants, solid propellant rocket motors and ammunition with inert projectiles.\n\nD: Secondary detonating explosive substance or black powder or article containing a secondary detonating explosive substance, in each case without means of initiation and without a propelling charge, or article containing a primary explosive substance and containing two or more effective protective features. (1.1D, 1.2D, 1.4D, 1.5D).\n\nE: Article containing a secondary detonating explosive substance without means of initiation, with a propelling charge (other than one containing flammable liquid, gel or hypergolic liquid) (1.1E, 1.2E, 1.4E).\n\nF containing a secondary detonating explosive substance with its means of initiation, with a propelling charge (other than one containing flammable liquid, gel or hypergolic liquid) or without a propelling charge (1.1F, 1.2F, 1.3F, 1.4F).\n\nG: Pyrotechnic substance or article containing a pyrotechnic substance, or article containing both an explosive substance and an illuminating, incendiary, tear-producing or smoke-producing substance (other than a water-activated article or one containing white phosphorus, phosphide or flammable liquid or gel or hypergolic liquid) (1.1G, 1.2G, 1.3G, 1.4G). Examples include Flares, signals, incendiary or illuminating ammunition and other smoke and tear producing devices.\n\nH: Article containing both an explosive substance and white phosphorus (1.2H, 1.3H). These articles will spontaneously combust when exposed to the atmosphere.\n\nJ: Article containing both an explosive substance and flammable liquid or gel (1.1J, 1.2J, 1.3J). This excludes liquids or gels which are spontaneously flammable when exposed to water or the atmosphere, which belong in group H. Examples include liquid or gel filled incendiary ammunition, fuel-air explosive (FAE) devices, and flammable liquid fueled missiles.\n\nK: Article containing both an explosive substance and a toxic chemical agent (1.2K, 1.3K)\n\nL Explosive substance or article containing an explosive substance and presenting a special risk (e.g., due to water-activation or presence of hypergolic liquids, phosphides, or pyrophoric substances) needing isolation of each type (1.1L, 1.2L, 1.3L). Damaged or suspect ammunition of any group belongs in this group.\n\nN: Articles containing only extremely insensitive detonating substances (1.6N).\n\nS: Substance or article so packed or designed that any hazardous effects arising from accidental functioning are limited to the extent that they do not significantly hinder or prohibit fire fighting or other emergency response efforts in the immediate vicinity of the package (1.4S).\n\nThe legality of possessing or using explosives varies by jurisdiction. Various countries around the world have enacted explosives law and require licenses to manufacture, distribute, store, use, possess explosives or ingredients.\n\nIn the Netherlands, the civil and commercial use of explosives is covered under the Wet explosieven voor civiel gebruik (explosives for civil use Act), in accordance with EU directive nr. 93/15/EEG (Dutch). The illegal use of explosives is covered under the Wet Wapens en Munitie (Weapons and Munition Act) (Dutch).\n\nDuring World War I, numerous laws were created to regulate war related industries and increase security within the United States. In 1917, the 65th United States Congress created many laws, including the \"Espionage Act of 1917\" and \"Explosives Act of 1917\".\n\nThe \"Explosives Act of 1917\" (session 1, chapter 83, ) was signed on 6 October 1917 and went into effect on 16 November 1917. The legal summary is \"An Act to prohibit the manufacture, distribution, storage, use, and possession in time of war of explosives, providing regulations for the safe manufacture, distribution, storage, use, and possession of the same, and for other purposes\". This was the first federal regulation of licensing explosives purchases. The act was deactivated after World War I ended.\n\nAfter the United States entered World War II, the Explosives Act of 1917 was reactivated. In 1947, the act was deactivated by President Truman.\n\nThe \"Organized Crime Control Act of 1970\" () transferred many explosives regulations to the Bureau of Alcohol, Tobacco and Firearms (ATF) of the Department of Treasury. The bill became effective in 1971.\n\nCurrently, regulations are governed by Title 18 of the United States Code and Title 27 of the Code of Federal Regulations:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "10193", "url": "https://en.wikipedia.org/wiki?curid=10193", "title": "Enter the Dragon", "text": "Enter the Dragon\n\nEnter the Dragon is a 1973 Hong Kong-American martial arts action film, directed by Robert Clouse, and starring Bruce Lee, John Saxon and Jim Kelly. This was Bruce Lee's final film appearance before his death on 20 July 1973 at age 32. The film was first released on 26 July 1973 in Hong Kong, six days after Lee's death.\n\nOften considered one of the greatest martial arts films of all time, in 2004 the film was selected for preservation in the United States National Film Registry by the Library of Congress as being \"culturally, historically, or aesthetically significant\".\n\nLee (Bruce Lee), a highly skilled Shaolin martial artist from Hong Kong, is approached by Braithwaite, a British intelligence agent investigating suspected crime lord Han (Shih Kien). Lee is persuaded to attend a high-profile martial arts competition on Han's private island in order to gather evidence that will prove Han's involvement in drug trafficking and prostitution. Shortly before his departure, Lee also learns that his sister's killer, O'Hara (Robert Wall), is working as Han's bodyguard on the island. Also fighting in the competition are indebted gambling addict Roper (John Saxon) and fellow Vietnam war veteran Williams (Jim Kelly). \n\nAt the end of the first day, Han gives strict orders to the competitors not to leave their rooms. Lee makes contact with undercover operative Mei Ling (Betty Chung), and sneaks into Han's compound looking for evidence. He is discovered by several guards, but manages to escape. The next morning, Han has the guards publicly killed by chief guard Bolo (Bolo Yeung) for failing him. After the execution, Lee faces O'Hara in the competition and after an emotional battle ends up killing him. With the day's competition over, Han confronts Williams – who had also left his room the previous night to exercise – initially thinking him the intruder, and beats him to death when he refuses to cooperate. Han then reveals the scale of his drug operation to Roper in the hope that he will join his organization. He also implicitly threatens to imprison Roper, along with all the other martial artists who competed in Han's tournament in the past, if Roper refuses. Despite being initially convinced, Roper refuses after learning of Williams' fate.\n\nLee sneaks out again that night and manages to send a message to Braithwaite, but is finally captured after a protracted battle with the guards. The next morning Han arranges for Roper to fight Lee, but Roper refuses. As punishment, he is forced to fight Bolo instead but manages to overpower and kill him after a grueling encounter. Enraged by the unexpected victory, Han commands his remaining men to kill Lee and Roper. Facing insurmountable odds, they are soon aided by the island's prisoners, who had been freed by Mei Ling. Han escapes, pursued by Lee, who finally corners him in a hidden mirror room. The mirrors give Han an advantage, but Lee breaks all the room's mirrors to reveal Han's location, and eventually kills him. Lee returns to the main battle, which is now over. A bruised and bloodied Roper sits victorious while the military finally arrive to take control of the island.\n\nMany feel that there are some connections between \"Enter the Dragon\" and the Black Power movement. The Black Power movement, led by and large by Stokley Carmichael, was a racial empowerment movement. Carmichael believed in strengthening the black individual, as well as the black community, without the help of whites. Only then could true and successful integration take place. Carmichael did not believe in peaceful resistance, and advocated violence, stating that the Black community and the movement would achieve its goals by \"whatever means necessary\". Carmichael wanted to bring the country to its knees if it persecuted black men, and claimed the movement would back up this sentiment.\n\nThemes that are present in the Black Power Movement are also often present in martial arts movies, such as \"Enter the Dragon\". These themes include use of violence, self-reliance, self-protection, \"beating the man\", and success of the underdog: one typical scene in the beginning of the film is when Williams character gets harassed/intimidated, at night time, by two L.A.P.D. white officers. This can be thought of as the reason why martial arts films have such a large black audience. These minorities in the black community can take pleasure in seeing the enemy destroyed, and the underdog rising up. This is a sentiment often reiterated within the black community.\n\nThe end of World War II set decolonization into motion around the world. Many territories formed new states and claimed independence from European rule, attempting to put an end to colonialism. During colonialism, countries in Africa and Asia, as well as across the globe, were exploited for their labor and raw materials. The inhabitants of these lands were treated brutally and divided up by the European power. After retaliation, Europe lost most of its territories or let them slip away, and the newly independent nations came to fruition in the 1950s and 60s.\n\nMany historians and film critics have explored the connection between martial arts films and decolonization. Many believe that decolonization was a major theme in many martial arts movies, as the \"kung fu craze\" started booming only a few decades after independence had been won. Some say it was the foundation of the films. Others argue that it was actually Bruce Lee who \"opened up an allegorical link with the mass movement toward decolonization\". The theory is that when analyzing a martial arts film in the context of decolonization, the fight scenes represent the conflict between imperialism and the popular resistance. The antagonist, Han, is the imperialist, while the hero, Bruce Lee, is the revolutionary. Most of these Kung Fu films end with the defeat of villain against all odds, which represents liberation. So, these films are meant to offer their audience a powerful narrative of liberation.\n\nThe film was arguably the first to combine martial arts films with the Blaxploitation genre. Jim Kelly is thought to have portrayed the first Blaxploitation character that appeared in a martial arts movie. He would later go on to be one of the Blaxploitation genre's biggest stars. The success of the film, and the large black audience it attracted, caused other films to start incorporating these Blaxploitation characters more and more. Thus, the mingling of the genres was created.\n\nThe film was heavily advertised in the United States before its release. The budget for advertising was over $1,000,000. It was unlike any promotional campaign that had been seen before, and was extremely comprehensive. In order to advertise the film, the studio offered free Karate classes, produced thousands of illustrated flip books, comic books, posters, photographs, and organized dozens of news releases, interviews, and public appearances for the stars. \"Esquire\", \"The Wall Street Journal\", \"Time\", and \"Newsweek\" all wrote stories on the film.\n\nThe soundtrack to the film was composed by Lalo Schifrin, who was also the composer for \"\". He composed the score by sampling sounds from China, Korea, and Japan. The soundtrack was a huge success as well, selling over 500,000 copies. It earned a gold record.\n\nThe scene in which Lee states that his style was the style of \"Fighting Without Fighting\" and then lures Parsons into boarding a dinghy is based upon a famous anecdote involving the 16th century samurai Tsukahara Bokuden.\n\nJackie Chan appears as a guard during the underground lair battle scene and gets his neck snapped by Lee. He also performed several stunts for the film, including the scene where Lee's character quickly climbs a rooftop at night. However, Yuen Wah was Lee's main stunt double for the film.\n\nSammo Hung appears in the movie in a brief fight scene against Lee during the opening of the film.\n\nThe title of the screenplay was originally \"Blood and Steel\".\n\n\"Enter The Dragon\" was filmed without sound. All of the dialogue and effects were dubbed in during post-production.\n\nArgentinian musician Lalo Schifrin composed the film's musical score. While Schifrin was widely known at the time for his jazz scores, he also incorporated funk and traditional film score elements into the film's soundtrack.\n\nIn 1973, \"Enter the Dragon\" grossed an estimated $21,483,063 in North America, on a tight budget of $850,000. It was one of the most successful films of 1973.\n\nIn Hong Kong, the film grossed HK$3,307,536—huge business for the time, but substantially less than Lee's \"Fist of Fury\" and \"Way of the Dragon\". In India, the movie opened to full houses.\n\nWorldwide, the film grossed $90 million, including $65 million outside of the United States. Its worldwide gross is equivalent to $ million in 2016.\n\nThe film was well received by critics and is regarded by many as one of the best films of 1973. Critics have referred to \"Enter the Dragon\" as \"a low-rent James Bond thriller\", a \"remake of \"Dr. No\"\" with elements of Fu Manchu. J.C. Maçek III of PopMatters wrote, \"Of course the real showcase here is the obvious star here, Bruce Lee, whose performance as an actor and a fighter are the most enhanced by the perfect sound and video transfer. While Kelly was a famous martial artist and a surprisingly good actor and Saxon was a famous actor and a surprisingly good martial artist, Lee proves to be a master of both fields.\"\n\nMany additional acclaimed newspapers and magazines reviewed the film as well. Variety complimented multiple aspects of the film, claiming that film was overall \"rich in the atmosphere\", the music score was \"a strong asset\" and the photography as interesting. Additionally, The New York Times gave the film a rave review. The review stated \"The picture is expertly made and well-meshed; it moves like lightning and brims with color. It is also the most savagely murderous and numbing hand-hacker (not a gun in it) you will ever see anywhere.\"\n\nThe film currently holds a 95% approval rating on the review aggregate website Rotten Tomatoes, with 43 reviews counted and an average rating of 7.8/10. In 2004, the film was deemed \"culturally significant\" by the Library of Congress and selected for preservation in the National Film Registry.\n\nThe film also ranks No. 474 on \"Empire\" magazine's 2008 list of \"The 500 Greatest Movies of All Time\".\n\nThe film has been parodied and referenced in places such as the 1976 film \"The Pink Panther Strikes Again\", the satirical publication \"The Onion\", the Japanese game-show \"Takeshi's Castle\", and the 1977 John Landis comedy anthology film \"Kentucky Fried Movie\" (in its lengthy \"A Fistful of Yen\" sequence, basically a comedic, note for note remake of \"Dragon\") and also in the film \"Balls of Fury\". It was also parodied on television in \"That '70s Show\" during the episode \"Jackie Moves On\" with regular character Fez taking on the Bruce Lee role. Several clips from the film are comically used during the theatre scene in \"The Last Dragon\".\n\nIn August 2007, the now defunct Warner Independent Pictures announced that television producer Kurt Sutter would be remaking the film as a noir-style thriller entitled \"Awaken the Dragon\" with Korean singer-actor Rain starring. It was announced in September 2014 that Spike Lee will work on the remake. In March 2015, Brett Ratner revealed that he wanted to make the remake.\n\nThe popular video game \"Mortal Kombat\" borrows multiple plot elements from \"Enter The Dragon\".\n\nThe popular 1980s martial arts video game \"Double Dragon\" features two enemies named Roper and Williams, a reference to the two characters Roper and Williams from \"Enter The Dragon\".\n\nUniverse (Hong Kong)\n\nFortune Star – Bruce Lee Ultimate DVD Collection (Hong Kong)\n\nZoke Culture (China)\n\nWarner – 30th Anniversary Special Edition (America)\n\nWarner – 25th Anniversary Special Edition (America)\n\nWarner – Limited Edition (United Kingdom)\n\nKam & Ronson (Hong Kong)\n\nWarner (North America and South America)\n\nWarner (40th Anniversary Edition – Remastered)\n\n"}
{"id": "10201", "url": "https://en.wikipedia.org/wiki?curid=10201", "title": "Exothermic process", "text": "Exothermic process\n\nIn thermodynamics, the term exothermic process (exo- : \"outside\") describes a process or reaction that releases energy from the system to its surroundings, usually in the form of heat, but also in a form of light (e.g. a spark, flame, or flash), electricity (e.g. a battery), or sound (e.g. explosion heard when burning hydrogen). Its etymology stems from the Greek prefix \"έξω\" (exō, which means \"outwards\") and the Greek word \"θερμικός\" (thermikόs, which means \"thermal\"). The term \"exothermic\" was first coined by Marcellin Berthelot. The opposite of an exothermic process is an endothermic process, one that absorbs energy in the form of heat.\n\nThe concept is frequently applied in the physical sciences to chemical reactions, where as in chemical bond energy that will be converted to thermal energy (heat).\n\nExothermic (and endothermic) describe two types of chemical reactions or systems found in nature, as follows.\n\nSimply stated, after an exothermic reaction, more energy has been released to the surroundings than was absorbed to initiate and maintain the reaction. An example would be the burning of a candle, wherein the sum of calories produced by combustion (found by looking at radiant heating of the surroundings and visible light produced, including increase in temperature of the fuel (wax) itself, which with oxygen, have become hot CO and water vapor,) exceeds the number of calories absorbed initially in lighting the flame and in the flame maintaining itself. (i.e. some energy produced by combustion is reabsorbed and used in melting, then vaporizing the wax, etc. but is (far) outstripped by the energy produced in breaking carbon-hydrogen bonds and combination of oxygen with the resulting carbon and hydrogen).\n\nOn the other hand, in an endothermic reaction or system, energy is taken from the surroundings in the course of the reaction. An example of an endothermic reaction is a first aid cold pack, in which the reaction of two chemicals, or dissolving of one in another, requires calories from the surroundings, and the reaction cools the pouch and surroundings by absorbing heat from them. An endothermic system is seen in the production of wood: trees absorb radiant energy, from the sun, use it in endothermic reactions such as taking apart CO and HO and combining the carbon and hydrogen generated to produce cellulose and other organic chemicals. These products, in the form of wood, say, may later be burned in a fireplace, exothermically, producing CO and water, and releasing energy in the form of heat and light to their surroundings, e.g., to a home's interior and chimney gasses.\n\nExothermic refers to a transformation in which a system releases energy (heat) to the surroundings, expressed by\n\nWhen the transformation occurs at constant pressure, one has for the enthalpy\n\nand constant volume, one has for the internal energy\n\nIn an adiabatic system (i.e. a system that does not exchange heat with the surroundings), an exothermic process results in an increase in temperature of the system.\n\nIn exothermic chemical reactions, the heat that is released by the reaction takes the form of electromagnetic energy. The transition of electrons from one quantum energy level to another causes light to be released. This light is equivalent in energy to the stabilization energy of the energy for the chemical reaction, i.e. the bond energy. This light that is released can be absorbed by other molecules in solution to give rise to molecular vibrations or rotations, which gives rise to the classical understanding of heat. In contrast, when endothermic reactions occur, energy is absorbed to place an electron in a higher energy state, such that the electron can associate with another atom to form a chemical complex. Net energy is absorbed by an endothermic reaction. In an exothermic reaction, the energy needed to start the reaction is less than the energy that is subsequently released, so there is a net release of energy. This is the physical understanding of exothermic and endothermic reactions.\n\nSome examples of exothermic processes are:\n\nChemical exothermic reactions are generally more spontaneous than their counterparts, endothermic reactions. \n\nIn a thermochemical reaction that is exothermic, the heat may be listed among the products of the reaction.\n\nBecause of historical accident, students encounter a source of possible confusion between the terminology of physics and biology. Whereas the thermodynamic terms \"exothermic\" and \"endothermic\" respectively refer to processes that give out heat energy and processes that absorb heat energy, in biology the sense is effectively inverted. The metabolic terms \"ectothermic\" and \"endothermic\" respectively refer to organisms that rely largely on external heat to achieve a full working temperature, and to organisms that produce heat from within as a major factor in controlling their bodily temperature.\n\n"}
{"id": "10204", "url": "https://en.wikipedia.org/wiki?curid=10204", "title": "Elihu Yale", "text": "Elihu Yale\n\nElihu Yale (5 April 1649 – 8 July 1721) was a British merchant, philanthropist and slave trader, President of the East India Company settlement in Fort St. George, at Madras, and a benefactor of the Collegiate School in the Colony of Connecticut, which in 1718 was renamed Yale College in his honor.\n\nBorn in Boston, Massachusetts, to David Yale (1613–1690) and Ursula, he was the grandson of Ann Lloyd (1591–1659), who after the death of her first husband, Thomas Yale (1587–1619) in Chester, Cheshire, England, married Governor Theophilus Eaton (1590–1658) of New Haven Colony.\n\nYale's ancestry can be traced back to the family estate at Plas yn Iâl near the village of Llandegla, Denbighshire, Wales. The name Yale is the English spelling of the Welsh place name Iâl.\n\nThe Yale family left Boston and returned to England when Elihu was three years old and he grew up going to school in London.\n\nFor 20 years Yale served the Honourable East India Company. In 1684 he became the first president of Fort St. George, the company's post at Madras (now Chennai), India. He succeeded a number of agents from Andrew Cogan to William Gyfford. Yale was instrumental in the development of the Government General Hospital, housed at Fort St. George.\n\nYale amassed a fortune while working for the company, largely through secret contracts with Madras merchants, against the East India Company's directive. By 1692, his repeated flouting of East India Company regulations and growing embarrassment at his illegal profiteering resulted in his being relieved of the post of governor.\nYale returned to Britain in 1699. He spent the rest of his life at 'Plas Grono', a mansion bought by his father near Wrexham, Wales, or at his house in London, spending liberally the considerable wealth he had accumulated.\n\nYale married Catherine Hynmers, a widow, in 1680. The wedding took place at St. Mary's Church, at Fort St. George, where Yale was a vestryman and treasurer. The marriage was the first registered at the church.\n\nElihu Yale was re-appointed as president of the administration of Fort St George on 26 July 1687. He then implemented an order dated 14 January 1685 which required the English at Fort St George to make all attempts at procurement of the town of St Thome on lease. To this effect, Chinna Venkatadri was sent to negotiate with the local governor on 4 August 1687. The mission was successful and Chinna Venkatadri assumed sovereignty over St Thome for a period of three years. Notwithstanding the vehement protests of the Portuguese inhabitants of St Thome, the English gained absolute control over all lands up to St Thomas Mount for a period of three years.\n\nIn September 1688, the Mughal Emperor Aurangazeb took Golconda after a prolonged battle. The Mughals took Sultan of Golconda prisoner and annexed the state. The newly designated Mughal Subedar of the province immediately sent a letter to the British authorities at Fort St George demanding that the English at Madras acknowledge the overlordship of the Mughal Emperor. The English complied willingly. Aurangazeb guaranteed the independence of Madras, but in return demanded that the English supply troops in the event of a war against the Marathas. It was around this time that Yale's three-year-old son David Yale died and was interred in the Madras cemetery.\n\nThe records of this period mention a flourishing slave trade in Madras, a trade in which Yale participated and from which he profited. He enforced a law that at least ten slaves should be carried on every ship bound for Europe. In his capacity as judge he also on several occasions sentenced so-called \"black criminals\" to whipping and enslavement. When the demand began to increase rapidly, the English merchants even began to kidnap young children and deport them to distant parts of the world, very much against their will. At a time when profits from the slavetrade were dwindling and pressure from the Mughal government to stop the enslavement was mounting, the administration of Fort St George eventually stepped in and introduced laws to curb enslavement.\n\nDuring Yale's presidency, a plan for setting up a corporation in Madras was conceived by Josiah Child, the President of the Board of Directors of the East India Company, in a letter addressed to the factors at Madras on 28 September 1687. Three months later, Josiah Child and his deputy had an audience with James II, and as per the ensuing discussions, a Charter was issued by the king on 30 December 1687 which established the Corporation of Madras. The charter came into effect on 29 September 1688, and a Corporation was established comprising a Mayor, 12 Aldermen, 60-100 Burgesses and sergeants. Nathaniel Higginson, who was then the second member of the Council of Fort St George took office as the Mayor of Madras.\n\nIn August 1689, a French fleet appeared near the coast of Ceylon compelling the Governor of Pulicat Lawrence Pitt who was on high seas to seek protection within the bastions of Fort St George. Throughout the year 1690, French naval ships from Pondicherry ravaged the coast in order to drive the English and the Dutch out of the East Indies but were unsuccessful. They eventually withdrew from their enterprise when faced with heavy losses. It was also during this time that the English purchased the town of Tegnapatnam from the Marathas.\n\nAs president of Fort St. George, Yale purchased territory for private purposes with East India Company funds, including a fort at Tevnapatam (now Cuddalore). Yale imposed high taxes for the maintenance of the colonial garrison and town, resulting in an unpopular regime and several revolts by Indians, brutally quelled by garrison soldiers. Yale was also notorious for arresting and trying Indians on his own private authority, including the hanging of a stable boy who had absconded with a Company horse.\n\nCharges of corruption were brought against Elihu Yale in the last years of his Presidency. He was eventually removed in 1692 and replaced with Nathaniel Higginson as the President of Madras.\n\nYale died on 8 July 1721 in London, but was buried in the churchyard of the parish church of St. Giles in Wrexham. His tomb is inscribed with these lines:\n\nIn Boston, Massachusetts, a tablet to Yale was erected in 1927 at Scollay Square, near the site of Yale's birth. Yale president Arthur Twining Hadley penned the inscription, which reads: \"On Pemberton Hill, 255 Feet North of This Spot, Was Born on April Fifth 1649 Elihu Yale, Governor of Madras, Whose Permanent Memorial in His Native Land is the College That Bears His Name.\"\n\nIn 1718, Cotton Mather contacted Yale and asked for his help. Mather represented a small institution of learning that had been founded in 1701 in New Haven, Connecticut, as the Collegiate School of Connecticut, which needed money for a new building. Yale sent Mather 417 books, a portrait of King George I, and nine bales of goods. These last were sold by the school for £800 pound sterling, a substantial sum in the early 18th century. In gratitude, officials named the new building Yale; eventually the entire institution became Yale College.\n\nYale was also a vestryman and treasurer of St. Mary's Church at Fort St. George. On 6 October 1968, the 250th anniversary of the naming of Yale College for Elihu Yale, the classmates of Chester Bowles, then the American ambassador to India and a graduate of Yale (1924), donated money for lasting improvements to the church and erected a plaque to commemorate the occasion.\n\nOn 5 April 1999, Yale University recognized the 350th anniversary of Yale's birthday. An article that year in \"American Heritage\" magazine rated Elihu Yale the \"most overrated philanthropist\" in American history, arguing that the college that became Yale University was successful largely because of the generosity of a man named Jeremiah Dummer, but that the trustees of the school did not want it known by the name \"Dummer College\".\n\nIn her article for \"The Atlantic\" about Skull and Bones, a secret society at Yale University, Alexandra Robbins alleges that Yale's headstone was stolen years ago from its proper setting in Wrexham. She further alleges that the tombstone is now displayed in a glass case in a room with purple walls.\n\n\n\n \n"}
{"id": "10207", "url": "https://en.wikipedia.org/wiki?curid=10207", "title": "Émile Baudot", "text": "Émile Baudot\n\nJean-Maurice-Émile Baudot (11 September 1845 – 28 March 1903), French telegraph engineer and inventor of the first means of digital communication Baudot code, was one of the pioneers of telecommunications. He invented a multiplexed printing telegraph system that used his code and allowed multiple transmissions over a single line. The baud unit was named after him.\n\nBaudot was born in Magneux, Haute-Marne, France, the son of farmer Pierre Emile Baudot, who later became the mayor of Magneux. His only formal education was at his local primary school, after which he carried out agricultural work on his father's farm before joining the French Post & Telegraph Administration as an apprentice operator in 1869.\n\nThe telegraph service trained him in the Morse telegraph and also sent him on a four-month course of instruction on the Hughes printing telegraph system, which was later to inspire his own system.\n\nAfter serving briefly during the Franco-Prussian War, he returned to civilian duties in Paris in 1872.\n\nThe Telegraph Service encouraged Baudot to develop—on his own time—a system for time-multiplexing several telegraph messages using Hughes teleprinters. He realised that with most printing telegraphs of the period the line is idle for most of the time, apart from the brief intervals when a character is transmitted. Baudot devised one of the first applications of time-division multiplexing in telegraphy. Using synchronized clockwork-powered switches at the transmitting and receiving ends, he was able to transmit five messages simultaneously; the system was officially adopted by the French Post & Telegraph Administration five years later.\n\nBaudot invented his telegraph code in 1870 and patented it in 1874. It was a 5-bit code, with equal on and off intervals, which allowed telegraph transmission of the Roman alphabet, punctuation and control signals. By 1874 or 1875 (various sources give both dates) he had also perfected the electromechanical hardware to transmit his code. His inventions were based on the printing mechanism from Hughes' instrument, a distributor invented by Bernard Meyer in 1871, and the five-unit code devised by Carl Friedrich Gauss and Wilhelm Weber. Baudot combined these, together with original ideas of his own, to produce a complete multiplex system.\n\nOn 17 June 1874 Baudot patented his first printing telegraph (Patent no. 103,898 \"Système de télégraphie rapide\"), in which the signals were translated automatically into typographic characters. Baudot's hardware had three main parts: the keyboard, the distributor, and a paper tape.\n\nEach operator - there were as many as four - was allocated a single sector. The keyboard had just five piano type keys, operated with two fingers of the left hand and three fingers of the right hand. The five unit code was designed to be easy to remember. Once the keys had been pressed they were locked down until the contacts again passed over the sector connected to that particular keyboard, when the keyboard was unlocked ready for the next character to be entered, with an audible click (known as the \"cadence signal\") to warn the operator. Operators had to maintain a steady rhythm, and the usual speed of operation was 30 words per minute.\n\nThe receiver was also connected to the distributor. The signals from the telegraph line were temporarily stored on a set of five electromagnets, before being decoded to print the corresponding character on paper tape.\n\nAccurate operation of this system depended on the distributor at the transmitting end keeping in synchronization with the one at the receiving end and operators only sending characters when the contacts passed over their allocated sector. This could be achieved at a speed of 30 wpm by strictly observing the \"cadence\" of rhythm of the system when the distributor gave the operator the use of the line.\n\nThe Baudot system was accepted by the French Telegraph Administration in 1875, with the first online tests of his system occurring between Paris and Bordeaux on 12 November 1877. At the end of 1877, the Paris-Rome line, which was about , began operating a duplex Baudot.\n\nThe Baudot apparatus was shown at the Paris Exposition Universelle (1878) and won him the Exposition's gold medal, as well as bringing his system to worldwide notice.\n\nAfter the first success of his system, Baudot was promoted to Controller in 1880, and was named Inspector-Engineer in 1882.\n\nIn July 1887 he conducted successful tests on the Atlantic telegraph cable between Weston-super-Mare and Waterville, Nova Scotia operated by the Commercial Company, with a double Baudot installed in duplex, the Baudot transmitters and receivers substituted for the recorder.\n\nOn 8 August 1890 he established communications between Paris, Vannes, and Lorient over a single wire. On 3 January 1894 he installed a triplex apparatus on the telegraph between Paris and Bordeaux that had previously been operating with some difficulty on the Hughes telegraph system. On 27 April 1894 he established communications between the Paris stock exchange and the Milan stock exchange, again over a single wire, using his new invention, the retransmitter. The British Post Office adopted the Baudot system in 1897 for a simplex circuit between London and Paris.\n\nIn 1897 the Baudot system was improved by switching to punched tape, which was prepared offline like the Morse tape used with the Wheatstone and Creed systems. A tape reader, controlled by the Baudot distributor, then replaced the manual keyboard. The tape had five rows of holes for the code, with a sixth row of smaller holes for transporting the tape through the reader mechanism. Baudot’s code was later standardised as International Telegraph Alphabet Number One.\n\nBaudot received little help from the French Telegraph Administration for his system, and often had to fund his own research, even having to sell the gold medal awarded by the 1878 Exposition Universelle in 1880.\n\nThe Baudot telegraph system was employed progressively in France, and then was adopted in other countries, Italy being the first to introduce it, in its inland service, in 1887. The Netherlands followed in 1895, Switzerland in 1896, and Austria and Brazil in 1897. The British Post Office adopted it for a simplex circuit between London and Paris during 1897, then used it for more general purposes from 1898. In 1900 it was adopted by Germany, by Russia in 1904, the British West Indies in 1905, Spain in 1906, Belgium in 1909, Argentina in 1912, and Romania in 1913.\n\nBaudot married Marie Josephine Adelaide Langrognet on 15 January 1890. She died only three months later, on 9 April 1890.\n\nSoon after starting work with the telegraph service, Baudot began to suffer physical discomfort and was frequently absent from work for this reason, for as long as a month on one occasion. His condition affected him for the rest of his life, until he died on 28 March 1903, at Sceaux, Hauts-de-Seine, near Paris, at the age of 57.\n\nIn 1874, French telegraph operator Louis Victor Mimault patented a telegraph system using five separate lines to transmit. After his patent was rejected by the Telegraph Administration, Mimault modified his device to incorporate features from the Meyer telegraph and obtained a new patent which was also rejected. In the meantime, Baudot had patented his prototype telegraph a few weeks earlier.\n\nMimault claimed priority of invention over Baudot and brought a patent suit against him in 1877. The Tribunal Civil de la Seine, which reviewed testimony from three experts unconnected with the Telegraph Administration, found in favor of Mimault and accorded him priority of invention of the Baudot code and ruled that Baudot's patents were simply improvements of Mimault's. Neither inventor was satisfied with this judgment, which was eventually rescinded with Mimault being ordered to pay all legal costs.\n\nMimault became unnerved because of the decision, and after an incident where he shot at and wounded two students of the École Polytechnique (charges for which were dropped), he demanded a special act to prolong the duration of his patents, 100,000 Francs, and election to the Légion d'honneur. A commission directed by Jules Raynaud (head of telegraph research) rejected his demands. Upon hearing the decision, Mimault shot and killed Raynaud, and was sentenced to 10 years forced labour and 20 years of exile.\n\n\n\n"}
{"id": "10211", "url": "https://en.wikipedia.org/wiki?curid=10211", "title": "Economic security", "text": "Economic security\n\nEconomic security or financial security is the condition of having stable income or other resources to support a standard of living now and in the foreseeable future. It includes:\n\nFinancial security more often refers to individual and family money management and savings. Economic security tends to include the broader effect of a society's production levels and monetary support for non-working citizens.\n\nIn the United States, children's economic security is indicated by the income level and employment security of their families or organizations. Economic security of people over 50 years old is based on Social Security benefits, pensions and savings, earnings and employment, and health insurance coverage.\n\nIn 1972, the state legislature of Arizona formed a Department of Economic Security with a mission to promote \"the safety, well-being, and self sufficiency of children, adults, and families\". This department combines state government activities previously managed by the Employment Security Commission, the State Department of Public Welfare, the Division of Vocational Rehabilitation, the State Office of Economic Opportunity, the Apprenticeship Council, the State Office of Manpower Planning, and the State Department of Mental Retardation. The State Department of Mental Retardation (renamed the Division of Developmental Disabilities, House Bill 2213) joined the Department in 1974 . The purpose in creating the Department was to provide an integration of direct services to people in such a way as to reduce duplication of administrative efforts, services and expenditures. Family Connections became a part of the Department in January 2007.\n\nThe Minnesota Department of Economic Security was formed in 1977 from the departments of Employment Services and Vocational Rehabilitation, the Governor's Manpower Office, and the Economic Opportunity Office, which administered anti-poverty programs. In 1985, State Services for the Blind was included in this department. In 2003, the Minnesota Department of Economic Security and Minnesota Department of Trade and Economic Development were merged to form The Minnesota Department of Employment and Economic Development.\n\nEconomic security, in the context of politics and international relations, is the ability of a nation-state to follow its choice of policies to develop the national economy in the manner desired. Historically, conquest of nations have made conquerors rich through plunder, access to new resources and enlarged trade through controlling of the conquered nations'economy. In today's complex system of international trade, characterised by multi-national agreements, mutual inter-dependence and availability of natural resources etc., Economic security today forms, arguably, as important a part of national security as military policy.\n\nEconomic security has been proposed as a key determinant of international relations, particularly in the geopolitics of petroleum in American foreign policy after September 11, 2001.\n\nIn Canada, threats to the country's overall economic security are considered economic espionage, which is \"illegal, clandestine or coercive activity by a foreign government in order to gain unauthorized access to economic intelligence, such as proprietary information or technology, for economic advantage.\"\n\nIt is widely believed that there is a tradeoff between economic security and economic opportunity.\n"}
{"id": "10213", "url": "https://en.wikipedia.org/wiki?curid=10213", "title": "Enhanced Data Rates for GSM Evolution", "text": "Enhanced Data Rates for GSM Evolution\n\nEnhanced Data rates for GSM Evolution (EDGE) (also known as Enhanced GPRS (EGPRS), or IMT Single Carrier (IMT-SC), or Enhanced Data rates for Global Evolution) is a digital mobile phone technology that allows improved data transmission rates as a backward-compatible extension of GSM. EDGE is considered a pre-3G radio technology and is part of ITU's 3G definition. EDGE was deployed on GSM networks beginning in 2003 – initially by Cingular (now AT&T) in the United States.\n\nEDGE is standardized also by 3GPP as part of the GSM family. A variant, so called Compact-EDGE, was developed for use in a portion of Digital AMPS network spectrum.\n\nThrough the introduction of sophisticated methods of coding and transmitting data, EDGE delivers higher bit-rates per radio channel, resulting in a threefold increase in capacity and performance compared with an ordinary GSM/GPRS connection.\n\nEDGE can be used for any packet switched application, such as an Internet connection.\n\nEvolved EDGE continues in Release 7 of the 3GPP standard providing reduced latency and more than doubled performance e.g. to complement High-Speed Packet Access (HSPA). Peak bit-rates of up to 1 Mbit/s and typical bit-rates of 400 kbit/s can be expected.\n\nEDGE/EGPRS is implemented as a bolt-on enhancement for 2.5G GSM/GPRS networks, making it easier for existing GSM carriers to upgrade to it. EDGE is a superset to GPRS and can function on any network with GPRS deployed on it, provided the carrier implements the necessary upgrade.\nEDGE requires no hardware or software changes to be made in GSM core networks. EDGE-compatible transceiver units must be installed and the base station subsystem needs to be upgraded to support EDGE. If the operator already has this in place, which is often the case today, the network can be upgraded to EDGE by activating an optional software feature. Today EDGE is supported by all major chip vendors for both GSM and WCDMA/HSPA.\n\nIn addition to Gaussian minimum-shift keying (GMSK), EDGE uses higher-order PSK/8 phase shift keying (8PSK) for the upper five of its nine modulation and coding schemes. EDGE produces a 3-bit word for every change in carrier phase. This effectively triples the gross data rate offered by GSM. EDGE, like GPRS, uses a rate adaptation algorithm that adapts the modulation and coding scheme (MCS) according to the quality of the radio channel, and thus the bit rate and robustness of data transmission. It introduces a new technology not found in GPRS, Incremental Redundancy, which, instead of retransmitting disturbed packets, sends more redundancy information to be combined in the receiver. This increases the probability of correct decoding.\n\nEDGE can carry a bandwidth up to 236 kbit/s (with end-to-end latency of less than 150 ms) for 4 timeslots (theoretical maximum is 473.6 kbit/s for 8 timeslots) in packet mode. This means it can handle four times as much traffic as standard GPRS. EDGE meets the International Telecommunications Union's requirement for a 3G network, and has been accepted by the ITU as part of the IMT-2000 family of 3G standards. It also enhances the circuit data mode called HSCSD, increasing the data rate of this service.\n\nThe channel encoding process in GPRS as well as EGPRS/EDGE consists of two steps: first, a cyclic code is used to add parity bits, which are also referred to as the Block Check Sequence, followed by coding with a possibly punctured convolutional code. In GPRS, the Coding Schemes CS-1 to CS-4 specify the number of parity bits generated by the cyclic code and the puncturing rate of the convolutional code. In GPRS Coding Schemes CS-1 through CS-3, the convolutional code is of rate 1/2, i.e. each input bit is converted into two coded bits. In Coding Schemes CS-2 and CS-3, the output of the convolutional code is punctured to achieve the desired code rate. In GPRS Coding Scheme CS-4, no convolutional coding is applied.\n\nIn EGPRS/EDGE, the Modulation and Coding Schemes MCS-1 to MCS-9 take the place of the Coding Schemes of GPRS, and additionally specify which modulation scheme is used, GMSK or 8PSK. MCS-1 through MCS-4 use GMSK and have performance similar (but not equal) to GPRS, while MCS-5 through MCS-9 use 8PSK. In all EGPRS Modulation and Coding Schemes, a convolutional code of rate 1/3 is used, and puncturing is used to achieve the desired code rate. In contrast to GPRS, the Radio Link Control (RLC) and Media Access Control (MAC) headers and the payload data are coded separately in EGPRS. The headers are coded more robustly than the data.\n\nEvolved EDGE, also called EDGE Evolution, is a bolt-on extension to the GSM mobile telephony standard, which improves on EDGE in a number of ways. Latencies are reduced by lowering the Transmission Time Interval by half (from 20 ms to 10 ms). Bit rates are increased up to 1 Mbit/s peak bandwidth and latencies down to 80 ms using dual carrier, higher symbol rate and higher-order modulation (32QAM and 16QAM instead of 8PSK), and turbo codes to improve error correction. This results in real world downlink speeds of up to 600kbit/s. Further the signal quality is improved using dual antennas improving average bit-rates and spectrum efficiency.\n\nThe main intention of increasing the existing EDGE throughput is that many operators would like to upgrade their existing infrastructure rather than invest on new network infrastructure. Mobile operators have invested billions in GSM networks, many of which are already capable of supporting EDGE data speeds up to 236.8 kbit/s. With a software upgrade and a new device compliant with Evolved EDGE (like an Evolved EDGE smart phone) for the user, these data rates can be boosted to speeds approaching 1 Mbit/s (i.e. 98.6 kbit/s per timeslot for 32QAM). Many service providers may not invest on a completely new technology like 3G networks.\n\nConsiderable research and development happened throughout the world for this new technology. A successful trial by Nokia Siemens and \"one of China's leading operators\" has been achieved in a live environment. With the introduction for more advanced wireless technologies like UMTS and LTE, which also focus on a network coverage layer on low frequencies and the upcoming phase-out and shutdown of 2G mobile networks, it is very unlikely that Evolved EDGE will ever see any deployment on live networks. Up to now (as of 2016) there are no commercial networks which support the Evolved EDGE standard (3GPP Rel-7).\n\nWith Evolved EDGE come three major features designed to reduce latency over the air interface.\n\nIn EDGE, a single RLC data block (ranging from 23 to 148 bytes of data) is transmitted over four frames, using a single time slot. On average, this requires 20 ms for one way transmission. Under the RTTI scheme, one data block is transmitted over two frames in two timeslots, reducing the latency of the air interface to 10 ms.\n\nIn addition, Reduced Latency also implies support of Piggy-backed ACK/NACK (PAN), in which a bitmap of blocks not received is included in normal data blocks. Using the PAN field, the receiver may report missing data blocks immediately, rather than waiting to send a dedicated PAN message.\n\nA final enhancement is RLC-non persistent mode. With EDGE, the RLC interface could operate in either acknowledged mode, or unacknowledged mode. In unacknowledged mode, there is no retransmission of missing data blocks, so a single corrupt block would cause an entire upper-layer IP packet to be lost. With non-persistent mode, an RLC data block may be retransmitted if it is less than a certain age. Once this time expires, it is considered lost, and subsequent data blocks may then be forwarded to upper layers.\n\nWith Downlink Dual Carrier, the handheld is able to receive on two different frequency channels at the same time, doubling the downlink throughput. In addition, if second receiver is present then the handheld is able to receive on an additional timeslot in single-carrier mode, because it may overlap the tuning of one receiver with other tasks.\n\nBoth uplink and downlink throughput is improved by using 16 or 32 QAM (Quadrature Amplitude Modulation), along with turbo codes and higher symbol rates.\n\nThe Global mobile Suppliers Association (GSA) states that, as of May 2013, there were 604 GSM/EDGE networks in 213 countries, from a total of 606 mobile network operator commitments in 213 countries.\n\n\n"}
{"id": "10216", "url": "https://en.wikipedia.org/wiki?curid=10216", "title": "Eth", "text": "Eth\n\nEth (, uppercase: Ð, lowercase: ð; also spelled edh or eð) is a letter used in Old English, Middle English, Icelandic, Faroese (in which it is called \"edd\"), and Elfdalian. It was also used in Scandinavia during the Middle Ages but was subsequently replaced with \"dh\" and later \"d\". It is often transliterated as \"d\" (and \"d-\" is rarely used as a mnemonic). The lowercase version has been adopted to represent a voiced dental fricative in the International Phonetic Alphabet.\n\nIn Old English, \"ð\" (called \"\" by the Anglo-Saxons) was used interchangeably with \"þ\" to represent the Old English dental fricative phoneme , which exists in modern English phonology as the voiced and voiceless dental fricatives now spelled 'th'.\n\nUnlike the runic letter þ, ð is a modified Roman letter. ð was not found in the earliest records of Old English. A study of Mercian royal diplomas found that ð (along with đ) began to emerge in the early 8th century, with ð becoming strongly preferred by the 780s. Another source indicates that the letter is 'derived from Irish writing.'\n\nThe lowercase version has retained the curved shape of a medieval scribe's \"d\", which \"d\" itself in general has not. \"ð\" was used throughout the Anglo-Saxon era but gradually fell out of use in Middle English, practically disappearing altogether by 1300; \"þ\" survived longer, ultimately being replaced by the digraph \"th\".\nIn Icelandic, \"ð\" represents a (usually apical) voiced alveolar non-sibilant fricative , similar to the \"th\" in English \"that\", but it never appears as the first letter of a word, where \"þ\" is used in its stead. The name of the letter is pronounced in isolation (and before words beginning with a voiceless consonant) as and therefore with a voiceless rather than voiced fricative.\n\nIn Faroese, \"ð\" is not assigned to any particular phoneme and appears mostly for etymological reasons; however, it does show where most of the Faroese glides are; when \"ð\" appears before \"r\", it is, in a few words, pronounced . In the Icelandic and Faroese alphabets, \"ð\" follows \"d\".\n\nIn 's version of based on , \"ð\" was always silent and was introduced for etymological reasons.\n\n\"Ð\" has also been used by some in written Welsh to represent , which is normally represented as \"dd\".\n\n\n\nNotes\nBibliography\n\n"}
{"id": "10217", "url": "https://en.wikipedia.org/wiki?curid=10217", "title": "Eth, Nord", "text": "Eth, Nord\n\nEth is a commune in the Nord department in northern France.\n\nIt is about east-southeast of Valenciennes. Residents are called Ethois (feminine plural Ethoises).\n\n\n"}
{"id": "10221", "url": "https://en.wikipedia.org/wiki?curid=10221", "title": "Euphrates", "text": "Euphrates\n\nThe Euphrates (; Sumerian: : \"Buranuna\", : \"Purattu\", : \"al-Furāt\", : \"Pǝrāt\", : \"Yeprat\", : \"Perat\", , ) is the longest and one of the most historically important rivers of Western Asia. Together with the Tigris, it is one of the two defining rivers of Mesopotamia (the \"Land between the Rivers\"). Originating in eastern Turkey, the Euphrates flows through Syria and Iraq to join the Tigris in the Shatt al-Arab, which empties into the Persian Gulf.\n\nThe Ancient Greek form \"Euphrátēs\" () was borrowed from Old Persian \"Ufrātu\", itself from Elamite \"ú-ip-ra-tu-iš\". The Elamite name is ultimately derived from the Sumerian \"Buranuna\", possibly through the Akkadian name. In Akkadian the river was similarly called \"Purattu\", which has been perpetuated in Semitic languages (cf. Syriac \"P(ə)rāṯ\", Arabic \"al-Furrāt\") and in other nearby languages of the time (cf. Hurrian \"Puranti\", Sabarian \"Uruttu\"). The Elamite, Akkadian, and possibly Sumerian forms are suggested to be from an unrecorded substrate language. Gamkrelidze and Ivanov suggest the Proto-Sumerian *burudu \"copper\" (Sumerian \"urudu\") as an origin, with an explanation that Euphrates was the river by which the copper ore was transported in rafts, since Mesopotamia was the center of copper metallurgy during the period.\n\nThe earliest references to the Euphrates come from cuneiform texts found in Shuruppak and pre-Sargonic Nippur in southern Iraq and date to the mid-3rd millennium BCE. In these texts, written in Sumerian, the Euphrates is called \"Buranuna\" (logographic: UD.KIB.NUN). The name could also be written KIB.NUN.(NA) or KIB.NUN, with the prefix \"\" indicating that the river was a divinity. In Sumerian, the name of the city of Sippar in modern-day Iraq was also a written UD.KIB.NUN, indicating a historically strong relationship between the city and the river.\n\nThe Euphrates is the longest river of Western Asia. It emerges from the confluence of the Kara Su or Western Euphrates () and the Murat Su or Eastern Euphrates () upstream from the town of Keban in southeastern Turkey. Daoudy and Frenken put the length of the Euphrates from the source of the Murat River to the confluence with the Tigris at , of which falls in Turkey, in Syria and in Iraq. The same figures are given by Isaev and Mikhailova. The length of the Shatt al-Arab, which connects the Euphrates and the Tigris with the Persian Gulf, is given by various sources as .\n\nBoth the Kara Su and the Murat Su rise northwest from Lake Van at elevations of and amsl, respectively. At the location of the Keban Dam, the two rivers, now combined into the Euphrates, have dropped to an elevation of amsl. From Keban to the Syrian–Turkish border, the river drops another over a distance of less than . Once the Euphrates enters the Upper Mesopotamian plains, its grade drops significantly; within Syria the river falls while over the last stretch between Hīt and the Shatt al-Arab the river drops only .\n\nThe Euphrates receives most of its water in the form of rainfall and melting snow, resulting in peak volumes during the months April through May. Discharge in these two months accounts for 36 percent of the total annual discharge of the Euphrates, or even 60–70 percent according to one source, while low runoff occurs in summer and autumn. The average natural annual flow of the Euphrates has been determined from early- and mid-twentieth century records as at Keban, at Hīt and at Hindiya. However, these averages mask the high inter-annual variability in discharge; at Birecik, just north of the Syro–Turkish border, annual discharges have been measured that ranged from a low volume of in 1961 to a high of in 1963.\n\nThe discharge regime of the Euphrates has changed dramatically since the construction of the first dams in the 1970s. Data on Euphrates discharge collected after 1990 show the impact of the construction of the numerous dams in the Euphrates and of the increased withdrawal of water for irrigation. Average discharge at Hīt after 1990 has dropped to per second ( per year). The seasonal variability has equally changed. The pre-1990 peak volume recorded at Hīt was per second, while after 1990 it is only per second. The minimum volume at Hīt remained relatively unchanged, rising from per second before 1990 to per second afterward.\n\nIn Syria, three rivers add their water to the Euphrates; the Sajur, the Balikh and the Khabur. These rivers rise in the foothills of the Taurus Mountains along the Syro–Turkish border and add comparatively little water to the Euphrates. The Sajur is the smallest of these tributaries; emerging from two streams near Gaziantep and draining the plain around Manbij before emptying into the reservoir of the Tishrin Dam. The Balikh receives most of its water from a karstic spring near 'Ayn al-'Arus and flows due south until it reaches the Euphrates at the city of Raqqa. In terms of length, drainage basin and discharge, the Khabur is the largest of these three. Its main karstic springs are located around Ra's al-'Ayn, from where the Khabur flows southeast past Al-Hasakah, where the river turns south and drains into the Euphrates near Busayrah. Once the Euphrates enters Iraq, there are no more natural tributaries to the Euphrates, although canals connecting the Euphrates basin with the Tigris basin exist.\n\nThe drainage basins of the Kara Su and the Murat River cover an area of and , respectively. The estimates that have been made for the area of the Euphrates drainage basin vary widely; from a low to a high . Recent estimates put the basin area at , and . The greater part of the Euphrates basin is located in Turkey, Syria, and Iraq. According to both Daoudy and Frenken, Turkey's share is 28 percent, Syria's is 17 percent and that of Iraq is 40 percent. Isaev and Mikhailova estimate the percentages of the drainage basin lying within Turkey, Syria and Iraq at 33, 20 and 47 percent respectively. Some sources estimate that approximately 15 percent of the drainage basin is located within Saudi Arabia, while a small part falls inside the borders of Kuwait. Finally, some sources also include Jordan in the drainage basin of the Euphrates; a small part of the eastern desert () drains toward the east rather than to the west.\n\nThe Euphrates flows through a number of distinct vegetation zones. Although millennia-long human occupation in most parts of the Euphrates basin has significantly degraded the landscape, patches of original vegetation remain. The steady drop in annual rainfall from the sources of the Euphrates toward the Persian Gulf is a strong determinant for the vegetation that can be supported. In its upper reaches the Euphrates flows through the mountains of Southeast Turkey and their southern foothills which support a xeric woodland. Plant species in the moister parts of this zone include various oaks, pistachio trees, and \"Rosaceae\" (rose/plum family). The drier parts of the xeric woodland zone supports less dense oak forest and \"Rosaceae\". Here can also be found the wild variants of many cereals, including einkorn wheat, emmer wheat, oat and rye. South of this zone lies a zone of mixed woodland-steppe vegetation. Between Raqqa and the Syro–Iraqi border the Euphrates flows through a steppe landscape. This steppe is characterised by white wormwood (\"Artemisia herba-alba\") and \"Chenopodiaceae\". Throughout history, this zone has been heavily overgrazed due to the practicing of sheep and goat pastoralism by its inhabitants. Southeast of the border between Syria and Iraq starts true desert. This zone supports either no vegetation at all or small pockets of \"Chenopodiaceae\" or \"Poa sinaica\". Although today nothing of it survives due to human interference, research suggests that the Euphrates Valley would have supported a riverine forest. Species characteristic of this type of forest include the Oriental plane, the Euphrates poplar, the tamarisk, the ash and various wetland plants.\n\nAmong the fish species in the Tigris–Euphrates basin, the family of the Cyprinidae are the most common, with 34 species out of 52 in total. Among the Cyprinids, the mangar has good sport fishing qualities, leading the British to nickname it \"Tigris salmon.\" The \"Rafetus euphraticus\" is an endangered soft-shelled turtle that is limited to the Tigris–Euphrates river system.\n\nThe Neo-Assyrian palace reliefs from the 1st millennium BCE depict lion and bull hunts in fertile landscapes. Sixteenth to nineteenth century European travellers in the Syrian Euphrates basin reported on an abundance of animals living in the area, many of which have become rare or even extinct. Species like gazelle, onager and the now-extinct Arabian ostrich lived in the steppe bordering the Euphrates valley, while the valley itself was home to the wild boar. Carnivorous species include the gray wolf, the golden jackal, the red fox, the leopard and the lion. The Syrian brown bear can be found in the mountains of Southeast Turkey. The presence of European beaver has been attested in the bone assemblage of the prehistoric site of Abu Hureyra in Syria, but the beaver has never been sighted in historical times.\n\nThe Hindiya Barrage on the Iraqi Euphrates, based on plans by British civil engineer William Willcocks and finished in 1913, was the first modern water diversion structure built in the Tigris–Euphrates river system. The Hindiya Barrage was followed in the 1950s by the Ramadi Barrage and the nearby Abu Dibbis Regulator, which serve to regulate the flow regime of the Euphrates and to discharge excess flood water into the depression that is now Lake Habbaniyah. Iraq's largest dam on the Euphrates is the Haditha Dam; a earth-fill dam creating Lake Qadisiyah. Syria and Turkey built their first dams in the Euphrates in the 1970s. The Tabqa Dam in Syria was completed in 1973 while Turkey finished the Keban Dam, a prelude to the immense Southeastern Anatolia Project, in 1974. Since then, Syria has built two more dams in the Euphrates, the Baath Dam and the Tishrin Dam, and plans to build a fourth dam – the Halabiye Dam – between Raqqa and Deir ez-Zor. The Tabqa Dam is Syria's largest dam and its reservoir (Lake Assad) is an important source of irrigation and drinking water. It was planned that should be irrigated from Lake Assad, but in 2000 only had been realized. Syria also built three smaller dams on the Khabur and its tributaries.\n\nWith the implementation of the Southeastern Anatolia Project (\"Güneydoğu Anadolu Projesi\", or \"GAP\") in the 1970s, Turkey launched an ambitious plan to harness the waters of the Tigris and the Euphrates for irrigation and hydroelectricity production and provide an economic stimulus to its southeastern provinces. GAP affects a total area of and approximately 7 million people; representing about 10 percent of Turkey's total surface area and population, respectively. When completed, GAP will consist of 22 dams – including the Keban Dam – and 19 power plants and provide irrigation water to of agricultural land, which is about 20 percent of the irrigable land in Turkey. C. of this irrigated land is located in the Euphrates basin. By far the largest dam in GAP is the Atatürk Dam, located c. northwest of Şanlıurfa. This and dam was completed in 1992; thereby creating a reservoir that is the third-largest lake in Turkey. With a maximum capacity of , the Atatürk Dam reservoir is large enough to hold the entire annual discharge of the Euphrates. Completion of GAP was scheduled for 2010 but has been delayed because the World Bank has withheld funding due to the lack of an official agreement on water sharing between Turkey and the downstream states on the Euphrates and the Tigris.\n\nApart from barrages and dams, Iraq has also created an intricate network of canals connecting the Euphrates with Lake Habbaniyah, Lake Tharthar, and Abu Dibbis reservoir; all of which can be used to store excess floodwater. Via the Shatt al-Hayy, the Euphrates is connected with the Tigris. The largest canal in this network is the Main Outfall Drain or so-called \"Third River;\" constructed between 1953 and 1992. This canal is intended to drain the area between the Euphrates and the Tigris south of Baghdad to prevent soil salinization from irrigation. It also allows large freight barges to navigate up to Baghdad.\n\nThe construction of the dams and irrigation schemes on the Euphrates has had a significant impact on the environment and society of each riparian country. The dams constructed as part of GAP – in both the Euphrates and the Tigris basins – have affected 382 villages and almost 200,000 people have been resettled elsewhere. The largest number of people was displaced by the building of the Atatürk Dam, which alone affected 55,300 people. A survey among those who were displaced showed that the majority were unhappy with their new situation and that the compensation they had received was considered insufficient. The flooding of Lake Assad led to the forced displacement of c. 4,000 families, who were resettled in other parts of northern Syria as part of a now abandoned plan to create an \"Arab belt\" along the borders with Turkey and Iraq.\n\nApart from the changes in the discharge regime of the river, the numerous dams and irrigation projects have also had other effects on the environment. The creation of reservoirs with large surfaces in countries with high average temperatures has led to increased evaporation; thereby reducing the total amount of water that is available for human use. Annual evaporation from reservoirs has been estimated at in Turkey, in Syria and in Iraq. Water quality in the Iraqi Euphrates is low because irrigation water tapped in Turkey and Syria flows back into the river, together with dissolved fertilizer chemicals used on the fields. The salinity of Euphrates water in Iraq has increased as a result of upstream dam construction, leading to lower suitability as drinking water. The many dams and irrigation schemes, and the associated large-scale water abstraction, have also had a detrimental effect on the ecologically already fragile Mesopotamian Marshes and on freshwater fish habitats in Iraq.\n\nThe inundation of large parts of the Euphrates valley, especially in Turkey and Syria, has led to the flooding of many archaeological sites and other places of cultural significance. Although concerted efforts have been made to record or save as much of the endangered cultural heritage as possible, many sites are probably lost forever. The combined GAP projects on the Turkish Euphrates have led to major international efforts to document the archaeological and cultural heritage of the endangered parts of the valley. Especially the flooding of Zeugma with its unique Roman mosaics by the reservoir of the Birecik Dam has generated much controversy in both the Turkish and international press. The construction of the Tabqa Dam in Syria led to a large international campaign coordinated by UNESCO to document the heritage that would disappear under the waters of Lake Assad. Archaeologists from numerous countries excavated sites ranging in date from the Natufian to the Abbasid period, and two minarets were dismantled and rebuilt outside the flood zone. Important sites that have been flooded or affected by the rising waters of Lake Assad include Mureybet, Emar and Abu Hureyra. A similar international effort was made when the Tishrin Dam was constructed, which led, among others, to the flooding of the important Pre-Pottery Neolithic B site of Jerf el-Ahmar. An archaeological survey and rescue excavations were also carried out in the area flooded by Lake Qadisiya in Iraq. Parts of the flooded area have recently become accessible again due to the drying up of the lake, resulting not only in new possibilities for archaeologists to do more research, but also providing opportunities for looting, which has been rampant elsewhere in Iraq in the wake of the 2003 invasion.\n\nThe early occupation of the Euphrates basin was limited to its upper reaches; that is, the area that is popularly known as the Fertile Crescent. Acheulean stone artifacts have been found in the Sajur basin and in the El Kowm oasis in the central Syrian steppe; the latter together with remains of \"Homo erectus\" that were dated to 450,000 years old. In the Taurus Mountains and the upper part of the Syrian Euphrates valley, early permanent villages such as Abu Hureyra – at first occupied by hunter-gatherers but later by some of the earliest farmers, Jerf el-Ahmar, Mureybet and Nevalı Çori became established from the eleventh millennium BCE onward. In the absence of irrigation, these early farming communities were limited to areas where rainfed agriculture was possible, that is, the upper parts of the Syrian Euphrates as well as Turkey. Late Neolithic villages, characterized by the introduction of pottery in the early 7th millennium BCE, are known throughout this area. Occupation of lower Mesopotamia started in the 6th millennium and is generally associated with the introduction of irrigation, as rainfall in this area is insufficient for dry agriculture. Evidence for irrigation has been found at several sites dating to this period, including Tell es-Sawwan. During the 5th millennium BCE, or late Ubaid period, northeastern Syria was dotted by small villages, although some of them grew to a size of over . In Iraq, sites like Eridu and Ur were already occupied during the Ubaid period. Clay boat models found at Tell Mashnaqa along the Khabur indicate that riverine transport was already practiced during this period. The Uruk period, roughly coinciding with the 4th millennium BCE, saw the emergence of truly urban settlements across Mesopotamia. Cities like Tell Brak and Uruk grew to over in size and displayed monumental architecture. The spread of southern Mesopotamian pottery, architecture and sealings far into Turkey and Iran has generally been interpreted as the material reflection of a widespread trade system aimed at providing the Mesopotamian cities with raw materials. Habuba Kabira on the Syrian Euphrates is a prominent example of a settlement that is interpreted as an Uruk colony.\n\nDuring the Jemdet Nasr (3600–3100 BCE) and Early Dynastic periods (3100–2350 BCE), southern Mesopotamia experienced a growth in the number and size of settlements, suggesting strong population growth. These settlements, including Sumero-Akkadian sites like Sippar, Uruk, Adab and Kish, were organized in competing city-states. Many of these cities were located along canals of the Euphrates and the Tigris that have since dried up, but that can still be identified from remote sensing imagery. A similar development took place in Upper Mesopotamia, Subartu and Assyria, although only from the mid 3rd millennium and on a smaller scale than in Lower Mesopotamia. Sites like Ebla, Mari and Tell Leilan grew to prominence for the first time during this period.\n\nLarge parts of the Euphrates basin were for the first time united under a single ruler during the Akkadian Empire (2335–2154 BC) and Ur III empires, which controlled – either directly or indirectly through vassals – large parts of modern-day Iraq and northeastern Syria. Following their collapse, the Old Assyrian Empire (1975–1750 BCE) and Mari asserted their power over northeast Syria and northern Mesopotamia, while southern Mesopotamia was controlled by city-states like Isin, Kish and Larsa before their territories were absorbed by the newly emerged state of Babylonia under Hammurabi in the early to mid 18th century BCE.\n\nIn the second half of the 2nd millennium BCE, the Euphrates basin was divided between Kassite Babylon in the south and Mitanni, Assyria and the Hittite Empire in the north, with the Middle Assyrian Empire (1365–1020 BC) eventually eclipsing the Hittites, Mitanni and Kassite Babylonians. Following the end of the Middle Assyrian Empire in the late 11th century BCE, struggles broke out between Babylonia and Assyria over the control of the Iraqi Euphrates basin. The Neo-Assyrian Empire (935–605 BC) eventually emerged victorious out of this conflict and also succeeded in gaining control of the northern Euphrates basin in the first half of the 1st millennium BCE.\n\nIn the centuries to come, control of the wider Euphrates basin shifted from the Neo-Assyrian Empire (which collapsed between 612 and 599 BC) to the short lived Median Empire (612–546 BC) and equally brief Neo-Babylonian Empire (612–539 BC) in the last years of the 7th century BC, and eventually to the Achaemenid Empire (539–333 BC). The Achaemenid Empire was in turn overrun by Alexander the Great, who defeated the last king Darius III and died in Babylon in 323 BCE.\n\nSubsequent to this, the region came under the control of the Seleucid Empire (312–150 BC), Parthian Empire (150–226 AD) (during which several Neo-Assyrian states such as Osroene and Adiabene came to rule certain regions of the Euphrates), and was fought over by the Roman Empire, its succeeding Byzantine Empire and the Sassanid Empire (226–638 AD), until the Arab invasion and accompanying Islamic conquest of the mid 7th century AD.\n\nAfter World War I, the borders in Southwest Asia were redrawn in the Treaty of Lausanne, when the Ottoman Empire was partitioned. Clause 109 of the treaty stipulated that the three riparian states of the Euphrates (at that time Turkey, France for its Syrian mandate and the United Kingdom for its mandate of Iraq) had to reach a mutual agreement on the use of its water and on the construction of any hydraulic installation. An agreement between Turkey and Iraq signed in 1946 required Turkey to report to Iraq on any hydraulic changes it made on the Tigris–Euphrates river system, and allowed Iraq to construct dams on Turkish territory to manage the flow of the Euphrates.\n\nTurkey and Syria completed their first dams on the Euphrates – the Keban Dam and the Tabqa Dam, respectively – within one year of each other and filling of the reservoirs commenced in 1975. At the same time, the area was hit by severe drought and river flow toward Iraq was reduced from in 1973 to in 1975. This led to an international crisis during which Iraq threatened to bomb the Tabqa Dam. An agreement was eventually reached between Syria and Iraq after intervention by Saudi Arabia and the Soviet Union. A similar crisis, although not escalating to the point of military threats, occurred in 1981 when the Keban Dam reservoir had to be refilled after it had been almost emptied to temporarily increase Turkey's hydroelectricity production. In 1984, Turkey unilaterally declared that it would ensure a flow of at least per second, or per year, into Syria, and in 1987 a bilateral treaty to that effect was signed between the two countries. Another bilateral agreement from 1989 between Syria and Iraq settles the amount of water flowing into Iraq at 60 percent of the amount that Syria receives from Turkey. In 2008, Turkey, Syria and Iraq instigated the Joint Trilateral Committee (JTC) on the management of the water in the Tigris–Euphrates basin and on 3 September 2009 a further agreement was signed to this effect.\nOn April 15, 2014, Turkey began to reduce the flow of the Euphrates into Syria and Iraq. The flow was cut off completely on May 16, 2014. The Euphrates now terminates at the Turkish–Syrian border. This is in violation of an agreement reached in 1987 in which Turkey committed to releasing a minimum of of water per second at the Turkish–Syrian border.\n\nThroughout history, the Euphrates has been of vital importance to those living along its course. With the construction of large hydropower stations, irrigation schemes, and pipelines capable of transporting water over large distances, many more people now depend on the river for basic amenities such as electricity and drinking water than in the past. Syria's Lake Assad is the most important source of drinking water for the city of Aleppo, to the west of the river valley. The lake also supports a modest state-operated fishing industry. Through a newly restored power line, the Haditha Dam in Iraq provides electricity to Baghdad.\n\n"}
{"id": "10223", "url": "https://en.wikipedia.org/wiki?curid=10223", "title": "Estonian language", "text": "Estonian language\n\nEstonian ( ) is the official language of Estonia, spoken natively by about 922,000 people in Estonia and 160,000 outside Estonia. It belongs to the Finnic branch of the Uralic language family.\n\nEstonian belongs to the Finnic branch of the Uralic languages, along with Finnish, Karelian, and other nearby languages. The Uralic languages do not belong to the Indo-European languages. Estonian is distantly related to Hungarian and to the Sami languages.\n\nEstonian has been influenced by Swedish, German (initially Middle Low German, which was the lingua franca of the Hanseatic League and spoken natively in the area known today as Estonia by a sizeable burgher community of Baltic Germans, and later, standard German), and Russian, though it is not related to them genetically.\n\nLike Finnish and Hungarian, Estonian is a predominantly agglutinative language, but unlike them, it has lost vowel harmony, the front vowels occurring exclusively on the first or stressed syllable, although in older texts the vowel harmony can still be recognized. Furthermore, the loss of word-final sounds is extensive, and this has made its inflectional morphology a markedly more fusional than the rest of the language, especially with respect to noun and adjective inflection. Word order is considerably more flexible than English, but the basic order is subject–verb–object.\n\nThe two different historical Estonian languages (sometimes considered dialects), the North and South Estonian languages, are based on the ancestors of modern Estonians' migration into the territory of Estonia in at least two different waves, both groups speaking considerably different Finnic vernaculars. Modern standard Estonian has evolved on the basis of the dialects of Northern Estonia.\n\nThe domination of Estonia after the Northern Crusades, from the 13th century to 1918 by Denmark, Germany, Sweden, and Russia delayed indigenous literacy in Estonia. \nThe oldest written records of the Finnic languages of Estonia date from the 13th century. \"Originates Livoniae\" in Chronicle of Henry of Livonia contains Estonian place names, words and fragments of sentences.\n\nThe earliest extant samples of connected (north) Estonian are the so-called Kullamaa prayers dating from 1524 and 1528. In 1525 the first book published in the Estonian language was printed. The book was a Lutheran manuscript, which never reached the reader and was destroyed immediately after publication.\n\nThe first extant Estonian book is a bilingual German-Estonian translation of the Lutheran catechism by S.Wanradt and J.Koell dating to 1535, during the Protestant Reformation period. An Estonian grammar book to be used by priests was printed in German in 1637. The New Testament was translated into southern Estonian in 1686 (northern Estonian, 1715). The two languages were united based on northern Estonian by Anton thor Helle.\n\nWritings in Estonian became more significant in the 19th century during the Estophile Enlightenment Period (1750–1840).\n\nThe birth of native Estonian literature was in 1810 to 1820 when the patriotic and philosophical poems by Kristjan Jaak Peterson were published. Peterson, who was the first student at the then German-language University of Dorpat to acknowledge his Estonian origin, is commonly regarded as a herald of Estonian national literature and considered the founder of modern Estonian poetry. His birthday, March 14, is celebrated in Estonia as Mother Tongue Day. A fragment from Peterson's poem \"Kuu\" expresses the claim reestablishing the birthright of the Estonian language:\n\nIn English:\nIn the period from 1525 to 1917, 14,503 titles were published in Estonian; by comparison, between 1918 and 1940, 23,868 titles were published.\n\nIn modern times Jaan Kross and Jaan Kaplinski remain as two of Estonia's best known and most translated writers.\n\nWritings in Estonian became significant only in the 19th century with the spread of the ideas of the Age of Enlightenment, during the Estophile Enlightenment Period (1750–1840). Although Baltic Germans at large regarded the future of Estonians as being a fusion with themselves, the Estophile educated class admired the ancient culture of the Estonians and their era of freedom before the conquests by Danes and Germans in the 13th century.\n\nAfter the Estonian War of Independence in 1919, the Estonian language became the state language of the newly independent country. In 1945, 97.3% of Estonia considered itself ethnic Estonian and spoke the language.\n\nWhen Estonia was invaded and occupied by the Soviet Union in World War II, the status of the Estonian language changed to the first of two official languages (Russian being the other one). As with Latvia many immigrants entered Estonia under Soviet encouragement. In the second half of the 1970s, the pressure of bilingualism (for Estonians) intensified, resulting in widespread knowledge of Russian throughout the country. The Russian language was termed as ‘the language of friendship of nations’ and was taught to Estonian children, sometimes as early as in kindergarten. Although teaching Estonian to non-Estonians in schools was compulsory, in practice learning the language was often considered unnecessary.\n\nDuring the Perestroika era, The Law on the Status of the Estonian Language was adopted in January 1989. The 1991 collapse of the Soviet Union led to the restoration of Republic of Estonia's independence. Estonian went back to being the only state language in Estonia which in practice meant that use of Estonian was promoted while the use of Russian was discouraged.\n\nThe return of Soviet immigrants to their countries of origin has brought the proportion of Estonians in Estonia back above 70%. And again as in Latvia, today many of the remnant non-Estonians in Estonia have adopted the Estonian language; about 40% at the 2000 census.\n\nThe Estonian dialects are divided into two groups – the northern and southern dialects, historically associated with the cities of Tallinn in the north and Tartu in the south, in addition to a distinct \"kirderanniku\" dialect, Northeastern coastal Estonian.\n\nThe northern group consists of the \"keskmurre\" or central dialect that is also the basis for the standard language, the \"läänemurre\" or western dialect, roughly corresponding to Lääne County and Pärnu County, the \"saarte murre\" (islands') dialect of Saaremaa and Hiiumaa and the \"idamurre\" or eastern dialect on the northwestern shore of Lake Peipus.\n\nSouth Estonian consists of the Tartu, Mulgi, Võro and Seto varieties. These are sometimes considered either variants of South Estonian or separate languages altogether. Also, Seto and Võro distinguish themselves from each other less by language and more by their culture and their respective Christian confession.\n\nLike Finnish, Estonian employs the Latin script as the basis for its alphabet, which adds the letters \"ä\", \"ö\", \"ü\", and \"õ\", plus the later additions \"š\" and \"ž\". The letters \"c\", \"q\", \"w\", \"x\" and \"y\" are limited to proper names of foreign origin, and \"f\", \"z\", \"š\", and \"ž\" appear in loanwords and foreign names only. \"Ö\" and \"ü\" are pronounced similarly to their equivalents in Swedish and German. Unlike in standard German but like Finnish and Swedish (when followed by 'r'), \"Ä\" is pronounced [æ], as in English \"mat\". The vowels Ä, Ö and Ü are clearly separate phonemes and inherent in Estonian, although the letter shapes come from German. The letter \"õ\" denotes , unrounded , or a close-mid back unrounded vowel. It is almost identical to the Bulgarian ъ and the Vietnamese ơ, and is used to transcribe the Russian ы.\n\nAlthough the Estonian orthography is generally guided by phonemic principles, with each grapheme corresponding to one phoneme, there are some historical and morphological deviations from this: for example preservation of the morpheme in declension of the word (writing b, g, d in places where p, k, t is pronounced) and in the use of 'i' and 'j'. Where it is very impractical or impossible to type \"š\" and \"ž\", they are substituted with \"sh\" and \"zh\" in some written texts, although this is considered incorrect. Otherwise, the \"h\" in \"sh\" represents a voiceless glottal fricative, as in \"Pasha\" (\"pas-ha\"); this also applies to some foreign names.\n\nModern Estonian orthography is based on the \"Newer Orthography\" created by Eduard Ahrens in the second half of the 19thcentury based on Finnish orthography. The \"Older Orthography\" it replaced was created in the 17thcentury by Bengt Gottfried Forselius and Johann Hornung based on standard German orthography. Earlier writing in Estonian had by and large used an \"ad hoc\" orthography based on Latin and Middle Low German orthography. Some influences of the standard German orthography - for example, writing 'W'/'w' instead of 'V'/'v' - persisted well into the 1930s.\n\nIt should be noted that Estonian words and names quoted in international publications from Soviet sources are often back-transliterations from the Russian transliteration. Examples are the use of \"ya\" for \"ä\" (e.g. Pyarnu instead of Pärnu), \"y\" instead of \"õ\" (e.g., Pylva instead of Põlva) and \"yu\" instead of \"ü\" (e.g., Pyussi instead of Püssi). Even in the \"Encyclopædia Britannica\" one can find \"ostrov Khiuma\", where \"ostrov\" means \"island\" in Russian and \"Khiuma\" is back-transliteration from Russian instead of \"Hiiumaa\" (\"Hiiumaa > Хийума(а) > Khiuma\").\n\nThere are 9 vowels and 36 diphthongs, 28 of which are native to Estonian. All nine vowels can appear as the first component of a diphthong, but only /ɑ e i o u/ occur as the second component. A vowel characteristic of Estonian is the unrounded back vowel /ɤ/, which may be close-mid back, close back, or close-mid central.\n\nTypologically, Estonian represents a transitional form from an agglutinating language to a fusional language. The canonical word order is SVO (subject–verb–object).\n\nIn Estonian, nouns and pronouns do not have grammatical gender, but nouns and adjectives decline in fourteen cases: nominative, genitive, partitive, illative, inessive, elative, allative, adessive, ablative, translative, terminative, essive, abessive, and comitative, with the case and number of the adjective(s) always agreeing with that of the noun (except in the terminative, essive, abessive and comitative, where there is agreement only for the number, the adjective being in the genitive form). Thus the illative for \"kollane maja\" (\"a yellow house\") is \"kollasesse majja\" (\"into a yellow house\"), but the terminative is \"kollase majani\" (\"as far as a yellow house\"). With respect to the Proto-Finnic language, elision has occurred; thus, the actual case marker may be absent, but the stem is changed, cf. \"maja – majja\" and the Ostrobothnia dialect of Finnish \"maja – majahan\".\n\nThe direct object of the verb appears either in the accusative (for total objects) or in the partitive (for partial objects). The accusative coincides with the genitive in the singular and with nominative in the plural. Accusative vs. partitive case opposition of the object used with transitive verbs creates a telicity contrast, just as in Finnish. This is a rough equivalent of the perfective vs. imperfective aspect opposition.\n\nThe verbal system lacks a distinctive future tense (the present tense serves here) and features special forms to express an action performed by an undetermined subject (the \"impersonal\").\n\nAlthough the Estonian and Germanic languages are of very different origins, one can identify many similar words in Estonian and English, for example. This is primarily because the Estonian language has borrowed nearly one third of its vocabulary from Germanic languages, mainly from Low Saxon (Middle Low German) during the period of , and High German (including standard German). The percentage of Low Saxon and High German loanwords can be estimated at 22–25 percent, with Low Saxon making up about 15 percent.\n\nOften 'b' & 'p' are interchangeable, for example 'baggage' becomes 'pagas', 'lob' (to throw) becomes 'loopima'. The initial letter 's' before another consonant is often dropped, for example 'skool' becomes 'kool', 'stool' becomes 'tool'.\n\nEstonian language planners such as Ado Grenzstein (a journalist active in Estonia in the 1870s–90s) tried to use formation \"ex nihilo\", Urschöpfung; i.e. they created new words out of nothing.\n\nThe most famous reformer of Estonian, Johannes Aavik (1880–1973), used creations \"ex nihilo\" (cf. ‘free constructions’, Tauli 1977), along with other sources of lexical enrichment such as derivations, compositions and loanwords (often from Finnish; cf. Saareste and Raun 1965: 76). In Aavik’s dictionary (1921), which lists approximately 4000 words, there are many words which were (allegedly) created \"ex nihilo\", many of which are in common use today. Examples are\n\nMany of the coinages that have been considered (often by Aavik himself) as words concocted \"ex nihilo\" could well have been influenced by foreign lexical items, for example words from Russian, German, French, Finnish, English and Swedish. Aavik had a broad classical education and knew Ancient Greek, Latin and French. Consider \"roim\" ‘crime’ versus English \"crime\" or \"taunima\" ‘to condemn, disapprove’ versus Finnish \"tuomita\" ‘to condemn, to judge’ (these Aavikisms appear in Aavik’s 1921 dictionary). These words might be better regarded as a peculiar manifestation of morpho-phonemic adaptation of a foreign lexical item.\n\nArticle 1 of the Universal Declaration of Human Rights in Estonian:\n\n<poem>Kõik inimesed sünnivad vabadena ja võrdsetena oma väärikuselt ja õigustelt. Neile on antud mõistus ja südametunnistus ja nende suhtumist üksteisesse peab kandma vendluse vaim.\n\n(All people are born free and equal in their dignity and rights. They are given reason and conscience and they shall create their relationships to one another according to the spirit of brotherhood.)</poem>\n\n\n\n"}
{"id": "10224", "url": "https://en.wikipedia.org/wiki?curid=10224", "title": "E-Prime", "text": "E-Prime\n\nE-Prime (short for English-Prime or English Prime, sometimes denoted É or E′) is a version of the English language that excludes all forms of the verb \"to be\", including all conjugations, contractions and archaic forms.\n\nSome scholars advocate using E-Prime as a device to clarify thinking and strengthen writing. For example, the sentence \"the film was good\" could not be expressed under the rules of E-Prime, and the speaker might instead say \"I liked the film\", \"the film made me laugh\", or \"the film has value\". The E-Prime versions communicate the writer's experience rather than judgment, making it harder for the writer or reader to confuse opinion with fact.\n\nKellogg and Bourland describe misuse of the verb \"to be\" as creating a \"deity mode of speech\", allowing \"even the most ignorant to transform their opinions magically into god-like pronouncements on the nature of things\".\n\nD. David Bourland, Jr., who had studied under Alfred Korzybski, devised E-Prime as an addition to Korzybski's general semantics in the late 1940s. Bourland published the concept in a 1965 essay entitled \"A Linguistic Note: Writing in E-Prime\" (originally published in \"General Semantics Bulletin\"). The essay quickly generated controversy within the general semantics field, partly because practitioners of general semantics sometimes saw Bourland as attacking the verb 'to be' as such, and not just certain usages.\n\nBourland collected and published three volumes of essays in support of his innovation. The first (1991), co-edited by Paul Dennithorne Johnston, bore the title: \"To Be or Not: An E-Prime Anthology\" \nFor the second, \"More E-Prime: To Be or Not II\", published in 1994, he added a third editor, Jeremy Klein. Bourland and Johnston then edited a third book, \"E-Prime III: a third anthology\", published in 1997.\n\nKorzybski (1879–1950) determined that two forms of the verb 'to be'—the 'is' of identity and the 'is' of predication—had structural problems. For example, the sentence \"The coat is red\" has no observer, the sentence \"We see the coat as red\" (where \"we\" indicates observers) appears more specific, and describes light waves and colour as determined by the human brain.\n\nKorzybski pointed out the circularity of many dictionary definitions, and suggested adoption of the mathematical practice of acknowledging some minimal ensemble of primitive notions as necessarily 'undefined'; he chose 'structure', 'order', and 'relation'. He wrote of those that do not lend themselves to explication in words, but only by exhibiting how to use them in sentences. Korzybski advocated raising one's awareness of structural issues generally through training in general semantics.\n\nIn the English language, the verb 'to be' (also known as the \"copula\") has several distinct functions:\n\nBourland sees specifically the \"identity\" and \"predication\" functions as pernicious, but advocates eliminating all forms for the sake of simplicity. In the case of the \"existence\" form (and less idiomatically, the \"location\" form), one might (for example) simply substitute the verb \"exists\". Other copula-substitutes in English include \"taste\", \"feel\", \"smell\", \"sound\", \"grow\", \"remain\", \"stay\", and \"turn\", among others a user of E-prime might use instead of \"to be\".\n\nBourland and other advocates also suggest that use of E-Prime leads to a less dogmatic style of language that reduces the possibility of misunderstanding or conflict.\n\nAlfred Korzybski justified the expression he coined — \"the map is not the territory\" — by saying that \"the denial of identification (as in 'is not') has opposite neuro-linguistic effects on the brain from the assertion of identity (as in 'is').\"\n\n\"To be\" belongs to the set of irregular verbs in English, and some people, especially those who learned English as a second language, may have difficulty recognizing all its forms. In addition, speakers of colloquial English frequently contract forms of \"to be\" after pronouns or before the word \"not\". E-Prime would prohibit the following words as forms of \"to be\":\n\n\nE-prime does not prohibit the following words, because they do not derive from forms of \"to be\". Some of these serve similar grammatical functions (see auxiliary verbs).\n\nScholars of general semantics emphasize distinctions between different perceptions at different points in space (called \"indexing\") over any universal God's eye view or assumed-shared or collective identity. By encouraging clarity on the active subject that \"does\" or wants or believes something, and disallowing passive constructions about the state of affairs (a common use of \"to be\"), E-Prime makes it more difficult to hide assumptions in statements about The Other or equivalent constructions such as \"they\" or \"most people\" or \"the public\" or \"the taxpayer\". E-Prime disallows forms of statement such as \"they say X is Y\" or \"most people are into Z\" or \"the taxpayer is angry\" while allowing statements such as \"a clear majority of people say X always coexists with Y\" or \"most people approve of Z\" or \"the taxpayer doesn't like measure Q\" or \"lots of taxpayers express anger about Q\".\n\nE-Prime also discourages broad assertions crossing boundaries between past, present and future. General semantics' practice of \"dating\" and modern theories of scenario analysis and financial risk (based on statistics) emphasize a need to keep time frames of measurement and analysis carefully aligned. This avoids confusion between past events (which cannot be changed), the present (which one can test but not generally change) and future events (which one still has time to change even on a large scale), which can prevent noticing or taking an action to improve a future outcome.\n\nReplacing statements including \"to be\" with those using becomes, remains and equals divides perception of, and expressions about, time more operationally into actual cognitive categories that humans know how to act upon:\n\nSince history and memory (representations of or belief about the past) are distinct in all philosophy and ontology from plan, vision or intent (representations of our will to change the future), statements that confuse these are category errors: No statement about history or memory can imply a similar statement about a plan or vision or intent, nor vice versa - a distinction sometimes credited to Hume who distinguished also the morality of a statement from its truth. The very different ways that humans process memory or agree on history (about the past) must be, according to most philosophers, kept distinct from ways we employ logic on snapshots of axioms about our own immediate present and the ways we plan and envision an uncertain and collective future. By contrast, theology does assert high value for some unquestioned and eternal past-to-future equivalences. By substituting these three verbs, even without clarifying morality (ought, shall, should, must) or the actor(s) who do or did something, becomes/remains/equals makes clear what time frame of relationship is asserted, and disallows assuming one stable past/present/future timeline - known as single scenario planning or blind linearity and considered a grave error in risk analysis.\n\nUsers of E-Prime also generally encourage other replacements that clarify subject, object, time frame, intent and scope of relationships, replacing:\n\nWhile teaching at the University of Florida, Alfred Korzybski counseled his students to eliminate the infinitive and verb forms of \"to be\" from their vocabulary, whereas a second group continued to use \"I am,\" \"You are,\" \"They are\" statements as usual. For example, instead of saying, \"I am depressed,\" a student was asked to eliminate that emotionally primed verb and to say something else, such as, \"I feel depressed when ...\" or \"I tend to make myself depressed about ...\"\nKorzybski observed improvement \"of one full letter grade\" by \"students who did not generalize by using that infinitive\".\nAlthough this took place before the invention of E-Prime, it does show the application of general semantics to psychotherapy.\n\nAlbert Ellis advocated the use of E-Prime when discussing psychological distress to encourage framing these experiences as temporary (see also Solution focused brief therapy) and to encourage a sense of agency by specifying the subject of statements. According to Ellis, rational emotive behavior therapy \"has favored E-Prime more than any other form of psychotherapy and I think it is still the only form of therapy that has some of its main books written in E-Prime\". However, Ellis did not always use E-Prime because he believed it interferes with readability.\n\nNeuro-linguistic programming uses E-Prime as a technique. NLP's theoretical basis relies heavily on Korzybski's and Bourland's work.\n\n\nMany authors have questioned E-Prime's effectiveness at improving readability and reducing prejudice (Lakoff, 1992; Murphy, 1992; Parkinson, 1992; Kenyon, 1992; French, 1992, 1993; Lohrey, 1993). These authors observed that a communication under the copula ban can remain extremely unclear and imply prejudice, while losing important speech patterns, such as identities and identification. Further, prejudices and judgments that are made are more difficult to notice or refute. James D. French, a computer programmer at the University of California, Berkeley, summarized ten arguments against E-Prime (in the context of general semantics) as follows:\n\n\nAccording to an article (written in E-Prime and advocating a role for E-Prime in ESL and EFL programs) published by the Office of English Language Programs of the Bureau of Educational and Cultural Affairs in the State Department of the United States, \"Requiring students to avoid the verb to be on every assignment would deter students from developing other fundamental skills of fluent writing.\"\n\n\n\n"}
{"id": "10225", "url": "https://en.wikipedia.org/wiki?curid=10225", "title": "Elliptic curve", "text": "Elliptic curve\n\nIn mathematics, an elliptic curve is a plane algebraic curve defined by an equation of the form\n\nthat is non-singular; that is, it has no cusps or self-intersections. (When the characteristic of the coefficient field is equal to 2 or 3, the above equation is not quite general enough to comprise all non-singular cubic curves; see below for a more precise definition.) \n\nFormally, an elliptic curve is a smooth, projective, algebraic curve of genus one, on which there is a specified point \"O\". An elliptic curve is in fact an abelian variety – that is, it has a multiplication defined algebraically, with respect to which it is an abelian group – and \"O\" serves as the identity element. Often the curve itself, without \"O\" specified, is called an elliptic curve. The point \"O\" is actually the \"point at infinity\" in the projective plane.\n\nIf \"y\" = \"P\"(\"x\"), where \"P\" is any polynomial of degree three in \"x\" with no repeated roots, then we obtain a nonsingular plane curve of genus one, which is thus an elliptic curve. If \"P\" has degree four and is square-free this equation again describes a plane curve of genus one; however, it has no natural choice of identity element. More generally, any algebraic curve of genus one, for example from the intersection of two quadric surfaces embedded in three-dimensional projective space, is called an elliptic curve, provided that it has at least one rational point to act as the identity.\n\nUsing the theory of elliptic functions, it can be shown that elliptic curves defined over the complex numbers correspond to embeddings of the torus into the complex projective plane. The torus is also an abelian group, and in fact this correspondence is also a group isomorphism.\n\nElliptic curves are especially important in number theory, and constitute a major area of current research; for example, they were used in the proof, by Andrew Wiles, of Fermat's Last Theorem. They also find applications in elliptic curve cryptography (ECC) and integer factorization.\n\nAn elliptic curve is \"not\" an ellipse: see elliptic integral for the origin of the term. Topologically, a complex elliptic curve is a torus.\n\nAlthough the formal definition of an elliptic curve is fairly technical and requires some background in algebraic geometry, it is possible to describe some features of elliptic curves over the real numbers using only introductory algebra and geometry.\n\nIn this context, an elliptic curve is a plane curve defined by an equation of the form\n\nwhere \"a\" and \"b\" are real numbers. This type of equation is called a Weierstrass equation.\n\nThe definition of elliptic curve also requires that the curve be non-singular. Geometrically, this means that the graph has no cusps, self-intersections, or isolated points. Algebraically, this involves calculating the discriminant\n\nThe curve is non-singular if and only if the discriminant is not equal to zero. (Although the factor −16 is irrelevant to whether or not the curve is non-singular, this definition of the discriminant is useful in a more advanced study of elliptic curves.)\n\nThe (real) graph of a non-singular curve has \"two\" components if its discriminant is positive, and \"one\" component if it is negative. For example, in the graphs shown in figure to the right, the discriminant in the first case is 64, and in the second case is −368.\n\nWhen working in the projective plane, we can define a group structure on any smooth cubic curve. In Weierstrass normal form, such a curve will have an additional point at infinity, \"O\", at the homogeneous coordinates [0:1:0] which serves as the identity of the group.\n\nSince the curve is symmetrical about the x-axis, given any point \"P\", we can take −\"P\" to be the point opposite it. We take −\"O\" to be just \"O\".\n\nIf \"P\" and \"Q\" are two points on the curve, then we can uniquely describe a third point, \"P\" + \"Q\", in the following way. First, draw the line between \"P\" and \"Q\". This will generally intersect the cubic at a third point, \"R\". We then take \"P\" + \"Q\" to be −\"R\", the point opposite \"R\".\n\nThis definition for addition works except in a few special cases related to the point at infinity and intersection multiplicity. The first is when one of the points is \"O\". Here, we define \"P\" + \"O\" = \"P\" = \"O\" + \"P\", making \"O\" the identity of the group. Next, if \"P\" and \"Q\" are opposites of each other, we define \"P\" + \"Q\" = \"O\". Lastly, if \"P\" = \"Q\" we only have one point, thus we can't define the line between them. In this case, we use the tangent line to the curve at this point as our line. In most cases, the tangent will intersect a second point \"R\" and we can take its opposite. However, if \"P\" happens to be an inflection point (a point where the concavity of the curve changes), we take \"R\" to be \"P\" itself and \"P\" + \"P\" is simply the point opposite itself.\n\nFor a cubic curve not in Weierstrass normal form, we can still define a group structure by designating one of its nine inflection points as the identity \"O\". In the projective plane, each line will intersect a cubic at three points when accounting for multiplicity. For a point \"P\", −\"P\" is defined as the unique third point passing through \"O\" and \"P\". Then, for any \"P\" and \"Q\", \"P\" + \"Q\" is defined as −\"R\" where \"R\" is the unique third point on the line containing \"P\" and \"Q\".\n\nLet \"K\" be a field over which the curve is defined (i.e., the coefficients of the defining equation or equations of the curve are in \"K\") and denote the curve by \"E\". Then the \"K\"-rational points of \"E\" are the points on \"E\" whose coordinates all lie in \"K\", including the point at infinity. The set of \"K\"-rational points is denoted by \"E\"(\"K\"). It, too, forms a group, because properties of polynomial equations show that if \"P\" is in \"E\"(\"K\"), then −\"P\" is also in \"E\"(\"K\"), and if two of \"P\", \"Q\", and \"R\" are in \"E\"(\"K\"), then so is the third. Additionally, if \"K\" is a subfield of \"L\", then \"E\"(\"K\") is a subgroup of \"E\"(\"L\").\n\nThe above group can be described algebraically as well as geometrically. Given the curve \"y\" = \"x\" − \"px\" − \"q\" over the field \"K\" (whose characteristic we assume to be neither 2 nor 3), and points \"P\" = (\"x\", \"y\") and \"Q\" = (\"x\", \"y\") on the curve, assume first that \"x\" ≠ \"x\" (first pane below). Let \"s\" be the slope of the line containing \"P\" and \"Q\"; i.e.,\n\nSince \"K\" is a field, \"s\" is well-defined. Then we can define \"R\" = (\"x\", \"y\") = −(\"P\" + \"Q\") by\n\nIf \"x\" = \"x\", then there are two options: if \"y\" = −\"y\" (third and fourth panes below), including the case where \"y\" = \"y\" = 0 (fourth pane), then the sum is defined as 0; thus, the inverse of each point on the curve is found by reflecting it across the \"x\"-axis. If \"y\" = \"y\" ≠ 0, then \"Q\" = \"P\" and \"R\" = (\"x\", \"y\") = −(\"P\" + \"P\") = −2\"P\" = -2\"Q\" (second pane below with \"P\" shown for \"R\") is given by\n\nThe formulation of elliptic curves as the embedding of a torus in the complex projective plane follows naturally from a curious property of Weierstrass's elliptic functions. These functions and their first derivative are related by the formula\n\nHere, \"g\" and \"g\" are constants; formula_8 is the Weierstrass elliptic function and formula_9 its derivative. It should be clear that this relation is in the form of an elliptic curve (over the complex numbers). The Weierstrass functions are doubly periodic; that is, they are periodic with respect to a lattice Λ; in essence, the Weierstrass functions are naturally defined on a torus \"T\" = C/Λ. This torus may be embedded in the complex projective plane by means of the map\n\nThis map is a group isomorphism of the torus (considered with its natural group structure) with the chord-and-tangent group law on the cubic curve which is the image of this map. It is also an isomorphism of Riemann surfaces from the torus to the cubic curve, so topologically, an elliptic curve is a torus. If the lattice Λ is related by multiplication by a non-zero complex number \"c\" to a lattice \"c\"Λ, then the corresponding curves are isomorphic. Isomorphism classes of elliptic curves are specified by the j-invariant.\n\nThe isomorphism classes can be understood in a simpler way as well. The constants \"g\" and \"g\", called the modular invariants, are uniquely determined by the lattice, that is, by the structure of the torus. However, the complex numbers form the splitting field for polynomials with real coefficients, and so the elliptic curve may be written as\n\nOne finds that\n\nand\n\nso that the modular discriminant is\n\nHere, λ is sometimes called the modular lambda function.\n\nNote that the uniformization theorem implies that every compact Riemann surface of genus one can be represented as a torus.\n\nThis also allows an easy understanding of the torsion points on an elliptic curve: if the lattice Λ is spanned by the fundamental periods ω and ω, then the \"n\"-torsion points are the (equivalence classes of) points of the form\n\nfor \"a\" and \"b\" integers in the range from 0 to \"n\"−1.\n\nOver the complex numbers, every elliptic curve has nine inflection points. Every line through two of these points also passes through a third inflection point; the nine points and 12 lines formed in this way form a realization of the Hesse configuration.\n\nA curve \"E\" defined over the field of rational numbers is also defined over the field of real numbers. Therefore the law of addition (of points with real coordinates) by the tangent and secant method can be applied to \"E\". The explicit formulae show that the sum of two points \"P\" and \"Q\" with rational coordinates has again rational coordinates, since the line joining \"P\" and \"Q\" has rational coefficients. This way, one shows that the set of rational points of \"E\" forms a subgroup of the group of real points of \"E\". As this group, it is an abelian group, that is, \"P\" + \"Q\" = \"Q\" + \"P\".\n\nThe most important result is that all points can be constructed by the method of tangents and secants starting with a \"finite\" number of points. More precisely the Mordell–Weil theorem states that the group \"E\"(Q) is a finitely generated (abelian) group. By the fundamental theorem of finitely generated abelian groups it is therefore a finite direct sum of copies of Z and finite cyclic groups.\n\nThe proof of that theorem rests on two ingredients: first, one shows that for any integer \"m\" > 1, the quotient group \"E\"(Q)/\"mE\"(Q) is finite (weak Mordell–Weil theorem). Second, introducing a height function \"h\" on the rational points \"E\"(Q) defined by \"h\"(\"P\") = 0 and if \"P\" (unequal to the point at infinity \"P\") has as abscissa the rational number \"x\" = \"p\"/\"q\" (with coprime \"p\" and \"q\"). This height function \"h\" has the property that \"h\"(\"mP\") grows roughly like the square of \"m\". Moreover, only finitely many rational points with height smaller than any constant exist on \"E\".\n\nThe proof of the theorem is thus a variant of the method of infinite descent and relies on the repeated application of Euclidean divisions on \"E\": let \"P\" ∈ \"E\"(Q) be a rational point on the curve, writing \"P\" as the sum 2\"P\" + \"Q\" where \"Q\" is a fixed representant of \"P\" in \"E\"(Q)/2\"E\"(Q), the height of \"P\" is about of the one of \"P\" (more generally, replacing 2 by any \"m\" > 1, and by ). Redoing the same with \"P\", that is to say \"P\" = 2\"P\" + \"Q\", then \"P\" = 2\"P\" + \"Q\", etc. finally expresses \"P\" as an integral linear combination of points \"Q\" and of points whose height is bounded by a fixed constant chosen in advance: by the weak Mordell–Weil theorem and the second property of the height function \"P\" is thus expressed as an integral linear combination of a finite number of fixed points.\n\nSo far, the theorem is not effective since there is no known general procedure for determining the representants of \"E\"(Q)/\"mE\"(Q).\n\nThe rank of \"E\"(Q), that is the number of copies of Z in \"E\"(Q) or, equivalently, the number of independent points of infinite order, is called the \"rank\" of \"E\". The Birch and Swinnerton-Dyer conjecture is concerned with determining the rank. One conjectures that it can be arbitrarily large, even if only examples with relatively small rank are known. The elliptic curve with biggest exactly known rank is\n\nIt has rank 19, found by Noam Elkies in 2009. Curves of rank at least 28 are known, but their rank is not exactly known.\n\nAs for the groups constituting the torsion subgroup of \"E\"(Q), the following is known: the torsion subgroup of \"E\"(Q) is one of the 15 following groups (a theorem due to Barry Mazur): Z/\"NZ for \"N\" = 1, 2, ..., 10, or 12, or Z/2Z × Z/2\"NZ with \"N\" = 1, 2, 3, 4. Examples for every case are known. Moreover, elliptic curves whose Mordell–Weil groups over Q have the same torsion groups belong to a parametrized family.\n\nThe \"Birch and Swinnerton-Dyer conjecture\" (BSD) is one of the Millennium problems of the Clay Mathematics Institute. The conjecture relies on analytic and arithmetic objects defined by the elliptic curve in question.\n\nAt the analytic side, an important ingredient is a function of a complex variable, \"L\", the Hasse–Weil zeta function of \"E\" over Q. This function is a variant of the Riemann zeta function and Dirichlet L-functions. It is defined as an Euler product, with one factor for every prime number \"p\".\n\nFor a curve \"E\" over Q given by a minimal equation\n\nwith integral coefficients \"a\", reducing the coefficients modulo \"p\" defines an elliptic curve over the finite field F (except for a finite number of primes \"p\", where the reduced curve has a singularity and thus fails to be elliptic, in which case \"E\" is said to be of bad reduction at \"p\").\n\nThe zeta function of an elliptic curve over a finite field F is, in some sense, a generating function assembling the information of the number of points of \"E\" with values in the finite field extensions of F, F. It is given,\n\nThe interior sum of the exponential resembles the development of the logarithm and, in fact, the so-defined zeta function is a rational function:\n\nThe Hasse–Weil zeta function of \"E\" over Q is then defined by collecting this information together, for all primes \"p\". It is defined by\n\nwhere ε(\"p\") = 1 if \"E\" has good reduction at \"p\" and 0 otherwise (in which case \"a\" is defined differently than above).\n\nThis product converges for Re(\"s\") > 3/2 only. Hasse's conjecture affirms that the \"L\"-function admits an analytic continuation to the whole complex plane and satisfies a functional equation relating, for any \"s\", \"L\"(\"E\", \"s\") to \"L\"(\"E\", 2 − \"s\"). In 1999 this was shown to be a consequence of the proof of the Shimura–Taniyama–Weil conjecture, which asserts that every elliptic curve over \"Q\" is a modular curve, which implies that its \"L\"-function is the \"L\"-function of a modular form whose analytic continuation is known.\n\nOne can therefore speak about the values of \"L\"(\"E\", \"s\") at any complex number \"s\". The Birch-Swinnerton-Dyer conjecture relates the arithmetic of the curve to the behavior of its \"L\"-function at \"s\" = 1. More precisely, it affirms that the order of the \"L\"-function at \"s\" = 1 equals the rank of \"E\" and predicts the leading term of the Laurent series of \"L\"(\"E\", \"s\") at that point in terms of several quantities attached to the elliptic curve.\n\nMuch like the Riemann hypothesis, this conjecture has multiple consequences, including the following two:\n\nThe modularity theorem, once known as the Taniyama–Shimura–Weil conjecture, states that every elliptic curve \"E\" over Q is a modular curve, that is to say, its Hasse–Weil zeta function is the \"L\"-function of a modular form of weight 2 and level \"N\", where \"N\" is the conductor of \"E\" (an integer divisible by the same prime numbers as the discriminant of \"E\", Δ(\"E\").) In other words, if, for Re(\"s\") > 3/2, one writes the \"L\"-function in the form\n\nthe expression\n\ndefines a parabolic modular newform of weight 2 and level \"N\". For prime numbers ℓ not dividing \"N\", the coefficient \"a\"(ℓ) of the form equals ℓ – the number of solutions of the minimal equation of the curve modulo ℓ.\n\nFor example, to the elliptic curve formula_26 with discriminant (and conductor) 37, is associated the form\n\nFor prime numbers ℓ not equal to 37, one can verify the property about the coefficients. Thus, for ℓ = 3, the solutions of the equation modulo 3 are (0, 0), (0, 1), (2, 0), (1, 0), (1, 1), (2, 1), as and \"a\"(3) = 3 − 6 = −3.\n\nThe conjecture, going back to the 1950s, was completely proven by 1999 using ideas of Andrew Wiles, who proved it in 1994 for a large family of elliptic curves.\n\nThere are several formulations of the conjecture. Showing that they are equivalent is difficult and was a main topic of number theory in the second half of the 20th century. The modularity of an elliptic curve \"E\" of conductor \"N\" can be expressed also by saying that there is a non-constant rational map defined over Q, from the modular curve \"X\"(\"N\") to \"E\". In particular, the points of \"E\" can be parametrized by modular functions.\n\nFor example, a modular parametrization of the curve formula_28 is given by\n\nwhere, as above, \"q\" = exp(2π\"iz\"). The functions \"x(z)\" and \"y(z)\" are modular of weight 0 and level 37; in other words they are meromorphic, defined on the upper half-plane Im(\"z\") > 0 and satisfy\n\nand likewise for \"y(z)\" for all integers \"a, b, c, d\" with \"ad\" − \"bc\" = 1 and 37|\"c\".\n\nAnother formulation depends on the comparison of Galois representations attached on the one hand to elliptic curves, and on the other hand to modular forms. The latter formulation has been used in the proof the conjecture. Dealing with the level of the forms (and the connection to the conductor of the curve) is particularly delicate.\n\nThe most spectacular application of the conjecture is the proof of Fermat's Last Theorem (FLT). Suppose that for a prime \"p\" ≥ 5, the Fermat equation\n\nhas a solution with non-zero integers, hence a counter-example to FLT. Then the elliptic curve\n\nof discriminant\n\ncannot be modular. Thus, the proof of the Taniyama–Shimura–Weil conjecture for this family of elliptic curves (called Hellegouarch–Frey curves) implies FLT. The proof of the link between these two statements, based on an idea of Gerhard Frey (1985), is difficult and technical. It was established by Kenneth Ribet in 1987.\n\nThis section is concerned with points \"P\" = (\"x\", \"y\") of \"E\" such that \"x\" is an integer. The following theorem is due to C. L. Siegel: the set of points \"P\" = (\"x\", \"y\") of \"E\"(Q) such that \"x\" is an integer is finite. This theorem can be generalized to points whose \"x\" coordinate has a denominator divisible only by a fixed finite set of prime numbers.\n\nThe theorem can be formulated effectively. For example, if the Weierstrass equation of \"E\" has integer coefficients bounded by a constant \"H\", the coordinates (\"x\", \"y\") of a point of \"E\" with both \"x\" and \"y\" integer satisfy:\n\nThe Sato–Tate conjecture is a statement about how the error term formula_35 in Hasse's theorem varies with the different primes \"q\", if an elliptic curve E over Q is reduced modulo q. It was proven (for almost all such curves) in 2006 due to the results of Taylor, Harris and Shepherd-Barron, and says that the error terms are equidistributed.\n\nElliptic curves over finite fields are notably applied in cryptography and for the factorization of large integers. These algorithms often make use of the group structure on the points of \"E\". Algorithms that are applicable to general groups, for example the group of invertible elements in finite fields, F*, can thus be applied to the group of points on an elliptic curve. For example, the discrete logarithm is such an algorithm. The interest in this is that choosing an elliptic curve allows for more flexibility than choosing \"q\" (and thus the group of units in F). Also, the group structure of elliptic curves is generally more complicated.\n\nElliptic curves over finite fields are used in some cryptographic applications as well as for integer factorization. Typically, the general idea in these applications is that a known algorithm which makes use of certain finite groups is rewritten to use the groups of rational points of elliptic curves. For more see also:\n\n\n\nSerge Lang, in the introduction to the book cited below, stated that \"It is possible to write endlessly on elliptic curves. (This is not a threat.)\" The following short list is thus at best a guide to the vast expository literature available on the theoretical, algorithmic, and cryptographic aspects of elliptic curves.\n\n"}
{"id": "10229", "url": "https://en.wikipedia.org/wiki?curid=10229", "title": "Equidae", "text": "Equidae\n\nEquidae (sometimes known as the horse family) is the taxonomic family of horses and related animals, including the extant horses, donkeys, and zebras, and many other species known only from fossils. All extant species are in the genus \"Equus\". Equidae belongs to the order Perissodactyla, which includes the extant tapirs and rhinoceros, and several extinct families.\n\nThe term equid refers to any member of this family, including any equine.\n\nThe oldest known fossils assigned to Equidae date from the early Eocene, 54 million years ago. They used to be assigned to the genus \"Hyracotherium\", but the type species of that genus now is regarded to be not a member of this family. The other species have been split off into different genera. These early Equidae were fox-sized animals with three toes on the hind feet, and four on the front feet. They were herbivorous browsers on relatively soft plants, and already adapted for running. The complexity of their brains suggest that they already were alert and intelligent animals. Later species reduced the number of toes, and developed teeth more suited for grinding up grasses and other tough plant food.\n\nThe family became relatively diverse during the Miocene, with many new species appearing. By this time, equids were more truly horse-like, having developed the typical body shape of the modern animals. Many of these species bore the main weight of their bodies on their central, third, toe, with the others becoming reduced, and barely touching the ground, if at all. The sole surviving genus, \"Equus\", had evolved by the early Pleistocene, and spread rapidly through the world.\n\n"}
{"id": "10231", "url": "https://en.wikipedia.org/wiki?curid=10231", "title": "List of economists", "text": "List of economists\n\nThis is an incomplete alphabetical list by surname of notable economists, experts in the social science of economics, past and present. For a history of economics, see the article History of economic thought. Only economists with biographical articles in Wikipedia are listed here.\n\n\n\n[[File:Thomas Chalmers - Project Gutenberg 13103.jpg|right|thumb|100px|Thomas Chalmers]]\n[[File:Henrycharlescarey.jpg|right|thumb|100px|Henry Charles Carey]]\n[[File:John Bates Clark.jpg|right|thumb|100px|John Bates Clark]]\n[[File:Cassel.gif|right|thumb|100px|Gustav Cassel]]\n[[File:JohnCommons.jpg|right|thumb|100px|John R. Commons]]\n\n[[File:Attilio Celant 01.JPG|right|thumb|100px|Attilio Celant]]\n[[File:Agustin Carstens.jpg|right|thumb|100px|Augustin Carstens]]\n[[File:Ha-Joon Chang profile.jpg|right|thumb|100px|Ha-Joon Chang]]\n\n[[File:Antony Davies.png|right|thumb|100px|Antony Davies]]\n[[File:Debreu, Gérard (1921-2004).jpeg|right|thumb|100px|Gérard Debreu]]\n[[File:Demsetzatgmu.jpg|right|thumb|100px|Harold Demsetz]]\n[[File:Partha Dasgupta - Trento 2013 02.JPG|right|thumb|100px|Partha Dasgupta]]\n[[File:Professor Huw Dixon.jpg|right|thumb|100px|Huw Dixon]]\n[[File:Avinash Dixit.JPG|right|thumb|100px|Avinash Dixit]]\n[[File:Brad DeLong 201010.jpg|right|thumb|100px|J. Bradford DeLong]]\n[[Hugh Dalton]]\n\n[[File:Engels.jpg|thumb|right|100px|Friedrich Engels]]\n[[File:Robert F. Engle.jpg|thumb|right|100px|Robert F. Engle]]\n\n\n[[File:WilliamFleetwood.jpg|right|thumb|100px|William Fleetwood]]\n[[File:Irvingfisher.jpg|right|thumb|100px|Irving Fisher]]\n[[File:Portrait of Milton Friedman.jpg|right|thumb|100px|Milton Friedman]]\n[[File:Jason Furman 2011.jpg|right|thumb|100px|Jason Furman]]\n[[File:Robert William Fogel.jpg|right|thumb|100px|Robert Fogel]]\n\n\n[[File:Gide, Charles.jpg|right|thumb|100px|Charles Gide]]\n[[File:Henry George.jpg|right|thumb|100px|Henry George]]\n[[File:John Kenneth Galbraith.jpg|right|thumb|100px|John Kenneth Galbraith]]\n[[File:David Gale in Paris.jpg|right|thumb|100px|David Gale]]\n[[File:Nicholas Georgescu-Roegen.jpg|thumb|100px|Nicholas Georgescu-Roegen]]\n[[File:Edward L. Glaeser at FT Goldman Sachs Business Book of the Year Award 2011.jpg|right|thumb|100px|Edward Glaeser]]\n[[File:Ian Goldin World Economic Forum 2013.jpg|right|thumb|100px|Ian Goldin]]\n\n\n[[File:Painting of David Hume.jpg|thumb|right|100px|David Hume]]\n[[File:Friedrich Hayek portrait.jpg|thumb|right|100px|Friedrich Hayek]]\n[[File:Eli Heckscher.jpg|thumb|right|100px|Eli Heckscher]]\n[[File:Trygve Haavelmo.jpg|thumb|right|100px|Trygve Haavelmo]]\n[[File:James Heckman.jpg|thumb|right|100px|James Heckman]]\n[[File:Glenn Hubbard portrait.jpg|thumb|right|100px|Glenn Hubbard]]\n\n\n\n[[File:Picture of jevons.jpg|thumb|right|100px|William Stanley Jevons]]\n\n\n[[File:Ibn Khaldoun-Kassus.jpg|right|thumb|100px|Ibn Khaldun]]\n[[File:Keynes 1933.jpg|right|thumb|100px|[[John Maynard Keynes]]]]\n[[File:Nicholas Kaldor.jpg|right|thumb|100px|Nicholas Kaldor]]\n[[File:Daniel KAHNEMAN.jpg|right|thumb|100px|[[Daniel Kahneman]]]]\n[[File:Kydland.jpg|right|thumb|100px|Finn E. Kydland]]\n[[File:Anne O. Krueger (2004).jpg|right|thumb|100px|Anne Osborn Krueger]]\n\n\n[[File:John Law-Casimir Balthazar mg 8450.jpg|thumb|right|100px|John Law]]\n[[File:Lyndon LaRouche.jpg|thumb|right|100px|Lyndon LaRouche]]\n[[File:Abba Lerner.jpg|thumb|right|100px|Abba Lerner]]\n[[File:Oskar Lange 20-65.jpg|thumb|right|100px|Oskar Lange]]\n[[File:Rosa Luxemburg.jpg|thumb|right|100px|Rosa Luxemburg]]\n[[File:JohnLott.jpg|thumb|right|100px|John Lott]]\n\n\n[[File:Thomas Malthus.jpg|right|thumb|100px|Thomas Malthus]]\n[[File:Peter Middlebrook - Chief Executive Officer - Geopolicity Inc.jpg|thumb|right|100px|Peter Middlebrook]]\n[[File:PSM V03 D380 John Stuart Mill.jpg|right|thumb|100px|John Stuart Mill]]\n[[File:Alfred Marshall.jpg|right|thumb|100px|Alfred Marshall]]\n[[File:Karl Marx.jpg|right|thumb|100px|Karl Marx]]\n[[File:Ludwig von Mises.jpg|right|thumb|100px|Ludwig von Mises]]\n[[File:Gunnar Myrdal - Sveriges styresmän.jpg|right|thumb|100px|Gunnar Myrdal]]\n[[File:Myerson roger b print.jpg|right|thumb|100px|Roger Myerson]]\n[[File:Dale Mortensen 2.jpg|right|thumb|100px|Dale Mortensen]]\n[[File:Xavier Sala-i-Martin.jpg|right|thumb|100px|Xavier Sala i Martin]]\n[[File:Dambisa Moyo 2013 BlackRock.jpg|right|thumb|100px|Dambisa Moyo]]\n\n\n[[File:Dudley North.jpg|right|thumb|100px|Dudley North]]\n[[File:John Forbes Nash, Jr. by Peter Badge.jpg|right|thumb|100px|John Forbes Nash]]\n\n\n[[File:Portrait of Robert Owen.png|thumb|right|100px|Robert Owen]]\n[[File:Bertil Ohlin.jpg|thumb|right|100px|Bertil Ohlin]]\n[[File:Nobel Prize 2009-Press Conference KVA-30.jpg|thumb|right|100px|Elinor Ostrom]]\n\n\n[[File:V R Panchamukhi.jpg|thumb|right|100px|V R Panchamukhi]]\n[[File:Perez-Capdevila.jpg|thumb|right|100px|Javier Perez-Capdevila]]\n[[File:Vilfredo Pareto.jpg|thumb|right|100px|Vilfredo Pareto]]\n[[File:A.C. Pigou.jpg|thumb|right|100px|Arthur Cecil Pigou]]\n[[File:Piketty in Cambridge 3 crop.jpg|thumb|right|100px|Thomas Piketty]]\n[[File:Edward C. Prescott.jpg|thumb|right|100px|Edward C. Prescott]]\n[[File:Christina paxson.jpg|thumb|right|100px|Christina Paxson]]\n\n\n[[File:François Quesnay.jpg|right|thumb|100px|Francois Quesnay]]\n\n\n[[File:Portrait of David Ricardo by Thomas Phillips.jpg|thumb|right|100px|David Ricardo]]\n[[File:Joan Robinson Ramsey Muspratt.jpg|thumb|right|100px|Joan Robinson]]\n[[File:MurrayBW.jpg|thumb|right|100px|Murray Rothbard]]\n[[File:Christina Romer official portrait small.jpg|thumb|right|100px|Christina Romer]]\n[[File:Matthew Rabin 2008.jpg|thumb|right|100px|Matthew Rabin]]\n\n[[File:Jean-baptiste Say.jpg|right|thumb|100px|Jean-Baptiste Say]]\n[[File:AdamSmith.jpg|right|thumb|100px|Adam Smith]]\n[[File:Joseph Schumpeter ekonomialaria.jpg|right|thumb|100px|Joseph Schumpeter]]\n[[File:Paul Samuelson.jpg|right|thumb|100px|Paul Samuelson]]\n[[File:Robert Solow by Olaf Storbeck.jpg|right|thumb|100px|Robert Solow]]\n[[File:Joseph E. Stiglitz - cropped.jpg|right|thumb|100px|Joseph E. Stiglitz]]\n[[File:A Michael Spence.jpg|right|thumb|100px|Michael Spence]]\n[[File:MarkSkousen.jpg|right|thumb|100px|Mark Skousen]]\n[[File:Hans Werner Sinn.png|right|thumb|100px|Hans-Werner Sinn]]\n[[File:Robert Shiller - World Economic Forum Annual Meeting 2012.jpg|right|thumb|100px|Robert Shiller]]\n[[File:Lawrence Summers 2012.jpg|right|thumb|100px|Lawrence Summers]]\n[[File:Dr. D. Shina -.JPG|right|thumb|100px|D. Shina]]\n\n\n[[File:Anne Robert Jacques Turgot.jpg|thumb|right|100px|Anne Turgot]]\n[[File:Frank William Taussig by Pach Brothers.jpg|thumb|right|100px|Frank William Taussig]]\n[[File:Jan Tinbergen 1982.jpg|thumb|right|100px|Jan Tinbergen]]\n[[File:Gordon tullock.jpg|thumb|right|100px|Gordon Tullock]]\n\n\n\n[[File:Veblen3a.jpg|thumb|right|100px|Thorstein Veblen]]\n[[File:Paulvolcker.jpg|thumb|right|100px|Paul Volcker]]\n\n\n[[File:Lwalras.jpg|thumb|right|100px|Léon Walras]]\n[[File:Max Weber 1894.jpg|thumb|right|100px|Max Weber]]\n[[File:Wicksell.jpg|thumb|right|100px|Knut Wicksell]]\n[[File:Marilyn Waring.jpg|thumb|right|100px|Marilyn Waring]]\n[[File:MartinWolf2011ByDaphneBorowski.png|thumb|right|100px|Martin Wolf]]\n\n\n[[File:xenophon.jpg|right|thumb|100px|Xenophon (430-354 BCE)]]\n\n[[File:Janet yellen.jpg|thumb|right|100px|Janet Yellen]]\n[[File:Muhammad Yunus - World Economic Forum Annual Meeting 2012.jpg|thumb|right|100px|Muhammad Yunus]]\n\n\n\n\n\n[[Category:Lists of economists|*]]"}
{"id": "10235", "url": "https://en.wikipedia.org/wiki?curid=10235", "title": "ELIZA", "text": "ELIZA\n\nELIZA is an early natural language processing computer program created from 1964 to 1966 at the MIT Artificial Intelligence Laboratory by Joseph Weizenbaum. Created to demonstrate the superficiality of communication between man and machine, Eliza simulated conversation by using a 'pattern matching' and substitution methodology that gave users an illusion of understanding on the part of the program, but had no built in framework for contextualizing events. Directives on how to interact were provided by 'scripts', written originally in MAD-Slip, which allowed ELIZA to process user inputs and engage in discourse following the rules and directions of the script. The most famous script, DOCTOR, simulated a Rogerian psychotherapist and used rules, dictated in the script, to respond with non-directional questions to user inputs. As such, ELIZA was one of the first chatterbots, but was also regarded as one of the first programs capable of passing the Turing Test.\n\nELIZA's creator, Weizenbaum regarded the program as a method to show the superficiality of communication between man and machine, but was surprised by the number of individuals who attributed human-like feelings to the computer program, including Weizenbaum’s secretary. Many academics believed that the program would be able to positively influence the lives of many people, particularly those suffering from psychological issues and that it could aid doctors working on such patients’ treatment. While ELIZA was capable of engaging in discourse, ELIZA could not converse with true understanding. However, many early users were convinced of ELIZA’s intelligence and understanding, despite Weizenbaum’s insistence to the contrary.\n\nJoseph Weizenbaum’s ELIZA, running the DOCTOR script, was created to provide a parody of “the responses of a non-directional psychotherapist in an initial psychiatric interview” and to “demonstrate that the communication between man and machine was superficial”. While ELIZA is most well known for acting in the manner of a psychotherapist, this mannerism is due to the data and instructions supplied by the DOCTOR script. ELIZA itself examined the text for keywords, applied values to said keywords, and transformed the input into an output; the script that ELIZA ran determined the keywords, set the values of keywords, and set the rules of transformation for the output. Weizenbaum chose to make the DOCTOR script in the context of psychotherapy to “sidestep the problem of giving the program a data base of real-world knowledge,” as in a Rogerian therapeutic situation, the program had only to reflect back the patient’s statements. The algorithms of DOCTOR allowed for a deceptively intelligent response, that deceived many individuals when first using the program.\n\nWeizenbaum named his program ELIZA after Eliza Doolittle, a working-class character in George Bernard Shaw’s \"Pygmalion\". According to Weizenbaum, ELIZA’s ability to be “incrementally improved” by various users made it similar to Eliza Doolittle, since Eliza Doolittle was taught to speak with an upper-class accent in Shaw’s play. However, unlike in Shaw’s play, ELIZA is incapable of learning new patterns of speech or new words through interaction alone. Edits must be made directly to ELIZA’s active script in order to change the manner by which the program operates.\n\nWeizenbaum first implemented ELIZA in his own SLIP list-processing language, where, depending upon the initial entries by the user, the illusion of human intelligence could appear, or be dispelled through several interchanges. Some of ELIZA’s responses were so convincing that Weizenbaum and several others have anecdotes of users becoming emotionally attached to the program, occasionally forgetting that they were conversing with a computer. Weizenbaum’s own secretary reportedly asked Weizenbaum to leave the room so that she and ELIZA could have a real conversation. Weizenbaum was surprised by this, later writing, “I had not realized… that extremely short exposures to a relatively simple computer program could induce powerful delusional thinking in quite normal people.”\n\nIn 1966, interactive computing (via a teletype) was new. It was 15 years before the personal computer became familiar to the general public, and three decades before most people encountered attempts at natural language processing in Internet services like Ask.com or PC help systems such as Microsoft Office Clippy. Although those programs included years of research and work, \"ELIZA\" remains a milestone simply because it was the first time a programmer had attempted such a human-machine interaction with the goal of creating the illusion (however brief) of human-\"human\" interaction.\n\nAt the ICCC 1972 ELIZA met another early artificial intelligence program named PARRY and had the first computer only conversation. While ELIZA was built to be a \"Doctor\" PARRY was intended to simulate a patient with schizophrenia.\n\nWeizenbaum originally wrote ELIZA in MAD-Slip for the IBM 7094, as a program to make natural language conversation possible with a computer. To accomplish this, Weizenbaum identified five “fundamental technical problems” for ELIZA to overcome: the identification of critical words, the discovery of a minimal context, the choice of appropriate transformations, the generation of responses appropriate to the transformation or in the absence of critical words and the provision of an ending capacity for ELIZA scripts. Weizenbaum solved these problems in her ELIZA program and made ELIZA such that it had no built in contextual framework or universe of discourse. However, this required ELIZA to have a script of instructions on how to respond to inputs from users.\n\nELIZA starts its process of responding to an input by a user by first examining the text input for a ‘keyword’. A ‘keyword’ is a word designated as important by the acting ELIZA script, which assigns to each keyword a precedence number, or a RANK, designed by the programmer. If such words are found, they are put into a ‘keystack’, with the keyword of the highest RANK at the top. The input sentence is then manipulated and transformed as the rule associated with the keyword of the highest RANK directs. For example, when the DOCTOR script encounters words such as “alike” or “same”, it would output a message pertaining to similarity, in this case “In what way?”, as these words had high precedence number. This also demonstrates how certain words, as dictated by the script, can be manipulated regardless of contextual considerations, such as switching first-person pronouns and second-person pronouns and vice versa, as these too had high precedence numbers. Such words with high precedence numbers are deemed superior to conversational patterns, and are treated independently of contextual patterns.\n\nFollowing the first examination, the next step of the process is to apply an appropriate transformation rule, which includes two parts, the “decomposition rule” and the “reassembly rule”. First, the input is reviewed for syntactical patterns in order to establish the minimal context necessary to respond. Using the keywords and other nearby words from the input, different disassembly rules are tested until an appropriate pattern is found. Using the script’s rules, the sentence is then ‘dismantled’ and arranged into sections of the component parts as the “decomposition rule for the highest ranking keyword” dictates. The example that Weizenbaum gives is the input “I are very helpful” (remembering that “I” is “You” transformed), which is broken into (1) empty (2) I (3) are (4) very helpful. The decomposition rule has broken the phrase into four small segments, that contain both the keywords and the information in the sentence.\n\nThe decomposition rule then designates a particular reassembly rule, or set of reassembly rules, to follow when reconstructing the sentence. The reassembly rule then takes the fragments of the input that the decomposition rule had created, rearranges them, and adds in programmed words to create a response. Using Weizenbaum’s example previously stated, such a reassembly rule would take the fragments and apply them to the phrase “What makes you think I am (4)” which would result in “What makes you think I am very helpful”. This example is rather simple, since depending upon the disassembly rule, the output could be significantly more complex and use more of the input from the user. However, from this reassembly, ELIZA then sends the constructed sentence to the user in the form of text on the screen.\n\nThese steps represent the bulk of the procedures which ELIZA follows in order to create a response from a typical input, though there are several specialized situations that ELIZA/DOCTOR can respond to. One Weizenbaum specifically wrote about was when there is not a keyword. One solution was to have ELIZA respond with a remark that lacked content, such as “I see” or “Please go on.”. The second method was to use a “MEMORY” structure, which recorded prior recent inputs, and would use these inputs to create a response referencing a part of the earlier conversation when encountered with no keywords. This was possible due to Slip’s ability to tag words for other usage, which simultaneously allowed ELIZA to examine, store and repurpose words for usage in outputs.\n\nWhile these functions were all framed in ELIZA’s programming, the exact manner by which the program dismantled, examined, and reassembled inputs is determined by the operating script. However, the script is not static, and can be edited, or a new one created, as is necessary for the operation in the context needed (thus how ELIZA can “learn” new information). This also allows the program to be applied in multiple situations, including the well-known DOCTOR script, which simulates a Rogerian psychotherapist, but also a script called “STUDENT”, which is capable of taking in logical analysis parameters and using it to give the answers to problems of related logic.\n\nWeizenbaum's original MAD-SLIP implementation was re-written in Lisp by Bernie Cosell. A BASIC version appeared in Creative Computing in 1977 (although it was written in 1973 by Jeff Shrager). This version, which was ported to many of the earliest personal computers, appears to have been subsequently translated into many other versions in many other languages.\n\nAnother version of Eliza popular among software engineers is the version that comes with the default release of GNU Emacs, and which can be accessed by typing codice_1 from most modern emacs implementations.\n\nELIZA influenced a number of early computer games by demonstrating additional kinds of interface designs. Don Daglow wrote an enhanced version of the program called \"Ecala\" on a DEC PDP-10 minicomputer at Pomona College in 1973 before writing the computer role-playing game, \"Dungeon\" (1975).\n\nLay responses to ELIZA were disturbing to Weizenbaum and motivated him to write his book \"Computer Power and Human Reason: From Judgment to Calculation\", in which he explains the limits of computers, as he wants to make clear in people's minds his opinion that the anthropomorphic views of computers are just a reduction of the human being and any life form for that matter. In the independent documentary film \"Plug & Pray\" (2010) Weizenbaum said that only people who misunderstood ELIZA called it a sensation.\n\nThe Israeli poet David Avidan, who was fascinated with future technologies and their relation to art, desired to explore the use of computers for writing literature. He conducted several conversations with an APL implementation of ELIZA and published them – in English, and in his own translation to Hebrew – under the title \"My Electronic Psychiatrist – Eight Authentic Talks with a Computer\". In the foreword he presented it as a form of constrained writing.\n\nThere are many programs based on ELIZA in different programming languages. In 1980 a company called \"Don't Ask Software\" created a version called \"Abuse\" for the Apple II, Atari, and Commodore 64 computers, which verbally abused the user based on the user's input. Other versions adapted ELIZA around a religious theme, such as ones featuring Jesus (both serious and comedic) and another Apple II variant called \"I Am Buddha\". The 1980 game \"The Prisoner\" incorporated ELIZA-style interaction within its gameplay. George Lucas and Walter Murch incorporated an Eliza-like dialogue interface in their screenplay for the feature film \"THX-1138\" in 1969. Inhabitants of the underground future world of THX would retreat to \"confession booths\" when stressed, and initiate a one-sided Eliza-formula conversation with a Jesus-faced computer who claimed to be \"Omm\". In 1988 the British artist and friend of Weizenbaum Brian Reffin Smith created and showed at the exhibition 'Salamandre', in the Musée du Berry, Bourges, France, two art-oriented ELIZA-style programs written in BASIC, one called 'Critic' and the other 'Artist', running on two separate Amiga 1000 computers. The visitor was supposed to help them converse by typing in to 'Artist' what 'Critic' said, and vice versa. The secret was that the two programs were identical. GNU Emacs formerly had a codice_2 command that simulates a session between ELIZA and Zippy the Pinhead. The Zippyisms were removed due to copyright issues, but the DOCTOR program remains.\n\nELIZA has been referenced in popular culture and continues to be a source of inspiration for programmers and developers focused on Artificial Intelligence. It was also featured in a 2012 exhibit at Harvard University titled \"Go Ask A.L.I.C.E\", as part of a celebration of mathematician Alan Turing's 100th birthday. The exhibit explores Turing's lifelong fascination with the interaction between man and computer, pointing to ELIZA as one of the earliest realizations of Turing's ideas.\n\n\n\n\n\n"}
{"id": "10236", "url": "https://en.wikipedia.org/wiki?curid=10236", "title": "ELIZA effect", "text": "ELIZA effect\n\nThe ELIZA effect, in computer science, is the tendency to unconsciously assume computer behaviors are analogous to human behaviors, that is anthropomorphisation.\n\nIn its specific form, the ELIZA effect refers only to \"the susceptibility of people to read far more understanding than is warranted into strings of symbols — especially words — strung together by computers\". A trivial example of the specific form of the Eliza effect, given by Douglas Hofstadter, involves an automated teller machine which displays the words \"THANK YOU\" at the end of a transaction. A (very) casual observer might think that the machine is actually expressing gratitude; however, the machine is only printing a preprogrammed string of symbols.\n\nMore generally, the ELIZA effect describes any situation where, based solely on a system's output, users perceive computer systems as having \"intrinsic qualities and abilities which the software controlling the (output) cannot possibly achieve\" or \"assume that [outputs] reflect a greater causality than they actually do.\" In both its specific and general forms, the ELIZA effect is notable for occurring even when users of the system are aware of the determinate nature of output produced by the system. From a psychological standpoint, the ELIZA effect is the result of a subtle cognitive dissonance between the user's awareness of programming limitations and their behavior towards the output of the program. The discovery of the ELIZA effect was an important development in artificial intelligence, demonstrating the principle of using social engineering rather than explicit programming to pass a Turing test.\n\nThe effect is named for the 1966 chatterbot ELIZA, developed by MIT computer scientist Joseph Weizenbaum. When executing Weizenbaum's \"DOCTOR\" script, ELIZA parodied a Rogerian psychotherapist, largely by rephrasing the \"patient\"'s replies as questions:\n\nThough designed strictly as a mechanism to support \"natural language conversation\" with a computer, ELIZA's \"DOCTOR\" script was found to be surprisingly successful in eliciting emotional responses from users who, in the course of interacting with the program, began to ascribe understanding and motivation to the program's output. As Weizenbaum later wrote, \"I had not realized ... that extremely short exposures to a relatively simple computer program could induce powerful delusional thinking in quite normal people.\" Indeed, ELIZA's code had not been designed to evoke this reaction in the first place. Upon observation, researchers discovered users unconsciously assuming ELIZA's questions implied interest and emotional involvement in the topics discussed, \"even when they consciously knew that ELIZA did not simulate emotion\".\n\n\n"}
{"id": "10237", "url": "https://en.wikipedia.org/wiki?curid=10237", "title": "Exponentiation by squaring", "text": "Exponentiation by squaring\n\nIn mathematics and computer programming, exponentiating by squaring is a general method for fast computation of large positive integer powers of a number, or more generally of an element of a semigroup, like a polynomial or a square matrix. Some variants are commonly referred to as square-and-multiply algorithms or binary exponentiation. These can be of quite general use, for example in modular arithmetic or powering of matrices. For semigroups for which additive notation is commonly used, like elliptic curves used in cryptography, this method is also referred to as double-and-add.\n\nThe method is based on the observation that, for a positive integer \"n\", we have\n\nThis method uses the bits of the exponent to determine which powers are computed.\n\nThis example shows how to compute formula_2 using this method.\nThe exponent, 13, is 1101 in binary. The bits are used in left to right order.\nThe exponent has 4 bits, so there are 4 iterations.\n\nFirst, initialize the result to 1: formula_3.\n\nThis may be implemented as the following recursive algorithm: \nAlthough not tail-recursive, this algorithm may be rewritten into a tail recursive algorithm by introducing an auxiliary function:\n\nThe iterative version of the algorithm also uses a bounded auxiliary space, and is given by\n\nA brief analysis shows that such an algorithm uses formula_11 squarings and at most formula_11 multiplications, where formula_13 denotes the floor function. More precisely, the number of multiplications is one less than the number of ones present in the binary expansion of \"n\". For \"n\" greater than about 4 this is computationally more efficient than naively multiplying the base with itself repeatedly.\n\nEach squaring results in approximately double the number of digits of the previous, and so, if multiplication of two \"d\" digit numbers is implemented in O(\"d\") operations for some fixed \"k\" then the complexity of computing \"x\" is given by:\n\nThis algorithm calculates the value of x after expanding the exponent in base 2. It was first proposed by Brauer in 1939. In the algorithm below we make use of the following function f(0) = (k,0) and f(m) = (s,u) where m = u·2\nwith \"u\" odd.\n\nAlgorithm:\n\n\n\nFor optimal efficiency, \"k\" should be the smallest integer satisfying \n\nThis method is an efficient variant of the 2-ary method. For example, to calculate the exponent 398 which has binary expansion (110 001 110), we take a window of length 3 using the 2-ary method algorithm we calculate 1,x,x,x,x,x,x,x,x,x,x,x. \nBut, we can also compute 1,x,x,x,x,x,x,x,x,\nx which saves one multiplication and amounts to evaluating (110 001 110)n\n\nHere is the general algorithm:\n\nAlgorithm:\n\n\n\nAlgorithm:\n\nMany algorithms for exponentiation do not provide defence against side-channel attacks. Namely, an attacker observing the sequence of squarings and multiplications can (partially) recover the exponent involved in the computation. This is a problem if the exponent should remain secret, as with many public-key cryptosystems. A technique called Montgomery's Ladder addresses this concern.\n\nGiven the binary expansion of a positive, non-zero integer n=(n...n) with n=1 we can compute x as follows:\n\nThe algorithm performs a fixed sequence of operations (up to log n): a multiplication and squaring takes place for each bit in the exponent, regardless of the bit's specific value.\n\nThis specific implementation of Montgomery's ladder is not yet protected against cache timing attacks: memory access latencies might still be observable to an attacker as you access different variables depending on the value of bits of the secret exponent.\n\nThere are several methods which can be employed to calculate x when the base is fixed and the exponent varies. As one can see, precomputations play a key role in these algorithms.\n\nYao's method is orthogonal to the -ary method where the exponent is expanded in radix and the computation is as performed in the algorithm above. Let \"\", \"\", \"\", and \"\" be integers.\n\nLet the exponent \"\" be written as\n\nLet . Then the algorithm uses the equality\n\nGiven the element \" of , and the exponent \" written in the above form, along with the precomputed values the element is calculated using the algorithm below.\n\nIf we set and then the 's are simply the digits of in base . Yao's method collects in u first those which appear to the highest power ; in the next round those with power are collected in as well etc. The variable y is multiplied times with the initial , times with the next highest powers etc.\nThe algorithm uses multiplications and elements must be stored to compute .\n\nThe Euclidean method was first introduced in \"Efficient exponentiation using precomputation and vector addition chains\" by P.D Rooij.\n\nThis method for computing formula_22 in group , where is a natural integer, whose algorithm is given below, is using the following equality recursively:\n\nGiven the base element in group , and the exponent formula_25 written as in Yao's method, the element formula_22 is calculated using formula_27 precomputed values formula_28 and then the algorithm below.\n\nThe algorithm first finds the largest value amongst the and then the supremum within the set of .\nThen it raises to the power , multiplies this value with , and then assigns the result of this computation and the value modulo .\n\nThe same idea allows fast computation of large exponents modulo a number. Especially in cryptography, it is useful to compute powers in a ring of integers modulo \"q\". It can also be used to compute integer powers in a group, using the rule\n\nThe method works in every semigroup and is often used to compute powers of matrices.\n\nFor example, the evaluation of\n\nwould take a very long time and lots of storage space if the naïve method were used: compute 13789 then take the remainder when divided by 2345. Even using a more effective method will take a long time: square 13789, take the remainder when divided by 2345, multiply the result by 13789, and so on. This will take less than formula_29 modular multiplications.\n\nApplying above \"exp-by-squaring\" algorithm, with \"*\" interpreted as \"x\"*\"y\" = \"xy\" mod 2345 (that is a multiplication followed by a division with remainder) leads to only 27 multiplications and divisions of integers which may all be stored in a single machine word.\n\nThis is a non-recursive implementation of the above algorithm in Ruby.\n\nn=n-1 is redundant when n=n/2 implicitly rounds towards zero, as lower level languages would do.\nn[0] is the rightmost bit of the binary representation of n, so if it is 1, the number is odd, if it is zero, the number is even. It is also n modulo 2.\n\n parameter x = 3\n\n result := 3\n\nJavaScript-Demonstration: http://home.mnet-online.de/wzwz.de/temp/ebs/en.htm\n\nExponentiation by squaring may also be used to calculate the product of 2 or more powers.\nIf the underlying group or semigroup is commutative then it is often possible to reduce the\nnumber of multiplications by computing the product simultaneously.\n\nThe formula a×b may be calculated within 3 steps:\nso one gets eight multiplications in total.\n\nA faster solution is to calculate both powers simultaneously:\nwhich needs only 6 multiplications in total. Note that a×b is calculated twice; the result could be stored after the first calculation, which reduces the count of multiplication to 5.\n\nExample with numbers:\n\nCalculating the powers simultaneously instead of calculating them separately always reduces the\ncount of multiplications if at least two of the exponents are greater than 1.\n\nThe example above a×b may also be calculated with only 5\nmultiplications if the expression is transformed before calculation:\n\na×b = a×(ab) with ab := a×b\nGeneralization of transformation shows the following scheme:<br>\nFor calculating a×b×...×m×n<br>\n1st: define ab := a×b, abc = ab×c, ...<br>\n2nd: calculate the transformed expression a×ab×...×abc..m×abc..mn\n\nTransformation before calculation often reduces the count of multiplications\nbut in some cases it also increases the count (see the last one of the examples below),\nso it may be a good idea to check the count of multiplications before using the transformed expression for calculation.\n\nFor the following expressions the count of multiplications is shown for calculating each power separately,\ncalculating them simultaneously without transformation, and calculating them simultaneously after transformation.\nIn certain computations it may be more efficient to allow negative coefficients and hence use the inverse of the base, provided inversion in is 'fast' or has been precomputed. For example, when computing the binary method requires multiplications and squarings. However one could perform squarings to get and then multiply by to obtain .\n\nTo this end we define the signed-digit representation of an integer in radix as \n\nAnother algorithm by Koyama and Tsuruoka does not require the condition that formula_40; it still minimizes the Hamming weight.\n\nExponentiation by squaring can be viewed as a suboptimal addition-chain exponentiation algorithm: it computes the exponent via an addition chain consisting of repeated exponent doublings (squarings) and/or incrementing exponents by \"one\" (multiplying by \"x\") only. More generally, if one allows \"any\" previously computed exponents to be summed (by multiplying those powers of \"x\"), one can sometimes perform the exponentiation using fewer multiplications (but typically using more memory). The smallest power where this occurs is for \"n\"=15:\n\nIn general, finding the \"optimal\" addition chain for a given exponent is a hard problem, for which no efficient algorithms are known, so optimal chains are typically only used for small exponents (e.g. in compilers where the chains for small powers have been pre-tabulated). However, there are a number of heuristic algorithms that, while not being optimal, have fewer multiplications than exponentiation by squaring at the cost of additional bookkeeping work and memory usage. Regardless, the number of multiplications never grows more slowly than Θ(log \"n\"), so these algorithms only improve asymptotically upon exponentiation by squaring by a constant factor at best.\n\n"}
{"id": "10238", "url": "https://en.wikipedia.org/wiki?curid=10238", "title": "Exon", "text": "Exon\n\nAn exon is any part of a gene that will encode a part of the final mature RNA produced by that gene after introns have been removed by RNA splicing. The term \"exon\" refers to both the DNA sequence within a gene and to the corresponding sequence in RNA transcripts. In RNA splicing, introns are removed and exons are covalently joined to one another as part of generating the mature messenger RNA. Just as the entire set of genes for a species constitutes the genome, the entire set of exons constitutes the exome.\n\nThe term \"exon\" derives from the expressed region and was coined by American biochemist Walter Gilbert in 1978: \"The notion of the cistron… must be replaced by that of a transcription unit containing regions which will be lost from the mature messengerwhich I suggest we call introns (for intragenic regions)alternating with regions which will be expressedexons.\"\n\nThis definition was originally made for protein-coding transcripts that are spliced before being translated. The term later came to include sequences removed from rRNA and tRNA, and it also was used later for RNA molecules originating from different parts of the genome that are then ligated by trans-splicing.\n\nAlthough unicellular eukaryotes such as yeast have either no introns or very few, metazoans and especially vertebrate genomes have a large fraction of non-coding DNA. For instance, in the human genome only 1.1% of the genome is spanned by exons, whereas 24% is in introns, with 75% of the genome being intergenic DNA. This can provide a practical advantage in omics-aided health care (such as precision medicine) because it makes commercialized whole exome sequencing a smaller and less expensive challenge than commercialized whole genome sequencing. The large variation in genome size and C-value across life forms has posed an interesting challenge called the C-value enigma.\n\nAcross all eukaryotic genes in GenBank there were (in 2002), on average, 5.48 exons per gene. The average exon encoded 30-36 amino acids. While the longest exon in the human genome is 11555 bp long, several exons have been found to be only 2 bp long. A single-nucleotide exon has been reported from the \"Arabidopsis\" genome.\n\nIn protein-coding genes, the exons include both the protein-coding sequence and the 5′- and 3′-untranslated regions (UTR). Often the first exon includes both the 5′-UTR and the first part of the coding sequence, but exons containing only regions of 5′-UTR or (more rarely) 3′-UTR occur in some genes, i.e. the UTRs may contain introns. Some non-coding RNA transcripts also have exons and introns. \n\nMature mRNAs originating from the same gene need not include the same exons, since different introns in the pre-mRNA can be removed by the process of alternative splicing. \n\nExonization is the creation of a new exon, as a result of mutations in introns.\n\nExon trapping or 'gene trapping' is a molecular biology technique that exploits the existence of the intron-exon splicing to find new genes. The first exon of a 'trapped' gene splices into the exon that is contained in the insertional DNA. This new exon contains the ORF for a reporter gene that can now be expressed using the enhancers that control the target gene. A scientist knows that a new gene has been trapped when the reporter gene is expressed.\n\nSplicing can be experimentally modified so that targeted exons are excluded from mature mRNA transcripts by blocking the access of splice-directing small nuclear ribonucleoprotein particles (snRNPs) to pre-mRNA using Morpholino antisense oligos. This has become a standard technique in developmental biology. Morpholino oligos can also be targeted to prevent molecules that regulate splicing (e.g. splice enhancers, splice suppressors) from binding to pre-mRNA, altering patterns of splicing.\n\n\n\n"}
{"id": "10239", "url": "https://en.wikipedia.org/wiki?curid=10239", "title": "Exxon", "text": "Exxon\n\nExxon was the brand name of oil and natural resources company Exxon Corporation, prior to 1972 known as Standard Oil Company of New Jersey. In 1999, Exxon Corporation merged with Mobil to form ExxonMobil. The \"Exxon\" brand is still used by ExxonMobil's downstream operations as a brand for certain of its gas stations, motor fuel and related products (the highest concentration of which are located in New Jersey, Pennsylvania, Texas and in the Mid-Atlantic and Southeastern states). Standard Oil Company of New Jersey was one of the Seven Sisters that dominated the global petroleum industry from the mid-1940s to the 1970s.\n\nExxon replaced the Esso, Enco, and Humble brands in the United States on January 1, 1973. The Esso name was a trademark of Standard Oil Company of New Jersey, and attracted protests from other Standard Oil spinoffs because of its phonetic similarity to the acronym of the name of the parent company, Standard Oil. As a result, Standard Oil Company of New Jersey was restricted from using Esso in the U.S., except in those states awarded to it in the 1911 Standard Oil antitrust settlement.\n\nIn states where it was restricted from using the Esso name, the company marketed under the Humble or Enco brands. The Humble brand was used at Texas stations for decades, as those operations were under the direction of Standard Oil Company of New Jersey affiliate Humble Oil & Refining Company. In the middle to late 1950s, use of the Humble brand spread to other southwestern states, including Arizona, New Mexico, and Oklahoma.\n\nIn 1959, Standard Oil Company of New Jersey secured full control of Humble Oil and restructured it into its U.S. marketing and refining division, to market nationwide under the Enco, Esso and Humble brands. Enco was created as an acronym for the phrase \"Energy Company\". Humble introduced the Enco brand in 1960 in Oklahoma and surrounding states, to replace Humble's subsidiary Oklahoma and Pate brands. Humble also tried marketing under Enco in Ohio, but Standard Oil Company of Ohio (Sohio) protested that the Enco name and logo (a white oval with blue border and red lettering) too closely resembled that of Esso. Consequently, stations in Ohio were rebranded as Humble, and remained so until the Exxon brand came into use.\n\nAfter the Enco brand was discontinued in Ohio, it was moved to other non-Esso states. In 1961, Humble stations in Arizona, New Mexico, Oklahoma and Texas were rebranded to Enco. That same year, Enco appeared on former Carter stations in the Midwest and the Pacific Northwest.\n\nIn 1963, Humble Oil and Tidewater Oil Company began negotiating a sale of Tidewater's West Coast refining and marketing operations. The sale would have given Humble Oil a large number of existing Flying A stations and distributorships, as well as a refinery in California, the nation's fastest-growing gasoline market. However, the Justice Department objected to the sale on anti-trust grounds. (In 1966, Phillips Petroleum Company bought Tidewater's western properties and rebranded all Flying A outlets to Phillips 66.)\n\nHumble Oil continued to expand its West Coast operations, adding California to its marketing territory, building a large number of new Enco stations and rebranding others. In 1967, Humble Oil purchased all remaining Signal stations from Standard Oil Company of California (Chevron) and rebranded them as Enco outlets, greatly increasing Enco's presence in California. Finally, in 1969, Humble Oil opened a new refinery in Benicia, California.\n\nIn 1966, the U.S. Justice Department ordered Humble Oil to \"cease and desist\" from using the Esso brand at stations in several southeastern states, following protests from Standard Oil of Kentucky (Kyso), which was a Standard Oil of California subsidiary in the process of rebranding its Standard stations to Chevron. By 1967, Humble Oil's Esso stations in the Southeast were rebranded to Enco.\n\nIn the 1960s and early 1970s, Humble Oil continued to have difficulties promoting itself as a nationwide marketer of petroleum products, despite a number of high-profile marketing strategies. These included the popular \"Put a Tiger in Your Tank\" advertising campaign and accompanying tiger mascot, introduced in 1959, to promote Enco Extra and Esso Extra gasolines. Humble Oil also used similar logotypes, use of the Humble name in all Enco and Esso advertising, and uniform designs for all stations regardless of brand. In addition, Humble Oil was a major promoter and broadcast sponsor for college football in the Pacific-8 (now Pac-12) and Southwestern conferences.\n\nBut Humble Oil still faced stiff competition from such national brands such as Shell and Texaco, which at that time was the only company to market under one brand name in all 50 states. By the late 1960s, Humble officials realized that the time had come to develop a new brand name that could be used nationwide.\n\nAt first, consideration was given to simply rebranding all stations as Enco, but that was shelved when it was learned that the word \"Enco\" is similar in pronunciation to the Japanese slang term \"enko\", meaning \"stalled car\" (an abbreviation of \"enjin no kosho\", \"engine breakdown\").\n\nIn 1972, Exxon was unveiled as the new, unified brand name for all former Enco and Esso outlets. At the same time, the company changed its corporate name from Standard Oil of New Jersey to Exxon Corporation. The rebranding came after successful test-marketing of the Exxon name, under two experimental logos, in the fall and winter of 1971–1972. Along with the new name, Exxon settled on a rectangular logo using red lettering and blue trim on a white background, similar to the familiar color scheme on the old Enco and Esso logos.\n\nThe company initially planned to change its name to \"Exon\", in keeping with the four-letter format of Enco and Esso. However, during the planning process, it was noted that James Exon was the governor of Nebraska. Renaming the company after a sitting governor seemed ill-advised, and the second \"x\" was added to the new name and logo.\n\nThe unrestricted international use of the popular Esso brand prompted Exxon to continue using it outside the U.S. Esso is the only widely used Standard Oil descendant brand left in existence. Others, such as Chevron, maintain a few Standard-branded stations in specific states in order to retain their trademarks and prevent others from using them.\n\nIn 1989, Exxon announced that it was moving its headquarters, including about 300 employees, from Manhattan, New York City to the Las Colinas area of Irving, Texas. Exxon sold the Exxon Building (1251 Avenue of the Americas), its former headquarters in Rockefeller Center, to a unit of Mitsui Real Estate Development Co. Ltd. in 1986 for $610 million. John Walsh, president of Exxon subsidiary Friendswood Development Company, stated that Exxon left New York because the costs were too high. In 2009 Exxon partnered with Turner Ridge Capital Management to develop and finance their U.S. alternative energy Infastructure.\n\nIn 2016, ExxonMobil successfully asked a U.S. federal court to lift the aforementioned trademark injunction that banned it from using the Esso brand in various states. By this time, as a result of numerous mergers and rebranding, the remaining Standard Oil companies that previously objected to the Esso name had been acquired by BP. ExxonMobil cited trademark surveys in which there was no longer possible confusion with the Esso name as it was more than seven decades before. BP also had no objection to lift the ban. ExxonMobil did not specify whether they would now open new stations in the U.S. under the Esso name; they were primarily concerned about the additional expenses of having separate marketing, letterheads, packaging, and other materials that omit \"Esso\".\n\nThe rectangular Exxon logo, with the blue strip at the bottom and red lettering with the two 'X's interlinked together, was designed by noted industrial stylist Raymond Loewy. The interlinked 'X's are incorporated in the modern-day ExxonMobil corporate logo, but the original Exxon logo continues for marketing and station signage. MAD Magazine spoofed the logo by showing a huge sign above the White House: \n\"NIXXON\" with the caption: \"..but it's still the same old gas!\"\n\nIn 1985, Minolta introduced a new autofocus SLR camera system named \"Maxxum\" in the United States. Originally, cameras (such as the Maxxum 7000) lenses and flashes used a logo with the X's crossed in 'MAXXUM'. Exxon considered this a violation of their trademark, and as a result, Minolta was allowed to distribute cameras already produced, but was forced to change the stylistic 'XX' and implement this as a change in new production.\n\nExxon is ExxonMobil's primary retail gasoline brand in most of the United States, with the highest concentration of retail outlets located in New Jersey, Pennsylvania, Texas and in the Mid-Atlantic and Southeastern states. The Exxon brand has a significant market presence in the following metropolitan areas:\n\nMobil is the company's primary retail gasoline brand in California, Florida, New York, New England, the Great Lakes and the Midwest. Esso is ExxonMobil's primary gasoline brand worldwide except in Australia and New Zealand, where the Mobil brand is used exclusively. In Colombia, both the Esso and Mobil brands are used.\n"}
{"id": "10243", "url": "https://en.wikipedia.org/wiki?curid=10243", "title": "Exxon Valdez oil spill", "text": "Exxon Valdez oil spill\n\nThe \"Exxon Valdez\" oil spill occurred in Prince William Sound, Alaska, March 24, 1989, when \"Exxon Valdez\", an oil tanker owned by Exxon Shipping Company, bound for Long Beach, California, struck Prince William Sound's Bligh Reef at 12:04 am local time and spilled of crude oil over the next few days. It is considered to be one of the most devastating human-caused environmental disasters. The \"Valdez\" spill is the second largest in US waters, after the 2010 \"Deepwater Horizon\" oil spill, in terms of volume released. Prince William Sound's remote location, accessible only by helicopter, plane, or boat, made government and industry response efforts difficult and severely taxed existing response plans. The region is a habitat for salmon, sea otters, seals and seabirds. The oil, originally extracted at the Prudhoe Bay oil field, eventually covered of coastline, and of ocean.\n\nAccording to official reports, the ship was carrying of oil, of which about were spilled into the Prince William Sound. An approximate figure of was a commonly accepted estimate of the spill's volume and has been used by the State of Alaska's \"Exxon Valdez\" Oil Spill Trustee Council, the National Oceanic and Atmospheric Administration and environmental groups such as Greenpeace and the Sierra Club.\n\nMultiple factors have been identified as contributing to the incident\n\nCaptain Joseph Hazelwood, who was widely reported to have been drinking heavily that night, was not at the controls when the ship struck the reef. However, as the senior officer, he was in command of the ship even though he was asleep in his bunk. In light of the other findings, investigative reporter Greg Palast stated in 2008, \"Forget the drunken skipper fable. As to Captain Joe Hazelwood, he was below decks, sleeping off his bender. At the helm, the third mate never would have collided with Bligh Reef had he looked at his RAYCAS radar. But the radar was not turned on. In fact, the tanker's radar was left broken and disabled for more than a year before the disaster, and Exxon management knew it. It was just too expensive to fix and operate.\" Exxon blamed Captain Hazelwood for the grounding of the tanker.\n\nOther factors, according to an MIT course entitled \"Software System Safety\" by Professor Nancy G. Leveson, included:\nThis disaster resulted in International Maritime Organization introducing comprehensive marine pollution prevention rules (MARPOL) through various conventions. The rules were ratified by member countries and, under International Ship Management rules, the ships are being operated with a common objective of \"safer ships and cleaner oceans\".\n\nIn 2009, \"Exxon Valdez\" Captain Joseph Hazelwood offered a \"heartfelt apology\" to the people of Alaska, suggesting he had been wrongly blamed for the disaster: \"The true story is out there for anybody who wants to look at the facts, but that's not the sexy story and that's not the easy story,\" he said. Hazelwood said he felt Alaskans always gave him a fair shake.\n\nChemical dispersant, a surfactant and solvent mixture, was applied to the slick by a private company on March 24 with a helicopter. Scientific data on its toxicity were either thin or incomplete. In addition, public acceptance of a new, widespread chemical treatment was lacking. Landowners, fishing groups, and conservation organizations questioned the use of chemicals on hundreds of miles of shoreline when other alternatives may have been available.\"\n\nAccording to a report by David Kirby for TakePart, the main component of the Corexit formulation used during cleanup, 2-butoxyethanol, was identified as \"one of the agents that caused liver, kidney, lung, nervous system, and blood disorders among cleanup crews in Alaska following the 1989 \"Exxon Valdez\" spill.\n\nMechanical cleanup was started shortly afterwards using booms and skimmers, but the skimmers were not readily available during the first 24 hours following the spill, and thick oil and kelp tended to clog the equipment. Despite civilian insistence for a complete clean, only 10% of total oil was actually completely cleaned. Exxon was widely criticized for its slow response to cleaning up the disaster and John Devens, the mayor of Valdez, has said his community felt betrayed by Exxon's inadequate response to the crisis. More than 11,000 Alaska residents, along with some Exxon employees, worked throughout the region to try to restore the environment.\nBecause Prince William Sound contained many rocky coves where the oil collected, the decision was made to displace it with high-pressure hot water. However, this also displaced and destroyed the microbial populations on the shoreline; many of these organisms (e.g. plankton) are the basis of the coastal marine food chain, and others (e.g. certain bacteria and fungi) are capable of facilitating the biodegradation of oil. At the time, both scientific advice and public pressure was to clean everything, but since then, a much greater understanding of natural and facilitated remediation processes has developed, due somewhat in part to the opportunity presented for study by the \"Exxon Valdez\" spill. Despite the extensive cleanup attempts, less than ten percent of the oil was recovered and a study conducted by NOAA determined that as of early 2007 more than of oil remain in the sandy soil of the contaminated shoreline, declining at a rate of less than 4% per year.\nBoth the long-term and short-term effects of the oil spill have been studied. Immediate effects included the deaths of 100,000 to as many as 250,000 seabirds, at least 2,800 sea otters, approximately 12 river otters, 300 harbor seals, 247 bald eagles, and 22 orcas, and an unknown number of salmon and herring.\n\nIn 2003, fourteen years after the spill, a team from the University of North Carolina found that the remaining oil was lasting far longer than anticipated, which in turn had resulted in more long-term loss of many species than had been expected. The researchers found that at only a few parts per billion, polycyclic aromatic hydrocarbons caused a long-term increase in mortality rates. They reported that \"species as diverse as sea otters, harlequin ducks and killer whales suffered large, long-term losses and that oiled mussel beds and other tidal shoreline habitats will take an estimated 30 years to recover.\"\n\nIn 2006, a study done by the National Marine Fisheries Service in Juneau found that about of shoreline around Prince William Sound was still affected by the spill, with 101.6 tonnes of oil remaining in the area. Exxon Mobil denied any concerns over any remaining oil, stating that they anticipated a remaining fraction that they assert will not cause any long-term ecological impacts, according to the conclusions of the studies they had done: \"We've done 350 peer-reviewed studies of Prince William Sound, and those studies conclude that Prince William Sound has recovered, it's healthy and it's thriving.\" However, in 2007 a NOAA study concluded that this contamination can produce chronic low-level exposure, discourage subsistence where the contamination is heavy, and decrease the \"wilderness character\" of the area.\n\nThe effects of the spill continued to be felt for many years afterwards. As of 2010 there were an estimated of Valdez crude oil still in Alaska's sand and soil, breaking down at a rate estimated at less than 4% per year.\n\nOn March 24, 2014, the twenty-fifth anniversary of the spill, NOAA scientists reported that some species seem to have recovered, with the sea otter the latest creature to return to pre-spill numbers. Scientists who have monitored the spill area for the last 25 years report that concern remains for one of two pods of local orca whales, with fears that one pod may eventually die out. Federal scientists estimate that between 16,000 and 21,000 US gallons (61 to 79 m) of oil remains on beaches in Prince William Sound and up to 450 miles (725 km) away. Some of the oil does not appear to have biodegraded at all. A USGS scientist who analyses the remaining oil along the coastline states that it remains among rocks and between tide marks. \"The oil mixes with seawater and forms an emulsion...Left out, the surface crusts over but the inside still has the consistency of mayonnaise – or mousse.\" Alaska state senator Berta Gardner is urging Alaskan politicians to demand that the US government force ExxonMobil to pay the final $92 million (£57 million) still owed from the court settlement. The major part of the money would be spent to finish cleaning up oiled beaches and attempting to restore the crippled herring population.\n\nIn the case of \"Exxon v. Baker\", an Anchorage jury awarded $287 million for actual damages and $5 billion for punitive damages. To protect itself in case the judgment was affirmed, Exxon obtained a $4.8 billion credit line from J.P. Morgan & Co. J.P. Morgan created the first modern credit default swap in 1994, so that Morgan's would not have to hold as much money in reserve (8% of the loan under Basel I) against the risk of Exxon's default.\n\nMeanwhile, Exxon appealed the ruling, and the 9th U.S. Circuit Court of Appeals ordered the original judge, Russel Holland, to reduce the punitive damages. On December 6, 2002, the judge announced that he had reduced the damages to $4 billion, which he concluded was justified by the facts of the case and was not grossly excessive. Exxon appealed again and the case returned to court to be considered in light of a recent Supreme Court ruling in a similar case, which caused Judge Holland to increase the punitive damages to $4.5 billion, plus interest.\n\nAfter more appeals, and oral arguments heard by the 9th Circuit Court of Appeals on January 27, 2006, the damages award was cut to $2.5 billion on December 22, 2006. The court cited recent Supreme Court rulings relative to limits on punitive damages.\n\nExxon appealed again. On May 23, 2007, the 9th Circuit Court of Appeals denied ExxonMobil's request for a third hearing and let stand its ruling that Exxon owes $2.5 billion in punitive damages. Exxon then appealed to the Supreme Court, which agreed to hear the case. On February 27, 2008, the Supreme Court heard oral arguments for 90 minutes. Justice Samuel Alito, who at the time, owned between $100,000 and $250,000 in Exxon stock, recused himself from the case. In a decision issued June 25, 2008, Justice David Souter issued the judgment of the court, vacating the $2.5 billion award and remanding the case back to the lower court, finding that the damages were excessive with respect to maritime common law. Exxon's actions were deemed \"worse than negligent but less than malicious.\" The punitive damages were further reduced to an amount of $507.5 million. The Court's ruling was that maritime punitive damages should not exceed the compensatory damages, supported by a peculiar precedent dating back from 1818. Senate Judiciary Committee Chairman Patrick J. Leahy has decried the ruling as \"another in a line of cases where this Supreme Court has misconstrued congressional intent to benefit large corporations.\"\n\nExxon's official position was that punitive damages greater than $25 million were not justified because the spill resulted from an accident, and because Exxon spent an estimated $2 billion cleaning up the spill and a further $1 billion to settle related civil and criminal charges. Attorneys for the plaintiffs contended that Exxon bore responsibility for the accident because the company \"put a drunk in charge of a tanker in Prince William Sound.\"\n\nExxon recovered a significant portion of clean-up and legal expenses through insurance claims associated with the grounding of the \"Exxon Valdez\". Also, in 1991, Exxon made a quiet, separate financial settlement of damages with a group of seafood producers known as the Seattle Seven for the disaster's effect on the Alaskan seafood industry. The agreement granted $63.75 million to the Seattle Seven, but stipulated that the seafood companies would have to repay almost all of any punitive damages awarded in other civil proceedings. The $5 billion in punitive damages was awarded later, and the Seattle Seven's share could have been as high as $750 million if the damages award had held. Other plaintiffs have objected to this secret arrangement, and when it came to light, Judge Holland ruled that Exxon should have told the jury at the start that an agreement had already been made, so the jury would know exactly how much Exxon would have to pay.\n\nAs of December 15, 2009, Exxon paid all owed $507.5 million punitive damages, including lawsuit costs, plus interest, which were further distributed to thousands of plaintiffs.\n\nIn October 1989, Exxon filed suit against the State of Alaska, charging that the government had interfered with Exxon's attempts to clean up the spill by refusing to approve the use of dispersant chemicals until the night of the 26th. The government disputed the claim, stating that there was a long-standing agreement to allow the use of dispersants to clean up spills, thus Exxon did not require permission to use them, and that in fact Exxon had not had enough dispersant on hand to effectively handle a spill of the size created by the \"Valdez\". Exxon filed claims in October 1990 against the Coast Guard, asking to be reimbursed for cleanup costs and damages awarded to plaintiffs in any lawsuits filed by the State of Alaska or the Federal Government against Exxon. The company claimed that the Coast Guard was \"wholly or partially responsible\" for the spill, because they had granted mariners' licenses to the crew of the Valdez, and because they had given the \"Valdez\" permission to leave regular shipping lanes to avoid ice. They also reiterated the claim that the Coast Guard had delayed cleanup by refusing to give permission to use chemical dispersants on the spill immediately.\n\nThe Oil Spill Recovery Institute was formed after United States Congress approved it to seek a solution. Collaborating with InnoCentive they found a partial solution for the flow of oil.\n\nA report by the US National Response Team summarized the event and made a number of recommendations, such as changes to the work patterns of Exxon crew in order to address the causes of the accident.\n\nIn response to the spill, the United States Congress passed the Oil Pollution Act of 1990 (OPA). The legislation included a clause that prohibits any vessel that, after March 22, 1989, has caused an oil spill of more than in any marine area, from operating in Prince William Sound.\n\nIn April 1998, the company argued in a legal action against the Federal government that the ship should be allowed back into Alaskan waters. Exxon claimed OPA was effectively a bill of attainder, a regulation that was unfairly directed at Exxon alone. In 2002, the 9th Circuit Court of Appeals ruled against Exxon. As of 2002, OPA had prevented 18 ships from entering Prince William Sound.\n\nOPA also set a schedule for the gradual phase in of a double hull design, providing an additional layer between the oil tanks and the ocean. While a double hull would likely not have prevented the \"Valdez\" disaster, a Coast Guard study estimated that it would have cut the amount of oil spilled by 60 percent.\n\nThe \"Exxon Valdez\" supertanker was towed to San Diego, arriving on July 10. Repairs began on July 30. Approximately of steel were removed and replaced. In June 1990 the tanker, renamed \"S/R Mediterranean\", left harbor after $30 million of repairs. It was still sailing as of January 2010, registered in Panama. The vessel was then owned by a Hong Kong company, who operated it under the name \"Oriental Nicety\". In August 2012, it was beached at Alang, India and dismantled.\n\nIn the aftermath of the spill, Alaska governor Steve Cowper issued an executive order requiring two tugboats to escort every loaded tanker from Valdez out through Prince William Sound to Hinchinbrook Entrance. As the plan evolved in the 1990s, one of the two routine tugboats was replaced with a Escort Response Vehicle (ERV). Tankers at Valdez are no longer single-hulled. Congress enacted legislation requiring all tankers to be double-hulled as of 2015.\n\nIn 1991, following the collapse of the local marine population (particularly clams, herring and seals) the Chugach Alaska Corporation, an Alaska Native Corporation, filed for Chapter 11 bankruptcy protection. It has since recovered.\n\nAccording to several studies funded by the state of Alaska, the spill had both short-term and long-term economic effects. These included the loss of recreational sports, fisheries, reduced tourism, and an estimate of what economists call \"existence value\", which is the value to the public of a pristine Prince William Sound.\n\nThe economy of the city of Cordova, Alaska was adversely affected after the spill damaged stocks of salmon and herring in the area.\n\nIn 2010, a CNN report alleged that many oil spill cleanup workers involved in the \"Exxon Valdez\" response had subsequently become sick. Anchorage lawyer Dennis Mestas found that this was true of 6,722 of 11,000 worker files he was able to inspect. Access to the records was controlled by Exxon. Exxon responded in a statement to CNN:\"After 20 years, there is no evidence suggesting that either cleanup workers or the residents of the communities affected by the Valdez spill have had any adverse health effects as a result of the spill or its cleanup.\"\n\nIn 1992, Exxon released a video titled \"Scientists and the Alaska Oil Spill\", to be distributed to schools. Dr. Michael Fry called it a piece of \"corporate propaganda\".\n\nIn December 1994, the Unabomber assassinated Burson-Marsteller executive Thomas Mosser, accusing him of having \"helped Exxon clean up its public image after the \"Exxon Valdez\" incident\". The PR company claimed not to have been contracted during the actual crisis.\n\n\n"}
{"id": "10244", "url": "https://en.wikipedia.org/wiki?curid=10244", "title": "Édouard de Pomiane", "text": "Édouard de Pomiane\n\nÉdouard Alexandre de Pomiane, sometimes Édouard Pozerski (20 April 1875 in Paris – 26 January 1964 in Paris) was a French scientist, radio broadcaster and food writer.\nHis parents emigrated from Poland in 1863, changed their name from \"Pozerski\" to \"de Pomiane\", and became French citizens.\n\nDe Pomiane worked as a physician at the Institut Pasteur in Paris, where he gave Félix d'Herelle a place to work on bacteriophages.\n\nHis best known works that have been translated into English are \"Cooking in Ten Minutes\" and \"Cooking with Pomiane\". His writing was remarkable in its time for its directness (he frequently uses a strange second-person voice, telling you—the reader—what you are seeing and smelling as you follow a recipe) and for his general disdain for upper-class elaborate French cuisine. He travelled widely and quite a few of his recipes are from abroad. His recipes often take pains to demystify cooking by explaining the chemical processes at work.\n\n\"Vingt Plats Qui Donnent Goutte\"IMG_7221.jpeg 1935 edition.\n\n"}
{"id": "10245", "url": "https://en.wikipedia.org/wiki?curid=10245", "title": "Edward VI of England", "text": "Edward VI of England\n\nEdward VI (12 October 1537 – 6 July 1553) was King of England and Ireland from 28 January 1547 until his death. He was crowned on 20 February at the age of nine. The son of Henry VIII and Jane Seymour, Edward was England's first monarch to be raised as a Protestant. During his reign, the realm was governed by a Regency Council because he never reached his majority. The Council was first led by his uncle Edward Seymour, 1st Duke of Somerset (1547–1549), and then by John Dudley, 1st Earl of Warwick, from 1551 Duke of Northumberland. \n\nEdward's reign was marked by economic problems and social unrest that in 1549 erupted into riot and rebellion. An expensive war with Scotland, at first successful, ended with military withdrawal from Scotland as well as Boulogne-sur-Mer in exchange for peace. The transformation of the Church of England into a recognisably Protestant body also occurred under Edward, who took great interest in religious matters. Although his father, HenryVIII, had severed the link between the Church and Rome, HenryVIII had never permitted the renunciation of Catholic doctrine or ceremony. It was during Edward's reign that Protestantism was established for the first time in England with reforms that included the abolition of clerical celibacy and the Mass and the imposition of compulsory services in English. \n\nIn February 1553, at age 15, Edward fell ill. When his sickness was discovered to be terminal, he and his Council drew up a \"Devise for the Succession\", attempting to prevent the country's return to Catholicism. Edward named his first cousin once removed, Lady Jane Grey, as his heir and excluded his half-sisters, Mary and Elizabeth. This decision was disputed following Edward's death, and Jane was deposed by Mary nine days after becoming queen. During her reign, Mary reversed Edward's Protestant reforms, which nonetheless became the basis of the Elizabethan Religious Settlement of 1559.\n\nEdward was born on 12 October 1537 in his mother's room inside Hampton Court Palace, in Middlesex. He was the son of King Henry VIII by his third wife, Jane Seymour. Throughout the realm, the people greeted the birth of a male heir, \"whom we hungered for so long\", with joy and relief. \"Te Deums\" were sung in churches, bonfires lit, and \"their was shott at the Tower that night above two thousand gonnes\". Queen Jane, appearing to recover quickly from the birth, sent out personally signed letters announcing the birth of \"a Prince, conceived in most lawful matrimony between my Lord the King's Majesty and us\". Edward was christened on 15 October, with his half-sisters, the 21-year-old Lady Mary as godmother and the 4-year-old Lady Elizabeth carrying the chrisom; and the Garter King of Arms proclaimed him as Duke of Cornwall and Earl of Chester. The Queen, however, fell ill on 23 October from presumed postnatal complications, and died the following night. Henry VIII wrote to Francis I of France that \"Divine Providence ... hath mingled my joy with bitterness of the death of her who brought me this happiness\".\n\nEdward was a healthy baby who suckled strongly from the outset. His father was delighted with him; in May 1538, Henry was observed \"dallying with him in his arms ... and so holding him in a window to the sight and great comfort of the people\". That September, the Lord Chancellor, Lord Audley, reported Edward's rapid growth and vigour; and other accounts describe him as a tall and merry child. The tradition that Edward VI was a sickly boy has been challenged by more recent historians. At the age of four, he fell ill with a life-threatening \"quartan fever\", but, despite occasional illnesses and poor eyesight, he enjoyed generally good health until the last six months of his life.\n\nEdward was initially placed in the care of Margaret Bryan, \"lady mistress\" of the prince's household. She was succeeded by Blanche Herbert, Lady Troy. Until the age of six, Edward was brought up, as he put it later in his \"Chronicle\", \"among the women\". The formal royal household established around Edward was, at first, under Sir William Sidney, and later Sir Richard Page, stepfather of Edward Seymour's wife, Anne Stanhope. Henry demanded exacting standards of security and cleanliness in his son's household, stressing that Edward was \"this whole realm's most precious jewel\". Visitors described the prince, who was lavishly provided with toys and comforts, including his own troupe of minstrels, as a contented child. \n\nFrom the age of six, Edward began his formal education under Richard Cox and John Cheke, concentrating, as he recalled himself, on \"learning of tongues, of the scripture, of philosophy, and all liberal sciences\". He received tuition from Elizabeth's tutor, Roger Ascham, and Jean Belmain, learning French, Spanish and Italian. In addition, he is known to have studied geometry and learned to play musical instruments, including the lute and the virginals. He collected globes and maps and, according to coinage historian C. E. Challis, developed a grasp of monetary affairs that indicated a high intelligence. Edward's religious education is assumed to have favoured the reforming agenda. His religious establishment was probably chosen by Archbishop Thomas Cranmer, a leading reformer. Both Cox and Cheke were \"reformed\" Catholics or Erasmians and later became Marian exiles. By 1549, Edward had written a treatise on the pope as Antichrist and was making informed notes on theological controversies. Many aspects of Edward's religion were essentially Catholic in his early years, including celebration of the mass and reverence for images and relics of the saints.\n\nBoth Edward's sisters were attentive to their brother and often visited him – on one occasion, Elizabeth gave him a shirt \"of her own working\". Edward \"took special content\" in Mary's company, though he disapproved of her taste for foreign dances; \"I love you most\", he wrote to her in 1546. In 1543, Henry invited his children to spend Christmas with him, signalling his reconciliation with his daughters, whom he had previously illegitimised and disinherited. The following spring, he restored them to their place in the succession with a Third Succession Act, which also provided for a regency council during Edward's minority. This unaccustomed family harmony may have owed much to the influence of Henry's new wife, Catherine Parr, of whom Edward soon became fond. He called her his \"most dear mother\" and in September 1546 wrote to her: \"I received so many benefits from you that my mind can hardly grasp them.\"\n\nOther children were brought to play with Edward, including the granddaughter of Edward's chamberlain, Sir William Sidney, who in adulthood recalled the prince as \"a marvellous sweet child, of very mild and generous condition\". Edward was educated with sons of nobles, \"appointed to attend upon him\" in what was a form of miniature court. Among these, Barnaby Fitzpatrick, son of an Irish peer, became a close and lasting friend. Edward was more devoted to his schoolwork than his classmates and seems to have outshone them, motivated to do his \"duty\" and compete with his sister Elizabeth's academic prowess. Edward's surroundings and possessions were regally splendid: his rooms were hung with costly Flemish tapestries, and his clothes, books, and cutlery were encrusted with precious jewels and gold. Like his father, Edward was fascinated by military arts, and many of his portraits show him wearing a gold dagger with a jewelled hilt, in imitation of Henry. Edward's \"Chronicle\" enthusiastically details English military campaigns against Scotland and France, and adventures such as John Dudley's near capture at Musselburgh in 1547.\n\nOn 1 July 1543, Henry VIII signed the Treaty of Greenwich with the Scots, sealing the peace with Edward's betrothal to the seven-month-old Mary, Queen of Scots. The Scots were in a weak bargaining position after their defeat at Solway Moss the previous November, and Henry, seeking to unite the two realms, stipulated that Mary be handed over to him to be brought up in England. When the Scots repudiated the treaty in December 1543 and renewed their alliance with France, Henry was enraged. In April 1544, he ordered Edward's uncle, Edward Seymour, Earl of Hertford, to invade Scotland and \"put all to fire and sword, burn Edinburgh town, so razed and defaced when you have sacked and gotten what ye can of it, as there may remain forever a perpetual memory of the vengeance of God lightened upon [them] for their falsehood and disloyalty\". Seymour responded with the most savage campaign ever launched by the English against the Scots. The war, which continued into Edward's reign, has become known as \"The Rough Wooing\".\n\nThe nine-year-old Edward wrote to his father and stepmother on 10 January 1547 from Hertford thanking them for his new year's gift of their portraits from life. By 28 January 1547, Henry VIII was dead. Those close to the throne, led by Edward Seymour and William Paget, agreed to delay the announcement of the king's death until arrangements had been made for a smooth succession. Seymour and Sir Anthony Browne, the Master of the Horse, rode to collect Edward from Hertford and brought him to Enfield, where Lady Elizabeth was living. He and Elizabeth were then told of the death of their father and heard a reading of the will.\n\nThe Lord Chancellor, Thomas Wriothesley, announced Henry's death to parliament on 31 January, and general proclamations of Edward's succession were ordered. The new king was taken to the Tower of London, where he was welcomed with \"great shot of ordnance in all places there about, as well out of the Tower as out of the ships\". The following day, the nobles of the realm made their obeisance to Edward at the Tower, and Seymour was announced as Protector. Henry VIII was buried at Windsor on 16 February, in the same tomb as Jane Seymour, as he had wished.\n\nEdward VI was crowned at Westminster Abbey four days later on Sunday 20 February. The ceremonies were shortened, because of the \"tedious length of the same which should weary and be hurtsome peradventure to the King's majesty, being yet of tender age\", and also because the Reformation had rendered some of them inappropriate.\n\nOn the eve of the coronation, Edward progressed on horseback from the Tower to the Palace of Westminster through thronging crowds and pageants, many based on the pageants for a previous boy king, Henry VI. He laughed at a Spanish tightrope walker who \"tumbled and played many pretty toys\" outside St Paul's Cathedral.\n\nAt the coronation service, Cranmer affirmed the royal supremacy and called Edward a second Josiah, urging him to continue the reformation of the Church of England, \"the tyranny of the Bishops of Rome banished from your subjects, and images removed\". After the service, Edward presided at a banquet in Westminster Hall, where, he recalled in his \"Chronicle\", he dined with his crown on his head.\n\nHenry VIII's will named sixteen executors, who were to act as Edward's Council until he reached the age of eighteen. These executors were supplemented by twelve men \"of counsail\" who would assist the executors when called on. The final state of Henry VIII's will has been the subject of controversy. Some historians suggest that those close to the king manipulated either him or the will itself to ensure a share-out of power to their benefit, both material and religious. In this reading, the composition of the Privy Chamber shifted towards the end of 1546 in favour of the reforming faction. In addition, two leading conservative Privy Councillors were removed from the centre of power.\n\nStephen Gardiner was refused access to Henry during his last months. Thomas Howard, 3rd Duke of Norfolk, found himself accused of treason; the day before the king's death his vast estates were seized, making them available for redistribution, and he spent the whole of Edward's reign in the Tower of London. Other historians have argued that Gardiner's exclusion was based on non-religious matters, that Norfolk was not noticeably conservative in religion, that conservatives remained on the Council, and that the radicalism of such men as Sir Anthony Denny, who controlled the dry stamp that replicated the king's signature, is debatable.\n\nWhatever the case, Henry's death was followed by a lavish hand-out of lands and honours to the new power group. The will contained an \"unfulfilled gifts\" clause, added at the last minute, which allowed Henry's executors to freely distribute lands and honours to themselves and the court, particularly to Edward Seymour, 1st Earl of Hertford, the new king's uncle who became Lord Protector of the Realm, Governor of the King's Person, and Duke of Somerset.\n\nIn fact, Henry VIII's will did not provide for the appointment of a Protector. It entrusted the government of the realm during his son's minority to a Regency Council that would rule collectively, by majority decision, with \"like and equal charge\". Nevertheless, a few days after Henry's death, on 4 February, the executors chose to invest almost regal power in Edward Seymour, now Duke of Somerset. Thirteen out of the sixteen (the others being absent) agreed to his appointment as Protector, which they justified as their joint decision \"by virtue of the authority\" of Henry's will. Somerset may have done a deal with some of the executors, who almost all received hand-outs. He is known to have done so with William Paget, private secretary to Henry VIII, and to have secured the support of Sir Anthony Browne of the Privy Chamber.\n\nSomerset's appointment was in keeping with historical precedent, and his eligibility for the role was reinforced by his military successes in Scotland and France. In March 1547, he secured letters patent from King Edward granting him the almost monarchical right to appoint members to the Privy Council himself and to consult them only when he wished. In the words of historian Geoffrey Elton, \"from that moment his autocratic system was complete\". He proceeded to rule largely by proclamation, calling on the Privy Council to do little more than rubber-stamp his decisions.\n\nSomerset's takeover of power was smooth and efficient. The imperial ambassador, François van der Delft, reported that he \"governs everything absolutely\", with Paget operating as his secretary, though he predicted trouble from John Dudley, Viscount Lisle, who had recently been raised to Earl of Warwick in the share-out of honours. In fact, in the early weeks of his Protectorate, Somerset was challenged only by the Chancellor, Thomas Wriothesley, whom the Earldom of Southampton had evidently failed to buy off, and by his own brother. Wriothesley, a religious conservative, objected to Somerset's assumption of monarchical power over the Council. He then found himself abruptly dismissed from the chancellorship on charges of selling off some of his offices to delegates.\n\nSomerset faced less manageable opposition from his younger brother Thomas Seymour, who has been described as a \"worm in the bud\". As King Edward's uncle, Thomas Seymour demanded the governorship of the king's person and a greater share of power. Somerset tried to buy his brother off with a barony, an appointment to the Lord Admiralship, and a seat on the Privy Council—but Thomas was bent on scheming for power. He began smuggling pocket money to King Edward, telling him that Somerset held the purse strings too tight, making him a \"beggarly king\". He also urged him to throw off the Protector within two years and \"bear rule as other kings do\"; but Edward, schooled to defer to the Council, failed to co-operate. In the Spring of 1547, using Edward's support to circumvent Somerset's opposition, Thomas Seymour secretly married Henry VIII's widow Catherine Parr, whose Protestant household included the 11-year-old Lady Jane Grey and the 13-year-old Lady Elizabeth.\n\nIn summer 1548, a pregnant Catherine Parr discovered Thomas Seymour embracing Lady Elizabeth. As a result, Elizabeth was removed from Catherine Parr's household and transferred to Sir Anthony Denny's. That September, Catherine Parr died shortly after childbirth, and Thomas Seymour promptly resumed his attentions to Elizabeth by letter, planning to marry her. Elizabeth was receptive, but, like Edward, unready to agree to anything unless permitted by the Council. In January 1549, the Council had Thomas Seymour arrested on various charges, including embezzlement at the Bristol mint. King Edward, whom Seymour was accused of planning to marry to Lady Jane Grey, himself testified about the pocket money. Lack of clear evidence for treason ruled out a trial, so Seymour was condemned instead by an Act of Attainder and beheaded on 20 March 1549.\n\nSomerset's only undoubted skill was as a soldier, which he had proven on expeditions to Scotland and in the defence of Boulogne-sur-Mer in 1546. From the first, his main interest as Protector was the war against Scotland. After a crushing victory at the Battle of Pinkie Cleugh in September 1547, he set up a network of garrisons in Scotland, stretching as far north as Dundee. His initial successes, however, were followed by a loss of direction, as his aim of uniting the realms through conquest became increasingly unrealistic. The Scots allied with France, who sent reinforcements for the defence of Edinburgh in 1548. The Queen of Scots was moved to France, where she was betrothed to the Dauphin. The cost of maintaining the Protector's massive armies and his permanent garrisons in Scotland also placed an unsustainable burden on the royal finances. A French attack on Boulogne in August 1549 at last forced Somerset to begin a withdrawal from Scotland.\n\nDuring 1548, England was subject to social unrest. After April 1549, a series of armed revolts broke out, fuelled by various religious and agrarian grievances. The two most serious rebellions, which required major military intervention to put down, were in Devon and Cornwall and in Norfolk. The first, sometimes called the Prayer Book Rebellion, arose from the imposition of Protestantism, and the second, led by a tradesman called Robert Kett, mainly from the encroachment of landlords on common grazing ground. A complex aspect of the social unrest was that the protesters believed they were acting legitimately against enclosing landlords with the Protector's support, convinced that the landlords were the lawbreakers.\n\nThe same justification for outbreaks of unrest was voiced throughout the country, not only in Norfolk and the west. The origin of the popular view of Somerset as sympathetic to the rebel cause lies partly in his series of sometimes liberal, often contradictory, proclamations, and partly in the uncoordinated activities of the commissions he sent out in 1548 and 1549 to investigate grievances about loss of tillage, encroachment of large sheep flocks on common land, and similar issues. Somerset's commissions were led by an evangelical M.P. called John Hales, whose socially liberal rhetoric linked the issue of enclosure with Reformation theology and the notion of a godly commonwealth. Local groups often assumed that the findings of these commissions entitled them to act against offending landlords themselves. King Edward wrote in his \"Chronicle\" that the 1549 risings began \"because certain commissions were sent down to pluck down enclosures\".\n\nWhatever the popular view of Somerset, the disastrous events of 1549 were taken as evidence of a colossal failure of government, and the Council laid the responsibility at the Protector's door. In July 1549, Paget wrote to Somerset: \"Every man of the council have misliked your proceedings ... would to God, that, at the first stir you had followed the matter hotly, and caused justice to be ministered in solemn fashion to the terror of others ...\".\n\nThe sequence of events that led to Somerset's removal from power has often been called a \"coup d'état\". By 1 October 1549, Somerset had been alerted that his rule faced a serious threat. He issued a proclamation calling for assistance, took possession of the king's person, and withdrew for safety to the fortified Windsor Castle, where Edward wrote, \"Me thinks I am in prison\". Meanwhile, a united Council published details of Somerset's government mismanagement. They made clear that the Protector's power came from them, not from Henry VIII's will. On 11 October, the Council had Somerset arrested and brought the king to Richmond. Edward summarised the charges against Somerset in his \"Chronicle\": \"ambition, vainglory, entering into rash wars in mine youth, negligent looking on Newhaven, enriching himself of my treasure, following his own opinion, and doing all by his own authority, etc.\" In February 1550, John Dudley, Earl of Warwick, emerged as the leader of the Council and, in effect, as Somerset's successor. Although Somerset was released from the Tower and restored to the Council, he was executed for felony in January 1552 after scheming to overthrow Dudley's regime. Edward noted his uncle's death in his \"Chronicle\": \"the duke of Somerset had his head cut off upon Tower Hill between eight and nine o'clock in the morning\".\n\nHistorians contrast the efficiency of Somerset's takeover of power, in which they detect the organising skills of allies such as Paget, the \"master of practices\", with the subsequent ineptitude of his rule. By autumn 1549, his costly wars had lost momentum, the crown faced financial ruin, and riots and rebellions had broken out around the country. Until recent decades, Somerset's reputation with historians was high, in view of his many proclamations that appeared to back the common people against a rapacious landowning class. More recently, however, he has often been portrayed as an arrogant and aloof ruler, lacking in political and administrative skills.\n\nIn contrast, Somerset's successor John Dudley, Earl of Warwick, made Duke of Northumberland in 1551, was once regarded by historians merely as a grasping schemer who cynically elevated and enriched himself at the expense of the crown. Since the 1970s, the administrative and economic achievements of his regime have been recognised, and he has been credited with restoring the authority of the royal Council and returning the government to an even keel after the disasters of Somerset's protectorate. \n\nThe Earl of Warwick's rival for leadership of the new regime was Thomas Wriothesley, 1st Earl of Southampton, whose conservative supporters had allied with Dudley's followers to create a unanimous Council, which they, and observers such as the Holy Roman Emperor Charles V's ambassador, expected to reverse Somerset's policy of religious reform. Warwick, on the other hand, pinned his hopes on the king's strong Protestantism and, claiming that Edward was old enough to rule in person, moved himself and his people closer to the king, taking control of the Privy Chamber. Paget, accepting a barony, joined Warwick when he realised that a conservative policy would not bring the emperor onto the English side over Boulogne. Southampton prepared a case for executing Somerset, aiming to discredit Warwick through Somerset's statements that he had done all with Warwick's co-operation. As a counter-move, Warwick convinced parliament to free Somerset, which it did on 14 January 1550. Warwick then had Southampton and his followers purged from the Council after winning the support of Council members in return for titles, and was made Lord President of the Council and great master of the king's household. Although not called a Protector, he was now clearly the head of the government.\n\nAs Edward was growing up, he was able to understand more and more government business. However, his actual involvement in decisions has long been a matter of debate, and during the 20th century, historians have presented the whole gamut of possibilities, \"balanc[ing] an articulate puppet against a mature, precocious, and essentially adult king\", in the words of Stephen Alford. A special \"Counsel for the Estate\" was created when Edward was fourteen. Edward chose the members himself. In the weekly meetings with this Council, Edward was \"to hear the debating of things of most importance\". A major point of contact with the king was the Privy Chamber, and there Edward worked closely with William Cecil and William Petre, the Principal Secretaries. The king's greatest influence was in matters of religion, where the Council followed the strongly Protestant policy that Edward favoured.\n\nThe Duke of Northumberland's mode of operation was very different from Somerset's. Careful to make sure he always commanded a majority of councillors, he encouraged a working council and used it to legitimatise his authority. Lacking Somerset's blood-relationship with the king, he added members to the Council from his own faction in order to control it. He also added members of his family to the royal household. He saw that to achieve personal dominance, he needed total procedural control of the Council. In the words of historian John Guy, \"Like Somerset, he became quasi-king; the difference was that he managed the bureaucracy on the pretence that Edward had assumed full sovereignty, whereas Somerset had asserted the right to near-sovereignty as Protector\".\nWarwick's war policies were more pragmatic than Somerset's, and they have earned him criticism for weakness. In 1550, he signed a peace treaty with France that agreed to withdrawal from Boulogne and recalled all English garrisons from Scotland. In 1551, Edward was betrothed to Elisabeth of Valois, King Henry II's daughter. In practice, he realised that England could no longer support the cost of wars. At home, he took measures to police local unrest. To forestall future rebellions, he kept permanent representatives of the crown in the localities, including lords lieutenant, who commanded military forces and reported back to central government.\n\nWorking with William Paulet and Walter Mildmay, Warwick tackled the disastrous state of the kingdom's finances. However, his regime first succumbed to the temptations of a quick profit by further debasing the coinage. The economic disaster that resulted caused Warwick to hand the initiative to the expert Thomas Gresham. By 1552, confidence in the coinage was restored, prices fell, and trade at last improved. Though a full economic recovery was not achieved until Elizabeth's reign, its origins lay in the Duke of Northumberland's policies. The regime also cracked down on widespread embezzlement of government finances, and carried out a thorough review of revenue collection practices, which has been called \"one of the more remarkable achievements of Tudor administration\".\n\nIn the matter of religion, the regime of Northumberland followed the same policy as that of Somerset, supporting an increasingly vigorous programme of reform. Although Edward VI's practical influence on government was limited, his intense Protestantism made a reforming administration obligatory; his succession was managed by the reforming faction, who continued in power throughout his reign. The man Edward trusted most, Thomas Cranmer, Archbishop of Canterbury, introduced a series of religious reforms that revolutionised the English church from one that—while rejecting papal supremacy—remained essentially Catholic, to one that was institutionally Protestant. The confiscation of church property that had begun under Henry VIII resumed under Edward—notably with the dissolution of the chantries—to the great monetary advantage of the crown and the new owners of the seized property. Church reform was therefore as much a political as a religious policy under Edward VI. By the end of his reign, the church had been financially ruined, with much of the property of the bishops transferred into lay hands.\n\nThe religious convictions of both Somerset and Northumberland have proved elusive for historians, who are divided on the sincerity of their Protestantism. There is less doubt, however, about the religious fervour of King Edward, who was said to have read twelve chapters of scripture daily and enjoyed sermons, and was commemorated by John Foxe as a \"godly imp\". Edward was depicted during his life and afterwards as a new Josiah, the biblical king who destroyed the idols of Baal. He could be priggish in his anti-Catholicism and once asked Catherine Parr to persuade Lady Mary \"to attend no longer to foreign dances and merriments which do not become a most Christian princess\". Edward's biographer Jennifer Loach cautions, however, against accepting too readily the pious image of Edward handed down by the reformers, as in John Foxe's influential \"Acts and Monuments\", where a woodcut depicts the young king listening to a sermon by Hugh Latimer. In the early part of his life, Edward conformed to the prevailing Catholic practices, including attendance at mass: but he became convinced, under the influence of Cranmer and the reformers among his tutors and courtiers, that \"true\" religion should be imposed in England.\n\nThe English Reformation advanced under pressure from two directions: from the traditionalists on the one hand and the zealots on the other, who led incidents of iconoclasm (image-smashing) and complained that reform did not go far enough. Reformed doctrines were made official, such as justification by faith alone and communion for laity as well as clergy in both kinds, of bread and wine. The Ordinal of 1550 replaced the divine ordination of priests with a government-run appointment system, authorising ministers to preach the gospel and administer the sacraments rather than, as before, \"to offer sacrifice and celebrate mass both for the living and the dead\". Cranmer set himself the task of writing a uniform liturgy in English, detailing all weekly and daily services and religious festivals, to be made compulsory in the first Act of Uniformity of 1549. The \"Book of Common Prayer\" of 1549, intended as a compromise, was attacked by traditionalists for dispensing with many cherished rituals of the liturgy, such as the elevation of the bread and wine, while some reformers complained about the retention of too many \"popish\" elements, including vestiges of sacrificial rites at communion. The prayer book was also opposed by many senior Catholic clerics, including Stephen Gardiner, Bishop of Winchester, and Edmund Bonner, Bishop of London, who were both imprisoned in the Tower and, along with others, deprived of their sees.\n\nAfter 1551, the Reformation advanced further, with the approval and encouragement of Edward, who began to exert more personal influence in his role as Supreme Head of the church. The new changes were also a response to criticism from such reformers as John Hooper, Bishop of Gloucester, and the Scot John Knox, who was employed as a minister in Newcastle upon Tyne under the Duke of Northumberland and whose preaching at court prompted the king to oppose kneeling at communion. Cranmer was also influenced by the views of the continental reformer Martin Bucer, who died in England in 1551, by Peter Martyr, who was teaching at Oxford, and by other foreign theologians. The progress of the Reformation was further speeded by the consecration of more reformers as bishops. In the winter of 1551–52, Cranmer rewrote the \"Book of Common Prayer\" in less ambiguous reformist terms, revised canon law, and prepared a doctrinal statement, the Forty-two Articles, to clarify the practice of the reformed religion, particularly in the divisive matter of the communion service. Cranmer's formulation of the reformed religion, finally divesting the communion service of any notion of the real presence of God in the bread and the wine, effectively abolished the mass. According to Elton, the publication of Cranmer's revised prayer book in 1552, supported by a second Act of Uniformity, \"marked the arrival of the English Church at protestantism\". The prayer book of 1552 remains the foundation of the Church of England's services. However, Cranmer was unable to implement all these reforms once it became clear in spring 1553 that King Edward, upon whom the whole Reformation in England depended, was dying.\n\nIn February 1553, Edward VI became ill, and by June, after several improvements and relapses, he was in a hopeless condition. The king's death and the succession of his Catholic half-sister Mary would jeopardise the English Reformation, and Edward's Council and officers had many reasons to fear it. Edward himself opposed Mary's succession, not only on religious grounds but also on those of legitimacy and male inheritance, which also applied to Elizabeth. He composed a draft document, headed \"My devise for the succession\", in which he undertook to change the succession, most probably inspired by his father Henry VIII's precedent. He passed over the claims of his half-sisters and, at last, settled the Crown on his first cousin once removed, the 16-year-old Lady Jane Grey, who on 25 May 1553 had married Lord Guilford Dudley, a younger son of the Duke of Northumberland. In the document he writes:\n\nIn his document Edward provided, in case of \"lack of issue of my body\", for the succession of male heirs only, that is, Jane Grey's mother's male heirs, Jane's, or her sisters'. As his death approached and possibly persuaded by Northumberland, he altered the wording so that Jane and her sisters themselves should be able to succeed. Yet Edward conceded Jane's right only as an exception to male rule, demanded by reality, an example not to be followed if Jane or her sisters had only daughters. In the final document both Mary and Elizabeth were excluded because of bastardy; since both had been declared bastards under Henry VIII and never made legitimate again, this reason could be advanced for both sisters. The provisions to alter the succession directly contravened Henry VIII's Third Succession Act of 1543 and have been described as bizarre and illogical.\n\nIn early June, Edward personally supervised the drafting of a clean version of his devise by lawyers, to which he lent his signature \"in six several places.\" Then, on 15 June he summoned high ranking judges to his sickbed, commanding them on their allegiance \"with sharp words and angry countenance\" to prepare his devise as letters patent and announced that he would have these passed in parliament. His next measure was to have leading councillors and lawyers sign a bond in his presence, in which they agreed faithfully to perform Edward's will after his death. A few months later, Chief Justice Edward Montagu recalled that when he and his colleagues had raised legal objections to the devise, Northumberland had threatened them \"trembling for anger, and ... further said that he would fight in his shirt with any man in that quarrel\". Montagu also overheard a group of lords standing behind him conclude \"if they refused to do that, they were traitors\". At last, on 21 June, the devise was signed by over a hundred notables, including councillors, peers, archbishops, bishops, and sheriffs; many of them later claimed that they had been bullied into doing so by Northumberland, although in the words of Edward's biographer Jennifer Loach, \"few of them gave any clear indication of reluctance at the time\".\n\nIt was now common knowledge that Edward was dying, and foreign diplomats suspected that some scheme to debar Mary was under way. France found the prospect of the emperor's cousin on the English throne disagreeable and engaged in secret talks with Northumberland, indicating support. The diplomats were certain that the overwhelming majority of the English people backed Mary, but nevertheless believed that Queen Jane would be successfully established. \n\nFor centuries, the attempt to alter the succession was mostly seen as a one-man-plot by the Duke of Northumberland. Since the 1970s, however, many historians have attributed the inception of the \"devise\" and the insistence on its implementation to the king's initiative. Diarmaid MacCulloch has made out Edward's \"teenage dreams of founding an evangelical realm of Christ\", while David Starkey has stated that \"Edward had a couple of co-operators, but the driving will was his\". Among other members of the Privy Chamber, Northumberland's intimate Sir John Gates has been suspected of suggesting to Edward to change his devise so that Lady Jane Grey herself—not just any sons of hers—could inherit the Crown. Whatever the degree of his contribution, Edward was convinced that his word was law and fully endorsed disinheriting his half-sisters: \"barring Mary from the succession was a cause in which the young King believed.\"\n\nEdward became ill during January 1553 with a fever and cough that gradually worsened. The imperial ambassador, Jean Scheyfve, reported that \"he suffers a good deal when the fever is upon him, especially from a difficulty in drawing his breath, which is due to the compression of the organs on the right side\". Edward felt well enough in early April to take the air in the park at Westminster and to move to Greenwich, but by the end of the month he had weakened again. By 7 May he was \"much amended\", and the royal doctors had no doubt of his recovery. A few days later the king was watching the ships on the Thames, sitting at his window. However, he relapsed, and on 11 June Scheyfve, who had an informant in the king's household, reported that \"the matter he ejects from his mouth is sometimes coloured a greenish yellow and black, sometimes pink, like the colour of blood\". Now his doctors believed he was suffering from \"a suppurating tumour\" of the lung and admitted that Edward's life was beyond recovery. Soon, his legs became so swollen that he had to lie on his back, and he lost the strength to resist the disease. To his tutor John Cheke he whispered, \"I am glad to die\". \n\nEdward made his final appearance in public on 1 July, when he showed himself at his window in Greenwich Palace, horrifying those who saw him by his \"thin and wasted\" condition. During the next two days, large crowds arrived hoping to see the king again, but on 3 July, they were told that the weather was too chilly for him to appear. Edward died at the age of 15 at Greenwich Palace at 8pm on 6 July 1553. According to John Foxe's legendary account of his death, his last words were: \"I am faint; Lord have mercy upon me, and take my spirit\". He was buried in the Henry VII Lady Chapel at Westminster Abbey on 8 August 1553, with reformed rites performed by Thomas Cranmer. The procession was led by \"a grett company of chylderyn in ther surples\" and watched by Londoners \"wepyng and lamenting\"; the funeral chariot, draped in cloth of gold, was topped by an effigy of Edward, with crown, sceptre, and garter. Edward's burial place was unmarked until as late as 1966, when an inscribed stone was laid in the chapel floor by Christ's Hospital school to commemorate their founder. The inscription reads as follows: \"In Memory Of King Edward VI Buried In This Chapel This Stone Was Placed Here By Christ's Hospital In Thanksgiving For Their Founder 7 October 1966\".\n\nThe cause of Edward VI's death is not certain. As with many royal deaths in the 16th century, rumours of poisoning abounded, but no evidence has been found to support these. The Duke of Northumberland, whose unpopularity was underlined by the events that followed Edward's death, was widely believed to have ordered the imagined poisoning. Another theory held that Edward had been poisoned by Catholics seeking to bring Mary to the throne. The surgeon who opened Edward's chest after his death found that \"the disease whereof his majesty died was the disease of the lungs\". The Venetian ambassador reported that Edward had died of consumption—in other words, tuberculosis—a diagnosis accepted by many historians. Skidmore believes that Edward contracted tuberculosis after a bout of measles and smallpox in 1552 that suppressed his natural immunity to the disease. Loach suggests instead that his symptoms were typical of acute bronchopneumonia, leading to a \"suppurating pulmonary infection\" or lung abscess, septicaemia, and kidney failure.\n\nLady Mary was last seen by Edward in February, and was kept informed about the state of her brother's health by Northumberland and through her contacts with the imperial ambassadors. Aware of Edward's imminent death, she left Hunsdon House, near London, and sped to her estates around Kenninghall in Norfolk, where she could count on the support of her tenants. Northumberland sent ships to the Norfolk coast to prevent her escape or the arrival of reinforcements from the continent. He delayed the announcement of the king's death while he gathered his forces, and Jane Grey was taken to the Tower on 10 July. On the same day, she was proclaimed queen in the streets of London, to murmurings of discontent. The Privy Council received a message from Mary asserting her \"right and title\" to the throne and commanding that the Council proclaim her queen, as she had already proclaimed herself. The Council replied that Jane was queen by Edward's authority and that Mary, by contrast, was illegitimate and supported only by \"a few lewd, base people\".\n\nNorthumberland soon realised that he had miscalculated drastically, not least in failing to secure Mary's person before Edward's death. Although many of those who rallied to Mary were conservatives hoping for the defeat of Protestantism, her supporters also included many for whom her lawful claim to the throne overrode religious considerations. Northumberland was obliged to relinquish control of a nervous Council in London and launch an unplanned pursuit of Mary into East Anglia, from where news was arriving of her growing support, which included a number of nobles and gentlemen and \"innumerable companies of the common people\". On 14 July Northumberland marched out of London with three thousand men, reaching Cambridge the next day; meanwhile, Mary rallied her forces at Framlingham Castle in Suffolk, gathering an army of nearly twenty thousand by 19 July. \n\nIt now dawned on the Privy Council that it had made a terrible mistake. Led by the Earl of Arundel and the Earl of Pembroke, on 19 July the Council publicly proclaimed Mary as queen; Jane's nine-day reign came to an end. The proclamation triggered wild rejoicing throughout London. Stranded in Cambridge, Northumberland proclaimed Mary himself—as he had been commanded to do by a letter from the Council. William Paget and the Earl of Arundel rode to Framlingham to beg Mary's pardon, and Arundel arrested Northumberland on 24 July. Northumberland was beheaded on 22 August, shortly after renouncing Protestantism. His recantation dismayed his daughter-in-law, Jane, who followed him to the scaffold on 12 February 1554, after her father's involvement in Wyatt's rebellion.\n\nAlthough Edward reigned for only six years and died at the age of 15, his reign made a lasting contribution to the English Reformation and the structure of the Church of England. The last decade of Henry VIII's reign had seen a partial stalling of the Reformation, a drifting back to more conservative values. By contrast, Edward's reign saw radical progress in the Reformation. In those six years, the Church transferred from an essentially Roman Catholic liturgy and structure to one that is usually identified as Protestant. In particular, the introduction of the Book of Common Prayer, the Ordinal of 1550, and Cranmer's Forty-two Articles formed the basis for English Church practices that continue to this day. Edward himself fully approved these changes, and though they were the work of reformers such as Thomas Cranmer, Hugh Latimer, and Nicholas Ridley, backed by Edward's determinedly evangelical Council, the fact of the king's religion was a catalyst in the acceleration of the Reformation during his reign.\n\nQueen Mary's attempts to undo the reforming work of her brother's reign faced major obstacles. Despite her belief in the papal supremacy, she ruled constitutionally as the Supreme Head of the English Church, a contradiction under which she bridled. She found herself entirely unable to restore the vast number of ecclesiastical properties handed over or sold to private landowners. Although she burned a number of leading Protestant churchmen, many reformers either went into exile or remained subversively active in England during her reign, producing a torrent of reforming propaganda that she was unable to stem. Nevertheless, Protestantism was not yet \"printed in the stomachs\" of the English people, and had Mary lived longer, her Catholic reconstruction might have succeeded, leaving Edward's reign, rather than hers, as a historical aberration.\n\nOn Mary's death in 1558, the English Reformation resumed its course, and most of the reforms instituted during Edward's reign were reinstated in the Elizabethan Religious Settlement. Queen Elizabeth replaced Mary's councillors and bishops with ex-Edwardians, such as William Cecil, Northumberland's former secretary, and Richard Cox, Edward's old tutor, who preached an anti-Catholic sermon at the opening of parliament in 1559. Parliament passed an Act of Uniformity the following spring that restored, with modifications, Cranmer's prayer book of 1552; and the Thirty-nine Articles of 1563 were largely based on Cranmer's Forty-two Articles. The theological developments of Edward's reign provided a vital source of reference for Elizabeth's religious policies, though the internationalism of the Edwardian Reformation was never revived.\n\n\n\n\n"}
{"id": "10248", "url": "https://en.wikipedia.org/wiki?curid=10248", "title": "Extrapyramidal", "text": "Extrapyramidal\n\nExtrapyramidal can refer to:\n"}
{"id": "10250", "url": "https://en.wikipedia.org/wiki?curid=10250", "title": "Epinephrine", "text": "Epinephrine\n\nEpinephrine, also known as adrenalin or adrenaline, is a hormone, neurotransmitter and medication. Epinephrine is normally produced by both the adrenal glands and certain neurons. It plays an important role in the fight-or-flight response by increasing blood flow to muscles, output of the heart, pupil dilation, and blood sugar. It does this by binding to alpha and beta receptors. It is found in many animals and some single cell organisms. Napoleon Cybulski first isolated epinephrine in 1895.\nAs a medication it is used to treat a number of conditions including anaphylaxis, cardiac arrest, and superficial bleeding. Inhaled epinephrine may be used to improve the symptoms of croup. It may also be used for asthma when other treatments are not effective. It is given intravenously, by injection into a muscle, by inhalation, or by injection just under the skin. Common side effects include shakiness, anxiety, and sweating. A fast heart rate and high blood pressure may occur. Occasionally it may result in an abnormal heart rhythm. While the safety of its use during pregnancy and breastfeeding is unclear, the benefits to the mother must be taken into account.\n\nThe adrenal medulla is a minor contributor to total circulating catecholamines (-DOPA is at a higher concentration in the plasma), though it contributes over 90% of circulating epinephrine. Little epinephrine is found in other tissues, mostly in scattered chromaffin cells. Following adrenalectomy, epinephrine disappears below the detection limit in the blood stream.\n\nThe adrenals contribute about 7% of circulating norepinephrine, most of which is a spill over from neurotransmission with little activity as a hormone.\nPharmacological doses of epinephrine stimulate α, α, β, β, and β adrenoceptors of the sympathetic nervous system. Sympathetic nerve receptors are classified as adrenergic, based on their responsiveness to adrenaline.\n\nThe term \"adrenergic\" is often misinterpreted in that the main sympathetic neurotransmitter is norepinephrine (noradrenaline), rather than epinephrine, as discovered by Ulf von Euler in 1946.\n\nEpinephrine does have a β adrenoceptor-mediated effect on metabolism and the airway, there being no direct neural connection from the sympathetic ganglia to the airway.\n\nThe concept of the adrenal medulla and the sympathetic nervous system being involved in the flight, fight and fright response was originally proposed by Cannon. But the adrenal medulla, in contrast to the adrenal cortex, is not required for survival. In adrenalectomized patients hemodynamic and metabolic responses to stimuli such as hypoglycemia and exercise remain normal.\n\nOne physiological stimulus to epinephrine secretion is exercise. This was first demonstrated using the denervated pupil of a cat as an assay, later confirmed using a biological assay on urine samples. Biochemical methods for measuring catecholamines in plasma were published from 1950 onwards. Although much valuable work has been published using fluorimetric assays to measure total catecholamine concentrations, the method is too non-specific and insensitive to accurately determine the very small quantities of epinephrine in plasma. The development of extraction methods and enzyme-isotope derivate radio-enzymatic assays (REA) transformed the analysis down to a sensitivity of 1 pg for epinephrine. Early REA plasma assays indicated that epinephrine and total catecholamines rise late in exercise, mostly when anaerobic metabolism commences.\n\nDuring exercise the epinephrine blood concentration rises partially from increased secretion from the adrenal medulla and partly from decreased metabolism because of reduced hepatic blood flow. Infusion of epinephrine to reproduce exercise circulating concentrations of epinephrine in subjects at rest has little haemodynamic effect, other than a small β-mediated fall in diastolic blood pressure. Infusion of epinephrine well within the physiological range suppresses human airway hyper-reactivity sufficiently to antagonize the constrictor effects of inhaled histamine.\n\nA link between what we now know as the sympathetic system and the lung was shown in 1887 when Grossman showed that stimulation of cardiac accelerator nerves reversed muscarine induced airway constriction. In elegant experiments in the dog, where the sympathetic chain was cut at the level of the diaphragm, Jackson showed that there was no direct sympathetic innervation to the lung, but that bronchoconstriction was reversed by release of epinephrine from the adrenal medulla. An increased incidence of asthma has not been reported for adrenalectomized patients; those with a predisposition to asthma will have some protection from airway hyper-reactivity from their corticosteroid replacement therapy. Exercise induces progressive airway dilation in normal subjects that correlates with work load and is not prevented by beta blockade. The progressive dilation of the airway with increasing exercise is mediated by a progressive reduction in resting vagal tone. Beta blockade with propranolol causes a rebound in airway resistance after exercise in normal subjects over the same time course as the bronchoconstriction seen with exercise induced asthma. The reduction in airway resistance during exercise reduces the work of breathing.\n\nEvery emotional response has a behavioral component, an autonomic component, and a hormonal component. The hormonal component includes the release of epinephrine, an adrenomedullary response that occurs in response to stress and that is controlled by the sympathetic nervous system. The major emotion studied in relation to epinephrine is fear. In an experiment, subjects who were injected with epinephrine expressed more negative and fewer positive facial expressions to fear films compared to a control group. These subjects also reported a more intense fear from the films and greater mean intensity of negative memories than control subjects. The findings from this study demonstrate that there are learned associations between negative feelings and levels of epinephrine. Overall, the greater amount of epinephrine is positively correlated with an arousal state of negative feelings. These findings can be an effect in part that epinephrine elicits physiological sympathetic responses including an increased heart rate and knee shaking, which can be attributed to the feeling of fear regardless of the actual level of fear elicited from the video. Although studies have found a definite relation between epinephrine and fear, other emotions have not had such results. In the same study, subjects did not express a greater amusement to an amusement film nor greater anger to an anger film. Similar findings were also supported in a study that involved rodent subjects that either were able or unable to produce epinephrine. Findings support the idea that epinephrine does have a role in facilitating the encoding of emotionally arousing events, contributing to higher levels of arousal due to fear.\n\nIt has been found that adrenergic hormones, such as epinephrine, can produce retrograde enhancement of long-term memory in humans. The release of epinephrine due to emotionally stressful events, which is endogenous epinephrine, can modulate memory consolidation of the events, ensuring memory strength that is proportional to memory importance. Post-learning epinephrine activity also interacts with the degree of arousal associated with the initial coding. There is evidence that suggests epinephrine does have a role in long-term stress adaptation and emotional memory encoding specifically. Epinephrine may also play a role in elevating arousal and fear memory under particular pathological conditions including post-traumatic stress disorder. Overall, \"Extensive evidence indicates that epinephrine (EPI) modulates memory consolidation for emotionally arousing tasks in animals and human subjects.”\nStudies have also found that recognition memory involving epinephrine depends on a mechanism that depends on β adrenoceptors. Epinephrine does not readily cross the blood–brain barrier, so its effects on memory consolidation are at least partly initiated by β adrenoceptors in the periphery. Studies have found that sotalol, a β adrenoceptor antagonist that also does not readily enter the brain, blocks the enhancing effects of peripherally administered epinephrine on memory. These findings suggest that β adrenoceptors are necessary for epinephrine to have an effect on memory consolidation.\n\nFor noradrenaline to be acted upon by PNMT in the cytosol, it must first be shipped out of granules of the chromaffin cells. This may occur via the catecholamine-H exchanger VMAT1. VMAT1 is also responsible for transporting newly synthesized adrenaline from the cytosol back into chromaffin granules in preparation for release.\n\nIn liver cells, adrenaline binds to the β adrenergic receptor, which changes conformation and helps G, a G protein, exchange GDP to GTP. This trimeric G protein dissociates to G alpha and G beta/gamma subunits. Gs alpha binds to adenyl cyclase, thus converting ATP into cyclic AMP. Cyclic AMP binds to the regulatory subunit of protein kinase A: Protein kinase A phosphorylates phosphorylase kinase. Meanwhile, Gs beta/gamma binds to the calcium channel and allows calcium ions to enter the cytoplasm. Calcium ions bind to calmodulin proteins, a protein present in all eukaryotic cells, which then binds to phosphorylase kinase and finishes its activation. Phosphorylase kinase phosphorylates glycogen phosphorylase, which then phosphorylates glycogen and converts it to glucose-6-phosphate. \n\nIncreased epinephrine secretion is observed in phaeochromocytoma, hypoglycaemia, myocardial infarction and to a lesser degree in benign essential familial tremor. A general increase in sympathetic neural activity is usually accompanied by increased adrenaline secretion, but there is selectivity during hypoxia and hypoglycaemia, when the ratio of adrenaline to noradrenaline is considerably increased. Therefore, there must be some autonomy of the adrenal medulla from the rest of the sympathetic system.\n\nMyocardial infarction is associated with high levels of circulating epinephrine and norepinephrine, particularly in cardiogenic shock.\n\nBenign familial tremor (BFT) is responsive to peripheral β adrenergic blockers and β-stimulation is known to cause tremor. Patients with BFT were found to have increased plasma epinephrine, but not norepinephrine.\n\nLow, or absent, concentrations of epinephrine can be seen in autonomic neuropathy or following adrenalectomy. Failure of the adrenal cortex, as with Addisons disease, can suppress epinephrine secretion as the activity of the synthesing enzyme, phenylethanolamine-\"N\"-methyltransferase, depends on the high concentration of cortisol that drains from the cortex to the medulla.\n\nEpinephrine is the pharmaceutical's United States Adopted Name and International Nonproprietary Name, though the name adrenaline is frequently used. The term \"epinephrine \"was coined by the pharmacologist John Abel (from the Greek for \"on top of the kidneys\"), who used the name to describe the extracts he prepared from the adrenal glands as early as 1897. In 1901, Jokichi Takamine patented a purified adrenal extract, and called it \"adrenalin\" (from the Latin for \"on top of the kidneys\"), which was trademarked by Parke, Davis & Co in the U.S. In the belief that Abel's extract was the same as Takamine's, a belief since disputed, epinephrine became the generic name in the U.S. The British Approved Name and European Pharmacopoeia term for this drug is adrenaline and is indeed now one of the few differences between the INN and BAN systems of names.\n\nAmong American health professionals and scientists, the term \"epinephrine\" is used over \"adrenaline\". However, pharmaceuticals that mimic the effects of epinephrine are often called adrenergics, and receptors for epinephrine are called adrenergic receptors or adrenoceptors.\n\nAs a hormone, epinephrine acts on nearly all body tissues. Its actions vary by tissue type and tissue expression of adrenergic receptors. For example, high levels of epinephrine causes smooth muscle relaxation in the airways but causes contraction of the smooth muscle that lines most arterioles.\n\nEpinephrine acts by binding to a variety of adrenergic receptors. Epinephrine is a nonselective agonist of all adrenergic receptors, including the major subtypes α, α, β, β, and β. Epinephrine's binding to these receptors triggers a number of metabolic changes. Binding to α-adrenergic receptors inhibits insulin secretion by the pancreas, stimulates glycogenolysis in the liver and muscle, and stimulates glycolysis and inhibits insulin-mediated glycogenesis in muscle. β adrenergic receptor binding triggers glucagon secretion in the pancreas, increased adrenocorticotropic hormone (ACTH) secretion by the pituitary gland, and increased lipolysis by adipose tissue. Together, these effects lead to increased blood glucose and fatty acids, providing substrates for energy production within cells throughout the body.\n\nIts actions are to increase peripheral resistance via α receptor-dependent vasoconstriction and to increase cardiac output via its binding to β receptors. The goal of reducing peripheral circulation is to increase coronary and cerebral perfusion pressures and therefore increase oxygen exchange at the cellular level. While epinephrine does increase aortic, cerebral, and carotid circulation pressure, it lowers carotid blood flow and end-tidal CO or ECO levels. It appears that epinephrine may be improving macrocirculation at the expense of the capillary beds where actual perfusion is taking place.\n\nEpinephrine may be quantified in blood, plasma or serum as a diagnostic aid, to monitor therapeutic administration, or to identify the causative agent in a potential poisoning victim. Endogenous plasma epinephrine concentrations in resting adults are normally less than 10 ng/L, but may increase by 10-fold during exercise and by 50-fold or more during times of stress. Pheochromocytoma patients often have plasma adrenaline levels of 1000–10,000 ng/L. Parenteral administration of epinephrine to acute-care cardiac patients can produce plasma concentrations of 10,000 to 100,000 ng/L.\n\nIn chemical terms, epinephrine is one of a group of monoamines called the catecholamines. It is produced in some neurons of the central nervous system, and in the chromaffin cells of the adrenal medulla from the amino acids phenylalanine and tyrosine.\n\nEpinephrine is synthesized in the medulla of the adrenal gland in an enzymatic pathway that converts the amino acid tyrosine into a series of intermediates and, ultimately, epinephrine. Tyrosine is first oxidized to -DOPA, which is subsequently decarboxylated to give dopamine. Oxidation gives norepinephrine. The final step in epinephrine biosynthesis is the methylation of the primary amine of norepinephrine. This reaction is catalyzed by the enzyme phenylethanolamine \"N\"-methyltransferase (PNMT) which utilizes \"S\"-adenosyl methionine (SAMe) as the methyl donor. While PNMT is found primarily in the cytosol of the endocrine cells of the adrenal medulla (also known as chromaffin cells), it has been detected at low levels in both the heart and brain.\n\nThe major physiologic triggers of adrenaline release center upon stresses, such as physical threat, excitement, noise, bright lights, and high ambient temperature. All of these stimuli are processed in the central nervous system.\n\nAdrenocorticotropic hormone (ACTH) and the sympathetic nervous system stimulate the synthesis of adrenaline precursors by enhancing the activity of tyrosine hydroxylase and dopamine β-hydroxylase, two key enzymes involved in catecholamine synthesis. ACTH also stimulates the adrenal cortex to release cortisol, which increases the expression of PNMT in chromaffin cells, enhancing adrenaline synthesis. This is most often done in response to stress. The sympathetic nervous system, acting via splanchnic nerves to the adrenal medulla, stimulates the release of adrenaline. Acetylcholine released by preganglionic sympathetic fibers of these nerves acts on nicotinic acetylcholine receptors, causing cell depolarization and an influx of calcium through voltage-gated calcium channels. Calcium triggers the exocytosis of chromaffin granules and, thus, the release of adrenaline (and noradrenaline) into the bloodstream.\n\nUnlike many other hormones adrenaline (as with other catecholamines) does not exert negative feedback to down-regulate its own synthesis. Abnormally elevated levels of adrenaline can occur in a variety of conditions, such as surreptitious epinephrine administration, pheochromocytoma, and other tumors of the sympathetic ganglia.\n\nIts action is terminated with reuptake into nerve terminal endings, some minute dilution, and metabolism by monoamine oxidase and catechol-\"O\"-methyl transferase.\n\nExtracts of the adrenal gland were first obtained by Polish physiologist Napoleon Cybulski in 1895. These extracts, which he called \"nadnerczyna\" (\"adrenalin\"), contained adrenaline and other catecholamines. American ophthalmologist William H. Bates discovered adrenaline's usage for eye surgeries prior to 20 April 1896. Japanese chemist Jokichi Takamine and his assistant Keizo Uenaka independently discovered adrenaline in 1900. In 1901, Takamine successfully isolated and purified the hormone from the adrenal glands of sheep and oxen. Adrenaline was first synthesized in the laboratory by Friedrich Stolz and Henry Drysdale Dakin, independently, in 1904.\n\nAn \"adrenaline junkie\" is somebody who engages in sensation-seeking behavior through \"the pursuit of novel and intense experiences without regard for physical, social, legal or financial risk\". Such activities include extreme and risky sports, substance abuse, unsafe sex, and crime. The term relates to the increase in circulating levels of adrenaline during physiological stress. Such an increase in the circulating concentration of adrenaline is secondary to activation of the sympathetic nerves innervating the adrenal medulla, as it is rapid and not present in animals where the adrenal gland has been removed. Although such stress triggers adrenaline release, it also activates many other responses within the central nervous system reward system which drives behavioral responses, so while the circulating adrenaline concentration is present, it may not drive behavior. Nevertheless, adrenaline infusion alone does increase alertness and has roles in the brain including the augmentation of memory consolidation.\n\nAdrenaline has been implicated in feats of great strength, often occurring in times of crisis. For example, there are stories of a parent lifting part of a car when their child is trapped underneath.\n\n"}
{"id": "10251", "url": "https://en.wikipedia.org/wiki?curid=10251", "title": "Electronic delay storage automatic calculator", "text": "Electronic delay storage automatic calculator\n\nThe electronic delay storage automatic calculator (EDSAC) was an early British computer. Inspired by John von Neumann's seminal \"First Draft of a Report on the EDVAC\", the machine was constructed by Maurice Wilkes and his team at the University of Cambridge Mathematical Laboratory in England. EDSAC was the second electronic digital stored-program computer to go into regular service.\n\nLater the project was supported by J. Lyons & Co. Ltd., a British firm, who were rewarded with the first commercially applied computer, LEO I, based on the EDSAC design. Work on EDSAC started during 1947, and it ran its first programs on 6 May 1949, when it calculated a table of squares and a list of prime numbers. EDSAC 1 was finally shut down on 11 July 1958, having been superseded by EDSAC 2, which remained in use until 1965.\n\nAs soon as EDSAC was operational, it began serving the University's research needs. It used mercury delay lines for memory, and derated vacuum tubes for logic. Cycle time was 1.5 ms for all ordinary instructions, 6 ms for multiplication. Input was via five-hole punched tape and output was via a teleprinter.\n\nInitially registers were limited to an accumulator and a multiplier register. In 1953, David Wheeler, returning from a stay at the University of Illinois, designed an index register as an extension to the original EDSAC hardware.\n\nA magnetic tape drive was added in 1952 but never worked sufficiently well to be of real use.\n\nUntil 1952, the available main memory (instructions and data) was only 512 18-bit words, and there was no backing store. The delay lines (or \"tanks\") were arranged in two batteries providing 512 words each. The second battery came into operation in 1952.\n\nThe full 1024-word delay line store was not available until 1955 or early 1956, limiting programs to about 800 words until then.\n\nJohn Lindley (diploma student 1958–1959) mentioned \"the incredible difficulty we had ever to produce a single correct piece of paper tape with the crude and unreliable home-made punching, printing and verifying gear available in the late 50s\".\n\nThe EDSAC's main memory consisted of 1024 locations, though only 512 locations were initially installed. Each contained 18 bits, but the topmost bit was always unavailable due to timing problems, so only 17 bits were used. An instruction consisted of a five-bit instruction code, one spare bit, a ten bit operand (usually a memory address), and a length bit to control whether the instruction used a 17-bit or a 35-bit operand (two consecutive words, little-endian). All instruction codes were by design represented by one mnemonic letter, so that the \"Add\" instruction, for example, used the EDSAC character code for the letter A.\n\nInternally, the EDSAC used two's complement, binary numbers. Numbers were either 17 bits (one word) or 35 bits (two words) long. Unusually, the multiplier was designed to treat numbers as fixed-point fractions in the range −1 ≤ \"x\" < 1, i.e. the binary point was immediately to the right of the sign. The accumulator could hold 71 bits, including the sign, allowing two long (35-bit) numbers to be multiplied without losing any precision.\n\nThe instructions available were: \nThere was no division instruction (but various division subroutines were supplied) and no way to directly load a number into the accumulator (a \"sTore and zero accumulator\" instruction followed by an \"Add\" instruction were necessary for this). There was no unconditional jump instruction, nor was there a procedure call instruction - it had not yet been invented.\n\nThe \"initial orders\" were hard-wired on a set of uniselector switches and loaded into the low words of memory at startup. By May 1949, the initial orders provided a primitive relocating assembler taking advantage of the mnemonic design described above, all in 31 words. This was the world's first assembler, and arguably the start of the global software industry. There is a simulation of EDSAC available and a full description of the initial orders and first programs.\n\nThe machine was used by other members of the University to solve real problems, and many early techniques were developed that are now included in operating systems.\nUsers prepared their programs by punching them (in assembler) onto a paper tape. They soon became good at being able to hold the paper tape up to the light and read back the codes. When a program was ready it was hung on a length of line strung up near the paper tape reader. The machine operators, who were present during the day, selected the next tape from the line and loaded it into EDSAC. This is of course well known today as job queues. If it printed something then the tape and the printout were returned to the user, otherwise they were informed at which memory location it had stopped. Debuggers were some time away, but a CRT screen could be set to display the contents of a particular piece of memory. This was used to see if a number was converging, for example. A loudspeaker was connected to the accumulator's sign bit; experienced users knew healthy and unhealthy sounds of programs, particularly programs 'hung' in a loop. After office hours certain \"Authorised Users\" were allowed to run the machine for themselves, which went on late into the night until a valve blew – which usually happened according to one such user.\n\nThe early programmers had to make use of techniques frowned upon today — especially altering the code. As there was no index register until much later, the only way of accessing an array was to alter which memory location a particular instruction was referencing.\n\nDavid Wheeler, who earned the world's first Computer Science PhD working on the project, is credited with inventing the concept of a subroutine. Users wrote programs that called a routine by jumping to the start of the subroutine with the return address (i.e. the location-plus-one of the jump itself) in the accumulator (a Wheeler jump). By convention the subroutine expected this and the first thing it did was to modify its concluding jump instruction to that return address. Multiple and nested subroutines could be called so long as the user knew the length of each one in order to calculate the location to jump to; recursive calls were forbidden. The user then copied the code for the subroutine from a master tape onto their own tape following the end of their own program.\n\nThe subroutine concept led to the availability of a substantial subroutine library. By 1951, 87 subroutines in the following categories were available for general use: floating point arithmetic; arithmetic operations on complex numbers; checking; division; exponentiation; routines relating to functions; differential equations; special functions; power series; logarithms; miscellaneous; print and layout; quadrature; read (input); \"n\"th root; trigonometric functions; counting operations (simulating repeat until loops, while loops and for loops); vectors; and matrices.\n\n\nEDSAC's successor, EDSAC 2, was commissioned in 1958.\n\nIn 1961, an EDSAC 2 version of Autocode, an ALGOL-like high-level programming language for scientists and engineers, was developed by David Hartley.\n\nIn the mid-1960s, a successor to the EDSAC 2 was planned, but the move was instead made to the Titan, a prototype Atlas 2 developed from the Atlas Computer of the University of Manchester, Ferranti, and Plessey.\n\nOn 13 January 2011, the Computer Conservation Society announced that it planned to build a working replica of EDSAC, at the National Museum of Computing (TNMoC) in Bletchley Park supervised by Andrew Herbert, who studied under Maurice Wilkes. The first parts of the recreation were switched on in November 2014. The ongoing project is open to visitors of the museum. As of November 2016, commissioning of the fully completed and operational state of the replica is estimated by the autumn of 2017.\n\n\n\n"}
{"id": "10252", "url": "https://en.wikipedia.org/wiki?curid=10252", "title": "E. H. Shepard", "text": "E. H. Shepard\n\nErnest Howard Shepard (10 December 1879 – 24 March 1976) was an English artist and book illustrator. He is known especially for illustrations of the anthropomorphic soft toy and animal characters in \"The Wind in the Willows\" by Kenneth Grahame and \"Winnie-the-Pooh\" by A. A. Milne.\n\nShepard was born in St John's Wood, London. Having shown some promise in drawing at St Paul's School, in 1897 he enrolled in Heatherley's School of Fine Art in Chelsea. After a productive year there, he attended the Royal Academy Schools, winning a Landseer scholarship in 1899 and a British Institute prize in 1900. There he met Florence Eleanor Chaplin, who he married in 1904. By 1906 Shepard had become a successful illustrator, having produced work for illustrated editions of Aesop's Fables, \"David Copperfield\", and \"Tom Brown's Schooldays\", while at the same time working as an illustrator on the staff of \"Punch\". The couple bought a house in London, but in 1905 moved to Sharnley Green, near Guildford.\n\nShepard was a prolific painter, showing in a number of major exhibitions. He exhibited at the Royal Society of Artists, Birmingham—a traditional venue for generic painters—as well as in the more radical atmosphere of Glasgow's Institute of Fine Arts, where some of the most innovative artists were on show. He was twice an exhibitor at the prestigious Walker Art Gallery in Liverpool, one of the largest and most important provincial galleries in the country, and another at the Manchester Art Gallery, a Victorian institution now part of the public libraries. But at heart, Shepard was a Londoner, showing sixteen times at the Royal Academy on Piccadilly. His wife, who was also a painter, found a home in London's West End venue for her own modest output during a 25-year career.\n\nAlthough in his mid-thirties when World War I broke out in 1914, Shepard received a commission as a second lieutenant in the Royal Garrison Artillery, an arm of the Royal Artillery. By 1916, Shepard started working for the Intelligence Department sketching the combat area within the view of his battery position. On 16 February 1917, he was made an acting captain whilst second-in-command of a siege battery, and briefly served as an acting major in late April and early May of that year, when he reverted to the acting rank of captain. He was promoted to lieutenant on 1 July 1917. Whilst acting as Captain, he was awarded the Military Cross for his service at the Battle of Passchendaele. His citation read:\n\n\"For conspicuous gallantry and devotion to duty. As forward Observation Officer he continued to observe and send back valuable information, in spite of heavy shell and machine gun fire. His courage and coolness were conspicuous.\"\n\nBy war's end, he had achieved the rank of major.\n\nThroughout the war he had been contributing to \"Punch\". He was hired as a regular staff cartoonist in 1921 and became lead cartoonist in 1945. He was removed from this post in 1953 by \"Punch\"'s new editor, Malcolm Muggeridge.\n\nShepard was recommended to A. A. Milne in 1923 by another \"Punch\" staffer, E. V. Lucas. Milne initially thought Shepard's style was not what he wanted, but used him to illustrate the book of poems \"When We Were Very Young\". Happy with the results, Milne then insisted Shepard illustrate \"Winnie-the-Pooh\". Realising his illustrator's contribution to the book's success, the writer arranged for Shepard to receive a share of his royalties. Milne also inscribed a copy of \"Winnie-the-Pooh\" with the following personal verse:\n\"When I am gone,<br>\n\"Let Shepard decorate my tomb,<br>\n\"And put (if there is room)<br>\n\"Two pictures on the stone:<br>\n\"Piglet from page a hundred and eleven,<br>\n\"And Pooh and Piglet walking (157) ...<br>\n\"And Peter, thinking that they are my own,<br>\n\"Will welcome me to Heaven.\"\nEventually Shepard came to resent \"that silly old bear\" as he felt that the Pooh illustrations overshadowed his other work.\n\nShepard modelled Pooh not on the toy owned by Milne's son Christopher Robin but on \"Growler\", a stuffed bear owned by his own son. (Growler no longer exists, having been given to his granddaughter Minnie Hunt and subsequently destroyed by a neighbour's dog.) His Pooh work is so famous that 300 of his preliminary sketches were exhibited at the Victoria and Albert Museum in 1969, when he was 90 years old.\n\nA Shepard painting of Winnie the Pooh, believed to have been painted in the 1930s for a Bristol teashop, is the only known oil painting of the famous teddy bear. It was purchased at an auction for $243,000 in London late in 2000. The painting is displayed in the Pavilion Gallery at Assiniboine Park in Winnipeg, Manitoba, Canada.\n\nShepard wrote two autobiographies: \"Drawn from Memory\" (1957) and \"Drawn From Life\" (1961).\n\nIn 1972, Shepard gave his personal collection of papers and illustrations to the University of Surrey. These now form the E.H. Shepard Archive.\n\nShepard was made an Officer of the Order of the British Empire in the 1972 Queen's Birthday Honours.\n\nShepard lived at Melina Place in St John's Wood and from 1955 in Lodsworth, West Sussex. He had two children, Graham (born 1907) and Mary (born 1909), who both became illustrators.\n\n\n\n\n\n"}
{"id": "10253", "url": "https://en.wikipedia.org/wiki?curid=10253", "title": "Enterobacteriaceae", "text": "Enterobacteriaceae\n\nThe Enterobacteriaceae are a large family of Gram-negative bacteria that includes, along with many harmless symbionts, many of the more familiar pathogens, such as \"Salmonella\", \"Escherichia coli\", \"Yersinia pestis\", \"Klebsiella\", and \"Shigella\". Other disease-causing bacteria in this family include \"Proteus\", \"Enterobacter\", \"Serratia\", and \"Citrobacter\". This family is the only representative in the order Enterobacteriales of the class Gammaproteobacteria in the phylum Proteobacteria. Phylogenetically, in the Enterobacteriales, several peptidoglycan-less insect endosymbionts form a sister clade to the Enterobacteriaceae, but as they are not validly described, this group is not officially a taxon; examples of these species are \"Sodalis\", \"Buchnera\", \"Wigglesworthia\", \"Baumannia cicadellinicola\", and \"Blochmannia\", but not former Rickettsias. Members of the Enterobacteriaceae can be trivially referred to as enterobacteria or \"enteric bacteria\", as several members live in the intestines of animals. In fact, the etymology of the family is enterobacterium with the suffix to designate a family (aceae)—not after the genus \"Enterobacter\" (which would be \"Enterobacteraceae\")—and the type genus is \"Escherichia\".\n\nMembers of the Enterobacteriaceae are rod-shaped, and are typically 1–5 μm in length. They appear as small grey colonies on blood agar. Like other proteobacteria, enterobacteria have Gram-negative stains, and they are facultative anaerobes, fermenting sugars to produce lactic acid and various other end products. Most also reduce nitrate to nitrite, although exceptions exist (e.g. \"Photorhabdus\"). Unlike most similar bacteria, enterobacteria generally lack cytochrome C oxidase, although there are exceptions (e.g. \"Plesiomonas shigelloides\"). Most have many flagella used to move about, but a few genera are nonmotile. They are not spore-forming. Catalase reactions vary among Enterobacteriaceae.\n\nMany members of this family are a normal part of the gut flora found in the intestines of humans and other animals, while others are found in water or soil, or are parasites on a variety of different animals and plants. \"Escherichia coli\" is one of the most important model organisms, and its genetics and biochemistry have been closely studied.\n\nMost members of Enterobacteriaceae have peritrichous, type I fimbriae involved in the adhesion of the bacterial cells to their hosts.\nSome enterobacteria produce endotoxins. Endotoxins reside in the cell wall and are released when the cell dies and the cell wall disintegrates. Some members of the Enterobacteriaceae produce endotoxins that, when released into the bloodstream following cell lysis, cause a systemic inflammatory and vasodilatory response. The most severe form of this is known as endotoxic shock, which can be rapidly fatal.\n\n\nTo identify different genera of Enterobacteriaceae, a microbiologist may run a series of tests in the lab. These include:\n\nIn a clinical setting, three species make up 80 to 95% of all isolates identified. These are \"Escherichia coli\", \"Klebsiella pneumoniae\", and \"Proteus mirabilis\".\n\nSeveral Enterobacteriaceae strains have been isolated which are resistant to antibiotics including carbapenems, which are often claimed as \"the last line of antibiotic defense\" against resistant organisms. For instance, some \"Klebsiella pneumoniae\" strains are carbapenem resistant.\n\n"}
{"id": "10256", "url": "https://en.wikipedia.org/wiki?curid=10256", "title": "Eccentricity", "text": "Eccentricity\n\nEccentricity or eccentric may refer to:\n\n\n\n\n\n"}
{"id": "10257", "url": "https://en.wikipedia.org/wiki?curid=10257", "title": "Essendon Football Club", "text": "Essendon Football Club\n\nThe Essendon Football Club is a professional Australian rules football club which plays in the Australian Football League (AFL), the sport's premier competition. Formed in 1871 as a junior club and playing as a senior club since 1878, Essendon is one of the oldest clubs in the AFL. It is historically associated with Essendon, a suburb in the north-west of Melbourne, Victoria. Since 2013, the club has been headquartered at the True Value Solar Centre, Melbourne Airport, and plays its home games at either Docklands Stadium or the Melbourne Cricket Ground; throughout most of its history the club's home ground and headquarters was Windy Hill, Essendon. Dyson Heppell is the current team captain.\n\nA founding member club of both the Victorian Football Association, in 1877, and the Victorian Football League (since renamed the AFL), in 1896, Essendon is one of Australia's best-known football clubs. The club claims to have at least one million supporters Australia wide. Essendon has won 16 VFL/AFL premierships which, along with Carlton, is the most of any club in the competition.\n\nThe club was founded by members of the Royal Agricultural Society, the Melbourne Hunt Club and the Victorian Woolbrokers. The Essendon Football Club is thought to have formed in 1872 at a meeting it the home of a well-known brewery family, the McCrackens, whose Ascot Vale property hosted a team of local junior players.\n\nRobert McCracken, the owner of several city hotels, was the founder and first president of the Essendon club and his son, Alex, its first secretary. Alex would later become president of the newly formed VFL. Alex's cousin, Collier, who had already played with Melbourne, was the team's first captain.\n\nThe club played its first recorded match against the Carlton second twenty on 7 June 1873, with Essendon winning by one goal. Essendon played 13 matches in its first season, winning seven, with four draws and losing two. The club was one of the inaugural junior members of the Victorian Football Association (VFA) in 1877, and began competing as a senior club from the 1878 season. During its early years in the Association, Essendon played its home matches at Flemington Hill, but moved to the East Melbourne Cricket Ground in 1881.\n\nIn 1878, Essendon played in the first match on what would be considered by modern standards to be a full-sized field at Flemington Hill. In 1879 Essendon played Melbourne in one of the earliest night matches recorded when the ball was painted white. In 1883 the team played four matches in Adelaide.\n\nIn 1891 Essendon won their first VFA premiership, which they repeated in 1892, 1893 and 1894. One of the club's greatest players, Albert Thurgood played for the club during this period. Essendon was undefeated in the 1893 season.\n\nAt the end of the 1896 season Essendon along with seven other clubs formed the Victorian Football League. Essendon's first VFL game was in 1897 was against Geelong at Corio Oval in Geelong. Essendon won its first VFL premiership by winning the 1897 VFL finals series. Essendon again won the premiership in 1901, defeating Collingwood in the Grand Final. The club won successive premierships in 1911 and 1912 over Collingwood and South Melbourne respectively.\n\nHaving already re-located from its ground at Kent Street, Ascot Vale (\"McCracken's Paddock\") to Flemington Hill, the club was again forced to move in 1881; and, because the City of Essendon mayor of the day considered the Essendon Cricket Ground \"to be suitable only for the gentleman's game of cricket\", Essendon moved to East Melbourne.\n\nThe club became known by the nickname \"the Same Old Essendon\", from the title and hook of the principal song performed by a band of supporters which regularly occupied a section of the grandstand at the club's games. The nickname first appeared in print in the local \"North Melbourne Advertiser\" in 1889, and ended up gaining wide use, often as the diminutive \"Same Olds\".\n\nThis move away from Essendon, at a time when fans would walk to their local ground, didn't go down too well with many Essendon people; and, as a consequence, a new team and club was formed in 1900, unconnected with the first (although it played in the same colours), that was based at the Essendon Cricket Ground, and playing in the Victorian Football Association. It was known firstly as Essendon Town and, after 1905, as Essendon (although it was often called Essendon A, with the A standing for association).\n\nAfter the 1921 season, the East Melbourne Cricket Ground was closed and demolished to expand the Flinders Street Railyard. Having played at the East Melbourne Cricket Ground from 1882 to 1921, and having won four VFA premierships (1891–1894) and four VFL premierships (1897, 1901, 1911 and 1912) whilst there, Essendon was looking for a new home, and was offered grounds at the current Royal Melbourne Showgrounds, at Victoria Park, at Arden St, North Melbourne, and the Essendon Cricket Ground. The Essendon City Council offered the (VFL) team the Essendon Cricket Ground, announcing that it would be prepared to spend over ₤12,000 on improvements, including a new grandstand, scoreboard and re-fencing of the oval.\n\nThe club's first preference was to move to North Melbourne – a move which the North Melbourne Football Club (then in the VFA) saw as a grand opportunity to get into the VFL. Most of Essendon's members and players were from the North Melbourne area, and sportswriters believed that Essendon would have been taken over by or rebranded as North Melbourne within only a few years of the move. However, the VFA, desperate for its own strategic reasons not to lose its use of the North Melbourne Cricket Ground, successfully appealed to the State Government to block Essendon's move to North Melbourne. With its preferred option off the table, the club returned to Essendon, and the Essendon VFA club disbanded, with most of its players moving to North Melbourne.\n\nThe old \"Same Olds\" nickname fell into disuse, and by 1922 the other nicknames \"Sash Wearers\" and \"Essendonians\" that had been variously used from time to time were also abandoned. The team became universally known as \"the Dons\" (from EssenDON); it was not until much later, during the War years of the early 1940s, that they became known as \"The Bombers\" — due to Windy Hill's proximity to the Essendon Aerodrome.\n\nIn the 1922 season, playing in Essendon for the first time in decades, Essendon reached the final four for the first time since 1912, finishing in third place. In the 1923 season the club topped the ladder with 13 wins from 16 games. After a 17-point second semi final loss to South Melbourne defeated Fitzroy (who had beaten South Melbourne) in the challenge final: Essendon 8.15 (63) to Fitzroy 6.10 (46). Amongst Essendon's best players were half forward flanker George \"Tich\" Shorten, centre half forward Justin McCarthy, centre half back Tom Fitzmaurice, rover Frank Maher and wingman Jack Garden.\n\nThis was one of Essendon's most famous sides, dubbed the \"Mosquito Fleet\", due to the number of small, very fast players in the side. Six players were 5'6\" (167 cm) or smaller.\n\nThe 1924 season proved to be arguably the strangest year in Essendon's entire history. For the first time since 1897 there was no ultimate match — either \"Challenge Final\" or \"Grand Final\" — to determine the premiers; instead, the top four clubs after the home and away season played a round-robin to determine the premiers. Essendon, having previously defeated both Fitzroy (by 40 points) and South Melbourne (by 33 points), clinched the premiership by means of a 20-point loss to Richmond. With the Tigers having already lost a match to Fitzroy by a substantial margin, the Dons were declared premiers by virtue of their superior percentage, meaning that Essendon again managed to win successive premierships. But the poor crowds for the finals meant this was never attempted again, resulting in Essendon having the unique record of winning the only two premierships without a grand final.\n\nProminent contributors to Essendon's 1924 Premiership success included back pocket Clyde Donaldson, follower Norm Beckton, half back flanker Roy Laing, follower Charlie May and rover Charlie Hardy.\n\nThe 1924 season was not without controversy, with rumours of numerous players accepting bribes. Regardless of the accuracy of these allegations, the club's image was tarnished, and the side experienced its lowest period during the decade that followed, with poor results on the field and decreased support off it.\n\nThere was worse to follow, with various Essendon players publicly blaming each other for the poor performance against Richmond, and then, with dissension still rife in the ranks, the side plummeted to an humiliating 28-point loss to VFA premiers Footscray in a special charity match played a week later in front of 46,100 people, in aid of \"Dame Nellie Melba's Limbless Soldiers' Appeal Fund\", purportedly (but not officially) for the championship of Victoria.\n\nWhile it is always difficult to assess the damage caused by events such as these, the club's fortunes dipped alarmingly, and persistently. Indeed, after finishing third in the 1926 season, it was to be 14 years before Essendon would even contest a finals series.\n\nThe 1933 season, was probably the start of the Essendon revival, seeing the debut of the player regarded as one of Essendon's greatest players Dick Reynolds. His impact was immediate. He won his first Brownlow Medal aged 19. His record of three Brownlow victories (1934, 1937, 1938), equalled Haydn Bunton, Sr (1931, 1932, 1935), and later equalled by Bob Skilton (1959, 1963, 1968), and Ian Stewart (1965, 1966, 1971).\n\nReynolds went on to arguably even greater achievements as a coach, a position to which he was first appointed, jointly with Harry Hunter, in 1939 (this was while Reynolds was still a player). A year later he took the reins on a solo basis and was rewarded with immediate success (at least in terms of expectations at the time which, after so long in the wilderness, were somewhat modest). He was regarded as having a sound tactical knowledge of the game and being an inspirational leader, as he led the side into the finals in 1940 for the first time since 1926, when the side finished 3rd. Melbourne, which defeated Essendon by just 5 points in the preliminary final, later went on to trounce Richmond by 39 points in the grand final.\n\n1941 brought Essendon's first grand final appearance since 1923, but the side again lowered its colours to Melbourne. A year later war broke out and the competition was considerably weakened, with Geelong being forced to pull out of the competition due to travel restrictions as a result of petrol rationing. Attendances at games also declined dramatically, whilst some clubs had to move from their normal grounds due to them being used for military purposes. Many players were lost to football due to their military service. Nevertheless, Essendon went on to win the 1942 Premiership with Western Australian Wally Buttsworth in irrepressible form at centre half back. Finally, the long-awaited premiership was Essendon's after comprehensively outclassing Richmond in the grand final, 19.18 (132) to 11.13 (79). The match was played at Carlton in front of 49,000 spectators.\n\nIn any case, there could be no such reservations about Essendon's next premiership, which came just four years later. Prior to that Essendon lost a hard fought grand final to Richmond in 1943 by 5 points, finished 3rd in 1944, and dropped to 8th in 1945.\n\nAfter WWII, Esssendon enjoyed great success. In the five years immediately after the war, Essendon won 3 premierships (1946, 1949, 1950) and were runners up twice (1947, 1948). In 1946, Essendon were clearly the VFL's supreme force, topping the ladder after the roster games and surviving a drawn second semi final against Collingwood to win through to the grand final a week later with a 10.16 (76) to 8.9 (57). Then, in the grand final against Melbourne, Essendon set a grand final record score of 22.18 (150) to Melbourne 13.9 (87), with 7 goal centre half forward Gordon Lane. Rover Bill Hutchinson, and defenders Wally Buttsworth, Cec Ruddell and Harold Lambert among the best players.\n\nThe 1947 Grand Final has to go down in the ledger as 'one of the ones that got away', Essendon losing to Carlton by a single point despite managing 30 scoring shots to 21. As if to prove that lightning does occasionally strike twice, the second of the 'ones that got away' came just a year later, the Dons finishing with a lamentable 7.27, to tie with Melbourne (who managed 10.9) in the 1948 grand final. A week later Essendon waved the premiership good-bye, as Melbourne raced to a 13.11 (89) to 7.8 (50) triumph. The club's Annual Report made an assessment that was at once restrained and, as was soon to emerge, tacitly and uncannily prophetic:\n\nIt is very apparent that no team is complete without a spearhead and your committee has high hopes of rectifying that fault this coming season.\n\nThe 1949 season heralded the arrival on the VFL scene of John Coleman, arguably the greatest player in Essendon's history, and, in the view of some, the finest player the game has known. In his first ever appearance for the Dons, against Hawthorn in Round 1 1949, he booted 12 of his side's 18 goals to create an opening round record which was to endure for forty five years. More importantly, however, he went on to maintain the same high level of performance throughout the season, kicking precisely 100 goals for the year to become the first player to top the ton since Richmond's Jack Titus in 1940.\n\nThe Coleman factor was just what Essendon needed to enable them to take that vital final step to premiership glory, but even so it was not until the business end of the season that this became clear. Essendon struggled to make the finals in 4th place, but once there they suddenly ignited to put in one of the most consistently devastating September performances in VFL history.\nCollingwood succumbed first as the Dons powered their way to an 82-point first semi final victory, and a fortnight later it was the turn of the North Melbourne Football Club as Essendon won the preliminary final a good deal more comfortably than the ultimate margin of 17 points suggested. In the grand final, Essendon were pitted against Carlton and in a match that was a total travesty as a contest they overwhelmed the Blues to the tune of 73 points, 18.17 (125) to 6.16 (52). Best for the Dons included pacy aboriginal half back flanker Norm McDonald, ruckman Bob McLure, and rovers Bill Hutchinson and Ron McEwin. John Coleman also did well, registering 6 majors.\n\nA year later Essendon were if anything even more dominant, defeating the North Melbourne Football Club in both the second semi final and the grand final to secure consecutive VFL premierships for the third time. Best afield in the grand final in what was officially his swansong as a player was captain-coach Dick Reynolds, who received sterling support from the likes of Norm McDonald, ruckman/back pocket Wally May, back pocket Les Gardiner, and big Bob McLure.\n\nWith 'King Richard' still holding court as coach in 1951, albeit now in a non-playing capacity, Essendon seemed on course for a third consecutive flag but a controversial four-week suspension dished out to John Coleman on the eve of the finals effectively put paid to their chances. Coleman was reported for retaliation after twice being struck by his Carlton opponent, Harry Caspar, and without him the Dons were rated a 4 goals poorer team. Nevertheless, they still managed to battle their way to a 6th successive grand final with wins over Footscray by 8 points in the first semi final and Collingwood by 2 points in the preliminary final.\n\nThe Dons sustained numerous injuries in the preliminary final and the selectors sprang a surprise on grand final day by naming the officially retired Dick Reynolds as 20th man. 'King Richard' was powerless to prevent the inevitable, although leading at half time, the Geelong kicked five goals to two points in the third quarter to set up victory by 11 points.\n\nEssendon slumped to 8th in 1952 but John Coleman was in irrepressible form managing 103 goals for the year. Hugh Buggy noted in \"The Argus\": \"It was the wettest season for twenty two years and Coleman showed that since the war he was without peer in the art of goal kicking.\"\n\nTwo seasons later Coleman's career was ended after he dislocated a knee during the Round 8 clash with the North Melbourne Football Club at Essendon. Aged just twenty five, he had kicked 537 goals in only 98 VFL games in what was generally a fairly low scoring period for the game. His meteoric rise and fall were clearly the stuff of legend, and few if any players, either before or since, have had such an immense impact over so brief a period.\n\nAccording to Alf Brown, football writer for \"The Herald\":\n\n(Coleman) had all football's gifts. He was courageous, a long, straight kick, he had a shrewd football brain and, above all, he was a spectacular, thrilling mark.\n\nSomewhat more colourful, R.S. Whittington suggested,\n\n\"Had he been a trapeze artist in a strolling circus, Coleman could have dispensed with the trapeze.\"\n\nWithout Coleman, Essendon's fortunes plummeted, and there were to be no further premierships in the 1950s. The nearest miss came in 1957 when the Bombers (as they were popularly known by this time) earned premiership favouritism after a superb 16 point second semi final defeat of Melbourne, only to lose by over 10 goals against the same side a fortnight later.\n\n1959 saw another grand final loss to Melbourne, this time by 37 points, but the fact that the average age of the Essendon side was only 22 was seen as providing considerable cause for optimism. However, it was to take another three years, and a change of coach, before the team's obvious potential was translated into tangible success.\n\nJohn Coleman started his coaching career at Essendon in 1961, thus ending the Dick Reynolds era at the club. In the same year Essendon finished the season mid table and supporters were not expecting too much for the following season. However, the club blitzed the opposition in this year, losing only two matches and finishing top of the table. Both losses were to the previous year's grand finalists. The finals posed no problems for the resurgent Dons, easily accounting for Carlton in the season's climax, winning the 1962 Premiership. This was a remarkable result for Coleman who in his second season of coaching pulled off the ultimate prize in Australian football. As so often is the case after a flag, the following two years were below standard. A further premiership in 1965 (won from 4th position on the ladder), was also unexpected due to periods of poor form during the season. The Bombers were a different club when the finals came around, but some of the credit for the improvement was given to the influence of Brian Sampson and Ted Fordham during the finals. Coleman's time as coach turned out to be much like his playing career: highly successful but cut short when he had to stand down due to health problems in 1967. Only six years later, on the eve of the 1973 season, he would be dead of a heart-attack at just 44 years of age.\n\nFollowing Coleman's retirement, the club experienced tough times on and off the field. Finals appearances were rare for the side, which was often in contention for the wooden spoon. Essendon did manage to make the 1968 VFL Grand Final, but lost to Carlton by just three points and would not make it back to the big stage for a decade-and-a-half.\n\nDuring the period from 1968 until 1980, five different coaches were tried, with none lasting longer than four years. Off the field the club went through troubled times as well. In 1970 five players went on strike before the season even began, demanding higher payments. Essendon did make the finals in 1972 and 1973 under the autocratic direction of Des Tuddenham (Collingwood) but they were beaten badly in successive elimination finals by St. Kilda and would not taste finals action again until the very end of the decade. The 70s Essendon sides were involved in many rough and tough encounters under Tuddenham, who himself came to logger heads with Ron Barassi at a quarter time huddle where both coaches exchanged heated words. Essendon had tough, but talented players with the likes of \"Rotten Ronnie\" Ron Andrews and experienced players such as Barry Davis, Ken Fletcher, Geoff Blethyn, Neville Fields and West Australian import Graham Moss. In May 1974, a controversial half time all-in-brawl with Richmond at Windy Hill and a 1975 encounter with Carlton were testimony of the era. Following the Carlton match, the 'Herald' described Windy Hill as \"Boot Hill\", because of the extent of the fights and the high number of reported players (eight in all – four from Carlton and four from Essendon). The peak of these incidents would occur in 1980 with new recruit Phil Carman making headlines for head-butting an umpire. The tribunal suspended him for sixteen weeks, and although most people thought this was a fair (or even lenient) sentence, he took his case to the supreme court, gathering even more unwanted publicity for the club. Despite this, the club had recruited many talented young players in the late 70s who would emerge as club greats. Three of those young players were Simon Madden, Tim Watson and Paul Van Der Haar. Terry Daniher and his brother Neale would come via a trade with South Melbourne, and Roger Merrett joined soon afterwards to form the nucleus of what would become the formidable Essendon sides of the 1980s. This raw but talented group of youngsters took Essendon to an elimination final in 1979 under Barry Davis but were again thrashed in an Elimination Final, this time at the hands of Fitzroy. Davis resigned at the end of the 1980 season after missing out on a finals appearance.\n\nOne of the few highlights for Essendon supporters during this time was when Graham Moss won the 1976 Brownlow Medal; he was the only Bomber to do so in a 40-year span from 1953–1993. Even that was bittersweet as he quit VFL football to move back to his native Western Australia, where Moss finished out his career as a player and coach at Claremont Football Club. In many ways, Moss' career reflects Essendon's mixed fortunes during the decade.\n\nFormer Richmond player Kevin Sheedy started as head coach in 1981.\n\nEssendon reached the Grand Final in 1983, the first time since 1968. Hawthorn won by a then record 83 points.\n\nIn 1984, Essendon won the pre-season competition and completed the regular season on top of the ladder. The club played, and beat, Hawthorn in the 1984 VFL Grand Final to win their 13th premiership—their first since 1965. The teams met again in the 1985 Grand Final, which Essendon also won. At the start of 1986, Essendon were considered unbackable for three successive flags, but a succession of injuries to key players Paul Van der Haar (only fifteen games from 1986 to 1988), Tim Watson, Darren Williams, Roger Merrett and Simon Madden led the club to win only eight of its last eighteen games in 1986 and only nine games (plus a draw with Geelong) in 1987. In July 1987, the Bombers suffered a humiliation at the hands of Sydney, who fell two points short of scoring the then highest score in VFL history.\n\nIn 1988, Essendon made a rebound to sixth place with twelve wins, including a 140-point thrashing of Brisbane where they had a record sixteen individual goalkickers. In 1989, they rebounded further to second on the ladder with only five losses and thrashed Geelong in the Qualifying Final. However, after a fiery encounter with Hawthorn ended in a convincing defeat, the Bombers were no match for Geelong next week.\n\nIn 1990, Essendon were pace-setters almost from the start, but a disruption from the Qualifying Final draw between Collingwood and West Coast was a blow from which they never recovered. The Magpies comprehensively thrashed them in both the second semi final and the grand final.\n\nFollowing the 1991 season, Essendon moved its home games from its traditional home ground at Windy Hill to the larger and newly renovated MCG. This move generated large increases in game attendance, membership and revenue for the club. The club's training and administrative base remained at Windy Hill until 2013.\n\nFollowing the retirement of Tim Watson and Simon Madden in the early 1990s, the team was built on new players such as Gavin Wanganeen, Joe Misiti, Mark Mercuri, Michael Long, Dustin Fletcher (son of Ken) and James Hird, who was taken at #79 in the 1992 draft. This side became known as the \"Baby Bombers\", as the core of the side was made up of young players early in their careers.\n\nThe team won the 1993 Grand Final against Carlton and that same year, Gavin Wanganeen won the Brownlow Medal, the first awarded to an Essendon player since 1976. Three years later, James Hird was jointly awarded the medal with Michael Voss of Brisbane.\n\nIn 2000, Essendon won 20 consecutive matches before they lost to the Western Bulldogs in round 21. The team went on to win their 16th premiership, defeating , thereby completing the most dominant single season in AFL/VFL history. The defeat to the Bulldogs was the only defeat for Essendon throughout the entire calendar year (Essendon also won the 2000 pre-season competition).\n\nEssendon was less successful after 2001. Lucrative contracts to a number of premiership players had caused serious pressure on the club's salary cap, forcing the club to trade several key players. Blake Caracella, Chris Heffernan, Justin Blumfield, Gary Moorcroft and Damien Hardwick had all departed by the end of 2002; in 2004 Mark Mercuri, Sean Wellman and Joe Misiti retired. The club remained competitive, however they could progress no further than the second week of the finals each year for the years of 2002, 2003, and 2004. Sheedy signed a new three-year contract at the end of 2004.\nIn 2005, Essendon missed the finals for the first time since 1997; and in 2006, the club suffered its worst season under Sheedy, and its worst for more than 70 years, finishing second-last with only three wins (one of which was against defending premiers , in which Matthew Lloyd kicked eight goals) and one draw from twenty-two games. Matthew Lloyd replaced James Hird as captain at the start of the season, but after suffering a season-ending hamstring injury early in the season, David Hille was appointed captain for the remainder of the season. The club improved its on-field position in 2007, but again missed the finals.\n\nSheedy's contract was not renewed after 2007, ending his 27-year tenure as Essendon coach. Matthew Knights replaced Sheedy as coach, and coached the club for three seasons, reaching the finals once – an eighth-place finish in 2009 at the expense of reigning premiers . On 29 August 2010, shortly after the end of the 2010 home-and-away season, Knights was dismissed as coach.\nOn 28 September 2010, former captain James Hird was named as Essendon's new coach from 2011 on a four-year deal. Former dual premiership winning coach and Essendon triple-premiership winning player Mark Thompson later joined Hird on the coaching panel. In his first season, Essendon finished eighth. The club started strongly in 2012, sitting fourth with a 10-3 record at the halfway mark of the season; but the club won only one more match for the season, finishing eleventh to miss the finals.\n\nIn 2013 the club moved its training and administrative base to the True Value Solar Centre, a new facility in the suburb of Melbourne Airport which it had developed in conjunction with the Australian Paralympic Committee. Essendon holds a 37-year lease at the facility, and maintains a lease at Windy Hill to use the venue for home matches for its reserves team in the Victorian Football League, and for a social club and merchandise store on the site.\n\nDuring 2013, the club was investigated by the AFL and the Australian Sports Anti-Doping Authority (ASADA) over its 2012 player supplements and sports science program, most specifically over allegations into illegal use of peptide supplements. An internal review found it to have \"established a supplements program that was experimental, inappropriate and inadequately vetted and controlled\", and on 27 August 2013 the club was found guilty of bringing the game into disrepute for this reason. Among its penalties, the club was fined A$2 million, stripped of early draft picks in the following two drafts, and forfeited its place in the 2013 finals series (having originally finished seventh on the ladder); Hird was suspended from coaching for twelve months. Several office-bearers also resigned their posts during the controversy, including chairman David Evans and CEO Ian Robson.\n\nIn the midst of the supplements saga, assistant coach Mark Thompson took over as coach for the 2014 season during Hird's suspension. He led the club back to the finals for a seventh-place finish but in a tense first elimination final against archrivals North Melbourne, the Bombers would lead by as much as 27 points at half time before a resurgent Kangaroos side came back and won the game by 12 points. After the 2014 season Mark Thompson left the club to make way for Hird's return to the senior coaching role.\n\nIn June 2014, thirty-four players were issued show-cause notices alleging the use of banned peptide Thymosin beta-4 during the program. The players faced the AFL Anti-Doping Tribunal over the 2014/15 offseason, and on 31 March 2015 the tribunal returned a not guilty verdict, determining that it was \"not comfortably satisfied\" that the players had been administered the peptide.\n\nHird returned as senior coach for the 2015 season, and after a strong start, the club's form severely declined after the announcement that WADA would appeal the decision of the AFL Anti-Doping Tribunal. The effect of the appeal on the team's morale was devastating and they would go on to win only six games for the year. Under extreme pressure, Hird resigned on 18 August 2015 following a disastrous 112-point loss to Adelaide. Former West Coast Eagles premiership coach John Worsfold was appointed as the new senior coach on a three-year contract.\n\nOn January 12, 2016, the Court of Arbitration for Sport overruled the AFL anti-doping tribunal's decision, deeming that 34 past and present players of the Essendon Football Club, took the banned substance Thymosin Beta-4. As a result, all 34 players, 12 of which were still at the club, were given two year suspensions. However all suspensions were effectively less due to players having previously taken part in provisional suspensions undertaken during the 2014/2015 off season. \nAs a result, Essendon contested the 2016 season with twelve of its regular senior players under suspension. In order for the club to remain competitive, the AFL granted Essendon the ability to upgrade all five of their rookie listed players and to sign an additional ten players to cover the loss of the suspended players for the season.\n\nDue to this unprecedented situation, many in the football community predicted the club would go through the 2016 AFL season without a win, however, they were able to win three matches: against , and in rounds two, 21 and 23 respectively. The absence of its most experienced players also allowed the development of its young players, with Zach Merrett and Orazio Fantasia having breakout years, while Darcy Parish and Anthony McDonald-Tipungwuti, impressing in their debut seasons. Merrett acted as captain in the side's round 21 win over the Suns. The club eventually finished on the bottom of the ladder and thus claimed its first wooden spoon since 1933.\n\nEssendon's first recorded jumpers were navy blue (The Footballers, edited by Thomas Power, 1875) although the club wore 'red and black caps and hose'. In 1877 The Footballers records the addition of 'a red sash over left shoulder'. This is the first time a red sash as part of the club jumper and by 1878 there are newspaper reports referring to Essendon players as 'the men in the sash'.\n\nGiven that blue and navy blue were the most popular colours at the time it is thought that Essendon adopted a red sash in 1877 to distinguish its players from others in similar coloured jumpers.\n\nIn 2007, the AFL Commission laid down the requirement that all clubs must produce an alternative jumper for use in matches where jumpers are considered to clash. From 2007–2011, the Essendon clash guernsey was the same design as its home guernsey, but with a substantially wider sash such that the guernsey was predominantly red rather than predominantly black. This was changed after 2011 when the AFL deemed that the wider sash did not provide a sufficient contrast.\n\nFrom 2012 to 2016, Essendon's clash guernsey was predominantly grey, with a red sash fimbriated in black; the grey field contained, in small print, the names of all Essendon premiership players.\n\nBefore the 2016 season, Essendon's changed their clash guernsey to a predominately red one, featuring a red sash in black. Similar to the grey jumper, the names of Essendon premiership players were also printed outside the sash.\n\nFollowing Adam Ramanauskas' personal battle with cancer, a \"Clash for Cancer\" match against was launched in 2006. This was a joint venture between Essendon and the Cancer Council of Victoria to raise funds for the organisation. Despite a formal request to the AFL being denied, players wore yellow armbands for the match which resulted in the club being fined $20,000. In 2007, the AFL agreed to allow yellow armbands to be incorporated into the left sleeve of the jumper. The 'Clash for Cancer' match against Melbourne has become an annual event, repeated in subsequent seasons, though in 2012, 2013, 2014 and 2016, (twice), the Sydney Swans and Brisbane Lions were the opponents in those respective seasons instead of Melbourne. In 2009, the jumpers were auctioned along with yellow boots worn by some players during the match.\n\nThe club's theme song, \"See the Bombers Fly Up\", was written c. 1959 by Kevin Andrews and is based on the tune of Johnnie Hamp's 1929 song \"(Keep Your) Sunny Side Up\" at an increased tempo. At the time, \"(Keep Your) Sunny Side Up\" was the theme song for the popular Melbourne-based TV show \"Sunnyside Up\". The official version of the song was recorded in 1972 by the Fable Singers and is still used today.\n\nThe song, as with all other AFL clubs, is played prior to every match and at the conclusion of matches when the team is victorious.\n\nSongwriter Mike Brady, of \"Up There Cazaly\" fame, penned an updated version of the song in 1999 complete with a new verse arrangement, but it was not well received. However, this version is occasionally played at club functions.\n\nThe club's mascot is named \"Skeeta Reynolds\". Named after Dick Reynolds, he is a mosquito and was created in honour of the team's back-to-back premiership sides in the 1920s known as the \"Mosquito Fleet\". He was first named through a competition run in the Bomber magazine with \"Skeeta\" being the winning entry. This was later changed by the AFL to \"Skeeta Reynolds\". He appears as a red mosquito in an Essendon jumper and wears a red and black scarf.\n\nNotable supporters include:\n\nEssendon has a four-way rivalry with , , and being the four biggest and most supported clubs in Victoria. Matches between the clubs are often close regardless of form and ladder positions. If out of the race themselves, all four have the desire to deny the others a finals spot or a premiership. Essendon also has a fierce rivalry with Hawthorn stemming from the 1980s.\n\n\nLindsay Tanner has served as chairman of the board since late 2015.\n\nEssendon's board members are Paul Brasher, Paul Cousins, Chris Heffernan, Daryl Jackson, Catherine Lio, Paul Little, Simon Madden, Andrew Muir and Lindsay Tanner.\n\nOn 25 August 2008, Samsung was announced as major sponsor of the Essendon Football Club in a three-year deal touted as the biggest individual annual club sponsorship in AFL history. The deal included Samsung having naming rights on the front and back of the club jumper and signage. Although the amount was only confirmed by the club as a very significant lift from where 3 were, it was estimated to be worth around $7 million in total.\n\nThe club's apparel is currently produced by ISC. The club's apparel has also been made by Reebok (1996-1999), Fila (2000-2002), Puma (2003-2008), and Adidas (2009-2016).\n\n\"See Essendon Football Club honours\"\n\"See W. S. Crichton Medal\"\n\n\nTo celebrate the 125th anniversary of the club, as well as 100 years of the VFL/AFL, Essendon announced its \"Team of the Century\" in 1997.\n\nIn 2002, a club panel chose and ranked the 25 greatest players to have played for Essendon.\n\n\nThe Essendon reserves team first competed in the Victorian Football League's reserves competition when the competition was established in 1919. The team enjoyed success in the form of eight premierships between 1919 and 1999, including the last Victorian State Football League year in 1999. From 2000 until 2002, the club's reserves team competed in the new Victorian Football League competition.\n\nAt the end of 2002, the club dissolved its reserves team and established a reserves affiliation with the Bendigo Football Club in the VFL. The affiliation ran for ten years from 2003 until 2012, allowing reserves players from the Essendon list to play with Bendigo.\n\nThe club re-established its reserves team in 2013, seeking greater developmental autonomy. The reserves team has since competed in the VFL. The team plays its home games at Windy Hill. The team is made up of AFL senior listed players and VFL contracted players.\n\n\n"}
{"id": "10258", "url": "https://en.wikipedia.org/wiki?curid=10258", "title": "Enid Blyton", "text": "Enid Blyton\n\nEnid Mary Blyton (11 August 1897 – 28 November 1968) was an English children's writer whose books have been among the world's best-sellers since the 1930s, selling more than 600 million copies. Blyton's books are still enormously popular, and have been translated into 90 languages; her first book, \"Child Whispers\", a 24-page collection of poems, was published in 1922. She wrote on a wide range of topics including education, natural history, fantasy, mystery, and biblical narratives and is best remembered today for her Noddy, Famous Five, Secret Seven, and Adventure series.\n\nFollowing the commercial success of her early novels such as \"Adventures of the Wishing Chair\" (1937) and \"The Enchanted Wood\" (1939), Blyton went on to build a literary empire, sometimes producing fifty books a year in addition to her prolific magazine and newspaper contributions. Her writing was unplanned and sprang largely from her unconscious mind; she typed her stories as events unfolded before her. The sheer volume of her work and the speed with which it was produced led to rumours that Blyton employed an army of ghost writers, a charge she vigorously denied.\n\nBlyton's work became increasingly controversial among literary critics, teachers and parents from the 1950s onwards, because of the alleged unchallenging nature of her writing and the themes of her books, particularly the Noddy series. Some libraries and schools banned her works, which the BBC had refused to broadcast from the 1930s until the 1950s because they were perceived to lack literary merit. Her books have been criticised as being elitist, sexist, racist, xenophobic and at odds with the more liberal environment emerging in post-war Britain, but they have continued to be best-sellers since her death in 1968.\n\nBlyton felt she had a responsibility to provide her readers with a strong moral framework, so she encouraged them to support worthy causes. In particular, through the clubs she set up or supported, she encouraged and organised them to raise funds for animal and paediatric charities. The story of Blyton's life was dramatised in a BBC film entitled \"Enid\", featuring Helena Bonham Carter in the title role and first broadcast in the United Kingdom on BBC Four in 2009. There have also been several adaptations of her books for stage, screen and television.\n\nEnid Blyton was born on 11 August 1897 in East Dulwich, South London, the eldest of three children, to Thomas Carey Blyton (1870–1920), a cutlery salesman, and his wife Theresa Mary ( Harrison; 1874–1950). Enid's younger brothers, Hanly (1899–1983) and Carey (1902–1976), were born after the family had moved to a semi-detached villa in Beckenham, then a village in Kent. A few months after her birth Enid almost died from whooping cough, but was nursed back to health by her father, whom she adored. Thomas Blyton ignited Enid's interest in nature; in her autobiography she wrote that he \"loved flowers and birds and wild animals, and knew more about them than anyone I had ever met\". He also passed on his interest in gardening, art, music, literature and the theatre, and the pair often went on nature walks, much to the disapproval of Enid's mother, who showed little interest in her daughter's pursuits. Enid was devastated when he left the family shortly after her thirteenth birthday to live with another woman. Enid and her mother did not have a good relationship, and she did not attend either of her parents' funerals.\n\nFrom 1907 to 1915 Blyton attended St Christopher's School in Beckenham, where she enjoyed physical activities and became school tennis champion and captain of lacrosse. She was not so keen on all the academic subjects but excelled in writing, and in 1911 she entered Arthur Mee's children's poetry competition. Mee offered to print her verses, encouraging her to produce more. Blyton's mother considered her efforts at writing to be a \"waste of time and money\", but she was encouraged to persevere by Mabel Attenborough, the aunt of a school friend.\nBlyton's father taught her to play the piano, which she mastered well enough for him to believe that she might follow in his sister's footsteps and become a professional musician. Blyton considered enrolling at the Guildhall School of Music, but decided she was better suited to becoming a writer. After finishing school in 1915 as head girl, she moved out of the family home to live with her friend Mary Attenborough, before going to stay with George and Emily Hunt at Seckford Hall near Woodbridge in Suffolk. Seckford Hall, with its allegedly haunted room and secret passageway provided inspiration for her later writing. At Woodbridge Congregational Church Blyton met Ida Hunt, who taught at Ipswich High School, and suggested that she train as a teacher. Blyton was introduced to the children at the nursery school, and recognising her natural affinity with them she enrolled in a National Froebel Union teacher training course at the school in September 1916. By this time she had almost ceased contact with her family.\n\nBlyton's manuscripts had been rejected by publishers on many occasions, which only made her more determined to succeed: \"it is partly the struggle that helps you so much, that gives you determination, character, self-reliance – all things that help in any profession or trade, and most certainly in writing\". In March 1916 her first poems were published in \"Nash's Magazine\". She completed her teacher training course in December 1918, and the following month obtained a teaching appointment at Bickley Park School, a small independent establishment for boys in Bickley, Kent. Two months later Blyton received a teaching certificate with distinctions in zoology and principles of education, 1st class in botany, geography, practice and history of education, child hygiene and class teaching and 2nd class in literature and elementary mathematics. In 1920 she moved to Southernhay in Hook Road Surbiton as nursery governess to the four sons of architect Horace Thompson and his wife Gertrude, with whom Blyton spent four happy years. Owing to a shortage of schools in the area her charges were soon joined by the children of neighbours, and a small school developed at the house.\n\nIn 1920 Blyton relocated to Chessington, and began writing in her spare time. The following year she won the \"Saturday Westminster Review\" writing competition with her essay \"On the Popular Fallacy that to the Pure All Things are Pure\". Publications such as \"The Londoner\", \"Home Weekly\" and \"The Bystander\" began to show an interest in her short stories and poems.\nBlyton's first book, \"Child Whispers\", a 24-page collection of poems, was published in 1922. It was illustrated by a schoolfriend, Phyllis Chase, who collaborated on several of her early works. Also in that year Blyton began writing in annuals for Cassell and George Newnes, and her first piece of writing, \"Peronel and his Pot of Glue\", was accepted for publication in \"Teachers' World\". Her success was boosted in 1923 when her poems were published alongside those of Rudyard Kipling, Walter de la Mare and G. K. Chesterton in a special issue of \"Teachers' World\". Blyton's educational texts were quite influential in the 1920s and '30s, her most sizeable being the three-volume \"The Teacher's Treasury\" (1926), the six-volume \"Modern Teaching\" (1928), the ten-volume \"Pictorial Knowledge\" (1930), and the four-volume \"Modern Teaching in the Infant School\" (1932).\n\nIn July 1923 Blyton published \"Real Fairies\", a collection of thirty-three poems written especially for the book with the exception of \"Pretending\", which had appeared earlier in \"Punch\" magazine. The following year she published \"The Enid Blyton Book of Fairies\", illustrated by Horace J. Knowles, and in 1926 the \"Book of Brownies\". Several books of plays appeared in 1927, including \"A Book of Little Plays\" and \"The Play's the Thing\" with the illustrator Alfred Bestall.\n\nIn the 1930s Blyton developed an interest in writing stories related to various myths, including those of ancient Greece and Rome; \"The Knights of the Round Table\", \"Tales of Ancient Greece\" and \"Tales of Robin Hood\" were published in 1930. In \"Tales of Ancient Greece\" Blyton retold sixteen well-known ancient Greek myths, but used the Latin rather than the Greek names of deities and invented conversations between the characters. \"The Adventures of Odysseus\", \"Tales of the Ancient Greeks and Persians\" and \"Tales of the Romans\" followed in 1934.\n\nThe first of twenty-eight books in Blyton's Old Thatch series, \"The Talking Teapot and Other Tales\", was published in 1934, the same year as the first book in her Brer Rabbit series, \"Brer Rabbit Retold\"; (note that Brer Rabbit originally featured in Uncle Remus stories by Joel Chandler Harris), her first serial story and first full-length book, \"Adventures of the Wishing-Chair\", followed in 1937. \"The Enchanted Wood\", the first book in the Faraway Tree series, published in 1939, is about a magic tree inspired by the Norse mythology that had fascinated Blyton as a child. According to Blyton's daughter Gillian the inspiration for the magic tree came from \"thinking up a story one day and suddenly she was walking in the enchanted wood and found the tree. In her imagination she climbed up through the branches and met Moon-Face, Silky, the Saucepan Man and the rest of the characters. She had all she needed.\" As in the Wishing-Chair series, these fantasy books typically involve children being transported into a magical world in which they meet fairies, goblins, elves, pixies and other mythological creatures.\n\nBlyton's first full-length adventure novel, \"The Secret Island\", was published in 1938, featuring the characters of Jack, Mike, Peggy and Nora. Described by \"The Glasgow Herald\" as a \"Robinson Crusoe-style adventure on an island in an English lake\", \"The Secret Island\" was a lifelong favourite of Gillian's and spawned the Secret series. The following year Blyton released her first book in the Circus series and her initial book in the Amelia Jane series, \"Naughty Amelia Jane!\" According to Gillian the main character was based on a large handmade doll given to her by her mother on her third birthday.\n\nDuring the 1940s Blyton became a prolific author, her success enhanced by her \"marketing, publicity and branding that was far ahead of its time\". In 1940 Blyton published two books – \"Three Boys and a Circus\" and \"Children of Kidillin\" – under the pseudonym of Mary Pollock (middle name plus first married name), in addition to the eleven published under her own name that year. So popular were Pollock's books that one reviewer was prompted to observe that \"Enid Blyton had better look to her laurels\". But Blyton's readers were not so easily deceived and many complained about the subterfuge to her and her publisher, with the result that all six books published under the name of Mary Pollock – two in 1940 and four in 1943 – were reissued under Blyton's name. Later in 1940 Blyton published the first of her boarding school story books and the first novel in the Naughtiest Girl series, \"The Naughtiest Girl in the School\", which followed the exploits of the mischievous schoolgirl Elizabeth Allen at the fictional Whyteleafe School. The first of her six novels in the St. Clare's series, \"The Twins at St. Clare's\", appeared the following year, featuring the twin sisters Patricia and Isabel O'Sullivan.\n\nIn 1942 Blyton released the first book in the Mary Mouse series, \"Mary Mouse and the Dolls' House\", about a mouse exiled from her mousehole who becomes a maid at a dolls' house. Twenty-three books in the series were produced between 1942 and 1964; 10,000 copies were sold in 1942 alone. The same year, Blyton published the first novel in the Famous Five series, \"Five on a Treasure Island\", with illustrations by Eileen Soper. Its popularity resulted in twenty-one books between then and 1963, and the characters of Julian, Dick, Anne, George (Georgina) and Timmy the dog became household names in Britain. Matthew Grenby, author of \"Children's Literature\", states that the five were involved with \"unmasking hardened villains and solving serious crimes\", although the novels were \"hardly 'hard-boiled' thrillers\". Blyton based the character of Georgina, a tomboy she described as \"short-haired, freckled, sturdy, and snub-nosed\" and \"bold and daring, hot-tempered and loyal\", on herself.\n\nBlyton had an interest in biblical narratives, and retold Old and New Testament stories. \"The Land of Far-Beyond\" (1942) is a Christian parable along the lines of John Bunyan's \"The Pilgrim's Progress\" (1698), with contemporary children as the main characters. In 1943 she published \"The Children's Life of Christ\", a collection of fifty-nine short stories related to the life of Jesus, with her own slant on popular biblical stories, from the Nativity and the Three Wise Men through to the trial, the crucifixion and the resurrection. \"Tales from the Bible\" was published the following year, followed by \"The Boy with the Loaves and Fishes\" in 1948.\n\nThe first book of Blyton's Five Find-Outers series, \"The Mystery of the Burnt Cottage\", was published in 1943, as was the second book in the Faraway series, \"The Magic Faraway Tree\", which in 2003 was voted 66th in the BBC's Big Read poll to find the UK's favourite book. Several of Blyton's works during this period have seaside themes; \"John Jolly by the Sea\" (1943), a picture book intended for younger readers, was published in a booklet format by Evans Brothers. Other books with a maritime theme include \"The Secret of Cliff Castle\" and \"Smuggler Ben\", both attributed to Mary Pollock in 1943; \"The Island of Adventure\", the first in the Adventure series of eight novels from 1944 onwards; and various novels of the Famous Five series such as \"Five on a Treasure Island\" (1942), \"Five on Kirrin Island Again\" (1947) and \"Five Go Down to the Sea\" (1953).\n\nCapitalising on her success, with a loyal and ever-growing readership, Blyton produced a new edition of many of her series such as the Famous Five, the Five Find-Outers and St. Clare's every year in addition to many other novels, short stories and books. In 1946 Blyton launched the first in the Malory Towers series of six books based around the schoolgirl Darrell Rivers, \"First Term at Malory Towers\", which became extremely popular, particularly with girls.\n\nThe first book in Blyton's Barney Mysteries series, \"The Rockingdown Mystery\", was published in 1949, as was the first of her fifteen Secret Seven novels. The Secret Seven Society consists of Peter, his sister Janet, and their friends Colin, George, Jack, Pam and Barbara, who meet regularly in a shed in the garden to discuss peculiar events in their local community. Blyton rewrote the stories so they could be adapted into cartoons, which appeared in \"Mickey Mouse Weekly\" in 1951 with illustrations by George Brook. The French author Evelyne Lallemand continued the series in the 1970s, producing an additional twelve books, nine of which were translated into English by Anthea Bell between 1983 and 1987.\nBlyton's Noddy, about a little wooden boy from Toyland, first appeared in the \"Sunday Graphic\" on 5 June 1949, and in November that year \"Noddy Goes to Toyland\", the first of at least two dozen books in the series, was published. The idea was conceived by one of Blyton's publishers, Sampson, Low, Marston and Company, who in 1949 arranged a meeting between Blyton and the Dutch illustrator Harmsen van der Beek. Despite having to communicate via an interpreter, he provided some initial sketches of how Toyland and its characters would be represented. Four days after the meeting Blyton sent the text of the first two Noddy books to her publisher, to be forwarded to van der Beek. The Noddy books became one of her most successful and best-known series, and were hugely popular in the 1950s. An extensive range of sub-series, spin-offs and strip books were produced throughout the decade, including \"Noddy's Library\", \"Noddy's Garage of Books\", \"Noddy's Castle of Books\", \"Noddy's Toy Station of Books\" and \"Noddy's Shop of Books\".\n\nIn 1950 Blyton established the company Darrell Waters Ltd to manage her affairs. By the early 1950s she had reached the peak of her output, often publishing more than fifty books a year, and she remained extremely prolific throughout much of the decade. By 1955 Blyton had written her fourteenth Famous Five novel, \"Five Have Plenty of Fun\", her fifteenth Mary Mouse book, \"Mary Mouse in Nursery Rhyme Land\", her eighth book in the Adventure series, \"The River of Adventure\", and her seventh Secret Seven novel, \"Secret Seven Win Through\". She completed the sixth and final book of the Malory Towers series, \"Last Term at Malory Towers\", in 1951.\n\nBlyton published several further books featuring the character of Scamp the terrier, following on from \"The Adventures of Scamp\", a novel she had released in 1943 under the pseudonym of Mary Pollock. \"Scamp Goes on Holiday\" (1952) and \"Scamp and Bimbo\", \"Scamp at School\", \"Scamp and Caroline\" and \"Scamp Goes to the Zoo\" (1954) were illustrated by Pierre Probst. She introduced the character of Bom, a stylish toy drummer dressed in a bright red coat and helmet, alongside Noddy in \"TV Comic\" in July 1956. A book series began the same year with \"Bom the Little Toy Drummer\", featuring illustrations by R. Paul-Hoye, and followed with \"Bom and His Magic Drumstick\" (1957), \"Bom Goes Adventuring\" and \"Bom Goes to Ho Ho Village\" (1958), \"Bom and the Clown\" and \"Bom and the Rainbow\" (1959) and \"Bom Goes to Magic Town\" (1960). In 1958 she produced two annuals featuring the character, the first of which included twenty short stories, poems and picture strips.\n\nMany of Blyton's series, including Noddy and The Famous Five, continued to be successful in the 1960s; by 1962, 26 million copies of Noddy had been sold. Blyton concluded several of her long-running series in 1963, publishing the last books of The Famous Five (\"Five Are Together Again\") and The Secret Seven (\"Fun for the Secret Seven\"); she also produced three more Brer Rabbit books with the illustrator Grace Lodge: \"Brer Rabbit Again\", \"Brer Rabbit Book\", and \"Brer Rabbit's a Rascal\". In 1962 many of her books were among the first to be published by Armada Books in paperback, making them more affordable to children.\n\nAfter 1963 Blyton's output was generally confined to short stories and books intended for very young readers, such as \"Learn to Count with Noddy\" and \"Learn to Tell Time with Noddy\" in 1965, and \"Stories for Bedtime\" and the Sunshine Picture Story Book collection in 1966. Her declining health and a falling off in readership among older children have been put forward as the principal reasons for this change in trend. Blyton published her last book in the Noddy series, \"Noddy and the Aeroplane\", in February 1964. In May the following year she published \"Mixed Bag\", a song book with music written by her nephew Carey, and in August she released her last full-length books, \"The Man Who Stopped to Help\" and \"The Boy Who Came Back\".\n\nBlyton cemented her reputation as a children's writer when in 1926 she took over the editing of \"Sunny Stories\", a magazine that typically included the re-telling of legends, myths, stories and other articles for children. That same year she was given her own column in \"Teachers' World\", entitled \"From my Window\". Three years later she began contributing a weekly page in the magazine, in which she published letters from her fox terrier dog Bobs. They proved to be so popular that in 1933 they were published in book form as \"Letters from Bobs\", and sold ten thousand copies in the first week. Her most popular feature was \"Round the Year with Enid Blyton\", which consisted of forty-eight articles covering aspects of natural history such as weather, pond life, how to plant a school garden and how to make a bird table. Among Blyton's other nature projects was her monthly \"Country Letter\" feature that appeared in \"The Nature Lover\" magazine in 1935.\n\n\"Sunny Stories\" was renamed \"Enid Blyton's Sunny Stories\" in January 1937, and served as a vehicle for the serialisation of Blyton's books. Her first Naughty Amelia Jane story, about an anti-heroine based on a doll owned by her daughter Gillian, was published in the magazine. Blyton stopped contributing in 1952, and it closed down the following year, shortly before the appearance of the new fortnightly \"Enid Blyton Magazine\" written entirely by Blyton. The first edition appeared on 18 March 1953, and the magazine ran until September 1959.\n\nNoddy made his first appearance in the \"Sunday Graphic\" in 1949, the same year as Blyton's first daily Noddy strip for the London \"Evening Standard\". It was illustrated by van der Beek until his death in 1953.\n\nBlyton worked in a wide range of fictional genres, from fairy tales to animal, nature, detective, mystery, and circus stories, but she often \"blurred the boundaries\" in her books, and encompassed a range of genres even in her short stories. In a 1958 article published in \"The Author\", she wrote that there were a \"dozen or more different types of stories for children\", and she had tried them all, but her favourites were those with a family at their centre.\n\nIn a letter to the psychologist Peter McKellar, Blyton describes her writing technique:\nIn another letter to McKellar she describes how in just five days she wrote the 60,000-word book \"The River of Adventure\", the eighth in her Adventure Series, by listening to what she referred to as her \"under-mind\", which she contrasted with her \"upper conscious mind\". Blyton was unwilling to conduct any research or planning before beginning work on a new book, which coupled with the lack of variety in her life according to Druce almost inevitably presented the danger that she might unconsciously, and clearly did, plagiarise the books she had read, including her own. Gillian has recalled that her mother \"never knew where her stories came from\", but that she used to talk about them \"coming from her 'mind's eye\", as did William Wordsworth and Charles Dickens. Blyton had \"thought it was made up of every experience she'd ever had, everything she's seen or heard or read, much of which had long disappeared from her conscious memory\" but never knew the direction her stories would take. Blyton further explained in her biography that \"If I tried to think out or invent the whole book, I could not do it. For one thing, it would bore me and for another, it would lack the 'verve' and the extraordinary touches and surprising ideas that flood out from my imagination.\"\n\nBlyton's daily routine varied little over the years. She usually began writing soon after breakfast, with her portable typewriter on her knee and her favourite red Moroccan shawl nearby; she believed that the colour red acted as a \"mental stimulus\" for her. Stopping only for a short lunch break she continued writing until five o'clock, by which time she would usually have produced 6,000–10,000 words.\n\nA 2000 article in \"The Malay Mail\" considers Blyton's children to have \"lived in a world shaped by the realities of post-war austerity\", enjoying freedom without the political correctness of today, which serves modern readers of Blyton's novels with a form of escapism. Brandon Robshaw of \"The Independent\" refers to the Blyton universe as \"crammed with colour and character\", \"self-contained and internally consistent\", noting that Blyton exemplifies a strong mistrust of adults and figures of authority in her works, creating a world in which children govern. Gillian noted that in her mother's adventure, detective and school stories for older children, \"the hook is the strong storyline with plenty of cliffhangers, a trick she acquired from her years of writing serialised stories for children's magazines. There is always a strong moral framework in which bravery and loyalty are (eventually) rewarded\". Blyton herself wrote that \"my love of children is the whole foundation of all my work\".\n\nVictor Watson, Assistant Director of Research at Homerton College, Cambridge, believes that Blyton's works reveal an \"essential longing and potential associated with childhood\", and notes how the opening pages of \"The Mountain of Adventure\" present a \"deeply appealing ideal of childhood\". He argues that Blyton's work differs from that of many other authors in its approach, describing the narrative of The Famous Five series for instance as \"like a powerful spotlight, it seeks to illuminate, to explain, to demystify. It takes its readers on a roller-coaster story in which the darkness is always banished; everything puzzling, arbitrary, evocative is either dismissed or explained\". Watson further notes how Blyton often used minimalist visual descriptions and introduced a few careless phrases such as \"gleamed enchantingly\" to appeal to her young readers.\n\nFrom the mid-1950s rumours began to circulate that Blyton had not written all the books attributed to her, a charge she found particularly distressing. She published an appeal in her magazine asking children to let her know if they heard such stories and, after one mother informed her that she had attended a parents' meeting at her daughter's school during which a young librarian had repeated the allegation, Blyton decided in 1955 to begin legal proceedings. The librarian was eventually forced to make a public apology in open court early the following year, but the rumours that Blyton operated \"a 'company' of ghost writers\" persisted, as some found it difficult to believe that one woman working alone could produce such a volume of work.\n\nBlyton felt a responsibility to provide her readers with a positive moral framework, and she encouraged them to support worthy causes. Her view, expressed in a 1957 article, was that children should help animals and other children rather than adults:\nBlyton and the members of the children's clubs she promoted via her magazines raised a great deal of money for various charities; according to Blyton, membership of her clubs meant \"working for others, for no reward\". The largest of the clubs she was involved with was the Busy Bees, the junior section of the People's Dispensary for Sick Animals, which Blyton had actively supported since 1933. The club had been set up by Maria Dickin in 1934, and after Blyton publicised its existence in the \"Enid Blyton Magazine\" it attracted 100,000 members in three years. Such was Blyton's popularity among children that after she became Queen Bee in 1952 more than 20,000 additional members were recruited in her first year in office. The Enid Blyton Magazine Club was formed in 1953. Its primary objective was to raise funds to help those children with cerebral palsy who attended a centre in Cheyne Walk, in Chelsea, London, by furnishing an on-site hostel among other things.\n\nThe Famous Five series gathered such a following that readers asked Blyton if they might form a fan club. She agreed, on condition that it serve a useful purpose, and suggested that it could raise funds for the Shaftesbury Society Babies' Home in Beaconsfield, on whose committee she had served since 1948. The club was established in 1952, and provided funds for equipping a Famous Five Ward at the home, a paddling pool, sun room, summer house, playground, birthday and Christmas celebrations, and visits to the pantomime. By the late 1950s Blyton's clubs had a membership of 500,000, and raised £35,000 in the six years of the \"Enid Blyton Magazine\"'s run.\n\nBy 1974 the Famous Five Club had a membership of 220,000, and was growing at the rate of 6,000 new members a year. The Beaconsfield home it was set up to support closed in 1967, but the club continued to raise funds for other paediatric charities, including an Enid Blyton bed at Great Ormond Street Hospital and a mini-bus for disabled children at Stoke Mandeville Hospital.\n\nBlyton capitalised upon her commercial success as an author by negotiating agreements with jigsaw puzzle and games manufacturers from the late 1940s onwards; by the early 1960s some 146 different companies were involved in merchandising Noddy alone. In 1948 Bestime released four jigsaw puzzles featuring her characters, and the first Enid Blyton board game appeared, \"Journey Through Fairyland\", created by BGL. The first card game, Faraway Tree, appeared from Pepys in 1950. In 1954 Bestime released the first four jigsaw puzzles of the Secret Seven, and the following year a Secret Seven card game appeared.\n\nBestime released the Little Noddy Car Game in 1953 and the Little Noddy Leap Frog Game in 1955, and in 1956 American manufacturer Parker Brothers released Little Noddy's Taxi Game, a board game which features Noddy driving about town, picking up various characters. Bestime released its Plywood Noddy Jigsaws series in 1957 and a Noddy jigsaw series featuring cards appeared from 1963, with illustrations by Robert Lee. Arrow Games became the chief producer of Noddy jigsaws in the late 1970s and early 1980s. Whitman manufactured four new Secret Seven jigsaw puzzles in 1975, and produced four new Malory Towers ones two years later. In 1979 the company released a Famous Five adventure board game, Famous Five Kirrin Island Treasure. Stephen Thraves wrote eight Famous Five adventure game books, published by Hodder & Stoughton in the 1980s. The first adventure game book of the series, \"The Wreckers' Tower Game\", was published in October 1984.\n\nOn 28 August 1924 Blyton married Major Hugh Alexander Pollock, DSO (1888–1971) at Bromley Register Office, without inviting her family. They married shortly after he divorced from his first wife, with whom he had two sons. Pollock was editor of the book department in the publishing firm of George Newnes, which became her regular publisher. It was he who requested that Blyton write a book about animals, \"The Zoo Book\", which was completed in the month before they married. They initially lived in a flat in Chelsea before moving to Elfin Cottage in Beckenham in 1926, and then to Old Thatch in Bourne End (called Peterswood in her books) in 1929. Blyton's first daughter Gillian, was born on 15 July 1931, and after a miscarriage in 1934, she gave birth to a second daughter, Imogen, on 27 October 1935.\n\nIn 1938 Blyton and her family moved to a house in Beaconsfield, which was named Green Hedges by Blyton's readers following a competition in her magazine. By the mid-1930s, Pollock – possibly due to the trauma he had suffered during the First World War being revived through his meetings as a publisher with Winston Churchill – withdrew increasingly from public life and became a secret alcoholic. With the outbreak of the Second World War, he became involved in the Home Guard. Pollock met again Ida Crowe, a 19 years younger writer whom he had met years ago, and he offered her to join him as secretary in his posting to a Home Guard training centre at Denbies, a Gothic mansion in Surrey belonging to Lord Ashcombe, and they entered into a romantic relationship. Blyton's marriage to Pollock became troubled for years, and according to Crowe's memoir, Blyton began a series of affairs, including a lesbian relationship with one of the children's nannies. In 1941 Blyton met Kenneth Fraser Darrell Waters, a London surgeon with whom she began a serious affair. Pollock discovered the liaison, and threatened to initiate divorce proceedings against Blyton. Fearing that exposure of her adultery would ruin her public image, it was ultimately agreed that Blyton would instead file for divorce against Pollock. According to Crowe's memoir, Blyton promised that if he admitted to infidelity she would allow him parental access to their daughters; but after the divorce he was forbidden to contact them, and Blyton ensured he was subsequently unable to find work in publishing. Pollock, having married Crowe on 26 October 1943, eventually resumed his heavy drinking and was forced to petition for bankruptcy in 1950.\n\nBlyton and Darrell Waters married at the City of Westminster Register Office on 20 October 1943. She changed the surname of her daughters to Darrell Waters and publicly embraced her new role as a happily married and devoted doctor's wife. After discovering she was pregnant in the spring of 1945, Blyton miscarried five months later, following a fall from a ladder. The baby would have been Darrell Waters's first child and it would also have been the son for which both of them longed.\n\nHer love of tennis included playing naked, with nude tennis \"a common practice in those days among the more louche members of the middle classes\"\n\nBlyton's health began to deteriorate in 1957, when during a round of golf she started to complain of feeling faint and breathless, and by 1960 she was displaying signs of dementia. Her agent George Greenfield recalled that it was \"unthinkable\" for the \"most famous and successful of children's authors with her enormous energy and computer-like memory\" to be losing her mind and suffering from what is now known as Alzheimer's disease in her mid-sixties. Blyton's situation was worsened by her husband's declining health throughout the 1960s; he suffered from severe arthritis in his neck and hips, deafness, and became increasingly ill-tempered and erratic until his death on 15 September 1967.\n\nThe story of Blyton's life was dramatised in a BBC film entitled \"Enid\", which aired in the United Kingdom on BBC Four on 16 November 2009. Helena Bonham Carter, who played the title role, described Blyton as \"a complete workaholic, an achievement junkie and an extremely canny businesswoman\" who \"knew how to brand herself, right down to the famous signature\".\n\nDuring the months following her husband's death Blyton became increasingly ill, and moved into a nursing home three months before her death. She died at the Greenways Nursing Home, Hampstead, North London, on 28 November 1968, aged 71. A memorial service was held at St James's Church, Piccadilly, and she was cremated at Golders Green Crematorium, where her ashes remain. Blyton's home, Green Hedges, was auctioned on 26 May 1971 and demolished in 1973; the site is now occupied by houses and a street named Blyton Close. An English Heritage blue plaque commemorates Blyton at Hook Road in Chessington, where she lived from 1920 to 1924. In 2014 a plaque recording her time as a Beaconsfield resident from 1938 until her death in 1968 was unveiled in the town hall gardens, next to small iron figures of Noddy and Big Ears.\n\nSince her death and the publication of her daughter Imogen's 1989 autobiography, \"A Childhood at Green Hedges\", Blyton has emerged as an emotionally immature, unstable and often malicious figure. Imogen considered her mother to be \"arrogant, insecure, pretentious, very skilled at putting difficult or unpleasant things out of her mind, and without a trace of maternal instinct. As a child, I viewed her as a rather strict authority. As an adult I pitied her.\" Blyton's eldest daughter Gillian remembered her rather differently however, as \"a fair and loving mother, and a fascinating companion\".\n\nThe Enid Blyton Trust for Children was established in 1982 with Imogen as its first chairman, and in 1985 it established the National Library for the Handicapped Child. \"Enid Blyton's Adventure Magazine\" began publication in September 1985, and on 14 October 1992 the BBC began publishing \"Noddy Magazine\" and released the Noddy CD-Rom in October 1996.\n\nThe first Enid Blyton Day was held at Rickmansworth on 6 March 1993, and in October 1996 the Enid Blyton award, The Enid, was given to those who have made outstanding contributions towards children. The Enid Blyton Society was formed in early 1995, to provide \"a focal point for collectors and enthusiasts of Enid Blyton\" through its thrice-annual \"Enid Blyton Society Journal\", its annual Enid Blyton Day, and its website. On 16 December 1996 Channel 4 broadcast a documentary about Blyton, \"Secret Lives\". To celebrate her centenary in 1997 exhibitions were put on at the London Toy & Model Museum (now closed), Hereford and Worcester County Museum and Bromley Library, and on 9 September the Royal Mail issued centenary stamps.\n\nThe London-based entertainment and retail company Trocadero plc purchased Blyton's Darrell Waters Ltd in 1995 for £14.6 million and established a subsidiary, Enid Blyton Ltd, to handle all intellectual properties, character brands and media in Blyton's works. The group changed its name to Chorion in 1998, but after financial difficulties in 2012 sold its assets. Hachette UK acquired from Chorion world rights in the Blyton estate in March 2013, including The Famous Five series but excluding the rights to Noddy, which had been sold to DreamWorks Classics (formerly Classic Media, now a subsidiary of DreamWorks Animation) in 2012.\n\nBlyton's granddaughter, Sophie Smallwood, wrote a new Noddy book to celebrate the character's 60th birthday, 46 years after the last book was published; \"Noddy and the Farmyard Muddle\" (2009) was illustrated by Robert Tyndall. In February 2011, the manuscript of a previously unknown Blyton novel, \"Mr Tumpy's Caravan\", was discovered by the archivist at Seven Stories, National Centre for Children's Books in a collection of papers belonging to Blyton's daughter Gillian, purchased by Seven Stories in 2010 following her death. It was initially thought to belong to a comic strip collection of the same name published in 1949, but it appears to be unrelated and is believed to be something written in the 1930s, which had been rejected by a publisher.\n\nIn a 1982 survey of 10,000 eleven-year-old children Blyton was voted their most popular writer. She is the world's fourth most-translated author, behind Agatha Christie, Jules Verne and William Shakespeare with her books being translated into 90 languages. From 2000 to 2010, Blyton was listed as a Top Ten author, selling almost 8 million copies (worth £31.2 million) in the UK alone. In 2003 \"The Magic Faraway Tree\" was voted 66 in the BBC's Big Read. In the 2008 Costa Book Awards, Blyton was voted Britain's best-loved author. Her books continue to be very popular among children in Commonwealth nations such as India, Pakistan, Sri Lanka, Singapore, Malta, New Zealand, and Australia, and around the world. They have also seen a surge of popularity in China, where they are \"big with every generation\". In March 2004 Chorion and the Chinese publisher Foreign Language Teaching and Research Press negotiated an agreement over the Noddy franchise, which included bringing the character to an animated series on television, with a potential audience of a further 95 million children under the age of five. Chorion spent around £10 million digitising Noddy, and as of 2002 had made television agreements with at least 11 countries worldwide.\n\nNovelists influenced by Blyton include the crime writer Denise Danks, whose fictional detective Georgina Powers is based on George from the Famous Five. Peter Hunt's \"A Step off the Path\" (1985) is also influenced by the Famous Five, and the St. Clare's and Malory Towers series provided the inspiration for Jacqueline Wilson's \"Double Act\" (1996) and Adèle Geras's Egerton Hall trilogy (1990–92) respectively.\n\nBlyton's range of plots and settings has been described as limited and continually recycled. Responding to claims that her moral views were \"dependably predictable\", Blyton commented that \"most of you could write down perfectly correctly all the things that I believe in and stand for – you have found them in my books, and a writer's books are always a faithful reflection of himself\". Many of her books were critically assessed by teachers and librarians, deemed unfit for children to read, and removed from syllabuses and public libraries.\n\nFrom the 1930s to the 1950s the BBC operated a \"de facto\" ban on dramatising Blyton's books for radio, considering her to be a \"second-rater\" whose work was without literary merit. The children's literary critic Margery Fisher likened Blyton's books to \"slow poison\", and Jean E. Sutcliffe of the BBC's schools broadcast department wrote of Blyton's ability to churn out \"mediocre material\", noting that \"her capacity to do so amounts to genius ... anyone else would have died of boredom long ago\". Michael Rosen, Children's Laureate from 2007 until 2009, wrote that \"I find myself flinching at occasional bursts of snobbery and the assumed level of privilege of the children and families in the books.\" The children's author Anne Fine presented an overview of the concerns about Blyton's work and responses to them on BBC Radio 4 in November 2008, in which she noted the \"drip, drip, drip of disapproval\" associated with the books. Blyton's response to her critics was that she was uninterested in the views of anyone over the age of 12, claiming that half the attacks on her work were motivated by jealousy and the rest came from \"stupid people who don't know what they're talking about because they've never read any of my books\".\n\nAlthough Blyton's works have been banned from more public libraries than those of any other author, there is no evidence that the popularity of her books ever suffered, and by 1990 she was still described as being very widely read. Although some criticised her in the 1950s for the volume of work she produced, Blyton astutely capitalised on being considered a more \"savoury\" English alternative to what was seen by contemporaries as an invasion by American culture in the form of Disney and comics.\n\nSome librarians felt that Blyton's restricted use of language, a conscious product of her teaching background, was prejudicial to an appreciation of more literary qualities. In a scathing article published in \"Encounter\" in 1958, the journalist Colin Welch remarked that it was \"hard to see how a diet of Miss Blyton could help with the 11-plus or even with the Cambridge English Tripos\", but reserved his harshest criticism for Blyton's Noddy, describing him as an \"unnaturally priggish ... sanctimonious ... witless, spiritless, snivelling, sneaking doll.\"\n\nThe author Nicholas Tucker notes that it was common to see Blyton cited as people's favourite or least favourite author according to their age, and argues that her books create an \"encapsulated world for young readers that simply dissolves with age, leaving behind only memories of excitement and strong identification\". Fred Inglis considers Blyton's books to be technically easy to read, but to also be \"emotionally and cognitively easy\". He mentions that the psychologist Michael Woods believed that Blyton was different from many other older authors writing for children in that she seemed untroubled by presenting them with a world that differed from reality. Woods surmised that Blyton \"was a child, she thought as a child, and wrote as a child ... the basic feeling is essentially pre-adolescent ... Enid Blyton has no moral dilemmas ... Inevitably Enid Blyton was labelled by rumour a child-hater. If true, such a fact should come as no surprise to us, for as a child herself all other children can be nothing but rivals for her.\" Inglis argues though that Blyton was clearly devoted to children and put an enormous amount of energy into her work, with a powerful belief in \"representing the crude moral diagrams and garish fantasies of a readership\". Blyton's daughter Imogen has stated that she \"loved a relationship with children through her books\", but real children were an intrusion, and there was no room for intruders in the world that Blyton occupied through her writing.\n\nAccusations of racism in Blyton's books were first made by Lena Jeger in a \"Guardian\" article published in 1966, in which she was critical of Blyton's \"The Little Black Doll\", published a few months earlier. Sambo, the black doll of the title, is hated by his owner and the other toys owing to his \"ugly black face\", and runs away. A shower of rain washes his face clean, after which he is welcomed back home with his now pink face. Jamaica Kincaid also considers the Noddy books to be \"deeply racist\" because of the blonde children and the black golliwogs. In Blyton's 1944 novel \"The Island of Adventure\", a black servant named Jo-Jo is very intelligent, but is particularly cruel to the children.\n\nAccusations of xenophobia were also made. As George Greenfield observed, \"Enid was very much part of that between-the-wars middle class which believed that foreigners were untrustworthy or funny or sometimes both\". The publisher Macmillan conducted an internal assessment of Blyton's \"The Mystery That Never Was\", submitted to them at the height of her fame in 1960. The review was carried out by the author and books editor Phyllis Hartnoll, in whose view \"There is a faint but unattractive touch of old-fashioned xenophobia in the author's attitude to the thieves; they are 'foreign' ... and this seems to be regarded as sufficient to explain their criminality.\" Macmillan rejected the manuscript, but it was published by William Collins in 1961, and then again in 1965 and 1983.\n\nBlyton's depictions of boys and girls are considered by many critics to be sexist. In a \"Guardian\" article published in 2005 Lucy Mangan proposed that The Famous Five series depicts a power struggle between Julian, Dick and George (Georgina), in which the female characters either act like boys or are talked down to, as when Dick lectures George: \"it's really time you gave up thinking you're as good as a boy\".\n\nTo address criticisms levelled at Blyton's work some later editions have been altered to reflect more liberal attitudes towards issues such as race, gender and the treatment of children; modern reprints of the Noddy series substitute teddy bears or goblins for golliwogs, for instance. The golliwogs who steal Noddy's car and dump him naked in the Dark Wood in \"Here Comes Noddy Again\" are replaced by goblins in the 1986 revision, who strip Noddy only of his shoes and hat and return at the end of the story to apologise.\n\n\"The Faraway Tree\"'s Dame Slap, who made regular use of corporal punishment, was changed to Dame Snap who no longer did so, and the names of Dick and Fanny in the same series were changed to Rick and Frannie. Characters in the Malory Towers and St. Clare's series are no longer spanked or threatened with a spanking, but are instead scolded. References to George's short hair making her look like a boy were removed in revisions to \"Five on a Hike Together\", reflecting the idea that girls need not have long hair to be considered feminine or normal. Anne of \"The Famous Five\" stating that boys cannot wear pretty dresses or like dolls was removed.\n\nIn 2010 Hodder, the publisher of the Famous Five series, announced its intention to update the language used in the books, of which it sold more than half a million copies a year. The changes, which Hodder described as \"subtle\", mainly affect the dialogue rather than the narrative. For instance, \"school tunic\" becomes \"uniform\", \"mother and father\" becomes \"mum and dad\", \"bathing\" is replaced by \"swimming\", and \"jersey\" by \"jumper\". Some commentators see the changes as necessary to encourage modern readers, whereas others regard them as unnecessary and patronising. In 2016 Hodder's parent company Hachette announced that they would abandon the revisions as, based on feedback, they had not been a success.\n\nIn 1954 Blyton adapted Noddy for the stage, producing the \"Noddy in Toyland\" pantomime in just two or three weeks. The production was staged at the 2660-seat Stoll Theatre in Kingsway, London at Christmas. Its popularity resulted in the show running during the Christmas season for five or six years. Blyton was delighted with its reception by children in the audience, and attended the theatre three or four times a week. TV adaptations of Noddy since 1954 include one in the 1970s narrated by Richard Briers. In 1955 a stage play based on the Famous Five was produced, and in January 1997 the King's Head Theatre embarked on a six-month tour of the UK with \"The Famous Five Musical\", to commemorate Blyton's centenary. On 21 November 1998 \"The Secret Seven Save the World\" was first performed at the Sherman Theatre in Cardiff.\n\nThere have also been several film and television adaptations of the Famous Five: by the Children's Film Foundation in 1957 and 1964, Southern Television in 1978–79, and Zenith Productions in 1995–97. The series was also adapted for the German film \"Fünf Freunde\", directed by Mike Marzuk and released in 2011.\n\nThe Comic Strip, a group of British comedians, produced two extreme parodies of the Famous Five for Channel 4 television: \"Five Go Mad in Dorset\", broadcast in 1982, and \"Five Go Mad on Mescalin\", broadcast the following year. A third in the series, \"Five Go to Rehab\", was broadcast on Sky in 2012.\n\nIn October 2014 it was announced that a deal had been signed with publishers Hachette for \"The Faraway Tree\" series to be adapted into a live action film by director Sam Mendes’ production company. Marlene Johnson, head of children’s books at Hachette, said: \"Enid Blyton was a passionate advocate of children’s storytelling, and The Magic Faraway Tree is a fantastic example of her creative imagination.\"\n\nSeven Stories, the National Centre for Children's Books in Newcastle upon Tyne, holds the largest public collection of Blyton's papers and typescripts. The Seven Stories collection contains a significant number of Blyton's typescripts, including the previously unpublished novel, \"Mr Tumpy's Caravan\", as well as personal papers and diaries. The purchase of the material in 2010 was made possible by special funding from the Heritage Lottery Fund, the MLA/V&A Purchase Grant Fund, and two private donations.\n\n\nNotes\nCitations\nBibliography\n\n\n"}
{"id": "10259", "url": "https://en.wikipedia.org/wiki?curid=10259", "title": "Epipaleolithic", "text": "Epipaleolithic\n\nEpipaleolithic is a term used for the \"final Upper Palaeolithic industries occurring at the end of the final glaciation which appear to merge technologically into the Mesolithic\". The period is generally dated from  BP to  BP, having emerged from the Palaeolithic era.\n\nThe term is sometimes used as a synonym of \"Mesolithic\". When a distinction is made, \"Epipaleolithic\" stresses the continuity with the Upper Paleolithic and Mesolithic as we understand it today, whilst \"Protoneolithic\" stresses a subsequent transition to the Neolithic.\nAlfonso Moure says in this respect:\nSome authors reserve the term \"Mesolithic\" for the cultures of Europe, where the extinction of the megafauna had a great impact on the Paleolithic populations at the end of the Ice Age, from  BCE until the advent of the Neolithic (Sauveterrian, Tardenoisian, Maglemosian, etc.).\n\nEpipalaeolithic hunter-gatherers, generally nomadic, made relatively advanced tools from small flint or obsidian blades, known as microliths, that were hafted in wooden implements.\n\nThe Epipaleolithic is best understood when discussing the southern Levant, as the period is well documented due to good preservation at the site.\nThe most prevalent animal food sources in the Levant during this period were:\n\nThese were most likely the main food sources throughout the Pre-Pottery Neolithic A (PPNA) period. Of these animals, it is likely that only the equids were migrational.\n"}
{"id": "10263", "url": "https://en.wikipedia.org/wiki?curid=10263", "title": "Executive (government)", "text": "Executive (government)\n\nThe executive is the organ exercising authority in and holding responsibility for the governance of a state. The executive executes and enforces law.\n\nIn political systems based on the principle of separation of powers, authority is distributed among several branches (executive, legislative, judicial) — an attempt to prevent the concentration of power in the hands of a small group of people. In such a system, the executive does not pass laws (the role of the legislature) or interpret them (the role of the judiciary). Instead, the executive enforces the law as written by the legislature and interpreted by the judiciary. The executive can be the source of certain types of law, such as a decree or executive order. Executive bureaucracies are commonly the source of regulations.\n\nIn the Westminster political system, the principle of separation of powers is not as entrenched. Members of the executive, called ministers, are also members of the legislature, and hence play an important part in both the writing and enforcing of law.\n\nIn this context, the executive consists of a leader(s) of an office or multiple offices. Specifically, the top leadership roles of the executive branch may include:\n\nIn a presidential system, the leader of the executive is both the \"head of state and head of government\". In a parliamentary system, a cabinet minister responsible to the legislature is the head of government, while the head of state is usually a largely ceremonial monarch or president.\n\n"}
{"id": "10264", "url": "https://en.wikipedia.org/wiki?curid=10264", "title": "Enrico Fermi", "text": "Enrico Fermi\n\nEnrico Fermi (; 29 September 1901 – 28 November 1954) was an Italian physicist and the creator of the world's first nuclear reactor, the Chicago Pile-1. He has been called the \"architect of the nuclear age\" and the \"architect of the atomic bomb\". He was one of the very few physicists in history to excel both theoretically and experimentally. Fermi held several patents related to the use of nuclear power, and was awarded the 1938 Nobel Prize in Physics for his work on induced radioactivity by neutron bombardment and the discovery of transuranic elements. He made significant contributions to the development of quantum theory, nuclear and particle physics, and statistical mechanics.\n\nFermi's first major contribution was to statistical mechanics. After Wolfgang Pauli announced his exclusion principle in 1925, Fermi followed with a paper in which he applied the principle to an ideal gas, employing a statistical formulation now known as Fermi–Dirac statistics. Today, particles that obey the exclusion principle are called \"fermions\". Later Pauli postulated the existence of an uncharged invisible particle emitted along with an electron during beta decay, to satisfy the law of conservation of energy. Fermi took up this idea, developing a model that incorporated the postulated particle, which he named the \"neutrino\". His theory, later referred to as Fermi's interaction and still later as weak interaction, described one of the four fundamental forces of nature. Through experiments inducing radioactivity with recently discovered neutrons, Fermi discovered that slow neutrons were more easily captured than fast ones, and developed the Fermi age equation to describe this. After bombarding thorium and uranium with slow neutrons, he concluded that he had created new elements; although he was awarded the Nobel Prize for this discovery, the new elements were subsequently revealed to be fission products.\n\nFermi left Italy in 1938 to escape new Italian Racial Laws that affected his Jewish wife Laura Capon. He emigrated to the United States where he worked on the Manhattan Project during World War II. Fermi led the team that designed and built Chicago Pile-1, which went critical on 2 December 1942, demonstrating the first artificial self-sustaining nuclear chain reaction. He was on hand when the X-10 Graphite Reactor at Oak Ridge, Tennessee, went critical in 1943, and when the B Reactor at the Hanford Site did so the next year. At Los Alamos he headed F Division, part of which worked on Edward Teller's thermonuclear \"Super\" bomb. He was present at the Trinity test on 16 July 1945, where he used his Fermi method to estimate the bomb's yield.\n\nAfter the war, Fermi served under J. Robert Oppenheimer on the General Advisory Committee, which advised the Atomic Energy Commission on nuclear matters and policy. Following the detonation of the first Soviet fission bomb in August 1949, he strongly opposed the development of a hydrogen bomb on both moral and technical grounds. He was among the scientists who testified on Oppenheimer's behalf at the 1954 hearing that resulted in the denial of the latter's security clearance. Fermi did important work in particle physics, especially related to pions and muons, and he speculated that cosmic rays arose through material being accelerated by magnetic fields in interstellar space. Many awards, concepts, and institutions are named after Fermi, including the Enrico Fermi Award, the Enrico Fermi Institute, the Fermi National Accelerator Laboratory, the Fermi Gamma-ray Space Telescope, the Enrico Fermi Nuclear Generating Station, and the synthetic element fermium, making him one of 16 scientists who have elements named after them.\n\nEnrico Fermi was born in Rome, Italy, on 29 September 1901. He was the third child of Alberto Fermi, a division head (\"\") in the Ministry of Railways, and Ida de Gattis, an elementary school teacher. His only sister, Maria, was two years older than he was, and his brother Giulio was a year older. After the two boys were sent to a rural community to be wet nursed, Enrico rejoined his family in Rome when he was two and a half. Although he was baptised a Roman Catholic in accordance with his grandparents' wishes, his family was not particularly religious; Enrico was an agnostic throughout his adult life. As a young boy he shared the same interests as his brother Giulio, building electric motors and playing with electrical and mechanical toys. Giulio died during the administration of an anesthetic for an operation on a throat abscess in 1915. Maria died in an airplane crash near Milano in 1959.\n\nOne of Fermi's first sources for his study of physics was a book he found at the local market at \"Campo de' Fiori\" in Rome. Published in 1840, the 900-page \"Elementorum physicae mathematicae\", was written in Latin by Jesuit Father Andrea Caraffa, a professor at the Collegio Romano. It covered mathematics, classical mechanics, astronomy, optics, and acoustics, insofar as these disciplines were understood when the book was written. Fermi befriended another scientifically inclined student, Enrico Persico, and together the two worked on scientific projects such as building gyroscopes and trying to accurately measure the acceleration of Earth's gravity. Fermi's interest in physics was further encouraged by his father's colleague Adolfo Amidei, who gave him several books on physics and mathematics, which he read and assimilated quickly.\n\nFermi graduated from high school in July 1918 and, at Amidei's urging, applied to the \"Scuola Normale Superiore\" in Pisa. Having lost one son, his parents were reluctant to let him move away from home for four years while attending it, but in the end they acquiesced. The school provided free lodging for students, but candidates had to take a difficult entrance exam that included an essay. The given theme was \"Specific characteristics of Sounds\". The 17-year-old Fermi chose to derive and solve the partial differential equation for a vibrating rod, applying Fourier analysis in the solution. The examiner, Professor Giulio Pittarelli from the Sapienza University of Rome, interviewed Fermi and praised him, saying that he would become an outstanding physicist in the future. Fermi achieved first place in the classification of the entrance exam.\n\nDuring his years at the \"Scuola Normale Superiore\", Fermi teamed up with a fellow student named Franco Rasetti with whom he would indulge in light-hearted pranks and who would later become Fermi's close friend and collaborator. In Pisa, Fermi was advised by the director of the physics laboratory, Luigi Puccianti, who acknowledged that there was little that he could teach Fermi, and frequently asked Fermi to teach him something instead. Fermi's knowledge of quantum physics reached such a high level that Puccianti asked him to organize seminars on the topic. During this time Fermi learned tensor calculus, a mathematical technique invented by Gregorio Ricci and Tullio Levi-Civita that was needed to demonstrate the principles of general relativity. Fermi initially chose mathematics as his major, but soon switched to physics. He remained largely self-taught, studying general relativity, quantum mechanics, and atomic physics.\n\nIn September 1920, Fermi was admitted to the Physics department. Since there were only three students in the department—Fermi, Rasetti, and Nello Carrara—Puccianti let them freely use the laboratory for whatever purposes they chose. Fermi decided that they should research X-ray crystallography, and the three worked to produce a Laue photograph—an X-ray photograph of a crystal. During 1921, his third year at the university, Fermi published his first scientific works in the Italian journal \"Nuovo Cimento\". The first was entitled \"On the dynamics of a rigid system of electrical charges in translational motion\" ('). A sign of things to come was that the mass was expressed as a tensor—a mathematical construct commonly used to describe something moving and changing in three-dimensional space. In classical mechanics, mass is a scalar quantity, but in relativity it changes with velocity. The second paper was \"On the electrostatics of a uniform gravitational field of electromagnetic charges and on the weight of electromagnetic charges\" ('). Using general relativity, Fermi showed that a charge has a weight equal to U/c, where U was the electrostatic energy of the system, and c is the speed of light.\n\nThe first paper seemed to point out a contradiction between the electrodynamic theory and the relativistic one concerning the calculation of the electromagnetic masses, as the former predicted a value of 4/3 U/c. Fermi addressed this the next year in a paper \"Concerning a contradiction between electrodynamic and the relativistic theory of electromagnetic mass\" in which he showed that the apparent contradiction was a consequence of relativity. This paper was sufficiently well-regarded that it was translated into German and published in the German scientific journal \"Physikalische Zeitschrift\" in 1922. That year, Fermi submitted his article \"On the phenomena occurring near a world line\" (\"\") to the Italian journal \"I Rendiconti dell'Accademia dei Lincei\". In this article he examined the Principle of Equivalence, and introduced the so-called \"Fermi coordinates\". He proved that on a world line close to the time line, space behaves as if it were a Euclidean space.\nFermi submitted his thesis, \"A theorem on probability and some of its applications\" (\"\"), to the \"Scuola Normale Superiore\" in July 1922, and received his laurea at the unusually young age of 20. The thesis was on X-ray diffraction images. Theoretical physics was not yet considered a discipline in Italy, and the only thesis that would have been accepted was one on experimental physics. For this reason, Italian physicists were slow in embracing the new ideas like relativity coming from Germany. Since Fermi was quite at home in the lab doing experimental work, this did not pose insurmountable problems for him.\n\nWhile writing the appendix for the Italian edition of the book \"Fundamentals of Einstein Relativity\" by August Kopff in 1923, Fermi was the first to point out that hidden inside the famous Einstein equation () was an enormous amount of nuclear potential energy to be exploited. \"It does not seem possible, at least in the near future\", he wrote, \"to find a way to release these dreadful amounts of energy—which is all to the good because the first effect of an explosion of such a dreadful amount of energy would be to smash into smithereens the physicist who had the misfortune to find a way to do it.\"\n\nIn 1924 Fermi was initiated to the Freemasonry in the Masonic Lodge \"Adriano Lemmi\" of the Grand Orient of Italy.\n\nFermi decided to travel abroad, and spent a semester studying under Max Born at the University of Göttingen, where he met Werner Heisenberg and Pascual Jordan. Fermi then studied in Leiden with Paul Ehrenfest from September to December 1924 on a fellowship from the Rockefeller Foundation obtained through the intercession of the mathematician Vito Volterra. Here Fermi met Hendrik Lorentz and Albert Einstein, and became good friends with Samuel Goudsmit and Jan Tinbergen. From January 1925 to late 1926, Fermi taught mathematical physics and theoretical mechanics at the University of Florence, where he teamed up with Rasetti to conduct a series of experiments on the effects of magnetic fields on mercury vapour. He also participated in seminars at the Sapienza University of Rome, giving lectures on quantum mechanics and solid state physics. While giving lectures of new quantum mechanics based on remarkable accuracy of predictions of Schrödinger equation, the Italian physicist would often say, \"It has no business to fit so well!\"\n\nAfter Wolfgang Pauli announced his exclusion principle in 1925, Fermi responded with a paper \"On the quantisation of the perfect monoatomic gas\" (\"), in which he applied the exclusion principle to an ideal gas. The paper was especially notable for Fermi's statistical formulation, which describes the distribution of particles in systems of many identical particles that obey the exclusion principle. This was independently developed soon after by the British physicist Paul Dirac, who also showed how it was related to the Bose–Einstein statistics. Accordingly, it is now known as Fermi–Dirac statistics. Following Dirac, particles that obey the exclusion principle are today called \"fermions\", while those that do not are called \"bosons\".\n\nProfessorships in Italy were granted by competition (\") for a vacant chair, the applicants being rated on their publications by a committee of professors. Fermi applied for a chair of mathematical physics at the University of Cagliari on Sardinia, but was narrowly passed over in favour of Giovanni Giorgi. In 1926, at the age of 24, he applied for a professorship at the Sapienza University of Rome. This was a new chair, one of the first three in theoretical physics in Italy, that had been created by the Minister of Education at the urging of Professor Orso Mario Corbino, who was the University's professor of experimental physics, the Director of the Institute of Physics, and a member of Benito Mussolini's cabinet. Corbino, who also chaired the selection committee, hoped that the new chair would raise the standard and reputation of physics in Italy. The committee chose Fermi ahead of Enrico Persico and Aldo Pontremoli, and Corbino helped Fermi recruit his team, which was soon joined by notable students such as Edoardo Amaldi, Bruno Pontecorvo, Ettore Majorana and Emilio Segrè, and by Franco Rasetti, whom Fermi had appointed as his assistant. They were soon nicknamed the \"Via Panisperna boys\" after the street where the Institute of Physics was located.\n\nFermi married Laura Capon, a science student at the University, on 19 July 1928. They had two children: Nella, born in January 1931, and Giulio, born in February 1936. On 18 March 1929, Fermi was appointed a member of the Royal Academy of Italy by Mussolini, and on 27 April he joined the Fascist Party. He later opposed Fascism when the 1938 racial laws were promulgated by Mussolini in order to bring Italian Fascism ideologically closer to German National Socialism. These laws threatened Laura, who was Jewish, and put many of Fermi's research assistants out of work.\n\nDuring their time in Rome, Fermi and his group made important contributions to many practical and theoretical aspects of physics. In 1928, he published his \"Introduction to Atomic Physics\" (\"\"), which provided Italian university students with an up-to-date and accessible text. Fermi also conducted public lectures and wrote popular articles for scientists and teachers in order to spread knowledge of the new physics as widely as possible. Part of his teaching method was to gather his colleagues and graduate students together at the end of the day and go over a problem, often from his own research. A sign of success was that foreign students now began to come to Italy. The most notable of these was the German physicist Hans Bethe, who came to Rome as a Rockefeller Foundation fellow, and collaborated with Fermi on a 1932 paper \"On the Interaction between Two Electrons\" ().\n\nAt this time, physicists were puzzled by beta decay, in which an electron was emitted from the atomic nucleus. To satisfy the law of conservation of energy, Pauli postulated the existence of an invisible particle with no charge and little or no mass that was also emitted at the same time. Fermi took up this idea, which he developed in a tentative paper in 1933, and then a longer paper the next year that incorporated the postulated particle, which Fermi called a \"neutrino\". His theory, later referred to as Fermi's interaction, and still later as the theory of the weak interaction, described one of the four fundamental forces of nature. The neutrino was detected after his death, and his interaction theory showed why it was so difficult to detect. When he submitted his paper to the British journal \"Nature\", that journal's editor turned it down because it contained speculations which were \"too remote from physical reality to be of interest to readers\". Thus Fermi saw the theory published in Italian and German before it was published in English.\n\nIn the introduction to the 1968 English translation, physicist Fred L. Wilson noted that:\n\nIn January 1934, Irène Joliot-Curie and Frédéric Joliot announced that they had bombarded elements with alpha particles and induced radioactivity in them. By March, Fermi's assistant Gian-Carlo Wick had provided a theoretical explanation using Fermi's theory of beta decay. Fermi decided to switch to experimental physics, using the neutron, which James Chadwick had discovered in 1932. In March 1934, Fermi wanted to see if he could induce radioactivity with Rasetti's polonium-beryllium neutron source. Neutrons had no electric charge, and so would not be deflected by the positively charged nucleus. This meant that they needed much less energy to penetrate the nucleus than charged particles, and so would not require a particle accelerator, which the Via Panisperna boys did not have.\nFermi had the idea to resort to replacing the polonium-beryllium neutron source with a radon-beryllium one, which he created by filling a glass bulb with beryllium powder, evacuating the air, and then adding 50 mCi of radon gas, supplied by Giulio Cesare Trabacchi. This created a much stronger neutron source, the effectiveness of which declined with the 3.8-day half-life of radon. He knew that this source would also emit gamma rays, but, on the basis of his theory, he believed that this would not affect the results of the experiment. He started by bombarding platinum, an element with a high atomic number that was readily available, without success. He turned to aluminium, which emitted an alpha particle and produced sodium, which then decayed into magnesium by beta particle emission. He tried lead, without success, and then fluorine in the form of calcium fluoride, which emitted an alpha particle and produced nitrogen, decaying into oxygen by beta particle emission. In all, he induced radioactivity in 22 different elements. Fermi rapidly reported the discovery of neutron-induced radioactivity in the Italian journal \"La Ricerca Scientifica\" on 25 March 1934.\n\nThe natural radioactivity of thorium and uranium made it hard to determine what was happening when these elements were bombarded with neutrons but, after correctly eliminating the presence of elements lighter than uranium but heavier than lead, Fermi concluded that they had created new elements, which he called hesperium and ausonium. The chemist Ida Noddack criticised this work, suggesting that some of the experiments could have produced lighter elements than lead rather than new, heavier elements. Her suggestion was not taken seriously at the time because her team had not carried out any experiments with uranium, and its claim to have discovered masurium (technetium) was disputed. At that time, fission was thought to be improbable if not impossible on theoretical grounds. While physicists expected elements with higher atomic numbers to form from neutron bombardment of lighter elements, nobody expected neutrons to have enough energy to split a heavier atom into two light element fragments in the manner that Noddack suggested.\nThe Via Panisperna boys also noticed some unexplained effects. The experiment seemed to work better on a wooden table than a marble table top. Fermi remembered that Joliot-Curie and Chadwick had noted that paraffin wax was effective at slowing neutrons, so he decided to try that. When neutrons were passed through paraffin wax, they induced a hundred times as much radioactivity in silver compared with when it was bombarded without the paraffin. Fermi guessed that this was due to the hydrogen atoms in the paraffin. Those in wood similarly explained the difference between the wooden and the marble table tops. This was confirmed by repeating the effect with water. He concluded that collisions with hydrogen atoms slowed the neutrons. The lower the atomic number of the nucleus it collides with, the more energy a neutron loses per collision, and therefore the less collisions that are required to slow a neutron down by a given amount. Fermi realised that this induced more radioactivity because slow neutrons were more easily captured than fast ones. He developed a diffusion equation to describe this, which became known as the Fermi age equation.\n\nIn 1938 Fermi received the Nobel Prize in Physics at the age of 37 for his \"demonstrations of the existence of new radioactive elements produced by neutron irradiation, and for his related discovery of nuclear reactions brought about by slow neutrons\". After Fermi received the prize in Stockholm, he did not return home to Italy, but rather continued on to New York City with his family in December 1938, where they applied for permanent residency. The decision to move to America and become U.S. citizens was primarily a result of the racial laws in Italy.\n\nFermi arrived in New York City on 2 January 1939. He was immediately offered posts at five different universities, and accepted a post at Columbia University, where he had already given summer lectures in 1936. He received the news that in December 1938, the German chemists Otto Hahn and Fritz Strassmann had detected the element barium after bombarding uranium with neutrons, which Lise Meitner and her nephew Otto Frisch correctly interpreted as the result of nuclear fission. Frisch confirmed this experimentally on 13 January 1939. The news of Meitner and Frisch's interpretation of Hahn and Strassmann's discovery crossed the Atlantic with Niels Bohr, who was to lecture at Princeton University. Isidor Isaac Rabi and Willis Lamb, two Columbia University physicists working at Princeton, found out about it and carried it back to Columbia. Rabi said he told Enrico Fermi, but Fermi later gave the credit to Lamb:\nNoddack was proven right after all. Fermi had dismissed the possibility of fission on the basis of his calculations, but he had not taken into account the binding energy that would appear when a nuclide with an odd number of neutrons absorbed an extra neutron. For Fermi, the news came as a profound embarrassment, as the transuranic elements that he had partly been awarded the Nobel Prize for discovering had not been transuranic elements at all, but fission products. He added a footnote to this effect to his Nobel Prize acceptance speech.\nThe scientists at Columbia decided that they should try to detect the energy released in the nuclear fission of uranium when bombarded by neutrons. On 25 January 1939, in the basement of Pupin Hall at Columbia, an experimental team including Fermi conducted the first nuclear fission experiment in the United States. The other members of the team were Herbert L. Anderson, Eugene T. Booth, John R. Dunning, G. Norris Glasoe, and Francis G. Slack. The next day, the Fifth Washington Conference on Theoretical Physics began in Washington, D.C. under the joint auspices of George Washington University and the Carnegie Institution of Washington. There, the news on nuclear fission was spread even further, which fostered many more experimental demonstrations.\n\nFrench scientists Hans von Halban, Lew Kowarski, and Frédéric Joliot-Curie had demonstrated that uranium bombarded by neutrons emitted more neutrons than it absorbed, which implies chain reaction may be a possibility. Fermi and Anderson did so too a few weeks later. Leó Szilárd obtained of uranium oxide from Canadian radium producer Eldorado Gold Mines Limited, allowing Fermi and Anderson to conduct experiments with fission on a much larger scale. Fermi and Szilárd collaborated on a design of a device to achieve a self-sustaining nuclear reaction—a nuclear reactor. Due to the rate of absorption of neutrons by the hydrogen in water, it was unlikely that a self-sustaining reaction could be achieved with natural uranium and water as a neutron moderator. Fermi suggested, based on his work with neutrons, that the reaction could be achieved with uranium oxide blocks and graphite as a moderator instead of water. This would reduce the neutron capture rate, and in theory make a self-sustaining chain reaction possible. Szilárd came up with a workable design: a pile of uranium oxide blocks interspersed with graphite bricks. Szilárd, Anderson, and Fermi published a paper on \"Neutron Production in Uranium\". But their work habits and personalities were different, and Fermi had trouble working with Szilárd.\n\nFermi was among the first to warn military leaders about the potential impact of nuclear energy, giving a lecture on the subject at the Navy Department on 18 March 1939. The response fell short of what he had hoped for, although the Navy agreed to provide $1,500 towards further research at Columbia. Later that year, Szilárd, Eugene Wigner, and Edward Teller sent the famous letter signed by Einstein to U.S. President Roosevelt, warning that Nazi Germany was likely to build an atomic bomb. In response, Roosevelt formed the Advisory Committee on Uranium to investigate the matter.\nThe Advisory Committee on Uranium provided money for Fermi to buy graphite, and he built a pile of graphite bricks on the seventh floor of the Pupin Hall laboratory. By August 1941, he had six tons of uranium oxide and thirty tons of graphite, which he used to build a still larger pile in Schermerhorn Hall at Columbia.\n\nThe S-1 Section of the Office of Scientific Research and Development, as the Advisory Committee on Uranium was now known, met on 18 December 1941, with the U.S. now engaged in World War II, making its work urgent. Most of the effort sponsored by the Committee had been directed at producing enriched uranium, but Committee member Arthur Compton determined that a feasible alternative was plutonium, which could be mass-produced in nuclear reactors by the end of 1944. He decided to concentrate the plutonium work at the University of Chicago. Fermi reluctantly moved, and his team became part of the new Metallurgical Laboratory there.\n\nThe possible results of a self-sustaining nuclear reaction were unknown, so it seemed inadvisable to build the first nuclear reactor on the U. of C. campus in the middle of the city. Compton found a location in Argonne Woods Forest Preserve, about from Chicago. Stone & Webster was contracted to develop the site, but the work was halted by an industrial dispute. Fermi then persuaded Compton that he could build the reactor in the squash court under the stands of the U of C's Stagg Field. Construction of the pile began on 6 November 1942, and Chicago Pile-1 went critical on 2 December. The shape of the pile was intended to be roughly spherical, but as work proceeded Fermi calculated that criticality could be achieved without finishing the entire pile as planned.\n\nThis experiment was a landmark in the quest for energy, and it was typical of Fermi's approach. Every step was carefully planned, every calculation meticulously done. When the first self-sustained nuclear chain reaction was achieved, Compton made a coded phone call to James B. Conant, the chairman of the National Defense Research Committee.\nTo continue the research where it would not pose a public health hazard, the reactor was disassembled and moved to the Argonne Woods site. There Fermi directed experiments on nuclear reactions, revelling in the opportunities provided by the reactor's abundant production of free neutrons. The laboratory soon branched out from physics and engineering into using the reactor for biological and medical research. Initially, Argonne was run by Fermi as part of the University of Chicago, but it became a separate entity with Fermi as its director in May 1944.\n\nWhen the air-cooled X-10 Graphite Reactor at Oak Ridge went critical on 4 November 1943, Fermi was on hand just in case something went wrong. The technicians woke him early so that he could see it happen. Getting X-10 operational was another milestone in the plutonium project. It provided data on reactor design, training for DuPont staff in reactor operation, and produced the first small quantities of reactor-bred plutonium. Fermi became an American citizen in July 1944, the earliest date the law allowed.\n\nIn September 1944, Fermi inserted the first uranium fuel slug into the B Reactor at the Hanford Site, the production reactor designed to breed plutonium in large quantities. Like X-10, it had been designed by Fermi's team at the Metallurgical Laboratory, and built by DuPont, but it was much larger, and was water-cooled. Over the next few days, 838 tubes were loaded, and the reactor went critical. Shortly after midnight on 27 September, the operators began to withdraw the control rods to initiate production. At first all appeared to be well, but around 03:00, the power level started to drop and by 06:30 the reactor had shut down completely. The Army and DuPont turned to Fermi's team for answers. The cooling water was investigated to see if there was a leak or contamination. The next day the reactor suddenly started up again, only to shut down once more a few hours later. The problem was traced to neutron poisoning from xenon-135, a fission product with a half-life of 9.2 hours. Fortunately, DuPont had deviated from the Metallurgical Laboratory's original design in which the reactor had 1,500 tubes arranged in a circle, and had added 504 tubes to fill in the corners. The scientists had originally considered this over-engineering a waste of time and money, but Fermi realized that by loading all 2,004 tubes, the reactor could reach the required power level and efficiently produce plutonium.\nIn mid-1944, Robert Oppenheimer persuaded Fermi to join his Project Y at Los Alamos, New Mexico. Arriving in September, Fermi was appointed an associate director of the laboratory, with broad responsibility for nuclear and theoretical physics, and was placed in charge of F Division, which was named after him. F Division had four branches: F-1 Super and General Theory under Teller, which investigated the \"Super\" (thermonuclear) bomb; F-2 Water Boiler under L. D. P. King, which looked after the \"water boiler\" aqueous homogeneous research reactor; F-3 Super Experimentation under Egon Bretscher; and F-4 Fission Studies under Anderson. Fermi observed the Trinity test on 16 July 1945, and conducted an experiment to estimate the bomb's yield by dropping strips of paper into the blast wave. He paced off how far they were blown by the explosion, and calculated the yield as ten kilotons of TNT; the actual yield was about 18.6 kilotons.\n\nAlong with Oppenheimer, Compton, and Ernest Lawrence, Fermi was part of the scientific panel that advised the Interim Committee on target selection. The panel agreed with the committee that atomic bombs would be used without warning against an industrial target. Like others at the Los Alamos Laboratory, Fermi found out about the atomic bombings of Hiroshima and Nagasaki from the public address system in the technical area. Fermi did not believe that atomic bombs would deter nations from starting wars, nor did he think that the time was ripe for world government. He therefore did not join the Association of Los Alamos Scientists.\n\nFermi became the Charles H. Swift Distinguished Professor of Physics at the University of Chicago on 1 July 1945, although he did not depart the Los Alamos Laboratory with his family until 31 December 1945. He was elected a member of the U.S. National Academy of Sciences in 1945. The Metallurgical Laboratory became the Argonne National Laboratory on 1 July 1946, the first of the national laboratories established by the Manhattan Project. The short distance between Chicago and Argonne allowed Fermi to work at both places. At Argonne he continued experimental physics, investigating neutron scattering with Leona Marshall. He also discussed theoretical physics with Maria Mayer, helping her develop insights into spin–orbit coupling that would lead to her receiving the Nobel Prize.\n\nThe Manhattan Project was replaced by the Atomic Energy Commission (AEC) on 1 January 1947. Fermi served on the AEC General Advisory Committee, an influential scientific committee chaired by Robert Oppenheimer. He also liked to spend a few weeks of each year at the Los Alamos National Laboratory, where he collaborated with Nicholas Metropolis, and with John von Neumann on Rayleigh–Taylor instability, the science of what occurs at the border between two fluids of different densities.\nFollowing the detonation of the first Soviet fission bomb in August 1949, Fermi, along with Isidor Rabi, wrote a strongly worded report for the committee, opposing the development of a hydrogen bomb on moral and technical grounds. Nonetheless, Fermi continued to participate in work on the hydrogen bomb at Los Alamos as a consultant. Along with Stanislaw Ulam, he calculated that not only would the amount of tritium needed for Teller's model of a thermonuclear weapon be prohibitive, but a fusion reaction could still not be assured to propagate even with this large quantity of tritium. Fermi was among the scientists who testified on Oppenheimer's behalf at the Oppenheimer security hearing in 1954 that resulted in denial of Oppenheimer's security clearance.\n\nIn his later years, Fermi continued teaching at the University of Chicago. His PhD students in the post-war period included Owen Chamberlain, Geoffrey Chew, Jerome Friedman, Marvin Goldberger, Tsung-Dao Lee, Arthur Rosenfeld and Sam Treiman. Jack Steinberger was a graduate student. Fermi conducted important research in particle physics, especially related to pions and muons. He made the first predictions of pion-nucleon resonance, relying on statistical methods, since he reasoned that exact answers were not required when the theory was wrong anyway. In a paper co-authored with Chen Ning Yang, he speculated that pions might actually be composite particles. The idea was elaborated by Shoichi Sakata. It has since been supplanted by the quark model, in which the pion is made up of quarks, which completed Fermi's model, and vindicated his approach.\n\nFermi wrote a paper \"On the Origin of Cosmic Radiation\" in which he proposed that cosmic rays arose through material being accelerated by magnetic fields in interstellar space, which led to a difference of opinion with Teller. Fermi examined the issues surrounding magnetic fields in the arms of a spiral galaxy. He mused about what is now referred to as the \"Fermi paradox\": the contradiction between the presumed probability of the existence of extraterrestrial life and the fact that contact has not been made.\n\nToward the end of his life, Fermi questioned his faith in society at large to make wise choices about nuclear technology. He said:\n\nFermi died at age 53 of stomach cancer in his home in Chicago, and was interred at Oak Woods Cemetery.\n\nFermi received numerous awards in recognition of his achievements, including the Matteucci Medal in 1926, the Nobel Prize for Physics in 1938, the Hughes Medal in 1942, the Franklin Medal in 1947, and the Rumford Prize in 1953. He was awarded the Medal for Merit in 1946 for his contribution to the Manhattan Project. Fermi was elected a Foreign Member of the Royal Society (FRS) in 1950. The Basilica of Santa Croce, Florence, known as the \"Temple of Italian Glories\" for its many graves of artists, scientists and prominent figures in Italian history, has a plaque commemorating Fermi. In 1999, \"Time\" named Fermi on its list of the top 100 persons of the twentieth century. Fermi was widely regarded as an unusual case of a 20th-century physicist who excelled both theoretically and experimentally. The historian of physics, C. P. Snow, wrote that \"if Fermi had been born a few years earlier, one could well imagine him discovering Rutherford's atomic nucleus, and then developing Bohr's theory of the hydrogen atom. If this sounds like hyperbole, anything about Fermi is likely to sound like hyperbole\".\n\nFermi was known as an inspiring teacher, and was noted for his attention to detail, simplicity, and careful preparation of his lectures. Later, his lecture notes were transcribed into books. His papers and notebooks are today in the University of Chicago. Victor Weisskopf noted how Fermi \"always managed to find the simplest and most direct approach, with the minimum of complication and sophistication.\" Fermi's ability and success stemmed as much from his appraisal of the art of the possible, as from his innate skill and intelligence. He disliked complicated theories, and while he had great mathematical ability, he would never use it when the job could be done much more simply. He was famous for getting quick and accurate answers to problems that would stump other people. Later on, his method of getting approximate and quick answers through back-of-the-envelope calculations became informally known as the \"Fermi method\", and is widely taught.\n\nFermi was fond of pointing out that Alessandro Volta, working in his laboratory, could have had no idea where the study of electricity would lead. Fermi is generally remembered for his work on nuclear power and nuclear weapons, especially the creation of the first nuclear reactor, and the development of the first atomic and hydrogen bombs. His scientific work has stood the test of time. This includes his theory of beta decay, his work with non-linear systems, his discovery of the effects of slow neutrons, his study of pion-nucleon collisions, and his Fermi–Dirac statistics. His speculation that a pion was not a fundamental particle pointed the way towards the study of quarks and leptons.\n\nMany things have been named in Fermi's honour. These include the Fermilab particle accelerator and physics lab in Batavia, Illinois, which was renamed in his honour in 1974, and the Fermi Gamma-ray Space Telescope, which was named after him in 2008, in recognition of his work on cosmic rays. Three nuclear reactor installations have been named after him: the Fermi 1 and Fermi 2 nuclear power plants in Newport, Michigan, the Enrico Fermi Nuclear Power Plant at Trino Vercellese in Italy, and the RA-1 Enrico Fermi research reactor in Argentina. A synthetic element isolated from the debris of the 1952 Ivy Mike nuclear test was named fermium, in honour of Fermi's contributions to the scientific community. This makes him one of 16 scientists who have elements named after them.\n\nSince 1956, the United States Atomic Energy Commission has named its highest honour, the Fermi Award, after him. Recipients of the award include well-known scientists like Otto Hahn, Robert Oppenheimer, Edward Teller and Hans Bethe.\n\n\nFor a full list of his papers, see pages 75–78 in ref.\n\n\n\n"}
{"id": "10267", "url": "https://en.wikipedia.org/wiki?curid=10267", "title": "Entente", "text": "Entente\n\nEntente, meaning a diplomatic \"understanding\", may refer to a number of agreements:\n\n\n\n"}
{"id": "10268", "url": "https://en.wikipedia.org/wiki?curid=10268", "title": "Editor war", "text": "Editor war\n\nEditor war is the common name for the rivalry between users of the Emacs and vi (Vim) text editors. The rivalry has become a lasting part of hacker culture and the free software community.\n\nThe Emacs vs vi debate was one of the original \"holy wars\" conducted on Usenet groups, with many flame wars fought between those insisting that their editor of choice is the of editing perfection, and insulting the other, since at least 1985. Related battles have been fought over operating systems, programming languages, version control systems, and even source code indent style. Notably, unlike other wars (e.g., UNIX vs ITS vs VMS, C vs Pascal vs Fortran), the editor war has yet to be resolved with a clear winner, and the hacker community remains split roughly 50/50.\n\nThe most important differences between vi and Emacs are presented in the following table:\n\n\nFrequently, at some point in the discussion, someone will point out that ed is the \"standard text editor\".\n\nThe Church of Emacs, formed by Emacs and the GNU Project's creator Richard Stallman, is a parody religion. While it refers to vi as the \"editor of the beast\" (vi-vi-vi being 6-6-6 in Roman numerals), it does not oppose the use of vi; rather, it calls proprietary software anathema. (\"Using a free version of vi is not a sin but a penance.\") The Church of Emacs has its own newsgroup, alt.religion.emacs, that has posts purporting to support this belief system.\n\nStallman has referred to himself as St IGNU−cius, a saint in the Church of Emacs.\n\nSupporters of vi have created an opposing Cult of vi, argued by the more hardline Emacs users to be an attempt to \"ape their betters\".\n\nRegarding vi's modal nature (a point of extreme frustration for new users) some Emacs users joke that vi has two modes – \"beep repeatedly\" and \"break everything\". vi users enjoy joking that Emacs's key-sequences induce carpal tunnel syndrome, or mentioning one of many satirical expansions of the acronym EMACS, such as \"Escape Meta Alt Control Shift\" (a jab at Emacs's reliance on modifier keys). or \"Eight Megabytes And Constantly Swapping\" (in a time when that was a great amount of memory) or \"EMACS Makes Any Computer Slow\" (a recursive acronym like those Stallman uses) or \"Eventually Munches All Computer Storage\", in reference to Emacs's high system resource requirements. GNU EMACS has been expanded to \"Generally Not Used, Except by Middle-Aged Computer Scientists\" referencing its most ardent fans, and its declining usage among younger programmers compared to more graphically-oriented editors such as TextMate or Sublime Text. The Emacs distribution includes the full list.\n\nAs a poke at Emacs' creeping featurism, vi advocates have been known to describe Emacs as \"a great operating system, lacking only a decent editor\". Emacs advocates have been known to respond that the editor is actually very good, but the operating system could use improvement (referring to Emacs' famous lack of concurrency.)\n\nA game among UNIX users, either to test the depth of an Emacs user's understanding of the editor or to poke fun at the complexity of Emacs, involved predicting what would happen if a user held down a modifier key (such as Control or Alt) and typed their own name. A similar \"game\" was reportedly played among users of the old TECO editor, in which lay the roots of Emacs.\n\nDue to the unintuitive character sequence to exit vi (\":q!\"), hackers joke that there is a proposed method of creating a pseudorandom character sequence by having a user unfamiliar with vi seated in front of an open editor and asking them to exit the program.\n\nIn the past, many small editors modeled after or derived from vi flourished. This was due to the importance of conserving memory with the comparatively minuscule amount available at the time. As computers have become more powerful, many vi clones, Vim in particular, have grown in size and code complexity. These vi variants of today, as with the old lightweight Emacs variants, tend to have many of the perceived benefits and drawbacks of the opposing side. For example, Vim without any extensions requires about ten times the disk space required by vi, and recent versions of Vim can have more extensions and run slower than Emacs. In \"The Art of Unix Programming\", Eric S. Raymond called Vim's supposed light weight when compared with Emacs \"a shared myth.\" Moreover, with the large amounts of RAM in modern computers, both Emacs and vi are lightweight compared to large integrated development environments such as Eclipse, which tend to draw derision from Emacs and vi users alike.\n\nTim O'Reilly said, in 1999, that O'Reilly Media's tutorial on vi sells twice as many copies as that on Emacs (but noted that Emacs came with a free manual). Many programmers use either Emacs and vi or their various offshoots, including Linus Torvalds who uses MicroEMACS. Also in 1999, vi creator Bill Joy said that vi was \"written for a world that doesn't exist anymore\" and stated that Emacs was written on much more capable machines with faster displays so they could have \"funny commands with the screen shimmering and all that, and meanwhile, I'm sitting at home in sort of World War II surplus housing at Berkeley with a modem and a terminal that can just barely get the cursor off the bottom line.\"\n\nIn addition to Emacs and vi workalikes, pico and its free and open source clone nano and other text editors such as ne often have their own third-party advocates in the editor wars, though not to the extent of Emacs and vi.\n\nAs of 2014, both Emacs and vi can lay claim to being among the longest-lived application programs of all time, as well as being the two most commonly used text editors on Linux and Unix. Many operating systems, especially Linux and BSD derivatives, bundle multiple text editors with the operating system to cater to user demand. For example, a default installation of macOS contains Emacs, ed, nano, TextEdit, and Vim.\n\n\n"}
{"id": "10270", "url": "https://en.wikipedia.org/wiki?curid=10270", "title": "Orthodox Church organization", "text": "Orthodox Church organization\n\nThis article covers the organization of the Eastern Orthodox Churches rather than the doctrines, traditions, practices, or other aspects of Eastern Orthodoxy. Like the Catholic Church, the Orthodox Church claims to be the One, Holy, Catholic and Apostolic Church.\n\nThe term Western Orthodoxy is sometimes used to denominate what is technically a Vicariate within the Antiochian Orthodox and the Russian Orthodox Churches and thus a part of the Eastern Orthodox Church as that term is defined here. The term \"Western Orthodox Church\" is disfavored by members of that Vicariate.\n\nIn the 5th century, Oriental Orthodoxy separated from Chalcedonian Christianity (and is therefore separate from both the Eastern Orthodox and Roman Catholic churches), well before the 11th century Great Schism. It should not be confused with Eastern Orthodoxy.\n\nThe Orthodox Church is a communion comprising the fifteen separate autocephalous hierarchical churches that recognize each other as \"canonical\" Orthodox Christian churches. Each constituent church is self-governing; its highest-ranking bishop (a patriarch, a metropolitan or an archbishop) reports to no higher earthly authority. Each regional church is composed of constituent eparchies (or dioceses) ruled by bishops. Some autocephalous churches have given an eparchy or group of eparchies varying degrees of autonomy (self-government). Such autonomous churches maintain varying levels of dependence on their mother church, usually defined in a Tomos or other document of autonomy. In many cases, autonomous churches are almost completely self-governing, with the mother church retaining only the right to appoint the highest-ranking bishop (an archbishop or metropolitan) of the autonomous church.\n\nNormal governance is enacted through a synod of bishops within each church. In case of issues that go beyond the scope of a single church, multiple self-governing churches send representatives to a wider synod, sometimes wide enough to be called an Orthodox \"ecumenical council\". Such councils are deemed to have authority superior to that of any autocephalous church or its ranking bishop.\n\nThe Orthodox Church is decentralised, having no central authority, earthly head or a single Bishop in a leadership role. Thus, the Orthodox Church uses a synodical system canonically, which is significantly different from the hierarchically organised Catholic Church that follows the doctrine of papal supremacy. References to the Ecumenical Patriarch of Constantinople as a leader are an erroneous interpretation of his title (\"first among equals\"). His title is of honor rather than authority and in fact the Ecumenical Patriarch has no real authority over Churches other than the Constantinopolitan. His unique role often sees the Ecumenical Patriarch referred to as the \"spiritual leader\" of the Orthodox Church in some sources, though this is not an official title of the patriarch nor is it usually used in scholarly sources on the patriarchate.\n\nThe autocephalous churches are in full communion with each other, so any priest of any of those churches may lawfully minister to any member of any of them, and no member of any is excluded from any form of worship in any of the others, including reception of the Eucharist.\n\nIn the early Middle Ages, the One Holy Catholic and Apostolic Church was ruled by five patriarchs: the bishops of Rome, Constantinople, Alexandria, Antioch, and Jerusalem; these were collectively referred to as the Pentarchy. Each patriarch had jurisdiction over bishops in a specified geographic region. This continued until 927, when the autonomous Bulgarian Archbishopric became the first newly promoted patriarchate to join the original five.\n\nThe patriarch of Rome was \"first in place of honor\" among the five patriarchs. Disagreement about the limits of his authority was one of the causes of the Great Schism, conventionally dated to the year 1054, which split the church into the Catholic Church in the West, headed by the Bishop of Rome, and the Orthodox Church, led by the four eastern patriarchs. After the schism this honorary primacy shifted to the Patriarch of Constantinople, who had previously been accorded the second-place rank at the First Council of Constantinople.\n\nRanked in order of seniority, with the year of independence (autocephaly) given in parentheses, where applicable.\n\n\n\n\nThe four ancient patriarchates are the most senior, followed by the five junior patriarchates. Autocephalous archbishoprics follow the patriarchates in seniority, with the Church of Cyprus being the only ancient one (AD 431). In the diptychs of the Russian Orthodox Church and some of its daughter churches (e.g., the Orthodox Church in America), the ranking of the five junior patriarchal churches is different. Following the Russian Church in rank is Georgian, followed by Serbian, Romanian, and then Bulgarian Church. The ranking of the archbishoprics is the same.\n\n\n\n\n\n\n<nowiki>*</nowiki>\"Autonomy not universally recognised.\"\n\n\nThese are churches that have separated from the mainstream communion over issues of Ecumenism and Calendar reform since the 1920s. Due to what these churches perceive as being errors of modernism and ecumenism in mainstream Orthodoxy, they refrain from concelebration of the Divine Liturgy with the mainstream Orthodox, while maintaining that they remain fully within the canonical boundaries of the Church: i.e., professing Orthodox belief, retaining legitimate apostolic succession, and existing in communities with historical continuity. With the exception of the Orthodox Church of Greece (Holy Synod in Resistance), they will commune the faithful from all the canonical jurisdictions and are recognized by and in communion with the Russian Orthodox Church Outside Russia.\n\nDue in part to the re-establishment of official ties between the Russian Orthodox Church Outside Russia and the Moscow Patriarchate, the \"Orthodox Church of Greece (Holy Synod in Resistance)\" has broken ecclesial communion with ROCOR, but the converse has not happened. Where the Old Calendar Romanian and Bulgarian churches stand on the matter is as yet unclear.\n\nThe Churches in resistance are:\n\n\nThese Churches do not practice Communion with any other Orthodox jurisdictions nor do they tend to recognize each other. Yet, like the \"Churches in Resistance\" above, they consider themselves to be within the canonical boundaries of the Church: i.e., professing Orthodox belief, retaining what they believe to be legitimate apostolic succession, and existing in communities with historical continuity. Nevertheless, their relationship with all other Orthodox Churches remains unclear, as Orthodox Churches normally recognize and are recognized by others.\n\n\nThe following Churches recognize all other mainstream Orthodox Churches, but are not recognized by any of them due to various disputes:\n\n\nThe following Churches use the term \"Orthodox\" in their name and carries belief or the traditions of Eastern Orthodox church, but blend beliefs and traditions from other denominations outside of Eastern Orthodoxy:\n\n\n\n"}
{"id": "10271", "url": "https://en.wikipedia.org/wiki?curid=10271", "title": "EDT", "text": "EDT\n\nEDT may refer to:\n\n\n"}
{"id": "10272", "url": "https://en.wikipedia.org/wiki?curid=10272", "title": "Electric guitar", "text": "Electric guitar\n\nAn electric guitar is a fretted stringed instrument with a neck and body that uses a pickup to convert the vibration of its strings into electrical signals. The vibration occurs when a guitarist strums, plucks or fingerpicks the strings. It is sensed by a pickup, most commonly by a magnetic pickup that uses the principle of direct electromagnetic induction. The signal generated by an electric guitar is too weak to drive a loudspeaker, so it is plugged into a guitar amplifier before being sent to a loudspeaker, which makes a sound loud enough to hear. The output of an electric guitar is an electric signal, and the signal can easily be altered by electronic circuits to add \"color\" to the sound or change the sound. Often the signal is modified using effects such as reverb and distortion and \"overdrive\", with the growling sound of the latter being a key element of the sound of the electric guitar as it is used in blues and rock music.\n\nInvented in 1931, the amplified electric guitar was adopted by jazz guitarists, who sought to be able to do single-note guitar solos in large big band ensembles. Early proponents of the electric guitar on record included Les Paul, Lonnie Johnson, Sister Rosetta Tharpe, T-Bone Walker, and Charlie Christian. During the 1950s and 1960s, the electric guitar became the most important instrument in pop music. It has evolved into an instrument that is capable of a multitude of sounds and styles in genres ranging from pop and rock to country music, blues and jazz. It served as a major component in the development of electric blues, rock and roll, rock music, heavy metal music and many other genres of music.\n\nElectric guitar design and construction vary greatly in the shape of the body and the configuration of the neck, bridge, and pickups. Guitars may have a fixed bridge or a spring-loaded hinged bridge that lets players \"bend\" the pitch of notes or chords up or down or perform vibrato effects. The sound of a guitar can be modified by new playing techniques such as string bending, tapping, hammering on, using audio feedback, or slide guitar playing. There are several types of electric guitar, including the solid-body guitar, various types of hollow-body guitars, the six-string guitar (the most common type, usually tuned E, A, D, G, B, E, from lowest to highest strings), the seven-string guitar, which typically adds a low B string below the low E, and the twelve-string electric guitar, which has six pairs of strings.\n\nPopular music and rock groups often use the electric guitar in two roles: as a rhythm guitar, which plays the chord sequence or progression and riffs and sets the beat (as part of a rhythm section), and as a lead guitar, which is used to perform instrumental melody lines, melodic instrumental fill passages, and solos. In a small group, such as a power trio, one guitarist switches between both roles. In larger rock and metal bands, there is often a rhythm guitarist and a lead guitarist.\nMany experiments at electrically amplifying the vibrations of a string instrument were made dating back to the early part of the 20th century. Patents from the 1910s show telephone transmitters were adapted and placed inside violins and banjos to amplify the sound. Hobbyists in the 1920s used carbon button microphones attached to the bridge; however, these detected vibration from the bridge on top of the instrument, resulting in a weak signal. With numerous people experimenting with electrical instruments in the 1920s and early 1930s, there are many claimants to have been the first to invent an electric guitar.\nElectric guitars were originally designed by acoustic guitar makers and instrument manufacturers. Some of the earliest electric guitars adapted hollow-bodied acoustic instruments and used tungsten pickups. The first electrically amplified guitar was designed in 1931 by George Beauchamp, the general manager of the National Guitar Corporation, with Paul Barth, who was vice president. The maple body prototype for the one-piece cast aluminium \"frying pan\" was built by Harry Watson, factory superintendent of the National Guitar Corporation. Commercial production began in late summer of 1932 by the Ro-Pat-In Corporation (Electro-Patent-Instrument Company), in Los Angeles, a partnership of Beauchamp, Adolph Rickenbacker (originally Rickenbacher), and Paul Barth. In 1934, the company was renamed the Rickenbacker Electro Stringed Instrument Company. In that year Beauchamp applied for a United States patent for an \"Electrical Stringed Musical Instrument\" and the patent was issued in 1937.\n\nBy early-mid 1935, Electro String Instrument Corporation had achieved mainstream success with the A-22 Frying Pan, and set out to capture a new audience through its release of the \"Electro-Spanish Model B\" and the \"Electro-Spanish Ken Roberts\" which was the first full 25\" scale electric guitar produced. The Electro-Spanish Ken Roberts provided players a full 25\" scale, with 17 frets free of the fretboard. It is estimated that fewer than 50 Electro-Spanish Ken Roberts were constructed between 1933 and 1937; fewer than 10 are known to survive today.\nThe need for the amplified guitar became apparent during the big band era as orchestras increased in size, particularly when acoustic guitars had to compete with large, loud brass sections. The first electric guitars used in jazz were hollow archtop acoustic guitar bodies with electromagnetic transducers. Early electric guitar manufacturers include Rickenbacker in 1932; Dobro in 1933; National, AudioVox and Volu-tone in 1934; Vega, Epiphone (Electrophone and Electar), and Gibson in 1935 and many others by 1936.\n\nThe earliest documented performance with an electrically amplified guitar was in 1932, by Gage Brewer, a musician based in Wichita, Kansas. He had an Electric Hawaiian A-25 (frypan, lap steel) and a standard Electric Spanish from George Beauchamp of Los Angeles. Brewer publicized his new instruments in an article in the \"Wichita Beacon\" of 2 October 1932 and through performances that month. The first recordings using the electric guitar were by Hawaiian-style players, in 1933. Bob Dunn of Milton Brown's Musical Brownies introduced the electric Hawaiian guitar to Western swing with his January 1935 Decca recordings, departing almost entirely from the Hawaiian musical influence and heading towards jazz and blues. Alvino Rey was an artist who took this instrument to a wide audience in a large orchestral setting and later developed the pedal steel guitar for Gibson. An early proponent of the electric Spanish guitar was jazz guitarist George Barnes, who used the instrument in two songs recorded in Chicago on 1 March 1938, \"Sweetheart Land\" and \"It's a Low-Down Dirty Shame\". Some incorrectly attribute the first recording to Eddie Durham, but his recording with the Kansas City Five was made 15 days later. Durham introduced the instrument to a young Charlie Christian, who made the instrument famous in his brief life and would be a major influence on jazz guitarists for decades thereafter.\n\nGibson's first production electric guitar, marketed in 1936, was the ES-150 model (\"ES\" for \"Electric Spanish\", and \"150\" reflecting the $150 price of the instrument, along with matching amplifier). The ES-150 guitar featured a single-coil, hexagonally shaped \"bar\" pickup, which was designed by Walt Fuller. It became known as the \"Charlie Christian\" pickup (named for the great jazz guitarist who was among the first to perform with the ES-150 guitar). The ES-150 achieved some popularity but suffered from unequal loudness across the six strings.\nEarly proponents of the electric guitar on record include Alvino Rey (Phil Spitalney Orchestra), Les Paul (Fred Waring Orchestra), Danny Stewart (Andy Iona Orchestra), George Barnes (under many aliases), Lonnie Johnson, Floyd Smith, Big Bill Broonzy, T-Bone Walker, George Van Eps, Charlie Christian (Benny Goodman Orchestra), Tampa Red, Memphis Minnie, and Arthur Crudup.\n\nA functionally solid-body electric guitar was designed and built in 1940 by Les Paul from an Epiphone acoustic archtop. His \"log guitar\" (so called because it consisted of a simple 4x4 wood post with a neck attached to it and homemade pickups and hardware, with two detachable Epiphone hollow-body halves attached to the sides for appearance only) shares nothing in design or hardware with the solid-body Gibson Les Paul introduced in 1952. However, the feedback associated with hollow-bodied electric guitars was understood long before Paul's \"log\" was created in 1940; Gage Brewer's Ro-Pat-In of 1932 had a top so heavily reinforced that it essentially functioned as a solid-body instrument. In 1945, Richard D. Bourgerie made an electric guitar pickup and amplifier for professional guitar player George Barnes. Bourgerie worked through World War II at Howard Radio Company, making electronic equipment for the American military. Barnes showed the result to Les Paul, who then arranged for Bourgerie to have one made for him.\n\nThis table shows the layout of pitches on a standard tuning six-string guitar, which is tuned E, A, D, G, B, E, going from the lowest-pitch, thickest string to the highest - pitch, thinnest string. The table depicts a guitar fretboard as it would appear to an observer looking at a guitar that is on its side and upside-down, thus giving the table the same appearance that a guitarist would see when holding the instrument in playing position.\nZero is the nut; 5 is the fifth (tuning) fret. This table only shows up to the twelfth fret. Most electric guitars have additional frets beyond the twelfth fret which have the same layout as the 1st- 12th fret (although the notes are an octave higher in pitch). \n\nElectric guitar design and construction vary greatly in the shape of the body and the configuration of the neck, bridge, and pickups. However, some features are present on most guitars. The photo below shows the different parts of an electric guitar. The headstock (1) contains the metal machine heads (1.1), which use a worm gear for tuning. The nut (1.4)—a thin fret-like strip of metal, plastic, graphite or bone—supports the strings at the headstock end of the instrument. The frets (2.3) are thin metal strips that stop the string at the correct pitch when the player pushes a string against the fingerboard. The truss rod (1.2) is a metal rod (usually adjustable) that counters the tension of the strings to keep the neck straight. Position markers (2.2) provide the player with a reference to the playing position on the fingerboard.\n\nThe neck and fretboard (2.1) extend from the body. At the neck joint (2.4), the neck is either glued or bolted to the body. The body (3) is typically made of wood with a hard, polymerized finish. Strings vibrating in the magnetic field of the pickups (3.1, 3.2) produce an electric current in the pickup winding that passes through the tone and volume controls (3.8) to the output jack. Some guitars have piezo pickups, in addition to or instead of magnetic pickups.\n\nSome guitars have a fixed bridge (3.4). Others have a spring-loaded hinged bridge called a \"vibrato bar\", \"tremolo bar\", or \"whammy bar\", which lets players bend notes or chords up or down in pitch or perform a vibrato embellishment. A plastic pickguard on some guitars protects the body from scratches or covers the control cavity, which holds most of the wiring.\nThe degree to which the choice of woods and other materials in the solid-guitar body (3) affects the sonic character of the amplified signal is disputed. Many believe it is highly significant, while others think the difference between woods is subtle. In acoustic and archtop guitars, wood choices more clearly affect tone.\n\nWoods typically used in solid-body electric guitars include alder (brighter, but well rounded), swamp ash (similar to alder, but with more pronounced highs and lows), mahogany (dark, bassy, warm), poplar (similar to alder), and basswood (very neutral). Maple, a very bright tonewood, is also a popular body wood, but is very heavy. For this reason it is often placed as a \"cap\" on a guitar made primarily of another wood. Cheaper guitars are often made of cheaper woods, such as plywood, pine or agathis—not true hardwoods—which can affect durability and tone. Though most guitars are made of wood, any material may be used. Materials such as plastic, metal, and even cardboard have been used in some instruments.\n\nThe guitar output jack typically provides a monaural signal. Many guitars with active electronics use a jack with an extra contact normally used for stereo. These guitars use the extra contact to break the ground connection to the on-board battery to preserve battery life when the guitar is unplugged. These guitars require a mono plug to close the internal switch and connect the battery to ground. Standard guitar cables use a high-impedance 1/4-inch (6.35-mm) mono plug. These have a tip and sleeve configuration referred to as a TS phone connector. The voltage is usually around 1 to 9 millivolts.\n\nA few guitars feature stereo output, such as Rickenbacker guitars equipped with \"Rick-O-Sound\". There are a variety of ways the \"stereo\" effect may be implemented. Commonly, but not exclusively, stereo guitars route the neck and bridge pickups to separate output buses on the guitar. A stereo cable then routes each pickup to its own signal chain or amplifier. For these applications, the most popular connector is a high-impedance 1/4-inch plug with a tip, ring and sleeve configuration, also known as a TRS phone connector. Some studio instruments, notably certain Gibson Les Paul models, incorporate a low-impedance three-pin XLR connector for balanced audio. Many exotic arrangements and connectors exist that support features such as midi and hexaphonic pickups.\n\nThe bridge and tailpiece, while serving separate purposes, work closely together to affect playing style and tone. There are four basic types of bridge and tailpiece systems on electric guitars. Within these four types are many variants.\n\nA hard-tail guitar bridge anchors the strings at or directly behind the bridge and is fastened securely to the top of the instrument. These are common on carved-top guitars, such as the Gibson Les Paul and the Paul Reed Smith models, and on slab-body guitars, such as the Music Man Albert Lee and Fender guitars that are not equipped with a vibrato arm.\n\nA \"floating\" or \"trapeze\" tailpiece (similar to a violin's) fastens to the body at the base of the guitar. These appear on Rickenbackers, Gretsches, Epiphones, a wide variety of archtop guitars, particularly Jazz guitars, and the 1952 Gibson Les Paul.\n\nPictured is a \"tremolo arm\" or \"vibrato tailpiece\" style bridge and tailpiece system, often called a \"whammy bar\" or \"trem\". It uses a lever (\"vibrato arm\") attached to the bridge that can temporarily slacken or tighten the strings to alter the pitch. A player can use this to create a vibrato or a portamento effect. Early vibrato systems were often unreliable and made the guitar go out of tune easily. They also had a limited pitch range. Later Fender designs were better, but Fender held the patent on these, so other companies used older designs for many years. \n\nWith expiration of the Fender patent on the Stratocaster-style vibrato, various improvements on this type of internal, multi-spring vibrato system are now available. Floyd Rose introduced one of the first improvements on the vibrato system in many years when, in the late 1970s, he experimented with \"locking\" nuts and bridges that prevent the guitar from losing tuning, even under heavy vibrato bar use.\n\nThe fourth type of system employs string-through body anchoring. The strings pass over the bridge saddles, then through holes through the top of the guitar body to the back. The strings are typically anchored in place at the back of the guitar by metal ferrules. Many believe this design improves a guitar's sustain and timbre. \nA few examples of string-through body guitars are the Fender Telecaster Thinline, the Fender Telecaster Deluxe, the B.C. Rich IT Warlock and Mockingbird, and the Schecter Omen 6 and 7 series.\n\nCompared to an acoustic guitar, which has a hollow body, electric guitars make much less audible sound when their strings are plucked, so electric guitars are normally plugged into a guitar amplifier and speaker. When an electric guitar is played, string movement produces a signal by generating (i.e., inducing) a small electric current in the magnetic pickups, which are magnets wound with coils of very fine wire. \nThe signal passes through the tone and volume circuits to the output jack, and through a cable to an amplifier. The current induced is proportional to such factors as string density and the amount of movement over the pickups. \nBecause in most cases it is desirable to isolate coil-wound pickups from the unintended sound of internal vibration of loose coil windings, a guitar's magnetic pickups are normally embedded or \"potted\" in wax, lacquer, or epoxy to prevent the pickup from producing a microphonic effect. Because of their natural inductive qualities, all magnetic pickups tend to pick up ambient, usually unwanted electromagnetic interference or EMI. The resulting hum is particularly strong with single-coil pickups, and it is aggravated by the fact that many vintage guitars are insufficiently shielded against electromagnetic interference. The most common source is 50- or 60-Hz hum from power transmission systems (house wiring, etc.). Since nearly all amplifiers and audio equipment associated with electric guitars must be plugged in, it is a continuing technical challenge to reduce or eliminate unwanted hum.\n\nDouble-coil or \"humbucker\" pickups were invented as a way to reduce or counter the unwanted ambient hum sounds (known as 60-cycle hum). Humbuckers have two coils of opposite magnetic and electric polarity to produce a differential signal. Electromagnetic noise that hits both coils equally tries to drive the pickup signal toward positive on one coil and toward negative on the other, which cancels out the noise. The two coils are wired in phase, so their signal adds together. This high combined inductance of the two coils leads to the richer, \"fatter\" tone associated with humbucking pickups.\n\nPiezoelectric pickups use a \"sandwich\" of quartz crystal or other piezoelectric material, typically placed beneath the string saddles or nut. These devices respond to pressure changes from all vibration at these specific points.\n\nOptical pickups are a type of pickup that sense string and body vibrations using infrared LED light. These pickups are not sensitive to EMI.\n\nSome \"hybrid\" electric guitars are equipped with additional microphone, piezoelectric, optical, or other types of transducers to approximate an acoustic instrument tone and broaden the sonic palette of the instrument.\n\nElectric guitar necks vary in composition and shape. The primary metric of guitar necks is the \"scale length\", which is the vibrating length of the strings from nut to bridge. A typical Fender guitar uses a 25.5-inch scale length, while Gibson uses a 24.75-inch scale length in their \"Les Paul\". While the scale length of the Les Paul is often described as 24.75 inches, it has varied through the years by as much as a half inch.\n\nFrets are positioned proportionally to scale length—the shorter the scale length, the closer the fret spacing. Opinions vary regarding the effect of scale length on tone and feel. Popular opinion holds that longer scale length contributes to greater amplitude. Reports of playing feel are greatly complicated by the many factors involved in this perception. String gauge and design, neck construction and relief, guitar setup, playing style and other factors contribute to the subjective impression of playability or feel.\n\nNecks are described as \"bolt-on\", \"set-in\", or \"neck-through\", depending on how they attach to the body. Set-in necks are glued to the body in the factory. They are said to have a warmer tone and greater sustain. This is the traditional type of joint. Leo Fender pioneered bolt-on necks on electric guitars to facilitate easy adjustment and replacement. Neck-through instruments extend the neck the length of the instrument, so that it forms the center of the body, and are known for long sustain and for being particularly sturdy. While a set-in neck can be carefully unglued by a skilled luthier, and a bolt-on neck can simply be unscrewed, a neck-through design is difficult or even impossible to repair, depending on the damage. Historically, the bolt-on style has been more popular for ease of installation and adjustment. Since bolt-on necks can be easily removed, there is an after-market in replacement bolt-on necks from companies such as Warmoth and Mighty Mite. Some instruments—notably most Gibson models—continue to use set-in glued necks. Neck-through bodies are somewhat more common in bass guitars.\n\nMaterials for necks are selected for dimensional stability and rigidity, and some allege that they influence tone. Hardwoods are preferred, with maple, mahogany, and ash topping the list. The neck and fingerboard can be made from different materials; for example, a guitar may have a maple neck with a rosewood or ebony fingerboard. In the 1970s, designers began to use exotic man-made materials such as aircraft-grade aluminum, carbon fiber, and ebonol. Makers known for these unusual materials include John Veleno, Travis Bean, Geoff Gould, and Alembic.\n\nAside from possible engineering advantages, some feel that in relation to the rising cost of rare tonewoods, man-made materials may be economically preferable and more ecologically sensitive. However, wood remains popular in production instruments, though sometimes in conjunction with new materials. Vigier guitars, for example, use a wooden neck reinforced by embedding a light, carbon fiber rod in place of the usual heavier steel bar or adjustable steel truss rod. After-market necks made entirely from carbon fiber fit existing bolt-on instruments. Few, if any, extensive formal investigations have been widely published that confirm or refute claims over the effects of different woods or materials on electric guitar sound.\n\nSeveral neck shapes appear on guitars, including shapes known as C necks, U necks, and V necks. These refer to the cross-sectional shape of the neck (especially near the nut). Several sizes of fret wire are available, with traditional players often preferring thin frets, and metal shredders liking thick frets. Thin frets are considered better for playing chords, while thick frets allow lead guitarists to bend notes with less effort.\n\nAn electric guitar with a folding neck called the \"Foldaxe\" was designed and built for Chet Atkins by Roger C. Field. Steinberger guitars developed a line of exotic, carbon fiber instruments without headstocks, with tuning done on the bridge instead.\n\nFingerboards vary as much as necks. The fingerboard surface usually has a cross-sectional radius that is optimized to accommodate finger movement for different playing techniques. Fingerboard radius typically ranges from nearly flat (a very large radius) to radically arched (a small radius). The vintage Fender Telecaster, for example, has a typical small radius of approximately 7.25 inches. Some manufacturers have experimented with fret profile and material, fret layout, number of frets, and modifications of the fingerboard surface for various reasons. Some innovations were intended to improve playability by ergonomic means, such as Warmoth Guitars' compound radius fingerboard. Scalloped fingerboards added enhanced microtonality during fast legato runs. Fanned frets intend to provide each string with an optimal playing tension and enhanced musicality. Some guitars have no frets—and others, like the Gittler guitar, have no neck in the traditional sense.\n\nWhile an acoustic guitar's sound depends largely on the vibration of the guitar's body and the air inside it, the sound of an electric guitar depends largely on the signal from the pickups. The signal can be \"shaped\" on its path to the amplifier via a range of effect devices or circuits that modify the tone and characteristics of the signal. Amplifiers and speakers also add coloration to the final sound.\n\nElectric guitars usually have one to four magnetic pickups. Identical pickups produce different tones depending on how near they are to the neck or bridge. Bridge pickups produce a bright or trebly timbre, and neck pickups are warmer or more bassy. The type of pickup also affects tone. Dual-coil pickups sound warm, thick, perhaps even muddy; single-coil pickups sound clear, bright, perhaps even biting. Guitars don't require a uniform pickup type: a common mixture is the \"fat Strat\" arrangement of one dual-coil at the bridge position and single coils in the middle and neck positions, known as HSS (humbucker/single/single). Some guitars have piezoelectric pickup in addition to electromagnetic pickups. Piezo pickups produce a more acoustic sound. The piezo runs through a built-in equalizer (EQ) to improve similitude and control tone. A blend knob controls the mix between electromagnetic and piezoelectric sounds.\n\nWhere there is more than one pickup, a pickup selector switch is usually present. These typically select or combine the outputs of two or more pickups, so that two-pickup guitars have three-way switches, and three-pickup guitars have five-way switches (a Gibson Les Paul three-pickup Black Beauty has a three-position toggle switch which configures bridge, bridge and middle [switch in middle position] and neck pickups). Further circuitry sometimes combines pickups in different ways. For instance, phase switching places one pickup out of phase with the other(s), leading to a \"honky\", \"nasal\", or \"funky\" sound. Individual pickups can also have their timbre altered by switches, typically coil tap switches that effectively short-circuit some of a dual-coil pickup's windings to produce a tone similar to a single-coil pickup (usually done with push-pull volume knobs).\n\nThe final stages of on-board sound-shaping circuitry are the volume control (potentiometer) and tone control (which \"rolls off\" the treble frequencies). Where there are individual volume controls for different pickups, and where pickup signals can be combined, they would affect the timbre of the final sound by adjusting the balance between pickups from a straight 50:50.\n\nThe strings fitted to the guitar also have an influence on tone. Rock musicians often prefer the lightest gauge of roundwound string, which is easier to bend, while jazz musicians go for heavier, flatwound strings, which have a rich, dark sound. Steel, nickel, and cobalt are common string materials, and each gives a slightly different tone color. Recent guitar designs may incorporate much more complex circuitry than described above; see\nDigital and synthesizer guitars, below.\n\nThe solid-body electric guitar does not produce enough sound to be audible to the audience in a performance setting without it being plugged into an electronic amplifier (exceptions would be when a guitarist is doing a sound recording and plugs into the mixing console or when a bassist plugs directly into the PA system in a live show). \n\nGuitar amplifiers are designed with a different approach than that used to design sound reinforcement system power amplifiers and home \"hi-fi\" stereo systems. Audio amplifiers generally are intended to accurately reproduce the source signal without adding unwanted tonal coloration (i.e., they have a flat frequency response) or unwanted distortion. In contrast, most guitar amplifiers are intended to provide tonal coloration and/or overdrive (distortion of various types) that can add to a guitar signal. A common tonal coloration sought by guitarists is rolling off some of the high frequencies. Along with a guitarist's playing style and choice of electric guitar and pickups, the choice of guitar amp model is a key part of a guitarist's unique tone. Many top guitarists are associated with a specific brand of guitar amp. As well, electric guitarists in blues, rock and many related sub-genres often intentionally choose amplifiers or effects units with controls that distort or alter the sound (to a greater or lesser degree).\n\nIn the 1950s and 1960s, some guitarists began exploring a wider range of tonal effects by distorting the sound of the instrument. To do this, they used overdrive — increasing the gain of the preamplifier beyond the level where the signal could be reproduced with little distortion, resulting in a \"fuzzy\" sound. This effect is called \"clipping\" by sound engineers, because when viewed with an oscilloscope, the wave forms of a distorted signal appear to have had their peaks \"clipped off\", in the process introducing additional tones (often approximating the harmonics characteristic of a square wave of that basic frequency). This was not actually a new development in the musical instrument or its supporting gear, but rather a shift of aesthetics, such sounds not having been thought desirable previously. Some distortion modes with an electric guitar increase the sustain of single notes and chords, which changes the sound of the instrument. In particular, distortion made it more feasible to perform guitar solos that used long, sustained notes.\n\nAfter distortion became popular amongst rock music groups, guitar amplifier manufacturers included various provisions for it as part of amplifier design, making amps easier to overdrive, and providing separate \"dirty\" and \"clean\" channels so that distortion could easily be switched on and off. The distortion characteristics of vacuum tube amplifiers are particularly sought-after in blues and many rock music genres, and various attempts have been made to emulate them without the disadvantages (e.g., fragility, low power, expense) of actual tubes. Distortion, especially in tube based amplifiers, can come from several sources: power supply sag as more power is demanded than the supply can provide at a steady voltage, deliberate gain over drive of active elements, or alterations in the feedback provisions for various circuit stages.\n\nGuitar amplifiers have long included at least a few effect units, often tone controls for bass and treble, an integrated tremolo system (sometimes incorrectly labeled (and marketed) as vibrato), and/or a mechanical spring reverb unit. In the 2010s, guitar amps often have onboard distortion effects. Some 2010-era amps provide multiple effects, such as chorus, flanger, phaser and octave down effects. The use of offboard effects such as stompbox pedals is made possible by either plugging the guitar into the external effect pedal and then plugging the effect pedal into the amp, or by using one or more effects loops, an arrangement that allows effects to be electrically or mechanically switched in or out of the signal path as desired. In the signal chain, the effects loop is typically located between the preamplifier stage and the power amplifier stages (though reverb units generally precede the effects loop if both are featured on an amplifier). This allows the guitarist to apply modulation effects to the signal after it has been processed through the preamplifier, something generally desirable, particularly with time-based effects such as delay. By the 2010s, guitar amplifiers usually included a distortion effect. Effects circuitry (whether internal to an amplifier or not) can be taken as far as amp modeling, by which is meant alteration of the electrical and audible behavior in such a way as to make an amp sound as though it were another (or one of several) amplifiers. When done well, a solid state amplifier can sound like a tube amplifier (even one with power supply sag), reducing the need to manage more than one amp. Some modeling systems even attempt to emulate the sound of different speakers/cabinets. Nearly all amp and speaker cabinet modeling is done digitally, using computer techniques (e.g., Digital Signal Processing or DSP circuitry and software). There is disagreement about whether this approach is musically satisfactory, and also whether this or that unit is more or less successful than another.\n\nIn the 1960s, the tonal palette of the electric guitar was further modified by introducing effect units in its signal path, before the guitar amp, of which one of the earliest units was the fuzz pedal. Effects units come in several formats, the most common of which are the stompbox \"pedal\" and the rackmount unit. A stomp box (or pedal) is a small metal or plastic box containing the circuitry, which is placed on the floor in front of the musician and connected in line with the patch cord connected to the instrument. The box is typically controlled by one or more foot-pedal on-off switches and it typically contains only one or two effects. Pedals are smaller than rackmount effects and usually less expensive. \"Guitar pedalboards\" are used by musicians who use multiple stomp-boxes; these may be a DIY project made with plywood or a commercial stock or custom-made pedalboard.\n\nA rackmount effects unit may contain an electronic circuit nearly identical to a stompbox-based effect, but it is mounted in a standard 19\" equipment rack, which is usually mounted in a road case that is designed to protect the equipment during transport. More recently, as signal-processing technology continuously becomes more feature-dense, rack-mount effects units frequently contain several types of effects. They are typically controlled by knobs or switches on the front panel, and often by a MIDI digital control interface.\n\nTypical effects include:\n\nIn the 1970s, as effects pedals proliferated, their sounds were combined with tube amp distortion at lower, more controlled volumes by using power attenuators, such as Tom Scholz's Power Soak, as well as re-amplified dummy loads, such as Eddie Van Halen's use of dummy-load power resistor, post-power-tube effects, and a final solid-state amp driving the guitar speakers.\n\nRecent amplifiers may include digital technology similar to modern effects pedals, including the ability to model or emulate a variety of classic amps.\n\nA multi-effects device (also called a \"multi-FX\" device) is a single electronics effects pedal or rack-mount device that contains many electronic effects. In the late 1990s and throughout the 2000s, multi-FX manufacturers such as Zoom and Korg produced devices that were increasingly feature-laden. Multi-FX devices combine several effects together, and most devices allow users to use preset combinations of effects, including distortion, chorus, reverb, compression, and so on. This allows musicians to have quick on-stage access to different effects combinations. Some multi-FX pedals contain modelled versions of well-known effects pedals or amplifiers.\n\nMulti-effects devices have garnered a large share of the effects device market, because they offer the user such a large variety of effects in a single package. A low-priced multi-effects pedal may provide 20 or more effects for the price of a regular single-effect pedal. More expensive multi-effect pedals may include 40 or more effects, amplifier modelling, and the ability to combine effects and/or modelled amp sounds in different combinations, as if the user was using multiple guitar amps. More expensive multi-effects pedals may also include more input and output jacks (e.g., an auxiliary input or a \"dry\" output), MIDI inputs and outputs, and an expression pedal, which can control volume or modify effect parameters (e.g., the rate of the simulated rotary speaker effect).\n\nBy the 1980s and 1990s, software effects became capable of replicating the analog effects used in the past. These new digital effects attempt to model the sound produced by analog effects and tube amps, with varying degrees of quality. There are many free guitar effects computer programs that can be downloaded from the Internet. Now, computers with sound cards can be used as digital guitar effects processors. Although digital and software effects offer many advantages, many guitarists still use analog effects.\n\nIn 2002, Gibson announced the first digital guitar, which performs analog-to-digital conversion internally. The resulting digital signal is delivered over a standard Ethernet cable, eliminating cable-induced line noise. The guitar also provides independent signal processing for each individual string. In 2003, modelling amplifier maker Line 6 introduced the Variax guitar. It differs in some fundamental ways from conventional solid-body electrics. It has on-board electronics capable of modelling the sound of a variety of unique guitars and some other stringed instruments. At one time, some models featured piezoelectric pickups instead of the conventional electromagnetic pickups.\n\nThe sound of a guitar can not only be adapted by electronic sound effects but is also heavily affected by various new techniques developed or becoming possible in combination with electric amplification. This is called extended technique.\n\nExtended techniques include:\n\n\n\nOther techniques, such as axial finger vibrato, pull-offs, hammer-ons, palm muting, harmonics and altered tunings, are also used on the classical and acoustic guitar. Shred guitar is a genre involving a number of extended techniques.\n\nUnlike acoustic guitars, solid-body electric guitars have no vibrating soundboard to amplify string vibration. Instead, solid-body instruments depend on electric pickups and an amplifier (or amp) and speaker. The solid body ensures that the amplified sound reproduces the string vibration alone, thus avoiding the wolf tones and unwanted feedback associated with amplified acoustic guitars of the period. These guitars are generally made of hardwood covered with a hard polymer finish, often polyester or lacquer. In large production facilities, the wood is stored for three to six months in a wood-drying kiln before being cut to shape. Premium custom-built guitars are frequently made with much older, hand-selected wood.\n\nOne of the first solid-body guitars was invented by Les Paul. Gibson did not present their Gibson Les Paul guitar prototypes to the public, as they did not believe the solid-body style would catch on. Another early solid-body Spanish style guitar, resembling what would become Gibson's Les Paul guitar a decade later, was developed in 1941 by O.W. Appleton, of Nogales, Arizona. Appleton made contact with both Gibson and Fender but was unable to sell the idea behind his \"App\" guitar to either company. In 1946, Merle Travis commissioned steel guitar builder Paul Bigsby to build him a solid-body Spanish-style electric. Bigsby delivered the guitar in 1948. The first mass-produced solid-body guitar was Fender Esquire and Fender Broadcaster (later to become the Fender Telecaster), first made in 1948, five years after Les Paul made his prototype. The Gibson Les Paul appeared soon after to compete with the Broadcaster. Another notable solid-body design is the Fender Stratocaster, which was introduced in 1954 and became extremely popular among musicians in the 1960s and 1970s for its wide tonal capabilities and more comfortable ergonomics than other models.\n\nSome solid-bodied guitars, such as the Gibson Les Paul Supreme, the PRS Singlecut, and the Fender Telecaster Thinline, among others, are built with hollows in the body. These hollows are designed specifically not to interfere with the critical bridge and string anchor point on the solid body. In the case of Gibson and PRS, these are called chambered bodies. The motivation for this may be to reduce weight, to achieve a semi-acoustic tone (see below) or both.\n\nSemi-acoustic guitars have a hollow body (similar in depth to a solid-body guitar) and electronic pickups mounted on the body. They work in a similar way to solid-body electric guitars except that, because the hollow body also vibrates, the pickups convert a combination of string and body vibration into an electrical signal. Whereas chambered guitars are made, like solid-body guitars, from a single block of wood, semi-acoustic and full-hollowbody guitars bodies are made from thin sheets of wood. They do not provide enough acoustic volume for live performance, but they can be used unplugged for quiet practice. Semi-acoustics are noted for being able to provide a sweet, plaintive, or funky tone. They are used in many genres, including blues, funk, sixties pop, and indie rock. They generally have cello-style F-shaped sound holes. These can be blocked off to prevent feedback, as in B. B. King's famous Lucille. Feedback can also be reduced by making them with a solid block in the middle of the soundbox.\n\nFull hollow-body guitars have large, deep bodies made of glued-together sheets, or \"plates\", of wood. They can often be played at the same volume as an acoustic guitar and therefore can be used unplugged at intimate gigs. They qualify as electric guitars inasmuch as they have fitted pickups. Historically, archtop guitars\nwith retrofitted pickups were among the very earliest electric guitars. The instrument originated during the Jazz Age, in the 1920s and 1930s, and are still considered the classic jazz guitar (nicknamed \"jazzbox\"). Like semi-acoustic guitars, they often have f-shaped sound holes.\n\nHaving humbucker pickups (sometimes just a neck pickup) and usually strung heavlly, jazzboxes are noted for their warm, rich tone. A variation with single-coil pickups, and sometimes with a Bigsby tremolo, has long been popular in country and rockabilly; it has a distinctly more twangy, biting tone than the classic jazzbox. The term \"archtop\" refers to a method of construction subtly different from the typical acoustic (or \"folk\" or \"western\" or \"steel-string\" guitar): the top is formed from a moderately thick (1 inch or 2–3 cm) piece of wood, which is then carved into a thin (0.1 in, or 2–3 mm) domed shape, whereas conventional acoustic guitars have a thin, flat top.\n\nSome steel-string acoustic guitars are fitted with pickups purely as an alternative to using a separate microphone. They may also be fitted with a piezoelectric pickup under the bridge, attached to the bridge mounting plate, or with a low-mass microphone (usually a condenser mic) inside the body of the guitar that converts the vibrations in the body into electronic signals. Combinations of these types of pickups may be used, with an integral mixer/preamp/graphic equalizer. Such instruments are called electric acoustic guitars. They are regarded as acoustic guitars rather than electric guitars, because the pickups do not produce a signal directly from the vibration of the strings, but rather from the vibration of the guitar top or body.\n\nElectric acoustic guitars should not be confused with semi-acoustic guitars, which have pickups of the type found on solid-body electric guitars, or solid-body hybrid guitars with piezoelectric pickups.\n\nThe one-string guitar is also known as the Unitar. Although rare, the one-string guitar is sometimes heard, particularly in Delta blues, where improvised folk instruments were popular in the 1930s and 1940s. Eddie \"One String\" Jones had some regional success. Mississippi blues musician Lonnie Pitchford played a similar, homemade instrument. In a more contemporary style, Little Willie Joe, the inventor of the Unitar, had a rhythm and blues instrumental hit in the 1950s with \"Twitchy\", recorded with the Rene Hall Orchestra.\n\nThe four-string guitar is better known as the tenor guitar. One of its best-known players was Tiny Grimes, who played on 52nd Street with the beboppers and played a major role in the Prestige Blues Swingers. Multi-instrumentalist Warren Ellis (musician) of Dirty Three and Nick Cave and the Bad Seeds is a contemporary player who includes a tenor guitar in his repertoire.\n\nThe four-string guitar is normally tuned CGDA, but some players, such as Tiny Grimes, tune to DGBE in order to preserve familiar 6-string guitar chord fingerings. The tenor guitar can also be tuned like a soprano, concert, or tenor ukulele, using versions of GCEA tuning.\n\nMost seven-string guitars add a low B string below the low E. Both electric and classical guitars exist designed for this tuning. A high A string above the high E instead of the low B string is sometimes used. Another less common seven-string arrangement is a second G string situated beside the standard G string and tuned an octave higher, in the same manner as a twelve-stringed guitar (see below). Jazz guitarists using a seven-string include George Van Eps, Lenny Breau, Bucky Pizzarelli and his son John Pizzarelli.\n\nSeven-string electric guitars were popularized among rock players in the 1980s by Steve Vai. Along with the Japanese guitar company Ibanez, Vai created the Universe series seven-string guitars in the 1980s, with a double locking tremolo system for a seven-string guitar. These models were based on Vai's six-string signature series, the Ibanez Jem. Seven-string guitars experienced a resurgence in popularity in the 2000s, championed by Deftones, Limp Bizkit, Slayer, KoRn, Fear Factory, Strapping Young Lad, Nevermore, Muse and other hard rock and metal bands. Metal musicians often prefer the seven-string guitar for its extended lower range. The seven-string guitar has also played an essential role in progressive metal rock and is commonly used in bands such as Dream Theater and Pain of Salvation and by experimental guitarists such as Ben Levin.\n\nEight-string electric guitars are rare but not unused. One is played by Charlie Hunter, which was manufactured by Novax Guitars. The largest manufacturer of eight- to 14-string instruments is Warr Guitars. Their models are used by Trey Gunn (ex King Crimson), who has his own \"signature\" line from the company. Similarly, Mårten Hagström and Fredrik Thordendal of Meshuggah used 8-string guitars made by Nevborn Guitars and now guitars by Ibanez. Munky of the nu metal band KoRn is also known to use seven-string Ibanez guitars, and it is rumored that he is planning to release a K8 eight-string guitar similar to his K7 seven-string guitar. Another Ibanez player is Tosin Abasi, lead guitarist of the progressive metal band Animals as Leaders, who uses an Ibanez RG2228 to mix bright chords with very heavy low riffs on the seventh and eighth strings. Stephen Carpenter of Deftones also switched from a seven-string to an eight-string in 2008 and released his signature STEF B-8 with ESP Guitars. In 2008, Ibanez released the Ibanez RG2228-GK, which is the first mass-produced eight-string guitar. Jethro Tull's first album uses a nine-string guitar. Bill Kelliher, guitarist for the heavy metal group Mastodon, worked with First Act on a custom mass-produced nine-string guitar.\n\nB.C. Rich manufactures a ten-string six-course electric guitar, the Bich, whose radical shape positions the machine heads for the four secondary strings on the body, avoiding the head-heaviness of many electric twelve-string guitars. However many players bought it for the body shape or electrics and simply removed the extra strings. The company recognized this and released six-string models of the Bich, but ten-string models also remain in production.\n\nTwelve-string electric guitars feature six pairs of strings, usually with each pair tuned to the same note. The extra E, A, D, and G strings add a note one octave above, and the extra B and E strings are in unison. The pairs of strings are played together as one, so the technique and tuning are the same as a conventional guitar, but they create a much fuller tone, with the additional strings adding a natural chorus effect. They are used almost solely to play harmony and rhythm parts, rather than for guitar solos. They are relatively common in folk rock music. Lead Belly is the folk artist most identified with the twelve-string guitar, usually acoustic with a pickup.\n\nGeorge Harrison of the Beatles and Roger McGuinn of the Byrds brought the electric twelve-string to notability in rock and roll. During the Beatles' first trip to the United States, in February 1964, Harrison received a new 360/12 model guitar from the Rickenbacker company, a twelve-string electric made to look onstage like a six-string. He began using the 360 in the studio on Lennon's \"You Can't Do That\" and other songs. McGuinn began using electric twelve-string guitars to create the jangly, ringing sound of the Byrds. Both Jimmy Page, the guitarist with Led Zeppelin, and Leo Kottke, a solo artist, are well known as twelve-string guitar players.\n\nThe third-bridge guitar is an electric prepared guitar with an additional, third bridge. This can be a normal guitar with, for instance, a screwdriver placed under the strings, or it can be a custom-made instrument. Lee Ranaldo of Sonic Youth plays with a third bridge.\n\nDouble-neck (or, less commonly, \"twin-neck\") guitars enable guitarists to play both guitar and bass guitar or, more commonly, both a six-string and a twelve-string. In the mid-1960s, one of the first players to use this type of guitar was Paul Revere & the Raiders' guitarist Drake Levin. Another early user was John McLaughlin. The double-neck guitar was popularized by Jimmy Page, who used a custom-made, cherry-finished Gibson EDS-1275 to perform \"Stairway to Heaven\", \"The Song Remains the Same\" and \"The Rain Song\", although for the recording of \"Stairway to Heaven\" he used a Fender Telecaster and a Fender XII electric twelve-string. Mike Rutherford of Genesis and Mike + the Mechanics is also famous for his use of a double-neck guitar during live shows. Don Felder of the Eagles used the Gibson EDS-1275 during the Hotel California tour. Muse guitarist and vocalist Matthew Bellamy uses a silver Manson double-neck on his band's Resistance Tour. Rush guitarist Alex Lifeson is also known for using double-neck guitars in the live performance of several songs. In performances of the song \"Xanadu\" during the band's 2015 R40 anniversary tour, Lifeson played a white Gibson EDS-1275 double-neck guitar with six-string and twelve-string necks, while bassist Geddy Lee performed with a double-neck Rickenbacker guitar with four-string bass and twelve-string guitar necks.\n\nPopular music and rock groups often use the electric guitar in two roles: as a rhythm guitar which provides the chord sequence or \"progression\" and sets out the \"beat\" (as part of a rhythm section), and a lead guitar, which is used to perform melody lines, melodic instrumental fill passages, and guitar solos. In some rock or metal bands with two guitarists, the two performers may perform as a guitar tandem, and trade off the lead guitar and rhythm guitar roles. In bands with a single guitarist, the guitarist may switch between these two roles, playing chords to accompany the singer's lyrics, and then playing a guitar solo in the middle of the song.\n\nIn the most commercially available and consumed pop and rock genres, electric guitars tend to dominate their acoustic cousins in both the recording studio and live venues, especially in the \"harder\" genres such as heavy metal and hard rock. However the acoustic guitar remains a popular choice in country, western and especially bluegrass music, and it is widely used in folk music. Even metal and hard rock guitarists play acoustic guitars for some ballads and for MTV unplugged acoustic performances.\n\nJazz guitar playing styles include rhythm guitar-style \"comping\" (accompanying) with jazz chord voicings (and in some cases, walking basslines) and \"blowing\" (improvising solos) over jazz chord progressions with jazz-style phrasing and ornaments. The accompanying style for electric guitar in most jazz styles differs from the way chordal instruments accompany in many popular styles of music. In rock and pop, the rhythm guitarist usually performs the chords in dense and regular fashion, which sets out the beat of a tune. Rock and pop chord voicings tend to focus on the first, third, and fifth notes of the chord. In contrast, in many modern jazz styles, the guitarist plays much more sparsely, intermingling periodic chords and delicate voicings into pauses in the melody or solo. Jazz chord voicings are usually rootless and emphasize the third and seventh notes of the chord. Jazz chords also often include the 9th, 11th and 13th notes of the chord, which are called \"extensions\".\n\nWhen jazz guitar players improvise, they use scales, modes, and arpeggios associated with the chords in a tune's chord progression. Jazz guitarists have to learn how to use scales (whole tone scale, chromatic scale, etc.) to solo over chord progressions. Jazz guitar improvising is not merely the recitation of jazz scales and rapid arpeggios. Jazz guitarists try to imbue their melodic phrasing with the sense of natural breathing and legato phrasing used by horn players such as saxophone players. As well, a jazz guitarists' solo improvisations have to have a rhythmic drive and \"time feel\" that creates a sense of \"swing\" and \"groove\". In addition to the traditional rhythm/comping and lead/blowing roles, some jazz guitarists use the electric instrument to play unaccompanied, combining harmony notes and the melody to form a complete piece of music, like classical guitarists.\n\nMost jazz guitarists play hollow-body instruments, but solid-body guitars are also used. Hollow-body instruments were the first guitars used in jazz in the 1930s and 1940s. During the 1970s jazz fusion era, many jazz guitarists switched to the solid body guitars that dominated the rock world, using powerful guitar amps to get a loud sound.\n\nUntil the 1950s, the acoustic, nylon-stringed classical guitar was the only type of guitar favored by classical, or art music composers. In the 1950s a few contemporary classical composers began to use the electric guitar in their compositions. Examples of such works include Luciano Berio's \"Nones\" (1954) Karlheinz Stockhausen's \"Gruppen\" (1955–57); Donald Erb's \"String Trio\" (1966), Morton Feldman's \"The Possibility of a New Work for Electric Guitar\" (1966); George Crumb's \"Songs, Drones, and Refrains of Death\" (1968); Hans Werner Henze's \"Versuch über Schweine\" (1968); Francis Thorne's \"Sonar Plexus\" (1968) and \"Liebesrock\" (1968–69), Michael Tippett's \"The Knot Garden\" (1965–70); Leonard Bernstein's \"MASS\" (1971) and \"Slava!\" (1977); Louis Andriessen's \"De Staat\" (1972–76); Helmut Lachenmann's \"Fassade, für grosses Orchester\" (1973, rev. 1987), Valery Gavrilin \"Anyuta\" (1982), Steve Reich's \"Electric Counterpoint\" (1987), Arvo Pärt's \"Miserere\" (1989/92), György Kurtág's \"Grabstein für Stephan\" (1989), and countless works composed for the quintet of Ástor Piazzolla.\nAlfred Schnittke also used electric guitar in several works, like the \"Requiem\", \"Concerto Grosso N°2\" and \"Symphony N°1\".\n\nIn the 1970s, 1980s and 1990s, a growing number of composers (many of them composer-performers who had grown up playing the instrument in rock bands) began writing contemporary classical music for the electric guitar. These include Frank Zappa, Shawn Lane, Steven Mackey, Nick Didkovsky, Scott Johnson, Lois V Vierk, Tim Brady, Tristan Murail, and Randall Woolf.\n\nYngwie Malmsteen released his Concerto Suite for Electric Guitar and Orchestra in 1998, and Steve Vai released a double-live CD entitled \"Sound Theories\", of his work with the Netherlands Metropole Orchestra in June 2007. The American composers Rhys Chatham and Glenn Branca have written \"symphonic\" works for large ensembles of electric guitars, in some cases numbering up to 100 players, and the instrument is a core member of the Bang on a Can All-Stars (played by Mark Stewart). Still, like many electric and electronic instruments, the electric guitar remains primarily associated with rock and jazz music, rather than with classical compositions and performances. R. Prasanna plays a style of Indian classical music (Carnatic music) on the electric guitar.\n\nIn the 21st century, European avant garde composers like Richard Barrett, Fausto Romitelli, Peter Ablinger, Bernhard Lang, Claude Ledoux and Karlheinz Essl have used the electric guitar (together with extended playing techniques) in solo pieces or ensemble works. Probably the most ambitious and perhaps significant work to date is \"Ingwe\" (2003–2009) by Georges Lentz (written for Australian guitarist Zane Banks), a 60-minute work for solo electric guitar, exploring that composer's existential struggles and taking the instrument into realms previously unknown in a concert music setting.\n\nIn Vietnam, electric guitars are often used as an instrument in cải lương music (traditional southern Vietnamese folk opera), sometimes as a substitute for certain traditional stringed instruments like the Đàn nguyệt (two-stringed lute) when they are not available. Electric guitars used in cải lương are played in finger vibrato (string bending), with no amplifiers or sound effects.\n\n\n"}
{"id": "10273", "url": "https://en.wikipedia.org/wiki?curid=10273", "title": "Embryo drawing", "text": "Embryo drawing\n\nEmbryo drawing is the illustration of embryos in their developmental sequence. In plants and animals, an embryo develops from a zygote, the single cell that results when an egg and sperm fuse during fertilization. In animals, the zygote divides repeatedly to form a ball of cells, which then forms a set of tissue layers that migrate and fold to form an early embryo. Images of embryos provide a means of comparing embryos of different ages, and species. To this day, embryo drawings are made in undergraduate developmental biology lessons.\n\nComparing different embryonic stages of different animals is a tool that can be used to infer relationships between species, and thus biological evolution. This has been a source of quite some controversy, both now and in the past. Ernst Haeckel pioneered in this field. By comparing different embryonic stages of different vertebrate species, he formulated the recapitulation theory. This theory states that an animal's embryonic development follows exactly the same sequence as the sequence of its evolutionary ancestors. Haeckel's work and the ensuing controversy linked the fields of developmental biology and comparative anatomy into comparative embryology. From a more modern perspective, Haeckel's drawings were the beginnings of the field of evolutionary developmental biology (evo-devo).\n\nThe study of comparative embryology aims to prove or disprove that vertebrate embryos of different classes (e.g. mammals vs. fish) follow a similar developmental path due to their common ancestry. Such developing vertebrates have similar genes, which determine the basic body plan. However, further development allows for the distinguishing of distinct characteristics as adults.\n\nIn current biology, fundamental research in developmental biology and evolutionary developmental biology is no longer driven by morphological comparisons between embryos, but more by molecular biology. This is partly because Haeckel's drawings were very inaccurate.\n\nThe exactness of Ernst Haeckel's drawings of embryos has caused much controversy among Intelligent Design proponents recently and Haeckel's intellectual opponents in the past. Although the early embryos of different species exhibit similarities, Haeckel apparently exaggerated these similarities in support of his Recapitulation theory, sometimes known as the Biogenetic Law or \"Ontogeny recapitulates phylogeny\". Furthermore, Haeckel even proposed theoretical life-forms to accommodate certain stages in embryogenesis. A recent review concluded that the \"biogenetic law is supported by several recent studies - if applied to single characters only\".\n\nCritics in the late 19th and early 20th centuries, Karl von Baer and Wilhelm His, did not believe that living embryos reproduce the evolutionary process and produced embryo drawings of their own which emphasized the differences in early embryological development. Late 20th and early 21st century critics Jonathan Wells and Stephen Jay Gould have objected to the continued use of Haeckel’s embryo drawings in textbooks.\n\nOn the other hand, Michael K. Richardson, Professor of Evolutionary Developmental Zoology, Leiden University, while recognizing that some criticisms of the drawings are legitimate (indeed, it was he and his co-workers who began the modern criticisms in 1998), has supported the drawings as teaching aids, and has said that \"on a fundamental level, Haeckel was correct\"\n\nHaeckel’s illustrations show vertebrate embryos at different stages of development, which exhibit embryonic resemblance as support for evolution, recapitulation as evidence of the Biogenetic Law, and phenotypic divergence as evidence of von Baer’s laws. The series of twenty-four embryos from the early editions of Haeckel’s \"Anthropogenie\" remain the most famous. The different species are arranged in columns, and the different stages in rows. Similarities can be seen along the first two rows; the appearance of specialized characters in each species can be seen in the columns and a diagonal interpretation leads one to Haeckel’s idea of recapitulation.\n\nHaeckel’s embryo drawings are primarily intended to express his idiosyncratic theory of embryonic development, the Biogenetic Law, which in turn assumes (but is not crucial to) the evolutionary concept of common descent. His postulation of embryonic development coincides with his understanding of evolution as a developmental process. In and around 1800, embryology fused with comparative anatomy as the primary foundation of morphology. Ernst Haeckel, along with Karl von Baer and Wilhelm His, are primarily influential in forming the preliminary foundations of ‘phylogenetic embryology’ based on principles of evolution. Haeckel’s ‘Biogenetic Law’ portrays the parallel relationship between an embryo’s development and phylogenetic history. The term, ‘recapitulation,’ has come to embody Haeckel’s Biogenetic Law, for embryonic development is a recapitulation of evolution. Haeckel proposes that all classes of vertebrates pass through an evolutionarily conserved “phylotypic” stage of development, a period of reduced phenotypic diversity among higher embryos. Only in later development do particular differences appear. Haeckel portrays a concrete demonstration of his Biogenetic Law through his ‘Gastrea’ theory, in which he argues that the early cup-shaped gastrula stage of development is a universal feature of multi-celled animals. An ancestral form existed, known as the gastrea, which was a common ancestor to the corresponding gastrula.\n\nHaeckel argues that certain features in embryonic development are conserved and palingenetic, while others are caenogenetic. Caenogenesis represents “the blurring of ancestral resemblances in development,” which are said to be the result of certain adaptations to embryonic life due to environmental changes. In his drawings, Haeckel cites the notochord, pharyngeal arches and clefts, pronephros and neural tube as palingenetic features. However, the yolk sac, extra-embryonic membranes, egg membranes and endocardial tube are considered caenogenetic features. The addition of terminal adult stages and the telescoping, or driving back, of such stages to descendant’s embryonic stages are likewise representative of Haeckelian embryonic development. In addressing his embryo drawings to a general audience, Haeckel does not cite any sources, which gives his opponents the freedom to make assumptions regarding the originality of his work.\n\nHaeckel was not the only one to create a series of drawings representing embryonic development. Karl E. von Baer and Haeckel both struggled to model one of the most complex problems facing embryologists at the time: the arrangement of general and special characters during development in different species of animals. In relation to developmental timing, von Baer's scheme of development differs from Haeckel's scheme. Von Baer's scheme of development need not be tied to developmental stages defined by particular characters, where recapitulation involves heterochrony. Heterochrony represents a gradual alteration in the original phylogenetic sequence due to embryonic adaptation.\nAs well, von Baer early noted that embryos of different species could not be easily distinguished from one another as in adults.\n\nVon Baer’s laws governing embryonic development are specific rejections of recapitulation. As a response to Haeckel’s theory of recapitulation, von Baer enunciates his most notorious laws of development. Von Baer’s laws state that general features of animals appear earlier in the embryo than special features, where less general features stem from the most general, each embryo of a species departs more and more from a predetermined passage through the stages of other animals, and there is never a complete morphological similarity between an embryo and a lower adult. Von Baer’s embryo drawings display that individual development proceeds from general features of the developing embryo in early stages through differentiation into special features specific to the species, establishing that linear evolution could not occur. Embryological development, in von Baer’s mind, is a process of differentiation, \"a movement from the more homogeneous and universal to the more heterogeneous and individual.\"\n\nVon Baer argues that embryos will resemble each other before attaining characteristics differentiating them as part of a specific family, genus or species, but embryos are not the same as the final forms of lower organisms.\n\nWilhelm His was one of Haeckel’s most authoritative and primary opponents advocating physiological embryology. His \"Anatomie menschlicher Embryonen\" (Anatomy of human embryos) employs a series of his most important drawings chronicling developing embryos from the end of the second week through the end of the second month of pregnancy. His, in opposition to Haeckel, seeks to take human embryos out of the hands of Darwinist proponents. In 1878, His begins to engage in serious study of the anatomy of human embryos for his drawings. During the 19th century, embryologists often obtained early human embryos from abortions and miscarriages, postmortems of pregnant women and collections in anatomical museums. In order to construct his series of drawings, His collected specimens which he manipulated into a form that he could operate with.\n\nIn His’ \"Normentafel\", he displays specific individual embryos rather than ideal types. His does not produce norms from aborted specimens, but rather visualizes the embryos in order to make them comparable and specifically subjects his embryo specimens to criticism and comparison with other cases. Ultimately, His’ critical work in embryonic development comes with his production of a series of embryo drawings of increasing length and degree of development. His’ depiction of embryological development strongly differs from Haeckel’s depiction, for His argues that the phylogenetic explanation of ontogenetic events is unnecessary. His argues that all ontogenetic events are the “mechanical” result of differential cell growth. His’ embryology is not explained in terms of ancestral history.\n\nThe debate between Haeckel and His ultimately becomes fueled by the description of an embryo that Wilhelm Krause propels directly into the ongoing feud between Haeckel and His. Haeckel speculates that the allantois is formed in a similar way in both humans and other mammals. His, on the other hand, accuses Haeckel of altering and playing with the facts. Although Haeckel is proven right about the allantois, the utilization of Krause’s embryo as justification turns out to be problematic, for the embryo is that of a bird rather than a human. The underlying debate between Haeckel and His derives from differing viewpoints regarding the similarity or dissimilarity of vertebrate embryos. In response to Haeckel’s evolutionary claim that all vertebrates are essentially identical in the first month of embryonic life as proof of common descent, His responds by insisting that a more skilled observer would recognize even sooner that early embryos can be distinguished. His also counteracts Haeckel’s sequence of drawings in the \"Anthropogenie\" with what he refers to as “exact” drawings, highlighting specific differences. Ultimately, His goes so far as to accuse Haeckel of “faking” his embryo illustrations to make the vertebrate embryos appear more similar than in reality. His also accuses Haeckel of creating early human embryos that he conjured in his imagination rather than obtained through empirical observation. His completes his denunciation of Haeckel by pronouncing that Haeckel had “‘relinquished the right to count as an equal in the company of serious researchers.’”\n\nHaeckel encountered numerous oppositions to his artistic depictions of embryonic development during the late nineteenth and early twentieth centuries. Haeckel’s opponents believe that he de-emphasizes the differences between early embryonic stages in order to make the similarities between embryos of different species more pronounced.\n\nThe first suggestion of fakery against Haeckel was made in late 1868 by Ludwig Rutimeyer in the \"Archiv für Anthropogenie\". Rutimeyer was a professor of zoology and comparative anatomy at the University of Basel, who rejected natural selection as simply mechanistic and proposed an anti-materialist view of nature. Rutimeyer claimed that Haeckel “had taken to kinds of liberty with established truth.” Rutimeyer claimed that Haeckel presented the same image three consecutive times as the embryo of the dog, the chicken, and the turtle. Although Rutimeyer did not denounce Haeckel’s embryo drawings as fraud, he argued that such drawings are manipulations of public and scientific thought.\n\nTheodor Bischoff (1807–1882), was a strong opponent of Darwinism. As a pioneer in mammalian embryology, he was one of Haeckel’s strongest critics. Although Bischoff’s 1840 surveys depict how similar the early embryos of man are to other vertebrates, he later demanded that such hasty generalization was inconsistent with his recent findings regarding the dissimilarity between hamster embryos and those of rabbits and dogs. Nevertheless, Bischoff’s main argument was in reference to Haeckel’s drawings of human embryos, for Haeckel is later accused of miscopying the dog embryo from him. Throughout Haeckel’s time, criticism of his embryo drawings was often due in part to his critics' belief in his representations of embryological development as “crude schemata.” In this way, Haeckel specifically selected relevant features to portray in his drawings. Haeckel’s opponents found his methods problematic because such simplification eliminates certain structures that differentiate between higher and lower vertebrates. In 1877, Rudolf Virchow (1821–1902), once an inspiration to Haeckel at Würzburg, proclaimed that Haeckel’s embryo drawings represent mere hypotheses.\n\nMichael Richardson and his colleagues in a July 1997 issue of \"Anatomy and Embryology\", demonstrated that Haeckel fudged his drawings in order to exaggerate the similarity of the phylotypic stage.\nIn a March 2000 issue of \"Natural History\", Stephen Jay Gould argued that Haeckel \"exaggerated the similarities by idealizations and omissions.\" As well, Gould argued that Haeckel’s drawings are simply inaccurate and falsified. On the other hand, one of those who criticized Haeckel's drawings, Michael Richardson, has argued that \"Haeckel's much-criticized drawings are important as phylogenetic hypotheses, teaching aids, and evidence for evolution\".\nBut even Richardson admitted in \"Science\" Magazine in 1997 that his team's investigation of Haeckel's drawings were showing them to be \"one of the most famous fakes in biology.\"\n\nSome version of Haeckel’s drawings can be found in many modern biology textbooks in discussions of the history of embryology, with clarification that these are no longer considered valid .\n\nAlthough Charles Darwin accepted Haeckel's support for natural selection, he was tentative in using Haeckel's ideas in his writings; with regard to embryology, Darwin relied far more on von Baer's work. Haeckel's work was published in 1866 and 1874, years after Darwin's \"The Origin of Species\" (1859).\n\nDespite the numerous oppositions, Haeckel has influenced many disciplines in science in his drive to integrate such disciplines of taxonomy and embryology into the Darwinian framework and to investigate phylogenetic reconstruction through his Biogenetic Law. As well, Haeckel served as a mentor to many important scientists, including Anton Dohrn, Richard and Oscar Hertwig, Wilhelm Roux, and Hans Driesch.\n\nOne of Haeckel's earliest proponents was Carl Gegenbaur at the University of Jena (1865–1873), during which both men were absorbing the impact of Darwin's theory. The two quickly sought to integrate their knowledge into an evolutionary program. In determining the relationships between \"phylogenetic linkages\" and \"evolutionary laws of form,\" both Gegenbaur and Haeckel relied on a method of comparison. As Gegenbaur argued, the task of comparative anatomy lies in explaining the form and organization of the animal body in order to provide evidence for the continuity and evolution of a series of organs in the body. Haeckel then provided a means of pursuing this aim with his biogenetic law, in which he proposed to compare an individual's various stages of development with its ancestral line. Although Haeckel stressed comparative embryology and Gegenbaur promoted the comparison of adult structures, both believed that the two methods could work in conjunction to produce the goal of evolutionary morphology.\n\nThe philologist and anthropologist, Friedrich Müller, used Haeckel's concepts as a source for his ethnological research, involving the systematic comparison of the folklore, beliefs and practices of different societies. Müller's work relies specifically on theoretical assumptions that are very similar to Haeckel's and reflects the German practice to maintain strong connections between empirical research and the philosophical framework of science. Language is particularly important, for it establishes a bridge between natural science and philosophy. For Haeckel, language specifically represented the concept that all phenomena of human development relate to the laws of biology. Although Müller did not specifically have an influence in advocating Haeckel's embryo drawings, both shared a common understanding of development from lower to higher forms, for Müller specifically saw humans as the last link in an endless chain of evolutionary development.\n\nModern acceptance of Haeckel's Biogenetic Law, despite current rejection of Haeckelian views, finds support in the certain degree of parallelism between ontogeny and phylogeny. A. M. Khazen, on the one hand, states that \"ontogeny is obliged to repeat the main stages of phylogeny.\" A. S. Rautian, on the other hand, argues that the reproduction of ancestral patterns of development is a key aspect of certain biological systems. Dr. Rolf Siewing acknowledges the similarity of embryos in different species, along with the laws of von Baer, but does not believe that one should compare embryos with adult stages of development. According to M. S. Fischer, reconsideration of the Biogenetic Law is possible as a result of two fundamental innovations in biology since Haeckel's time: cladistics and developmental genetics.\n\nIn defense of Haeckel's embryo drawings, the principal argument is that of \"schematisation.\" Haeckel's drawings were not intended to be technical and scientific depictions, but rather schematic drawings and reconstructions for a specifically lay audience. Therefore, as R. Gursch argues, Haeckel's embryo drawings should be regarded as \"reconstructions.\" Although his drawings are open to criticism, his drawings should not be considered falsifications of any sort. Although modern defense of Haeckel's embryo drawings still considers the inaccuracy of his drawings, charges of fraud are considered unreasonable. As Erland Nordenskiöld argues, charges of fraud against Haeckel are unnecessary. R. Bender ultimately goes so far as to reject His's claims regarding the fabrication of certain stages of development in Haeckel's drawings, arguing that Haeckel's embryo drawings are faithful representations of real stages of embryonic development in comparison to published embryos.\n\nHaeckel's embryo drawings, as comparative plates, were at first only copied into biology textbooks, rather than texts on the study of embryology. Even though Haeckel's program in comparative embryology virtually collapsed after the First World War, his embryo drawings have often been reproduced and redrawn with increased precision and accuracy in works that have kept the study of comparative embryology alive. Nevertheless, neither His-inspired human embryology nor developmental biology are concerned with the comparison of vertebrate embryos. Although Stephen Jay Gould's 1977 book \"Ontogeny and Phylogeny\" helps to reassess Haeckelian embryology, it does not address the controversy over Haeckel's embryo drawings. Nevertheless, new interest in evolution in and around 1977 inspired developmental biologists to look more closely at Haeckel's illustrations.\n\n\n"}
{"id": "10274", "url": "https://en.wikipedia.org/wiki?curid=10274", "title": "Enthalpy", "text": "Enthalpy\n\nEnthalpy is a measurement of energy in a thermodynamic system. It is the thermodynamic quantity equivalent to the total heat content of a system. It is equal to the internal energy of the system plus the product of pressure and volume.\n\nMore technically, it includes the internal energy, which is the energy required to create a system, and the amount of energy required to make room for it by displacing its environment and establishing its volume and pressure.\n\nEnthalpy is defined as a state function that depends only on the prevailing equilibrium state identified by the system's internal energy, pressure, and volume. It is an extensive quantity. The unit of measurement for enthalpy in the International System of Units (SI) is the joule, but other historical, conventional units are still in use, such as the British thermal unit and the calorie.\n\nEnthalpy is the preferred expression of system energy changes in many chemical, biological, and physical measurements at constant pressure, because it simplifies the description of energy transfer. At constant pressure, the enthalpy change equals the energy transferred from the environment through heating or work other than expansion work.\n\nThe total enthalpy, \"H\", of a system cannot be measured directly. The same situation exists in classical mechanics: only a change or difference in energy carries physical meaning. Enthalpy itself is a thermodynamic potential, so in order to measure the enthalpy of a system, we must refer to a defined reference point; therefore what we measure is the change in enthalpy, Δ\"H\". The Δ\"H\" is a positive change in endothermic reactions, and negative in heat-releasing exothermic processes.\n\nFor processes under constant pressure, Δ\"H\" is equal to the change in the internal energy of the system, plus the pressure-volume work that the system has done on its surroundings. This means that the change in enthalpy under such conditions is the heat absorbed (or released) by the material through a chemical reaction or by external heat transfer. Enthalpies for chemical substances at constant pressure assume standard state: most commonly 1 bar pressure. Standard state does not, strictly speaking, specify a temperature (see standard state), but expressions for enthalpy generally reference the standard heat of formation at 25 °C.\n\nEnthalpy of ideal gases and incompressible solids and liquids does not depend on pressure, unlike entropy and Gibbs energy. Real materials at common temperatures and pressures usually closely approximate this behavior, which greatly simplifies enthalpy calculation and use in practical designs and analyses.\n\nThe word \"enthalpy\" stems from the Ancient Greek verb \"enthalpein\" (), which means \"to warm in\". It combines the Classical Greek prefix \"en-\", meaning \"to put into\", and the verb \"thalpein\", meaning \"to heat\". The word \"enthalpy\" is often incorrectly attributed to Benoît Paul Émile Clapeyron and Rudolf Clausius through the 1850 publication of their Clausius–Clapeyron relation. This misconception was popularized by the 1927 publication of \"The Mollier Steam Tables and Diagrams\". However, neither the concept, the word, nor the symbol for enthalpy existed until well after Clapeyron's death.\n\nThe earliest writings to contain the concept of enthalpy did not appear until 1875,\nwhen Josiah Willard Gibbs introduced \"a heat function for constant pressure\". However, Gibbs did not use the word \"enthalpy\" in his writings.\n\nThe actual word first appears in the scientific literature in a 1909 publication by J. P. Dalton. According to that publication, Heike Kamerlingh Onnes actually coined the word.\n\nOver the years, scientists used many different symbols to denote enthalpy. In 1922 Alfred W. Porter proposed the symbol \"\"H\"\" as a standard,\nthus finalizing the terminology still in use today.\n\nThe enthalpy of a homogeneous system is defined as\nwhere\n\nEnthalpy is an extensive property. This means that, for homogeneous systems, the enthalpy is proportional to the size of the system. It is convenient to introduce the specific enthalpy \"h\" = , where \"m\" is the mass of the system, or the molar enthalpy \"H\" = , where \"n\" is the number of moles (\"h\" and \"H\" are intensive properties). For inhomogeneous systems the enthalpy is the sum of the enthalpies of the composing subsystems:\n\nwhere the label \"k\" refers to the various subsystems. In case of continuously varying \"p\", \"T\" or composition, the summation becomes an integral:\n\nwhere \"ρ\" is the density.\n\nThe enthalpy of homogeneous systems can be viewed as function \"H\"(\"S\",\"p\") of the entropy \"S\" and the pressure \"p\", and a differential relation for it can be derived as follows. We start from the first law of thermodynamics for closed systems for an infinitesimal process:\n\nHere, \"δQ\" is a small amount of heat added to the system, and \"δW\" a small amount of work performed by the system. In a homogeneous system only reversible processes can take place, so the second law of thermodynamics gives , with \"T\" the absolute temperature of the system. Furthermore, if only \"pV\" work is done, . As a result,\n\nAdding \"d\"(\"pV\") to both sides of this expression gives\n\nor\n\nSo\n\nThe above expression of \"dH\" in terms of entropy and pressure may be unfamiliar to some readers. However, there are expressions in terms of more familiar variables such as temperature and pressure:\n\nHere \"C\" is the heat capacity at constant pressure and \"α\" is the coefficient of (cubic) thermal expansion:\n\nWith this expression one can, in principle, determine the enthalpy if \"C\" and \"V\" are known as functions of \"p\" and \"T\".\n\nNote that for an ideal gas, \"αT\" = 1, so that\n\nIn a more general form, the first law describes the internal energy with additional terms involving the chemical potential and the number of particles of various types. The differential statement for \"dH\" then becomes\n\nwhere \"μ\" is the chemical potential per particle for an \"i\"-type particle, and \"N\" is the number of such particles. The last term can also be written as (with \"dn\" the number of moles of component \"i\" added to the system and, in this case, \"μ\" the molar chemical potential) or as (with \"dm\" the mass of component \"i\" added to the system and, in this case, \"μ\" the specific chemical potential).\n\nThe \"U\" term can be interpreted as the energy required to create the system, and the \"pV\" term as the energy that would be required to \"make room\" for the system if the pressure of the environment remained constant. When a system, for example, \"n\" moles of a gas of volume \"V\" at pressure \"p\" and temperature \"T\", is created or brought to its present state from absolute zero, energy must be supplied equal to its internal energy \"U\" plus \"pV\", where \"pV\" is the work done in pushing against the ambient (atmospheric) pressure.\n\nIn basic physics and statistical mechanics it may be more interesting to study the internal properties of the system and therefore the internal energy is used. In basic chemistry, experiments are often conducted at constant atmospheric pressure, and the pressure-volume work represents an energy exchange with the atmosphere that cannot be accessed or controlled, so that Δ\"H\" is the expression chosen for the heat of reaction.\n\nFor a heat engine a change in its internal energy is the difference between the heat input and the pressure-volume work done by the working substance while a change in its enthalpy is the difference between the heat input and the work done by the engine:\nwhere the work W done by the engine is: \n\nIn order to discuss the relation between the enthalpy increase and heat supply, we return to the first law for closed systems: . We apply it to the special case with a uniform pressure at the surface. In this case the work term can be split into two contributions, the so-called \"pV\" work, given by (where here \"p\" is the pressure at the surface, \"dV\" is the increase of the volume of the system) and all other types of work \"δW′\", such as by a shaft or by electromagnetic interaction. So we write . In this case the first law reads:\n\nor\n\nFrom this relation we see that the increase in enthalpy of a system is equal to the added heat:\n\nprovided that the system is under constant pressure (\"dp\" = 0) and that the only work done by the system is expansion work (\"δW\"' = 0).\n\nIn thermodynamics, one can calculate enthalpy by determining the requirements for creating a system from \"nothingness\"; the mechanical work required, \"pV\", differs based upon the conditions that obtain during the creation of the thermodynamic system.\n\nEnergy must be supplied to remove particles from the surroundings to make space for the creation of the system, assuming that the pressure \"p\" remains constant; this is the \"pV\" term. The supplied energy must also provide the change in internal energy, \"U\", which includes activation energies, ionization energies, mixing energies, vaporization energies, chemical bond energies, and so forth. Together, these constitute the change in the enthalpy \"U\" + \"pV\". For systems at constant pressure, with no external work done other than the \"pV\" work, the change in enthalpy is the heat received by the system.\n\nFor a simple system, with a constant number of particles, the difference in enthalpy is the maximum amount of thermal energy derivable from a thermodynamic process in which the pressure is held constant.\n\nThe total enthalpy of a system cannot be measured directly, the \"enthalpy change\" of a system is measured instead. Enthalpy change is defined by the following equation:\n\nwhere\n\nFor an exothermic reaction at constant pressure, the system's change in enthalpy equals the energy released in the reaction, including the energy retained in the system and lost through expansion against its surroundings. In a similar manner, for an endothermic reaction, the system's change in enthalpy is equal to the energy \"absorbed\" in the reaction, including the energy \"lost by\" the system and \"gained\" from compression from its surroundings. A relatively easy way to determine whether or not a reaction is exothermic or endothermic is to determine the sign of Δ\"H\". If Δ\"H\" is positive, the reaction is endothermic, that is heat is absorbed by the system due to the products of the reaction having a greater enthalpy than the reactants. On the other hand, if Δ\"H\" is negative, the reaction is exothermic, that is the overall decrease in enthalpy is achieved by the generation of heat.\n\nThe specific enthalpy of a uniform system is defined as \"h\" = where \"m\" is the mass of the system. The SI unit for specific enthalpy is joule per kilogram. It can be expressed in other specific quantities by , where \"u\" is the specific internal energy, \"p\" is the pressure, and \"v\" is specific volume, which is equal to , where \"ρ\" is the density.\n\nAn enthalpy change describes the change in enthalpy observed in the constituents of a thermodynamic system when undergoing a transformation or chemical reaction. It is the difference between the enthalpy after the process has completed, i.e. the enthalpy of the products, and the initial enthalpy of the system, i.e. the reactants. These processes are reversible and the enthalpy for the reverse process is the negative value of the forward change.\n\nA common standard enthalpy change is the enthalpy of formation, which has been determined for a large number of substances. Enthalpy changes are routinely measured and compiled in chemical and physical reference works, such as the CRC Handbook of Chemistry and Physics. The following is a selection of enthalpy changes commonly recognized in thermodynamics.\n\nWhen used in these recognized terms the qualifier \"change\" is usually dropped and the property is simply termed \"enthalpy of 'process\"'. Since these properties are often used as reference values it is very common to quote them for a standardized set of environmental parameters, or standard conditions, including: \nFor such standardized values the name of the enthalpy is commonly prefixed with the term \"standard\", e.g. \"standard enthalpy of formation\".\n\nChemical properties:\n\nPhysical properties:\n\nIn thermodynamic open systems, matter may flow in and out of the system boundaries. The first law of thermodynamics for open systems states: The increase in the internal energy of a system is equal to the amount of energy added to the system by matter flowing in and by heating, minus the amount lost by matter flowing out and in the form of work done by the system:\n\nwhere \"U\" is the average internal energy entering the system, and \"U\" is the average internal energy leaving the system.\n\nThe region of space enclosed by the boundaries of the open system is usually called a control volume, and it may or may not correspond to physical walls. If we choose the shape of the control volume such that all flow in or out occurs perpendicular to its surface, then the flow of matter into the system performs work as if it were a piston of fluid pushing mass into the system, and the system performs work on the flow of matter out as if it were driving a piston of fluid. There are then two types of work performed: \"flow work\" described above, which is performed on the fluid (this is also often called \"pV work\"), and \"shaft work\", which may be performed on some mechanical device.\n\nThese two types of work are expressed in the equation\n\nSubstitution into the equation above for the control volume (cv) yields:\n\nThe definition of enthalpy, \"H\", permits us to use this thermodynamic potential to account for both internal energy and \"pV\" work in fluids for open systems:\n\nIf we allow also the system boundary to move (e.g. due to moving pistons), we get a rather general form of the first law for open systems. In terms of time derivatives it reads:\n\nwith sums over the various places \"k\" where heat is supplied, matter flows into the system, and boundaries are moving. The \"Ḣ\" terms represent enthalpy flows, which can be written as\n\nwith \"ṁ\" the mass flow and \"ṅ the molar flow at position \"k\" respectively. The term represents the rate of change of the system volume at position \"k\" that results in \"pV\" power done by the system. The parameter \"P\" represents all other forms of power done by the system such as shaft power, but it can also be e.g. electric power produced by an electrical power plant.\n\nNote that the previous expression holds true only if the kinetic energy flow rate is conserved between system inlet and outlet. Otherwise, it has to be included in the enthalpy balance. During steady-state operation of a device (\"see turbine, pump, and engine\"), the average may be set equal to zero. This yields a useful expression for the average power generation for these devices in the absence of chemical reactions:\n\nwhere the angle brackets denote time averages. The technical importance of the enthalpy is directly related to its presence in the first law for open systems, as formulated above.\n\nNowadays the enthalpy values of important substances can be obtained using commercial software. Practically all relevant material properties can be obtained either in tabular or in graphical form. There are many types of diagrams, such as \"h\"–\"T\" diagrams, which give the specific enthalpy as function of temperature for various pressures, and \"h\"–\"p\" diagrams, which give \"h\" as function of \"p\" for various \"T\". One of the most common diagrams is the temperature–specific entropy diagram (\"T\"–\"s\"-diagram). It gives the melting curve and saturated liquid and vapor values together with isobars and isenthalps. These diagrams are powerful tools in the hands of the thermal engineer.\n\nThe points a through h in the figure play a role in the discussion in this section.\n\nOne of the simple applications of the concept of enthalpy is the so-called throttling process, also known as Joule-Thomson expansion. It concerns a steady adiabatic flow of a fluid through a flow resistance (valve, porous plug, or any other type of flow resistance) as shown in the figure. This process is very important, since it is at the heart of domestic refrigerators, where it is responsible for the temperature drop between ambient temperature and the interior of the refrigerator. It is also the final stage in many types of liquefiers.\n\nIn the first law for open systems (see above) applied to the system, all terms are zero, except the terms for the enthalpy flow. Hence\n\nSince the mass flow is constant, the specific enthalpies at the two sides of the flow resistance are the same:\n\nthat is, the enthalpy per unit mass does not change during the throttling. The consequences of this relation can be demonstrated using the \"T\"–\"s\" diagram above. Point c is at 200 bar and room temperature (300 K). A Joule–Thomson expansion from 200 bar to 1 bar follows a curve of constant enthalpy of roughly 425 kJ/kg (not shown in the diagram) lying between the 400 and 450 kJ/kg isenthalps and ends in point d, which is at a temperature of about 270 K. Hence the expansion from 200 bar to 1 bar cools nitrogen from 300 K to 270 K. In the valve, there is a lot of friction, and a lot of entropy is produced, but still the final temperature is below the starting value!\n\nPoint e is chosen so that it is on the saturated liquid line with . It corresponds roughly with and . Throttling from this point to a pressure of 1 bar ends in the two-phase region (point f). This means that a mixture of gas and liquid leaves the throttling valve. Since the enthalpy is an extensive parameter, the enthalpy in f (\"h\") is equal to the enthalpy in g (\"h\") multiplied by the liquid fraction in f (\"x\") plus the enthalpy in h (\"h\") multiplied by the gas fraction in f . So\n\nWith numbers: , so \"x\" = 0.64. This means that the mass fraction of the liquid in the liquid–gas mixture that leaves the throttling valve is 64%.\n\nA power \"P\" is applied e.g. as electrical power. If the compression is adiabatic, the gas temperature goes up. In the reversible case it would be at constant entropy, which corresponds with a vertical line in the \"T\"–\"s\" diagram. For example, compressing nitrogen from 1 bar (point a) to 2 bar (point b) would result in a temperature increase from 300 K to 380 K. In order to let the compressed gas exit at ambient temperature \"T\", heat exchange, e.g. by cooling water, is necessary. In the ideal case the compression is isothermal. The average heat flow to the surroundings is \"Q̇\". Since the system is in the steady state the first law gives\n\nThe minimal power needed for the compression is realized if the compression is reversible. In that case the second law of thermodynamics for open systems gives\n\nEliminating \"Q̇\" gives for the minimal power\n\nFor example, compressing 1 kg of nitrogen from 1 bar to 200 bar costs at least . With the data, obtained with the \"T\"–\"s\" diagram, we find a value of 476 kJ/kg.\n\nThe relation for the power can be further simplified by writing it as\n\nWith , this results in the final relation\n\n\n\n"}
{"id": "10275", "url": "https://en.wikipedia.org/wiki?curid=10275", "title": "Erdoğan Atalay", "text": "Erdoğan Atalay\n\nErdoğan Atalay (born on September 22, 1966 in Hanover, West Germany) is a Turkish-German actor. \n\nIn 2017 he will marry his girlfriend and manager Katja Ohneck.\n\nHaving already made his first appearance as a minor actor in \"Aladdin and the miracle lamp\" at the National Theatre of Hanover before studying acting at the Hochschule für Musik und Theater Hamburg. Afterwards he took on first parts in several German television series such as \"Music Groschenweise\", \"Employment for Lohbeck\", \"Double Employment\" and \"The Guard\". In 1996 Action Concept engaged him for the role he has played successfully up to now: Semir Gerkhan in the German television series \"Alarm für Cobra 11 – Die Autobahnpolizei\".\n\n"}
{"id": "10277", "url": "https://en.wikipedia.org/wiki?curid=10277", "title": "Ennio Morricone", "text": "Ennio Morricone\n\nEnnio Morricone, (; born 10 November 1928) is an Italian composer, orchestrator, conductor, and former trumpet player. He composes a wide range of music styles, making him one of the most versatile, experimental and influential composers of all time, working in any medium. Since 1946 Morricone has composed over 500 scores for cinema and television, as well as over 100 classical works. His filmography includes over 70 award-winning films, including all Sergio Leone films since \"A Fistful of Dollars\" (including \"The Good, the Bad and the Ugly\" and \"Once Upon a Time in the West\"), all Giuseppe Tornatore films (since \"Cinema Paradiso\"), \"The Battle of Algiers\", Dario Argento's \"Animal Trilogy\", Bernardo Bertolucci's \"1900\", \"\", \"Days of Heaven\", several major films in French cinema, in particular the comedy trilogy \"La Cage aux Folles I\", \"II\", \"\" and \"Le Professionnel\", John Carpenter's \"The Thing\", \"The Mission\", \"The Untouchables\", \"Bugsy\", \"In the Line of Fire\", \"Disclosure\", \"Bulworth\", \"Mission to Mars\", \"Ripley's Game\" and \"The Hateful Eight\".\n\nAfter playing the trumpet in jazz bands in the 1940s, he became a studio arranger for RCA Victor and in 1955 started ghost writing for film and theatre. Throughout his career, he has composed music for artists such as Paul Anka, Mina, Milva, Zucchero and Andrea Bocelli. From 1960 to 1975, Morricone gained international fame for composing music for westerns. His score to 1966's \"The Good, the Bad and the Ugly\" is considered one of the most influential soundtracks in history and was inducted into the Grammy Hall of Fame. With an estimated 10 million copies sold, \"Once Upon a Time in the West\" is one of the best-selling scores worldwide. He also scored seven westerns for Sergio Corbucci, Duccio Tessari's \"Ringo\" duology and Sergio Sollima's \"The Big Gundown\" and \"Face to Face\". Morricone worked extensively for other film genres with directors such as Mauro Bolognini, Giuliano Montaldo, Roland Joffé, Roman Polanski and Henri Verneuil. His acclaimed soundtrack for \"The Mission\" (1986) was certified gold in the United States. The album \"Yo-Yo Ma Plays Ennio Morricone\" stayed 105 weeks on the Billboard Top Classical Albums.\n\nMorricone's best-known compositions include \"The Ecstasy of Gold\", \"Se Telefonando\", \"Man with a Harmonica\", \"Here's to You\", the UK No. 2 single \"Chi Mai\", \"Gabriel's Oboe\" and \"E Più Ti Penso\". He functioned during the period 1966–1980 as a main member of Il Gruppo, one of the first experimental composers collectives. In 1969, he co-founded Forum Music Village, a prestigious recording studio. From the 1970s, Morricone excelled in Hollywood, composing for prolific American directors such as Don Siegel, Mike Nichols, Brian De Palma, Barry Levinson, Oliver Stone, Warren Beatty and Quentin Tarantino. In 1977, he composed the official theme for the 1978 FIFA World Cup. He continued to compose music for European productions, such as \"Marco Polo\", \"La Piovra\", \"Nostromo\", \"Fateless\", \"\" and \"En mai, fais ce qu'il te plait\". Morricone's music has been reused in television series, including \"The Simpsons\" and \"The Sopranos\", and in many films, including \"Inglourious Basterds\" and \"Django Unchained\".\n\nAs of 2013, Ennio Morricone has sold over 70 million records worldwide. In 1971, he received a \"Targa d'Oro\" for the worldwide sales of 22 million. In 2007, he received the Academy Honorary Award \"for his magnificent and multifaceted contributions to the art of film music.\" He has been nominated for a further six Oscars. In 2016, Morricone received his first Academy Award for his score to Quentin Tarantino's film \"The Hateful Eight\" (2015). His other achievements include three Grammy Awards, three Golden Globes, six BAFTAs, ten David di Donatello, eleven Nastro d'Argento, two European Film Awards, the Golden Lion Honorary Award and the Polar Music Prize in 2010.\n\nMorricone was born in Rome, the son of Libera Ridolfi and Mario Morricone, a musician. His family came from Arpino, near Frosinone. Morricone, who had four siblings, Adriana, Aldo, Maria and Franca, lived in Trastevere, in the centre of Rome, with his parents. Mario was a trumpet player who worked professionally in different light-music orchestras, while Libera set up a small textile business.\n\nHis first teacher was his father Mario Morricone, who taught him how to read music and also to play several instruments. Compelled to take up the trumpet, he entered the National Academy of St Cecilia, to take trumpet lessons under the guidance of Umberto Semproni.\nMorricone formally entered the conservatory in 1940 at age 12, enrolling in a four-year harmony program. He completed it within six months. He studied the trumpet, composition, and choral music, under direction of Goffredo Petrassi, who influenced him; Morricone has since dedicated his concert pieces to Petrassi. In 1941, Morricone was chosen among the students of the National Academy of St Cecilia to be a part of the Orchestra of the Opera directed by Carlo Zecchi on the occasion of a tour of \"Veneto\" (the region of Venice). In 1946, he received his Diploma in Trumpet. After he graduated, he continued to work in classical composition and arrangement.\n\nAlthough the composer had received the \"Diploma in Instrumentation for Band Arrangement\" (fanfare) with a mark of 9/10 in 1952, his studies concluded at the Conservatory of Santa Cecilia in 1954 and obtained a final 9.5/10 in his Diploma in Composition, under the composer Goffredo Petrassi.\n\nMorricone wrote his first compositions when he was six years old and was encouraged to develop his natural talents. In 1946, he composed \"Il Mattino\" (\"The Morning\") for voice and piano on a text by Fukuko, first in a group of seven \"youth\" Lieder.\n\nIn the following years, he continued to write music for the theatre as well as classical music for voice and piano, such as \"Imitazione\", based on a text by Italian poet Giacomo Leopardi, \"Intimità\", based on a text by Olinto Dini, \"Distacco I\" and \"Distacco II\" with words by R. Gnoli, \"Oboe Sommerso\" for baritone and five instruments with words by poet Salvatore Quasimodo and \"Verrà la Morte\", for contralto and piano, based on a text by novelist Cesare Pavese.\n\nIn 1953, Morricone was asked by Gorni Kramer and Lelio Luttazzi to write an arrangement for some medleys in an American style for a series of evening radio shows. The composer continued with the composition of other 'serious' classical pieces, thus demonstrating the flexibility and eclecticism which has always been an integral part of his character. Many orchestral and chamber compositions date, in fact, from the period between 1954 and 1959: \"Musica per archi e pianoforte\" (1954), \"Invenzione, Canone e Ricercare per piano\"; \"Sestetto per flauto, oboe, fagotto, violino, viola e violoncello\" (1955), \"Dodici Variazione per oboe, violoncello e piano\"; \"Trio per clarinetto, corno e violoncello\"; \"Variazione su un tema di Frescobaldi\" (1956); \"Quattro pezzi per chitarra\" (1957); \"Distanze per violino, violoncello e piano\"; \"Musica per undici violini, Tre Studi per flauto, clarinetto e fagotto\" (1958); and the \"Concerto per orchestra\" (1957), dedicated to his teacher Goffredo Petrassi.\n\nMorricone soon gained popularity by writing his first background music for radio dramas and quickly moved into film.\n\nComposing for radio, television and pop artists\n\nMorricone's career as an arranger started in 1950, by arranging the piece \"Mamma Bianca\" (Narciso Parigi). In occasion of the \"Anno Santo\" (Holy Year), he arranged a long group of popular songs of devotion for radio broadcasting.\n\nIn 1956, Morricone started to support his family by playing in a jazz band and arranging pop songs for the Italian broadcasting service RAI. He was hired by RAI in 1958, but quit his job on his first day at work when he was told that broadcasting of music composed by employees was forbidden by a company rule. Subsequently, Morricone became a top studio arranger at RCA Victor, working with Renato Rascel, Rita Pavone, and Mario Lanza.\n\nThroughout his career Morricone has composed songs for several national and international jazz and pop artists. In 1962 Morricone worked with American jazz singer Helen Merrill as an arranger on an EP \"Helen Merrill sings Italian Songs\" on the RCA Italiana label. Gianni Morandi (\"Go Kart Twist\", 1962), Alberto Lionello (\"La donna che vale\", 1959), Edoardo Vianello (\"Ornella\", 1960; \"Cicciona cha-cha\", 1960; \"Faccio finta di dormire\", 1961; \"T'ho conosciuta\", 1963; ), Nora Orlandi (\"Arianna\", 1960), Jimmy Fontana (\"Twist no. 9\"; \"Nicole\", 1962), Rita Pavone (\"Come te non-ce nessuno\" and \"Pel di carota\" from 1962, arranged by Luis Bacalov), Catherine Spaak (\"Penso a te\"; \"Questi vent'anni miei\", 1964), Luigi Tenco (\"Quello che conta\"; \"Tra tanta gente\"; 1962), Gino Paoli (\"Nel corso\" from 1963, written by Morricone with Paoli), Renato Rascel (\"Scirocco\", 1964), Paul Anka (\"Ogni Volta\"), Amii Stewart, Rosy Armen (\"L'Amore Gira\"), Milva (\"Ridevi\", \"Metti Una Sera A Cena\"), Françoise Hardy (\"Je changerais d'avis\", 1966), Mireille Mathieu (\"Mon ami de toujours\"; \"Pas vu, pas pris\", 1971; \"J'oublie la pluie et le soleil\", 1974) and Demis Roussos (\"I Like The World\", 1970).\n\nIn 1963, the composer co-wrote (with Roby Ferrante) the music for the composition \"Ogni volta\" (\"Every Time\"), a song that was performed by Paul Anka for the first time during the Festival di San Remo in 1964. This song was arranged and conducted by Morricone and sold over three million copies worldwide, including one million copies in Italy alone.\n\nAnother particular success was his composition, \"Se telefonando.\" Performed by Mina, it was a standout track of \"Studio Uno 66\", the fifth-biggest-selling album of the year 1966 in Italy. Morricone's sophisticated arrangement of \"Se telefonando\" was a combination of melodic trumpet lines, Hal Blaine–style drumming, a string set, a '60s Europop female choir, and intensive subsonic-sounding trombones. The Italian Hitparade No. 7 song had eight transitions of tonality building tension throughout the chorus. During the following decades, the song was covered by several performers in Italy and abroad most notably by Françoise Hardy and Iva Zanicchi (1966), Delta V (2005), Vanessa and the O's (2007), and Neil Hannon (2008). \"Françoise Hardy – Mon amie la rose\" site in the reader's poll conducted by the la Repubblica newspaper to celebrate Mina's 70th anniversary in 2010, 30,000 voters picked the track as the best song ever recorded by Mina.\n\nIn 1987, Morricone co-wrote 'It Couldn't Happen Here' with the Pet Shop Boys. Other notable compositions for international artists include: \"La metà di me\" and \"Immagina\" (1988) by Ruggero Raimondi, \"Libera l'amore\" (1989) performed by Zucchero, \"Love Affair\" (1994) by k.d. lang, \"Ha fatto un sogno\" (1997) by Antonello Venditti, \"Di Più\" (1997) by Tiziana Tosca Donati, \"Come un fiume tu\" (1998), \"Un Canto\" (1998) and \"Conradian\" (2006) by Andrea Bocelli, \"Ricordare\" (1998) and \"Salmo\" (2000) by Angelo Branduardi and \"My heart and I\" (2001) by Sting.\n\nFirst film scores\n\nAfter graduating in 1954, Morricone started writing and arranging music as a ghost writer for films credited to other already well-known composers, while also arranging for many light music orchestras of the RAI television network, working most notably with Armando Trovajoli, Alessandro Cicognini and Carlo Savina. He occasionally adopted Anglicized pseudonyms, such as Dan Savio and Leo Nichols.\n\nIn 1959, Morricone was the conductor (and uncredited co-composer) for Mario Nascimbene's score to \"Morte Di Un Amico\" (Death of a Friend), an Italian drama directed by Franco Rossi. In the same year, he composed music for the theatre show \"Il Lieto Fine\" by Luciano Salce.\n\nThe 1960s began on a positive note: 1961 marked in fact his real film debut with Luciano Salce's \"Il Federale (The Fascist)\". In an interview with American composer Fred Karlin, Morricone discussed his beginnings, stating, \"My first films were light comedies or costume movies that required simple musical scores that were easily created, a genre that I never completely abandoned even when I went on to much more important films with major directors\".\n\n\"Il Federale\" marked the beginning of a long-run collaboration with Luciano Salce. In 1962 Morricone composed the jazz-influenced score for Salce's comedy \"La voglia matta (Crazy Desire)\". That year Morricone arranged also Italian singer Edoardo Vianello's summer hit \"Pinne, Fucile e Occhiali\", a cha-cha song, peppered with added water effects, unusual instrumental sounds and unexpected stops and starts.\n\nMorricone wrote more works in the climate of the Italian avant-garde. A few of these compositions have been made available on CD, such as \"Ut\", his trumpet concerto dedicated to the soloist Mauro Maur, one of his favorite musicians; some have yet to be premiered.\n\nFrom 1964 up to their eventual disbandment in 1980, he was part of Gruppo di Improvvisazione di Nuova Consonanza (G.I.N.C.), a group of composers who performed and recorded avant garde free improvisations. The Rome-based avant-garde ensemble was dedicated to the development of improvisation and new music methods. The ensemble functioned as a laboratory of sorts, working with anti-musical systems and noise techniques in an attempt to redefine the new music ensemble and explore \"New Consonance.\"\n\nKnown as \"The Group\" or \"Il Gruppo,\" they released seven albums across the Deutsche Grammophon, RCA and Cramps labels: \"Gruppo di Improvvisazione Nuova Consonanza\" (1966), \"The Private Sea of Dreams\" (1967), \"Improvisationen\" (1968), \"The Feed-back\" (1970), \"Improvvisazioni a Formazioni Variate\" (1973), \"Nuova Consonanza\" (1975) and \"Musica su Schemi\" (1976). Perhaps the most famous of these is their album entitled \"The Feed-back\", which combines free jazz and avant-garde classical music with funk; the album is frequently sampled by hip-hop DJs and is considered to be one of the most collectable records in existence, often fetching over $1,000 at auction.\n\nMorricone played a key role in The Group and was among the core members in its revolving line-up; in addition to serving as their trumpet player, he directed them on many occasions and they can be heard on a large number of his scores from the 1970s.\n\nHeld in high regard in avant-garde music circles, they are considered to be the first experimental composers collective, their only peers being the British improvisation collective AMM. Their influence can be heard in free improvising ensembles from the European movements including Evan Parker Electro-Acoustic Ensemble, the Swiss electronic free improvisation group Voice Crack, John Zorn and in the techniques of modern classical music and avant-garde jazz groups. The ensemble's groundbreaking work informed their work in composition. The ensemble did also perform in varying capacities with Morricone adding noise to some of his '60s and '70s Italian soundtracks, including \"A Quiet Place in the Country\" (1969) and \"Cold Eyes of Fear\" (1971).\n\nHis earliest scores were Italian light comedy and costume pictures, where Morricone learned to write simple, memorable themes. During the sixties and seventies he composed the scores for comedies such as \"Diciottenni al sole\" (1962), \"Il Successo\" (1963), Lina Wertmüller's \"I basilischi\" (1963), \"Slalom\" (1965), \"Menage all'italiana\" (1965), \"How I Learned to Love Women\" (1966), \"L'harem\" (1967), \"A Fine Pair\" (1968), \"L'Alibi\" (1969), \"Questa specie d'amore\" (1972), \"Forza \"G\"\" (1972) and \"Fiorina la vacca\" (1972).\n\nHis best-known scores for comedies includes \"La Cage aux Folles\" (1978) and \"La Cage aux Folles II\" (1980), both directed by Édouard Molinaro, \"Il ladrone\" (1980), Georges Lautner's \"\" (1985), Pedro Almodóvar's \"Tie Me Up! Tie Me Down!\" (1990) and Warren Beatty's \"Bulworth\" (1998). Morricone has never ceased to arrange and write music for comedies. In 2007, he composed a lighthearted score for the Italian romantic comedy \"Tutte le Donne della mia Vita\" by Simona Izzo, the director who co-wrote the Morricone-scored religious mini-series \"Il Papa Buono\".\n\nThough his first films were undistinguished, Morricone's arrangement of an American folk song intrigued director and former schoolmate Sergio Leone. Before being associated with Leone, Morricone had already composed some music for less-known western movies such as \"Duello nel Texas\" (aka \"Gunfight at Red Sands\") (1963). In 1962, Morricone met American folksinger Peter Tevis, who is credited with singing the lyrics of Morricone's songs such as \"A Gringo Like Me\" (from \"Gunfight at Red Sands\") and \"Lonesome Billy\" (from \"Bullets Don't Argue\").\n\nAssociation with Sergio Leone\n\nThe turning point in Morricone's career took place in 1964, the year in which his third child, Andrea Morricone, who would also become a film composer, was born. Film director Sergio Leone hired Morricone, and together they created a distinctive score to accompany Leone's different version of the Western, \"A Fistful of Dollars\" (1964).\n\nThe \"Dollars\" trilogy\nBecause budget strictures limited Morricone's access to a full orchestra, he used gunshots, cracking whips, whistle, voices, jew's harp, trumpets, and the new Fender electric guitar, instead of orchestral arrangements of Western standards à la John Ford. Morricone used his special effects to punctuate and comically tweak the action—cluing in the audience to the taciturn man's ironic stance. Though sonically bizarre for a movie score, Morricone's music was viscerally true to Leone's vision.\n\nAs memorable as Leone's close-ups, harsh violence, and black comedy, Morricone's work helped to expand the musical possibilities of film scoring. Morricone was initially billed on the film as Dan Savio. \"A Fistful of Dollars\" came out in Italy in 1964 and was released in America three years later, greatly popularizing the so-called Spaghetti Western genre. For the American release, Sergio Leone and Ennio Morricone decided to adopt American-sounding names, so they called themselves respectively Bob Robertson and Dan Savio. Over the film's theatrical release, it grossed more than any other Italian film up to that point. The film debuted in the United States in January 1967, where it grossed for the year. It eventually grossed $14.5 million in its American release, against its budget of 200–250,000.\n\nWith the score of \"A Fistful of Dollars\", Morricone began his 20-year collaboration with his childhood friend Alessandro Alessandroni and his Cantori Moderni. Alessandroni provided the whistling and the twanging guitar on the film scores, while his Cantori Moderni were a flexible troupe of modern singers. Morricone specifically exploited the solo soprano of the group, Edda Dell'Orso, at the height of her powers \"an extraordinary voice at my disposal\".\n\nThe composer subsequently scored Leone's other two \"Dollars Trilogy\" (or \"Man With No Name Trilogy\") spaghetti westerns: \"For a Few Dollars More\" (1965) and \"The Good, the Bad and the Ugly\" (1966). All three films starred the American actor Clint Eastwood as \"The Man With No Name\" and depicted Leone's own intense vision of the mythical West. Some of the music was written before the film, which was unusual. Leone's films were made like that because he wanted the music to be an important part of it; he kept the scenes longer because he did not want the music to end. According to Morricone this explains why the films are so slow.\n\nDespite the small film budgets, the \"Dollars Trilogy\" was a box-office success. The available budget for \"The Good, the Bad and The Ugly\" was about 1.2 million, but it became the most successful film of the \"Dollars Trilogy\", grossing 25.1 million in the United States and over 2,3 billion lire (1,2 million EUR) in Italy alone. Morricone's score became a major success and sold over three million copies worldwide. On 14 August 1968 the original score was certified by the RIAA with a golden record for the sale of 500,000 copies in the United States only.\n\nThe main theme of \"For a Few Dollars More\" (\"Per Qualche Dollaro in Più\") was covered by Hugo Montenegro (\"For a Few Dollars More\"), Babe Ruth (\"Theme From a Few Dollars More\"), Golden Palominos (\"For A Few Dollars More\"), Material (\"For a Few Dollars More\"), and Matti Heinivaho (\"Arosusi\"). More recently, a Techno-Industrial cover was done by Komor Kommando (\"Hasta Luego\"). A remix was done by Terranova, \"For a Few Dollars More (Terranova Remix)\".\n\nHugo Montenegro's version of the main theme of \"The Good, the Bad and the Ugly\" sold over one million copies worldwide. Montenegro's album with the same name included a selection of Morricone's compositions from the \"Dollars Trilogy\". In the United States, the album was certified gold by the RIAA on 9 September 1969. The main theme was later sampled by artists such as Cameo (\"Word Up!\"), Bomb the Bass and LL Cool J.\n\n\"The Ecstasy of Gold\" became one of Morricone's best-known compositions. The opening scene of Jeff Tremaine's \"Jackass Number Two\" (2006), in which the cast is chased through a suburban neighborhood by bulls, is accompanied by this piece. While punk rock band the Ramones used \"The Ecstasy of Gold\" as closing theme during their live performances, Metallica uses \"The Ecstasy of Gold\" as the introductory music for its concerts since 1983 This composition is also included on Metallica's live symphonic album \"S&M\" as well as the live album \"\". An instrumental metal cover by Metallica (with minimal vocals by lead singer James Hetfield) appeared on the 2007 Morricone tribute album \"We All Love Ennio Morricone\". This metal version was nominated for a Grammy Award in the category of Best Rock Instrumental Performance. In 2009, the Grammy Award-winning hip-hop artist Coolio extensively sampled the theme for his song \"Change\".\n\nOnce Upon a Time in the West and others\nSubsequent to the success of the \"Dollars trilogy\", Morricone composed also the scores for \"Once Upon a Time in the West\" (1968) and Leone's last credited western film \"A Fistful of Dynamite\" (1971), as well as the scores for \"My Name Is Nobody\" (1973) and \"A Genius, Two Partners and a Dupe\" (1975), produced by Sergio Leone.\n\nMorricone's score for \"Once Upon a Time in the West\" is one of the best-selling original instrumental scores in the world today, with up to 10 million copies sold, including one million copies in France and over 800,000 copies in the Netherlands. One of the main themes from the score, \"A Man with Harmonica\" (L'uomo Dell'armonica), became worldwide known and sold over 1,260,000 copies in France alone. This theme was later sampled in popular songs such as Beats International's \"Dub Be Good to Me\" (1990) and The Orb's ambient single \"Little Fluffy Clouds\" (1990). Film composer Hans Zimmer sampled \"A Man with Harmonica\" in 2007 as part of his composition \"Parlay\" (from the soundtrack \"\").\n\nThe collaboration with Leone is considered one of the exemplary collaborations between a director and a composer. Morricone's last score for Leone was for his last film, the gangster drama \"Once Upon a Time in America\" (1984). Leone died on 30 April 1989 of a heart attack at the age of 60. Before his death in 1989, Leone was part-way through planning a film on the Siege of Leningrad, set during World War II. By 1989, Leone had been able to acquire 100 million in financing from independent backers for the war epic. He had convinced Morricone to compose the film score. The project was canceled when Leone died two days before he was to officially sign on for the film. In early 2003, Italian filmmaker Giuseppe Tornatore announced he would direct a film called \"Leningrad\". The film has yet to go into production and Morricone has been cagey thus far as to details on account of Tornatore's superstitious nature.\n\nAssociation with Sergio Corbucci and Sergio Sollima\n\nTwo years after the start of his collaboration with Sergio Leone, Morricone also started to score music for another Spaghetti Western director, Sergio Corbucci. The composer wrote music for Corbucci's \"Navajo Joe\" (1966), \"The Hellbenders\" (1967), \"The Mercenary/The Professional Gun\" (1968), \"The Great Silence\" (1968), \"Compañeros\" (1970), \"Sonny and Jed\" (1972) and \"What Am I Doing in the Middle of the Revolution?\" (1972).\n\nIn addition, Morricone composed music for the western films by Sergio Sollima, \"The Big Gundown\" (with Lee Van Cleef, 1966), \"Face to Face\" (1967) and \"Run, Man, Run!\" (1968), as well as the 1970 crime thriller \"Violent City\" (with Charles Bronson) and the poliziottesco film \"Revolver\" (1973).\n\nOther westerns\nOther relevant scores for less popular Spaghetti Westerns include \"Duello nel Texas\" (1963), \"\" (1964), \"A Pistol for Ringo\" (1965), \"The Return of Ringo\" (1965), \"Seven Guns for the MacGregors\" (1966), \"The Hills Run Red\" (1966), Giulio Petroni's \"Death Rides a Horse\" (1967) and \"Tepepa\" (1968), \"A Bullet for the General\" (1967), \"Guns for San Sebastian\" (with Charles Bronson and Anthony Quinn, 1968), \"A Sky Full of Stars for a Roof\" (1968), \"The Five Man Army\" (1969), Don Siegel's \"Two Mules for Sister Sara\" (1970), \"Life Is Tough, Eh Providence?\" (1972) and \"Buddy Goes West\" (1981).\n\nWith Leone's films, Ennio Morricone's name had been put firmly on the map. Most of Morricone's film scores of the 1960s were composed outside the Spaghetti Western genre, while still using Alessandroni's team. Their music included the themes for \"Il Malamondo\" (1964), \"Slalom\" (1965) and \"Listen, Let's Make Love\" (1967). In 1968, Morricone reduced his work outside the movie business and wrote scores for 20 films in the same year. The scores included psychedelic accompaniment for Mario Bava's superhero romp \"\" (1968)\n\nHis talent and creativity were such that many other directors were soon keen to collaborate with him, and in the next few years Morricone scored a lot of films by politically committed directors: collaborating with Marco Bellocchio (\"Fists in the Pocket\", 1965), Gillo Pontecorvo (\"The Battle of Algiers\" (1966) and \"Queimada!\" (1969) with Marlon Brando), Roberto Faenza (H2S, 1968), Giuliano Montaldo (\"Sacco e Vanzetti\", 1971), Giuseppe Patroni Griffi (\"'Tis Pity She's a Whore\", 1971), Mauro Bolognini (\"Drama of the Rich\", 1974), Umberto Lenzi (\"Almost Human\", 1974), Pier Paolo Pasolini (\"Salò, or the 120 Days of Sodom\", 1975), Bernardo Bertolucci (\"Novecento\", 1976) and Tinto Brass (\"The Key\", 1983).\n\nIn 1970, Morricone wrote the score for \"Violent City\". That same year, he received his first Nastro d'Argento for the music in \"Metti una sera a cena\" (Giuseppe Patroni Griffi, 1969) and his second only a year later for \"Sacco e Vanzetti\" (Giuliano Montaldo, 1971), in which he had made a memorable collaboration with the legendary American folk singer and activist Joan Baez. His soundtrack for \"Sacco e Vanzetti\" contains another well-known composition by Morricone, the folk song \"Here's to You\", sung by Joan Baez. For the writing of the lyrics, Baez was inspired by a letter from Bartolomeo Vanzetti: \"\"Father, yes, I am a prisoner / Fear not to relay my crime\"\". The song became a hit in several countries, selling over 790,000 copies in France only. The song was later included in movies such as \"The Life Aquatic with Steve Zissou\" and in the video game \"\" as the closing theme as well as .\n\nIn the same year, Morricone composed the score for the less-known drama \"Maddalena\" (1971) by the Polish film director Jerzy Kawalerowicz which included its composition 'Chi Mai'. The theme appeared on the million-selling score for Georges Lautner's \"Le Professionnel\" (1981), as well as the TV series, \"An Englishman's Castle\" (1978) and \"The Life and Times of David Lloyd George\" (1981). Because of its appearance on the latter, \"Chi Mai\" reached number 2 on the UK Singles Chart in 1981. The single was certified by the BPI with a golden record on 1 May 1981 and sold over 900,000 copies in France alone. \"Chi Mai\" is also the name of the online community about Morricone, which offers a repository of information and a free online magazine called \"Maestro\", containing reviews, articles, discoveries and free comments.\n\nIn the beginning of the 1970s, Morricone achieved success with other singles, including \"A Fistful of Dynamite\" (1971) and \"God With Us\" (1974), having sold respectively 477,000 and 378,000 copies in France only.\n\nBetween 1967 and 1993 the composer had a long-term collaboration with director Mauro Bolognini. Morricone wrote more than 15 film scores for Bolognini, including \"Le streghe\" (1966), \"L'assoluto naturale\" (1969), \"Un bellissimo novembre\" (1969), \"Metello\" (1970), \"Chronicle of a Homicide\" (1972), \"Libera, My Love\" (1973), \"Per le antiche scale\" (1975), \"La Dame aux camelias\" (1980), \"Mosca addio\" (1987), \"Gli indifferenti\" (1988) and \"Husband and Lovers\" (1992).\n\nEnnio Morricone's eclecticism and knack for creating highly poignant, melodic and emotional music found great scope also in horror movies, such as the baroque thrillers of Dario Argento, from \"The Bird with the Crystal Plumage\" (1969), \"The Cat o' Nine Tails\" (1970) and \"Four Flies on Grey Velvet\" (1971) to \"The Stendhal Syndrome\" (1996) and \"The Phantom of the Opera\" (1998). His other horror scores include \"Nightmare Castle\" (1965), \"A Quiet Place in the Country\" (1968), \"The Antichrist\" (1974), \"Autopsy\" (1975) and \"Night Train Murders\" (1975).\n\nIn addition, Morricone's music has also been featured in many popular and cult Italian giallo films, such as \"Senza sapere niente di lei\" (1969), \"Forbidden Photos of a Lady Above Suspicion\" (1970), \"A Lizard in a Woman's Skin\" (1971), \"Cold Eyes of Fear\" (1971), \"The Fifth Cord\" (1971), \"Short Night of Glass Dolls\" (1971), \"My Dear Killer\" (1972), \"What Have You Done to Solange?\" (1972), \"Black Belly of the Tarantula\" (1972), \"Who Saw Her Die?\" (1972) and \"Spasmo\" (1974).\n\nIn 1977 Morricone scored Alberto De Martino's apocalyptic horror film \"Holocaust 2000\", starring Kirk Douglas. In 1982 he composed the score for John Carpenter's science fiction horror movie \"The Thing\". Morricone's main theme for the film was reflected in Marco Beltrami's film's score of the prequel of the 1982 film, which was released in 2011.\n\nThe \"Dollars Trilogy\" was not released in the United States until 1967 when United Artists, who had already enjoyed success distributing the British-produced James Bond films in the United States, decided to release Sergio Leone's Spaghetti Westerns. The American release gave Morricone an exposure in America and his film music became quite popular in the United States.\n\nOne of Morricone's first contributions to an American director concerned his music for the religious epic film \"\" by John Huston. According to Sergio Miceli's book \"Morricone, la musica, il cinema\", Morricone wrote about 15 or 16 minutes of music, which were recorded for a screen test and conducted by Franco Ferrara. At first Morricone's teacher Goffredo Petrassi had been engaged to write the score for the great big budget epic, but Huston preferred another composer. RCA Records then proposed Morricone who was under contract with them, but a conflict between the film's producer Dino De Laurentiis and RCA occurred. The producer wanted to have the exclusive rights for the soundtrack, while RCA still had the monopoly on Morricone at that time and did not want to release the composer. Subsequently, Morricone's work was rejected because he did not get the ok by RCA to work for Dino De Laurentiis alone. The composer reused the parts of his unused score for \"The Bible: In the Beginning\" in such films as \"The Return of Ringo\" (1965) by Duccio Tessari and Alberto Negrin's \"The Secret of the Sahara\" (1987).\n\nMorricone never left Rome to compose his music and never learned to speak English. But given that the composer has always worked in a wide field of composition genres, from absolute music, which he has always produced, to applied music, working as orchestrator as well as conductor in the recording field, and then as a composer for theatre, radio and cinema, the impression arises that he never really cared that much about his standing in the eyes of Hollywood.\n\nIn 1970, Morricone composed the music for Don Siegel's \"Two Mules for Sister Sara\", an American-Mexican western film starring Shirley MacLaine and Clint Eastwood. The same year the composer also delivered the title theme \"The Men from Shiloh\" for the American Western television series The Virginian<ref name=\"http://www.youtube.com/watch?v=8xna6GjwSJ0&feature=related\"></ref> and the score for Phil Karlson's war film \"Hornets' Nest\", starring Rock Hudson, and scored \"Bluebeard\", starring Richard Burton, two years later.\n\nIn 1974 Morricone wrote music for some unknown episodes of the science-fiction television series \"\", directed by Lee H. Katzin, and the following year he scored the George Kennedy revenge thriller \"The 'Human' Factor\", which was the final film of director Edward Dmytryk. Two years later he composed the score for the sequel to William Friedkin's 1973 film \"The Exorcist\", directed by John Boorman: \"\". The horror film was a major disappointment at the box office. The film grossed 30,749,142 in the United States, turning a profit but still disappointing in comparison to the original film's gross. The same year he scored the Dino De Laurentiis produced adventure film \"Orca\", starring Richard Harris, which was also only a minor hit but later developed a cult following.\n\nIn 1978, the composer worked with Terrence Malick for \"Days of Heaven\", starring Richard Gere. During the lengthy editing process of the romantic drama, which won an Academy Award for Best Cinematography with an additional three nominations for the score, Terrence Malick and Billy Weber made use of a temporary score dominated by Morricone's music for the Bernardo Bertolucci film \"Novecento\". Malick also chose the ethereal Aquarium music from Camille Saint-Saëns (\"The Carnival of the Animals\") to frame the film. When Malick decided he wanted Morricone to score his movie, the director sent a version of it to Italy with the Novecento temp track in place. Morricone agreed to the assignment and Malick flew to Italy because the composer did not fly, so would not travel to the United States. Malick took the movie over to Morricone in Italy and Morricone was writing for \"Days of Heaven\" the whole time. Afterwards they scored the music in Italy. In \"Days of Heaven\", Morricone's elegiac music coexists with pre-existing selections.\n\nDespite the fact that Morricone had produced some of the most popular and widely imitated film music ever written throughout the 1960s and '70s, \"Days of Heaven\" earned him his first Oscar nomination for Best Original Score, with his score up against Jerry Goldsmith's \"The Boys from Brazil\", Dave Grusins \"Heaven Can Wait\", Giorgio Moroders' \"Midnight Express\" (the eventual winner) and John Williams' \"\" at the Oscar ceremonies in 1979.\n\nIn 1979, Morricone provided the music for the thriller \"Bloodline\", directed by Terence Young, best known for directing the James Bond films \"Dr. No\" (1962), \"From Russia with Love\" (1963), and \"Thunderball\" (1965). Subsequently, the composer was asked to score Michael Ritchie's \"The Island\" (1980, starring Michael Caine), Gordon Willis's thriller \"Windows\" (1980), Andrew Bergman's comedy \"So Fine\" (1981) starring Ryan O'Neal, Matt Cimber's film \"Butterfly\" (1982), starring Pia Zadora, Samuel Fuller's controversial drama film \"White Dog\" (1982) and \"Thieves After Dark\" (1984), Jerry London's critically acclaimed TV movie \"The Scarlet and the Black\" (1983), starring Gregory Peck, and Richard Fleischers box office bomb \"Red Sonja\" (1985), starring Arnold Schwarzenegger and Brigitte Nielsen.\n\nMorricone's most fruitful and often long-term collaborations have been with Hollywood-related directors such as Brian De Palma, Barry Levinson, Warren Beatty, Oliver Stone and especially Roland Joffé, for whom Morricone wrote one of his best-known scores, the highly evocative soundtrack for \"The Mission\" (1986).\n\nAssociation with Roland Joffé\n\"The Mission\", directed by Joffé, was about a piece of history considerably more distant, as Spanish Jesuit missionaries see their work undone as a tribe of Paraguayan natives fall within a territorial dispute between the Spanish and Portuguese. Morricone's score is considered as an example of an absolute pinnacle of what music can do for a film, and what a soundtrack album can do to enrich the listener's life. At one point the score was one of the world's best-selling film scores, selling over 3 million copies worldwide.\n\nMorricone finally received a second Oscar nomination for \"The Mission\". Morricone's original score lost out to Herbie Hancock's coolly arranged jazz on Bertrand Tavernier's \"Round Midnight\". It was considered as a surprising win and a controversial one, given that much of the music in the film was pre-existing. Morricone stated the following during a 2001 interview with \"The Guardian\": \"I definitely felt that I should have won for The Mission. Especially when you consider that the Oscar-winner that year was Round Midnight, which was not an original score. It had a very good arrangement by Herbie Hancock, but it used existing pieces. So there could be no comparison with The Mission. There was a theft!\" His score for \"The Mission\" was ranked at number 1 in a poll of the all-time greatest film scores. The top 10 list was compiled by 40 film composers such as Michael Giacchino and Carter Burwell. The score is ranked 23rd on the AFI's list of 25 greatest film scores of all time.\n\nThe composer wrote also the music for three other movies by Joffé: \"Fat Man and Little Boy\" (1989, starring Paul Newman), \"City of Joy\" (1992, starring Patrick Swayze) and the opening film for the 2000 Cannes Film Festival, \"Vatel\", starring Gérard Depardieu, Uma Thurman and Tim Roth.\n\nAssociation with De Palma and Levinson\n\nOn three occasions, Brian De Palma worked with Morricone: \"The Untouchables\" (1987), the 1989 war drama \"Casualties of War\" and the science fiction film \"Mission to Mars\" (2000). De Palma's \"The Untouchables\", starring rising star Kevin Costner as Eliot Ness, Robert De Niro as Al Capone and the Oscar-winning Sean Connery, was released in 1987. Morricone's score for \"The Untouchables\" resulted in his third nomination for Academy Award for Best Original Score.\n\nIn a 2001 interview with \"The Guardian\", Morricone stated that he had good experiences with De Palma: \"De Palma is delicious! He respects music, he respects composers. For The Untouchables, everything I proposed to him was fine, but then he wanted a piece that I didn't like at all, and of course we didn't have an agreement on that. It was something I didn't want to write – a triumphal piece for the police. I think I wrote nine different pieces for this in total and I said, 'Please don't choose the seventh!' because it was the worst. And guess what he chose? The seventh one. But it really suits the movie.\"\n\nAnother American director, Barry Levinson, commissioned the composer on two occasions. First, for the crime-drama \"Bugsy\", starring Warren Beatty, which received ten Oscar nominations, winning two for Best Art Direction-Set Decoration (Dennis Gassner, Nancy Haigh) and Best Costume Design.\n\nThe highest-grossing American movie for which the composer wrote a complete score was for Levinson's \"Disclosure\" in 1994, starring Michael Douglas and Demi Moore.\n\n\"He doesn't have a piano in his studio, I always thought that with composers, you sit at the piano, and you try to find the melody. There's no such thing with Morricone. He hears a melody, and he writes it down. He hears the orchestration completely done\", said Barry Levinson in an interview.\n\nOther notable Hollywood scores\n\nDuring his career in Hollywood, Morricone was approached for numerous other projects, including the Gregory Nava drama \"A Time of Destiny\" (1988), \"Frantic\" by Polish-French director Roman Polanski (1988, starring Harrison Ford), Franco Zeffirelli's 1990 drama film \"Hamlet\" (starring Mel Gibson and Glenn Close), the neo-noir crime film \"State of Grace\" by Phil Joanou (1990, starring Sean Penn and Ed Harris), \"Rampage\" (1992) by William Friedkin, and the romantic drama \"Love Affair\" (1994) by Warren Beatty.\n\nNone of the aforementioned films were box office successes, but fortunately Morricone was also commissioned for more successful motion pictures such as \"In the Line of Fire\" (1993) by Wolfgang Petersen, starring Clint Eastwood and John Malkovich, the horror film \"Wolf\" (1994, Mike Nichols), which featured Jack Nicholson and Michelle Pfeiffer in the lead roles, and \"Bulworth\" by Warren Beatty.\n\nIn 1997, Morricone composed the music for \"Lolita\" (by Adrian Lyne) and Oliver Stone's \"U Turn\", starring Sean Penn and Jennifer Lopez. A year later, Ennio Morricone wrote a complete score for the 1998 drama \"What Dreams May Come\", but Vincent Ward found the music too emotional and replaced Morricone with Michael Kamen.\n\nOne of his last complete scores for an American-related project includes the 2002 thriller \"Ripley's Game\", starring John Malkovich, by Liliana Cavani.\n\nExtensive reuse of his music\n\nBesides the 500 original film scores that have been composed by Morricone for movies and television series in a career of over six decades, his music is in addition frequently reused in more than 150 other film projects. Morricone's compositions appeared in the German TV series \"Derrick\" (1989), the live-action comedy film \"Inspector Gadget\", \"Ally McBeal\" (2001), \"The Simpsons\" (2002), \"The Sopranos\" (2001–2002) and more recently in \"Dancing with the Stars\" (2010).\n\nQuentin Tarantino borrowed Morricone's music for several of his films. The Main Title of \"Death Rides a Horse\" (1967) can be heard in \"\", while \"\" contains music originally from \"For a Few Dollars More\", \"The Good, the Bad and the Ugly\", \"The Mercenary\" and \"Navajo Joe\". The themes \"Paranoia Prima\" and \"Unexpected Violence\" (\"Violenza inattesa\"), originally from respectively \"The Cat o' Nine Tails\" and \"The Bird with the Crystal Plumage\", were used in \"Death Proof\" (2007) by Tarantino.\n\nIn 2010, Tarantino originally wanted Morricone to compose the film score for \"Inglourious Basterds\". Morricone was unable to, because the film's sped-up production schedule conflicted with his scoring of Giuseppe Tornatore's \"Baarìa\". However, Tarantino did use eight tracks composed by Morricone in the film, with four of them included on the soundtrack. The tracks came originally from Morricone's scores for \"The Big Gundown\" (1966), \"Revolver\" (1973) and \"Allonsanfàn\" (1974).\n\nIn 2012, Morricone composed the song \"Ancora Qui\" with lyrics by Italian singer Elisa for Tarantino's \"Django Unchained\", a track that appeared together with three existing music tracks composed by Morricone on the soundtrack. \"Ancora Qui\" was one of the contenders for an Academy Award nomination in the Best Original Song category, but eventually the song was not nominated. On 4 January 2013 Morricone presented Tarantino with a Life Achievement Award at a special ceremony being cast as a continuation of the International Rome Film Festival. In 2014, Morricone claimed that he would \"never work\" with Tarantino again, but later agreed to write an original film score for Tarantino's \"The Hateful Eight\", which won an Academy Award in 2016 in the Best Original Score category. His nomination for this film marks him as the second oldest nominee in Academy history, behind Gloria Stuart. Morricone's win marked his first competitive Oscar, and at the age of 87 he became the oldest person to win a competitive Oscar.\n\nIn 2014, Morricone's song \"Giù La Testa\" was featured in Florian Habicht's feature film \"Pulp: a Film about Life, Death & Supermarkets\", an unconventional rockumentary about British group Pulp which premiered at SXSW that year.\n\nIn 1988 Morricone started an ongoing and very successful collaboration with Italian director Giuseppe Tornatore. His first score for Tornatore was for the drama film \"Cinema Paradiso\". The international version of the film won the Special Jury Prize at the 1989 Cannes Film Festival and the 1989 Best Foreign Language Film Oscar. In 2002, the director's cut 173-minute version was released (known in the U.S. as Cinema Paradiso: The New Version). Morricone received a BAFTA award and a David di Donatello for his score.\n\nAfter the success of \"Cinema Paradiso\", the composer wrote the music for all subsequent films by Tornatore: the drama film \"Everybody's Fine\" (Stanno Tutti Bene, 1990), \"A Pure Formality\" (1994) starring Gérard Depardieu and Roman Polanski, \"The Star Maker\" (1995), \"The Legend of 1900\" (1998) starring Tim Roth, the 2000 romantic drama \"Malèna\" (which featured Monica Bellucci) and the psychological thriller mystery film \"La sconosciuta\" (2006).\n\nMore recently, Morricone composed the scores for \"Baarìa - La porta del vento\" (2009), \"The Best Offer\" (2013) starring Geoffrey Rush, Jim Sturgess and Donald Sutherland and the romantic drama \"The Correspondence\" (2015) starring Jeremy Irons and Olga Kurylenko.\n\nThe composer won several music awards for his scores to Tornatore's movies. So, Morricone received a fifth Academy Award nomination and a Golden Globe nomination for \"Malèna\". For \"Legend of 1900\", he won a Golden Globe Award for Best Original Score.\n\nMorricone has worked for television, from a single title piece to variety shows and documentaries to TV series, including \"Moses the Lawgiver\" (1974), \"The Life and Times of David Lloyd George\" (1981), \"Marco Polo\" (1982) (which won two Primetime Emmys), \"The Secret of the Sahara\" (1987), I Promessi Sposi and \"Nostromo\" (1996).\n\nHe wrote the score for the Mafia television series \"La piovra\" seasons 2 to 10 from 1985 to 2001, including the themes \"Droga e sangue\" (\"Drugs and Blood\"), \"La Morale\", and \"L'Immorale\". Morricone worked as the conductor of seasons 3 to 5 of the series. He also worked as the music supervisor for the television project \"La bibbia\" (\"The Bible\").\n\nIn the late 1990s, he collaborated with his son Andrea on the \"Ultimo\" crime dramas, resulting in \"Ultimo\" (1998), \"Ultimo 2 – La sfida\" (1999), \"Ultimo 3 – L'infiltrato\" (2004) and \"Ultimo 4 – L'occhio del falco\" (2013).\n\nIn the 2000s, Morricone continued to compose music for successful television series such as \"Il Cuore nel Pozzo\" (2005), \"\" (2005), \"La provinciale\" (2006), \"Giovanni Falcone\" (2007), \"Pane e libertà\" (2009) and \"Come Un Delfino 1–2\" (2011–2013).\n\nWith an estimated 13 million viewers, \"\" became an incredible success. Morricone wrote additional music for the sequel, \"\" (2006), which portrayed Karol's life as Pope from his papal inauguration to his death. Both scores were originally released respectively in 2005 and 2006. One year later, a double disc album with both scores is released.\n\nIn 2003, Morricone scored another epic, for Japanese television, called \"Musashi\" and was the Taiga drama about Miyamoto Musashi, Japan's legendary warrior. A part of his \"applied music\" is now applied to Italian television films.\n\nMorricone provided the string arrangements on Morrissey's \"Dear God Please Help Me\" from the album \"Ringleader of the Tormentors\" in 2006.\n\nSince 2004, Morricone wrote music for almost exclusively Italian television movies and mini-series, especially for directors such as Giuseppe Tornatore, Alberto Negrin, Giuliano Montaldo, and Franza Di Rosa.\n\nIn 2008, the composer recorded music for a Lancia commercial, featuring Richard Gere and directed by Harald Zwart (known for directing \"The Pink Panther 2\").\n\nTarantino originally wanted Morricone to compose the soundtrack for his film, \"Inglourious Basterds\". However, Morricone refused because of the sped-up production schedule of the film. Tarantino did use several Morricone tracks from previous films in the soundtrack. Morricone instead wrote the music for \"Baaria - La porta del vento\" by Tornatore. It was the second time Morricone's turned down the director, he also turned down an offer to write some music for \"Pulp Fiction\" in 1994.\n\nIn spring and summer 2010, Morricone worked with Hayley Westenra for a collaboration on her album \"Paradiso\". The album features new songs written by Morricone, as well as some of his best-known film compositions of the last 50 years. Hayley recorded the album with Morricone's orchestra in Rome during the summer of 2010.\n\nSince 1995, he composed the music for several advertising campaigns of Dolce & Gabbana. The commercials were directed by Giuseppe Tornatore.\n\nIn 2013, Morricone collaborated with Italian singer-songwriter Laura Pausini on a new version of her hit single \"La solitudine\" for her 20 years anniversary greatest hits album \"20 – The Greatest Hits\".\n\nMorricone composed the music for \"The Best Offer\" (2013) by Giuseppe Tornatore.\n\nIn 2014, Ennio Morricone became a Honorary chairman of the First International Open Competition in author's music video \"Mediamusic.\" The final of the competition was scheduled on 1 March 2015 in Moscow.\n\nHe wrote the score for Christian Carion's \"En mai, fais ce qu'il te plait\" (2015) and the most recent movie by Tornatore: \"The Correspondence\" (2016), featuring Jeremy Irons and Olga Kurylenko.\n\nIn July 2015, Quentin Tarantino announced after the screening of footage of his movie \"The Hateful Eight\" at the San Diego Comic-Con International that Morricone would score the film, the first Western that Morricone has scored since 1981. The score was critically acclaimed and won several awards including the Golden Globe Award for Best Original Score and the Academy Award for Best Original Score.\n\nBefore receiving his diplomas in trumpet, composition and instrumentation from the conservatory, Morricone was already active as a trumpet player, often performing in an orchestra that specialized in music written for films. After completing his education at Saint Cecilia, the composer honed his orchestration skills as an arranger for Italian radio and television. In order to support himself, he moved to RCA in the early sixties and entered the front ranks of the Italian recording industry. Since 1964, Morricone was also a founding member of the Rome-based avant-garde ensemble Gruppo di Improvvisazione di Nuova Consonanza. During the existence of the group (until 1978), Morricone performed several times with the group as trumpet player.\n\nTo ready his music for live performance, he joined smaller pieces of music together into longer suites. Rather than single pieces, which would require the audience to applaud every few minutes, Morricone thought the best idea was to create a series of suites lasting from 15 to 20 minutes, which form a sort of symphony in various movements – alternating successful pieces with personal favorites. In concert, Morricone normally has 180 to 200 musicians and vocalists under his baton, performing multiple genre-crossing collections of music. Rock, symphonic and ethnic instruments share the stage.\n\nOn 20 September 1984 Morricone conducted the Orchestre National des Pays de la Loire at \"Cinésymphonie '84\" (\"Première nuit de la musique de film/First night of film music\") in the French concert hall Salle Pleyel in Paris. He performed some of his best-known compositions such as \"Metti una sera a cena\", \"Novecento\" and \"The Good, the Bad and the Ugly\". Michel Legrand and Georges Delerue performed on the same evening.\n\nOn 15 October 1987 Morricone gave a concert in front of 12,000 people in the Sportpaleis in Antwerp, Belgium, with the Dutch Metropole Orchestra and the Italian operatic soprano Alide Maria Salvetta. A live-album with a recording of this concert was released in the same year.\n\nOn 9 June 2000 Morricone went to the Flanders International Film Festival Ghent to conduct his music together with the National Orchestra of Belgium. During the concert's first part, the screening of \"The Life and Death of King Richard III\" (1912) was accompanied with live music by Morricone. It was the very first time that the score was performed live in Europe. The second part of the evening consisted of an anthology of the composer's work. The event took place on the eve of Euro 2000, the European Football Championship in Belgium and the Netherlands.\n\nMorricone performed over 250 concerts as of 2001. Since 2001, the composer has been on a world tour, the latter part sponsored by Giorgio Armani, with the Orchestra Roma Sinfonietta, touring London (Barbican 2001; 75th birthday \"Concerto\", Royal Albert Hall 2003), Paris, Verona, and Tokyo. Morricone performed his classic film scores at the Munich Philharmonie in 2005 and Hammersmith Apollo Theatre in London, UK, on 1 & 2 December 2006.\nHe made his North American concert debut on 3 February 2007 at Radio City Music Hall in New York City. The previous evening, Morricone had already presented at the United Nations a concert comprising some of his film themes, as well as the cantata \"Voci dal silenzio\" to welcome the new Secretary-General Ban Ki-Moon. A \"Los Angeles Times\" review bemoaned the poor acoustics and opined of Morricone: \"His stick technique is adequate, but his charisma as a conductor is zero.\" Morricone, though, has said: \"Conducting has never been important to me. If the audience comes for my gestures, they had better stay outside.\"\n\nOn 12 December 2007 Morricone conducted the Orchestra Roma Sinfonietta at the Wiener Stadthalle in Vienna, presenting a selection of his own works.\nTogether with the Roma Sinfonietta and the Belfast Philharmonic Choir, Morricone performed at the Opening Concerts of the Belfast Festival at Queen's, in the Waterfront Hall on 17 and 18 October 2008.\nMorricone and Orchestra Roma Sinfonietta also held a concert at the Belgrade Arena (Belgrade, Serbia) on 14 February 2009.\n\nOn 10 April 2010 Morricone conducted a concert at the Royal Albert Hall in London with the Orchestra Roma Sinfonietta and (as in all of his previous London concerts) the Crouch End Festival Chorus. On 11 September he conducted a concert in Verona.\n\nOn 26 February 2012 Morricone made his Australian debut when he conducted the Western Australian Youth Orchestra together with a 100 voice chorus (made up primarily of WASO chorus members) at the Burswood Theatre (part of Crown Perth (formerly known as Burswood Entertainment Complex)) in Perth. On 2 March 2012 he conducted the Adelaide Symphony Orchestra at Elder Park, Adelaide as part of the Adelaide Festival of Arts.\n\nOn 22 December 2012 Morricone conducted the 85-piece Belgian orchestra \"Orkest der Lage Landen\" and a 100-piece choir during a two-hour concert in the Sportpaleis in Antwerp.\n\nIn November 2013 Morricone began a world tour to coincide with the 50th anniversary of his film music career and performed in locations such as the Crocus City Hall in Moscow, Santiago, Chile, Berlin, Germany (O2 World), Budapest, Hungary, and Vienna (Stadhalle). Back in June 2014, Morricone had to cancel a U.S tour in New York (Barclays Center) and Los Angeles (Nokia Theatre LA Live) due to a back procedure on 20 February. Morricone postponed the rest of his world tour.\n\nIn November 2014 Morricone stated that he will resume his European tour starting from February 2015.\n\nIn the late 1960s, Morricone and three other Italian composers (Piero Piccioni, Armando Trovajoli and Luis Bacalov) founded Forum Music Village (Rome), previously called Ortophonic recording studio. The recording studio has some peculiarities, one of them is the ability to record a church organ directly to the studio.\n\nMorricone has been using the studio to create his scores for the past 40 years. The studio has hosted many directors who have worked alongside him, including Brian De Palma, Oliver Stone and Barry Levinson.\n\nThe Academy Award-winning scores of \"\" by Luis Bacalov and \"Life Is Beautiful\" by Nicola Piovani were recorded in Studio A of Forum Music Village.\n\nNotable artists who have recorded at Forum Music Village are Quincy Jones, Jon and Vangelis, Placido Domingo, Andrea Bocelli, Red Hot Chili Peppers, Will.i.am, Yo-Yo Ma, Morrissey, Bruno Nicolai, Alessandro Alessandroni, Goblin, Pino Donaggio, Nicola Piovani, Danger Mouse, Daniele Luppi and Cher.\n\nOn 13 October 1956 he married Maria Travia, whom he had met in 1950. Travia has written lyrics to complement her husband's pieces. Her works include the Latin texts for \"The Mission\". They have three sons and a daughter, in order of birth: Marco (1957), Alessandra (1961), the conductor and film composer Andrea (Andrew) (1964), and Giovanni Morricone (1966), a filmmaker, who lives in New York City.\n\nMorricone has lived in Italy his entire life and has never desired to live in Hollywood. Morricone is also not fluent in English and will take interviews only in his native language.\n\nEnnio Morricone has influenced many artists from other styles and genres, including Danger Mouse, Dire Straits, Muse, Metallica, Radiohead and Hans Zimmer.\n\n\n\nWorldwide sales\n\nEnnio Morricone has sold well over 70 million records worldwide during his career that spanned over seven decades, including 6.5 million albums and singles in France, over three million in the United States and more than two million albums in Korea. In 1971, the composer received his first golden record (disco d'oro) for the sale of 1,000,000 records in Italy and a \"Targa d'Oro\" for the worldwide sales of 22 million.\n\nTop worldwide film grosses\n\nEnnio Morricone has been involved with at least 19 different movies grossing over 20 million at the box office\n\n\" * \" = US-only figures. Other successful movies with Morricone's work are \"La Luna\" (1979), \"Kill Bill: Volumes 1 & 2\" (2003, 2004), \"Inglourious Basterds\" (2009) and \"Django Unchained\" (2012) though the tracks used are sampled from older pictures.\n\nSelected long-time collaborations with directors\n\nAcademy Awards\n\nEnnio Morricone received his first Academy Award nomination in 1979 for the score to \"Days of Heaven\" (Terrence Malick, 1978).\n\nIn 1984, the U.S. distributor of Sergio Leone's \"Once Upon a Time in America\" reportedly failed to file the proper paperwork so that Morricone's score, regarded as one of his best, would be eligible for consideration for an Academy Award.\n\nTwo years later, Morricone received his second Oscar nomination for \"The Mission\". He also received Oscar nominations for his scores to \"The Untouchables\" (1987), \"Bugsy\" (1991), \"Malèna\" (2000), and \"The Hateful Eight\" (2016). On 28 February 2016, Morricone won his first Academy Award for his score to \"The Hateful Eight.\"\n\nMorricone and Alex North are the only composers to receive the Honorary Oscar since the award's introduction in 1928. Ennio Morricone received the honorary Academy Award on 25 February 2007, presented by Clint Eastwood, \"for his magnificent and multifaceted contributions to the art of film music.\" With the statuette came a standing ovation. In conjunction with the honor, Morricone released a tribute album, \"We All Love Ennio Morricone\", that featured as its centerpiece Celine Dion's rendition of \"I Knew I Loved You\" (based on \"Deborah's Theme\" from \"Once Upon a Time in America\"), which she performed at the ceremony. Behind-the-scenes studio production and recording footage of \"I Knew I Loved You\" can be viewed in the debut episode of the QuincyJones.com Podcast. The lyric, as with Morricone's \"Love Affair\", had been written by Alan and Marilyn Bergman. Morricone's acceptance speech was in his native Italian tongue and was interpreted by Clint Eastwood, who stood to his left. Eastwood and Morricone had in fact met two days earlier for the first time in 40 years at a reception.\n\nAFI\n\nIn 2005 four film scores by Ennio Morricone were nominated by the American Film Institute for an honoured place in the AFI's Top 25 of Best American Film Scores of All Time. His score for \"The Mission\" was ranked 23rd in the Top 25 list.\n\nGolden Globes\nItalian Golden Globes\n\nGrammy Awards\n\nMorricone was nominated five times for a Grammy Award. In 2009 The Recording Academy inducted his score for The Good, the Bad and the Ugly (1966) into the Grammy Hall of Fame.\n\nNastro d'Argento (Silver Ribbon)\n\nASCAP Awards\n\nBAFTA Awards\n\nCésar Awards\n\nDavid Award\n\nEuropean Film Awards\n\nLAFCA\n\nSelected other awards\n\n\n\n"}
{"id": "10278", "url": "https://en.wikipedia.org/wiki?curid=10278", "title": "List of explosives used during World War II", "text": "List of explosives used during World War II\n\nAlmost all the common explosives listed here were mixtures of several common components:\n\n\nThis is only a partial list; there were many others. Many of these compositions are now obsolete and only encountered in legacy munitions and unexploded ordnance.\n\nTwo Nuclear explosives, containing mixtures of uranium and plutonium, respectively, were also used at the bombings of Hiroshima and Nagasaki\n\n"}
{"id": "10281", "url": "https://en.wikipedia.org/wiki?curid=10281", "title": "Emin Boztepe", "text": "Emin Boztepe\n\nEmin Boztepe (born 17 July 1962) is an American martial artist of Turkish origin who held German nationality prior to naturalization. He first came to prominence for his fight in 1986 with noted Wing Chun practitioner William Cheung, and he continued to gain attention in the 1990s with a public challenge of the Gracie family. He was a notable member of Leung Ting's Wing Tsun organisation until 2002, when he formed his own organisation.\n\nBoztepe was born in Eskişehir, Turkey, the second of six children. At the age of four, his family, originally from Bağlıca, Emirdağ, moved to Germany. According to Boztepe, his early days in Germany were difficult due to his Turkish heritage—he was a constant target for racial insults and, more often than not, verbal abuse would escalate into physical abuse. Martial arts became something of a necessity and his father urged him to begin training. Boztepe recalled, \"Germany was not the healthiest place for a young Turk in those days of growing racism and neo-Nazi movements.\" He claimed to have been in over 300 street fights, many of them a result of this period, though he also claimed to have not started any of these fights.\n\nIn 1976, at the age of 14, Boztepe began studying martial arts, including judo, Shotokan karate, wrestling, Muay Thai, and traditional boxing. During this period, he also fought as an amateur boxer in 16 matches.\n\nIn 1980, Boztepe was attracted to Wing Chun when he saw a demonstration by Keith R. Kernspecht who was teaching in Kiel, Germany. He said, \"Wing tsun was, really, love at first sight. And it fit me. For whatever reason, I was a natural at it.\" Boztepe also began training in Latosa-Escrima, which Kernspecht's German Wing Tsun Organization had decided to make part of the family in 1982.\n\nHis fight with Traditional Wing Chun Kung Fu master William Cheung in 1986, at a seminar in Germany, caused controversy in the wider Wing Chun community.\n\nAfter some financial problems occurred with his master, Kernspecht, Boztepe headed to his master's master, Leung Ting, and took special lessons from him until a financial dispute, which caused him to leave the Wing Tsun organisation. Boztepe formed his own organisation, called Emin Boztepe Martial Arts System (EBMAS), afterwards.\n\nBoztepe was romantically linked with English actress Jacqueline Bisset from 1997 until 2005. He is known to have dated Zeynep Urgancı, the ex-wife of Turkish businessman Mehmet Urgancı after Bisset. He is currently engaged to Roma Gonzalesáenz a Spanish professional photographer, graphic designer, creative director, classic ballet and TV dancer and bass player.\n\n"}
{"id": "10283", "url": "https://en.wikipedia.org/wiki?curid=10283", "title": "Erlang (unit)", "text": "Erlang (unit)\n\nThe erlang (symbol E) is a dimensionless unit that is used in telephony as a measure of offered load or carried load on service-providing elements such as telephone circuits or telephone switching equipment. A single cord circuit has the capacity to be used for 60 minutes in one hour. Full utilization of that capacity, 60 minutes of traffic, constitutes 1 erlang.\n\nIn 1946, the CCITT named the international unit of telephone traffic the erlang in honor of Agner Krarup Erlang.\n\nWhen used to represent carried traffic, a value (which can be a non-integer such as 43.5) followed by “erlangs” represents the average number of concurrent calls carried by the circuits (or other service-providing elements), where that average is calculated over some reasonable period of time. The period over which the average is calculated is often one hour, but shorter periods (e.g., 15 minutes) may be used where it is known that there are short spurts of demand and a traffic measurement is desired that does not mask these spurts.\nOne erlang of carried traffic refers to a single resource being in continuous use, or two channels each being in use fifty percent of the time, and so on. For example, if an office has two telephone operators who are both busy all the time, that would represent two erlangs (2 E) of traffic; or a radio channel that is occupied for one hour continuously is said to have a load of 1 erlang.\n\nWhen used to describe offered traffic, a value followed by “erlangs” represents the average number of concurrent calls that would have been carried if there were an unlimited number of circuits (that is, if the call-attempts that were made when all circuits were in use had not been rejected). The relationship between offered traffic and carried traffic depends on the design of the system and user behavior. Three common models are (a) callers whose call-attempts are rejected go away and never come back, (b) callers whose call-attempts are rejected try again within a fairly short space of time, and (c) the system allows users to wait in queue until a circuit becomes available.\n\nA third measurement of traffic is instantaneous traffic, expressed as a certain number of erlangs, meaning the exact number of calls taking place at a point in time. In this case the number is an integer. Traffic-level-recording devices, such as moving-pen recorders, plot instantaneous traffic.\n\nThe concepts and mathematics introduced by Agner Krarup Erlang have broad applicability beyond telephony. They apply wherever users arrive more or less at random to receive exclusive service from any one of a group of service-providing elements without prior reservation, for example, where the service-providing elements are ticket-sales windows, toilets on an airplane, or motel rooms. (Erlang’s models do not apply where the service-providing elements are shared between several concurrent users or different amounts of service are consumed by different users, for instance, on circuits carrying data traffic.)\n\nOffered traffic (in erlangs) is related to the call arrival rate, λ, and the average call-holding time (the average time of a phone call), \"h\", by:\n\nprovided that \"h\" and λ are expressed using the same units of time (seconds and calls per second, or minutes and calls per minute).\n\nThe practical measurement of traffic is typically based on continuous observations over several days or weeks, during which the instantaneous traffic is recorded at regular, short intervals (such as every few seconds). These measurements are then used to calculate a single result, most commonly the busy hour traffic (in erlangs). This is the average number of concurrent calls during a given one-hour period of the day, where that period is selected to give the highest result. (This result is called the time-consistent busy hour traffic). An alternative is to calculate a busy hour traffic value separately for each day (which may correspond to slightly different times each day) and take the average of these values. This generally gives a slightly higher value than the time-consistent busy hour value.\n\nThe goal of Erlang’s traffic theory is to determine exactly how many service-providing elements should be provided in order to satisfy users, without wasteful over-provisioning. To do this, a target is set for the grade of service (GoS) or quality of service (QoS). For example, in a system where there is no queuing, the GoS may be that no more than 1 call in 100 is blocked (i.e., rejected) due to all circuits being in use (a GoS of 0.01), which becomes the target probability of call blocking, \"P\", when using the Erlang B formula.\n\nThere are several Erlang formulae, including Erlang B, Erlang C and the related Engset formula, based on different models of user behavior and system operation. These are discussed below, and may each be derived by means of a special case of continuous-time Markov processes known as a birth-death process.\n\nWhere the existing busy-hour carried traffic, \"E\", is measured on an already-overloaded system, with a significant level of blocking, it is necessary to take account of the blocked calls in estimating the busy-hour offered traffic \"E\" (which is the traffic value to be used in the Erlang formula). The offered traffic can be estimated by \"E\" = \"E\"/(1 − \"P\"). For this purpose, where the system includes a means of counting blocked calls and successful calls, \"P\" can be estimated directly from the proportion of calls that are blocked. Failing that, \"P\" can be estimated by using \"E\" in place of \"E\" in the Erlang formula and the resulting estimate of \"P\" can then be used in \"E\" = \"E\"/(1 − \"P\") to estimate \"E\". Another method of estimating \"E\" in an overloaded system is to measure the busy-hour call arrival rate, \"λ\" (counting successful calls and blocked calls), and the average call-holding time (for successful calls), \"h\", and then estimate \"E\" using the formula \"E\" = \"λh\".\n\nFor a situation where the traffic to be handled is completely new traffic, the only choice is to try to model expected user behavior, estimating active user population, \"N\", expected level of use, \"U\" (number of calls/transactions per user per day), busy-hour concentration factor, \"C\" (proportion of daily activity that will fall in the busy hour), and average holding time/service time, \"h\" (expressed in minutes). A projection of busy-hour offered traffic would then be \"E\" = (NUC/60)\"h\" erlangs. (The division by 60 translates the busy-hour call/transaction arrival rate into a per-minute value, to match the units in which \"h\" is expressed.)\n\nErlang-B (sometimes also written without the hyphen Erlang), also known as the Erlang loss formula, is a formula for the blocking probability that describes the probability of call losses for a group of identical parallel resources (telephone lines, circuits, traffic channels, or equivalent), sometimes referred to as an M/M/c/c queue. It is, for example, used to dimension a telephone network's links. The formula was derived by Agner Krarup Erlang and is not limited to telephone networks, since it describes a probability in a queuing system (albeit a special case with a number of servers but no queueing space for incoming calls to wait for a free server). Hence, the formula is also used in certain inventory systems with lost sales.\n\nThe formula applies under the condition that an unsuccessful call, because the line is busy, is not queued or retried, but instead really vanishes forever. It is assumed that call attempts arrive following a Poisson process, so call arrival instants are independent. Further, it is assumed that the message lengths (holding times) are exponentially distributed (Markovian system), although the formula turns out to apply under general holding time distributions.\n\nThe Erlang B formula assumes an infinite population of sources (such as telephone subscribers), which jointly offer traffic to \"N\" servers (such as telephone lines). The rate expressing the frequency at which new calls arrive, λ, (birth rate, traffic intensity, etc.) is constant, and does \"not\" depend on the number of active sources. The total number of sources is assumed to be infinite. \nThe Erlang B formula calculates the blocking probability of a buffer-less loss system, where a request that is not served immediately is aborted, causing that no requests become queued. Blocking occurs when a new request arrives at a time where all available servers are currently busy. The formula also assumes that blocked traffic is cleared and does not return.\n\nThe formula provides the GoS (grade of service) which is the probability \"P\" that a new call arriving to the resources group is rejected because all resources (servers, lines, circuits) are busy: \"B\"(\"E\", \"m\") where \"E\" is the total offered traffic in erlang, offered to \"m\" identical parallel resources (servers, communication channels, traffic lanes). \n\nwhere:\n\nNote: The \"erlang\" is a dimensionless load unit calculated as the mean arrival rate, λ, multiplied by the mean call holding time, \"h\". \nSee Little's law to prove that the erlang unit has to be dimensionless for Little's Law to be dimensionally sane.\n\nThis may be expressed recursively as follows, in a form that is used to simplify the calculation of tables of the Erlang B formula:\n\nTypically, instead of \"B\"(\"E\", \"m\") the inverse 1/\"B\"(\"E\", \"m\") is calculated in numerical computation in order to ensure numerical stability:\n\nThe Erlang B formula is decreasing and convex in \"m\".\nIt requires that call arrivals can be modeled by a Poisson process, which not always is a good match, but it is valid for any statistical distribution of call holding times with finite mean. \nIt applies to traffic transmission systems that do not buffer traffic. \nMore modern examples compared to POTS where Erlang B is still applicable, are optical burst switching (OBS) and several current approaches to optical packet switching (OPS). \nErlang B was developed as a trunk sizing tool for telephone networks with holding times in the minutes range, but being a mathematical equation it applies on any time-scale.\n\nExtended Erlang B is an iterative calculation, rather than a formula, that adds an extra parameter, the recall factor, which defines the recall attempts.\n\nThe steps in the process are as follows:\n\n1. Calculate \nas above for Erlang B.\n\n2. Calculate the probable number of blocked calls\n\n3. Calculate the number of recalls, formula_10 assuming a Recall Factor, formula_11:\n\n4. Calculate the new offered traffic\nwhere formula_14 is the initial (baseline) level of traffic.\n5. Return to step 1 and iterate until a stable value of formula_15 is obtained.\n\nThe Erlang C formula expresses the probability that an arriving customer will need to queue (as opposed to immediately being served). Just as the Erlang B formula, Erlang C assumes an infinite population of sources, which jointly offer traffic of \"A\" erlangs to \"N\" servers. However, if all the servers are busy when a request arrives from a source, the request is queued. An unlimited number of requests may be held in the queue in this way simultaneously. This formula calculates the probability of queuing offered traffic, assuming that blocked calls stay in the system until they can be handled. This formula is used to determine the number of agents or customer service representatives needed to staff a call centre, for a specified desired probability of queuing. However, the Erlang C formula assumes that callers never hang up while in queue, which makes the formula predict that more agents should be used than are really needed to maintain a desired service level.)\n\nwhere:\n\nIt is assumed that the call arrivals can be modeled by a Poisson process and that call holding times are described by a negative exponential distribution.\n\n\n\n"}
{"id": "10285", "url": "https://en.wikipedia.org/wiki?curid=10285", "title": "Eligible receiver", "text": "Eligible receiver\n\nIn American football and Canadian football, not all players on offense are entitled to receive a forward pass. Only an eligible pass receiver may legally catch a forward pass, and only an eligible receiver may advance beyond the neutral zone if a forward pass crosses the neutral zone. If the pass is received by a non-eligible receiver, it is \"illegal touching\" (five yards and loss of down). If an ineligible receiver is beyond the neutral zone when a forward pass crossing the neutral zone is thrown, a foul of \"ineligible receiver downfield\" (five yards, but no loss of down) is called. Each league has slightly different rules regarding who is considered an eligible receiver.\n\nThe NCAA rulebook defines eligible receivers for college football in Rule 7, Section 3, Article 3. The determining factors are the player's position on the field at the snap and their jersey number. Specifically, any players on offense wearing numbers between 50 and 79 are always ineligible. All defensive players are eligible receivers and offensive players who are not wearing an ineligible number are eligible receivers if they meet one of the following three criteria:\n\nPlayers may only wear eligible numbers at an ineligible position when it is obvious that a punt or field goal is to be attempted.\n\nIf a player is to change between eligible and ineligible positions, they must physically change jersey numbers to reflect the position.\n\nA receiver loses his eligibility by leaving the field of play unless he was forced out by a defensive player and immediately attempts to get back inbounds (Rule 7-3-4). All players on the field become eligible as soon as the ball is touched by a defensive player or an official during play (Rule 7-3-5).\n\nIn both American and Canadian professional football, every player on the defensive team is considered eligible. The offensive team must have at least seven players lined up on the line of scrimmage. Of the players on the line of scrimmage, only the two players on the ends of the line of scrimmage are eligible receivers. The remaining players are in the backfield (four in American football, five in Canadian football), including the quarterback. These backfield players are also eligible receivers. In the National Football League, a quarterback who takes his stance behind center as a T-formation quarterback is not eligible unless, before the ball is snapped, he legally moves to a position at least one yard behind the line of scrimmage or on the end of the line, and is stationary in that position for at least one second before the snap, but is nonetheless not counted toward the seven men required on the line of scrimmage.\n\nIf, for example, eight men line up on the line of scrimmage, the team loses an eligible receiver. This can often happen when a flanker or slot receiver, who is supposed to line up behind the line of scrimmage, instead lines up on the line of scrimmage between the offensive line and a split end. In most cases where a pass is caught by an ineligible receiver, it is usually because the quarterback was under pressure and threw it to an offensive lineman out of desperation.\n\nIn many leagues eligible receivers must wear certain uniform numbers, so that the officials can more easily distinguish between eligible and ineligible receivers. In the NFL running backs must wear numbers 20 to 49, tight ends must wear numbers 80 to 89 (or 40 to 49 if the numbers 80 to 89 have been exhausted), and wide receivers must wear numbers 10 to 19 or 80 to 89. In the CFL ineligible receivers must wear numbers 50 to 69; all other numbers (including 0 and 00) may be worn by eligible receivers. A player who is not wearing a number that corresponds to an eligible receiver is ineligible even if he lines up in an eligible position. However, a player who reports to the referee that he intends to be eligible in the following play is allowed to line up and act as an eligible receiver. An example of this was a 1985 NFL game in which William Perry, wearing number 72 and normally a defensive lineman, was made an eligible receiver on an offensive play, and successfully caught a touchdown pass attempt. A more recent example, and more commonly used, has been former New England Patriots linebacker Mike Vrabel lining up as a tight end in goal line situations.\n\nBefore the snap of the ball, in the American game, backfield players may only move parallel to the line of scrimmage, only one back may be in motion at any given time, and if forward motion has occurred, the back must be still for a full second before the snap. The receiver may be in motion laterally or away from the line of scrimmage at the snap. A breach of this rule results in a penalty for illegal procedure (five yards). However, in the Canadian game, eligible receivers may move in any direction before the snap, any number may be in motion at any one time, and there is no need to be motionless before the snap.\n\nThe rules on eligible receivers only apply to forward passes. Any player may legally catch a backwards or lateral pass. \n\nIn the American game, once the play has started, eligible receivers can become ineligible depending on how the play develops. Any eligible receiver that goes out of bounds is no longer an eligible receiver and cannot receive a forward pass, unless that player re-establishes by taking three steps in bounds. Also, if a pass is touched by any defensive player or eligible offensive receiver (tipped by a defensive lineman, slips through a receiver's hands, etc.), every offensive player immediately becomes eligible. In the CFL all players become eligible receivers if a pass is touched by a member of the defensive team.\n\nIn high school football, the rules of eligibility are roughly the same as in the college game. However, as of February 1999, at least five players must wear numbers between 50 and 79 on first, second, or third down, which by rule would make them ineligible receivers. This was because of a change in the definition of a scrimmage-kick formation made by the National Federation of State High School Associations (NFHS). The change was intended to close a loophole in the rules which allowed teams to run an A-11 offense, in which a team could legally be exempted from eligibility numbering restrictions if the player receiving the snap was at least seven yards behind the line of scrimmage.\n\n"}
{"id": "10286", "url": "https://en.wikipedia.org/wiki?curid=10286", "title": "Enver Hoxha", "text": "Enver Hoxha\n\nEnver Halil Hoxha (; 16 October 190811 April 1985) was an Albanian communist politician who served as the head of state of Albania from 1944 until his death in 1985, as the First Secretary of the Party of Labour of Albania. He was chairman of the Democratic Front of Albania and commander-in-chief of the armed forces from 1944 until his death. He served as the 22nd Prime Minister of Albania from 1944 to 1954 and at various times served as foreign minister and defence minister as well.\n\nBorn in Gjirokastër in 1908, Hoxha became a teacher in grammar school in 1936. Following Italy's invasion of Albania shortly before the beginning of World War II he was dismissed as a teacher for refusing to join the Albanian Fascist Party. He entered into the Communist Party of Albania following its creation in 1941. Hoxha was elected First Secretary in March 1943 at the age of 34. The Yugoslav Partisans assisted the Albanians, but communication was limited and Hoxha disagreed with their goal of preventing the creation of a Greater Albania. Less than two years after the liberation of the country, the monarchy was abolished, King Zog was deposed and Hoxha rose to power as the head of state of Albania.\n\nDuring his 40-year-rule, Hoxha's regime committed a series of political repressions which included the establishment and use of forced labor camps, wrongful incarcerations, extrajudicial killings and executions that targeted and eliminated anti-communists and other dissidents, and evictions of families from their homes to remote villages strictly controlled by his secret police, the \"Sigurimi\", which, like Nicolae Ceaușescu's Securitate and Erich Honecker's Stasi, was strongly oppressive and ubiquitous. His rule was also characterized by the use of Stalinist methods to destroy associates who threatened his power. He focused on rebuilding the country, which was left in ruins after World War II, building Albania's first railway line, eliminating adult illiteracy and leading Albania towards becoming agriculturally self-sufficient.\n\nHoxha's government was characterized by his proclaimed firm adherence to anti-revisionist Marxism–Leninism from the mid-1970s onwards. After his break with Maoism in the 1976–78 period, numerous Maoist parties around the world declared themselves Hoxhaist. The International Conference of Marxist–Leninist Parties and Organizations (Unity & Struggle) is the best known association of these parties today.\n\nHoxha was born in Gjirokastër, a city in southern Albania (then under the Ottoman Empire) that has been home to many prominent families. He was the son of Halil Hoxha, a Muslim Tosk cloth merchant who travelled widely across Europe and the United States, and Gjylihan (Gjylo) Hoxha.\n\nThe Hoxha family was attached to the Bektashi Order; fourteen years before Enver set off for France to study, his father brought him to seek the blessing of Baba Selim of the Zall Teqe.\n\nAt age 16, Hoxha helped found and became secretary of the Students Society of Gjirokastër, which protested against the monarchist government of Zog I of Albania. After the government closed the Society, he moved to Korçë, continuing his studies at the French-language Albanian National Lyceum. There he learned French history, literature and philosophy, and read \"The Communist Manifesto\" for the first time.\nIn 1930, Hoxha went to study at the University of Montpellier in France on a state scholarship given to him by Queen Mother Sadije for the faculty of natural science. He attended the lessons and the conferences of the Association of Workers organised by the French Communist Party, but dropped out to pursue a degree in either philosophy or law. After a year, lacking interest in biology, and after not having passed any university exams, he left Montpellier to go to Paris hoping to continue his studies. He attended philosophy classes at the Sorbonne, but, again, did not sit for any exam. In Paris, it is said that he collaborated with \"L'Humanité\", writing articles on the situation in Albania under the pseudonym \"Lulo Malësori\". He also got involved in the Albanian Communist Group under the tutelage of Llazar Fundo, who taught him law.\n\nHe dropped out once more, and from 1934 to 1936 he was a secretary at the Albanian consulate in Brussels, attached to the personnel office of the Queen Mother. He was dismissed after the consul discovered that his employee kept Marxist materials and books in his office. He returned to Albania in 1936 and taught grammar school in the French lyceum of Korçë. His extensive education left him fluent in French with a working knowledge of Italian, Croatian, English and Russian. As a leader, he would often reference \"Le Monde\" and the \"International Herald Tribune\".\n\nOn 7 April 1939, Albania was invaded by Fascist Italy. The Italians established a puppet government, the Albanian Kingdom (1939–43), under Mustafa Merlika-Kruja. Hoxha was dismissed from his teaching post following the invasion for refusing to join the Albanian Fascist Party. He opened a tobacco shop in Tirana called Flora where a small communist group soon started gathering. Eventually the government closed it.\n\nOn 8 November 1941, the Communist Party of Albania (later renamed the Party of Labour of Albania in 1948) was founded. Hoxha was chosen from the \"Korca group\" as a Muslim representative by the two Yugoslav envoys as one of the seven members of the provisional Central Committee. The First Consultative Meeting of Activists of the Communist Party of Albania was held in Tirana from April 8-11, 1942, with Hoxha himself delivering the main report on 8 April 1942.\n\nIn July 1942, Hoxha wrote \"Call to the Albanian Peasantry\", issued in the name of the Communist Party of Albania. The call sought to enlist support in Albania for the war against the fascists. The peasants were encouraged to hoard their grain and refuse to pay taxes or livestock levies brought by the government. After the September 1942 Conference at Pezë, the National Liberation Movement was founded with the purpose of uniting the anti-fascist Albanians, regardless of ideology or class.\n\nBy March 1943, the first National Conference of the Communist Party elected Hoxha formally as First Secretary. During World War II, the Soviet Union's role in Albania was negligible. On 10 July 1943, the Albanian partisans were organised in regular units of companies, battalions and brigades and named the Albanian National Liberation Army. The organization received military support from the British intelligence service, SOE. The General Headquarters was created, with Spiro Moisiu as the commander and Hoxha as political commissar. The Yugoslav Partisans had a much more practical role, helping to plan attacks and exchanging supplies, but communication between them and the Albanians was limited and letters would often arrive late, sometimes well after a plan had been agreed upon by the National Liberation Army without consultation from the Yugoslav partisans.\n\nWithin Albania, repeated attempts were made during the war to remedy the communications difficulties which faced partisan groups. In August 1943, a secret meeting, the Mukje Conference, was held between the anti-communist Balli Kombëtar (National Front) and the Communist Party of Albania. The result of this was an agreement to:\n\n\nTo encourage the Balli Kombëtar to sign, the Greater Albania sections that included Kosovo (part of Yugoslavia) and Chamëria were made part of the Agreement.\n\nA problem developed when the Yugoslav Communists disagreed with the goal of a Greater Albania and asked the Communists in Albania to withdraw their agreement. According to Hoxha, Josip Broz Tito had agreed that \"Kosovo was Albanian\" but that Serbian opposition made transfer an unwise option. After the Albanian Communists repudiated the Greater Albania agreement, the Balli Kombëtar condemned the Communists, who in turn accused the Balli Kombëtar of siding with the Italians. The Balli Kombëtar, however, lacked support from the people. After judging the Communists as an immediate threat, the Balli Kombëtar sided with Nazi Germany, fatally damaging its image among those fighting the Fascists. The Communists quickly added to their ranks many of those disillusioned with the Balli Kombëtar and took center stage in the fight for liberation.\nThe Permet National Congress held during that time called for a \"new democratic Albania for the people.\" Although the monarchy was not formally abolished, King Zog was barred from returning to the country, which further increased the Communists' control. The Anti-Fascist Committee for National Liberation was founded, chaired by Hoxha. On 22 October 1944, the Committee became the Democratic Government of Albania after a meeting in Berat and Hoxha was chosen as interim Prime Minister. Tribunals were set up to try alleged war criminals who were designated \"enemies of the people\" and were presided over by Koçi Xoxe.\n\nAfter liberation on 29 November 1944, several Albanian partisan divisions crossed the border into German-occupied Yugoslavia, where they fought alongside Tito's partisans and the Soviet Red Army in a joint campaign which succeeded in driving out the last pockets of German resistance. Marshal Tito, during a Yugoslavian conference in later years, thanked Hoxha for the assistance that the Albanian partisans had given during the War for National Liberation (\"Lufta Nacionalçlirimtare\"). The Democratic Front, dominated by the Albanian Communist Party, succeeded the National Liberation Front in August 1945 and the first post-war election was the held on 2 December. The Front was the only legal political organisation allowed to stand in the elections, and the government reported that 93% of Albanians voted for it.\n\nOn 11 January 1946, Zog was officially deposed and Albania was proclaimed the People's Republic of Albania (renamed the People's Socialist Republic of Albania in 1976). As First Secretary, Hoxha was \"de facto\" head of state and the most powerful man in the country.\n\nAlbanians celebrate their independence day on 28 November (which is the date on which they declared their independence from the Ottoman Empire in 1912), while in the former People's Socialist Republic of Albania the national day was 29 November, the day the country was liberated from the Italians. Both days are currently national holidays.\n\nHoxha declared himself a Marxist–Leninist and strongly admired Soviet leader Joseph Stalin. During the period of 1945–1950, the government adopted policies which were intended to consolidate power. The Agrarian Reform Law was passed in August 1945. It confiscated land from beys and large landowners, giving it without compensation to peasants. 52% of all land was owned by large landowners before the law was passed; this declined to 16% after the law's passage. Illiteracy, which was 90–95% in rural areas in 1939 went down to 30% by 1950 and by 1985 it was equal to that of a Western country.\n\nThe State University of Tirana was established in 1957, which was the first of its kind in Albania. The Medieval Gjakmarrja (blood feud) was banned. Malaria, the most widespread disease, was successfully fought through advances in health care, the use of DDT, and through the draining of swamplands. From 1965 to 1985, no cases of malaria were reported, whereas previously Albania had the greatest number of infected patients in Europe. No cases of syphilis had been recorded for 30 years. In order to solve the Gheg-Tosk divide, books were written in the Tosk dialect, and the majority of the Party's members came from southern Albania where the Tosk dialect is spoken.\n\nBy 1949, the United States and British intelligence organisations were working with King Zog and the mountain men of his personal guard. They recruited Albanian refugees and émigrés from Egypt, Italy and Greece, trained them in Cyprus, Malta and the Federal Republic of Germany (West Germany), and infiltrated them into Albania. Guerrilla units entered Albania in 1950 and 1952, but they were killed or captured by Albanian security forces. Kim Philby, a Soviet double agent working as a liaison officer between the British intelligence service and the United States Central Intelligence Agency, had leaked details of the infiltration plan to Moscow, and the security breach claimed the lives of about 300 infiltrators.\n\nAt this point, relations with Yugoslavia had begun to change. The roots of the change began on 20 October 1944 at the Second Plenary Session of the Communist Party of Albania. The Session considered the problems that the post-independence Albanian government would face. However, the Yugoslav delegation led by Velimir Stoinić accused the party of \"sectarianism and opportunism\" and blamed Hoxha for these errors. He also stressed the view that the Yugoslav Communist partisans spearheaded the Albanian partisan movement.\n\nAnti-Yugoslav members of the Albanian Communist Party had begun to think that this was a plot by Tito who intended to destabilize the Party. Koçi Xoxe, Sejfulla Malëshova and others who supported Yugoslavia were looked upon with deep suspicion. Tito's position on Albania was that it was too weak to stand on its own and that it would do better as a part of Yugoslavia. Hoxha alleged that Tito had made it his goal to get Albania into Yugoslavia, firstly by creating the Treaty of Friendship, Co-operation and Mutual Aid in 1946. In time, Albania began to feel that the treaty was heavily slanted towards Yugoslav interests, much like the Italian agreements with Albania under Zog that made the nation dependent upon Italy.\n\nThe first issue was that the Albanian lek became revalued in terms of the Yugoslav dinar as a customs union was formed and Albania's economic plan was decided more by Yugoslavia. Albanian economists H. Banja and V. Toçi stated that the relationship between Albania and Yugoslavia during this period was exploitative and that it constituted attempts by Yugoslavia to make the Albanian economy an \"appendage\" to the Yugoslav economy. Hoxha then began to accuse Yugoslavia of misconduct:\n\nJoseph Stalin advised Hoxha that Yugoslavia was attempting to annex Albania: \"We did not know that the Yugoslavs, under the pretext of 'defending' your country against an attack from the Greek fascists, wanted to bring units of their army into the PRA [People's Republic of Albania]. They tried to do this in a very secretive manner. In reality, their aim in this direction was utterly hostile, for they intended to overturn the situation in Albania.\" By June 1947, the Central Committee of Yugoslavia began publicly condemning Hoxha, accusing him of talking an individualistic and anti-Marxist line. When Albania responded by making agreements with the Soviet Union to purchase a supply of agricultural machinery, Yugoslavia said that Albania could not enter into any agreements with other countries without Yugoslav approval.\n\nKoçi Xoxe tried to stop Hoxha from improving relations with Bulgaria, reasoning that Albania would be more stable with one trading partner rather than with many. Nako Spiru, an anti-Yugoslav member of the Party, condemned Xoxe and vice versa. With no one coming to Spiru's defense, he viewed the situation as hopeless and feared that Yugoslav domination of his nation was imminent, which caused him to commit suicide in November.\n\nAt the Eighth Plenum of the Central Committee of the Party which lasted from 26 February to 8 March 1948, Xoxe was implicated in a plot to isolate Hoxha and consolidate his own power. He accused Hoxha of being responsible for the decline in relations with Yugoslavia, and stated that a Soviet military mission should be expelled in favor of a Yugoslav counterpart. Hoxha managed to remain firm and his support had not declined. When Yugoslavia publicly broke with the Soviet Union, Hoxha's support base grew stronger. Then, on 1 July 1948, Tirana called on all Yugoslav technical advisors to leave the country and unilaterally declared all treaties and agreements between the two countries null and void. Xoxe was expelled from the party and on 13 June 1949 he was executed by hanging.\n\nAfter the break with Yugoslavia, Hoxha aligned himself with the Soviet Union, for which he had a great admiration. From 1948 to 1960, $200 million in Soviet aid was given to Albania for technical and infrastructural expansion. Albania was admitted to the Comecon on 22 February 1949 and remained important both as a way to pressure Yugoslavia and to serve as a pro-Soviet force in the Adriatic Sea. A submarine base was built on the island of Sazan near Vlorë, posing a possible threat to the United States Sixth Fleet. Relations remained close until the death of Stalin on 5 March 1953. His death was met with 14 days of national mourning in Albania—more than in the Soviet Union. Hoxha assembled the entire population in the capital's largest square featuring a statue of Stalin, requested that they kneel, and made them take a two-thousand word oath of \"eternal fidelity\" and \"gratitude\" to their \"beloved father\" and \"great liberator\" to whom the people owed \"everything.\"\n\nUnder Nikita Khrushchev, Stalin's successor, aid was reduced and Albania was encouraged to adopt Khrushchev's specialization policy. Under this policy, Albania would develop its agricultural output in order to supply the Soviet Union and other Warsaw Pact nations while these nations would be developing specific resource outputs of their own, which would in theory strengthen the Warsaw Pact by greatly reducing the lack of certain resources that many of the nations faced. However, this also meant that Albanian industrial development, which was stressed heavily by Hoxha, would have to be significantly reduced.\nFrom 16 May to 17 June 1955, Nikolai Bulganin and Anastas Mikoyan visited Yugoslavia and Khrushchev renounced the expulsion of Yugoslavia from the Communist bloc. Khrushchev also began making references to Palmiro Togliatti's polycentrism theory. Hoxha had not been consulted on this and was offended. Yugoslavia began asking for Hoxha to rehabilitate the image of Koçi Xoxe, which Hoxha steadfastly rejected. In 1956 at the Twentieth Party Congress of the Soviet Communist Party, Khrushchev condemned the cult of personality that had been built up around Joseph Stalin and also accused him of many grave mistakes. Khrushchev then announced the theory of peaceful coexistence, which angered Hoxha greatly. The Institute of Marxist–Leninist Studies, led by Hoxha's wife Nexhmije, quoted Vladimir Lenin: \"The fundamental principle of the foreign policy of a socialist country and of a Communist party is proletarian internationalism; not peaceful coexistence.\" Hoxha now took a more active stand against perceived revisionism.\n\nUnity within the Albanian Party of Labour began to decline as well, with a special delegate meeting held in Tirana in April 1956, composed of 450 delegates and having unexpected results. The delegates \"criticized the conditions in the party, the negative attitude toward the masses, the absence of party and socialist democracy, the economic policy of the leadership, etc.\" while also calling for discussions on the cult of personality and the Twentieth Party Congress.\n\nIn 1956, Hoxha called for a resolution which would uphold the current leadership of the Party. The resolution was accepted, and all of the delegates who had spoken out were expelled from the party and imprisoned. Hoxha stated that this was yet another of many attempts to overthrow the leadership of Albania which had been organized by Yugoslavia. This incident further consolidated Hoxha's power, effectively making Khrushchev-esque reforms nearly impossible. In the same year, Hoxha traveled to the People's Republic of China, then enduring the Sino-Soviet Split, and personally met with Mao Zedong. Relations with China improved, as evidenced by Chinese aid to Albania being 4.2% in 1955 before the visit, and rising to 21.6% in 1957.\n\nIn an effort to keep Albania in the Soviet sphere, increased aid was given but the Albanian leadership continued to move closer towards China. Relations with the Soviet Union remained at the same level until 1960, when Khrushchev met with Sophocles Venizelos, a left-wing Greek politician. Khrushchev sympathized with the concept of an autonomous Greek North Epirus and hoped to use Greek claims to keep the Albanian leadership in line with Soviet interests. Hoxha reacted by only sending Hysni Kapo, a member of the Albanian Political Bureau, to the Third Congress of the Romanian Communist Party in Bucharest, an event that heads of state were normally expected to attend. As relations between the two countries continued to deteriorate in the course of the meeting, Khrushchev said:\n\nRelations with the Soviet Union began to decline rapidly. A hardline policy was adopted and the Soviets reduced aid shipments, specifically grain, at a time when Albania needed them due to the possibility of a flood-induced famine. In July 1960, a plot to overthrow the government was discovered. It was to be organized by Soviet-trained Rear Admiral Teme Sejko. After this, two pro-Soviet members of the Party, Liri Belishova and Koço Tashko, were expelled, with a humorous incident involving Tashko pronouncing \"\" (Russian for \"full stop\").\n\nIn August, the Party's Central Committee sent a letter of protest to the Central Committee of the Communist Party of the Soviet Union, stating its displeasure at having an anti-Albanian Soviet Ambassador in Tirana. The Fourth Congress of the Party, held from 13 to 20 February 1961, was the last meeting that the Soviet Union or other Eastern European nations attended in Albania. During the congress, the Soviet Union was condemned while China was praised. Mehmet Shehu stated that while many members of the Party were accused of tyranny, this was a baseless charge and unlike the Soviet Union, Albania was led by genuine Marxists.\n\nThe Soviet Union retaliated by threatening \"dire consequences\" if the condemnations were not retracted. Days later, Khrushchev and Antonín Novotný, President of Czechoslovakia (which was Albania's largest source of aid besides the Soviets), threatened to cut off economic aid. In March, Albania was not invited to attend the meeting of the Warsaw Pact nations (Albania had been one of its founding members in 1955) and in April all Soviet technicians were withdrawn from the nation. In May nearly all Soviet troops on the Orikum naval base were withdrawn, leaving the Albanians with 4 submarines and other military equipment.\n\nOn 7 November 1961, Hoxha made a speech in which he called Khrushchev a \"revisionist, an anti-Marxist and a defeatist.\" Hoxha portrayed Stalin as the last Communist leader of the Soviet Union and began to stress Albania's independence. By 11 November, the USSR and every other Warsaw Pact nation broke relations with Albania. Albania was unofficially excluded (by not being invited) from both the Warsaw Pact and Comecon. The Soviet Union also attempted to claim control of the Vlorë port due to a lease agreement; the Albanian Party then passed a law prohibiting any other nation from owning an Albanian port through lease or otherwise. The Soviet–Albanian split was now complete.\n\nAs Hoxha's leadership continued he took on an increasingly theoretical stance. He wrote criticisms based both on current events at the time and on theory; most notably his condemnations of Maoism post-1978. A major achievement under Hoxha was the advancement of women's rights. Albania had been one of the most, if not the most, patriarchal countries in Europe. The \"Code of Lekë\", which regulated the status of women, states, \"A woman is known as a sack, made to endure as long as she lives in her husband's house.\" Women were not allowed to inherit anything from their parents, and discrimination was even made in the case of the murder of a pregnant woman:\nWomen were forbidden to obtain a divorce, and the wife's parents were obliged to return a runaway daughter to the husband or else suffer shame which could even result in a generations-long blood feud. During World War II, the Albanian Communists encouraged women to join the partisans. and following the war women were encouraged to take up menial jobs, as the education necessary for higher level work was out of most women's reach. In 1938, 4% worked in various sectors of the economy. In 1970, this number had risen to 38%, and in 1982 to 46%.\n\nDuring the Cultural and Ideological Revolution (discussed below), women were encouraged to take up \"all\" jobs, including government posts, which resulted in 40.7% of the People's Councils and 30.4% of the People's Assembly being made up of women, including two women in the Central Committee by 1985. In 1978, 15.1 times as many females attended eight-year schools as had done so in 1938 and 175.7 times as many females attended secondary schools. By 1978, 101.9 times as many women attended higher schools as in 1957. Hoxha said of women's rights in 1967:The entire party and country should hurl into the fire and break the neck of anyone who dared trample underfoot the sacred edict of the party on the defense of women's rights.In 1969, direct taxation was abolished and during this period the quality of schooling and health care continued to improve. An electrification campaign was begun in 1960 and the entire nation was expected to have electricity by 1985. Instead, it achieved this on 25 October 1970, making it the first nation with complete electrification in the world. During the Cultural & Ideological Revolution of 1967–1968 the military changed from traditional Communist army tactics and began to adhere to the Maoist strategy known as people's war, which included the abolition of military ranks, which were not fully restored until 1991. Mehmet Shehu said of the country's health service in 1979:\nHoxha's legacy also included a complex of 750,000 one-man concrete bunkers across a country of 3 million inhabitants, to act as look-outs and gun emplacements along with chemical weapons. The bunkers were built strong and mobile, with the intention that they could be easily placed by a crane or a helicopter in a previously dug hole. The types of bunkers vary from machine gun pillboxes, beach bunkers, to underground naval facilities, and even Air Force Mountain and underground bunkers.\n\nHoxha's internal policies were true to Stalin's paradigm which he admired, and the personality cult developed in the 1970s organized around him by the Party also bore a striking resemblance to that of Stalin. At times it even reached an intensity similar to the personality cult surrounding Kim Il-sung (which Hoxha condemned) with Hoxha being portrayed as a genius commenting on virtually all facets of life from culture to economics to military matters. Each schoolbook required one or more quotations from him on the subjects being studied. The Party honored him with titles such as Supreme Comrade, Sole Force and Great Teacher.\n\nHoxha's governance was also distinguished by his encouragement of a high birthrate policy. For instance, a woman who bore an above-average amount of children would be given the government award of \"Heroine Mother\" (in Albanian: \"Nënë Heroinë\") along with cash rewards. Abortion was essentially restricted (to encourage high birth rates), except if the birth posed a danger to the mother's life, though it was not completely banned; the process being decided by district medical commissions. As a result, the population of Albania tripled from 1 million in 1944 to around 3 million in 1985.\n\nIn Albania's Third Five Year Plan, China promised a loan of $125 million to build twenty-five chemical, electrical and metallurgical plants called for under the Plan. However, the nation had a difficult transition period, because Chinese technicians were of a lower quality than Soviet ones and the distance between the two nations, plus the poor relations Albania had with its neighbors, further complicated matters. Unlike Yugoslavia or the USSR, China had less influence economically on Albania during Hoxha's leadership. The previous fifteen years (1946–1961) had at least 50% of the economy under foreign commerce.\n\nBy the time the 1976 Constitution prohibited foreign debt, aid and investments, Albania had basically become self-sufficient although it was lacking in modern technology. Ideologically, Hoxha found Mao's initial views to be in line with Marxism-Leninism. Mao condemned Nikita Khrushchev's alleged revisionism and was also critical of Yugoslavia. Aid given from China was interest-free and did not have to be repaid until Albania could afford to do so.\n\nChina never intervened in what Albania's economic output should be, and Chinese technicians worked for the same wages as Albanian workers, unlike Soviet technicians who sometimes made more than three times the pay of Hoxha. Albanian newspapers were reprinted in Chinese newspapers and read on Chinese radio. Finally, Albania led the movement to give the People's Republic of China a seat in the UN, an effort made successful in 1971 and thus replacing the Republic of China's seat.\n\nDuring this period, Albania became the second largest producer of chromium in the world, which was considered an important export for Albania. Strategically, the Adriatic Sea was also attractive to China, and the Chinese leadership had hoped to gain more allies in Eastern Europe with the help of Albania, although this failed. Zhou Enlai visited Albania in January 1964. On 9 January, \"The 1964 Sino-Albanian Joint Statement\" was signed in Tirana. The statement said of relations between socialist countries:\nLike Albania, China defended the \"purity\" of Marxism by attacking both US imperialism as well as \"Soviet and Yugoslav revisionism\", both equally as part of a \"dual adversary\" theory. Yugoslavia was viewed as a \"special detachment of U.S. imperialism\" and a \"saboteur against world revolution.\" These views however began to change in China, which was one of the major issues Albania had with the alliance. Also unlike Yugoslavia and the Soviet Union, the Sino-Albanian alliance lacked \"... an organizational structure for regular consultations and policy coordination, and was characterized by an informal relationship conducted on an \"ad hoc\" basis.\" Mao made a speech on 3 November 1966 which claimed that Albania was the only Marxist-Leninist state in Europe and that \"an attack on Albania will have to reckon with great People's China. If the U.S. imperialists, the modern Soviet revisionists or any of their lackeys dare to touch Albania in the slightest, nothing lies ahead for them but a complete, shameful and memorable defeat.\" Likewise, Hoxha stated that \"You may rest assured, comrades, that come what may in the world at large, our two parties and our two peoples will certainly remain together. They will fight together and they will win together.\"\n\nChina entered into a four-year period of relative diplomatic isolation following the Cultural Revolution and at this point relations between China and Albania reached their zenith. On 20 August 1968, the Soviet invasion of Czechoslovakia was condemned by Albania, as was the Brezhnev doctrine. Albania then officially withdrew from the Warsaw Pact on 5 September. Relations with China began to deteriorate on 15 July 1971, when United States President Richard Nixon agreed to visit China to meet with Zhou Enlai. Hoxha felt betrayed and the government was in a state of shock. On 6 August a letter was sent from the Central Committee of the Albanian Party of Labour to the Central Committee of the Communist Party of China, calling Nixon a \"frenzied anti-Communist.\" The letter stated:\n\nThe result was a 1971 message from the Chinese leadership stating that Albania could not depend on an indefinite flow of further Chinese aid and in 1972 Albania was advised to \"curb its expectations about further Chinese contributions to its economic development.\" By 1973, Hoxha wrote in his diary \"Reflections on China\" that the Chinese leaders:\n\nIn response, trade with COMECON (although trade with the Soviet Union was still blocked) and Yugoslavia grew. Trade with Third World nations was $0.5 million in 1973, but $8.3 million in 1974. Trade rose from 0.1% to 1.6%. Following Mao's death on 9 September 1976, Hoxha (who attended Mao's funeral in Beijing) remained optimistic about Sino-Albanian relations, but in August 1977, Hua Guofeng, the new leader of China, stated that Mao's Three Worlds Theory would become official foreign policy. Hoxha viewed this as a way for China to justify having the U.S. as the \"secondary enemy\" while viewing the Soviet Union as the main one, thus allowing China to trade with the U.S. \"... the Chinese plan of the 'third world' is a major diabolical plan, with the aim that China should become another superpower, precisely by placing itself at the head of the 'third world' and 'non-aligned world.'\" From 30 August to 7 September 1977, Tito visited Beijing and was welcomed by the Chinese leadership. At this point, the Albanian Party of Labour had declared that China was now a revisionist state akin to the Soviet Union and Yugoslavia, and that Albania was the only Marxist–Leninist state on earth. Hoxha stated:\n\nOn 13 July 1978, China announced that it was cutting off all aid to Albania. For the first time in modern history, Albania did not have an ally or major trading partner.\n\nCertain clauses in the 1976 constitution effectively circumscribed the exercise of political liberties which the government interpreted as contrary to the established order. In addition, the government denied the population access to information other than that disseminated by the government-controlled media. Internally, the Sigurimi followed the repressive methods of the NKVD, MGB, KGB, and the East German Stasi. At one point, every third Albanian had either been incarcerated in labour camps or interrogated by the Sigurimi.\n\nTo eliminate dissent, the government imprisoned thousands in forced-labour camps or executed them for crimes such as alleged treachery or for disrupting the proletarian dictatorship. Travel abroad was forbidden after 1968 to all but those on official business. Western European culture was looked upon with deep suspicion, resulting in arrests and bans on unauthorised foreign material. Art was made to reflect the styles of socialist realism. Beards were banned as unhygienic in order to curb the influence of Islam (many Imams and Babas had beards) and the Eastern Orthodox faith.\n\nThe justice system regularly degenerated into show trials. An American human rights group described the proceedings of one trial: \"... [The defendant] was not permitted to question the witnesses and that, although he was permitted to state his objections to certain aspects of the case, his objections were dismissed by the prosecutor who said, 'Sit down and be quiet. We know better than you.'\" In order to lessen the threat of political dissidents and other exiles, relatives of the accused were often arrested, ostracised, and accused of being \"enemies of the people\". Political executions were common, and as a result at least 5,000 people—possibly as many as 25,000—were killed by the regime.\n\nTorture was often used to obtain confessions:One émigré, for example, testified to being bound by his hands and legs for one and a half months, and to being beaten with a belt, fists or boots for periods of two to three hours every two or three days. Another was detained in a cell one meter by eight meters large in the local police station and kept in solitary confinement for a five-day period punctuated by two beating sessions until he signed a confession; he was taken to \"Sigurimi\" headquarters, where he was again tortured and questioned, despite his prior confession, until his three-day trial. Still another witness was confined underground for more than a year in a three-meter square cell. During this time he was interrogated at irregular intervals and subjected to various forms of physical and psychological torture. He was chained to a chair, beaten, and subjected to electric shocks. He was shown a bullet that was supposedly meant for him and told that car engines starting within his earshot were driving victims to their executions, the next of which would be his.During Hoxha's rule, \"[t]here were six institutions for political prisoners and fourteen labour camps where political prisoners and common criminals worked together. It has been estimated that there were approximately 32,000 people imprisoned in Albania in 1985.\"\n\nArticle 47 of the Albanian Criminal Code stated that to \"escape outside the state, as well as refusal to return to the Fatherland by a person who has been sent to serve or has been permitted temporarily to go outside the state\" was an act of treason, a crime punishable by a minimum sentence of ten years and a maximum sentence of death. The Albanian government went to great lengths in order to prevent people from defecting by fleeing the country:An electrically-wired metal fence stands 600 meters to one kilometer from the actual border. Anyone touching the fence not only risks electrocution, but also sets off alarm bells and lights which alert guards stationed at approximately one-kilometer intervals along the fence. Two meters of soil on either side of the fence are cleared in order to check for footprints of escapees and infiltrators. The area between the fence and the actual border is seeded with booby traps such as coils of wire, noise makers consisting of thin pieces of metal strips on top of two wooden slats with stones in a tin container which rattle if stepped on, and flares that are triggered by contact, thus illuminating would-be escapees during the night.\n\nAlbania, the only predominantly Muslim country in Europe at that time, largely owing to Turkish influence in the region, had not, like the Ottoman Empire, identified religion with ethnicity. In the Ottoman Empire, Muslims were viewed as Turks, Orthodox Christians were viewed as Greeks, and Roman Catholics were viewed as Latins. Hoxha believed this was a serious issue, feeling that it both fueled Greek separatists in southern Albania and that it also divided the nation in general. The Agrarian Reform Law of 1945 confiscated much of the church's property in the country. Catholics were the earliest religious community to be targeted, since the Vatican was seen as being an agent of Fascism and anti-Communism. In 1946 the Jesuit Order was banned and the Franciscans were banned in 1947. \"Decree No. 743\" (On religion) sought a national church and forbade religious leaders to associate with foreign powers.\n\nThe Party focused on atheist education in schools. This tactic was effective, primarily due to the high birthrate policy encouraged after the war. During what the religious consider \"holy periods,\" such as Lent and Ramadan, many foods which are scorned by them (dairy products, meat, etc.) were distributed in schools and factories, and those who refused to eat those foods were denounced for their reactionary behaviour.\n\nStarting on 6 February 1967, the Party began to defend secularism rather than Abrahamic religious obscurantism and reaction. Hoxha, who had declared a \"Cultural and Ideological Revolution\" after being partly inspired by China's Cultural Revolution, encouraged communist students and workers to use more forceful tactics to discourage religious practices, although violence was initially condemned.\n\nAccording to Hoxha, the surge in anti-theist activity began with the youth. The result of this \"spontaneous, unprovoked movement\" was the closing of all 2,169 churches and mosques in Albania. State atheism became official policy, and Albania was declared the world's first atheist state. Town and city names which echoed Abrahamic religious themes were abandoned for neutral secular ones, as well as personal names. During this period religiously based names were also made illegal. The \"Dictionary of People's Names\", published in 1982, contained 3,000 approved, secular names. In 1992, Monsignor Dias, the Papal Nuncio for Albania appointed by Pope John Paul II, said that of the three hundred Catholic priests present in Albania prior to the Communists coming to power, only thirty were still active. Promotion of religious obscurantism and all clerics were outlawed as reactionaries. Those religious figures who refused to embrace the principles of Marxist-Leninism were either arrested or carried on their activities from in hiding.\n\nEnver Hoxha had declared during the anti-religious campaign that \"the only religion of Albania is Albanianism,\" a quotation from the poem \"O moj Shqiperi\" (\"O Albania\") by the 19th-century Albanian writer Pashko Vasa.\n\nMuzafer Korkuti, one of the dominant figures in post-war Albanian archaeology and now Director of the institute of Archaeology in Tirana, said this in an interview on 10 July 2002:\n\nEfforts were focused on an Illyrian-Albanian continuity issue.\nAn Illyrian origin of the Albanians (without denying \"Pelasgian\" roots) continued to play a significant role in Albanian nationalism, resulting in a revival of given names supposedly of \"Illyrian\" origin, at the expense of given names associated with Christianity. At first, Albanian nationalist writers opted for the Pelasgians as the forefathers of the Albanians, but as this form of nationalism flourished in Albania under Enver Hoxha, the Pelasgians became a secondary element to the Illyrian theory of Albanian origins, which could claim some support in scholarship.\n\nThe Illyrian descent theory soon became one of the pillars of Albanian nationalism, especially because it could provide some evidence of continuity of an Albanian presence both in Kosovo and in southern Albania, i.e., areas that were subject to ethnic conflicts between Albanians, Serbs and Greeks. Under the government of Enver Hoxha, an autochthonous ethnogenesis was promoted and physical anthropologists tried to demonstrate that Albanians were different from any other Indo-European populations, a theory now disproved.\nThey claimed that the Illyrians were the most ancient people in the Balkans and greatly extended the age of the Illyrian language.\n\nA new Constitution was decided upon by the Seventh Congress of the Albanian Party of Labour on 1–7 November 1976. According to Hoxha, \"The old Constitution was the Constitution of the building of the foundations of socialism, whereas the new Constitution will be the Constitution of the complete construction of a socialist society.\"\n\nSelf-reliance was now stressed more than ever. Citizens were encouraged to train in the use of weapons, and this activity was also taught in schools. This was to encourage the creation of quick partisans.\n\nBorrowing and foreign investment were banned under Article 26 of the Constitution, which read: \"The granting of concessions to, and the creation of foreign economic and financial companies and other institutions or ones formed jointly with bourgeois and revisionist capitalist monopolies and states as well as obtaining credits from them are prohibited in the People's Socialist Republic of Albania.\" Hoxha said of borrowing money and allowing investment from other countries:\nDuring this period Albania was the most isolated and poorest country in Europe and socially backwards by European standards. It had the lowest standard of living in Europe. However, a result of economic self-sufficiency, Albania had a minimal foreign debt. In 1983, Albania imported goods worth $280 million but exported goods worth $290 million, producing a trade surplus of $10 million.\n\nIn 1981, Hoxha ordered the execution of several party and government officials in a new purge. Prime Minister Mehmet Shehu, the second-most powerful man in Albania and Hoxha's closest comrade-in-arms for 40 years, was reported to have committed suicide in December 1981. He was subsequently condemned as a \"traitor\" to Albania, and was also accused of operating in the service of multiple intelligence agencies. It is generally believed that he was either killed or shot himself during a power struggle or over differing foreign policy matters with Hoxha. Hoxha also wrote a large assortment of books during this period, resulting in over 65 volumes of collected works, condensed into six volumes of selected works.\nHoxha suffered a heart attack in 1973 from which he never fully recovered. In increasingly precarious health from the late 1970s onward, he turned most state functions over to Ramiz Alia. In his final days he was bound to a wheelchair and suffering from diabetes, which had developed in 1948, and cerebral ischemia, from which he had suffered since 1983. On 9 April 1985, he was struck by a massive ventricular fibrillation. All efforts to reverse it failed, and he died in the early morning of 11 April 1985. He was 76 years old.\n\nHoxha's death left Albania with a legacy of isolation and fear of the outside world. Despite some economic progress made by Hoxha, the country was in economic stagnation; Albania had been the poorest European country throughout much of the Cold War period. Following the transition to capitalism in 1992, Hoxha's legacy diminished, so that by the early 21st century very little of it was still in place in Albania.\n\nThe surname \"Hoxha\" is the Albanian variant of Hodja (from ), a title given to his ancestors due to their efforts to teach Albanians about Islam. In addition, among the population he was widely known by his nickname of \"Dulla\", a short form for the Muslim name Abdullah stemming from his Muslim roots.\n\nHoxha's parents were Halil and Gjylihan (Gjylo) Hoxha, and Hoxha had three sisters named Fahrije, Haxhire and Sanije. Hysen Hoxha () was Enver Hoxha's uncle and was a militant who campaigned vigorously for the independence of Albania, which occurred when Enver was four years old. His grandfather Beqir was involved in the Gjirokastër section of the League of Prizren.\n\nHoxha's son Sokol Hoxha was the CEO of the Albanian Post and Telecommunication service and is married to Liliana Hoxha. The later democratic president of Albania Sali Berisha was often seen socializing with Sokol Hoxha and other close relatives of leading communist figures in Albania.\n\nHoxha's daughter, Pranvera, is an architect. Along with her husband, Klement Kolaneci, she designed the Enver Hoxha Museum in Tirana, a white-tiled pyramid. Some sources have referred to the edifice, said to be the most expensive ever constructed in Albanian history, as the \"Enver Hoxha Mausoleum,\" though this was not an official appellation. The museum opened in 1988, three years after her father's death, and in 1991 was transformed into a conference center and exhibition venue renamed Pyramid of Tirana.\n\nBanda Mustafaj was a group of four Albanian emigres, led by Xhevdet Mustafa, who wanted to assassinate Enver Hoxha in 1982. The gang was connected to counter-revolutionary elements such as the Albanian mafia and members of the royal House of Zogu. The plan failed and two of its members were killed and another one was arrested. It marked the only real effort to kill Hoxha.\n\n\n\n"}
